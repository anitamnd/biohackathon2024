<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Nucleic Acids Res</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nucleic Acids Res</journal-id>
    <journal-id journal-id-type="publisher-id">nar</journal-id>
    <journal-title-group>
      <journal-title>Nucleic Acids Research</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0305-1048</issn>
    <issn pub-type="epub">1362-4962</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9252827</article-id>
    <article-id pub-id-type="pmid">35552439</article-id>
    <article-id pub-id-type="doi">10.1093/nar/gkac369</article-id>
    <article-id pub-id-type="publisher-id">gkac369</article-id>
    <article-categories>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI00010</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Web Server Issue</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DLEB: a web application for building deep learning models in biological research</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wy</surname>
          <given-names>Suyeon</given-names>
        </name>
        <xref rid="FN1" ref-type="author-notes"/>
        <aff><institution>Department of Biomedical Science and Engineering, Konkuk University</institution>, Seoul 05029, <country country="KR">Republic of Korea</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kwon</surname>
          <given-names>Daehong</given-names>
        </name>
        <xref rid="FN1" ref-type="author-notes"/>
        <aff><institution>Department of Biomedical Science and Engineering, Konkuk University</institution>, Seoul 05029, <country country="KR">Republic of Korea</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kwon</surname>
          <given-names>Kisang</given-names>
        </name>
        <aff><institution>Department of Biomedical Science and Engineering, Konkuk University</institution>, Seoul 05029, <country country="KR">Republic of Korea</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8772-7071</contrib-id>
        <name>
          <surname>Kim</surname>
          <given-names>Jaebum</given-names>
        </name>
        <!--jbkim@konkuk.ac.kr-->
        <xref rid="COR1" ref-type="corresp"/>
        <aff><institution>Department of Biomedical Science and Engineering, Konkuk University</institution>, Seoul 05029, <country country="KR">Republic of Korea</country></aff>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="COR1">To whom correspondence should be addressed. Tel: +82 2 450 0456; Fax: +82 2 444 3490; Email: <email>jbkim@konkuk.ac.kr</email></corresp>
      <fn id="FN1">
        <p>The authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="collection">
      <day>05</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-05-12">
      <day>12</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>12</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <volume>50</volume>
    <issue>W1</issue>
    <fpage>W254</fpage>
    <lpage>W260</lpage>
    <history>
      <date date-type="accepted">
        <day>28</day>
        <month>4</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>14</day>
        <month>4</month>
        <year>2022</year>
      </date>
      <date date-type="received">
        <day>11</day>
        <month>3</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press on behalf of Nucleic Acids Research.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact <email>journals.permissions@oup.com</email></license-p>
      </license>
    </permissions>
    <self-uri xlink:href="gkac369.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>Deep learning has been applied for solving many biological problems, and it has shown outstanding performance. Applying deep learning in research requires knowledge of deep learning theories and programming skills, but researchers have developed diverse deep learning platforms to allow users to build deep learning models without programming. Despite these efforts, it is still difficult for biologists to use deep learning because of limitations of the existing platforms. Therefore, a new platform is necessary that can solve these challenges for biologists. To alleviate this situation, we developed a user-friendly and easy-to-use web application called DLEB (Deep Learning Editor for Biologists) that allows for building deep learning models specialized for biologists. DLEB helps researchers (i) design deep learning models easily and (ii) generate corresponding Python code to run directly in their machines. DLEB provides other useful features for biologists, such as recommending deep learning models for specific learning tasks and data, pre-processing of input biological data, and availability of various template models and example biological datasets for model training. DLEB can serve as a highly valuable platform for easily applying deep learning to solve many important biological problems. DLEB is freely available at <ext-link xlink:href="http://dleb.konkuk.ac.kr/" ext-link-type="uri">http://dleb.konkuk.ac.kr/</ext-link>.</p>
    </abstract>
    <abstract abstract-type="graphical">
      <title>Graphical Abstract</title>
      <p>
        <fig position="float" id="ga1">
          <label>Graphical Abstract</label>
          <caption>
            <p>DLEB (Deep Learning Editor for Biologists) is a user-friendly and easy-to-use web application that allows for building deep learning models specialized for biologists.</p>
          </caption>
          <graphic xlink:href="gkac369figgra1" position="float"/>
        </fig>
      </p>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Ministry of Science and ICT, Republic of Korea</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2021M3H9A2097134</award-id>
        <award-id>2014M3C9A3063544</award-id>
        <award-id>2019R1F1A1042018</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="SEC1">
    <title>INTRODUCTION</title>
    <p>Deep learning is one class of machine learning algorithms that can extract important features from raw data by themselves in an end-to-end method (<xref rid="B1" ref-type="bibr">1</xref>). Dramatic improvement of computational power and learning algorithms, as well as the accumulation of enormous sets of biological data, have enabled the use of deep learning for solving many biological problems (<xref rid="B2" ref-type="bibr">2</xref>) including transcription factor binding site prediction (<xref rid="B3" ref-type="bibr">3</xref>,<xref rid="B4" ref-type="bibr">4</xref>), variant detection (<xref rid="B5" ref-type="bibr">5</xref>,<xref rid="B6" ref-type="bibr">6</xref>), and biomedical image diagnosis (<xref rid="B7" ref-type="bibr">7</xref>,<xref rid="B8" ref-type="bibr">8</xref>). Diverse libraries based on Python programming language, including Tensorflow (<ext-link xlink:href="https://www.tensorflow.org/" ext-link-type="uri">https://www.tensorflow.org/</ext-link>), Keras (<ext-link xlink:href="https://keras.io/" ext-link-type="uri">https://keras.io/</ext-link>) and PyTorch (<ext-link xlink:href="https://pytorch.org/" ext-link-type="uri">https://pytorch.org/</ext-link>), have been developed to help implement deep learning models. However, they are difficult to use without knowledge of deep learning theories and programming skills.</p>
    <p>Accordingly, diverse deep learning platforms such as Deep Cognition (<ext-link xlink:href="https://deepcognition.ai/" ext-link-type="uri">https://deepcognition.ai/</ext-link>), Watson Studio Neural Network Modeler (<ext-link xlink:href="https://www.ibm.com/cloud/watson-studio" ext-link-type="uri">https://www.ibm.com/cloud/watson-studio</ext-link>), and Neural Network Console (<ext-link xlink:href="https://dl.sony.com" ext-link-type="uri">https://dl.sony.com</ext-link>) have been developed to allow users to build deep learning models without programming. Nevertheless, biologists are still discouraged from applying deep learning in their research because existing deep learning platforms only focus on implementing general deep learning models. To successfully apply deep learning models in research, it is important to choose the most appropriate model for the prepared input data and the specific learning task (<xref rid="B2" ref-type="bibr">2</xref>). For example, the convolutional neural network (CNN) is useful for extracting and using local patterns in image data (<xref rid="B9" ref-type="bibr">9</xref>), and the recurrent neural network (RNN) is a good model for processing sequential or signal data (<xref rid="B1" ref-type="bibr">1</xref>). However, existing platforms do not provide enough example models or recommend appropriate models specialized for a specific learning task that users want to solve. Therefore, it is difficult for biologists to choose appropriate deep learning models in those platforms.</p>
    <p>Existing deep learning platforms also do not support pre-processing of biological data, an essential step when using such data in deep learning. However, it is difficult to be carried out by biologists, especially if they do not have enough programming skills. The input data for a deep learning model is typically represented as a matrix with numerical or categorical values. However, because most biological data is not in the shape of a matrix, it has to be pre-processed to be converted into an allowed format. Thus, a pipeline for pre-processing the biological data can be useful for biologists. Furthermore, recent biological studies have applied various deep learning models with complicated structures including a generative adversarial network (GAN) (<xref rid="B10" ref-type="bibr">10</xref>) and a Wasserstein generative adversarial network (WGAN) (arXiv preprint arXiv:1712.06148). However, building such complex deep learning models in existing platforms is still limited and furthermore, most existing platforms are not freely available to users. Therefore, a new deep learning platform that can solve the above limitations especially for biologists is necessary.</p>
    <p>We developed a user-friendly and easy-to-use web application called DLEB (Deep Learning Editor for Biologists) for building deep learning models specialized for biologists. DLEB can help researchers (i) easily design deep learning models and (ii) generate corresponding Python code for running in their machines directly. DLEB provides additional useful features for biologists, such as recommending deep learning models for specific learning tasks and data, pre-processing input biological data, making available of various template models, and example biological datasets for model training. DLEB can serve as a highly valuable platform for easily applying deep learning to solve many important biological problems.</p>
  </sec>
  <sec sec-type="materials|methods" id="SEC2">
    <title>MATERIALS AND METHODS</title>
    <sec id="SEC2-1">
      <title>Web application overview</title>
      <p>DLEB consists of two parts: a client-side web interface and a server-side module (Figure <xref rid="F1" ref-type="fig">1</xref>). In the client-side web interface, users can design deep learning models using a user-friendly and easy-to-use WYSIWYG (What You See Is What You Get) interface. Diverse template models and step-by-step model recommendations are also provided for users who lack adequate knowledge of model structures. After the users design the deep learning model with the specified training parameters, DLEB implements the model and generates a Python code in the server-side module. The generated Python code consists of many useful parts, such as implementation of designed deep learning models, code for pre-processing input biological data, model training, and monitoring, that allow users to run the code and examine the training process in their machines directly without any additional tasks. The details of functions provided by DLEB are described in the following subsections.</p>
      <fig position="float" id="F1">
        <label>Figure 1.</label>
        <caption>
          <p>DLEB workflow. In the client-side web interface, the structure of deep learning models is designed using an easy-to-use web interface of DLEB (top panel). The format of input biological data and parameters are also set in the web interface. Users can use template models and the model recommendation function as they design models (yellow boxes in the top panel). In the server-side module, models designed in the client-side web interface are imported into Python code using the Tensorflow2 and Keras deep learning libraries (bottom panel). The final Python code generated by the server-side module in DLEB includes all required code, ranging from input data pre-processing to model training and validation.</p>
        </caption>
        <graphic xlink:href="gkac369fig1" position="float"/>
      </fig>
    </sec>
    <sec id="SEC2-2">
      <title>Deep learning model design in the client-side web interface</title>
      <p>DLEB provides an easy-to-use web interface for designing and constructing deep learning models using simply mouse click and drag (Figure <xref rid="F2" ref-type="fig">2</xref>). DLEB supports diverse types of layers, activation functions, and pre-trained models (layer panel in Figure <xref rid="F2" ref-type="fig">2A</xref>). Users can easily set various parameters for each layer such as an activation function in the parameter panel (Figure <xref rid="F2" ref-type="fig">2D</xref>). For user's convenience, DLEB provides commonly used parameter values as defaults. Users can also add custom layers and define their operation. Designed models are visualized as a graph structure where nodes and edges represent layers consisting of the model and connections among them, respectively (Figure <xref rid="F2" ref-type="fig">2C</xref>). Additionally, multiple layers designed for working together for the same function such as encoder and decoder can be grouped and visualized as a layer group (blue boxes in Figure <xref rid="F2" ref-type="fig">2C</xref>). Activation functions, which transform outputs of layers, are represented as circles with a function icon positioned on edges.</p>
      <fig position="float" id="F2">
        <label>Figure 2.</label>
        <caption>
          <p>Client-side web interface of DLEB. (<bold>A</bold>) Layer and Template panel for adding layers in models. (<bold>B</bold>) Information panel for displaying the number of layers and parameters in current models. The numbers are changed in real-time. (<bold>C</bold>) Designed models are visualized as in graph form in which nodes and edges represent layers and connections between layers, respectively. Multiple layers can be grouped and visualized as a layer group (blue boxes). Activation functions are presented as circles with a function icon positioned on edges. (<bold>D</bold>) Parameter panel for setting various parameters of each layer and activation functions.</p>
        </caption>
        <graphic xlink:href="gkac369fig2" position="float"/>
      </fig>
      <p>For researchers with little experience in designing deep learning models, DLEB provides diverse template models (Template panel in Figure <xref rid="F2" ref-type="fig">2A</xref>) and recommends deep learning models (Figure <xref rid="F3" ref-type="fig">3</xref>). DLEB supports widely used deep learning models as templates including DNN (Deep Neural Network), CNN, RNN, GAN, WGAN and autoencoder as well as popular pre-trained neural networks including Xception (<xref rid="B11" ref-type="bibr">11</xref>), VGG (arXiv preprint arXiv:1409.1556) and ResNet (<xref rid="B12" ref-type="bibr">12</xref>). DLEB recommends deep learning models appropriate for a selected learning task with its available input data (Figure <xref rid="F3" ref-type="fig">3A</xref>–<xref rid="F3" ref-type="fig">C</xref>). When the users choose a model among the recommended ones, DLEB generates a template for the model in the web interface for further customization (Figure <xref rid="F3" ref-type="fig">3D</xref>).</p>
      <fig position="float" id="F3">
        <label>Figure 3.</label>
        <caption>
          <p>Model recommendation function of DLEB. (<bold>A</bold>) Web interface for selecting a learning task. Users can choose one of the learning tasks including ‘Feature extraction’, ‘Data generation’, ‘Classification’, and ‘Regression’. (<bold>B</bold>) Web interface for selecting the type of available data. (<bold>C</bold>) Examples of models recommended by DLEB. (<bold>D</bold>) Web interface for customizing a recommended model.</p>
        </caption>
        <graphic xlink:href="gkac369fig3" position="float"/>
      </fig>
      <p>Moreover, DLEB provides various information on constructed models that could be used to build complete models. For example, DLEB can calculate and display numbers of layers and parameters in deep learning models that are updated in real time during model construction (Figure <xref rid="F2" ref-type="fig">2B</xref>). Those numbers can be valuable information for users to reduce the size of the model or the time needed for training. DLEB also checks the integrity of model structures and parameter values before generating corresponding Python code.</p>
    </sec>
    <sec id="SEC2-3">
      <title>Deep learning model implementation in the server-side module</title>
      <p>Given a model structure and user-defined parameters, DLEB generates Python code in the server-side module for running in users’ machines directly without additional programming. The Python code consists of multiple parts: pre-processing input biological data, implementing the designed model, and training and monitoring the model. It is difficult to directly use data in formats specialized for biological data, such as FASTA, BAM, bigWig, VCF and GFF, as input data for deep learning models. Therefore, DLEB generates Python code for calculating biological features in each genomic region of interest and summarizing them in a matrix format using the Python library ‘janggu’ (<xref rid="B13" ref-type="bibr">13</xref>) and in-house Python scripts. Image and text data can also be pre-processed into pixels and string arrays, respectively, which are summarized in NumPy (<xref rid="B14" ref-type="bibr">14</xref>) array format that can be directly used in deep learning models. For model training and evaluation, the pre-processed dataset can be divided into training, validation, and test datasets. The generated code can be also used to post-process the output of output layers by converting it into the original format of the input data such as a sequence or an image. The generated Python code includes code for all of the above tasks.</p>
      <p>The designed deep learning models are implemented in the server-side module using Tensorflow2 and Keras, the two most popular deep learning libraries. For handling models with complex structures including multiple inputs or outputs and non-linear topology, the Keras functional API, which is more flexible than the Keras sequential API, is used. To identify the order of layers in the model structure efficiently, the depth-first search algorithm is used for traversing the graph structure of models. Furthermore, the final code includes code for training, testing, monitoring, and saving models. Therefore, all processes from data pre-processing to model training can be executed directly by running just the generated Python code. Additionally, users can obtain intermediate outputs generated by hidden layers by using a command-line option of the generated Python code.</p>
    </sec>
    <sec id="SEC2-4">
      <title>Example biological datasets</title>
      <p>There are various public example datasets for evaluating the performance of deep learning models, such as MNIST (<xref rid="B15" ref-type="bibr">15</xref>), Street View House Numbers (<xref rid="B16" ref-type="bibr">16</xref>), and the 1 Billion Word Language Model Benchmark datasets (arXiv preprint arXiv:1312.3005). Even though there are unique characteristics of biological data compared with other datasets including high complexity (<xref rid="B17" ref-type="bibr">17</xref>) and variability (<xref rid="B18" ref-type="bibr">18</xref>), there are no example datasets specialized for evaluating deep learning models designed for biological input data. Therefore, DLEB provides example biological datasets that researchers have used in deep learning models in recent biological studies (<xref rid="B5" ref-type="bibr">5</xref>,<xref rid="B19" ref-type="bibr">19–21</xref>). DLEB supports example datasets with diverse types including sequence, alignment, signal, and image and provides example deep learning models for each data type.</p>
    </sec>
    <sec id="SEC2-5">
      <title>Implementation</title>
      <p>The server-side module was written by Python (version 3.8.10). The client-side web interface was implemented using HTML5 (<ext-link xlink:href="https://www.w3.org/TR/html5/" ext-link-type="uri">https://www.w3.org/TR/html5/</ext-link>), Bootstrap (version 4.6, <ext-link xlink:href="https://getbootstrap.com/" ext-link-type="uri">https://getbootstrap.com/</ext-link>), and JavaScript (<ext-link xlink:href="https://www.javascript.com/" ext-link-type="uri">https://www.javascript.com/</ext-link>) along with several libraries, such as jQuery (<ext-link xlink:href="https://jquery.com/" ext-link-type="uri">https://jquery.com/</ext-link>) and d3.js (<ext-link xlink:href="https://d3js.org/" ext-link-type="uri">https://d3js.org/</ext-link>). PHP (version5.3.3, <ext-link xlink:href="https://php.net" ext-link-type="uri">https://php.net</ext-link>) was used for Python code generation.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="SEC3">
    <title>RESULTS</title>
    <p>To illustrate the capability and usefulness of DLEB, we built a GAN model that generates in situ hybridization (ISH) images of Drosophila embryo (Figure <xref rid="F4" ref-type="fig">4</xref>). In this experiment, we randomly selected 1,000 ISH images obtained from the Berkeley Drosophila Genome Project (BDGP) dataset (<xref rid="B22" ref-type="bibr">22</xref>) available in the DLEB website to use as training data. The GAN model was designed to contain two sub-models: a generator that could generate the ISH images and a discriminator that could distinguish real images from images the generator provided (Figure <xref rid="F4" ref-type="fig">4A</xref>). The generator comprises two parts: encoder and decoder. The encoder has three convolutional layers and two batch normalization layers with a LeakyReLU activation function, and the decoder consists of three deconvolution layers and two batch normalization layers with a ReLU activation function. To generate image vectors with values ranging from –1 to 1, a Tanh activation function is fed to the result of the final decoder block. The discriminator consists of four convolutional layers followed by the LeakyReLU activation function and batch normalization. The resulting feature vector is fed to a sigmoid activation function for binary classification. To train this model, we set the batch size to 1 and the number of epochs to 100, and used the Adam optimizer with a learning rate of 1E–5 and a cross entropy loss function. Figure <xref rid="F4" ref-type="fig">4B</xref> shows an example of input ISH image, the feature maps of the last hidden layer in the encoder, and the synthesized ISH image from the generator, which was similar to the input image.</p>
    <fig position="float" id="F4">
      <label>Figure 4.</label>
      <caption>
        <p>Example generative adversarial network (GAN) model designed using DLEB. (<bold>A</bold>) The model structure of GAN consisting of a discriminator and a generator. (<bold>B</bold>) Images of the input and the output of the generator in the GAN model. Feature maps of the last hidden layer in the encoder are also visualized as gray-scale images (blue box).</p>
      </caption>
      <graphic xlink:href="gkac369fig4" position="float"/>
    </fig>
    <p>We next built a CNN model that predicts chromatin features from a given DNA sequence as designed and described in (<xref rid="B21" ref-type="bibr">21</xref>) (Figure <xref rid="F5" ref-type="fig">5A</xref>). For training and testing the model, we collected 99 298 DNA sequences in 1000 bp length with labels of 10 chromatin features, and split them to training (80%), validating (10%), and testing (10%) dataset. The DNA sequences in FASTA format were converted to matrices containing one-hot encoded nucleotides using a source code for pre-processing input data provided by DLEB (Figure <xref rid="F5" ref-type="fig">5B</xref>). The CNN model consists of two 2D convolution blocks, a 2D convolution layer, and a fully connected layer (Figure <xref rid="F5" ref-type="fig">5A</xref>). The 2D convolution block contains a 2D convolution layer with a ReLU activation function followed by a max pooling and a dropout layer. The output of the second 2D convolution block is fed to the 2D convolution layer and then to a fully connected layer. The final output vector is then transformed with a sigmoid activation function for multi-label classification of 10 chromatin features. For training this model, the batch size was set to 16 and the SGD optimizer was used with a learning rate of 1E-3 and a mean squared error loss function. Figure <xref rid="F5" ref-type="fig">5C</xref> shows an example of the probability of each chromatin feature predicted by the CNN model (top row) and a true label (bottom row; 1 means the input sequence is related to the corresponding chromatin feature). By using 0.5 as the probability cutoff for classification, we can observe perfect agreement between the predicted and true labels.</p>
    <fig position="float" id="F5">
      <label>Figure 5.</label>
      <caption>
        <p>Example convolutional neural network (CNN) model designed using DLEB. (<bold>A</bold>) The architecture of the CNN model. (<bold>B</bold>) Pre-processing of an input DNA sequence. A DNA sequence in 1000 bp length is converted to a one-hot encoded matrix using a source code provided by DLEB. (<bold>C</bold>) Predicted probabilities of chromatin features (top row) and true labels (bottom row; 1 means the input sequence is related to the corresponding chromatin feature).</p>
      </caption>
      <graphic xlink:href="gkac369fig5" position="float"/>
    </fig>
    <p>The deep learning models shown in Figures <xref rid="F4" ref-type="fig">4A</xref> and <xref rid="F5" ref-type="fig">5A</xref> were solely designed by using the client-side web interface in DLEB. The generated Python code for those models (<xref rid="sup1" ref-type="supplementary-material">Supplementary Data S1 and S2</xref>) was successfully run in a machine with the NVIDIA Quadro RTX 5000 GPU. These experiments clearly showed the applicability of DLEB for solving biological problems using deep learning.</p>
  </sec>
  <sec sec-type="conclusions" id="SEC4">
    <title>CONCLUSIONS</title>
    <p>DLEB is a user-friendly web application for designing and implementing deep learning models for biologists. It helps users design and implement deep learning models with an easy-to-use web interface and various useful functions. DLEB can serve as a highly valuable platform for easily applying deep learning to solve many important biological problems. Because various biological data can be presented in graph form, future updates in DLEB will include the support of graph-based neural networks such as graph convolutional networks.</p>
  </sec>
  <sec sec-type="data-availability" id="SEC5">
    <title>DATA AVAILABILITY</title>
    <p>DLEB is freely available at <ext-link xlink:href="http://dleb.konkuk.ac.kr/" ext-link-type="uri">http://dleb.konkuk.ac.kr/</ext-link>.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>gkac369_Supplemental_File</label>
      <media xlink:href="gkac369_supplemental_file.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec id="SEC6">
    <title>SUPPLEMENTARY DATA</title>
    <p><ext-link xlink:href="https://academic.oup.com/nar/article-lookup/doi/10.1093/nar/gkac369#supplementary-data" ext-link-type="uri">Supplementary Data</ext-link> are available at NAR Online.</p>
  </sec>
  <sec id="SEC7">
    <title>FUNDING</title>
    <p>Ministry of Science and ICT, Republic of Korea [2021M3H9A2097134, 2014M3C9A3063544, 2019R1F1A1042018]. Funding for open access charge: Ministry of Science and ICT, Republic of Korea.</p>
    <p><italic toggle="yes">Conflict of interest statement</italic>. None declared.</p>
  </sec>
  <ref-list id="REF1">
    <title>REFERENCES</title>
    <ref id="B1">
      <label>1.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Goodfellow</surname><given-names>I.</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Courville</surname><given-names>A.</given-names></string-name></person-group><source>Deep Learning</source>. <year>2016</year>; <publisher-name>MIT Press</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eraslan</surname><given-names>G.</given-names></string-name>, <string-name><surname>Avsec</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Gagneur</surname><given-names>J.</given-names></string-name>, <string-name><surname>Theis</surname><given-names>F.J.</given-names></string-name></person-group><article-title>Deep learning: new computational modelling techniques for genomics</article-title>. <source>Nat. Rev. Genet.</source><year>2019</year>; <volume>20</volume>:<fpage>389</fpage>–<lpage>403</lpage>.<pub-id pub-id-type="pmid">30971806</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Koo</surname><given-names>P.K.</given-names></string-name>, <string-name><surname>Ploenzke</surname><given-names>M.</given-names></string-name></person-group><article-title>Deep learning for inferring transcription factor binding sites</article-title>. <source>Curr. Opin. Syst. Biol.</source><year>2020</year>; <volume>19</volume>:<fpage>16</fpage>–<lpage>23</lpage>.<pub-id pub-id-type="pmid">32905524</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Quang</surname><given-names>D.</given-names></string-name>, <string-name><surname>Xie</surname><given-names>X.</given-names></string-name></person-group><article-title>FactorNet: a deep learning framework for predicting cell type specific transcription factor binding from nucleotide-resolution sequential data</article-title>. <source>Methods</source>. <year>2019</year>; <volume>166</volume>:<fpage>40</fpage>–<lpage>47</lpage>.<pub-id pub-id-type="pmid">30922998</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Poplin</surname><given-names>R.</given-names></string-name>, <string-name><surname>Chang</surname><given-names>P.C.</given-names></string-name>, <string-name><surname>Alexander</surname><given-names>D.</given-names></string-name>, <string-name><surname>Schwartz</surname><given-names>S.</given-names></string-name>, <string-name><surname>Colthurst</surname><given-names>T.</given-names></string-name>, <string-name><surname>Ku</surname><given-names>A.</given-names></string-name>, <string-name><surname>Newburger</surname><given-names>D.</given-names></string-name>, <string-name><surname>Dijamco</surname><given-names>J.</given-names></string-name>, <string-name><surname>Nguyen</surname><given-names>N.</given-names></string-name>, <string-name><surname>Afshar</surname><given-names>P.T.</given-names></string-name><etal>et al</etal>.</person-group><article-title>A universal SNP and small-indel variant caller using deep neural networks</article-title>. <source>Nat. Biotechnol.</source><year>2018</year>; <volume>36</volume>:<fpage>983</fpage>–<lpage>987</lpage>.<pub-id pub-id-type="pmid">30247488</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sahraeian</surname><given-names>S.M.E.</given-names></string-name>, <string-name><surname>Liu</surname><given-names>R.L.</given-names></string-name>, <string-name><surname>Lau</surname><given-names>B.Y.</given-names></string-name>, <string-name><surname>Podesta</surname><given-names>K.</given-names></string-name>, <string-name><surname>Mohiyuddin</surname><given-names>M.</given-names></string-name>, <string-name><surname>Lam</surname><given-names>H.Y.K.</given-names></string-name></person-group><article-title>Deep convolutional neural networks for accurate somatic mutation detection</article-title>. <source>Nat. Commun.</source><year>2019</year>; <volume>10</volume>:<fpage>1041</fpage>.<pub-id pub-id-type="pmid">30833567</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Esteva</surname><given-names>A.</given-names></string-name>, <string-name><surname>Kuprel</surname><given-names>B.</given-names></string-name>, <string-name><surname>Novoa</surname><given-names>R.A.</given-names></string-name>, <string-name><surname>Ko</surname><given-names>J.</given-names></string-name>, <string-name><surname>Swetter</surname><given-names>S.M.</given-names></string-name>, <string-name><surname>Blau</surname><given-names>H.M.</given-names></string-name>, <string-name><surname>Thrun</surname><given-names>S.</given-names></string-name></person-group><article-title>Dermatologist-level classification of skin cancer with deep neural networks</article-title>. <source>Nature</source>. <year>2017</year>; <volume>542</volume>:<fpage>115</fpage>–<lpage>118</lpage>.<pub-id pub-id-type="pmid">28117445</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kermany</surname><given-names>D.S.</given-names></string-name>, <string-name><surname>Goldbaum</surname><given-names>M.</given-names></string-name>, <string-name><surname>Cai</surname><given-names>W.</given-names></string-name>, <string-name><surname>Valentim</surname><given-names>C.C.S.</given-names></string-name>, <string-name><surname>Liang</surname><given-names>H.</given-names></string-name>, <string-name><surname>Baxter</surname><given-names>S.L.</given-names></string-name>, <string-name><surname>McKeown</surname><given-names>A.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>G.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>X.</given-names></string-name>, <string-name><surname>Yan</surname><given-names>F.</given-names></string-name><etal>et al</etal>.</person-group><article-title>Identifying medical diagnoses and treatable diseases by image-Based deep learning</article-title>. <source>Cell</source>. <year>2018</year>; <volume>172</volume>:<fpage>1122</fpage>–<lpage>1131</lpage>.<pub-id pub-id-type="pmid">29474911</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yamashita</surname><given-names>R.</given-names></string-name>, <string-name><surname>Nishio</surname><given-names>M.</given-names></string-name>, <string-name><surname>Do</surname><given-names>R.K.G.</given-names></string-name>, <string-name><surname>Togashi</surname><given-names>K.</given-names></string-name></person-group><article-title>Convolutional neural networks: an overview and application in radiology</article-title>. <source>Insights Imaging</source>. <year>2018</year>; <volume>9</volume>:<fpage>611</fpage>–<lpage>629</lpage>.<pub-id pub-id-type="pmid">29934920</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gupta</surname><given-names>A.</given-names></string-name>, <string-name><surname>Zou</surname><given-names>J.</given-names></string-name></person-group><article-title>Feedback GAN for DNA optimizes protein functions</article-title>. <source>Nat. Mach. Intell.</source><year>2019</year>; <volume>1</volume>:<fpage>105</fpage>–<lpage>111</lpage>.</mixed-citation>
    </ref>
    <ref id="B11">
      <label>11.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Chollet</surname><given-names>F.</given-names></string-name></person-group><article-title>Xception: deep learning with depthwise separable convolutions</article-title>. <source>Proc. Cvpr. IEEE</source>. <year>2017</year>; <fpage>1800</fpage>–<lpage>1807</lpage>.</mixed-citation>
    </ref>
    <ref id="B12">
      <label>12.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>K.M.</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>X.Y.</given-names></string-name>, <string-name><surname>Ren</surname><given-names>S.Q.</given-names></string-name>, <string-name><surname>Sun</surname><given-names>J.</given-names></string-name></person-group><article-title>Deep residual learning for image recognition</article-title>. <source>2016 Ieee Conference on Computer Vision and Pattern Recognition (Cvpr)</source>. <year>2016</year>; <fpage>770</fpage>–<lpage>778</lpage>.</mixed-citation>
    </ref>
    <ref id="B13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kopp</surname><given-names>W.</given-names></string-name>, <string-name><surname>Monti</surname><given-names>R.</given-names></string-name>, <string-name><surname>Tamburrini</surname><given-names>A.</given-names></string-name>, <string-name><surname>Ohler</surname><given-names>U.</given-names></string-name>, <string-name><surname>Akalin</surname><given-names>A.</given-names></string-name></person-group><article-title>Deep learning for genomics using janggu</article-title>. <source>Nat. Commun.</source><year>2020</year>; <volume>11</volume>:<fpage>3488</fpage>.<pub-id pub-id-type="pmid">32661261</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harris</surname><given-names>C.R.</given-names></string-name>, <string-name><surname>Millman</surname><given-names>K.J.</given-names></string-name>, <string-name><surname>van der Walt</surname><given-names>S.J.</given-names></string-name>, <string-name><surname>Gommers</surname><given-names>R.</given-names></string-name>, <string-name><surname>Virtanen</surname><given-names>P.</given-names></string-name>, <string-name><surname>Cournapeau</surname><given-names>D.</given-names></string-name>, <string-name><surname>Wieser</surname><given-names>E.</given-names></string-name>, <string-name><surname>Taylor</surname><given-names>J.</given-names></string-name>, <string-name><surname>Berg</surname><given-names>S.</given-names></string-name>, <string-name><surname>Smith</surname><given-names>N.J.</given-names></string-name><etal>et al</etal>.</person-group><article-title>Array programming with NumPy</article-title>. <source>Nature</source>. <year>2020</year>; <volume>585</volume>:<fpage>357</fpage>–<lpage>362</lpage>.<pub-id pub-id-type="pmid">32939066</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deng</surname><given-names>L.</given-names></string-name></person-group><article-title>The mnist database of handwritten digit images for machine learning research [best of the web]</article-title>. <source>IEEE Signal Process. Mag</source>. <year>2012</year>; <volume>29</volume>:<fpage>141</fpage>–<lpage>142</lpage>.</mixed-citation>
    </ref>
    <ref id="B16">
      <label>16.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Netzer</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>T.</given-names></string-name>, <string-name><surname>Coates</surname><given-names>A.</given-names></string-name>, <string-name><surname>Bissacco</surname><given-names>A.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>B.</given-names></string-name>, <string-name><surname>Ng</surname><given-names>A.Y.</given-names></string-name></person-group><article-title>Reading digits in natural images with unsupervised feature learning</article-title>. <source>NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011</source>. <year>2011</year>; </mixed-citation>
    </ref>
    <ref id="B17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>C.M.</given-names></string-name>, <string-name><surname>Jackson</surname><given-names>S.A.</given-names></string-name></person-group><article-title>Machine learning and complex biological data</article-title>. <source>Genome Biol.</source><year>2019</year>; <volume>20</volume>:<fpage>76</fpage>.<pub-id pub-id-type="pmid">30992073</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fay</surname><given-names>D.S.</given-names></string-name>, <string-name><surname>Gerow</surname><given-names>K.</given-names></string-name></person-group><article-title>A biologist's guide to statistical thinking and analysis</article-title>. <source>WormBook: the Online Review of C. elegans Biology</source>. <year>2013</year>; <fpage>1</fpage>–<lpage>54</lpage>.</mixed-citation>
    </ref>
    <ref id="B19">
      <label>19.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Cai</surname><given-names>L.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Kulathinal</surname><given-names>R.</given-names></string-name>, <string-name><surname>Kumar</surname><given-names>S.</given-names></string-name>, <string-name><surname>Ji</surname><given-names>S.</given-names></string-name></person-group><article-title>Deep low-shot learning for biological image classification and visualization from limited training samples</article-title>. <source>IEEE Trans. Neural Netw. Learn. Syst</source>. <year>2021</year>; <pub-id pub-id-type="doi">10.1109/TNNLS.2021.3106831</pub-id>.</mixed-citation>
    </ref>
    <ref id="B20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ernst</surname><given-names>J.</given-names></string-name>, <string-name><surname>Kellis</surname><given-names>M.</given-names></string-name></person-group><article-title>ChromHMM: automating chromatin-state discovery and characterization</article-title>. <source>Nat. Methods</source>. <year>2012</year>; <volume>9</volume>:<fpage>215</fpage>–<lpage>216</lpage>.<pub-id pub-id-type="pmid">22373907</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>J.</given-names></string-name>, <string-name><surname>Troyanskaya</surname><given-names>O.G.</given-names></string-name></person-group><article-title>Predicting effects of noncoding variants with deep learning-based sequence model</article-title>. <source>Nat. Methods</source>. <year>2015</year>; <volume>12</volume>:<fpage>931</fpage>–<lpage>934</lpage>.<pub-id pub-id-type="pmid">26301843</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mace</surname><given-names>D.L.</given-names></string-name>, <string-name><surname>Varnado</surname><given-names>N.</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>W.P.</given-names></string-name>, <string-name><surname>Frise</surname><given-names>E.</given-names></string-name>, <string-name><surname>Ohler</surname><given-names>U.</given-names></string-name></person-group><article-title>Extraction and comparison of gene expression patterns from 2D RNA in situ hybridization images</article-title>. <source>Bioinformatics</source>. <year>2010</year>; <volume>26</volume>:<fpage>761</fpage>–<lpage>769</lpage>.<pub-id pub-id-type="pmid">19942587</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
