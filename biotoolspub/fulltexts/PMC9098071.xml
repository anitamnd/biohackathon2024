<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?subarticle pone.0268426.r001?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS One</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLoS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9098071</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0268426</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-21-05607</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Data Management</subject>
          <subj-group>
            <subject>Data Visualization</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Research Assessment</subject>
          <subj-group>
            <subject>Reproducibility</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Data Management</subject>
          <subj-group>
            <subject>Data Processing</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Industrial Engineering</subject>
          <subj-group>
            <subject>Quality Control</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Earth Sciences</subject>
        <subj-group>
          <subject>Geography</subject>
          <subj-group>
            <subject>Physical Geography</subject>
            <subj-group>
              <subject>Earth Systems</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Electronics Engineering</subject>
          <subj-group>
            <subject>Computer Engineering</subject>
            <subj-group>
              <subject>Man-Computer Interface</subject>
              <subj-group>
                <subject>Graphical User Interfaces</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Computer Architecture</subject>
          <subj-group>
            <subject>User Interfaces</subject>
            <subj-group>
              <subject>Graphical User Interfaces</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
            <subj-group>
              <subject>Open Source Software</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
            <subj-group>
              <subject>Open Source Software</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Science Policy</subject>
        <subj-group>
          <subject>Open Science</subject>
          <subj-group>
            <subject>Open Source Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Computational Techniques</subject>
          <subj-group>
            <subject>Computational Pipelines</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Addressing the need for interactive, efficient, and reproducible data processing in ecology with the datacleanr R package</article-title>
      <alt-title alt-title-type="running-head">Interactive and reproducible data processing with the datacleanr R package</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9641-2805</contrib-id>
        <name>
          <surname>Hurley</surname>
          <given-names>Alexander G.</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Peters</surname>
          <given-names>Richard L.</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff003" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pappas</surname>
          <given-names>Christoforos</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff004" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="aff005" ref-type="aff">
          <sup>5</sup>
        </xref>
        <xref rid="aff006" ref-type="aff">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Steger</surname>
          <given-names>David N.</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff007" ref-type="aff">
          <sup>7</sup>
        </xref>
        <xref rid="aff008" ref-type="aff">
          <sup>8</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Heinrich</surname>
          <given-names>Ingo</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff007" ref-type="aff">
          <sup>7</sup>
        </xref>
        <xref rid="aff008" ref-type="aff">
          <sup>8</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Climate Dynamics and Landscape Evolution, GFZ German Research Centre for Geosciences, Potsdam, Germany</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Laboratory of Plant Ecology, Department of Plants and Crops, Faculty of Bioscience Engineering, Ghent University, Ghent, Belgium</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Department of Environmental Sciences, University of Basel, Basel, Switzerland</addr-line>
    </aff>
    <aff id="aff004">
      <label>4</label>
      <addr-line>Centre d’étude de la forêt, Université du Québec à Montréal, Montréal, Canada</addr-line>
    </aff>
    <aff id="aff005">
      <label>5</label>
      <addr-line>Département Science et Technologie, Téluq, Université du Québec, Montréal, Canada</addr-line>
    </aff>
    <aff id="aff006">
      <label>6</label>
      <addr-line>Department of Civil Engineering, University of Patras, Rio Patras, Greece</addr-line>
    </aff>
    <aff id="aff007">
      <label>7</label>
      <addr-line>Humboldt-Universität zu Berlin, Berlin, Germany</addr-line>
    </aff>
    <aff id="aff008">
      <label>8</label>
      <addr-line>Natural Sciences Unit, German Archaeological Institute DAI, Berlin, Germany</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Krug</surname>
          <given-names>Rainer M.</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>University of Zurich Faculty of Mathematics and Science: Universitat Zurich Mathematisch-Naturwissenschaftliche Fakultat, SWITZERLAND</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>hurley@gfz-potsdam.de</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>12</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>17</volume>
    <issue>5</issue>
    <elocation-id>e0268426</elocation-id>
    <history>
      <date date-type="received">
        <day>19</day>
        <month>2</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>4</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 Hurley et al</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Hurley et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pone.0268426.pdf"/>
    <abstract>
      <p>Ecological research, just as all Earth System Sciences, is becoming increasingly data-rich. Tools for processing of “big data” are continuously developed to meet corresponding technical and logistical challenges. However, even at smaller scales, data sets may be challenging when best practices in data exploration, quality control and reproducibility are to be met. This can occur when conventional methods, such as generating and assessing diagnostic visualizations or tables, become unfeasible due to time and practicality constraints. Interactive processing can alleviate this issue, and is increasingly utilized to ensure that large data sets are diligently handled. However, recent interactive tools rarely enable data manipulation, may not generate reproducible outputs, or are typically data/domain-specific. We developed datacleanr, an interactive tool that facilitates best practices in data exploration, quality control (e.g., outlier assessment) and flexible processing for multiple tabular data types, including time series and georeferenced data. The package is open-source, and based on the R programming language. A key functionality of datacleanr is the “reproducible recipe”—a translation of all interactive actions into R code, which can be integrated into existing analyses pipelines. This enables researchers experienced with script-based workflows to utilize the strengths of interactive processing without sacrificing their usual work style or functionalities from other (R) packages. We demonstrate the package’s utility by addressing two common issues during data analyses, namely 1) identifying problematic structures and artefacts in hierarchically nested data, and 2) preventing excessive loss of data from ‘coarse,’ code-based filtering of time series. Ultimately, with datacleanr we aim to improve researchers’ workflows and increase confidence in and reproducibility of their results.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001711</institution-id>
            <institution>Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung</institution>
          </institution-wrap>
        </funding-source>
        <award-id>P2BSP3_184475</award-id>
        <principal-award-recipient>
          <name>
            <surname>Peters</surname>
            <given-names>Richard L.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001656</institution-id>
            <institution>Helmholtz-Gemeinschaft</institution>
          </institution-wrap>
        </funding-source>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9641-2805</contrib-id>
          <name>
            <surname>Hurley</surname>
            <given-names>Alexander</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>AGH and IH were supported through the Helmholtz-Climate-Initiative (HI-CAM), funded by the Helmholtz Initiative and Networking Fund (<ext-link xlink:href="https://www.helmholtz.de/en/about-us/the-association/initiating-and-networking/" ext-link-type="uri">https://www.helmholtz.de/en/about-us/the-association/initiating-and-networking/</ext-link>); the authors are responsible for the content of this publication. RLP acknowledges support of the Swiss National Science Foundation (<ext-link xlink:href="http://www.snf.ch/" ext-link-type="uri">http://www.snf.ch/</ext-link>), Grant P2BSP3_184475. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="9"/>
      <table-count count="0"/>
      <page-count count="16"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All software and data necessary for reproducibility are publicly available. The software is available from an online repository at <ext-link xlink:href="https://github.com/the-Hull/datacleanr" ext-link-type="uri">https://github.com/the-Hull/datacleanr</ext-link> and via CRAN (<ext-link xlink:href="https://cran.r-project.org/package=datacleanr" ext-link-type="uri">https://cran.r-project.org/package=datacleanr</ext-link>); the software version used for this publication is archived at <ext-link xlink:href="https://doi.org/10.5281/zenodo.6337609" ext-link-type="uri">https://doi.org/10.5281/zenodo.6337609</ext-link>. Eddy covariance data are available online from the FLUXNET2015 webpage (<ext-link xlink:href="http://fluxnet.fluxdata.org/data/fluxnet2015-dataset/" ext-link-type="uri">http://fluxnet.fluxdata.org/data/fluxnet2015-dataset/</ext-link>). The allometry and trait data is available at <ext-link xlink:href="https://github.com/dfalster/baad" ext-link-type="uri">https://github.com/dfalster/baad</ext-link>. The Berlin street and park tree data is available at <ext-link xlink:href="https://daten.berlin.de/" ext-link-type="uri">https://daten.berlin.de/</ext-link>. The data to reproduce the profiling and time series cleaning example are archived at <ext-link xlink:href="https://doi.org/10.5281/zenodo.4550726" ext-link-type="uri">https://doi.org/10.5281/zenodo.4550726</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All software and data necessary for reproducibility are publicly available. The software is available from an online repository at <ext-link xlink:href="https://github.com/the-Hull/datacleanr" ext-link-type="uri">https://github.com/the-Hull/datacleanr</ext-link> and via CRAN (<ext-link xlink:href="https://cran.r-project.org/package=datacleanr" ext-link-type="uri">https://cran.r-project.org/package=datacleanr</ext-link>); the software version used for this publication is archived at <ext-link xlink:href="https://doi.org/10.5281/zenodo.6337609" ext-link-type="uri">https://doi.org/10.5281/zenodo.6337609</ext-link>. Eddy covariance data are available online from the FLUXNET2015 webpage (<ext-link xlink:href="http://fluxnet.fluxdata.org/data/fluxnet2015-dataset/" ext-link-type="uri">http://fluxnet.fluxdata.org/data/fluxnet2015-dataset/</ext-link>). The allometry and trait data is available at <ext-link xlink:href="https://github.com/dfalster/baad" ext-link-type="uri">https://github.com/dfalster/baad</ext-link>. The Berlin street and park tree data is available at <ext-link xlink:href="https://daten.berlin.de/" ext-link-type="uri">https://daten.berlin.de/</ext-link>. The data to reproduce the profiling and time series cleaning example are archived at <ext-link xlink:href="https://doi.org/10.5281/zenodo.4550726" ext-link-type="uri">https://doi.org/10.5281/zenodo.4550726</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Ecology, just as all Earth system sciences, is increasingly data-rich [e.g., <xref rid="pone.0268426.ref001" ref-type="bibr">1</xref>]. These data are a boon for novel inferences, and increasingly inform decision making [<xref rid="pone.0268426.ref002" ref-type="bibr">2</xref>, <xref rid="pone.0268426.ref003" ref-type="bibr">3</xref>], for example, through databases from coordinated efforts that facilitate synoptic studies of carbon fluxes [e.g., FLUXNET, <xref rid="pone.0268426.ref004" ref-type="bibr">4</xref>] and stocks [<xref rid="pone.0268426.ref005" ref-type="bibr">5</xref>] or ecosystem functioning [e.g., via trait databases like TRY, <xref rid="pone.0268426.ref006" ref-type="bibr">6</xref>]. Low-cost monitoring and sensing solutions have also immensely increased the amount of data individual researchers can produce [e.g., <xref rid="pone.0268426.ref007" ref-type="bibr">7</xref>]. However, the data deluge—often from heterogeneous sources—introduces new logistical and computational challenges for researchers [<xref rid="pone.0268426.ref007" ref-type="bibr">7</xref>, <xref rid="pone.0268426.ref008" ref-type="bibr">8</xref>] wanting to maintain best practices in data analyses, reproducibility and transparency [see frameworks on workflow implementation in <xref rid="pone.0268426.ref009" ref-type="bibr">9</xref>, <xref rid="pone.0268426.ref010" ref-type="bibr">10</xref>]. It is clear that we need not only frameworks, but also flexible tools to deal with the ever-increasing, heterogeneous data and corresponding issues.</p>
    <p>Paramount to any analyses is ensuring the validity of input data through adequate exploration and quality control, which allows identifying any idiosyncrasies, outliers or erroneous structures. However, with growing data volumes this becomes increasingly difficult. Indeed, several definitions establish “big data” at the threshold where single entities (i.e. researchers, institutions, disciplines) are no longer able to manage and process a given data set due to its size or complexity [e.g., <xref rid="pone.0268426.ref011" ref-type="bibr">11</xref>, <xref rid="pone.0268426.ref012" ref-type="bibr">12</xref>]. Yet, several current research applications in ecology and Earth system science require handling more than Gigabyte-scale data and regularly lead to the development of dedicated and domain-specific processing pipelines and tools, e.g., processing of raw data from FLUXNET [<xref rid="pone.0268426.ref004" ref-type="bibr">4</xref>] or automating data assimilation from long-term experiments [<xref rid="pone.0268426.ref013" ref-type="bibr">13</xref>].</p>
    <p>Individual scientists, however, frequently encounter data sets smaller than this, which nonetheless challenge the feasibility of common data processing and exploration methods. These include the best practice examples of generating static diagnostic/summary visualizations, statistics and tables for detecting problematic observations [e.g., <xref rid="pone.0268426.ref014" ref-type="bibr">14</xref>, <xref rid="pone.0268426.ref015" ref-type="bibr">15</xref>]. Data sets of this intermediate scale are termed “high-volume,” rather than “big,” for purposes of this study. Issues with these data often arise when the dimensions and data types require numerous of the aforementioned items (e.g., n-dimensional visualizations), and their individual assessment becomes unfeasible due to time and practicality constraints, even when their generation can be largely automated. Hence, they can pose a challenge even for experienced researchers adept at script-based analyses, if convenient tools do not exist or are financially inaccessible due to commercial licensing. For instance, over-plotting may require generating several static visualizations for nested categorical levels, such as branch, individual tree and forest stand, or for spatial granularity, such as plot, site and region. Furthermore, time series from monitoring equipment may show issues related to sensor drift, step-shifts, or random sensor errors. While gap-filtering, trend-adjustment and outlier-removal algorithms exist for these circumstances [e.g., <xref rid="pone.0268426.ref016" ref-type="bibr">16</xref>, <xref rid="pone.0268426.ref017" ref-type="bibr">17</xref>], subsequent manual checking is usually still advised, leading to similar issues as above. For time series, in particular, problematic periods (e.g., systematically-occurring sensor errors) may be removed entirely for convenience in code-based processing; by contrast, interactive engagement down to individual observations may allow applying more diligence and retaining more data.</p>
    <p>Ideally, researchers should be able to engage with their data, across scales and dimensions as diligently as needed, with as little effort as possible. Accordingly, interactive processing is increasingly called for and deemed critical [<xref rid="pone.0268426.ref018" ref-type="bibr">18</xref>] for ensuring best practices in data exploration, and quality control when dealing with high-volume data and beyond [e.g., <xref rid="pone.0268426.ref019" ref-type="bibr">19</xref>, <xref rid="pone.0268426.ref020" ref-type="bibr">20</xref>]. Indeed, interactive exploration is increasingly provided through open-source graphing frameworks (e.g., plotly; <ext-link xlink:href="https://plotly.com/" ext-link-type="uri">https://plotly.com/</ext-link> or, highcharts; <ext-link xlink:href="https://highcharts.com/" ext-link-type="uri">https://highcharts.com/</ext-link>) and/or commercially-licensed software (e.g., Tableau®; <ext-link xlink:href="https://tableau.com/" ext-link-type="uri">https://tableau.com/</ext-link>). However, actual data manipulation, and especially the generation of subsequent outputs that are fully reproducible, are far less common features; this could potentially stimulate reluctance for sharing analysis code [e.g., <xref rid="pone.0268426.ref021" ref-type="bibr">21</xref>]. Further issues can arise when outputs are (commercially licensed) platform/software dependent and thus not easily incorporated with other widely-used languages, such as R [<xref rid="pone.0268426.ref022" ref-type="bibr">22</xref>] or python [<xref rid="pone.0268426.ref023" ref-type="bibr">23</xref>]. Interactive, reproducible is, therefore, typically linked to method-specific workflows within research domains, for instance, to annotate images [e.g., <xref rid="pone.0268426.ref024" ref-type="bibr">24</xref>], acoustic files [e.g., <xref rid="pone.0268426.ref025" ref-type="bibr">25</xref>], or explore spatial and time series data [e.g., <xref rid="pone.0268426.ref020" ref-type="bibr">20</xref>, <xref rid="pone.0268426.ref026" ref-type="bibr">26</xref>].</p>
    <p>There is a clear need for interactive tools that can facilitate best practices in processing heterogeneous, high-volume data, while enabling interoperability with reproducible workflows. To address this, we developed datacleanr: an open-source R-based package containing a graphical user interface for rapid data exploration and filtering, as well as interactive visualization and annotation of various data types, including spatial (georeferenced) and time series observations. datacleanr is designed to fit in existing, scripted processing (R) pipelines, without sacrificing the benefits of interactivity: this is achieved through features that allow validating the results of previous quality control, and by generating a code script to repeat any interactive operation. The code script can be slotted into existing workflows, and datacleanr’s output can hence be directly used for subsequent reproducible analyses.</p>
    <p>Below we provide an overview of the package. Additionally, we demonstrate datacleanr’s utility with two ecology-based use-cases addressing common issues during data processing: 1) Identifying problematic data structures and artefacts using an urban tree survey, where data is nested by species, street and city district. 2) Preventing excessive loss of data from “coarse,” code-based filtering in messy time series of sap flow data, bolstering subsequent analyses.</p>
    <p>Lastly, we provide an outlook for future developments and conclude by inviting the community to contribute to further increase datacleanr’s capabilities and reach.</p>
  </sec>
  <sec id="sec002">
    <title>Datacleanr overview</title>
    <sec id="sec003">
      <title>Availability</title>
      <p>This publication used v1.0.3 of datacleanr, which is permanently archived on Zenodo under <ext-link xlink:href="https://doi.org/10.5281/zenodo.6337609" ext-link-type="uri">https://doi.org/10.5281/zenodo.6337609</ext-link>. Stable package releases are available on the Comprehensive R Archive Network (CRAN; use install.packages(“datacleanr”)), which aim to mirror new developments provided and documented on a dedicated repository (<ext-link xlink:href="http://www.github.com/the-hull/datacleanr" ext-link-type="uri">www.github.com/the-hull/datacleanr</ext-link>). The repository provides installation instructions for all sources (CRAN, repository) and animated demonstrations with test data. datacleanr is available under a GPL-3 license.</p>
    </sec>
    <sec id="sec004">
      <title>Capabilities</title>
      <p>datacleanr is an interactive R package for processing high-volume data, and it caters to best practices in data exploration, processing, and reproducibility. This section describes the general capabilities of the package, and an in-depth walk-through of all functionalities is provided with animated examples in <xref rid="pone.0268426.s001" ref-type="supplementary-material">S1 File</xref> in the supplemental material. The package uses the shiny [<xref rid="pone.0268426.ref027" ref-type="bibr">27</xref>] and plotly [<xref rid="pone.0268426.ref028" ref-type="bibr">28</xref>] packages to generate a web browser-based graphical user interface (GUI), where modern browser capabilities allow displaying approximately 2 million observations smoothly, around which the visualizations and processing increasingly slow down (dependent on computing power). The GUI has four modules represented in application tabs, which are documented using intuitively-placed help links and package documentation: 1) Set-up and Overview (grouping and exploration), 2) Filtering, 3) Visual Cleaning and Annotating, 4) Extraction (reproducible recipe). The processing GUI is launched with datacleanr::dcr_app(x) in R, where x is a data set for processing (several data types are possible, including data.frames, tibbles and data.tables; run? datacleanr::dcr_app() for help).</p>
      <p>The chart in <xref rid="pone.0268426.g001" ref-type="fig">Fig 1</xref> shows the datacleanr workflow across the four modules (A-D) with optional pre- and post-processing with external algorithms. Users are encouraged to cycle through multiple grouping structures, filters and variable combinations to get adequately acquainted with their data. The functions of individual tabs are discussed in detail below.</p>
      <fig position="float" id="pone.0268426.g001">
        <object-id pub-id-type="doi">10.1371/journal.pone.0268426.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>Conceptual workflow for datacleanr across its four processing modules.</title>
          <p>A) The Set-up and Overview tab allows for a quick initial assessment of a data set (variable types, distribution, completeness), where nested structures (e.g., by plot, site, region) can be resolved by defining a grouping structure from a categorical data column. B) The Filtering tab allows sub-setting the data based on valid R code (logical statements), which can be targeted (i.e., “scoped”) to individual groups from A). C) The Visual Cleaning and Annotating tab allows generating two or three dimensional visualizations (X, Y, and point size) rapidly, while dividing the data set into groups specified in A); data points for further inspection can be identified by clicking or lasso selection through which annotations may also be added. An overview table and histogram highlight selected points and the potential impact on the data’s distribution, should the selected observations be removed. D) The Extract Recipe tab generates code to reproduce all processing steps, which can be copied to the clipboard or sent directly to an active RStudio® [<xref rid="pone.0268426.ref029" ref-type="bibr">29</xref>] session’s script; depending on the processing mode (in memory or from a file), additional settings for file name specification are available. The schematic here illustrates the potential for including datacleanr into an existing workflow, for example, with prior determination of outliers using external algorithms (requires appending a logical TRUE/FALSE column named.dcrflag), interactive exploration and processing (with datacleanr), and informing subsequent analyses by drawing on the interactively annotated data (.annotation column in output from datacleanr).</p>
        </caption>
        <graphic xlink:href="pone.0268426.g001" position="float"/>
      </fig>
      <sec id="sec005">
        <title>Set-up and overview</title>
        <p>datacleanr facilitates processing of nested data through defining a grouping structure (<xref rid="pone.0268426.g001" ref-type="fig">Fig 1A</xref>; also see animation at <ext-link xlink:href="https://doi.org/10.5281/zenodo.6469658" ext-link-type="uri">https://doi.org/10.5281/zenodo.6469658</ext-link>) to the level of interest (e.g., by selecting species, plot and region). The structure is available during targeted filtering (scoping; see section <italic toggle="yes">Filtering</italic>) and visual cleaning (see section <italic toggle="yes">Visual cleaning and annotating</italic>, as well as <italic toggle="yes">Case studies</italic>). Once the grouping is set, a dataset summary can be generated via the package summarytools [<xref rid="pone.0268426.ref030" ref-type="bibr">30</xref>], highlighting duplicates, missingness, and distribution of each variable.</p>
      </sec>
      <sec id="sec006">
        <title>Filtering</title>
        <p>Filtering (<xref rid="pone.0268426.g001" ref-type="fig">Fig 1B</xref>; also see animation at <ext-link xlink:href="https://doi.org/10.5281/zenodo.6469721" ext-link-type="uri">https://doi.org/10.5281/zenodo.6469721</ext-link>) is done by adding filter statement text boxes by clicking on the respective button on the tab. Statements can be applied to the entire data set, or targeted to specific groups using a “scoped” (i.e. group-specific) filter. The application’s interactivity allows reviewing the impact of filters through a text note highlighting the percentage of removed data and an overview table showing the remaining observations (per group), as well as by iterating between settings and visualizations (across several variable combinations). This is more efficient than (re-)generating individual, static figures, and highlights which data will be excluded. The result of a quantile-based threshold filter implemented in datacleanr, as used e.g., in TRY [<xref rid="pone.0268426.ref006" ref-type="bibr">6</xref>] or BAAD [<xref rid="pone.0268426.ref031" ref-type="bibr">31</xref>], is illustrated in <xref rid="pone.0268426.g002" ref-type="fig">Fig 2</xref>.</p>
        <fig position="float" id="pone.0268426.g002">
          <object-id pub-id-type="doi">10.1371/journal.pone.0268426.g002</object-id>
          <label>Fig 2</label>
          <caption>
            <title>Example application of statistical filtering.</title>
            <p>A percentile threshold filter (0.01 and 0.99) is applied to the full range or scoped to groups (panels, see bold text) on the x-variable. Trait data from BAAD [<xref rid="pone.0268426.ref031" ref-type="bibr">31</xref>] is used to illustrate the impact on bivariate relationships across plant functional types, where the gray shading indicates the filtered variable space and text labels count the excluded observations (e.g.,” n = 2”). Note, the figure was not generated in datacleanr.</p>
          </caption>
          <graphic xlink:href="pone.0268426.g002" position="float"/>
        </fig>
        <p>Example of the impact of statistical filtering on bivariate relationships between trait data from BAAD [<xref rid="pone.0268426.ref031" ref-type="bibr">31</xref>]. A percentile threshold filter (0.01 and 0.99) is used to remove extreme low and high values on the x-variable across its full space (left) or scoped to groups represented by functional types (right). The gray shading indicates the filtered variable space (full or scoped), while text labels and black points count and highlight, respectively, individual observations captured by the applied filter. Note, the figure was not generated in datacleanr.</p>
        <p>Any filtering statement (provided as valid R code) which evaluates to TRUE or FALSE and using the dataset’s column names can be used, as shown below. That is, let example_numeric_variable and example_categorical_variable be column names, then following statements are valid and can be supplied in a filter statement box:</p>
        <p specific-use="line">
          <italic toggle="yes"># simple logical filter</italic>
        </p>
        <p specific-use="line">example_numeric_variable &gt; 3</p>
        <p specific-use="line">
          <italic toggle="yes"># using expressions to define thresholds</italic>
        </p>
        <p specific-use="line">
          <italic toggle="yes">## percentile/rank based</italic>
        </p>
        <p specific-use="line">example_numeric_variable &gt; quantile(example_numeric_variable, 0.01)</p>
        <p specific-use="line">
          <italic toggle="yes">## dispersion based (median absolute distance)</italic>
        </p>
        <p specific-use="line">example_numeric_variable &gt; median(example_numeric_variable)–</p>
        <p specific-use="line">3 * mad(example_numeric_variable)</p>
        <p specific-use="line">
          <italic toggle="yes"># example for subsetting</italic>
        </p>
        <p specific-use="line">example_categorical_variable = = "SpeciesA"</p>
        <p specific-use="line">example_categorical_variable %in% c("SpeciesA", "SpeciesB")</p>
      </sec>
      <sec id="sec007">
        <title>Visual cleaning and annotating</title>
        <p>Interactive visualizations (<xref rid="pone.0268426.g001" ref-type="fig">Fig 1C</xref>; also see animation at <ext-link xlink:href="https://doi.org/10.5281/zenodo.6469756" ext-link-type="uri">https://doi.org/10.5281/zenodo.6469756</ext-link>) via plotly [<xref rid="pone.0268426.ref028" ref-type="bibr">28</xref>] are based on bivariate scatter or time series plots with optional third dimension represented by point size. Spatial data can be displayed on interactive map tiles, if columns named lon (longitude) and lat (latitude) are present in decimal degrees. Example visualizations for currently supported data types are in <xref rid="pone.0268426.g003" ref-type="fig">Fig 3</xref>.</p>
        <fig position="float" id="pone.0268426.g003">
          <object-id pub-id-type="doi">10.1371/journal.pone.0268426.g003</object-id>
          <label>Fig 3</label>
          <caption>
            <title>Examples of interactive visualizations.</title>
            <p>Panels show a subset of hourly time series of latent heat fluxes (A) from all Swiss FLUXNET2015 sites [<xref rid="pone.0268426.ref004" ref-type="bibr">4</xref>], spatial data illustrating sample locations for BAAD (B) and the relationship between stem diameter and height (C) with plant traits from BAAD [<xref rid="pone.0268426.ref031" ref-type="bibr">31</xref>]. Colors represent the grouping structure defined in the “Set-up” operation (A: Swiss sites; B, C: functional types).</p>
          </caption>
          <graphic xlink:href="pone.0268426.g003" position="float"/>
        </fig>
        <p>A key feature on the visualization tab is the grouping structure table, which allows highlighting granular data levels, e.g., all species at a given site, by hiding all other data (see Figs <xref rid="pone.0268426.g007" ref-type="fig">7</xref> and <xref rid="pone.0268426.g008" ref-type="fig">8</xref>). Entries in this table correspondto colored traces in the figure legend via unique numbers. Users can thus cycle through or compare deeply nested data structures. Visualizations support zooming and panning (scatter plots and maps), as well as axes scrolling and stretching on mouse hover-over. Observations can be (de-)selected through clicking or lasso and box selecting, and annotated with text labels, which are listed in a summary table below the visualization. Annotations can be provided in a text box, and are added either individually through a button click, or automatically on every selection (requires ticking corresponding box); these are added to the input data in an appended column (.annotation) and can be used to inform subsequent processing. Lastly, histograms of all displayed, numeric variables can be generated to assess the potential impact of data removal.</p>
      </sec>
      <sec id="sec008">
        <title>Extract recipe</title>
        <p>Reproducibility requires that any analyses step can be recovered, comprehended, and executed identically, repeatedly, and independently of the user. The datacleanr package caters to this by translating every processing (filtering, highlighting or annotating) action into R code on the Extract Recipe tab, which can be copied or directly sent to an active RStudio® [R development environment, 29] session (<xref rid="pone.0268426.g001" ref-type="fig">Fig 1D</xref>; also see animation at <ext-link xlink:href="https://doi.org/10.5281/zenodo.6469767" ext-link-type="uri">https://doi.org/10.5281/zenodo.6469767</ext-link>). This code represents a recipe to reproduce the interactive processing, and survives the interactive session; subsequent analyses steps can thus include and build on the recipe (i.e., code script) for generating quality-controlled data. The dcr_app can also be launched with a file path to an *.RDS file on disk, rather than an object in R’s environment (i.e., memory). In this case, additional saving options are available for adjusting output names and file locations (<xref rid="pone.0268426.g004" ref-type="fig">Fig 4</xref>). This is currently recommended for data requiring extensive annotation, which would result in code scripts of considerable length. However, the option will be made available for both modes (file path, object) in a future version.</p>
        <fig position="float" id="pone.0268426.g004">
          <object-id pub-id-type="doi">10.1371/journal.pone.0268426.g004</object-id>
          <label>Fig 4</label>
          <caption>
            <title>Code recipe extraction.</title>
            <p>Options provided in the Extract Recipe tab for defining and saving outputs when datacleanr is launched with a file path. Copying or sending the recipe (i.e. R code) to an active RStudio® [<xref rid="pone.0268426.ref029" ref-type="bibr">29</xref>] session is always possible.</p>
          </caption>
          <graphic xlink:href="pone.0268426.g004" position="float"/>
        </fig>
      </sec>
      <sec id="sec009">
        <title>Interoperability with external packages and algorithms. Interoperability is achieved with pre- and post-processing (in R) by two means:</title>
        <list list-type="order">
          <list-item>
            <p>Observations that were flagged by prior outlier or data processing have distinct symbols in interactive visualizations; this is enabled by adding (or renaming) a logical (TRUE / FALSE) flagging column named.dcrflag before launching dcr_app().</p>
          </list-item>
          <list-item>
            <p>The reproducible code recipe can be used as a step following or preceding additional analyses.</p>
          </list-item>
        </list>
        <p>datacleanr can hence be embedded in R- based workflows with the existing strengths of R’s extensive ecosystem of packages to increase flexibility and, ultimately, productivity. For instance, a script-based workflow applying widely-used R packages for reading, “wrangling” and cleaning data, such as readr [<xref rid="pone.0268426.ref032" ref-type="bibr">32</xref>], dplyr [<xref rid="pone.0268426.ref033" ref-type="bibr">33</xref>], tidyr [<xref rid="pone.0268426.ref034" ref-type="bibr">34</xref>] and lubridate [<xref rid="pone.0268426.ref035" ref-type="bibr">35</xref>] from the tidyverse [<xref rid="pone.0268426.ref036" ref-type="bibr">36</xref>], as well as janitor [<xref rid="pone.0268426.ref037" ref-type="bibr">37</xref>], can be complemented with datacleanr’s interactivity. In addition, due to the script and file-based output, datacleanr can also be included in workflow management tools such as drake [<xref rid="pone.0268426.ref038" ref-type="bibr">38</xref>] and workflowr [<xref rid="pone.0268426.ref039" ref-type="bibr">39</xref>].</p>
      </sec>
    </sec>
    <sec id="sec010">
      <title>Efficiency and batching</title>
      <p>datacleanr has been extensively tested on mobile and desktop workstations (Windows 10 and 11, Ubuntu 19.10) considered medium to high-end, and is easily capable of processing and displaying above 1 million observations simultaneously. A speed test with outlier selections at excessive and improbable scales indicated comfortable response times for most user scenarios (<xref rid="pone.0268426.g005" ref-type="fig">Fig 5</xref>).</p>
      <fig position="float" id="pone.0268426.g005">
        <object-id pub-id-type="doi">10.1371/journal.pone.0268426.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <title>Speed test of visualization and data selection on synthetic data (n = 250000).</title>
          <p>In 25 consecutive steps 10000 (additional) observations were selected. This was repeated three times (points) on low and high CPU-power settings, and processing time was determined using profvis [<xref rid="pone.0268426.ref040" ref-type="bibr">40</xref>], with bands plotted as visual aids. The inset shows processing totals (mean, min, max) after completing all 25 selections. Even with selections representing unlikely outlier numbers, the application remained responsive and appreciably fast.</p>
        </caption>
        <graphic xlink:href="pone.0268426.g005" position="float"/>
      </fig>
      <p>Nevertheless, the notable limiting factors for processing are number of columns (in exploratory summary) and the grouping structure during plotting. That is, a large number of unique groups will slow down the visualization, and we recommended aiming for a maximum of around 100 groups per datacleanr run.</p>
      <p>datacleanr::dcr_app() returns processed results to the active R session. Hence, multiple datasets can be processed in batch and results (including code) saved for subsequent use. This is especially helpful when data nesting structures are too deep (e.g., ≫100 groups), or datasets too large (approximately above 2 million observations) to handle in one sitting. In these cases, a split-combine approach is recommended:</p>
      <p specific-use="line"># prepare data into species sub-sets</p>
      <p specific-use="line">iris_split &lt;- split(x = iris,</p>
      <p specific-use="line">            f = iris$Species)</p>
      <p specific-use="line"># run for each species</p>
      <p specific-use="line">dcr_iris &lt;- lapply(iris_split,</p>
      <p specific-use="line">            <bold>function</bold>(split){</p>
      <p specific-use="line">                    datacleanr::dcr_app(split)</p>
      <p specific-use="line">            })</p>
      <p>Similarly, a list of file paths to datasets can be supplied (see help in R via? datacleanr::dcr_app()).</p>
    </sec>
  </sec>
  <sec id="sec011">
    <title>Case studies</title>
    <p>Below are two use-cases illustrating the utility of the interactive approach adopted in datacleanr.</p>
    <sec id="sec012">
      <title>Identifying structure and artefacts in nested data</title>
      <p>High-volume, data with nested hierarchical structure (i.e. observations grouped at many levels) are difficult to explore and process, especially when obtained from secondary sources, where the data-generating process or the collection method are not fully known [e.g., see <xref rid="pone.0268426.ref041" ref-type="bibr">41</xref>]. In such cases greater care is required, as unexpected or erroneous structures and artifacts can be present—especially so when these vary at group-level. Here, interactively engaging with the data can expedite processing while increasing confidence. As an example of dealing with such scenarios in datacleanr, we present a subset of nearly 320000 city and park trees listed in Berlin’s (DE) green infrastructure registry (<ext-link xlink:href="https://daten.berlin.de/" ext-link-type="uri">https://daten.berlin.de/</ext-link>, Strassenbäume, Anlagenbäume), focusing on mensuration data from the 10 most-frequent species across all 12 districts. These data were collected by different agencies or contractors (within and between districts), and are nested at multiple levels (district, street/park). For convenient exploration with datacleanr, the data is grouped by district and species (<xref rid="pone.0268426.g006" ref-type="fig">Fig 6</xref>), giving 120 sub-groups.</p>
      <fig position="float" id="pone.0268426.g006">
        <object-id pub-id-type="doi">10.1371/journal.pone.0268426.g006</object-id>
        <label>Fig 6</label>
        <caption>
          <title>Example set-up for hierarchically nested data.</title>
          <p>Grouping structure set to district (BEZIRK) and species (ART_BOT) in “Set-up and Overview” tab for subsequent exploration, plotting and cleaning.</p>
        </caption>
        <graphic xlink:href="pone.0268426.g006" position="float"/>
      </fig>
      <p>Potential outliers are readily identified and annotated in a bivariate plot of tree age and diameter (<xref rid="pone.0268426.g007" ref-type="fig">Fig 7</xref>). Note, these observations could also be captured using threshold filters.</p>
      <fig position="float" id="pone.0268426.g007">
        <object-id pub-id-type="doi">10.1371/journal.pone.0268426.g007</object-id>
        <label>Fig 7</label>
        <caption>
          <title>Overview of visual cleaning tab for Berlin tree data.</title>
          <p>The plot shows tree age (x) and diameter (y), resolving nesting by district and species. All 120 groups are displayed (see A, and figure legend). Potential outliers are obvious and easily highlighted and annotated for later reference (B, C). The dense point cloud comprises nearly 320000 observations and requires further inspection.</p>
        </caption>
        <graphic xlink:href="pone.0268426.g007" position="float"/>
      </fig>
      <p>Upon cycling through the set groups, however, additional structures are apparent in the district of Neukölln for <italic toggle="yes">Quercus robur</italic> L (<xref rid="pone.0268426.g008" ref-type="fig">Fig 8</xref>), among others. These structures would only be apparent if individual visualizations (at least 120, and potentially at variable zoom) had been generated. Yet, they could not be removed easily with threshold filters and would require a high level of effort to address with manual or automated code-based processing.</p>
      <fig position="float" id="pone.0268426.g008">
        <object-id pub-id-type="doi">10.1371/journal.pone.0268426.g008</object-id>
        <label>Fig 8</label>
        <caption>
          <title>Identification of problematic data structures.</title>
          <p>Closer inspection of the tree dataset using the grouping structure (A) to highlight/hide specific groups. The obvious, near-perfect linear relationship between tree age and diameter at breast height requires further inspection. Concerning data points are easily selected leveraging the interactivity of the visualization by clicking or with a lasso tool (B, see inset).</p>
        </caption>
        <graphic xlink:href="pone.0268426.g008" position="float"/>
      </fig>
      <p>Contrastingly, with scroll and zoom in datacleanr, problematic observations are efficiently selected and annotated. Such observations could be erroneous, and, for example, pose an issue in hierarchical modeling, if an entire group structure is affected (e.g., random effect at park or street level). We take this opportunity to explicitly urge users to make extensive use of the annotation feature on the visualization tab to provide rich information on the selected observations (e.g., “interpolated observations”), as well as to adhere to best practices and transparency in outlier assessment and handling [e.g., <xref rid="pone.0268426.ref042" ref-type="bibr">42</xref>] for any subsequent removal.</p>
    </sec>
    <sec id="sec013">
      <title>Retaining more data from time series with interactive cleaning</title>
      <p>Time series data, e.g., from ecophysiological monitoring, can be messy due to instrument drift, response lags, power issues, etc. In high volumes, messy data may call for pragmatic decisions, such as indiscriminately removing entire periods, if interactive processing tools are not available. Such decisions may be owed to either time constraints for detailed manual processing, or because automated approaches may not accommodate unexpected processes and resulting observations. Interactive processing—both after automated quality control as well as in first instance—with datacleanr allows inspecting high-volume data at high resolution and to identify the impact of erroneous data points. Consequently, individual problematic observations, rather than entire periods, can be flagged and removed after careful consideration. We provide an example of manual (code-based period filtering) <italic toggle="yes">vs</italic>. interactive processing with datacleanr of an unpublished (in prep.) time series of raw sap flow data from the TERENO North-East Observatory [Müritz National Park, <xref rid="pone.0268426.ref043" ref-type="bibr">43</xref>]. Note, in both cases due diligence and best practices were applied. With datacleanr more observations were retained, as individual points—not only periods—could be removed. Consequently, resulting gaps were shorter, could be gap-filled and potentially provide a higher level of insight (<xref rid="pone.0268426.g009" ref-type="fig">Fig 9</xref>). Further, the processing time decreased from approximately 2 hours by a skilled R-user to under 15 minutes for the entire series.</p>
      <fig position="float" id="pone.0268426.g009">
        <object-id pub-id-type="doi">10.1371/journal.pone.0268426.g009</object-id>
        <label>Fig 9</label>
        <caption>
          <title>Comparison of code-based and interactive processing with datacleanr of raw sap flux data.</title>
          <p>Compared to often more tedious, code-based filtering, the interactive quality control using domain expertise allowed retaining more observations resulting in greater data coverage across days (x-axis) for the measurement campaign, which lasted a total of 2769 days. Here, three additional full days of measurements, as well as several additional days with varying partial coverage were retained, as indicated by text labels to the right of bars (completeness by day; e.g. 25% of all measurements for a given day). This is because individual, problematic observations could be removed interactively (see inset), which may increase explanatory power in subsequent analyses.</p>
        </caption>
        <graphic xlink:href="pone.0268426.g009" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec id="sec014">
    <title>Future developments</title>
    <p>Development will be continued to enhance performance, and incorporate user feedback. Additional improvements are planned and will be implemented in upcoming versions. These include: 1) saving and loading processing progress within the application, 2) pre-select groups for plotting to reduce loading times, 3) a toggle to display filtered data (from the Filter tab) in visualizations for easier assessment of filters. Further, 4) a more convenient method for gracefully handling data selections from multiple groups in the interactive visualization will be added; this is particularly helpful when, for instance, problematic observations cluster in similar plot regions. Lastly, 5) additional options for data input via data base connections and internal splitting of (large) data sets will be added.</p>
  </sec>
  <sec sec-type="conclusions" id="sec015">
    <title>Conclusion</title>
    <p>Exploration and processing of high-volume data can be enhanced by using interactive tools. datacleanr achieves this with its flexibility and interoperability, while facilitating best practices in data exploration, outlier detection, and especially reproducibility through the extractable code recipe. While we acknowledge the place for and utility of fully-automated processing pipelines, we are certain that freely-available, interactive tools will improve researchers’ and analysts’ necessary engagement with their data, and consequently, increase confidence in their results. Further, we believe the datacleanr’s design will increase productivity of both technically-proficient as well as users with limited programming ability. For this, we ensured it would fit seamlessly into existing, script-based analyses pipelines, or that it could be used as a stand-alone tool by a wide audience. Lastly, we hope datacleanr will be of great use to the scientific community, including ecology, Earth system sciences and fields working with spatial and temporal data in general. We encourage users to provide feedback and suggestions in the dedicated repository to drive the continued development of the application.</p>
  </sec>
  <sec id="sec016" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pone.0268426.s001" position="float" content-type="local-data">
      <label>S1 File</label>
      <caption>
        <title>Animated walk-through.</title>
        <p>An overview of the package’s functionalities with animated examples of every feature.</p>
        <p>(HTML)</p>
      </caption>
      <media xlink:href="pone.0268426.s001.html">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>We are grateful for feedback on early versions of this manuscript and the application by anonymous reviewers.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pone.0268426.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Schimel</surname><given-names>D</given-names></name>, <name><surname>Keller</surname><given-names>M</given-names></name>. <article-title>Big questions, big science: Meeting the challenges of global ecology</article-title>. <source>Oecologia</source>. <year>2015</year>;<volume>177</volume>: <fpage>925</fpage>–<lpage>934</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s00442-015-3236-3</pub-id><?supplied-pmid 25680334?><pub-id pub-id-type="pmid">25680334</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Hampton</surname><given-names>SE</given-names></name>, <name><surname>Strasser</surname><given-names>CA</given-names></name>, <name><surname>Tewksbury</surname><given-names>JJ</given-names></name>, <name><surname>Gram</surname><given-names>WK</given-names></name>, <name><surname>Budden</surname><given-names>AE</given-names></name>, <name><surname>Batcheller</surname><given-names>AL</given-names></name>, <etal>et al</etal>. <article-title>Big data and the future of ecology</article-title>. <source>Frontiers in Ecology and the Environment</source>. <year>2013</year>;<volume>11</volume>: <fpage>156</fpage>–<lpage>162</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1890/120103</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Franklin</surname><given-names>J</given-names></name>, <name><surname>Serra‐Diaz</surname><given-names>JM</given-names></name>, <name><surname>Syphard</surname><given-names>AD</given-names></name>, <name><surname>Regan</surname><given-names>HM</given-names></name>. <article-title>Big data for forecasting the impacts of global change on plant communities</article-title>. <source>Global Ecology and Biogeography</source>. <year>2017</year>;<volume>26</volume>: <fpage>6</fpage>–<lpage>17</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/geb.12501</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Pastorello</surname><given-names>G</given-names></name>, <name><surname>Trotta</surname><given-names>C</given-names></name>, <name><surname>Canfora</surname><given-names>E</given-names></name>, <name><surname>Chu</surname><given-names>H</given-names></name>, <name><surname>Christianson</surname><given-names>D</given-names></name>, <name><surname>Cheah</surname><given-names>Y-W</given-names></name>, <etal>et al</etal>. <article-title>The FLUXNET2015 dataset and the ONEFlux processing pipeline for eddy covariance data</article-title>. <source>Scientific Data</source>. <year>2020</year>;<volume>7</volume>: <fpage>225</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41597-020-0534-3</pub-id><?supplied-pmid 32647314?><pub-id pub-id-type="pmid">32647314</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Anderson‐Teixeira</surname><given-names>KJ</given-names></name>, <name><surname>Wang</surname><given-names>MMH</given-names></name>, <name><surname>McGarvey</surname><given-names>JC</given-names></name>, <name><surname>Herrmann</surname><given-names>V</given-names></name>, <name><surname>Tepley</surname><given-names>AJ</given-names></name>, <name><surname>Bond‐Lamberty</surname><given-names>B</given-names></name>, <etal>et al</etal>. <article-title>ForC: A global database of forest carbon stocks and fluxes</article-title>. <source>Ecology</source>. <year>2018</year>;<volume>99</volume>: <fpage>1507</fpage>–<lpage>1507</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/ecy.2229</pub-id><?supplied-pmid 29603730?><pub-id pub-id-type="pmid">29603730</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Kattge</surname><given-names>J</given-names></name>, <name><surname>Bönisch</surname><given-names>G</given-names></name>, <name><surname>Díaz</surname><given-names>S</given-names></name>, <name><surname>Lavorel</surname><given-names>S</given-names></name>, <name><surname>Prentice</surname><given-names>IC</given-names></name>, <name><surname>Leadley</surname><given-names>P</given-names></name>, <etal>et al</etal>. <article-title>TRY plant trait database–enhanced coverage and open access</article-title>. <source>Global Change Biology</source>. <year>2020</year>;<volume>26</volume>: <fpage>119</fpage>–<lpage>188</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/gcb.14904</pub-id><?supplied-pmid 31891233?><pub-id pub-id-type="pmid">31891233</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Farley</surname><given-names>SS</given-names></name>, <name><surname>Dawson</surname><given-names>A</given-names></name>, <name><surname>Goring</surname><given-names>SJ</given-names></name>, <name><surname>Williams</surname><given-names>JW</given-names></name>. <article-title>Situating Ecology as a Big-Data Science: Current Advances, Challenges, and Solutions</article-title>. <source>BioScience</source>. <year>2018</year>;<volume>68</volume>: <fpage>563</fpage>–<lpage>576</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/biosci/biy068</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Escamilla Molgora</surname><given-names>JM</given-names></name>, <name><surname>Sedda</surname><given-names>L</given-names></name>, <name><surname>Atkinson</surname><given-names>PM</given-names></name>. <article-title>Biospytial: Spatial graph-based computing for ecological Big Data</article-title>. <source>Gigascience</source>. <year>2020</year>;<fpage>9</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/gigascience/giaa039</pub-id><?supplied-pmid 32391910?><pub-id pub-id-type="pmid">32391910</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref009">
      <label>9</label>
      <mixed-citation publication-type="book"><collab>BES</collab>. <source>A guide to data management in ecology and evolution.</source><publisher-name>BES</publisher-name>. <year>2014</year>. Available: <ext-link xlink:href="https://www.britishecologicalsociety.org/wp-content/uploads/2019/06/BES-Guide-Data-Management-2019.pdf" ext-link-type="uri">https://www.britishecologicalsociety.org/wp-content/uploads/2019/06/BES-Guide-Data-Management-2019.pdf</ext-link><comment>doi: </comment><pub-id pub-id-type="doi">10.1002/ece3.1046</pub-id><?supplied-pmid 24963377?></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref010">
      <label>10</label>
      <mixed-citation publication-type="book"><collab>BES, Cooper N</collab>. <source>A Guide to Reproducible Code in Ecology and Evolution.</source><publisher-name>BES</publisher-name>. <year>2017</year> [cited 23 Sep 2020]. Available: <ext-link xlink:href="https://nhm.openrepository.com/handle/10141/622618" ext-link-type="uri">https://nhm.openrepository.com/handle/10141/622618</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref011">
      <label>11</label>
      <mixed-citation publication-type="book"><name><surname>Chang</surname><given-names>WL</given-names></name>, <name><surname>Grady</surname><given-names>N</given-names></name>. <source>NIST Big Data Interoperability Framework: Volume 1, Definitions</source>. <publisher-name>NIST</publisher-name>; <year>2019</year><month>Oct</month>. Report No.: 1500-1r2. Available: <ext-link xlink:href="https://www.nist.gov/publications/nist-big-data-interoperability-framework-volume-1-definitions" ext-link-type="uri">https://www.nist.gov/publications/nist-big-data-interoperability-framework-volume-1-definitions</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Ward</surname><given-names>JS</given-names></name>, <name><surname>Barker</surname><given-names>A</given-names></name>. <source>Undefined By Data: A Survey of Big Data Definitions</source>. <year>2013</year>. Available: <ext-link xlink:href="http://arxiv.org/abs/1309.5821" ext-link-type="uri">http://arxiv.org/abs/1309.5821</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Yenni</surname><given-names>GM</given-names></name>, <name><surname>Christensen</surname><given-names>EM</given-names></name>, <name><surname>Bledsoe</surname><given-names>EK</given-names></name>, <name><surname>Supp</surname><given-names>SR</given-names></name>, <name><surname>Diaz</surname><given-names>RM</given-names></name>, <name><surname>White</surname><given-names>EP</given-names></name>, <etal>et al</etal>. <article-title>Developing a modern data workflow for regularly updated data</article-title>. <source>PLOS Biology</source>. <year>2019</year>;<volume>17</volume>: <fpage>e3000125</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pbio.3000125</pub-id><?supplied-pmid 30695030?><pub-id pub-id-type="pmid">30695030</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Zuur</surname><given-names>AF</given-names></name>, <name><surname>Ieno</surname><given-names>EN</given-names></name>, <name><surname>Elphick</surname><given-names>CS</given-names></name>. <article-title>A protocol for data exploration to avoid common statistical problems</article-title>. <source>Methods in Ecology and Evolution</source>. <year>2010</year>;<volume>1</volume>: <fpage>3</fpage>–<lpage>14</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/j.2041-210X.2009.00001.x</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Benhadi-Marín</surname><given-names>J.</given-names></name><article-title>A conceptual framework to deal with outliers in ecology</article-title>. <source>Biodivers Conserv</source>. <year>2018</year>;<volume>27</volume>: <fpage>3295</fpage>–<lpage>3300</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10531-018-1602-2</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Wutzler</surname><given-names>T</given-names></name>, <name><surname>Lucas-Moffat</surname><given-names>A</given-names></name>, <name><surname>Migliavacca</surname><given-names>M</given-names></name>, <name><surname>Knauer</surname><given-names>J</given-names></name>, <name><surname>Sickel</surname><given-names>K</given-names></name>, <name><surname>Šigut</surname><given-names>L</given-names></name>, <etal>et al</etal>. <article-title>Basic and extensible post-processing of eddy covariance flux data with REddyProc</article-title>. <source>Biogeosciences</source>. <year>2018</year>;<volume>15</volume>: <fpage>5015</fpage>–<lpage>5030</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.5194/bg-15-5015-2018</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Shaughnessy</surname><given-names>AR</given-names></name>, <name><surname>Prener</surname><given-names>CG</given-names></name>, <name><surname>Hasenmueller</surname><given-names>EA</given-names></name>. <article-title>An R package for correcting continuous water quality monitoring data for drift</article-title>. <source>Environ Monit Assess</source>. <year>2019</year>;<volume>191</volume>: <fpage>445</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10661-019-7586-x</pub-id><?supplied-pmid 31209582?><pub-id pub-id-type="pmid">31209582</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Heer</surname><given-names>J</given-names></name>, <name><surname>Kandel</surname><given-names>S</given-names></name>. <article-title>Interactive analysis of big data</article-title>. <source>XRDS</source>. <year>2012</year>;<volume>19</volume>: <fpage>50</fpage>–<lpage>54</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1145/2331042.2331058</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref019">
      <label>19</label>
      <mixed-citation publication-type="book"><name><surname>Binnig</surname><given-names>C</given-names></name>, <name><surname>Basık</surname><given-names>F</given-names></name>, <name><surname>Buratti</surname><given-names>B</given-names></name>, <name><surname>Cetintemel</surname><given-names>U</given-names></name>, <name><surname>Chung</surname><given-names>Y</given-names></name>, <name><surname>Crotty</surname><given-names>A</given-names></name>, <etal>et al</etal>. <part-title>Towards interactive data exploration</part-title>. <source>Real-time business intelligence and analytics</source>. <publisher-name>Springer</publisher-name>; <year>2015</year>. pp. <fpage>177</fpage>–<lpage>190</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0268426.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Beilschmidt</surname><given-names>C</given-names></name>, <name><surname>Drönner</surname><given-names>J</given-names></name>, <name><surname>Mattig</surname><given-names>M</given-names></name>, <name><surname>Schmidt</surname><given-names>M</given-names></name>, <name><surname>Authmann</surname><given-names>C</given-names></name>, <name><surname>Niamir</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>VAT: A Scientific Toolbox for Interactive Geodata Exploration</article-title>. <source>Datenbank Spektrum</source>. <year>2017</year>;<volume>17</volume>: <fpage>233</fpage>–<lpage>243</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s13222-017-0266-5</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Culina</surname><given-names>A</given-names></name>, <article-title>Berg I van den, Evans S, Sánchez-Tójar A. Low availability of code in ecology: A call for urgent action</article-title>. <source>PLOS Biology</source>. <year>2020</year>;<volume>18</volume>: <fpage>e3000763</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pbio.3000763</pub-id><?supplied-pmid 32722681?><pub-id pub-id-type="pmid">32722681</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref022">
      <label>22</label>
      <mixed-citation publication-type="book"><collab>R Core Team</collab>. <source>R: A language and environment for statistical computing</source>. <publisher-loc>Vienna, Austria</publisher-loc>: <publisher-name>R Foundation for Statistical Computing</publisher-name>; <year>2020</year>. Available: <ext-link xlink:href="https://www.R-project.org/" ext-link-type="uri">https://www.R-project.org/</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Rossum</surname><given-names>G.</given-names></name><article-title>Python reference manual</article-title>. <source>Centre for Mathematics and Computer Science</source>. <year>1995</year>.</mixed-citation>
    </ref>
    <ref id="pone.0268426.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>Gerum</surname><given-names>RC</given-names></name>, <name><surname>Richter</surname><given-names>S</given-names></name>, <name><surname>Fabry</surname><given-names>B</given-names></name>, <name><surname>Zitterbart</surname><given-names>DP</given-names></name>. <article-title>ClickPoints: An expandable toolbox for scientific image annotation and analysis</article-title>. <source>Methods in Ecology and Evolution</source>. <year>2017</year>;<volume>8</volume>: <fpage>750</fpage>–<lpage>756</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/2041-210X.12702</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Solsona-Berga</surname><given-names>A</given-names></name>, <name><surname>Frasier</surname><given-names>KE</given-names></name>, <name><surname>Baumann-Pickering</surname><given-names>S</given-names></name>, <name><surname>Wiggins</surname><given-names>SM</given-names></name>, <name><surname>Hildebrand</surname><given-names>JA</given-names></name>. <article-title>DetEdit: A graphical user interface for annotating and editing events detected in long-term acoustic monitoring data</article-title>. <source>PLOS Computational Biology</source>. <year>2020</year>;<volume>16</volume>: <fpage>e1007598</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007598</pub-id><?supplied-pmid 31929520?><pub-id pub-id-type="pmid">31929520</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Jakimow</surname><given-names>B</given-names></name>, <name><surname>van der Linden</surname><given-names>S</given-names></name>, <name><surname>Thiel</surname><given-names>F</given-names></name>, <name><surname>Frantz</surname><given-names>D</given-names></name>, <name><surname>Hostert</surname><given-names>P</given-names></name>. <article-title>Visualizing and labeling dense multi-sensor earth observation time series: The EO Time Series Viewer</article-title>. <source>Environmental Modelling &amp; Software</source>. <year>2020</year>;<volume>125</volume>: <fpage>104631</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.envsoft.2020.104631</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Chang</surname><given-names>W</given-names></name>, <name><surname>Cheng</surname><given-names>J</given-names></name>, <name><surname>Allaire</surname><given-names>J</given-names></name>, <name><surname>Xie</surname><given-names>Y</given-names></name>, <name><surname>McPherson</surname><given-names>J</given-names></name>. <source>Shiny: Web application framework for r</source>. <year>2020</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=shiny" ext-link-type="uri">https://CRAN.R-project.org/package=shiny</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref028">
      <label>28</label>
      <mixed-citation publication-type="book"><name><surname>Sievert</surname><given-names>C.</given-names></name><source>Interactive web-based data visualization with r, plotly, and shiny</source>. <publisher-loc>Chapman and Hall</publisher-loc>/<publisher-name>CRC</publisher-name>; <year>2020</year>. Available: <ext-link xlink:href="https://plotly-r.com" ext-link-type="uri">https://plotly-r.com</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref029">
      <label>29</label>
      <mixed-citation publication-type="book"><name><surname>Team</surname><given-names>RStudio</given-names></name>. <source>RStudio: Integrated development environment for r</source>. <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>RStudio, PBC</publisher-name>; <year>2021</year>. Available: <ext-link xlink:href="http://www.rstudio.com/" ext-link-type="uri">http://www.rstudio.com/</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Comtois</surname><given-names>D.</given-names></name><source>Summarytools: Tools to quickly and neatly summarize data</source>. <year>2020</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=summarytools" ext-link-type="uri">https://CRAN.R-project.org/package=summarytools</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Falster</surname><given-names>DS</given-names></name>, <name><surname>Duursma</surname><given-names>RA</given-names></name>, <name><surname>Ishihara</surname><given-names>MI</given-names></name>, <name><surname>Barneche</surname><given-names>DR</given-names></name>, <name><surname>FitzJohn</surname><given-names>RG</given-names></name>, <name><surname>Vårhammar</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>BAAD: A Biomass And Allometry Database for woody plants</article-title>. <source>Ecology</source>. <year>2015</year>;<volume>96</volume>: <fpage>1445</fpage>–<lpage>1445</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1890/14-1889.1</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Wickham</surname><given-names>H</given-names></name>, <name><surname>Hester</surname><given-names>J</given-names></name>, <name><surname>Bryan</surname><given-names>J</given-names></name>. <source>Readr: Read rectangular text data</source>. <year>2021</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=readr" ext-link-type="uri">https://CRAN.R-project.org/package=readr</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Wickham</surname><given-names>H</given-names></name>, <name><surname>François</surname><given-names>R</given-names></name>, <name><surname>Henry</surname><given-names>L</given-names></name>, <name><surname>Müller</surname><given-names>K</given-names></name>. <source>Dplyr: A grammar of data manipulation</source>. <year>2021</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=dplyr" ext-link-type="uri">https://CRAN.R-project.org/package=dplyr</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Wickham</surname><given-names>H.</given-names></name><source>Tidyr: Tidy messy data</source>. <year>2021</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=tidyr" ext-link-type="uri">https://CRAN.R-project.org/package=tidyr</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Grolemund</surname><given-names>G</given-names></name>, <name><surname>Wickham</surname><given-names>H</given-names></name>. <article-title>Dates and times made easy with lubridate</article-title>. <source>Journal of Statistical Software</source>. <year>2011</year>;<volume>40</volume>: <fpage>1</fpage>–<lpage>25</lpage>. Available: <ext-link xlink:href="https://www.jstatsoft.org/v40/i03/" ext-link-type="uri">https://www.jstatsoft.org/v40/i03/</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Wickham</surname><given-names>H</given-names></name>, <name><surname>Averick</surname><given-names>M</given-names></name>, <name><surname>Bryan</surname><given-names>J</given-names></name>, <name><surname>Chang</surname><given-names>W</given-names></name>, <name><surname>McGowan</surname><given-names>LD</given-names></name>, <name><surname>François</surname><given-names>R</given-names></name>, <etal>et al</etal>. <article-title>Welcome to the tidyverse</article-title>. <source>Journal of Open Source Software</source>. <year>2019</year>;<volume>4</volume>: <fpage>1686</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.21105/joss.01686</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Firke</surname><given-names>S.</given-names></name><source>Janitor: Simple tools for examining and cleaning dirty data</source>. <year>2020</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=janitor" ext-link-type="uri">https://CRAN.R-project.org/package=janitor</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref038">
      <label>38</label>
      <mixed-citation publication-type="journal"><name><surname>Landau</surname><given-names>WM</given-names></name>. <article-title>The drake R package: A pipeline toolkit for reproducibility and high-performance computing</article-title>. <source>Journal of Open Source Software</source>. <year>2018</year>;<fpage>3</fpage>. Available: <comment>doi: </comment><pub-id pub-id-type="doi">10.21105/joss.00550</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Blischak</surname><given-names>JD</given-names></name>, <name><surname>Carbonetto</surname><given-names>P</given-names></name>, <name><surname>Stephens</surname><given-names>M</given-names></name>. <article-title>Creating and sharing reproducible research code the workflowr way [version 1; peer review: 3 approved].</article-title><source>F1000Research</source>. <year>2019</year>;<fpage>8</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.12688/f1000research.17047.1</pub-id><?supplied-pmid 30854195?><pub-id pub-id-type="pmid">30854195</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>Chang</surname><given-names>W</given-names></name>, <name><surname>Luraschi</surname><given-names>J</given-names></name>, <name><surname>Mastny</surname><given-names>T</given-names></name>. <source>Profvis: Interactive visualizations for profiling r code</source>. <year>2019</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=profvis" ext-link-type="uri">https://CRAN.R-project.org/package=profvis</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>García Criado</surname><given-names>M</given-names></name>, <name><surname>Myers-Smith</surname><given-names>I</given-names></name>, <name><surname>Baeten</surname><given-names>L</given-names></name>, <name><surname>Cunliffe</surname><given-names>A</given-names></name>, <name><surname>Daskalova</surname><given-names>G</given-names></name>, <name><surname>Gallois</surname><given-names>E</given-names></name>, <etal>et al</etal>. <article-title>Sharing is Caring: Working With Other People’s Data</article-title>. <source>methods.blog</source>; <day>4</day><month>Sep</month><year>2020</year> [cited 24 Sep 2020]. Available: <ext-link xlink:href="https://methodsblog.com/2020/09/04/sharing-is-caring-working-with-other-peoples-data/" ext-link-type="uri">https://methodsblog.com/2020/09/04/sharing-is-caring-working-with-other-peoples-data/</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref042">
      <label>42</label>
      <mixed-citation publication-type="journal"><name><surname>Aguinis</surname><given-names>H</given-names></name>, <name><surname>Gottfredson</surname><given-names>RK</given-names></name>, <name><surname>Joo</surname><given-names>H</given-names></name>. <article-title>Best-Practice Recommendations for Defining, Identifying, and Handling Outliers</article-title>. <source>Organizational Research Methods</source>. <year>2013</year>;<volume>16</volume>: <fpage>270</fpage>–<lpage>301</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1177/1094428112470848</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0268426.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Heinrich</surname><given-names>I</given-names></name>, <name><surname>Balanzategui</surname><given-names>D</given-names></name>, <name><surname>Bens</surname><given-names>O</given-names></name>, <name><surname>Blasch</surname><given-names>G</given-names></name>, <name><surname>Blume</surname><given-names>T</given-names></name>, <name><surname>Böttcher</surname><given-names>F</given-names></name>, <etal>et al</etal>. <article-title>Interdisciplinary geo-ecological research across time scales in the northeast german lowland observatory (TERENO-NE)</article-title>. <source>Vadose Zone Journal</source>. <year>2018</year>;<volume>17</volume>: <fpage>1</fpage>–<lpage>25</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article article-type="aggregated-review-documents" id="pone.0268426.r001" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0268426.r001</article-id>
    <title-group>
      <article-title>Decision Letter 0</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>McDonald</surname>
          <given-names>Natasha</given-names>
        </name>
        <role>Staff Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2022 Natasha McDonald</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Natasha McDonald</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0268426" id="rel-obj001" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>0</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">15 Feb 2022</named-content>
    </p>
    <p><!-- <div> -->PONE-D-21-05607<!-- </div> --><!-- <div> -->Addressing the need for interactive, efficient and reproducible data processing in ecology with the datacleanr R application<!-- </div> --><!-- <div> -->PLOS ONE</p>
    <p>Dear Dr. Hurley,</p>
    <p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p>
    <p>The reviewers raised a number of concerns with your study, in particular the ease of use of the program and the lack of a walk-through analysis, as well as some points to improve clarity. Their comments can be viewed in full, below and in the attached file.</p>
    <p>Please submit your revised manuscript by Mar 31 2022 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at <email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p>
    <p>Please include the following items when submitting your revised manuscript:<!-- </div> --><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list><!-- <div> --></p>
    <p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p>
    <p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link>.</p>
    <p>We look forward to receiving your revised manuscript.</p>
    <p>Kind regards,</p>
    <p>Natasha McDonald, PhD</p>
    <p>Associate Editor</p>
    <p>PLOS ONE</p>
    <p>Journal Requirements:</p>
    <p>When submitting your revision, we need you to address these additional requirements.</p>
    <p>1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at </p>
    <p><ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link> and </p>
    <p>
      <ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link>
    </p>
    <p>2. Your abstract cannot contain citations. Please only include citations in the body text of the manuscript, and ensure that they remain in ascending numerical order on first mention.</p>
    <p>3. We note that Figure 3 in your submission contain map images which may be copyrighted. All PLOS content is published under the Creative Commons Attribution License (CC BY 4.0), which means that the manuscript, images, and Supporting Information files will be freely available online, and any third party is permitted to access, download, copy, distribute, and use these materials in any way, even commercially, with proper attribution. For these reasons, we cannot publish previously copyrighted maps or satellite images created using proprietary data, such as Google software (Google Maps, Street View, and Earth). For more information, see our copyright guidelines: <ext-link xlink:href="http://journals.plos.org/plosone/s/licenses-and-copyright" ext-link-type="uri">http://journals.plos.org/plosone/s/licenses-and-copyright</ext-link>.</p>
    <p>We require you to either (1) present written permission from the copyright holder to publish these figures specifically under the CC BY 4.0 license, or (2) remove the figures from your submission:</p>
    <p>a. You may seek permission from the original copyright holder of Figure 3 to publish the content specifically under the CC BY 4.0 license.  </p>
    <p>We recommend that you contact the original copyright holder with the Content Permission Form (<ext-link xlink:href="http://journals.plos.org/plosone/s/file?id=7c09/content-permission-form.pdf" ext-link-type="uri">http://journals.plos.org/plosone/s/file?id=7c09/content-permission-form.pdf</ext-link>) and the following text:</p>
    <p>“I request permission for the open-access journal PLOS ONE to publish XXX under the Creative Commons Attribution License (CCAL) CC BY 4.0 (<ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>). Please be aware that this license allows unrestricted use and distribution, even commercially, by third parties. Please reply and provide explicit written permission to publish XXX under a CC BY license and complete the attached form.”</p>
    <p>Please upload the completed Content Permission Form or other proof of granted permissions as an "Other" file with your submission.</p>
    <p>In the figure caption of the copyrighted figure, please include the following text: “Reprinted from [ref] under a CC BY license, with permission from [name of publisher], original copyright [original copyright year].”</p>
    <p>b. If you are unable to obtain permission from the original copyright holder to publish these figures under the CC BY 4.0 license or if the copyright holder’s requirements are incompatible with the CC BY 4.0 license, please either i) remove the figure or ii) supply a replacement figure that complies with the CC BY 4.0 license. Please check copyright information on all replacement figures and update the figure caption with source information. If applicable, please specify in the figure caption text when a figure is similar but not identical to the original image and is therefore for illustrative purposes only.</p>
    <p>The following resources for replacing copyrighted map figures may be helpful:</p>
    <p>USGS National Map Viewer (public domain): <ext-link xlink:href="http://viewer.nationalmap.gov/viewer/" ext-link-type="uri">http://viewer.nationalmap.gov/viewer/</ext-link></p>
    <p>The Gateway to Astronaut Photography of Earth (public domain): <ext-link xlink:href="http://eol.jsc.nasa.gov/sseop/clickmap/" ext-link-type="uri">http://eol.jsc.nasa.gov/sseop/clickmap/</ext-link></p>
    <p>Maps at the CIA (public domain): <ext-link xlink:href="https://www.cia.gov/library/publications/the-world-factbook/index.html" ext-link-type="uri">https://www.cia.gov/library/publications/the-world-factbook/index.html</ext-link> and <ext-link xlink:href="https://www.cia.gov/library/publications/cia-maps-publications/index.html" ext-link-type="uri">https://www.cia.gov/library/publications/cia-maps-publications/index.html</ext-link></p>
    <p>NASA Earth Observatory (public domain): <ext-link xlink:href="http://earthobservatory.nasa.gov/" ext-link-type="uri">http://earthobservatory.nasa.gov/</ext-link></p>
    <p>Landsat: <ext-link xlink:href="http://landsat.visibleearth.nasa.gov/" ext-link-type="uri">http://landsat.visibleearth.nasa.gov/</ext-link></p>
    <p>USGS EROS (Earth Resources Observatory and Science (EROS) Center) (public domain): <ext-link xlink:href="http://eros.usgs.gov/#" ext-link-type="uri">http://eros.usgs.gov/#</ext-link></p>
    <p>Natural Earth (public domain): <ext-link xlink:href="http://www.naturalearthdata.com/" ext-link-type="uri">http://www.naturalearthdata.com/</ext-link></p>
    <p>4. We note that Figures 4, 6, 7 and 8 in your submission contain copyrighted images. All PLOS content is published under the Creative Commons Attribution License (CC BY 4.0), which means that the manuscript, images, and Supporting Information files will be freely available online, and any third party is permitted to access, download, copy, distribute, and use these materials in any way, even commercially, with proper attribution. For more information, see our copyright guidelines: <ext-link xlink:href="http://journals.plos.org/plosone/s/licenses-and-copyright" ext-link-type="uri">http://journals.plos.org/plosone/s/licenses-and-copyright</ext-link>.</p>
    <p>We require you to either (1) present written permission from the copyright holder to publish these figures specifically under the CC BY 4.0 license, or (2) remove the figures from your submission:</p>
    <p>a. You may seek permission from the original copyright holder of Figures 4, 6, 7 and 8 to publish the content specifically under the CC BY 4.0 license. </p>
    <p>We recommend that you contact the original copyright holder with the Content Permission Form (<ext-link xlink:href="http://journals.plos.org/plosone/s/file?id=7c09/content-permission-form.pdf" ext-link-type="uri">http://journals.plos.org/plosone/s/file?id=7c09/content-permission-form.pdf</ext-link>) and the following text:</p>
    <p>“I request permission for the open-access journal PLOS ONE to publish XXX under the Creative Commons Attribution License (CCAL) CC BY 4.0 (<ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>). Please be aware that this license allows unrestricted use and distribution, even commercially, by third parties. Please reply and provide explicit written permission to publish XXX under a CC BY license and complete the attached form.”</p>
    <p>Please upload the completed Content Permission Form or other proof of granted permissions as an "Other" file with your submission. </p>
    <p>In the figure caption of the copyrighted figure, please include the following text: “Reprinted from [ref] under a CC BY license, with permission from [name of publisher], original copyright [original copyright year].”</p>
    <p>b. If you are unable to obtain permission from the original copyright holder to publish these figures under the CC BY 4.0 license or if the copyright holder’s requirements are incompatible with the CC BY 4.0 license, please either i) remove the figure or ii) supply a replacement figure that complies with the CC BY 4.0 license. Please check copyright information on all replacement figures and update the figure caption with source information. If applicable, please specify in the figure caption text when a figure is similar but not identical to the original image and is therefore for illustrative purposes only.</p>
    <p>5. Please review your reference list to ensure that it is complete and correct. If you have cited papers that have been retracted, please include the rationale for doing so in the manuscript text, or remove these references and replace them with relevant current references. Any changes to the reference list should be mentioned in the rebuttal letter that accompanies your revised manuscript. If you need to cite a retracted article, indicate the article’s retracted status in the References list and also include a citation and full reference for the retraction notice.</p>
    <p>[Note: HTML markup is below. Please do not edit.]</p>
    <p>Reviewers' comments:</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <!-- <font color="black"> -->
      <bold>Comments to the Author</bold>
    </p>
    <p>1. Is the manuscript technically sound, and do the data support the conclusions?</p>
    <p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->2. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p>
    <p>Reviewer #1: N/A</p>
    <p>Reviewer #2: N/A</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->3. Have the authors made all data underlying the findings in their manuscript fully available?</p>
    <p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->4. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
    <p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->5. Review Comments to the Author</p>
    <p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p>
    <p>Reviewer #1: Addressing the need for interactive, efficient and reproducible data processing in ecology with the dataclearnr R application</p>
    <p>The manuscript introduces an R package for data processing of large ecological data sets. It gives an overview of the package's functionality.</p>
    <p>I think that such an R package is useful, especially for the scenarios the authors have pointed out (large data sets with many different scales / scopes, large monitoring data sets), for quick visualizations, outlier and problem detection.</p>
    <p>I only have a few suggestions for improving the manuscript:</p>
    <p>1. line 139 Figure 1 caption: Sometimes the authors refer to specific functionality that the reader would only really understand when running the package, e.g. line 149 after "Set and Start" is clicked. This detail is perhaps too technical for this overview.</p>
    <p>2. line 151 via 29 .... would be more useful if it named the package directly</p>
    <p>3. line 156: not sure what 'through text cues on the tab' refers to</p>
    <p>4. Figure 2 and caption: To me it is not entirely clear what is displayed here. E.g. what is the difference between left and right, what the n = .. refer to? Make clearer that the grey areas correspond to points which are filtered out?'</p>
    <p>5. line 167 --- 'any statement': make clearer that this refers to the filtering statement, it would be useful to add that this filtering statement requires R code</p>
    <p>6. line 169: insert 'the' before 'following'</p>
    <p>7. line 185: more useful to refer directly to 'plotly'</p>
    <p>8. line 186: insert 'be' before 'displayed'</p>
    <p>9. line 197: clarify what 'key feature' refers to. I think it refers to the visualization tab, but this is not clear.</p>
    <p>10. line 199: correspond to</p>
    <p>11. line 242, Figure 5 caption:not sure what 'processing totals' refer to. Why (n=3) after means? Does this imply that there were 3 runs at every setting (number of points)?</p>
    <p>12. line 270: remove comma after high-volume</p>
    <p>13. Figure 9 and caption (line 331): I cannot see a difference between figures A and B. Therefore, is A necessary. If there are differences, maybe highlight these or point out. Also, I am not sure how to understand panel C. 'including' in caption misplaced?</p>
    <p>Reviewer #2: The paper describes an R package which provides an interactive graphical user interface to identify outliers and clean the data.</p>
    <p>It has one extremely important feature, i.e. it returns the R code for doing the filtering and the cleaning of the data, i.e. therefore making it transparent and reproducible. This is an essential feature, which bridges the gap between purely code based outlier removal and interactive outlier identification.</p>
    <p>But as the R script is effectively a script adding a column identifying if a data point was identified as an outlier or not, it would be very useful to also generate a report which includes e.g. the graphs in which the outliers were identified and the filtering rules as an html or pdf which can be added to the data as a justification why the points were identified as outliers.</p>
    <p>In the ideal case (future development?) I would suggest a config file (yaml?) which contains all the info and settings used, and when loaded, loads the data and applies all settings from the previous session.</p>
    <p>Unfortunately, I was only able to test the app after quite a bit of trying, as no walk-through of the data analysis is provided. This is a pity, as all the data is available in appropriate licenses and all that would be needed is to supplement the manuscript with boxes showing the settings for each step. This relatively easy addition would make the manuscript much more approachable.</p>
    <p>Overall, I have added a number of comments to the pdf document (attached) which can be easily adressed.</p>
    <p>As mentioned, my main concern is the missing of a walk-through through one analysis. I would suggest that this relatively straight forward addition / change is done before publication.</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->6. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p>
    <p>Reviewer #1: No</p>
    <p>Reviewer #2: No</p>
    <p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at <email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.<!-- </div> --></p>
    <supplementary-material id="pone.0268426.s002" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">PONE-D-21-05607_reviewer.pdf</named-content></p>
      </caption>
      <media xlink:href="pone.0268426.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pone.0268426.r002">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0268426.r002</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 0</article-title>
    </title-group>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0268426" id="rel-obj002" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">1 Apr 2022</named-content>
    </p>
    <p>Dear Editor and referees,</p>
    <p>Thank you for the chance to improve our manuscript; your comments were highly appreciated. I kindly refer you to the attached file "Response to Reviewers.docx" for a formatted version of our rebuttal, but have copy-pasted it below for completeness.</p>
    <p>Sincerely,</p>
    <p>Alexander Hurley</p>
    <p>______</p>
    <p>Addressing the need for interactive, efficient, and reproducible data processing in ecology with the datacleanr R package</p>
    <p>Response to reviewers</p>
    <p>Editor</p>
    <p>The reviewers raised a number of concerns with your study, in particular the ease of use of the program and the lack of a walk-through analysis, as well as some points to improve clarity. Their comments can be viewed in full, below and in the attached file.</p>
    <p>We thank the editor and reviewers for their time and the opportunity to improve the manuscript and thus the (initial) user experience of datacleanr. We have carefully considered the concerns raised by the referees and included a detailed walk-through analysis to further enhance the usability of the presented package. With these suggestions we feel that the manuscript has significantly improved. </p>
    <p>Reviewer 1</p>
    <p>The manuscript introduces an R package for data processing of large ecological data sets. It gives an overview of the package’s functionality. I think that such an R package is useful, especially for the scenarios the authors have pointed out (large data sets with many different scales / scopes, large monitoring data sets), for quick visualizations, outlier and problem detection.</p>
    <p>We thank the reviewer for their assessment and recognition of our tool’s utility.</p>
    <p>I only have a few suggestions for improving the manuscript:</p>
    <p>We have addressed all comments by implementing the suggested changes or by providing a justification for the issue at hand in its current state. An overview thereof is given below.</p>
    <p>*1. line 139 Figure 1 caption: Sometimes the authors refer to specific functionality that the reader would only really understand when running the package, e.g. line 149 after “Set and Start” is clicked. This detail is perhaps too technical for this overview.</p>
    <p>We improved the wording of technical details here, enhanced Fig 1 caption (package overview, L165 in response) to better guide the reader, and added a SI File with animated examples for a walk-through, as also suggested by Reviewer 2. The section mentioned above now reads:</p>
    <p>“The structure is available during targeted filtering (scoping; see Filtering) and visual cleaning (see Figs 6-8). Once the grouping is set, a dataset summary can be generated via the package summarytools [29], highlighting duplicates, missingness, and distribution of each variable.”</p>
    <p>As noted above, the caption of Fig 1 has been improved significantly, in accordance with Reviewer 2’s suggestions (see in respective section further below, L165), which we believe allows the reader to follow the descriptions more readily.</p>
    <p>*2. line 151 via 29 …. would be more useful if it named the package directly</p>
    <p>Adjusted to “..summary can be generated via the package summarytools [29]..”</p>
    <p>*3. line 156: not sure what ‘through text cues on the tab’ refers to</p>
    <p>The section in question now reads:</p>
    <p>“The application’s interactivity allows reviewing the impact of filters through a text note highlighting the percentage of removed data and an overview table showing the remaining observations (per group), …”</p>
    <p>*4. Figure 2 and caption: To me it is not entirely clear what is displayed here. E.g. what is the difference between left and right, what the n = .. refer to? Make clearer that the grey areas correspond to points which are filtered out?’</p>
    <p>We appreciate the caption was not detailed enough and have adjusted it to:</p>
    <p>“Figure 2: Example of the impact of statistical filtering on bivariate relationships between trait data from BAAD [30]. A percentile threshold filter (0.01 and 0.99) is used to remove extreme low and high values on the x-variable across its full space (left) or scoped to groups represented by functional types (right). The gray shading indicates the filtered variable space (full or scoped), while text labels and black points count and highlight, respectively, individual observations captured by the applied filter. Note, the figure was not generated in datacleanr.”</p>
    <p>We are confident that the adjusted caption sufficiently explains the figure and highlights the difference between full and scoped filtering adequately.</p>
    <p>*5. line 167 — ‘any statement’: make clearer that this refers to the filtering statement, it would be useful to add that this filtering statement requires R code</p>
    <p>The text was adjusted to:</p>
    <p>“Any filtering statement (provided as valid R code) which evaluates to TRUE or FALSE..”</p>
    <p>*6. line 169: insert ‘the’ before ‘following’</p>
    <p>Done.</p>
    <p>*7. line 185: more useful to refer directly to ‘plotly’</p>
    <p>Done.</p>
    <p>*8. line 186: insert ‘be’ before ‘displayed’</p>
    <p>Done.</p>
    <p>*9. line 197: clarify what ‘key feature’ refers to. I think it refers to the visualization tab, but this is not clear.</p>
    <p>This was changed to:</p>
    <p>“A key feature on the visualization tab is the grouping structure table…”</p>
    <p>*10. line 199: correspond to</p>
    <p>Done.</p>
    <p>*11. line 242, Figure 5 caption: not sure what ‘processing totals’ refer to. Why (n=3) after means? Does this imply that there were 3 runs at every setting (number of points)?</p>
    <p>The caption was adjusted to:</p>
    <p>“Figure 5: Speed test of visualization and outlier selection on synthetic data (n = 250000). In 25 consecutive steps 10000 (additional) points were selected. This was repeated three times on low and high CPU-power settings, and processing time was determined using profvis [35]. Bands represent minimum and maximum durations, and points are means of the three replicates. The inset shows processing totals (mean, min, max) after completing all 25 selections. Even with unlikely outlier numbers, the application remained responsive and appreciably fast.”</p>
    <p>*12. line 270: remove comma after high-volume</p>
    <p>Done.</p>
    <p>*13. Figure 9 and caption (line 331): I cannot see a difference between figures A and B. Therefore, is A necessary. If there are differences, maybe highlight these or point out. Also, I am not sure how to understand panel C. ‘including’ in caption misplaced?</p>
    <p>We appreciate this issue, and have previously tried different versions of the figure with overplotting and offsetting in a single panel. However, neither option was fully satisfactory. This was either due to the same issue (distance between lines) or overplotting due to the time scale. We do want to emphasize the entire time series to highlight the package’s capability of dealing with fairly large/high-resolution data here for one processing example, and have used the caption to better highlight visible differences, , although these admittedly require increased attention. The caption now reads:</p>
    <p>“Figure 9: Comparison of code-based (A) and interactive processing (B) of raw sap flux data. Compared to often more tedious, code-based filtering, interactive quality control using domain expertise allowed retaining more observations resulting in greater data coverage. Here, three additional full days of measurements, as well as several days with varying partial coverage were retained (C, completeness by day; e.g. 25 % of all measurements for a given day). For example, differences are found in 2014 and 2017, where the code-based filtering removes entire periods (i.e., days, weeks). By contrast, individual, problematic observations could be removed interactively (D), which may increase explanatory power in subsequent analyses.”</p>
    <p>Reviewer 2</p>
    <p>*It has one extremely important feature, i.e. it returns the R code for doing the filtering and the cleaning of the data, i.e. therefore making it transparent and reproducible. This is an essential feature, which bridges the gap between purely code based outlier removal and interactive outlier identification.</p>
    <p>We thank the reviewer for the recognition of datacleanr’s utility and the thorough review.</p>
    <p>*But as the R script is effectively a script adding a column identifying if a data point was identified as an outlier or not, it would be very useful to also generate a report which includes e.g. the graphs in which the outliers were identified and the filtering rules as an html or pdf which can be added to the data as a justification why the points were identified as outliers.</p>
    <p>We discussed similar features for PDF or HTML reports during datacleanr’s development. We agree that a justification or annotation for conspicuous data is not only useful but necessary. This is why we implemented the annotation feature in the interactive data selection. This gives users the freedom to use a set of self-defined annotations or tags for different scenarios (e.g., “high value,” “battery failure,” etc.). These annotations are stored in the .annotation column, and allow to not only identify selected points in a boolean manner, but also provide the user-specified annotation. From our own use of datacleanr we have concluded that this approach affords flexibility down the line to implement case-specific solutions, such as bespoke graphs and tables, which can be included in user-specific outputs (e.g., PDF or HTML reports based on RMarkdown). We also would like to emphasize that the reproducible recipe provides all the necessary information for such reports - or even as a stand-alone overview - if the data selection and annotation is done with due diligence.</p>
    <p>*In the ideal case (future development?) I would suggest a config file (yaml?) which contains all the info and settings used, and when loaded, loads the data and applies all settings from the previous session.</p>
    <p>This is most certainly planned as a future development, and will likely rely on the new shiny caching feature, rather than a yaml config file – we will explore the latter option as well and appreciate the idea/pointer, however. As we recognize the importance of this feature it is also the first we mention in this section (with updated wording):</p>
    <p>“Additional improvements are planned and will be implemented in upcoming versions. These include: 1) saving and loading processing progress within the application …”</p>
    <p>*Unfortunately, I was only able to test the app after quite a bit of trying, as no walk-through of the data analysis is provided. This is a pity, as all the data is available in appropriate licenses and all that would be needed is to supplement the manuscript with boxes showing the settings for each step. This relatively easy addition would make the manuscript much more approachable.</p>
    <p>Thank you for highlighting this. We have included the package’s readme file (<ext-link xlink:href="https://github.com/the-Hull/datacleanr" ext-link-type="uri">https://github.com/the-Hull/datacleanr</ext-link> or on CRAN as <ext-link xlink:href="https://cran.r-project.org/web/packages/datacleanr/readme/README.html" ext-link-type="uri">https://cran.r-project.org/web/packages/datacleanr/readme/README.html</ext-link>) with animated examples as an SI file (modified to comply with the 20 MB file restriction), which we consider even more instructive than a walk-through with screenshots only. It includes details on installation, capabilities, and use, with in-depth examples of every feature. We note this in the “Capabilities section” to prime the reader. The paragraph now reads:</p>
    <p>“datacleanr is an interactive R package for processing high-volume data, and it caters to best practices in data exploration, processing, and reproducibility. This section describes the general capabilities of the package, and an in-depth walk-through of all functionalities is provided with animated examples in S1 File).”</p>
    <p>*Overall, I have added a number of comments to the pdf document (attached) which can be easily adressed.</p>
    <p>Thank you for the thorough comments. We have adjusted the text accordingly.</p>
    <p>A list of noteworthy alterations or responses to comments in the PDF beyond simple text adjustments:</p>
    <p> -the title of the article was changed to read “package” rather than “application,” and is referred to as such throughout the article now</p>
    <p> -added DOI (<ext-link xlink:href="https://doi.org/10.5281/zenodo.6337609" ext-link-type="uri">https://doi.org/10.5281/zenodo.6337609</ext-link>) and version number (v1.0.3) to “Availability” section</p>
    <p> -Updated data availability statement to include “latest version” Zenodo DOI, for which the archive now contains CSV data only: <ext-link xlink:href="https://doi.org/10.5281/zenodo.4550726" ext-link-type="uri">https://doi.org/10.5281/zenodo.4550726</ext-link></p>
    <p> -instead of noting an explicit example with respect to financially inaccessible software, we rephrased to “..if convenient tools do not exist or are financially inaccessible due to commercial licensing”</p>
    <p> -tibbles can be supplied to dcr_app(); the help documentation for dcr_app() notes that the data can be a data.frame, tbl (tibble), or data.table</p>
    <p> -The caption for Figure 1 was modified to address all processing modules. It now reads: Figure 1: Conceptual workflow for datacleanr across its four processing modules. A) The Set-up and Overview tab allows for a quick initial assessment of a data set (variable types, distribution, completeness), where nested structures (e.g., by plot, site, region) can be resolved by defining a grouping structure from a categorical data column. B) The Filtering tab allows sub-setting the data based on valid R code (logical statements), which can be targeted (i.e., “scoped”) to individual groups from A). C) The Visual Cleaning and Annotating tab allows generating two or three dimensional visualizations (X, Y, and point size) rapidly, while dividing the data set into groups specified in A); data points for further inspection can be identified by clicking or lasso selection through which annotations may also be added. An overview table and histogram highlight selected points and the potential impact on the data’s distribution should the selected observations be removed. D) The Extract recipe tab generates code to reproduce all processing steps, which can be copied to the clipboard or sent directly to an active RStudio session’s script; depending on the processing mode (in memory or from a file), additional settings for file name specification are available. The schematic here illustrates the potential for including datacleanr into an existing workflow, for example, with prior determination of outliers using external algorithms (requires appending a logical TRUE/FALSE column named .dcrflag), interactive exploration and processing (with datacleanr), and informing subsequent analyses by drawing on the interactively annotated data (.annotation column in output from datacleanr).</p>
    <p> -We considered your comment on using text-based data objects, as opposed to binary files. We strongly feel that the binary format for use with datacleanr is necessary, as this is the only way to ensure that data input/output does not alter data types, for example from factor or time to character, which may require that additional bespoke code is added to the extracted recipe. We cannot ensure that this is would be done correctly during generation of the recipe, and thus prefer the *.RDS format. We appreciate the limitation on universal data input/output, however.</p>
    <p> - Is the cleaning (or any other aspects in this app) paralellised, and could you gain a substantial increase if you do this?</p>
    <p>Currently, the data selection (point clicking and lasso selection) is implemented by carrying point indices and plotly trace numbers (i.e., group numbers) in a data.frame. The limiting factors are checking for duplicates and redrawing the “outlier” trace (which is plotly’s equivalent of a ggplot2 geom). In fact, due to plotlys mechanics, the entire plot needs to be redrawn or refreshed when traces are manipulated. Packages such as multidplyr may be interesting for subsetting individual groups in the Filtering tab, but those operations are certainly not a bottleneck in processing time. We do, however, strive to enhance the user experience in the future by further decreasing processing time with streamlining above mentioned data.frame operations.</p>
    <p> -We appreciate you highlighting the necessity to provide information on why observations were considered conspicuous, erroneous or outliers, and have rephrased line 310 (PDF) to: We take this opportunity to explicitly urge users to make extensive use of the annotation feature on the Visualization tab to provide rich information on the selected observations (e.g., “interpolated observations”), as well as to adhere to best practices and transparency in outlier assessment and handling [e.g., 37] for any subsequent removal.</p>
    <p> -Comments on future developments were:</p>
    <p> + maybe included but not mentioned here: generate report which can include comments to why certain decisions were taken -THIS WOULD BE A VERY USEFUL FEATURE. See previous comments on annotation tool and flexibility (L111 in response)</p>
    <p> + loading from other file formats csv, txt, databases (DBI). See previous comments on file formats; database connections were data types are preserved could be a viable option, however, which we will consider for future developments</p>
    <p> + parallelisation of processing. See previous comments (L199 in response)</p>
    <p> + include splicing in the app (probably loading data into an sqlite database and query subsets out)? We have included this in the list of future developments within the text (L401 in Revised Mansuscript with Track Changes.docx)</p>
    <p> + I don’t know if it is possible - reduce the dependencies. We have done our best to keep dependencies as low as possible, but shiny and plotly are rather heavy. However, we still strive to drop dependencies where possible, and will aim to do so in the future, e.g., for new developments.</p>
    <p> + add vignettes to the package (possibly this paper? License?). We appreciate the utility of vignettes. However, the GitHub repository (<ext-link xlink:href="https://github.com/the-Hull/datacleanr" ext-link-type="uri">https://github.com/the-Hull/datacleanr</ext-link>) has an extensive set of examples with GIFs, which we believe are better suited to highlight the package’s functionality – this now constitutes the walk-through in the supporting information in a somewhat reduced fashion to meet the &lt;20 MB file size requirements We also would like to note that CRAN very regularly enforces a &lt;5 MB package size policy, and believe the GIFs in the ReadMe do better justice to the packages functionalities than a screenshot-based document of smaller size. The license for the package is GPL-3 and listed in the Availablility section.</p>
    <p> + In response to the comment on enhancement of data analyses through interactivity, we rephrased the first sentences of the conclusion to: “Exploration and processing of high-volume data can be enhanced by using interactive tools. datacleanr achieves this with its flexibility and interoperability, while facilitating best practices in data exploration, outlier detection, and especially reproducibility through the extractable code recipe.”</p>
    <p>*As mentioned, my main concern is the missing of a walk-through through one analysis. I would suggest that this relatively straight forward addition / change is done before publication.</p>
    <p>We appreciate this concern and are confident our animated examples in the Supporting Information file S1 File (Walkthrough.html) sufficiently address this concern.</p>
    <supplementary-material id="pone.0268426.s003" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">Response to Reviewers.docx</named-content></p>
      </caption>
      <media xlink:href="pone.0268426.s003.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pone.0268426.r003" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0268426.r003</article-id>
    <title-group>
      <article-title>Decision Letter 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Krug</surname>
          <given-names>Rainer M</given-names>
        </name>
        <role>Guest Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2022 Rainer M Krug</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Rainer M Krug</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0268426" id="rel-obj003" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">13 Apr 2022</named-content>
    </p>
    <p><!-- <div> -->PONE-D-21-05607R1<!-- </div> --></p>
    <p>Addressing the need for interactive, efficient, and reproducible data processing in ecology with the datacleanr R package</p>
    <p>PLOS ONE</p>
    <p>Dear Dr. Hurley,</p>
    <p>I took over the editorial role for your manuscript to PLOS ONE and would like to acknowledge my role as Reviewer 2 in the last round of review.</p>
    <p>I acknowledge the extremely long time since your initial submission but I was only assigned the role as editor for this paper a few days ago and will do anything possible to bring this paper to publication as soon as possible. A few comments are listed below in this letter.</p>
    <p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p>
    <p>Thanks a lot for addressing all points raised by the reviewers. I have only a few minor points which should be adressed before publication and some more general comments:</p>
    <p>Text:</p>
    <p>
      <list list-type="bullet">
        <list-item>
          <p>Please include a reference for RStudio, as it is done for e.g. R</p>
        </list-item>
        <list-item>
          <p>Figure 2 caption: clarify what n means</p>
        </list-item>
        <list-item>
          <p>Sort figs according to their first occurrence in the manuscript (i.e. 6-8 after fig 1)</p>
        </list-item>
        <list-item>
          <p>Availability Section:</p>
        </list-item>
        <list-item>
          <p>Start with stating which version you are using in the package and mention the DOI - than mention stable release and where one can get these from (DOI to newest version, 10.5281/zenodo.6337608, CRAN) and finally github repo as newest version. Probably one sentence about release plans to CRAN (always latest stable), github master / main is stable? Do you have a dev branch for development and possibly unstable versions?</p>
        </list-item>
        <list-item>
          <p>Capabilities l 135 add "in the supplemental material" or "LINK TO THE PERMANENT FILE IN GITHUB"</p>
        </list-item>
        <list-item>
          <p>l 238: "2 million observations smoothly" - is this a hard link, or soft link, after which it get's slower but still work? Also, in line 270 you mention one milion.</p>
        </list-item>
        <list-item>
          <p>I stil think it would be nice to have screenshots in the sections "Capabilities" when you refer to the individual steps (you have them in the visualization section), but I appreciate your point that the animated gifs give a better point. Can you put direct links to the animated gifs in the section they refer to and keep these permanent (e.g. link to a specific tagged release on github)?</p>
        </list-item>
        <list-item>
          <p>l 264: Add individual references to the individual packages (readr, dplyr, tidyr and lubridate)</p>
        </list-item>
      </list>
    </p>
    <p>Figures:</p>
    <p>
      <list list-type="bullet">
        <list-item>
          <p>Figure 5: with three replicates, to plot mean,min and max (which are two of the three points) is an aggressive approach. I would rather leave the shaded area and plot, instead of the mean, the third point. I do not see it as necessary as in this context, as the graph is not at all crucial to the paper, but regard would regard it as a cleaner approach.</p>
        </list-item>
        <list-item>
          <p>Figure 9 caption: re comment reviewer 1 on difference: I agree - I still, although explained in the caption, struggle to see where there is a difference. Also, I think the actual values of deltaV are not relevant in this graph. I think as a y asis, you would simply need four categories (from top to bottom): data in original data, day removed by using code based filering, day removed by using interactive processing, days gained by using interactive processing. These would be the relevant info, as the values at these days are not relevant based on the caption. If you want to retain the graph as it is, I would strongly suggest to have a fourth (or fifth?) colour, which highlights the data points retained in addition to the code based filtering.</p>
        </list-item>
      </list>
    </p>
    <p>SI:</p>
    <p>I like the SI a lot and the gifs work brilliantly - thanks.</p>
    <p>
      <list list-type="bullet">
        <list-item>
          <p>SI: Example 2 has missing GIF</p>
        </list-item>
      </list>
    </p>
    <p>General comments which do not require any action from your side:</p>
    <p>
      <list list-type="bullet">
        <list-item>
          <p>text based data object versus RDS: most data is stored in a csv file, as it can be generated from e.g. Excel. So using these as input would be very useful. Export of results does not need to be lossless, ut only include relevant results from the result and additional info could be saved as text files with additional details or even rds files. Saving should be lossless, so RDS is here appropriate. CRAN issues - use RUniverse for "full" package, provide functions in the package to download the additional info and data when needed, ..</p>
        </list-item>
        <list-item>
          <p>l 269: If you put the shiny app on shiny server, you can use it from all platforms (even smart phones) which have a browser. Probably include this in future plans (not relevant to the paper here).</p>
        </list-item>
        <list-item>
          <p>Reading in from databases (sqlite and duckdb come to mind as widely used stand alone databases which are used for larger datasets when standard handling in R is not possible anymore) would be extremely useful as a next step.</p>
        </list-item>
      </list>
    </p>
    <p>Please submit your revised manuscript by May 28 2022 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at <email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p>
    <p>Please include the following items when submitting your revised manuscript:</p>
    <p>
      <list list-type="bullet">
        <list-item>
          <p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p>
        </list-item>
        <list-item>
          <p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p>
        </list-item>
        <list-item>
          <p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p>
        </list-item>
      </list>
    </p>
    <p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p>
    <p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link>.</p>
    <p>We look forward to receiving your revised manuscript.</p>
    <p>Kind regards,</p>
    <p>Rainer M Krug, PhD</p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
    <p>Journal Requirements:</p>
    <p>Please review your reference list to ensure that it is complete and correct. If you have cited papers that have been retracted, please include the rationale for doing so in the manuscript text, or remove these references and replace them with relevant current references. Any changes to the reference list should be mentioned in the rebuttal letter that accompanies your revised manuscript. If you need to cite a retracted article, indicate the article’s retracted status in the References list and also include a citation and full reference for the retraction notice.</p>
    <p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at <email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pone.0268426.r004">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0268426.r004</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 1</article-title>
    </title-group>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0268426" id="rel-obj004" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>2</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">21 Apr 2022</named-content>
    </p>
    <p>Dear Editor, </p>
    <p>We extend our thanks for your time (also for the previous review) and the opportunity to further improve the manuscript. We have carefully considered the concerns and are confident that we fully address them in this second round of revisions. We kindly refer to the submitted response letter for detailed responses. Note that line references there refer to Revised Manuscript with Track Changes.docx</p>
    <p>Sincerely,</p>
    <p>Alexander Hurley on behalf of all authors</p>
    <supplementary-material id="pone.0268426.s004" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">Response to Reviewers.docx</named-content></p>
      </caption>
      <media xlink:href="pone.0268426.s004.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pone.0268426.r005" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0268426.r005</article-id>
    <title-group>
      <article-title>Decision Letter 2</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Krug</surname>
          <given-names>Rainer M</given-names>
        </name>
        <role>Guest Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2022 Rainer M Krug</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Rainer M Krug</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0268426" id="rel-obj005" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>2</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">2 May 2022</named-content>
    </p>
    <p>Addressing the need for interactive, efficient, and reproducible data processing in ecology with the datacleanr R package</p>
    <p>PONE-D-21-05607R2</p>
    <p>Dear Dr. Hurley,</p>
    <p>I received your revised version today and I am happy with the changes you made.</p>
    <p>We’re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p>
    <p>Within one week, you’ll receive an e-mail detailing the required amendments. When these have been addressed, you’ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p>
    <p>An invoice for payment will follow shortly after the formal acceptance. To ensure an efficient process, please log into Editorial Manager at <ext-link xlink:href="http://www.editorialmanager.com/pone/" ext-link-type="uri">http://www.editorialmanager.com/pone/</ext-link>, click the 'Update My Information' link at the top of the page, and double check that your user information is up-to-date. If you have any billing related questions, please contact our Author Billing department directly at <email>authorbilling@plos.org</email>.</p>
    <p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they’ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email>onepress@plos.org</email>.</p>
    <p>Kind regards,</p>
    <p>Rainer M Krug, PhD</p>
    <p>Guest Editor</p>
    <p>PLOS ONE</p>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pone.0268426.r006" specific-use="acceptance-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0268426.r006</article-id>
    <title-group>
      <article-title>Acceptance letter</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Krug</surname>
          <given-names>Rainer M</given-names>
        </name>
        <role>Guest Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2022 Rainer M Krug</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Rainer M Krug</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0268426" id="rel-obj006" related-article-type="reviewed-article"/>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">5 May 2022</named-content>
    </p>
    <p>PONE-D-21-05607R2 </p>
    <p>Addressing the need for interactive, efficient, and reproducible data processing in ecology with the datacleanr R package </p>
    <p>Dear Dr. Hurley:</p>
    <p>I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now with our production department. </p>
    <p>If your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information please contact <email>onepress@plos.org</email>.</p>
    <p>If we can help with anything else, please email us at <email>plosone@plos.org</email>. </p>
    <p>Thank you for submitting your work to PLOS ONE and supporting open access. </p>
    <p>Kind regards, </p>
    <p>PLOS ONE Editorial Office Staff</p>
    <p>on behalf of</p>
    <p>Dr. Rainer M Krug </p>
    <p>Guest Editor</p>
    <p>PLOS ONE</p>
  </body>
</sub-article>
