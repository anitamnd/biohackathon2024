<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD with OASIS Tables v1.0 20120330//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing-oasis-article1.dtd?>
<?SourceDTD.Version 1.0?>
<?ConverterInfo.XSLTName jats-oasis2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Biomed Opt</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Biomed Opt</journal-id>
    <journal-id journal-id-type="coden">JBOPFO</journal-id>
    <journal-id journal-id-type="publisher-id">JBO</journal-id>
    <journal-title-group>
      <journal-title>Journal of Biomedical Optics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1083-3668</issn>
    <issn pub-type="epub">1560-2281</issn>
    <publisher>
      <publisher-name>Society of Photo-Optical Instrumentation Engineers</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8978263</article-id>
    <article-id pub-id-type="pmid">35380031</article-id>
    <article-id pub-id-type="doi">10.1117/1.JBO.27.8.083010</article-id>
    <article-id pub-id-type="publisher-manuscript">JBO-210395SSR</article-id>
    <article-id pub-id-type="publisher-id">210395SSR</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Special Section Celebrating 30 Years of Open Source Monte Carlo Codes in Biomedical Optics</subject>
      </subj-group>
      <subj-group subj-group-type="SPIE-art-type">
        <subject>Paper</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SIMPA: an open-source toolkit for simulation and image processing for photonics and acoustics</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5332-4856</contrib-id>
        <name>
          <surname>Gröhl</surname>
          <given-names>Janek</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
        <xref rid="fn1" ref-type="author-notes">†</xref>
        <xref rid="fn2" ref-type="author-notes">‡</xref>
        <email>Janek.Grohl@cruk.cam.ac.uk</email>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-9179-9414</contrib-id>
        <name>
          <surname>Dreher</surname>
          <given-names>Kris K.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
        <xref rid="aff2" ref-type="aff">b</xref>
        <xref rid="cor1" ref-type="corresp">*</xref>
        <xref rid="fn2" ref-type="author-notes">‡</xref>
        <xref rid="b2" ref-type="bio"/>
        <email>k.dreher@dkfz-heidelberg.de</email>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7911-5622</contrib-id>
        <name>
          <surname>Schellenberg</surname>
          <given-names>Melanie</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
        <xref rid="aff3" ref-type="aff">c</xref>
        <xref rid="aff4" ref-type="aff">d</xref>
        <xref rid="b3" ref-type="bio"/>
        <email>melanie.schellenberg@dkfz-heidelberg.de</email>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0322-0370</contrib-id>
        <name>
          <surname>Rix</surname>
          <given-names>Tom</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
        <xref rid="aff3" ref-type="aff">c</xref>
        <xref rid="b4" ref-type="bio"/>
        <email>tom.rix@dkfz-heidelberg.de</email>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Holzwarth</surname>
          <given-names>Niklas</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
        <xref rid="b5" ref-type="bio"/>
        <email>n.holzwarth@dkfz-heidelberg.de</email>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Vieten</surname>
          <given-names>Patricia</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
        <xref rid="aff2" ref-type="aff">b</xref>
        <xref rid="b6" ref-type="bio"/>
        <email>p.vieten@dkfz-heidelberg.de</email>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3574-2085</contrib-id>
        <name>
          <surname>Ayala</surname>
          <given-names>Leonardo</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
        <xref rid="aff5" ref-type="aff">e</xref>
        <xref rid="b7" ref-type="bio"/>
        <email>l.menjivar@dkfz-heidelberg.de</email>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-0371-8635</contrib-id>
        <name>
          <surname>Bohndiek</surname>
          <given-names>Sarah E.</given-names>
        </name>
        <xref rid="aff6" ref-type="aff">f</xref>
        <xref rid="aff7" ref-type="aff">g</xref>
        <email>seb53@cam.ac.uk</email>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5919-9646</contrib-id>
        <name>
          <surname>Seitel</surname>
          <given-names>Alexander</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
        <xref rid="fn3" ref-type="author-notes">§</xref>
        <email>a.seitel@Dkfz-Heidelberg.de</email>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4910-9368</contrib-id>
        <name>
          <surname>Maier-Hein</surname>
          <given-names>Lena</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
        <xref rid="aff3" ref-type="aff">c</xref>
        <xref rid="aff5" ref-type="aff">e</xref>
        <xref rid="fn3" ref-type="author-notes">§</xref>
        <xref rid="b10" ref-type="bio"/>
        <email>l.maier-hein@ dkfz-heidelberg.de</email>
      </contrib>
      <aff id="aff1"><label>a</label><institution>German Cancer Research Center (DKFZ)</institution>, Division of Intelligent Medical Systems, Heidelberg, <country>Germany</country></aff>
      <aff id="aff2"><label>b</label><institution>Heidelberg University</institution>, Faculty of Physics and Astronomy, Heidelberg, <country>Germany</country></aff>
      <aff id="aff3"><label>c</label><institution>Heidelberg University</institution>, Faculty of Mathematics and Computer Science, Heidelberg, <country>Germany</country></aff>
      <aff id="aff4"><label>d</label><institution>HIDSS4Health - Helmholtz Information and Data Science School for Health</institution>, Heidelberg, <country>Germany</country></aff>
      <aff id="aff5"><label>e</label><institution>Heidelberg University</institution>, Medical Faculty, Heidelberg, <country>Germany</country></aff>
      <aff id="aff6"><label>f</label><institution>University of Cambridge, Cancer Research UK Cambridge Institute</institution>, Robinson Way, Cambridge, <country>United Kingdom</country></aff>
      <aff id="aff7"><label>g</label><institution>University of Cambridge</institution>, Department of Physics, Cambridge, <country>United Kingdom</country></aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>*</label>Address all correspondence to Kris K. Dreher, <email>k.dreher@dkfz-heidelberg.de</email></corresp>
      <fn id="fn1">
        <label>†</label>
        <p>Present address: Cancer Research UK Cambridge Institute, University of Cambridge, Robinson Way, Cambridge, CB2 0RE, United Kingdom, and Department of Physics, University of Cambridge, JJ Thomson Avenue, Cambridge, CB3 0HE, United Kingdom.</p>
      </fn>
      <fn id="fn2">
        <label>‡</label>
        <p>These authors contributed equally.</p>
      </fn>
      <fn id="fn3">
        <label>§</label>
        <p>Shared last authorship.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>4</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>4</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <!--PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>.-->
    <volume>27</volume>
    <issue>8</issue>
    <elocation-id>083010</elocation-id>
    <history>
      <date date-type="received">
        <day>20</day>
        <month>12</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>28</day>
        <month>2</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 The Authors</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>The Authors</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>Published by SPIE under a Creative Commons Attribution 4.0 International License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI.</license-p>
      </license>
    </permissions>
    <self-uri xlink:title="pdf" xlink:href="JBO_27_8_083010.pdf"/>
    <abstract>
      <title>Abstract.</title>
      <sec>
        <title>Significance</title>
        <p>Optical and acoustic imaging techniques enable noninvasive visualisation of structural and functional properties of tissue. The quantification of measurements, however, remains challenging due to the inverse problems that must be solved. Emerging data-driven approaches are promising, but they rely heavily on the presence of high-quality simulations across a range of wavelengths due to the lack of ground truth knowledge of tissue acoustical and optical properties in realistic settings.</p>
      </sec>
      <sec>
        <title>Aim</title>
        <p>To facilitate this process, we present the open-source simulation and image processing for photonics and acoustics (SIMPA) Python toolkit. SIMPA is being developed according to modern software design standards.</p>
      </sec>
      <sec>
        <title>Approach</title>
        <p>SIMPA enables the use of computational forward models, data processing algorithms, and digital device twins to simulate realistic images within a single pipeline. SIMPA’s module implementations can be seamlessly exchanged as SIMPA abstracts from the concrete implementation of each forward model and builds the simulation pipeline in a modular fashion. Furthermore, SIMPA provides comprehensive libraries of biological structures, such as vessels, as well as optical and acoustic properties and other functionalities for the generation of realistic tissue models.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>To showcase the capabilities of SIMPA, we show examples in the context of photoacoustic imaging: the diversity of creatable tissue models, the customisability of a simulation pipeline, and the degree of realism of the simulations.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p>SIMPA is an open-source toolkit that can be used to simulate optical and acoustic imaging modalities. The code is available at: <ext-link xlink:href="https://github.com/IMSY-DKFZ/simpa" ext-link-type="uri" specific-use="print">https://github.com/IMSY-DKFZ/simpa</ext-link>, and all of the examples and experiments in this paper can be reproduced using the code available at: <ext-link xlink:href="https://github.com/IMSY-DKFZ/simpa_paper_experiments" ext-link-type="uri" specific-use="print">https://github.com/IMSY-DKFZ/simpa_paper_experiments</ext-link>.</p>
      </sec>
    </abstract>
    <kwd-group>
      <title>Keywords:</title>
      <kwd>simulation</kwd>
      <kwd>open-source</kwd>
      <kwd>photoacoustics</kwd>
      <kwd>optical imaging</kwd>
      <kwd>acoustic imaging</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="sp1">
        <funding-source>European Research Council<named-content content-type="fundref:id">https://doi.org/10.13039/501100000781</named-content></funding-source>
        <award-id>ERC-2015-StG-37960</award-id>
        <award-id>101002198</award-id>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="10"/>
      <table-count count="3"/>
      <ref-count count="75"/>
      <page-count count="21"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>running-head</meta-name>
        <meta-value>Gröhl et al.: SIMPA: an open-source toolkit for simulation and image processing for photonics and acoustics</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <label>1</label>
    <title>Introduction</title>
    <p>Optical and acoustic imaging techniques enable real-time and noninvasive visualisation of structural and functional tissue properties without exposing the patient to harmful ionizing radiation. Nevertheless, the applicability of purely optical and acoustic imaging techniques is limited, for example, by the low penetration depth of near-infrared spectroscopy<xref rid="r1" ref-type="bibr"><sup>1</sup></xref> or by the difficulties of measuring functional tissue properties with ultrasound imaging.<xref rid="r2" ref-type="bibr"><sup>2</sup></xref> Furthermore, quantitative measurements are challenging as the state-of-the-art model-based approaches to solve the underlying inverse problems rely on assumptions that might not hold when applied to <italic>in vivo</italic> measurements.</p>
    <p>Data-driven approaches can be chosen to address these inverse problems. To this end, high-quality well-annotated data are needed, for example, to train deep learning algorithms<xref rid="r3" ref-type="bibr"><sup>3</sup></xref><named-content content-type="online"><xref rid="r4" ref-type="bibr"/></named-content><named-content content-type="print"><sup>–</sup></named-content><xref rid="r5" ref-type="bibr"><sup>5</sup></xref> or to optimize device design.<xref rid="r6" ref-type="bibr"><sup>6</sup></xref><sup>,</sup><xref rid="r7" ref-type="bibr"><sup>7</sup></xref> In living subjects, the acquisition of such data is extremely difficult because the underlying optical and acoustic tissue properties are generally not well known.<xref rid="r8" ref-type="bibr"><sup>8</sup></xref> As such, for algorithm training, many researchers instead use simulated data, which are comparatively easy to obtain, have known underlying optical and acoustic properties, and can be used for both algorithm training and validation.<xref rid="r9" ref-type="bibr"><sup>9</sup></xref><named-content content-type="online"><xref rid="r10" ref-type="bibr"/><xref rid="r11" ref-type="bibr"/><xref rid="r12" ref-type="bibr"/></named-content><named-content content-type="print"><sup>–</sup></named-content><xref rid="r13" ref-type="bibr"><sup>13</sup></xref> Nevertheless, the application of algorithms trained exclusively on synthetic training data to experimental measurements is challenging due to systematic differences between synthetic and experimental data.<xref rid="r14" ref-type="bibr"><sup>14</sup></xref></p>
    <p>Photoacoustic imaging (PAI) combines the advantages of optical and acoustic imaging by exploiting the photoacoustic (PA) effect, resulting in optical contrast with scalable high spatial resolution down to microns as a function of imaging depth, which can be up to several centimeters.<xref rid="r15" ref-type="bibr"><sup>15</sup></xref> PAI enables the recovery of functional tissue properties, such as blood oxygen saturation.<xref rid="r16" ref-type="bibr"><sup>16</sup></xref> To quantitatively recover such parameters, two inverse problems have to be solved: the acoustic inverse problem, which constitutes the accurate and quantitative reconstruction of the initial pressure distribution, and the optical inverse problem, which constitutes the quantitative recovery of the optical absorption coefficient.<xref rid="r8" ref-type="bibr"><sup>8</sup></xref> To generate realistic PA simulations for the purpose of training a data-driven method, all physical and computational aspects of signal formation need to be considered;<xref rid="r17" ref-type="bibr"><sup>17</sup></xref> these include synthetic volume generation, photon propagation, acoustic wave propagation, and image reconstruction.</p>
    <p>In recent years, a heterogeneous software landscape has emerged with various open-source or free-to-use tools to cover each of these physical and computational aspects. For example, for volume generation, there exist open access resources, such as the Digimouse<xref rid="r18" ref-type="bibr"><sup>18</sup></xref> annotated digital mouse phantom, digital breast phantoms (available at: <ext-link xlink:href="https://github.com/DIDSR/VICTRE" ext-link-type="uri">https://github.com/DIDSR/VICTRE</ext-link>, last visited March 22, 2022),<xref rid="r19" ref-type="bibr"><sup>19</sup></xref><sup>,</sup><xref rid="r20" ref-type="bibr"><sup>20</sup></xref> and the multimodal imaging-based detailed anatomical model of the human head and neck atlas MIDA.<xref rid="r21" ref-type="bibr"><sup>21</sup></xref> But usually, researchers use pseudorandom distributions of light-absorbing molecules (chromophores) to create tissue-mimicking <italic>in silico</italic> phantoms.<xref rid="r13" ref-type="bibr"><sup>13</sup></xref><sup>,</sup><xref rid="r22" ref-type="bibr"><sup>22</sup></xref> For optical modeling of photon transport in tissue, numerous approaches have been established; these focus in general either on (1) Monte Carlo methods including, for example, mcxyz,<xref rid="r23" ref-type="bibr"><sup>23</sup></xref> MCX,<xref rid="r24" ref-type="bibr"><sup>24</sup></xref> or ValoMC,<xref rid="r25" ref-type="bibr"><sup>25</sup></xref> which uses a Monte Carlo approach to light transport to simulate the propagation of photons in heterogeneous tissue, or (2) analytical methods to solve the radiative transfer equation, including diffusion approximation or finite element solvers as implemented in, for example, NIRFAST<xref rid="r26" ref-type="bibr"><sup>26</sup></xref> or Toast++.<xref rid="r27" ref-type="bibr"><sup>27</sup></xref> For acoustic modeling, there exists the popular k-Wave<xref rid="r28" ref-type="bibr"><sup>28</sup></xref> toolbox, which is a third-party MATLAB toolbox for the simulation and reconstruction of PA wave fields and is one of the most frequently used frameworks in the field. For image reconstruction, there are many different approaches, including backprojection algorithms,<xref rid="r29" ref-type="bibr"><sup>29</sup></xref><named-content content-type="online"><xref rid="r30" ref-type="bibr"/></named-content><named-content content-type="print"><sup>–</sup></named-content><xref rid="r31" ref-type="bibr"><sup>31</sup></xref> model-based algorithms,<xref rid="r32" ref-type="bibr"><sup>32</sup></xref><sup>,</sup><xref rid="r33" ref-type="bibr"><sup>33</sup></xref> and fast Fourier transform-based reconstruction algorithms.<xref rid="r34" ref-type="bibr"><sup>34</sup></xref><sup>,</sup><xref rid="r35" ref-type="bibr"><sup>35</sup></xref></p>
    <p>To navigate these tools and integrate them into a complete pipeline, the user must transform the output of each toolkit into an appropriate form for input to the next<xref rid="r36" ref-type="bibr"><sup>36</sup></xref><sup>,</sup><xref rid="r37" ref-type="bibr"><sup>37</sup></xref> or model the entire process in a joint computational framework.<xref rid="r38" ref-type="bibr"><sup>38</sup></xref><sup>,</sup><xref rid="r39" ref-type="bibr"><sup>39</sup></xref> Each step in assembling these pipelines can be time-consuming or error-prone, especially including correct consideration of the physical quantities and their units. They are typically limited to the toolkits that are currently integrated in their respective framework and thus lack broad applicability to other simulators. Furthermore, a seamless exchange from, e.g., a finite element method optical forward simulator to a Monte Carlo simulator is not straightforward in existing frameworks.</p>
    <p>To tackle these challenges, we developed the open-source simulation and image processing for photonics and acoustics (SIMPA) Python toolkit, which features a modular design that allows for easy exchange and combination of simulation pipeline elements. In its first version, the toolkit facilitates the simulation and processing of PA data and provides a straightforward way to adapt a simulation to meet the specific needs of a given researcher or project. It can easily be extended to support simulations corresponding to other optical and acoustic imaging modalities. The core idea of the framework is to standardize the information flow between different computational models by providing a central software architecture that abstracts from the individual requirements of external libraries. SIMPA achieves this by defining abstract implementations of the simulation steps based on adapters that can be implemented, such that specific toolkits can easily be integrated into the SIMPA ecosystem. SIMPA is tested using both Windows (specifically Windows 10) and Linux (specifically Ubuntu 20.04) operating systems. Third-party toolkits are executed on the GPU by default if this is supported by the respective toolkit and a compatible GPU is installed. Furthermore, SIMPA offers the possibility of exporting simulated time-series data compliant to the data format proposed by the International Photoacoustic Standardisation Consortium (IPASC).<xref rid="r40" ref-type="bibr"><sup>40</sup></xref></p>
    <p>In this paper, we first outline the purpose and the software details of SIMPA in Sec. <xref rid="sec2" ref-type="sec">2</xref>. Here, we give an overview of the software development process, the software architecture, the modeling of digital device twins, and computational tissue generation. Afterward, there is an extensive simulation and image processing examples section (Sec. <xref rid="sec3" ref-type="sec">3</xref>) in which we show the possibilities that SIMPA offers. We demonstrate the modularity of SIMPA by showcasing the results of example simulations including an overview of how parameter choices can affect the results and the degree of realism of the simulations that is achievable with SIMPA.</p>
  </sec>
  <sec id="sec2">
    <label>2</label>
    <title>SIMPA Toolkit</title>
    <p>SIMPA aims to facilitate realistic image simulation for optical and acoustic imaging modalities by providing adapters to crucial modeling steps, such as volume generation, optical modeling, acoustic modeling, and image reconstruction (<xref rid="f1" ref-type="fig">Fig. 1</xref>). SIMPA provides a communication layer between various modules that implement optical and acoustic forward and inverse models.</p>
    <fig position="float" id="f1">
      <label>Fig. 1</label>
      <caption>
        <p>The simulation and image processing for photonics and acoustics (SIMPA) toolkit.</p>
      </caption>
      <graphic xlink:href="JBO-027-083010-g001" position="float"/>
    </fig>
    <p>Non-experts can use the toolkit to create sensible simulations from default parameters in an end-to-end fashion. Domain experts are provided with the functionality to set up a highly customisable pipeline according to their specific use cases and tool requirements.</p>
    <p>The following high-level requirements are key to meeting the above purpose:</p>
    <list list-type="simple">
      <list-item>
        <label>1.</label>
        <p>Modularity: The different modules of the simulation pipeline should be implemented such that each of them can be paired with arbitrary implementations of preceding or succeeding modules. Specific module implementations can seamlessly be exchanged without breaking the simulation pipeline. The user has the freedom to arrange the elements of the simulation pipeline in exactly the way that they choose.</p>
      </list-item>
      <list-item>
        <label>2.</label>
        <p>Extensibility: The user should have the freedom to add any custom elements to the pipeline and to implement custom module adapters. There should exist documentation that shows how custom adapters for each module and completely new modules can be implemented.</p>
      </list-item>
      <list-item>
        <label>3.</label>
        <p>Physical correctness: Each module implementation should have a single purpose, produce plausible results, and not alter other parts of the pipeline. Physical quantities (i.e., units) should be correctly handled by the information flow between separate modules.</p>
      </list-item>
      <list-item>
        <label>4.</label>
        <p>Independence: Arbitrarily many sequentially executed SIMPA simulations should not influence the results of subsequent simulations.</p>
      </list-item>
      <list-item>
        <label>5.</label>
        <p>Usability: The entry for new users must be as easy as possible such that sensible PA images can be simulated without prior knowledge. A simulation with default parameters can be started using only a few lines of code.</p>
      </list-item>
    </list>
    <p>The following sections of this paper introduce the software development life cycle in Sec. <xref rid="sec2.1" ref-type="sec">2.1</xref> and SIMPA’s software architecture in Sec. <xref rid="sec2.2" ref-type="sec">2.2</xref>, as well as another prominent contribution of SIMPA: a volume creation adapter that enables the user to create diverse spatial distributions of tissue properties as detailed in Sec. <xref rid="sec2.4" ref-type="sec">2.4</xref>.</p>
    <sec id="sec2.1">
      <label>2.1</label>
      <title>Software Development Life Cycle</title>
      <p>SIMPA is developed using the Python programming language (Python Software Foundation),<xref rid="r41" ref-type="bibr"><sup>41</sup></xref> version 3.8 because it is currently one of the most commonly used programming languages. We use git<xref rid="r42" ref-type="bibr"><sup>42</sup></xref> as the version control system, and the code is maintained on GitHub (available at: <ext-link xlink:href="https://github.com/IMSY-DKFZ/simpa" ext-link-type="uri" specific-use="print">https://github.com/IMSY-DKFZ/simpa</ext-link>, last visited March 22, 2022). Stable versions of the develop branch are integrated into the main branch and then form a release with an increase in the version number according to the Semantic Versioning Specification (SemVer) scheme.<xref rid="r43" ref-type="bibr"><sup>43</sup></xref></p>
      <p>SIMPA code is written using a quality-controlled development process. Every feature request or bug fix is assigned an issue on the SIMPA GitHub page (available at: <ext-link xlink:href="https://github.com/IMSY-DKFZ/simpa/issues" ext-link-type="uri" specific-use="print">https://github.com/IMSY-DKFZ/simpa/issues</ext-link>, last visited March 22, 2022). Issues can be opened and commented on by any SIMPA user, and the code is written in separate branches that are only integrated into the develop branch after a successful code review by a member of the SIMPA core developer team. To ensure good code quality, the code reviews are designed to check whether the code follows the SIMPA developer guide:</p>
      <list list-type="simple">
        <list-item>
          <label>1.</label>
          <p>The code is executable and yields the expected result in a typical use case.</p>
        </list-item>
        <list-item>
          <label>2.</label>
          <p>The code is accompanied by an automatic or manual test.</p>
        </list-item>
        <list-item>
          <label>3.</label>
          <p>The code is written using the Python Enhancement Proposal (PEP) 8 style guide for Python code.<xref rid="r44" ref-type="bibr"><sup>44</sup></xref></p>
        </list-item>
        <list-item>
          <label>4.</label>
          <p>The code documents its intended use case, input parameters, and expected output.</p>
        </list-item>
      </list>
      <p>More specifically, each new feature and bug fix must add a unit test that tests the functionality of the feature. If automatic unit testing is not possible (e.g., because required third-party binaries are not available in the integrated testing environment), then a manual integration test is defined in which the feature is being used within a SIMPA simulation run. The output of the manual test is then reviewed by a SIMPA developer as a sanity check. Using such a mixture of automatic and manual tests, we aim to provide tests for every intended use case of SIMPA to ensure that the toolkit is stable and working as intended.</p>
    </sec>
    <sec id="sec2.2">
      <label>2.2</label>
      <title>Software Architecture</title>
      <p>SIMPA provides a unified abstract data structure that combines existing simulation tools to represent the full signal generation process of a given optical and/or acoustic imaging modality. Specifically, SIMPA handles the data/information flow from and to each simulation tool and provides an infrastructure to use these tools in an integrated pipeline. <xref rid="f2" ref-type="fig">Figure 2</xref> shows the main components of SIMPA and visualises their interactions in an example simulation pipeline.</p>
      <fig position="float" id="f2">
        <label>Fig. 2</label>
        <caption>
          <p>Software components of SIMPA. (a) The main software components of SIMPA’s software architecture. The toolkit consists of two main components, <monospace>core</monospace> and <monospace>utils</monospace>, as well as several smaller components (e.g., <monospace>io_handling</monospace>, <monospace>visualisation</monospace>), which are each composed of several subcomponents. The <monospace>core</monospace> contains all <monospace>SimulationModules</monospace>, <monospace>DeviceDigitaltwins</monospace>, and <monospace>ProcessingComponents</monospace>. The <monospace>utils</monospace> component contains the <monospace>Settings</monospace> dictionary, a standardized list of <monospace>Tags</monospace>, various <monospace>Libraries</monospace>, and other utility and helper classes to facilitate using the toolkit. (b) An example simulation pipeline. The pipeline is defined via a <monospace>Settings</monospace> dictionary using a standardized list of <monospace>Tags</monospace>. During the pipeline execution, each pipeline element (which can be either a <monospace>SimulationModule</monospace> or a <monospace>ProcessingComponent</monospace>) is called sequentially. After each step, the new results are amended to a hierarchical data format 5 (HDF5) file. The pipeline is repeated for each wavelength; afterwards, all multispectral <monospace>ProcessingComponents</monospace> are executed, and the results can be visualised. In this example, the included pipeline elements are volume generation, optical modeling, acoustic modeling, noise modeling, image reconstruction, field of view (FOV) cropping, linear unmixing, and result visualisation.</p>
        </caption>
        <graphic xlink:href="JBO-027-083010-g002" position="float"/>
      </fig>
      <p>SIMPA contains two primary Python modules: <monospace>core</monospace> and <monospace>utils</monospace>. Furthermore, the toolkit features several smaller Python modules: <monospace>io_handling</monospace>, <monospace>log</monospace>, <monospace>visualisation</monospace>, <monospace>algorithms</monospace>, <monospace>examples</monospace>, and <monospace>tests</monospace>. The SIMPA <monospace>core</monospace> defines a centralized structure to provide simulation tool-specific adapters to the abstract modules for each step in the simulation process. The <monospace>utils</monospace> package provides a collection of libraries and convenience methods to help a researcher set up a customized simulation pipeline.</p>
      <sec id="sec2.2.1">
        <label>2.2.1</label>
        <title>Core</title>
        <p>The <monospace>core</monospace> is organized into three Python submodules. The <monospace>SimulationModules</monospace> submodule provides interfaces for all simulation modules (e.g., the ones that are required for complete PA forward modeling). To meet the modularity criterion (Sec. <xref rid="sec2" ref-type="sec">2</xref>), it contains abstract module definitions for the major parts: <monospace>VolumeCreationModule</monospace>, <monospace>OpticalForwardModule</monospace>, <monospace>AcousticForwardModule</monospace>, and <monospace>ReconstructionForwardModule</monospace>. Furthermore, the <monospace>core</monospace> contains a <monospace>ProcessingComponents</monospace> submodule that contains a base for components that supplement the main simulation modules, such as a component for noise modeling, which currently supports a number of noise models: salt and pepper noise, Gaussian noise, Poisson noise, uniform noise, and Gamma noise. Finally, the <monospace>DeviceDigitalTwins</monospace> submodule also contains base classes that enable the definition of digital twins of PA imaging devices such as slit or pencil illuminations combined with circular or linear detector geometries. Details on the digital device representation in SIMPA can be found in Sec. <xref rid="sec2.3" ref-type="sec">2.3</xref>.</p>
        <p>The main entry point for the user is the <monospace>simulate</monospace> method that is contained in the <monospace>core</monospace>. This method is responsible for the execution of all desired simulation modules and processing components (referred to as <monospace>pipeline_elements</monospace>).</p>
        <p>To meet the extensibility criterion (Sec. <xref rid="sec2" ref-type="sec">2</xref>), a developer has the freedom to add custom new simulation module adapters, processing components, or digital device twins. Each pipeline element in the simulation pipeline has to be fully self-contained and thus handle its produced result correctly within the information flow of SIMPA. To ensure this, each of the Python submodules provides an abstract class that encapsulates parts of the functionality. For example, a user can define a custom simulation module using the abstract <monospace>SimulationModule</monospace> class as a blueprint. To implement a Python adapter, it has to inherit from this class and overwrite the <monospace>implementation</monospace> method. Internally, the representation of the computational grid is defined by isotropic voxels. This does not necessarily exclude external tools that work on differently defined grids such as anisotropic voxels or mesh-based methods if the according adapter translates one into another. The edge size of the voxels is generally defined by the user attribute <monospace>SPACING_MM</monospace>, but this would not prevent an adapter from resampling the voxel sizes. The grid uses the default unit for length within SIMPA, which is mm. The default unit for time in SIMPA is ms.</p>
      </sec>
      <sec id="sec2.2.2">
        <label>2.2.2</label>
        <title>Utils</title>
        <p>The <monospace>utils</monospace> Python module contains utility classes such as the <monospace>Tags</monospace> and <monospace>Settings</monospace> classes. The <monospace>Settings</monospace> class is a dictionary that contains key-value pairs defining the simulation parameters. To assert standardized naming conventions of the dictionary keys, these keys are globally accessible via the <monospace>Tags</monospace> class. Furthermore, there is the <monospace>Libraries</monospace> package that provides both <monospace>LiteratureValues</monospace> as well as collections of classes that represent, e.g., geometrical shapes and biochemical molecules. The <monospace>LiteratureValues</monospace> are used to instantiate these classes for the purpose of generating synthetic tissue models. The <monospace>Libraries</monospace> package provides the following collections:</p>
        <list list-type="simple">
          <list-item>
            <p><monospace>LiteratureValues:</monospace> Reference values for optical, acoustic, and morphological tissue properties including the respective online source.</p>
          </list-item>
          <list-item>
            <p><monospace>SpectrumLibrary:</monospace> Classes based on a <monospace>Spectrum</monospace>. A <monospace>Spectrum</monospace> represents wavelength-dependent tissue properties such as optical absorption or scattering defined for a specific set of wavelengths (depending on the reference literature).</p>
          </list-item>
          <list-item>
            <p><monospace>MoleculeLibrary:</monospace> Classes based on a <monospace>Molecule</monospace>. The <monospace>Molecule</monospace> class is used to represent the optical and acoustic properties of biochemical molecules such as melanin or hemoglobin.</p>
          </list-item>
          <list-item>
            <p><monospace>TissueLibrary:</monospace> Predefined <monospace>MolecularComposition</monospace> classes. A <monospace>MolecularComposition</monospace> is a linear mixture of different <monospace>Molecules</monospace>. The elements of the <monospace>TissueLibrary</monospace> are defined such that the optical and acoustic properties of the mixed <monospace>Molecules</monospace> agree with the literature references (e.g., skin or blood).</p>
          </list-item>
          <list-item>
            <p><monospace>StructureLibrary:</monospace> Classes based on a <monospace>Structure</monospace>. Each <monospace>Structure</monospace> defines the geometry of a certain volumetric shape (such as cuboids, tubes, or vessel trees) in a voxelized grid.</p>
          </list-item>
        </list>
        <p>The interplay of these libraries is described in greater detail in Sec. <xref rid="sec2.4" ref-type="sec">2.4</xref>. All libraries are designed such that they are easily customisable by the user, for example, by allowing for the addition of spectra, molecules, or tissue types.</p>
      </sec>
      <sec id="sec2.2.3">
        <label>2.2.3</label>
        <title>IO and data format</title>
        <p>SIMPA uses the <italic>Hierarchical Data Format 5</italic> (HDF5)<xref rid="r45" ref-type="bibr"><sup>45</sup></xref> as it comprises a hierarchical data structure, has interfaces in many commonly used programming languages, and features the possibility of adding metadata. All inputs, settings, and outputs of a SIMPA simulation are stored in a central HDF5 file, and at the end of the simulation, the file contents can be repacked to be saved in a compressed manner. The SIMPA <monospace>io_handling</monospace> Python module abstracts from the communication with the <monospace>h5py</monospace> package<xref rid="r46" ref-type="bibr"><sup>46</sup></xref> and contains functionality to save and write data to the hard drive (<xref rid="f3" ref-type="fig">Fig. 3</xref>).</p>
        <fig position="float" id="f3">
          <label>Fig. 3</label>
          <caption>
            <p>The SIMPA file data structure is hierarchical. The output file of SIMPA uses the Hierarchical Data Format 5 (HDF5). The top-level fields are (1) <monospace>Settings</monospace> in which the input parameters for the global simulation pipeline as well as for all pipeline elements are stored in. (2) The <monospace>Device</monospace> describes the digital device twin with which the simulations are performed. (3) The <monospace>Simulations</monospace> field stores all of the simulation property maps that serve as input for the pipeline elements, such as the optical absorption (<inline-formula><mml:math id="math1" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>), scattering (<inline-formula><mml:math id="math2" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>), and anisotropy (<inline-formula><mml:math id="math3" display="inline" overflow="scroll"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:math></inline-formula>). These properties are wavelength-dependent and therefore are saved for each wavelength respectively. The density (<inline-formula><mml:math id="math4" display="inline" overflow="scroll"><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow></mml:math></inline-formula>), acoustic attenuation (<inline-formula><mml:math id="math5" display="inline" overflow="scroll"><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:math></inline-formula>), speed of sound (<inline-formula><mml:math id="math6" display="inline" overflow="scroll"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow></mml:math></inline-formula>), Grüneisen parameter (<inline-formula><mml:math id="math7" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi></mml:mrow></mml:math></inline-formula>) or blood oxygen saturation (<inline-formula><mml:math id="math8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>sO</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) are wavelength-independent and therefore only stored once. The <monospace>Simulations</monospace> field also stores the outputs for each wavelength of each processing component and simulation module such as optical fluence (<inline-formula><mml:math id="math9" display="inline" overflow="scroll"><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:math></inline-formula>), initial pressure (<inline-formula><mml:math id="math10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>), time series pressure data (<inline-formula><mml:math id="math11" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>), or the reconstructed image (<inline-formula><mml:math id="math12" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mn>0</mml:mn><mml:mi>recon</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>). (4) The simulation pipeline is a list that stores the specific module adapters that have been combined and their order to form the simulation pipeline.</p>
          </caption>
          <graphic xlink:href="JBO-027-083010-g003" position="float"/>
        </fig>
        <p>SIMPA also offers the feature to export simulated time-series data into the data format proposed by IPASC.<xref rid="r47" ref-type="bibr"><sup>47</sup></xref> This data format is based on HDF5 as well and defines a standardized list of metadata parameters to include.<xref rid="r48" ref-type="bibr"><sup>48</sup></xref></p>
      </sec>
    </sec>
    <sec id="sec2.3">
      <label>2.3</label>
      <title>Digital Device Twins</title>
      <p>SIMPA enables the definition of digital twins of optical and acoustic devices by providing abstract base classes for the implementation of detectors and illuminators (cf. <xref rid="f4" ref-type="fig">Fig. 4</xref>). To this end, SIMPA contains the <monospace>DetectionGeometryBase</monospace> and <monospace>IlluminationGeometryBase</monospace> classes, both of which inherit from the <monospace>DigitalDeviceTwinBase</monospace> class. The <monospace>DigitalDeviceTwinBase</monospace> class defines the device position and the field-of-view (FOV). The <monospace>DetectionGeometryBase</monospace> and <monospace>IlluminationGeometryBase</monospace> classes are responsible for defining the necessary parameters and abstract methods for the implementation of custom devices. To define a detection geometry or an illumination geometry, a class that inherits from the fitting base class and implements the necessary abstract methods needs to be written. A PA device is defined by having both a detection and an illumination geometry.</p>
      <fig position="float" id="f4">
        <label>Fig. 4</label>
        <caption>
          <p>Unified modeling language (UML) class diagram of the digital device representation in SIMPA. Each box represents a class with the class name in bold. The first set of elements are the fields defined by these classes with their types shown in red, and the italic fields refer to abstract methods. A PA device comprises a detection geometry and an illumination geometry. All classes inherit from the <monospace>DigitalDeviceTwinBase</monospace> class, which defines common attributes: the device position and the FOV.</p>
        </caption>
        <graphic xlink:href="JBO-027-083010-g004" position="float"/>
      </fig>
      <p>SIMPA predefines some commonly used detection and illumination geometries, as well as some PA devices. Currently, SIMPA provides classes for curved arrays, linear arrays, and planar array detection geometries, as well as disk, Gaussian beam, pencil beam, pencil array, and slit illumination geometries. Using these classes, the user can freely combine detection and illumination geometries as well as their relative positions to accurately represent real devices. SIMPA also provides digital twins of some PA devices: the multispectral optoacoustic tomography (MSOT) Acuity Echo, the MSOT InVision 256-TF, or the raster-scan optoacoustic mesoscopy (RSOM) Xplorer P50 from iThera Medical (iThera Medical GmbH, Munich, Germany). Because SIMPA currently only supports MCX as the optical forward model, and MCX only has a limited amount of supported illumination geometries, the MSOT Acuity Echo and the MSOT InVision 256-TF illumination geometries are represented by individual classes, and a version of MCX that supports these geometries is provided as a fork at: <ext-link xlink:href="https://github.com/IMSY-DKFZ/mcx" ext-link-type="uri" specific-use="print">https://github.com/IMSY-DKFZ/mcx</ext-link>, (last visited March 22, 2022).</p>
    </sec>
    <sec id="sec2.4">
      <label>2.4</label>
      <title>Diverse Tissue Modeling</title>
      <p>A core prerequisite for the simulation of realistic PA images is the modeling of diverse tissue geometries by generating plausible distributions of optical and acoustic parameters in a virtual volume. In this context, diversity comprises not only a wide variety of geometrical shapes that might occur in biological tissue but also the accurate modeling of optical and acoustic properties of different tissue types such as skin, blood, or fat. These tissue types are usually mixtures of molecules each with distinct properties, which can be difficult to represent computationally. To meet this need, SIMPA provides a <monospace>VolumeCreation</monospace> module that enables the convenient generation of custom tissue models. The backbone of the module is the way that the optical and acoustic tissue properties are represented using flexible <monospace>MolecularCompositions</monospace> (see <xref rid="f5" ref-type="fig">Fig. 5</xref>). Using a hierarchical listing of predefined structures, the user can then create custom spatial distributions of these molecular compositions. The ability to create realistic tissue models depends on several factors, which include (1) the availability of high-quality reference measurements for the optical and acoustic properties, (2) information on the molecular composition of various tissue types, and (3) an accurate representation of their spatial distributions within the region of interest.</p>
      <fig position="float" id="f5">
        <label>Fig. 5</label>
        <caption>
          <p>Overview of the steps involved for modeling an <italic>in silico</italic> vessel tree with SIMPA. The diagram shows the resources that SIMPA provides for users to create custom tissue models. Wavelength-dependent properties such as the optical absorption (<inline-formula><mml:math id="math13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>), scattering (<inline-formula><mml:math id="math14" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>), or scattering anisotropy (<inline-formula><mml:math id="math15" display="inline" overflow="scroll"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:math></inline-formula>) are provided in the <monospace>SpectrumLibrary</monospace>, whereas wavelength-independent properties such as the speed of sound (<inline-formula><mml:math id="math16" display="inline" overflow="scroll"><mml:mrow><mml:mi>ν</mml:mi></mml:mrow></mml:math></inline-formula>), the tissue density (<inline-formula><mml:math id="math17" display="inline" overflow="scroll"><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow></mml:math></inline-formula>), or the Grüneisen parameter (<inline-formula><mml:math id="math18" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi></mml:mrow></mml:math></inline-formula>) are provided by the <monospace>LiteratureValues</monospace>. A <monospace>MolecularComposition</monospace> corresponds to a linear mixture of <monospace>Molecules</monospace> that can be used in combination with a geometrical molecular distribution from the <monospace>StructureLibrary</monospace> to create an <italic>in silico</italic> model.</p>
        </caption>
        <graphic xlink:href="JBO-027-083010-g005" position="float"/>
      </fig>
      <sec id="sec2.4.1">
        <label>2.4.1</label>
        <title>Optical and acoustic molecule properties</title>
        <p>A full list of all tissue properties considered in SIMPA is given in <xref rid="t001" ref-type="table">Tables 1</xref>–<xref rid="t002" ref-type="table">2</xref>. Within the SIMPA codebase, these molecular properties are integrated as inherent parts of a <monospace>Molecule</monospace>. While most properties can be approximated as singular values, the optical absorption, scattering, and anisotropy are wavelength-dependent and therefore represented by a <monospace>Spectrum</monospace> that linearly interpolates between the nearest known wavelengths to approximate the full spectrum during simulation.</p>
        <table-wrap position="float" id="t001">
          <label>Table 1</label>
          <caption>
            <p>Overview of all optical properties that are represented in a SIMPA molecule with their respective units.</p>
          </caption>
          <!--OASIS TABLE HERE-->
          <table frame="hsides" rules="groups">
            <colgroup>
              <col width="0.69*"/>
              <col width="1.31*"/>
            </colgroup>
            <thead>
              <tr>
                <th valign="top">Optical properties</th>
                <th valign="top">Unit</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Absorption coefficient</td>
                <td>
                  <inline-formula>
                    <mml:math id="math19" display="inline" overflow="scroll">
                      <mml:mrow>
                        <mml:msup>
                          <mml:mi>cm</mml:mi>
                          <mml:mrow>
                            <mml:mo>−</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                        </mml:msup>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td>Scattering coefficient</td>
                <td>
                  <inline-formula>
                    <mml:math id="math20" display="inline" overflow="scroll">
                      <mml:mrow>
                        <mml:msup>
                          <mml:mi>cm</mml:mi>
                          <mml:mrow>
                            <mml:mo>−</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                        </mml:msup>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td>Scattering anisotropy</td>
                <td>Unitless</td>
              </tr>
              <tr>
                <td>Grüneisen parameter</td>
                <td>Unitless</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="t002">
          <label>Table 2</label>
          <caption>
            <p>Overview of all acoustic properties that are represented in a SIMPA molecule with their respective units.</p>
          </caption>
          <!--OASIS TABLE HERE-->
          <table frame="hsides" rules="groups">
            <colgroup>
              <col width="0.65*"/>
              <col width="1.35*"/>
            </colgroup>
            <thead>
              <tr>
                <th valign="top">Acoustic properties</th>
                <th valign="top">Unit</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Speed of sound</td>
                <td>
                  <inline-formula>
                    <mml:math id="math21" display="inline" overflow="scroll">
                      <mml:mrow>
                        <mml:mi mathvariant="normal">m</mml:mi>
                        <mml:mtext> </mml:mtext>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mi mathvariant="normal">s</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mo>−</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                        </mml:msup>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td>Density</td>
                <td>
                  <inline-formula>
                    <mml:math id="math22" display="inline" overflow="scroll">
                      <mml:mrow>
                        <mml:mi>kg</mml:mi>
                        <mml:mtext> </mml:mtext>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mi mathvariant="normal">m</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mo>−</mml:mo>
                            <mml:mn>3</mml:mn>
                          </mml:mrow>
                        </mml:msup>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td>Acoustic attenuation</td>
                <td>
                  <inline-formula>
                    <mml:math id="math23" display="inline" overflow="scroll">
                      <mml:mrow>
                        <mml:mi>dB</mml:mi>
                        <mml:mtext> </mml:mtext>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mi>cm</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mo>−</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                        </mml:msup>
                        <mml:mtext> </mml:mtext>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mi>MHz</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mo>−</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                        </mml:msup>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>For wavelength-dependent information on the optical properties of the chromophores most commonly found in human tissue, Jacques published an invaluable review article<xref rid="r49" ref-type="bibr"><sup>49</sup></xref> and made information available via the OMLC website.<xref rid="r50" ref-type="bibr"><sup>50</sup></xref> We decided to follow the system of units introduced in the cited literature in SIMPA. For the tissue properties relevant for acoustic forward modeling, we used the IT’IS database for thermal and electromagnetic parameters of biological tissues<xref rid="r51" ref-type="bibr"><sup>51</sup></xref> as it provides information on the mean value and distribution of these properties for many different tissue types. Other literature sources that are being used by SIMPA for representing molecular properties are Kedenburg et al.<xref rid="r52" ref-type="bibr"><sup>52</sup></xref> for heavy water, Zhang et al.<xref rid="r53" ref-type="bibr"><sup>53</sup></xref> for water, or Antunes et al.<xref rid="r54" ref-type="bibr"><sup>54</sup></xref> for the optical properties of bone.</p>
      </sec>
      <sec id="sec2.4.2">
        <label>2.4.2</label>
        <title>Molecular tissue compositions</title>
        <p>To represent the properties of a tissue type, SIMPA uses a <monospace>MolecularComposition</monospace>, which is a linear combination of <monospace>Molecules</monospace>. In the <monospace>TissueLibrary</monospace>, SIMPA provides several predefined tissue types such as blood, skin, muscle, and bone that are compiled from literature sources. However, the framework can also be used to easily define custom user-specific molecular compositions.</p>
        <p>Information on the molecular composition of tissue types is sparse and scattered throughout the literature. SIMPA models the properties of different skin layers and muscle tissue using the review article of Bashkatov et al.,<xref rid="r55" ref-type="bibr"><sup>55</sup></xref> melanin content in the epidermis using Alaluf et al.,<xref rid="r56" ref-type="bibr"><sup>56</sup></xref> the water volume fractions of different tissue types in the human body using Timmins and Wall<xref rid="r57" ref-type="bibr"><sup>57</sup></xref> and Forbes et al.,<xref rid="r58" ref-type="bibr"><sup>58</sup></xref> and the distribution of arterial and venous blood oxygenations using Molnar and Nemeth<xref rid="r59" ref-type="bibr"><sup>59</sup></xref> and Merrick and Hayes.<xref rid="r60" ref-type="bibr"><sup>60</sup></xref></p>
      </sec>
      <sec id="sec2.4.3">
        <label>2.4.3</label>
        <title>Spatial tissue distribution</title>
        <p>Taking the creation of an <italic>in silico</italic> forearm as an example, specialized clinical papers can be used to obtain information on aspects such as the distribution of sizes of the radial and ulnar artery<xref rid="r61" ref-type="bibr"><sup>61</sup></xref> and their accompanying veins,<xref rid="r62" ref-type="bibr"><sup>62</sup></xref> the thickness of skin layers such as the dermis and epidermis,<xref rid="r63" ref-type="bibr"><sup>63</sup></xref> the separation of the radius and ulna bones,<xref rid="r64" ref-type="bibr"><sup>64</sup></xref> and the depth of subcutaneous vessels.<xref rid="r65" ref-type="bibr"><sup>65</sup></xref></p>
        <p>SIMPA offers the ability to create voxelized volumes of molecular compositions and provides two main ways to create their spatial distributions.</p>
        <sec id="sec2.4.3.1">
          <title>Model-based volume generator</title>
          <p>The purpose of this <monospace>Adapter</monospace> is to enable a rule-based creation of voxelized simulation volumes. The generator is given a list of structures that are each represented by a voxelized definition of their shape, a molecular composition, and a priority. In the case of two structures occupying the same voxel, the molecular composition of the structure with the higher priority is chosen for that voxel. Based on their shape and priority, all structures are then merged into a single distribution of optical and acoustic parameters.</p>
          <p>SIMPA provides a <monospace>StructureLibrary</monospace> that contains many basic 3D shapes (<monospace>Structures</monospace>), such as layers, spheres, elliptical tubes, cuboids, parallelepipeds, or vessel trees. These <monospace>Structures</monospace> can be mixed to create arbitrary simulation volumes. For the generation of vessel trees, we have integrated a random walk-based algorithm into SIMPA, in contrast to other work that uses Lindenmayer systems to build a grammar with the inclusion of stochastic rules.<xref rid="r66" ref-type="bibr"><sup>66</sup></xref></p>
        </sec>
        <sec id="sec2.4.3.2">
          <title>Segmentation-based volume generator</title>
          <p>The purpose of this <monospace>Adapter</monospace> is to take voxelized segmentation masks as input and map them to specific tissue types, which allows for the easy inclusion of spatial tissue property distributions from other sources. The user themself is responsible for loading a segmentation mask from a file into memory and transforming it into a numpy array as an input for the SIMPA pipeline.</p>
        </sec>
      </sec>
    </sec>
  </sec>
  <sec id="sec3">
    <label>3</label>
    <title>SIMPA Use Cases</title>
    <p>The functionality spectrum covered by the SIMPA toolkit is best demonstrated by exemplary use cases. The use cases in this section build upon each other with increasing complexity. Section <xref rid="sec3.1" ref-type="sec">3.1</xref> introduces the initiation of a basic simulation pipeline. Section <xref rid="sec3.2" ref-type="sec">3.2</xref> shows the convenience of changing smaller hyperparameters of an existing pipeline and the impact on the outcome of the pipeline, and Sec. <xref rid="sec3.3" ref-type="sec">3.3</xref> analogously illustrates this for the change of whole simulation modules as well as digital device twins. Section <xref rid="sec3.4" ref-type="sec">3.4</xref> showcases the diversity of possible tissue geometries, and Sec. <xref rid="sec3.5" ref-type="sec">3.5</xref> compares simulation outcomes of SIMPA with a real PA image. Finally, Sec. <xref rid="sec3.6" ref-type="sec">3.6</xref> combines the previous sections to exemplify the generation of a diverse dataset of PA images. The optical and acoustic modeling toolkits used for all experiments in this section were MCX<xref rid="r24" ref-type="bibr"><sup>24</sup></xref> and k-Wave,<xref rid="r28" ref-type="bibr"><sup>28</sup></xref> using SIMPA-provided adapters. MCX uses the Monte Carlo method that repeatedly draws random variables from an underlying model distribution to reach high accuracy.<xref rid="r67" ref-type="bibr"><sup>67</sup></xref> MCX approximates a light transport model using this method. K-Wave is based on the k-space pseudospectral method for modeling nonlinear ultrasound propagation in heterogeneous media.<xref rid="r68" ref-type="bibr"><sup>68</sup></xref> All experiments were conducted using a workstation with an AMD(R) Ryzen 3900x 12-core central processing unit, 64 GB of RAM, and NVIDIA RTX 3090 GPU running Ubuntu 20.04., and they can be reproduced using the code available at <ext-link xlink:href="https://github.com/IMSY-DKFZ/simpa_paper_experiments" ext-link-type="uri" specific-use="print">https://github.com/IMSY-DKFZ/simpa_paper_experiments</ext-link>. The run times for each executable experiment are mentioned; however, a detailed analysis of SIMPA’s run times, computational requirements, and postprocessing examples<xref rid="r69" ref-type="bibr"><sup>69</sup></xref><sup>,</sup><xref rid="r70" ref-type="bibr"><sup>70</sup></xref> can be found in the <ext-link xlink:href="https://doi.org/10.1117/1.JBO.27.8.083010.s01" ext-link-type="uri">Supplementary Material</ext-link>.</p>
    <sec id="sec3.1">
      <label>3.1</label>
      <title>Running a Simulation Out-of-the-Box</title>
      <p>Simulations are run using the <monospace>simulate</monospace> function, which is located in the <monospace>core</monospace> Python module. The function <monospace>simulate</monospace> takes three input arguments: (1) a <monospace>list</monospace> with a definition of the simulation pipeline, (2) a <monospace>Settings</monospace> dictionary, which contains all parameters for the simulation, and (3) a <monospace>Device</monospace>, which represents a digital twin of a PAI device. The following listing shows how these three input parameters are defined and given to the <monospace>simulate</monospace> function. For each of the used simulation pipeline elements, a settings dictionary that contains the parameters needs to be defined. An overview of the user-side pseudocode to set up a simulation with SIMPA is given by:</p>
      <p>
        <monospace>import simpa as sp</monospace>
      </p>
      <p>
        <monospace># Create general settings</monospace>
      </p>
      <p>
        <monospace>settings = sp.Settings(general_settings)</monospace>
      </p>
      <p>
        <monospace># Create specific settings for each pipeline element</monospace>
      </p>
      <p>
        <monospace># in the simulation pipeline</monospace>
      </p>
      <p>
        <monospace>settings.set_volume_creation_settings(volume_creation_settings)</monospace>
      </p>
      <p>
        <monospace>settings.set_optical_settings(optical_settings)</monospace>
      </p>
      <p>
        <monospace>settings.set_acoustic_settings(acoustic_settings)</monospace>
      </p>
      <p>
        <monospace>settings.set_reconstruction_settings(reconstruction_settings)</monospace>
      </p>
      <p>
        <monospace># Set the simulation pipeline</monospace>
      </p>
      <p>
        <monospace>simulation_pipeline = [sp.VolumeCreatorModule(settings),</monospace>
      </p>
      <p> <monospace>sp.OpticalForwardModule(settings),</monospace></p>
      <p> <monospace>sp.AcousticForwardModule(settings),</monospace></p>
      <p> <monospace>sp.ReconstructionModule(settings)]</monospace></p>
      <p>
        <monospace># Choose a PA device with device position in the volume</monospace>
      </p>
      <p>
        <monospace>device = sp.CustomDevice()</monospace>
      </p>
      <p>
        <monospace># Simulate the pipeline</monospace>
      </p>
      <p>
        <monospace>sp.simulate(simulation_pipeline, settings, device)</monospace>
      </p>
    </sec>
    <sec id="sec3.2">
      <label>3.2</label>
      <title>Customising Simulation Parameters</title>
      <p>SIMPA enables easy customization of simulation parameters according to the criterion usability. A wide range of simulation outputs can be achieved by simply changing one parameter, such as the spacing or image reconstruction bandpass filter (<xref rid="f6" ref-type="fig">Fig. 6</xref>), with the latter achieved, for example, by setting <monospace>Tags.RECONSTRUCTION_PERFORM_BANDPASS_FILTERING</monospace> in the reconstruction module settings to <monospace>True</monospace> instead of <monospace>False</monospace> as it is by default. To showcase this, a simulation pipeline was executed with three different spacings (0.15, 0.35, and 0.55 mm) and reconstructed with the default settings (delay-and-sum), with an applied bandpass filter, with a “differential mode” (delay-and-sum of the first derivative of the time signal), and finally, with a customized set of hyperparameters. For the bandpass filter, a Tukey window<xref rid="r71" ref-type="bibr"><sup>71</sup></xref> with an alpha value of 0.5 and 1 kHz as high-pass and 8 MHz as low-pass frequencies was applied. The set of hyperparameters was chosen such that the result is most similar to the underlying initial pressure. For different phantom designs, illumination geometries, or detection geometries, a different choice of parameters might be preferable.</p>
      <fig position="float" id="f6">
        <label>Fig. 6</label>
        <caption>
          <p>Simulation results with different hyperparameter configurations using a digital device twin of the MSOT Acuity Echo (iThera Medical GmbH, Munich, Germany). The results are shown for three spacings (<inline-formula><mml:math id="math24" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula>) in three rows (0.15, 0.35, and 0.55 mm), and from left to right, the columns show the following: (a) the ground truth initial pressure distribution; (b) the default pipeline with delay-and-sum reconstruction of the time-series pressure data (pressure mode); (c) delay-and-sum reconstruction with a bandpass filter (Tukey window with an alpha value of 0.5 and 1 kHz as high-pass and 8 MHz as low-pass frequencies) applied to the time-series data; (d) delay-and-sum reconstruction with the first derivative of the time-series data (differential mode); and (e) delay-and-sum reconstruction with a bandpass filter with the same configuration as in (c), the first derivative of the time-series data and envelope detection.</p>
        </caption>
        <graphic xlink:href="JBO-027-083010-g006" position="float"/>
      </fig>
      <p>The overall run time for these simulations was about 480 s. The run times of the optical and acoustic forward modules as well as the image reconstruction for the specified hardware are reported in <xref rid="t003" ref-type="table">Table 3</xref>. Only the mean for the different parameter combinations of these times are reported; however, an extensive listing of the run times of each module in each pipeline can be found in Tables S1-S4 in the <ext-link xlink:href="https://doi.org/10.1117/1.JBO.27.8.083010.s01" ext-link-type="uri">Supplementary Material</ext-link>.</p>
      <table-wrap position="float" id="t003">
        <label>Table 3</label>
        <caption>
          <p>Mean run times of the optical and acoustic forward modules and image reconstruction for simulation pipelines with different parameter combinations in seconds (s). The mean time was calculated from the run times of the pipelines: default, bandpass filter, differential mode, and custom. The times are reported for three different spacings: 0.15, 0.35, and 0.55 mm.</p>
        </caption>
        <!--OASIS TABLE HERE-->
        <table frame="hsides" rules="groups">
          <colgroup>
            <col/>
            <col/>
            <col/>
            <col/>
          </colgroup>
          <thead>
            <tr>
              <th valign="top">Spacing (mm)</th>
              <th valign="top">Optical modeling time (s)</th>
              <th valign="top">Acoustic modeling time (s)</th>
              <th valign="top">Image reconstruction time (s)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>0.55</td>
              <td>1.19</td>
              <td>7.96</td>
              <td>2.22</td>
            </tr>
            <tr>
              <td>0.35</td>
              <td>2.80</td>
              <td>8.28</td>
              <td>2.21</td>
            </tr>
            <tr>
              <td>0.15</td>
              <td>27.77</td>
              <td>11.62</td>
              <td>2.22</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="sec3.3">
      <label>3.3</label>
      <title>Rapid Prototyping with Multiple Pipelines</title>
      <p>SIMPA facilitates simulation of phantom imaging, which is highly relevant for experimental planning and rapid prototyping. To demonstrate this, a pipeline was executed with two commercial PAI systems (MSOT Acuity Echo and the MSOT InVision 256-TF devices, iThera Medical GmbH). For each device, the optical and acoustic forward simulations were executed only once. With the produced time-series data as a result, for each device, two different reconstruction adapters were added to the pipeline to reconstruct the final PA images. Currently, the following reconstruction algorithms are supported: delay-and-sum,<xref rid="r29" ref-type="bibr"><sup>29</sup></xref> delay-multiply-and-sum,<xref rid="r31" ref-type="bibr"><sup>31</sup></xref> signed delay-multiply-and-sum,<xref rid="r72" ref-type="bibr"><sup>72</sup></xref> and time reversal.<xref rid="r73" ref-type="bibr"><sup>73</sup></xref> The results that are shown in <xref rid="f7" ref-type="fig">Fig. 7</xref> are reconstructed with delay-and-sum or time reversal. The overall run time for these simulations was about 320 s with a spacing of 0.15 mm.</p>
      <fig position="float" id="f7">
        <label>Fig. 7</label>
        <caption>
          <p>Demonstration of the versatility of the toolkit. From the same tissue phantom, two initial pressure distributions and time-series data are simulated using completely different PA digital device twin [in this case, the MSOT Acuity Echo and the MSOT InVision 256-TF (iThera Medical GmbH, Munich, Germany)]. The simulated time-series data are then reconstructed using different reconstruction algorithms (time reversal and delay-and-sum), resulting in four distinct simulation results.</p>
        </caption>
        <graphic xlink:href="JBO-027-083010-g007" position="float"/>
      </fig>
      <p>Not only does the user have the ability to easily exchange devices and module adapters in the simulation pipeline but the pipeline can also be designed in such a way that the simulation is executed efficiently. The optical and acoustic forward models had to be simulated only once for each device, and the two image reconstruction algorithms were applied afterward, demonstrating the modularity of SIMPA.</p>
    </sec>
    <sec id="sec3.4">
      <label>3.4</label>
      <title>Generating Diverse Tissue Geometries</title>
      <p>A wide range of <italic>in silico</italic> tissue models can be generated using SIMPA. For this, we specifically showcase tissue structure distributions aligned to different use cases from the literature. <xref rid="f8" ref-type="fig">Figure 8(a)</xref> shows an arrangement of different geometrical shapes such as cuboids and spheres as used by Cox et al.<xref rid="r69" ref-type="bibr"><sup>69</sup></xref> In <xref rid="f8" ref-type="fig">Fig. 8(b)</xref>, a cylindrical phantom with two absorbing inclusions, comparable to the one presented by Hacker et al.,<xref rid="r74" ref-type="bibr"><sup>74</sup></xref> is generated. A volume containing complex vessel trees can easily be generated similar to the human lung vessel dataset acquired from computed tomography used by Bench et al.<xref rid="r14" ref-type="bibr"><sup>14</sup></xref> as shown in <xref rid="f8" ref-type="fig">Fig. 8(c)</xref>. Lastly, realistic tissue models such as a human forearm used by Gröhl et al.<xref rid="r13" ref-type="bibr"><sup>13</sup></xref> are possible by combining the previously mentioned structures, which are shown in <xref rid="f8" ref-type="fig">Fig. 8(d)</xref>. The overall run time for these simulations was about 10 s.</p>
      <fig position="float" id="f8">
        <label>Fig. 8</label>
        <caption>
          <p>Examples of chromophore distributions that can be created using the SIMPA volume generation module. (a) Arbitrarily placed and oriented geometrical structures, i.e., a tube (green), a sphere (blue), a parallelepiped (yellow), and a cuboid (red); (b) a cylindrical phantom (yellow) with two tubular inclusions (red); (c) a vessel tree with high blood oxygen saturation (red) and a vessel tree with lower blood oxygen saturation (blue); and (d) a forearm model including the epidermis (brown), dermis (pink), fat (yellow), vessels (red), and a bone (gray).</p>
        </caption>
        <graphic xlink:href="JBO-027-083010-g008" position="float"/>
      </fig>
    </sec>
    <sec id="sec3.5">
      <label>3.5</label>
      <title>Simulating Realistic Photoacoustic Images</title>
      <p>Being as realistic as possible is key to many applications in which simulated data are needed. Nevertheless, it has been reported multiple times that a domain gap exists between simulated and real PA images.<xref rid="r3" ref-type="bibr"><sup>3</sup></xref><named-content content-type="online"><xref rid="r4" ref-type="bibr"/></named-content><named-content content-type="print"><sup>–</sup></named-content><xref rid="r5" ref-type="bibr"><sup>5</sup></xref><sup>,</sup><xref rid="r14" ref-type="bibr"><sup>14</sup></xref> By its modular nature, SIMPA can be used to simulate PA images with a high degree of realism. To visually demonstrate the capabilities of the current version of SIMPA in this regard, an image of a human forearm was recorded from a volunteer using the MSOT Acuity Echo. The measurement was conducted within a healthy volunteer study that was approved by the ethics committee of the medical faculty of Heidelberg University under reference number S-451/2020, and the study is registered with the German Clinical Trials Register under reference number DRKS00023205. Based on this real image, the model-based, as well as the segmentation-based volume creators were used to synthetically recreate this image with SIMPA to compare the results with the original image (<xref rid="f9" ref-type="fig">Fig. 9</xref>).</p>
      <fig position="float" id="f9">
        <label>Fig. 9</label>
        <caption>
          <p>Comparison of simulations using SIMPA with a real PA image of a human forearm. From left to right, the panels show: (a) the normalized reconstructed PA image of a real human forearm acquired with the MSOT Acuity Echo; (b) a simulated image using SIMPA’s segmentation-based volume creator with a reference segmentation map of (a); and (c) a simulated image using SIMPA’s model-based volume creator. For both volume creators, a digital device twin of the MSOT Acuity Echo was used. For easier comparison, all images were normalized from 0 to 1 in arbitrary units.</p>
        </caption>
        <graphic xlink:href="JBO-027-083010-g009" position="float"/>
      </fig>
      <p>For the segmentation-based volume creator, the original image was manually annotated, and the different classes were assigned tissue properties by trial and error, so the image as a whole looks as close to the original image as possible. Using the model-based volume creator, the volume of the original image was recreated using the basic geometrical structures as described in Sec. <xref rid="sec2.4" ref-type="sec">2.4</xref>. It should be mentioned that the model-based recreation of high-quality images, such as the one depicted in <xref rid="f9" ref-type="fig">Fig. 9</xref>, is relatively time-consuming as it requires substantial manual interaction. To address this resource bottleneck and thus pave the way for the generation of large (training) data sets as required by modern machine learning algorithms, SIMPA also offers the option of generating the simulation volumes from predefined sets of rules (see Sec. <xref rid="sec3.6" ref-type="sec">3.6</xref>). The results show that both of these methods can lead to images that closely resemble the real PA image. The overall run time for these simulations was about 80 s.</p>
    </sec>
    <sec id="sec3.6">
      <label>3.6</label>
      <title>Generating a Diverse Dataset of Photoacoustic Images</title>
      <p>For the training and the generalization ability of a complex deep learning model, a large and diverse dataset is crucial. In PAI, however, a vast amount of real PA images with ground truth annotations for their underlying properties such as optical absorption <italic>in vivo</italic> is not feasible. To remedy this, SIMPA can be used to generate an arbitrarily large dataset of simulated PA images with a degree of realism that can be seen in the previous section. In <xref rid="f10" ref-type="fig">Fig. 10</xref>, 12 diverse PA images were simulated using randomized tissue mimicking settings of SIMPA’s model-based volume creator.</p>
      <fig position="float" id="f10">
        <label>Fig. 10</label>
        <caption>
          <p>Example of a diverse dataset of simulated PA images. With randomized settings of amount, location, size, shape, and blood oxygen saturation of vessels as well as the curvature of the skin, 12 diverse PA images were generated and normalized between 0 and 1 in arbitrary units (a.u.). The spacing of all images was 0.15 mm. For all simulations, a digital device twin of the MSOT Acuity Echo was used.</p>
        </caption>
        <graphic xlink:href="JBO-027-083010-g010" position="float"/>
      </fig>
      <p>These randomized settings allow for controlled distributions of, for example, amount of vessels, vessel locations, skin curvature, and blood oxygen saturations. The overall run time for the generation of these 12 images was about 570 s with a spacing of 0.15 mm. An investigation of adverse programming effects in SIMPA when generating such a dataset can be found in the <ext-link xlink:href="https://doi.org/10.1117/1.JBO.27.8.083010.s01" ext-link-type="uri">Supplementary Material</ext-link>.</p>
    </sec>
  </sec>
  <sec id="sec4">
    <label>4</label>
    <title>Conclusion and Discussion</title>
    <p>In this work, we present SIMPA, an open-source software library that allows for the simulation and image processing of optical and acoustic imaging modalities taking into account user-specific requirements common in the community. Core to the toolkit is its modular design, which allows for a flexible definition of simulation and processing pipelines. To this end, SIMPA defines abstract interfaces for the necessary forward modeling steps that allow for the integration of arbitrary third-party simulation tools in addition to modules already implemented in SIMPA. It already includes interfaces to toolkits that are commonly used in the field, such as MCX<xref rid="r24" ref-type="bibr"><sup>24</sup></xref> and k-Wave,<xref rid="r28" ref-type="bibr"><sup>28</sup></xref> is open-source, and is actively maintained and improved. Furthermore, a strong emphasis has been placed on tissue modeling as the basis for each simulation. SIMPA provides methods and functionalities to generate numerical tissue models that incorporate optical and acoustic tissue properties by means of a dynamic definition of molecular compositions. Using PAI as an example, we show the simulation results for several typical SIMPA use cases. By generating a diverse dataset of PA images, we demonstrate that SIMPA can create simulations with a high degree of flexibility suitable for, e.g., training of deep learning algorithms.</p>
    <p>The images simulated with SIMPA look realistic (<xref rid="f9" ref-type="fig">Fig. 9</xref>); however, because of the vast number of modeling assumptions both within SIMPA and within the used forward models, throughout all forward modeling steps, there remains a domain gap between simulated and experimental measurements. Steps toward increasing the realism of simulated images have already been taken by including various noise models and diverse tissue geometries such as the deformability of structures. This enables horizontal layers to more closely resemble the deformation of skin and vessels can thus also be squeezed analogously to applying pressure with an imaging device. Despite these efforts, computational modeling inaccuracies such as device-specific artifacts or a heterogeneous background with, e.g., varying blood volume fraction and oxygen saturation are not yet included.</p>
    <p>SIMPA’s modular design also facilitates the exchangeability of simulation algorithms without affecting the integrity of the simulation pipeline. Because of the modular design, arbitrary pipeline elements can be added to the simulation. SIMPA provides example scripts to achieve this and comprises an extensive test suite that incorporates unit tests for the code, as well as manual test scripts that can be used to test the integration of forward models. Analysis of over 100 subsequent runs shows that sequential simulations do not affect each other; the detailed results can be found in the <ext-link xlink:href="https://doi.org/10.1117/1.JBO.27.8.083010.s01" ext-link-type="uri">Supplementary Material</ext-link>.</p>
    <p>Decreasing the potential for user error and lowering the barrier to entry for PA simulation is one of the core ideas behind SIMPA; hence, we show here the simulation and customization of specific use cases. SIMPA itself also contains many example scripts and documentation. The SIMPA developers try to ensure high code quality through its software development life-cycle, which includes the presence of tests, as well as internal code reviews before changes are integrated. Using SIMPA lowers the barrier of entry into the field of PA image simulation by taking over many of the researchers’ responsibilities in navigating the respective simulation tools. At the same time, this increased ease of use comes at the cost of a reduced amount of flexibility, as users are limited to the SIMPA interface and do not directly control the third-party tools. Despite the high level of abstraction, there is still room for user errors that can potentially be hard to identify. For support, researchers can open issues in the SIMPA GitHub repository and can also join the SIMPA Slack channel upon request.</p>
    <p>Two major contributions of this work are the model-based volume creator that enables the user to create diverse spatial distributions of tissue properties and the segmentation-based volume creator that loads segmentation masks. The model-based approach includes features such as the simulation of partial volume effects and the rendering of the model in different spacings. Furthermore, it is straightforward to create diverse tissue geometries using random variables during the creation process (see Sec. <xref rid="sec3.6" ref-type="sec">3.6</xref>). SIMPA provides many utility functions that make the model-based volume creator easy to use. Rendering the scene description into a voxelized grid, however, can become computationally expensive for small spacings, and the user is limited by the SIMPA-defined structure primitives (unless they want to implement their own <monospace>Structure</monospace> classes). The segmentation-based approach addresses this issue by featuring great flexibility in the shapes that it can simulate. Moreover, the creation of the voxelized grid is generally much faster. On the negative, the spacing of the simulation is limited to the spacing of the segmentation, which can lead to hard edges and staircase artifacts.</p>
    <p>In addition to the signal simulation steps detailed in this paper, SIMPA also provides postprocessing modules for image processing. SIMPA currently provides two algorithms: (1) an iterative qPAI algorithm, implemented based on the publication of Cox et al. from 2006<xref rid="r69" ref-type="bibr"><sup>69</sup></xref> (cf. Fig. S3 in the <ext-link xlink:href="https://doi.org/10.1117/1.JBO.27.8.083010.s01" ext-link-type="uri">Supplementary Material</ext-link> 4.1), and (2) a linear spectral unmixing algorithm based on singular value decomposition (cf. Fig. S4 in the <ext-link xlink:href="https://doi.org/10.1117/1.JBO.27.8.083010.s01" ext-link-type="uri">Supplementary Material</ext-link> 4.2).</p>
    <p>Future work will include supporting more forward models, such as numerical approximations of the radiative transfer equation for photon transport in biological tissue;<xref rid="r75" ref-type="bibr"><sup>75</sup></xref> supporting other optical imaging modalities such as multi-/hyperspectral diffuse reflectance imaging; the addition of more reconstruction algorithms; the capabilities for ultrasound simulation; and the provision of more digital commercial PA devices from a variety of vendors including distinct artifacts that are introduced by different devices. The IPASC is working on a standardiszed data format for PAI (Ref. <xref rid="r48" ref-type="bibr">48</xref>) and has a digital device definition embedded in its format. They are currently planning to integrate support for their definition of the devices into MCX (available at: <ext-link xlink:href="https://github.com/IPASC/PACFISH/issues/15" ext-link-type="uri">https://github.com/IPASC/PACFISH/issues/15</ext-link>, last visited March 22, 2022). Once this is achieved, we will support arbitrary illumination geometries within SIMPA. Furthermore, the variety of structures that can be used will be increased by including heterogeneous backgrounds that more closely represent the irregularities within tissue as well as larger, more complex, and connected structures that can represent organs or tumors. A great current challenge is the steep increase of needed computational resources, especially RAM and hard drive space, when decreasing the spacing of the computational grid. To this end, optimization strategies will be investigated to minimize the achievable spacing for a given hardware configuration. We only tested SIMPA with NVIDIA GPUs for GPU acceleration, but we plan to support a wider variety of computing platforms in the future. We are currently also working toward an interactive visualisation tool for the data and the addition of a graphical user interface for SIMPA, which could further flatten the learning curve. Other interesting avenues of future work could be the consideration of heterogeneous molecular distributions within the structures or the integration of state-of-the-art deep learning-based processing components or module adapters.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="s01" position="float" content-type="local-data">
      <media xlink:href="JBO_027_083010_SD001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>The authors would like to thank Minu D. Tizabi for proofreading the manuscript. This project received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme through the ERC Starting Grant COMBIOSCOPY under Grant Agreement No. ERC-2015-StG-37960 and through the ERC Consolidator Grant NEURAL SPICING under Grant Agreement No. 101002198.</p>
  </ack>
  <bio id="b1">
    <p><bold>Janek Gröhl</bold> received his PhD from the University of Heidelberg in April 2021. In 2020, he worked as a postdoctoral researcher at the German Cancer Research Center (DKFZ) and he was working as a research associate at the Cancer Research UK Cambridge Institute in 2021. He was awarded the Walter Benjamin Fellowship by the German Research Foundation (DFG) in 2022. He conducts research on data-driven methods for image processing and signal quantification in photoacoustic imaging.</p>
  </bio>
  <bio id="b2">
    <p><bold>Kris K. Dreher</bold> received his MSc degree in physics from the University of Heidelberg in 2020. He is currently pursuing a PhD at the division of Intelligent Medical Systems (IMSY), DKFZ, and does research in deep learning-based domain adaptation methods to tackle the inverse problems of photoacoustic imaging.</p>
  </bio>
  <bio id="b3">
    <p><bold>Melanie Schellenberg</bold> received her MSc degree in physics from the University of Heidelberg in 2019. She is currently pursuing an interdisciplinary PhD in computer science at the division of IMSY, DKFZ, and aiming for quantitative photoacoustic imaging with a learning-to-simulate approach.</p>
  </bio>
  <bio id="b4">
    <p><bold>Tom Rix</bold> received his MRes degree in medical physics and biomedical engineering from the University College London in 2020. He submitted his MSc thesis in applied computer sciences at Heidelberg University in January 2022, where he worked on photoacoustic image synthesis with deep learning for highly realistic photoacoustic image simulations. He is going to pursue a PhD at the Division of IMSY, DKFZ, in quantitative photoacoustic imaging.</p>
  </bio>
  <bio id="b5">
    <p><bold>Niklas Holzwarth</bold> received his MSc degree in physics from the University of Heidelberg in 2020. He is currently pursuing an interdisciplinary PhD in computer science at the division of IMSY, DKFZ investigating a sensorless 3D photoacoustic approach, referred to as “tattoo tomography.”</p>
  </bio>
  <bio id="b6">
    <p><bold>Patricia Vieten</bold> received her BSc degree in physics from Heidelberg University in 2019. She is currently pursuing her MSc degree in physics at the Division of IMSY, DKFZ, and is working on semantic segmentation of multispectral photoacoustic images using deep learning-based methods.</p>
  </bio>
  <bio id="b7">
    <p><bold>Leonardo Ayala</bold> received his MSc degree in physics from Balseiro Institute in 2016, Argentina. He is currently pursuing a PhD at the division of IMSY, DKFZ, and does research in deep learning-based translational biophotonics.</p>
  </bio>
  <bio id="b8">
    <p><bold>Sarah Bohndiek</bold> received her PhD at University College London in 2008 and then worked in both the UK (at Cambridge) and the USA (at Stanford) as a postdoctoral fellow in molecular imaging. Since 2013, she has been a group leader at the University of Cambridge and was appointed as full professor of Biomedical Physics in 2020. She was recently awarded the CRUK Future Leaders in Cancer Research Prize and SPIE Early Career Achievement Award.</p>
  </bio>
  <bio id="b9">
    <p><bold>Alexander Seitel</bold> is a computer scientist currently working as a group lead and deputy head at DKFZ in Heidelberg and holds a doctorate in medical informatics from the University of Heidelberg. His research focusses on computer-assisted interventions and novel imaging methodologies aiming to improve interventional healthcare. In this area, he conducted various international projects at DKFZ and during his two-year postdoctoral fellowship at the University of British Columbia, Vancouver, Canada.</p>
  </bio>
  <bio id="b10">
    <p><bold>Lena Maier-Hein</bold> is a full professor at Heidelberg University (Germany) and division head at the DKFZ. She is managing director of the National Center for Tumor Diseases (NCT) Heidelberg and of the DKFZ Data Science and Digital Oncology cross-topic program. Her research concentrates on machine learning-based biomedical image analysis with a specific focus on surgical data science, computational biophotonics, and validation of machine learning algorithms.</p>
  </bio>
  <notes notes-type="conflict-of-interest">
    <title>Disclosures</title>
    <p>The authors have no conflicts of interest to declare that are relevant to the content of this article.</p>
  </notes>
  <sec id="sec5">
    <title>Code, Data, and Materials Availability</title>
    <p>The experiments conducted in this paper do not require any external data. The latest release of the SIMPA code can be downloaded from GitHub (<ext-link xlink:href="https://github.com/IMSY-DKFZ/simpa" ext-link-type="uri" specific-use="print">https://github.com/IMSY-DKFZ/simpa</ext-link>, last visited 22 March 2022). The code used to generate the results and figures is available in a GitHub repository (<ext-link xlink:href="https://github.com/IMSY-DKFZ/simpa_paper_experiments" ext-link-type="uri" specific-use="print">https://github.com/IMSY-DKFZ/simpa_paper_experiments</ext-link>).</p>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="r1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>R. H.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Review of short-wave infrared spectroscopy and imaging methods for biological tissue characterization</article-title>,” <source>J. Biomed. Opt.</source>
<volume>20</volume>(<issue>3</issue>), <fpage>030901</fpage> (<year>2015</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.20.3.030901</pub-id><pub-id pub-id-type="pmid">25803186</pub-id></mixed-citation>
    </ref>
    <ref id="r2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macé</surname><given-names>E.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Functional ultrasound imaging of the brain</article-title>,” <source>Nat. Methods</source>
<volume>8</volume>(<issue>8</issue>), <fpage>662</fpage>–<lpage>664</lpage> (<year>2011</year>).<issn>1548-7091</issn><pub-id pub-id-type="doi">10.1038/nmeth.1641</pub-id><pub-id pub-id-type="pmid">21725300</pub-id></mixed-citation>
    </ref>
    <ref id="r3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>C.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Review of deep learning for photoacoustic imaging</article-title>,” <source>Photoacoustics</source>
<volume>21</volume>, <fpage>100215</fpage> (<year>2021</year>).<pub-id pub-id-type="doi">10.1016/j.pacs.2020.100215</pub-id><pub-id pub-id-type="pmid">33425679</pub-id></mixed-citation>
    </ref>
    <ref id="r4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauptmann</surname><given-names>A.</given-names></name><name><surname>Cox</surname><given-names>B. T.</given-names></name></person-group>, “<article-title>Deep learning in photoacoustic tomography: current approaches and future directions</article-title>,” <source>J. Biomed. Opt.</source>
<volume>25</volume>(<issue>11</issue>), <fpage>112903</fpage> (<year>2020</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.25.11.112903</pub-id></mixed-citation>
    </ref>
    <ref id="r5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gröhl</surname><given-names>J.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Deep learning for biomedical photoacoustic imaging: a review</article-title>,” <source>Photoacoustics</source>
<volume>22</volume>, <fpage>100241</fpage> (<year>2021</year>).<pub-id pub-id-type="doi">10.1016/j.pacs.2021.100241</pub-id><pub-id pub-id-type="pmid">33717977</pub-id></mixed-citation>
    </ref>
    <ref id="r6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sowers</surname><given-names>T.</given-names></name><name><surname>Yoon</surname><given-names>H.</given-names></name><name><surname>Emelianov</surname><given-names>S.</given-names></name></person-group>, “<article-title>Investigation of light delivery geometries for photoacoustic applications using Monte Carlo simulations with multiple wavelengths, tissue types, and species characteristics</article-title>,” <source>J. Biomed. Opt.</source>
<volume>25</volume>(<issue>1</issue>), <fpage>016005</fpage> (<year>2020</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.25.1.016005</pub-id></mixed-citation>
    </ref>
    <ref id="r7">
      <label>7.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Ayala</surname><given-names>L. A.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Band selection for oxygenation estimation with multispectral/hyperspectral imaging</article-title>,” arXiv:1905.11297v2 (<year>2021</year>).</mixed-citation>
    </ref>
    <ref id="r8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>B.</given-names></name><name><surname>Laufer</surname><given-names>J.</given-names></name><name><surname>Beard</surname><given-names>P.</given-names></name></person-group>, “<article-title>The challenges for quantitative photoacoustic imaging</article-title>,” <source>Proc. SPIE</source>
<volume>7177</volume>, <fpage>717713</fpage> (<year>2009</year>).<pub-id pub-id-type="coden">PSISDG</pub-id><issn>0277-786X</issn><pub-id pub-id-type="doi">10.1117/12.806788</pub-id></mixed-citation>
    </ref>
    <ref id="r9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tzoumas</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Eigenspectra optoacoustic tomography achieves quantitative blood oxygenation imaging deep in tissues</article-title>,” <source>Nat. Commun.</source>
<volume>7</volume>, <fpage>12121</fpage> (<year>2016</year>).<pub-id pub-id-type="coden">NCAOBW</pub-id><issn>2041-1723</issn><pub-id pub-id-type="doi">10.1038/ncomms12121</pub-id><pub-id pub-id-type="pmid">27358000</pub-id></mixed-citation>
    </ref>
    <ref id="r10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirchner</surname><given-names>T.</given-names></name><name><surname>Gröhl</surname><given-names>J.</given-names></name><name><surname>Maier-Hein</surname><given-names>L.</given-names></name></person-group>, “<article-title>Context encoding enables machine learning-based quantitative photoacoustics</article-title>,” <source>J. Biomed. Opt.</source>
<volume>23</volume>(<issue>5</issue>), <fpage>056008</fpage> (<year>2018</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.23.5.056008</pub-id></mixed-citation>
    </ref>
    <ref id="r11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>C.</given-names></name><etal>et al.</etal></person-group>, “<article-title>End-to-end deep neural network for optical inversion in quantitative photoacoustic imaging</article-title>,” <source>Opt. Lett.</source>
<volume>43</volume>(<issue>12</issue>), <fpage>2752</fpage>–<lpage>2755</lpage> (<year>2018</year>).<pub-id pub-id-type="coden">OPLEDP</pub-id><issn>0146-9592</issn><pub-id pub-id-type="doi">10.1364/OL.43.002752</pub-id><pub-id pub-id-type="pmid">29905680</pub-id></mixed-citation>
    </ref>
    <ref id="r12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lan</surname><given-names>H.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Y-net: hybrid deep learning image reconstruction for photoacoustic tomography <italic>in vivo</italic></article-title>,” <source>Photoacoustics</source>
<volume>20</volume>, <fpage>100197</fpage> (<year>2020</year>).<pub-id pub-id-type="doi">10.1016/j.pacs.2020.100197</pub-id><pub-id pub-id-type="pmid">32612929</pub-id></mixed-citation>
    </ref>
    <ref id="r13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gröhl</surname><given-names>J.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Learned spectral decoloring enables photoacoustic oximetry</article-title>,” <source>Sci. Rep.</source>
<volume>11</volume>, <fpage>6565</fpage> (<year>2021</year>).<pub-id pub-id-type="doi">10.1038/s41598-021-83405-8</pub-id><pub-id pub-id-type="pmid">33753769</pub-id></mixed-citation>
    </ref>
    <ref id="r14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bench</surname><given-names>C.</given-names></name><name><surname>Hauptmann</surname><given-names>A.</given-names></name><name><surname>Cox</surname><given-names>B. T.</given-names></name></person-group>, “<article-title>Toward accurate quantitative photoacoustic imaging: learning vascular blood oxygen saturation in three dimensions</article-title>,” <source>J. Biomed. Opt.</source>
<volume>25</volume>(<issue>8</issue>), <fpage>085003</fpage> (<year>2020</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.25.8.085003</pub-id></mixed-citation>
    </ref>
    <ref id="r15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beard</surname><given-names>P.</given-names></name></person-group>, “<article-title>Biomedical photoacoustic imaging</article-title>,” <source>Interface Focus</source>
<volume>1</volume>(<issue>4</issue>), <fpage>602</fpage>–<lpage>631</lpage> (<year>2011</year>).<pub-id pub-id-type="doi">10.1098/rsfs.2011.0028</pub-id><pub-id pub-id-type="pmid">22866233</pub-id></mixed-citation>
    </ref>
    <ref id="r16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Y.</given-names></name><name><surname>Yao</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>L. V.</given-names></name></person-group>, “<article-title>Tutorial on photoacoustic tomography</article-title>,” <source>J. Biomed. Opt.</source>
<volume>21</volume>(<issue>6</issue>), <fpage>061007</fpage> (<year>2016</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.21.6.061007</pub-id></mixed-citation>
    </ref>
    <ref id="r17">
      <label>17.</label>
      <mixed-citation publication-type="thesis"><person-group person-group-type="author"><name><surname>Gröhl</surname><given-names>J.</given-names></name></person-group>, “<article-title>Data-driven quantitative photoacoustic imaging</article-title>,” PhD Thesis, <institution>Heidelberg University</institution> (<year>2021</year>).</mixed-citation>
    </ref>
    <ref id="r18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dogdas</surname><given-names>B.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Digimouse: a 3d whole body mouse atlas from CT and cryosection data</article-title>,” <source>Phys. Med. Biol.</source>
<volume>52</volume>(<issue>3</issue>), <fpage>577</fpage> (<year>2007</year>).<pub-id pub-id-type="coden">PHMBA7</pub-id><issn>0031-9155</issn><pub-id pub-id-type="doi">10.1088/0031-9155/52/3/003</pub-id><pub-id pub-id-type="pmid">17228106</pub-id></mixed-citation>
    </ref>
    <ref id="r19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Realistic three-dimensional optoacoustic tomography imaging trials using the VICTRE breast phantom of FDA (conference presentation)</article-title>,” <source>Proc. SPIE</source>
<volume>11240</volume>, <fpage>112401H</fpage> (<year>2020</year>).<pub-id pub-id-type="coden">PSISDG</pub-id><issn>0277-786X</issn><pub-id pub-id-type="doi">10.1117/12.2552380</pub-id></mixed-citation>
    </ref>
    <ref id="r20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lou</surname><given-names>Y.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Generation of anatomically realistic numerical phantoms for photoacoustic and ultrasonic breast imaging</article-title>,” <source>J. Biomed. Opt.</source>
<volume>22</volume>(<issue>4</issue>), <fpage>041015</fpage> (<year>2017</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.22.4.041015</pub-id></mixed-citation>
    </ref>
    <ref id="r21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iacono</surname><given-names>M. I.</given-names></name><etal>et al.</etal></person-group>, “<article-title>MIDA: a multimodal imaging-based detailed anatomical model of the human head and neck</article-title>,” <source>PLoS One</source>
<volume>10</volume>(<issue>4</issue>), <fpage>e0124126</fpage> (<year>2015</year>).<pub-id pub-id-type="coden">POLNCL</pub-id><issn>1932-6203</issn><pub-id pub-id-type="doi">10.1371/journal.pone.0124126</pub-id><pub-id pub-id-type="pmid">25901747</pub-id></mixed-citation>
    </ref>
    <ref id="r22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Antholzer</surname><given-names>S.</given-names></name><name><surname>Haltmeier</surname><given-names>M.</given-names></name><name><surname>Schwab</surname><given-names>J.</given-names></name></person-group>, “<article-title>Deep learning for photoacoustic tomography from sparse data</article-title>,” <source>Inverse Prob. Sci. Eng.</source>
<volume>27</volume>(<issue>7</issue>), <fpage>987</fpage>–<lpage>1005</lpage> (<year>2019</year>).<pub-id pub-id-type="doi">10.1080/17415977.2018.1518444</pub-id></mixed-citation>
    </ref>
    <ref id="r23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacques</surname><given-names>S. L.</given-names></name></person-group>, “<article-title>Coupling 3D Monte Carlo light transport in optically heterogeneous tissues to photoacoustic signal generation</article-title>,” <source>Photoacoustics</source>
<volume>2</volume>(<issue>4</issue>), <fpage>137</fpage>–<lpage>142</lpage> (<year>2014</year>).<pub-id pub-id-type="doi">10.1016/j.pacs.2014.09.001</pub-id><pub-id pub-id-type="pmid">25426426</pub-id></mixed-citation>
    </ref>
    <ref id="r24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fang</surname><given-names>Q.</given-names></name><name><surname>Boas</surname><given-names>D. A.</given-names></name></person-group>, “<article-title>Monte Carlo simulation of photon migration in 3D turbid media accelerated by graphics processing units</article-title>,” <source>Opt. Express</source>
<volume>17</volume>(<issue>22</issue>), <fpage>20178</fpage>–<lpage>20190</lpage> (<year>2009</year>).<pub-id pub-id-type="coden">OPEXFF</pub-id><issn>1094-4087</issn><pub-id pub-id-type="doi">10.1364/OE.17.020178</pub-id><pub-id pub-id-type="pmid">19997242</pub-id></mixed-citation>
    </ref>
    <ref id="r25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leino</surname><given-names>A. A.</given-names></name><name><surname>Pulkkinen</surname><given-names>A.</given-names></name><name><surname>Tarvainen</surname><given-names>T.</given-names></name></person-group>, “<article-title>ValoMC: a Monte Carlo software and Matlab toolbox for simulating light transport in biological tissue</article-title>,” <source>OSA Continuum</source>
<volume>2</volume>(<issue>3</issue>), <fpage>957</fpage>–<lpage>972</lpage> (<year>2019</year>).<pub-id pub-id-type="doi">10.1364/OSAC.2.000957</pub-id></mixed-citation>
    </ref>
    <ref id="r26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehghani</surname><given-names>H.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Near infrared optical tomography using NIRFAST: algorithm for numerical model and image reconstruction</article-title>,” <source>Commun. Numer. Methods Eng.</source>
<volume>25</volume>(<issue>6</issue>), <fpage>711</fpage>–<lpage>732</lpage> (<year>2009</year>).<pub-id pub-id-type="coden">CANMER</pub-id><issn>0748-8025</issn><pub-id pub-id-type="doi">10.1002/cnm.1162</pub-id></mixed-citation>
    </ref>
    <ref id="r27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schweiger</surname><given-names>M.</given-names></name><name><surname>Arridge</surname><given-names>S. R.</given-names></name></person-group>, “<article-title>The toast++ software suite for forward and inverse modeling in optical tomography</article-title>,” <source>J. Biomed. Opt.</source>
<volume>19</volume>(<issue>4</issue>), <fpage>040801</fpage> (<year>2014</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.19.4.040801</pub-id><pub-id pub-id-type="pmid">24781586</pub-id></mixed-citation>
    </ref>
    <ref id="r28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treeby</surname><given-names>B. E.</given-names></name><name><surname>Cox</surname><given-names>B. T.</given-names></name></person-group>, “<article-title>k-wave: Matlab toolbox for the simulation and reconstruction of photoacoustic wave fields</article-title>,” <source>J. Biomed. Opt.</source>
<volume>15</volume>(<issue>2</issue>), <fpage>021314</fpage> (<year>2010</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.3360308</pub-id><pub-id pub-id-type="pmid">20459236</pub-id></mixed-citation>
    </ref>
    <ref id="r29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>M.</given-names></name><name><surname>Wang</surname><given-names>L. V.</given-names></name></person-group>, “<article-title>Universal back-projection algorithm for photoacoustic computed tomography</article-title>,” <source>Phys. Rev. E</source>
<volume>71</volume>(<issue>1</issue>), <fpage>016706</fpage> (<year>2005</year>).<pub-id pub-id-type="coden">PLEEE8</pub-id><issn>1539-3755</issn><pub-id pub-id-type="doi">10.1103/PhysRevE.71.016706</pub-id></mixed-citation>
    </ref>
    <ref id="r30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Adaptive beamforming for photoacoustic imaging</article-title>,” <source>Opt. Lett.</source>
<volume>33</volume>(<issue>12</issue>), <fpage>1291</fpage>–<lpage>1293</lpage> (<year>2008</year>).<pub-id pub-id-type="coden">OPLEDP</pub-id><issn>0146-9592</issn><pub-id pub-id-type="doi">10.1364/OL.33.001291</pub-id><pub-id pub-id-type="pmid">18552935</pub-id></mixed-citation>
    </ref>
    <ref id="r31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matrone</surname><given-names>G.</given-names></name><etal>et al.</etal></person-group>, “<article-title>The delay multiply and sum beamforming algorithm in ultrasound b-mode medical imaging</article-title>,” <source>IEEE Trans. Med. Imaging</source>
<volume>34</volume>(<issue>4</issue>), <fpage>940</fpage>–<lpage>949</lpage> (<year>2015</year>).<pub-id pub-id-type="coden">ITMID4</pub-id><issn>0278-0062</issn><pub-id pub-id-type="doi">10.1109/TMI.2014.2371235</pub-id><pub-id pub-id-type="pmid">25420256</pub-id></mixed-citation>
    </ref>
    <ref id="r32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grün</surname><given-names>H.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Photoacoustic tomography using a fiber based Fabry-Perot interferometer as an integrating line detector and image reconstruction by model-based time reversal method</article-title>,” <source>Proc. SPIE</source>
<volume>6631</volume>, <fpage>663107</fpage> (<year>2007</year>).<pub-id pub-id-type="coden">PSISDG</pub-id><issn>0277-786X</issn><pub-id pub-id-type="doi">10.1117/12.729475</pub-id></mixed-citation>
    </ref>
    <ref id="r33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauptmann</surname><given-names>A.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Model-based learning for accelerated, limited-view 3-D photoacoustic tomography</article-title>,” <source>IEEE Trans. Med. Imaging</source>
<volume>37</volume>(<issue>6</issue>), <fpage>1382</fpage>–<lpage>1393</lpage> (<year>2018</year>).<pub-id pub-id-type="coden">ITMID4</pub-id><issn>0278-0062</issn><pub-id pub-id-type="doi">10.1109/TMI.2018.2820382</pub-id><pub-id pub-id-type="pmid">29870367</pub-id></mixed-citation>
    </ref>
    <ref id="r34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Y.</given-names></name><name><surname>Feng</surname><given-names>D.</given-names></name><name><surname>Wang</surname><given-names>L. V.</given-names></name></person-group>, “<article-title>Exact frequency-domain reconstruction for thermoacoustic tomography. I. Planar geometry</article-title>,” <source>IEEE Trans. Med. Imaging</source>
<volume>21</volume>(<issue>7</issue>), <fpage>823</fpage>–<lpage>828</lpage> (<year>2002</year>).<pub-id pub-id-type="coden">ITMID4</pub-id><issn>0278-0062</issn><pub-id pub-id-type="doi">10.1109/TMI.2002.801172</pub-id><pub-id pub-id-type="pmid">12374319</pub-id></mixed-citation>
    </ref>
    <ref id="r35">
      <label>35.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaeger</surname><given-names>M.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Fourier reconstruction in optoacoustic imaging using truncated regularized inverse k-space interpolation</article-title>,” <source>Inverse Prob.</source>
<volume>23</volume>(<issue>6</issue>), <fpage>S51</fpage> (<year>2007</year>).<pub-id pub-id-type="coden">INPEEY</pub-id><issn>0266-5611</issn><pub-id pub-id-type="doi">10.1088/0266-5611/23/6/S05</pub-id></mixed-citation>
    </ref>
    <ref id="r36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akhlaghi</surname><given-names>N.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Multidomain computational modeling of photoacoustic imaging: verification, validation, and image quality prediction</article-title>,” <source>J. Biomed. Opt.</source>
<volume>24</volume>(<issue>12</issue>), <fpage>121910</fpage> (<year>2019</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.24.12.121910</pub-id></mixed-citation>
    </ref>
    <ref id="r37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agrawal</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Modeling combined ultrasound and photoacoustic imaging: simulations aiding device development and artificial intelligence</article-title>,” <source>Photoacoustics</source>
<volume>24</volume>, <fpage>100304</fpage> (<year>2021</year>).<pub-id pub-id-type="doi">10.1016/j.pacs.2021.100304</pub-id><pub-id pub-id-type="pmid">34584840</pub-id></mixed-citation>
    </ref>
    <ref id="r38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sowmiya</surname><given-names>C.</given-names></name><name><surname>Thittai</surname><given-names>A. K.</given-names></name></person-group>, “<article-title>Simulation of photoacoustic tomography (PAT) system in comsol and comparison of two popular reconstruction techniques</article-title>,” <source>Proc. SPIE</source>
<volume>10137</volume>, <fpage>101371O</fpage> (<year>2017</year>).<pub-id pub-id-type="coden">PSISDG</pub-id><issn>0277-786X</issn><pub-id pub-id-type="doi">10.1117/12.2254450</pub-id></mixed-citation>
    </ref>
    <ref id="r39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fadden</surname><given-names>C.</given-names></name><name><surname>Kothapalli</surname><given-names>S.-R.</given-names></name></person-group>, “<article-title>A single simulation platform for hybrid photoacoustic and RF-acoustic computed tomography</article-title>,” <source>Appl. Sci.</source>
<volume>8</volume>(<issue>9</issue>), <fpage>1568</fpage> (<year>2018</year>).<pub-id pub-id-type="doi">10.3390/app8091568</pub-id><pub-id pub-id-type="pmid">31304045</pub-id></mixed-citation>
    </ref>
    <ref id="r40">
      <label>40.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bohndiek</surname><given-names>S. E.</given-names></name><etal>et al.</etal></person-group>, “<article-title>IPASC: a community-driven consensus-based initiative towartandardizationion in photoacoustic imaging</article-title>,” in <conf-name>IEEE Int. Ultrason. Symp.</conf-name>, <publisher-name>IEEE</publisher-name>, pp. <fpage>1</fpage>–<lpage>4</lpage> (<year>2020</year>).<pub-id pub-id-type="doi">10.1109/IUS46767.2020.9251362</pub-id></mixed-citation>
    </ref>
    <ref id="r41">
      <label>41.</label>
      <mixed-citation publication-type="webpage">Python Software Foundation, <ext-link xlink:href="http://www.python.org" ext-link-type="uri">http://www.python.org</ext-link>, (accessed 22 March 2022).</mixed-citation>
    </ref>
    <ref id="r42">
      <label>42.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chacon</surname><given-names>S.</given-names></name><name><surname>Straub</surname><given-names>B.</given-names></name></person-group>, <source>Pro Git</source>, <publisher-name>Apress</publisher-name>, <publisher-loc>Berlin, Germany</publisher-loc> (<year>2014</year>).</mixed-citation>
    </ref>
    <ref id="r43">
      <label>43.</label>
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Preston-Werner</surname><given-names>T.</given-names></name></person-group>, Semantic Versioning 2.0.0, <ext-link xlink:href="https://semver.org/" ext-link-type="uri">https://semver.org/</ext-link> (accessed 22 March 2022).</mixed-citation>
    </ref>
    <ref id="r44">
      <label>44.</label>
      <mixed-citation publication-type="webpage">Python Enhancement Proposals, <ext-link xlink:href="https://www.python.org/dev/peps/pep-0008/" ext-link-type="uri">https://www.python.org/dev/peps/pep-0008/</ext-link> (accessed 22 March 2022).</mixed-citation>
    </ref>
    <ref id="r45">
      <label>45.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Folk</surname><given-names>M.</given-names></name><etal>et al.</etal></person-group>, “<article-title>An overview of the HDF5 technology suite and its applications</article-title>,” in <conf-name>Proc. EDBT/ICDT Workshop Array Databases</conf-name>, pp. <fpage>36</fpage>–<lpage>47</lpage> (<year>2011</year>).</mixed-citation>
    </ref>
    <ref id="r46">
      <label>46.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Collette</surname><given-names>A.</given-names></name></person-group>, <source>Python and HDF5</source>, <publisher-name>O’Reilly</publisher-name>, <publisher-loc>Sebastopol, California</publisher-loc> (<year>2013</year>).</mixed-citation>
    </ref>
    <ref id="r47">
      <label>47.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bohndiek</surname><given-names>S.</given-names></name></person-group>, “<article-title>Addressing photoacoustics standards</article-title>,” <source>Nat. Photonics</source>
<volume>13</volume>(<issue>5</issue>), <fpage>298</fpage>–<lpage>298</lpage> (<year>2019</year>).<pub-id pub-id-type="coden">NPAHBY</pub-id><issn>1749-4885</issn><pub-id pub-id-type="doi">10.1038/s41566-019-0417-3</pub-id></mixed-citation>
    </ref>
    <ref id="r48">
      <label>48.</label>
      <mixed-citation publication-type="webpage">International Photoacoustic Standardisation Consortium, <ext-link xlink:href="https://www.ipasc.science/documents/20210916_IPASC_Format_V2.pdf" ext-link-type="uri">https://www.ipasc.science/documents/20210916_IPASC_Format_V2.pdf</ext-link> (accessed 22 March 2022).</mixed-citation>
    </ref>
    <ref id="r49">
      <label>49.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacques</surname><given-names>S. L.</given-names></name></person-group>, “<article-title>Optical properties of biological tissues: a review</article-title>,” <source>Phys. Med. Biol.</source>
<volume>58</volume>(<issue>11</issue>), <fpage>R37</fpage> (<year>2013</year>).<pub-id pub-id-type="coden">PHMBA7</pub-id><issn>0031-9155</issn><pub-id pub-id-type="doi">10.1088/0031-9155/58/11/R37</pub-id><pub-id pub-id-type="pmid">23666068</pub-id></mixed-citation>
    </ref>
    <ref id="r50">
      <label>50.</label>
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Prahl</surname><given-names>S.</given-names></name><name><surname>Jacques</surname><given-names>S.</given-names></name></person-group>, <ext-link xlink:href="https://omlc.org/" ext-link-type="uri">https://omlc.org/</ext-link> (accessed 22 March 2022).</mixed-citation>
    </ref>
    <ref id="r51">
      <label>51.</label>
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Hasgall</surname><given-names>P.</given-names></name><etal>et al.</etal></person-group>, “<article-title>IT’IS database for thermal and electromagnetic parameters of biological tissues</article-title>,” Version 4.0, May 15, 2018. doi: 10.13099/VIP21000-04-0, <ext-link xlink:href="www.itis.ethz.ch/database" ext-link-type="uri">www.itis.ethz.ch/database</ext-link>.</mixed-citation>
    </ref>
    <ref id="r52">
      <label>52.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kedenburg</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Linear refractive index and absorption measurements of nonlinear optical liquids in the visible and near-infrared spectral region</article-title>,” <source>Opt. Mater. Express</source>
<volume>2</volume>, <fpage>1588</fpage>–<lpage>1611</lpage> (<year>2012</year>).<pub-id pub-id-type="doi">10.1364/OME.2.001588</pub-id></mixed-citation>
    </ref>
    <ref id="r53">
      <label>53.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Hu</surname><given-names>L.</given-names></name><name><surname>He</surname><given-names>M.-X.</given-names></name></person-group>, “<article-title>Scattering by pure seawater: effect of salinity</article-title>,” <source>Opt. Express</source>
<volume>17</volume>, <fpage>5698</fpage>–<lpage>5710</lpage> (<year>2009</year>).<pub-id pub-id-type="coden">OPEXFF</pub-id><issn>1094-4087</issn><pub-id pub-id-type="doi">10.1364/OE.17.005698</pub-id><pub-id pub-id-type="pmid">19333338</pub-id></mixed-citation>
    </ref>
    <ref id="r54">
      <label>54.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Antunes</surname><given-names>A.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Optical properties on bone analysis: an approach to biomaterials</article-title>,” <source>Proceedings</source>
<volume>27</volume>(<issue>1</issue>), <fpage>36</fpage> (<year>2019</year>).<pub-id pub-id-type="doi">10.3390/proceedings2019027036</pub-id></mixed-citation>
    </ref>
    <ref id="r55">
      <label>55.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bashkatov</surname><given-names>A. N.</given-names></name><name><surname>Genina</surname><given-names>E. A.</given-names></name><name><surname>Tuchin</surname><given-names>V. V.</given-names></name></person-group>, “<article-title>Optical properties of skin, subcutaneous, and muscle tissues: a review</article-title>,” <source>J. Innovative Opt. Health Sci.</source>
<volume>4</volume>(<issue>01</issue>), <fpage>9</fpage>–<lpage>38</lpage> (<year>2011</year>).<pub-id pub-id-type="doi">10.1142/S1793545811001319</pub-id></mixed-citation>
    </ref>
    <ref id="r56">
      <label>56.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alaluf</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Ethnic variation in melanin content and composition in photoexposed and photoprotected human skin</article-title>,” <source>Pigment Cell Res.</source>
<volume>15</volume>(<issue>2</issue>), <fpage>112</fpage>–<lpage>118</lpage> (<year>2002</year>).<pub-id pub-id-type="coden">PCREEA</pub-id><issn>0893-5785</issn><pub-id pub-id-type="doi">10.1034/j.1600-0749.2002.1o071.x</pub-id><pub-id pub-id-type="pmid">11936268</pub-id></mixed-citation>
    </ref>
    <ref id="r57">
      <label>57.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Timmins</surname><given-names>P.</given-names></name><name><surname>Wall</surname><given-names>J.</given-names></name></person-group>, “<article-title>Bone water</article-title>,” <source>Calcified Tissue Res.</source>
<volume>23</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>5</lpage> (<year>1977</year>).<pub-id pub-id-type="coden">CATRBZ</pub-id><issn>0008-0594</issn><pub-id pub-id-type="doi">10.1007/BF02012759</pub-id></mixed-citation>
    </ref>
    <ref id="r58">
      <label>58.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Forbes</surname><given-names>R.</given-names></name><etal>et al.</etal></person-group>, “<article-title>The composition of the adult human body as determined by chemical analysis</article-title>,” <source>J. Biol. Chem.</source>
<volume>203</volume>(<issue>1</issue>), <fpage>359</fpage>–<lpage>366</lpage> (<year>1953</year>).<pub-id pub-id-type="doi">10.1016/S0021-9258(19)52646-1</pub-id><pub-id pub-id-type="pmid">13069519</pub-id></mixed-citation>
    </ref>
    <ref id="r59">
      <label>59.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Molnar</surname><given-names>Z.</given-names></name><name><surname>Nemeth</surname><given-names>M.</given-names></name></person-group>, “<article-title>Monitoring of tissue oxygenation: an everyday clinical challenge</article-title>,” <source>Front. Med.</source>
<volume>4</volume>, <fpage>247</fpage> (<year>2018</year>).<pub-id pub-id-type="doi">10.3389/fmed.2017.00247</pub-id></mixed-citation>
    </ref>
    <ref id="r60">
      <label>60.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merrick</surname><given-names>E. B.</given-names></name><name><surname>Hayes</surname><given-names>T. J.</given-names></name></person-group>, “<article-title>Continuous, non-invasive measurements of arterial blood oxygen levels</article-title>,” <source>Hewlett-Packard J.</source>
<volume>28</volume>(<issue>2</issue>), <fpage>2</fpage>–<lpage>9</lpage> (<year>1976</year>).<pub-id pub-id-type="coden">HPJOAX</pub-id><issn>0018-</issn><issn>1153</issn></mixed-citation>
    </ref>
    <ref id="r61">
      <label>61.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>G.</given-names></name><name><surname>Chung</surname><given-names>K. C.</given-names></name></person-group>, “<article-title>Ulnar artery to superficial arch bypass with a vein graft</article-title>,” in <source>Operative Techniques: Hand and Wrist Surgery</source>, <person-group person-group-type="editor"><name><surname>Chung</surname><given-names>K. C.</given-names></name></person-group>, Ed., pp. <fpage>732</fpage>–<lpage>737</lpage>, <publisher-name>Elsevier Health Sciences</publisher-name>, <publisher-loc>Amsterdam, Netherlands</publisher-loc> (<year>2018</year>).</mixed-citation>
    </ref>
    <ref id="r62">
      <label>62.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubmer</surname><given-names>M. G.</given-names></name><etal>et al.</etal></person-group>, “<article-title>The posterior interosseous artery in the distal part of the forearm. Is the term ‘recurrent branch of the anterior interosseous artery’justified?</article-title>” <source>Br. J. Plast. Surg.</source>
<volume>57</volume>(<issue>7</issue>), <fpage>638</fpage>–<lpage>644</lpage> (<year>2004</year>).<pub-id pub-id-type="coden">BJPSAZ</pub-id><issn>0007-1226</issn><pub-id pub-id-type="doi">10.1016/j.bjps.2004.06.011</pub-id><pub-id pub-id-type="pmid">15380697</pub-id></mixed-citation>
    </ref>
    <ref id="r63">
      <label>63.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oltulu</surname><given-names>P.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Measurement of epidermis, dermis, and total skin thicknesses from six different body regions with a new ethical histometric technique</article-title>,” <source>Turkish J. Plast. Surg.</source>
<volume>26</volume>(<issue>2</issue>), <fpage>56</fpage> (<year>2018</year>).<pub-id pub-id-type="doi">10.4103/tjps.TJPS_2_17</pub-id></mixed-citation>
    </ref>
    <ref id="r64">
      <label>64.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christensen</surname><given-names>J. B.</given-names></name><etal>et al.</etal></person-group>, “<article-title>A study of the interosseous distance between the radius and ulna during rotation of the forearm</article-title>,” <source>Anat. Rec.</source>
<volume>160</volume>(<issue>2</issue>), <fpage>261</fpage>–<lpage>271</lpage> (<year>1968</year>).<pub-id pub-id-type="coden">ANREAK</pub-id><issn>0003-276X</issn><pub-id pub-id-type="doi">10.1002/ar.1091600212</pub-id><pub-id pub-id-type="pmid">5651673</pub-id></mixed-citation>
    </ref>
    <ref id="r65">
      <label>65.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goh</surname><given-names>C.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Subcutaneous veins depth measurement using diffuse reflectance images</article-title>,” <source>Opt. Express</source>
<volume>25</volume>(<issue>21</issue>), <fpage>25741</fpage>–<lpage>25759</lpage> (<year>2017</year>).<pub-id pub-id-type="coden">OPEXFF</pub-id><issn>1094-4087</issn><pub-id pub-id-type="doi">10.1364/OE.25.025741</pub-id><pub-id pub-id-type="pmid">29041239</pub-id></mixed-citation>
    </ref>
    <ref id="r66">
      <label>66.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galarreta-Valverde</surname><given-names>M. A.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Three-dimensional synthetic blood vessel generation using stochastic l-systems</article-title>,” <source>Proc. SPIE</source>
<volume>8669</volume>, <fpage>86691I</fpage> (<year>2013</year>).<pub-id pub-id-type="coden">PSISDG</pub-id><issn>0277-786X</issn><pub-id pub-id-type="doi">10.1117/12.2007532</pub-id></mixed-citation>
    </ref>
    <ref id="r67">
      <label>67.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rubinstein</surname><given-names>R. Y.</given-names></name><name><surname>Kroese</surname><given-names>D. P.</given-names></name></person-group>, <source>Simulation and the Monte Carlo Method</source>, <publisher-name>John Wiley &amp; Sons</publisher-name>, <publisher-loc>Hoboken, New Jersey</publisher-loc> (<year>2016</year>).</mixed-citation>
    </ref>
    <ref id="r68">
      <label>68.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treeby</surname><given-names>B. E.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Modeling nonlinear ultrasound propagation in heterogeneous media with power law absorption using AK-space pseudospectral method</article-title>,” <source>J. Acoust. Soc. Am.</source>
<volume>131</volume>(<issue>6</issue>), <fpage>4324</fpage>–<lpage>4336</lpage> (<year>2012</year>).<pub-id pub-id-type="doi">10.1121/1.4712021</pub-id><pub-id pub-id-type="pmid">22712907</pub-id></mixed-citation>
    </ref>
    <ref id="r69">
      <label>69.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>B. T.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Two-dimensional quantitative photoacoustic image reconstruction of absorption distributions in scattering media by use of a simple iterative method</article-title>,” <source>Appl. Opt.</source>
<volume>45</volume>, <fpage>1866</fpage>–<lpage>1875</lpage> (<year>2006</year>).<pub-id pub-id-type="coden">APOPAI</pub-id><issn>0003-6935</issn><pub-id pub-id-type="doi">10.1364/AO.45.001866</pub-id><pub-id pub-id-type="pmid">16572706</pub-id></mixed-citation>
    </ref>
    <ref id="r70">
      <label>70.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keshava</surname><given-names>N.</given-names></name><name><surname>Mustard</surname><given-names>J. F.</given-names></name></person-group>, “<article-title>Spectral unmixing</article-title>,” <source>IEEE Signal Process. Mag.</source>
<volume>19</volume>(<issue>1</issue>), <fpage>44</fpage>–<lpage>57</lpage> (<year>2002</year>).<pub-id pub-id-type="coden">ISPRE6</pub-id><issn>1053-5888</issn><pub-id pub-id-type="doi">10.1109/79.974727</pub-id></mixed-citation>
    </ref>
    <ref id="r71">
      <label>71.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Tukey</surname><given-names>J. W.</given-names></name></person-group>, “<article-title>An introduction to the calculation of numerical spectrum analysis</article-title>,” Spectra Analysis of Time Series, pp. <fpage>25</fpage>–<lpage>46</lpage> (<year>1967</year>).</mixed-citation>
    </ref>
    <ref id="r72">
      <label>72.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirchner</surname><given-names>T.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Signed real-time delay multiply and sum beamforming for multispectral photoacoustic imaging</article-title>,” <source>J. Imaging</source>
<volume>4</volume>(<issue>10</issue>), <fpage>121</fpage> (<year>2018</year>).<pub-id pub-id-type="doi">10.3390/jimaging4100121</pub-id></mixed-citation>
    </ref>
    <ref id="r73">
      <label>73.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treeby</surname><given-names>B. E.</given-names></name><name><surname>Zhang</surname><given-names>E. Z.</given-names></name><name><surname>Cox</surname><given-names>B. T.</given-names></name></person-group>, “<article-title>Photoacoustic tomography in absorbing acoustic media using time reversal</article-title>,” <source>Inverse Prob.</source>
<volume>26</volume>(<issue>11</issue>), <fpage>115003</fpage> (<year>2010</year>).<pub-id pub-id-type="coden">INPEEY</pub-id><issn>0266-5611</issn><pub-id pub-id-type="doi">10.1088/0266-5611/26/11/115003</pub-id></mixed-citation>
    </ref>
    <ref id="r74">
      <label>74.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hacker</surname><given-names>L.</given-names></name><etal>et al.</etal></person-group>, “<article-title>A copolymer-in-oil tissue-mimicking material with tuneable acoustic and optical characteristics for photoacoustic imaging phantoms</article-title>,” <source>IEEE Trans. Med. Imaging</source>
<volume>40</volume>(<issue>12</issue>), <fpage>3593</fpage>–<lpage>3603</lpage> (<year>2021</year>).<pub-id pub-id-type="coden">ITMID4</pub-id><issn>0278-0062</issn><pub-id pub-id-type="doi">10.1109/TMI.2021.3090857</pub-id><pub-id pub-id-type="pmid">34152979</pub-id></mixed-citation>
    </ref>
    <ref id="r75">
      <label>75.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tarvainen</surname><given-names>T.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Utilising the radiative transfer equation in quantitative photoacoustic tomography</article-title>,” <source>Proc. SPIE</source>
<volume>10064</volume>, <fpage>100643E</fpage> (<year>2017</year>).<pub-id pub-id-type="coden">PSISDG</pub-id><issn>0277-786X</issn><pub-id pub-id-type="doi">10.1117/12.2249310</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
