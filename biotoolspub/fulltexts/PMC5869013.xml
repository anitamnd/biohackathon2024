<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with OASIS Tables with MathML3 v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-archive-oasis-article1-mathml3.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jpoasis-nisons2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Comput Psychiatr</journal-id>
    <journal-id journal-id-type="iso-abbrev">Comput Psychiatr</journal-id>
    <journal-id journal-id-type="publisher-id">cpsy</journal-id>
    <journal-title-group>
      <journal-title>Computational Psychiatry (Cambridge, Mass.)</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2379-6227</issn>
    <publisher>
      <publisher-name>MIT Press</publisher-name>
      <publisher-loc>One Rogers Street, Cambridge, MA 02142-1209USAjournals-info@mit.edu</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">5869013</article-id>
    <article-id pub-id-type="publisher-id">CPSY_a_00002</article-id>
    <article-id pub-id-type="doi">10.1162/CPSY_a_00002</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Revealing Neurocomputational Mechanisms of Reinforcement Learning and Decision-Making With the hBayesDM Package</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Ahn</surname>
          <given-names>Woo-Young</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Haines</surname>
          <given-names>Nathaniel</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Lei</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
      </contrib>
      <aff id="aff1"><label>1</label>Department of Psychology, The Ohio State University, Columbus, OH</aff>
      <aff id="aff2"><label>2</label>Institute for Systems Neuroscience, University Medical Center Hamburg-Eppendorf, Hamburg, Germany</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p>Competing Interests: The author declares no conflict of interest</p>
      </fn>
      <corresp id="cor1"><label>*</label>Corresponding author: <email xlink:href="mailto:wooyoung.ahn@gmail.com">wooyoung.ahn@gmail.com</email>.</corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>01</day>
      <month>10</month>
      <year>2017</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>10</month>
      <year>2017</year>
    </pub-date>
    <volume>1</volume>
    <fpage>24</fpage>
    <lpage>57</lpage>
    <history>
      <date date-type="received">
        <day>20</day>
        <month>7</month>
        <year>2016</year>
      </date>
      <date date-type="accepted">
        <day>06</day>
        <month>3</month>
        <year>2017</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2017 Massachusetts Institute of Technology Published under a Creative Commons Attribution 4.0 International (CC BY 4.0) license</copyright-statement>
      <copyright-year>2017</copyright-year>
      <copyright-holder>Massachusetts Institute of Technology</copyright-holder>
      <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/3.0/">
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="cpsy-01-24.pdf"/>
    <abstract>
      <p>Reinforcement learning and decision-making (RLDM) provide a quantitative framework and computational theories with which we can disentangle psychiatric conditions into the basic dimensions of neurocognitive functioning. RLDM offer a novel approach to assessing and potentially diagnosing psychiatric patients, and there is growing enthusiasm for both RLDM and computational psychiatry among clinical researchers. Such a framework can also provide insights into the brain substrates of particular RLDM processes, as exemplified by model-based analysis of data from functional magnetic resonance imaging (fMRI) or electroencephalography (EEG). However, researchers often find the approach too technical and have difficulty adopting it for their research. Thus, a critical need remains to develop a user-friendly tool for the wide dissemination of computational psychiatric methods. We introduce an R package called hBayesDM (<underline>h</underline>ierarchical <underline>Bayes</underline>ian modeling of <underline>D</underline>ecision-<underline>M</underline>aking tasks), which offers computational modeling of an array of RLDM tasks and social exchange games. The hBayesDM package offers state-of-the-art hierarchical Bayesian modeling, in which both individual and group parameters (i.e., posterior distributions) are estimated simultaneously in a mutually constraining fashion. At the same time, the package is extremely user-friendly: users can perform computational modeling, output visualization, and Bayesian model comparisons, each with a single line of coding. Users can also extract the trial-by-trial latent variables (e.g., prediction errors) required for model-based fMRI/EEG. With the hBayesDM package, we anticipate that anyone with minimal knowledge of programming can take advantage of cutting-edge computational-modeling approaches to investigate the underlying processes of and interactions between multiple decision-making (e.g., goal-directed, habitual, and Pavlovian) systems. In this way, we expect that the hBayesDM package will contribute to the dissemination of advanced modeling approaches and enable a wide range of researchers to easily perform computational psychiatric research within different populations.</p>
    </abstract>
    <kwd-group kwd-group-type="text">
      <title>Keywords</title>
      <kwd>reinforcement learning</kwd>
      <x xml:space="preserve">, </x>
      <kwd>decision-making</kwd>
      <x xml:space="preserve">, </x>
      <kwd>hierarchical Bayesian modeling</kwd>
      <x xml:space="preserve">, </x>
      <kwd>model-based fMRI</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution>German Research Foundation</institution>
            <institution-id institution-id-type="FundRef"/>
          </institution-wrap>
        </funding-source>
        <award-id>DFG GRK 1247</award-id>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution>Bernstein Computational Neuroscience Program of the German Federal Ministry of Education and Research</institution>
            <institution-id institution-id-type="FundRef"/>
          </institution-wrap>
        </funding-source>
        <award-id>BMBF Grant 01GQ1006</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>citation</meta-name>
        <meta-value>Ahn, W.-Y., Haines, N., &amp; Zhang, L. (2017). Revealing neurocomputational mechanisms of reinforcement learning and decision-making with the hBayesDM package. <italic>Computational Psychiatry</italic>, <italic>1</italic>, 24–57. <ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1162/cpsy_a_00002">https://doi.org/10.1162/cpsy_a_00002</ext-link></meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec>
    <title>INTRODUCTION</title>
    <p><italic>Computational modeling</italic> (a.k.a. <italic>cognitive modeling</italic>) describes human information processing in terms of basic principles of cognition, which are defined in formal mathematical notation (<xref ref-type="fig" rid="F1">Figure 1</xref>). Unlike verbalized or conceptualized approaches, computational modeling has the merit of allowing researchers to generate precise predictions and quantitatively test competing hypotheses (Busemeyer &amp; Diederich, <xref rid="bib19" ref-type="bibr">2010</xref>; Forstmann &amp; Wagenmakers, <xref rid="bib38" ref-type="bibr">2015</xref>; Lewandowsky &amp; Farrell, <xref rid="bib72" ref-type="bibr">2010</xref>). Computational modeling has been particularly useful in the reinforcement-learning and decision-making (RLDM) fields (Dayan &amp; Daw, <xref rid="bib31" ref-type="bibr">2008</xref>; Rangel, Camerer, &amp; Montague, <xref rid="bib92" ref-type="bibr">2008</xref>); it has also been integrated into the analysis of neural data, including data from functional magnetic resonance imaging (fMRI) and electroencephalography (EEG) (e.g., (Cavanagh, Eisenberg, Guitart-Masip, Huys, &amp; Frank, <xref rid="bib23" ref-type="bibr">2013</xref>; Daw, O’Doherty, Dayan, Seymour, &amp; Dolan, <xref rid="bib30" ref-type="bibr">2006</xref>; Gläscher, Hampton, &amp; O’Doherty, <xref rid="bib45" ref-type="bibr">2009</xref>; Hampton, Bossaerts, &amp; O’Doherty, <xref rid="bib52" ref-type="bibr">2006</xref>; Iglesias et al., <xref rid="bib60" ref-type="bibr">2013</xref>; Li, Schiller, Schoenbaum, Phelps, &amp; Daw, <xref rid="bib73" ref-type="bibr">2011</xref>; Mars et al., <xref rid="bib78" ref-type="bibr">2008</xref>; O’Doherty et al., <xref rid="bib87" ref-type="bibr">2004</xref>; O’Doherty, Hampton, &amp; Kim, <xref rid="bib88" ref-type="bibr">2007</xref>; Xiang, Lohrenz, &amp; Montague, <xref rid="bib123" ref-type="bibr">2013</xref>).</p>
    <fig id="F1" orientation="portrait" position="float">
      <label><bold>Figure 1.</bold> </label>
      <caption>
        <p><bold>Conceptual schema of computational modeling.</bold> Starting with a certain RLDM paradigm, the left pathway (yellow arrows) represents that the human brain produces behavioral responses (forward model) that we observe and measure. These observed outcomes can be used to make inferences about cognitive mechanisms (model inversion), but oftentimes this is difficult to achieve. One solution is to build cognitive models (green arrows) that produce predictions (forward model) and can also be inferred on the basis of those predictions (model inversion). As such, we are able to approximate brain mechanisms (dashed red line) by directly linking the model predictions (e.g., reward prediction error) with the observed outcomes (solid red line).</p>
      </caption>
      <graphic xlink:href="cpsy-01-24-g001"/>
    </fig>
    <p>As has been summarized in recent review articles (Ahn &amp; Busemeyer, <xref rid="bib2" ref-type="bibr">2016</xref>; Friston, Stephan, Montague, &amp; Dolan, <xref rid="bib40" ref-type="bibr">2014</xref>; Huys, Maia, &amp; Frank, <xref rid="bib59" ref-type="bibr">2016</xref>; Montague, Dolan, Friston, &amp; Dayan, <xref rid="bib81" ref-type="bibr">2012</xref>; Stephan, Bach, et al., <xref rid="bib106" ref-type="bibr">2016</xref>; Stephan, Binder, et al., <xref rid="bib107" ref-type="bibr">2016</xref>; Stephan, Iglesias, Heinzle, &amp; Diaconescu, <xref rid="bib108" ref-type="bibr">2015</xref>; Wang &amp; Krystal, <xref rid="bib118" ref-type="bibr">2014</xref>; Wiecki, Poland, &amp; Frank, <xref rid="bib120" ref-type="bibr">2015</xref>), computational modeling has gained much attention for its usefulness in investigating psychiatric conditions. Exemplified by the Research Domain Criteria (RDoC; Insel, <xref rid="bib61" ref-type="bibr">2014</xref>) and precision medicine, a growing consensus is advocating that diagnosis and treatment decisions incorporate the underlying cognitive and neurobiological underpinnings of psychiatric conditions, instead of relying only on behavioral symptoms. Toward this end, a new field, called <italic>computational psychiatry</italic> (e.g., Friston et al., <xref rid="bib40" ref-type="bibr">2014</xref>; Montague et al., <xref rid="bib81" ref-type="bibr">2012</xref>), aims to discover the neurocognitive mechanisms underlying normal and abnormal conditions by combining cutting-edge neurobiological and computational tools.</p>
    <p>Performing computational psychiatric research, however—especially computational modeling—is a challenging task for many clinical researchers or those with limited quantitative skills. Computational modeling involves multiple steps, including designing/ adopting laboratory tasks, building a theoretical framework of the task in terms of a set of assumptions and mathematical equations, formulating multiple computational models based on the assumptions, estimating the parameters of each model, and quantitatively comparing the models of interest (e.g., Busemeyer &amp; Diederich, <xref rid="bib19" ref-type="bibr">2010</xref>; Wiecki et al., <xref rid="bib120" ref-type="bibr">2015</xref>). Thus, a pressing issue is how to train clinical researchers in mental health (e.g., psychiatrists and clinical psychologists) so that they can receive in-depth training across several related fields, including cognitive science, advanced statistics, and neuroscience (Montague et al., <xref rid="bib81" ref-type="bibr">2012</xref>). For the dissemination of computational psychiatry, we believe that a critical need to develop user-friendly tools for computational modeling still remains. In fact, several software packages for this purpose do exist, but most of them focus on only a single class of modeling, such as sequential-sampling models (Matzke et al., <xref rid="bib79" ref-type="bibr">2013</xref>; Singmann et al., <xref rid="bib100" ref-type="bibr">2016</xref>; Vincent, <xref rid="bib114" ref-type="bibr">2016</xref>; Wabersich &amp; Vandekerckhove, <xref rid="bib115" ref-type="bibr">2014</xref>; Wiecki, Sofer, &amp; Frank, <xref rid="bib121" ref-type="bibr">2013</xref>). An exception is the Variational Bayesian Analysis (VBA) MATLAB toolbox (Daunizeau, Adam, &amp; Rigoux, <xref rid="bib29" ref-type="bibr">2014</xref>), which allows users to fit and compare various models using variational Bayesian algorithms. However, we believe users will still need some amount of programming skill and a background in computational modeling in order to model various tasks with the VBA toolbox.</p>
    <p>In this article, we describe a free R package, <italic>hBayesDM</italic> (for “<underline>h</underline>ierarchical <underline>Bayes</underline>ian modeling of <underline>D</underline>ecision-<underline>M</underline>aking tasks”), which we developed for the dissemination of computational modeling to a wide range of researchers. The hBayesDM package offers hierarchical Bayesian analysis (HBA; see the Mathematical Formulation of Hierarchical Bayesian Models section for more details) of various computational models for an array of decision-making tasks (see <xref ref-type="table" rid="T1">Table 1</xref> for a list of the tasks and models currently available). With the user-friendly hBayesDM package, users can perform model fitting with HBA, output visualization, and model comparisons—<italic>each with a single line of coding</italic>. Example datasets are also available to make it easy to use hBayesDM. With the package, users can extract the trial-by-trial latent vari ables (e.g., prediction errors) that are required for model-based fMRI/EEG (see the Extracting Trial-by-Trial Regressors for Model-Based fMRI/EEG Analysis section). Experienced users can even develop new models based on our framework and codes. All source codes are publically available at our GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/ccs-lab/hBayesDM">https://github.com/ccs-lab/hBayesDM</ext-link>). Users also can post questions to our mailing list (<ext-link ext-link-type="uri" xlink:href="https://groups.google.com/forum/#!forum/hbayesdm-users">https://groups.google.com/forum/#!forum/hbayesdm-users</ext-link>) or make suggestions by posting new issues to the GitHub repository. By making all steps for computational modeling user-friendly, we hope the hBayesDM package will allow even researchers with minimal programming knowledge to perform computational psychiatric research.</p>
    <table-wrap id="T1" orientation="portrait" position="float">
      <label><bold>Table 1.</bold> </label>
      <caption>
        <p>List of the tasks and models currently (as of version 0.3.0) implemented in the hBayesDM package</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr valign="bottom">
            <th align="left" rowspan="1" colspan="1">
              <bold>Task (Alpha Order) as of Version 0.3.0</bold>
            </th>
            <th align="left" rowspan="1" colspan="1">
              <bold>Required Columns in the Data File</bold>
            </th>
            <th align="left" rowspan="1" colspan="1">
              <bold>Model Names</bold>
            </th>
            <th align="left" rowspan="1" colspan="1">
              <bold>hBayesDM Functions</bold>
            </th>
            <th align="center" rowspan="1" colspan="1">
              <bold>Numbers of Parameters (per Subject)</bold>
            </th>
            <th align="left" rowspan="1" colspan="1">
              <bold>References</bold>
            </th>
          </tr>
        </thead>
        <tbody>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1">Delay discounting</td>
            <td align="left" rowspan="1" colspan="1"><bold>subjID</bold>: subject identifier</td>
            <td align="left" rowspan="1" colspan="1">Constant-sensitivity</td>
            <td align="left" rowspan="1" colspan="1">dd_cs</td>
            <td align="center" rowspan="1" colspan="1">3</td>
            <td align="left" rowspan="1" colspan="1">Ebert &amp; Prelec (<xref rid="bib34" ref-type="bibr">2007</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>delay_later</bold>: time delay of</td>
            <td align="left" rowspan="1" colspan="1">Exponential</td>
            <td align="left" rowspan="1" colspan="1">dd_exp</td>
            <td align="center" rowspan="1" colspan="1">2</td>
            <td align="left" rowspan="1" colspan="1">Samuelson (<xref rid="bib96" ref-type="bibr">1937</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">later option</td>
            <td align="left" rowspan="1" colspan="1">Hyperbolic</td>
            <td align="left" rowspan="1" colspan="1">dd_hyperbolic</td>
            <td align="center" rowspan="1" colspan="1">2</td>
            <td align="left" rowspan="1" colspan="1">Mazur (<xref rid="bib80" ref-type="bibr">1987</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>amount_later:</bold> amount of</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">later option</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>delay_sooner:</bold> time delay of</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">sooner option</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>amount_later:</bold> amount of</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">sooner option</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>choice:</bold> chosen option</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1">Iowa gambling</td>
            <td align="left" rowspan="1" colspan="1"><bold>subjID:</bold> subject identifier</td>
            <td align="left" rowspan="1" colspan="1">Prospect valence</td>
            <td align="left" rowspan="1" colspan="1">igt_pvl_decay</td>
            <td align="center" rowspan="1" colspan="1">4</td>
            <td align="left" rowspan="1" colspan="1">Ahn et al. (<xref rid="bib8" ref-type="bibr">2014</xref>),</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>choice:</bold> chosen deck</td>
            <td align="left" rowspan="1" colspan="1">learning-DecayRI</td>
            <td align="left" rowspan="1" colspan="1">igt_pvl_delta</td>
            <td align="center" rowspan="1" colspan="1">4</td>
            <td align="left" rowspan="1" colspan="1">Ahn et al. <xref rid="bib4" ref-type="bibr">2011</xref></td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">(= 1, 2, 3, or 4)</td>
            <td align="left" rowspan="1" colspan="1">Prospect valence</td>
            <td align="left" rowspan="1" colspan="1">igt_vpp</td>
            <td align="center" rowspan="1" colspan="1">7</td>
            <td align="left" rowspan="1" colspan="1">Ahn et al. (<xref rid="bib3" ref-type="bibr">2008</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>gain:</bold> amount gained</td>
            <td align="left" rowspan="1" colspan="1">learning-Delta</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">Worthy, Pang, &amp; Byrne (<xref rid="bib122" ref-type="bibr">2013</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">on each trial</td>
            <td align="left" rowspan="1" colspan="1">Value-plus-</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>loss:</bold> amount lost on</td>
            <td align="left" rowspan="1" colspan="1">perseverance</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">each trial</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1">Orthogonalized</td>
            <td align="left" rowspan="1" colspan="1"><bold>subjID:</bold>subject identifier</td>
            <td align="left" rowspan="1" colspan="1">RW + noise</td>
            <td align="left" rowspan="1" colspan="1">gng_m1</td>
            <td align="center" rowspan="1" colspan="1">3</td>
            <td align="left" rowspan="1" colspan="1">Guitart-Masip et al. (<xref rid="bib50" ref-type="bibr">2012</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1">go/no-go</td>
            <td align="left" rowspan="1" colspan="1"><bold>cue:</bold> cue number (= 1, 2,</td>
            <td align="left" rowspan="1" colspan="1">RW + noise + go bias</td>
            <td align="left" rowspan="1" colspan="1">gng_m2</td>
            <td align="center" rowspan="1" colspan="1">4</td>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">3, or 4)</td>
            <td align="left" rowspan="1" colspan="1">RW + noise + go bias +</td>
            <td align="left" rowspan="1" colspan="1">gng_m3</td>
            <td align="center" rowspan="1" colspan="1">5</td>
            <td align="left" rowspan="1" colspan="1">"</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>keyPressed:</bold> pressed (1) or</td>
            <td align="left" rowspan="1" colspan="1">Pav. bias</td>
            <td align="left" rowspan="1" colspan="1">gng_m4</td>
            <td align="center" rowspan="1" colspan="1">6</td>
            <td align="left" rowspan="1" colspan="1">"</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">not (0)</td>
            <td align="left" rowspan="1" colspan="1">RW(rew/pun) + noise +</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">Cavanagh et al. (<xref rid="bib23" ref-type="bibr">2013</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>outcome:</bold> outcome on each</td>
            <td align="left" rowspan="1" colspan="1">go bias + Pav. bias</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">trial (= − 1, 0, or 1)</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1">Probabilistic reversal</td>
            <td align="left" rowspan="1" colspan="1"><bold>subjID:</bold> subject identifier</td>
            <td align="left" rowspan="1" colspan="1">Experience-weighted</td>
            <td align="left" rowspan="1" colspan="1">prl_ewa</td>
            <td align="center" rowspan="1" colspan="1">3</td>
            <td align="left" rowspan="1" colspan="1">den Ouden et al. (<xref rid="bib33" ref-type="bibr">2013</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1">learning</td>
            <td align="left" rowspan="1" colspan="1"><bold>choice:</bold> chosen option (= 1</td>
            <td align="left" rowspan="1" colspan="1">attraction</td>
            <td align="left" rowspan="1" colspan="1">prl_fictitious</td>
            <td align="center" rowspan="1" colspan="1">3</td>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">or 2)</td>
            <td align="left" rowspan="1" colspan="1">Fictitious update</td>
            <td align="left" rowspan="1" colspan="1">prl_rp</td>
            <td align="center" rowspan="1" colspan="1">3</td>
            <td align="left" rowspan="1" colspan="1">Gläscher, Hampton, &amp; ODoherty (<xref rid="bib45" ref-type="bibr">2009</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>outcome:</bold> reward (1) or</td>
            <td align="left" rowspan="1" colspan="1">Reward–punishment</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">loss (− 1) on each trial</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">den Ouden et al. (<xref rid="bib33" ref-type="bibr">2013</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1">Risk aversion</td>
            <td align="left" rowspan="1" colspan="1"><bold>subjID:</bold> subject identifier</td>
            <td align="left" rowspan="1" colspan="1">Prospect theory (PT)</td>
            <td align="left" rowspan="1" colspan="1">ra_prospect</td>
            <td align="center" rowspan="1" colspan="1">3</td>
            <td align="left" rowspan="1" colspan="1">Sokol-Hessner et al. (<xref rid="bib102" ref-type="bibr">2009</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>gain:</bold> possible (50%) gain</td>
            <td align="left" rowspan="1" colspan="1">PT without loss</td>
            <td align="left" rowspan="1" colspan="1">ra_noLA</td>
            <td align="center" rowspan="1" colspan="1">2</td>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">of risky option</td>
            <td align="left" rowspan="1" colspan="1">aversion (LA)</td>
            <td align="left" rowspan="1" colspan="1">ra_noRA</td>
            <td align="center" rowspan="1" colspan="1">2</td>
            <td align="left" rowspan="1" colspan="1">Tom, Fox, Trepel, &amp; Poldrack (<xref rid="bib111" ref-type="bibr">2007</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>loss:</bold> possible (50%) loss</td>
            <td align="left" rowspan="1" colspan="1">PT without risk</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">of risky option</td>
            <td align="left" rowspan="1" colspan="1">aversion (RA)</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>cert:</bold> certain option</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>gamble:</bold> gamble was taken</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">(= 1) or not (= 0)</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1">Two-armed bandit</td>
            <td align="left" rowspan="1" colspan="1"><bold>subjID:</bold> subject identifier</td>
            <td align="left" rowspan="1" colspan="1">Rescorla–Wagner</td>
            <td align="left" rowspan="1" colspan="1">bandit2arm_delta</td>
            <td align="center" rowspan="1" colspan="1">2</td>
            <td align="left" rowspan="1" colspan="1">Erev et al et al. (<xref rid="bib35" ref-type="bibr">2010</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>choice:</bold> chosen option (= 1</td>
            <td align="left" rowspan="1" colspan="1">(delta)</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">Hertwig, Barron, Weber, &amp; Erev (<xref rid="bib55" ref-type="bibr">2004</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">or 2)</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>outcome:</bold> outcome on each</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">trial</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1">Ultimatum game</td>
            <td align="left" rowspan="1" colspan="1"><bold>subjID:</bold> subject identifier</td>
            <td align="left" rowspan="1" colspan="1">Ideal Bayesian observer</td>
            <td align="left" rowspan="1" colspan="1">ug_bayes</td>
            <td align="center" rowspan="1" colspan="1">3</td>
            <td align="left" rowspan="1" colspan="1">Xiang et al. (<xref rid="bib123" ref-type="bibr">2013</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>offer:</bold> offer made by</td>
            <td align="left" rowspan="1" colspan="1">Rescorla–Wagner (delta)</td>
            <td align="left" rowspan="1" colspan="1">ug_delta</td>
            <td align="center" rowspan="1" colspan="1">3</td>
            <td align="left" rowspan="1" colspan="1">Gu et al. (<xref rid="bib48" ref-type="bibr">2015</xref>)</td>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">proposer</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"><bold>accept:</bold> accepted (1) or</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
          <tr valign="top">
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">declined (0) by responder</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1"/>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>The remainder of this article is organized as follows. First, we describe each of the tasks and models currently implemented in the hBayesDM package (see Tasks and Computational Models Implemented in hBayesDM section). Second, we briefly describe HBA and why we adopted it for computational modeling (see Mathematical Formulation of Hierarchical Bayesian Models section). Third, we provide a detailed mathematical formulation of hierarchical Bayesian models (see Performing Hierarchial Bayesian Analysis With Stan section). Fourth, we provide step-by-step tutorials on how to use the hBayesDM package (see Step-by-Step Tutorials for the hBayesDM Package section). Finally, we discuss future directions and potential limitations of the package (see Future Directions). Readers who are not interested in the technical details may skip Mathematical Formulation of Hierarchical Bayesian Models and the equations in Performing Hierarchial Bayesian Analysis With Stan.</p>
  </sec>
  <sec>
    <title>TASKS AND COMPUTATIONAL MODELS IMPLEMENTED IN hBayesDM</title>
    <p><xref ref-type="table" rid="T1">Table 1</xref> shows the list of tasks and computational models currently implemented in the hBayesDM package (as of version 0.3.0). Note that some tasks have multiple computational models and that users can compare model performance within the hBayesDM framework (see Step-by-Step Tutorials for the hBayesDM Package). To fit models to a task, first the user must prepare trial-by-trial data as a text file (*.txt) in which each row (observation) contains the columns required for the given task (see <xref ref-type="table" rid="T1">Table 1</xref>). Users can also use each task’s sample dataset as a template.</p>
    <p>Below, we describe each task and its computational model(s), briefly review its applications to healthy and clinical populations, and describe the model parameters. For brevity, we refer readers to original articles for the full details of the experimental design and computational models, and to the package help files for example codes that detail how to estimate and extract the parameters from each model. The package help files can be found by issuing the following command within the R console:</p>
    <code position="float" orientation="portrait" xml:space="preserve">?hBayesDM</code>
    <p>The command above will open the main help page, from which one can then navigate to the corresponding task/model. Users can also directly look up a help file for each task/model by calling its help file, which follows the form <code position="float" orientation="portrait" xml:space="preserve">?function_name</code> (e.g., <code position="float" orientation="portrait" xml:space="preserve">?dd_cs</code>; see <xref ref-type="table" rid="T1">Table 1</xref> for a list of these functions). Each help file provides working codes to run a concrete real-data example from start to finish.</p>
    <sec>
      <title>The Delay-Discounting Task</title>
      <p>The delay-discounting task (DDT; Rachlin, Raineri, &amp; Cross, <xref rid="bib90" ref-type="bibr">1991</xref>) is designed to estimate how much an individual discounts temporally delayed larger outcomes in comparison to smaller–sooner ones. On each trial of the DDT, two options are presented: a sooner and smaller reward (e.g., $5 now) and a later and larger reward (e.g., $20 next week). Subjects are asked to choose which option they prefer on each trial.</p>
      <p>The DDT has been widely studied in healthy populations (e.g., Green &amp; Myerson, <xref rid="bib47" ref-type="bibr">2004</xref>; Kable &amp; Glimcher, <xref rid="bib62" ref-type="bibr">2007</xref>) and delay discounting has been associated with cognitive abilities such as intelligence (Shamosh et al., <xref rid="bib98" ref-type="bibr">2008</xref>) and working memory (Hinson, Jameson, &amp; Whitney, <xref rid="bib56" ref-type="bibr">2003</xref>). Steeper delay discounting is a strong behavioral marker for addictive behaviors (Ahn, Ramesh, Moeller, &amp; Vassileva, <xref rid="bib5" ref-type="bibr">2016</xref>; Ahn &amp; Vassileva, <xref rid="bib7" ref-type="bibr">2016</xref>; Bickel, <xref rid="bib16" ref-type="bibr">2015</xref>; Green &amp; Myerson, <xref rid="bib47" ref-type="bibr">2004</xref>; MacKillop, <xref rid="bib77" ref-type="bibr">2013</xref>) and has also been associated with other psychiatric conditions, including schizophrenia (Ahn, Rass, et al., <xref rid="bib6" ref-type="bibr">2011</xref>; Heerey, Matveeva, &amp; Gold, <xref rid="bib53" ref-type="bibr">2011</xref>; Heerey, Robinson, McMahon, &amp; Gold, <xref rid="bib54" ref-type="bibr">2007</xref>) and bipolar disorder (Ahn, Rass, et al., <xref rid="bib6" ref-type="bibr">2011</xref>). The hBayesDM package currently contains three different models for the DDT: </p>
      <list list-type="simple">
        <list-item>
          <label>1. </label>
          <p><code position="float" orientation="portrait" xml:space="preserve">dd_cs</code> (constant-sensitivity model; Ebert &amp; Prelec, <xref rid="bib34" ref-type="bibr">2007</xref>)</p>
          <p>Exponential discounting rate (0 &lt;<italic>r</italic> &lt; 1)</p>
          <p>Impatience (0 &lt; <italic>s</italic> &lt;10)</p>
          <p>Inverse temperature (0 &lt; <italic>β</italic>&lt; 5)</p>
        </list-item>
        <list-item>
          <label>2. </label>
          <p><code position="float" orientation="portrait" xml:space="preserve">dd_exp</code> (exponential model; Samuelson, <xref rid="bib96" ref-type="bibr">1937</xref>)</p>
          <p>Exponential discounting rate (0 &lt; <italic>r</italic> &lt; 1)</p>
          <p>Inverse temperature (0 &lt; <italic>β</italic> &lt; 5)</p>
        </list-item>
        <list-item>
          <label>3. </label>
          <p><code position="float" orientation="portrait" xml:space="preserve">dd_hyperbolic</code> (hyperbolic model; Mazur, <xref rid="bib80" ref-type="bibr">1987</xref>)</p>
          <p>Discounting rate (0 &lt; <italic>k</italic> &lt; 1)</p>
          <p>Inverse temperature (0 &lt; <italic>β</italic> &lt; 5)</p>
        </list-item>
      </list>
      <sec>
        <title>DDT: Parameter descriptions</title>
        <p>In the exponential and hyperbolic models, temporal discounting of future (i.e., delayed) rewards is described by a single parameter, the discounting rate (0 &lt; <italic>r</italic> &lt; 1), which indicates how much future rewards are discounted. High and low discounting rates reflect greater and lesser discounting of future rewards, respectively. In the exponential and hyperbolic models, the value of a delayed reward is discounted in an exponential and hyperbolic form, respectively. The constant-sensitivity (CS) model has an additional parame ter, called <italic>time sensitivity</italic> (0 &lt; <italic>s</italic> &lt; 10). When <italic>s</italic> is equal to 1, the CS model reduces to the ex ponential model. Values of <italic>s</italic> near 0 lead to a simple “present–future dichotomy” in which all future rewards are steeply discounted to a certain subjective value, irrespective of delays. Values of <italic>s</italic> greater than 1 result in an “extended-present” heuristic, in which rewards during the extended present are valued nearly equally, and future rewards outside the extended present have zero value.</p>
        <p>All models use the softmax choice rule with an inverse-temperature parameter (Kaelbling, Littman, &amp; Moore, <xref rid="bib63" ref-type="bibr">1996</xref>; Luce, <xref rid="bib74" ref-type="bibr">1959</xref>), which reflects how deterministically individuals’ choices are made with respect to the strength (subjective value) of the alternative choices. High and low inverse temperatures represent more deterministic and more random choices, respectively.</p>
      </sec>
    </sec>
    <sec>
      <title>The Iowa Gambling Task</title>
      <p>The Iowa Gambling Task (IGT; Bechara, Damasio, Damasio, &amp; Anderson, <xref rid="bib12" ref-type="bibr">1994</xref>) was originally developed to assess decision-making deficits of patients with ventromedial prefrontal cortex lesions. On each trial, subjects are presented with four decks of cards. Two decks are advantageous (good) and the other two decks disadvantageous (bad), in terms of long-term gains. Subjects are instructed to choose decks that maximize long-term gains, which they are expected to learn by trial and error. From a statistical perspective, the IGT is a four-armed bandit problem.</p>
      <p>The IGT has been used extensively to study decision-making in several psychiatric populations (Ahn et al., <xref rid="bib8" ref-type="bibr">2014</xref>; Bechara &amp; Martin, <xref rid="bib14" ref-type="bibr">2004</xref>; Bechara et al., <xref rid="bib13" ref-type="bibr">2001</xref>; Bolla et al., <xref rid="bib17" ref-type="bibr">2003</xref>; Grant, Contoreggi, &amp; London, <xref rid="bib46" ref-type="bibr">2000</xref>; Vassileva, Gonzalez, Bechara, &amp; Martin, <xref rid="bib113" ref-type="bibr">2007</xref>). The hBayesDM package currently contains three different models for the IGT:</p>
      <list list-type="simple">
        <list-item>
          <label>1. </label>
          <p><code position="float" orientation="portrait" xml:space="preserve">igt_pvl_decay</code> (Ahn et al., <xref rid="bib8" ref-type="bibr">2014</xref>; Ahn, Krawitz, Kim, Busemeyer, &amp; Brown, <xref rid="bib4" ref-type="bibr">2011</xref>)</p>
          <p>Decay rate (0 &lt; <italic>A</italic> &lt; 1)</p>
          <p>Shape (0 &lt; <italic>α</italic> &lt; 2)</p>
          <p>Consistency (0 &lt; <italic>c</italic> &lt; 5)</p>
          <p>Loss aversion (0 &lt; <italic>λ</italic> &lt; 10)</p>
        </list-item>
        <list-item>
          <label>2. </label>
          <p><code position="float" orientation="portrait" xml:space="preserve">igt_pvl_delta</code> (Ahn, Busemeyer, Wagenmakers, &amp; Stout, <xref rid="bib3" ref-type="bibr">2008</xref>)</p>
          <p>Learning rate (0 &lt; <italic>A</italic> &lt; 1)</p>
          <p>Shape (0 &lt; <italic>α</italic> &lt; 2)</p>
          <p>Consistency (0 &lt; <italic>c</italic> &lt; 5)</p>
          <p>Loss aversion (0 &lt; <italic>λ</italic> &lt; 10)</p>
        </list-item>
        <list-item>
          <label>3. </label>
          <p><code position="float" orientation="portrait" xml:space="preserve">igt_vpp</code> (Worthy, Pang, &amp; Byrne, <xref rid="bib122" ref-type="bibr">2013</xref>)</p>
          <p>Learning rate (0 &lt; <italic>A</italic> &lt; 1)</p>
          <p>Shape (0 &lt; <italic>α</italic> &lt; 2)</p>
          <p>Consistency (0 &lt; <italic>c</italic> &lt; 5)</p>
          <p>Loss aversion (0 &lt; <italic>λ</italic> &lt; 10)</p>
          <p>Perseverance gain impact (<inline-formula><mml:math id="m1"><mml:mo>−</mml:mo><mml:mi>∞</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p>
          <p>Perseverance loss impact (<inline-formula><mml:math id="m2"><mml:mo>−</mml:mo><mml:mi>∞</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p>
          <p>Perseverance decay rate (0 &lt; <italic>k</italic> &lt; 1)</p>
          <p>Reinforcement-learning weight (0 &lt; <italic>ω</italic> &lt; 1)</p>
        </list-item>
      </list>
      <sec>
        <title>IGT: Parameter descriptions</title>
        <p>The Prospect Valence Learning (PVL) model with delta rule (PVL-delta) uses a Rescorla–Wagner updating equation (Rescorla &amp; Wagner, <xref rid="bib94" ref-type="bibr">1972</xref>) to update the expected value of the selected deck on each trial. The expected value is updated with a learning rate parameter (0 &lt; <italic>A</italic> &lt; 1) and a prediction error term, where <italic>A</italic> close to 1 places more weight on recent outcomes, and <italic>A</italic> close to 0 places more weight on past outcomes; the prediction error is the difference between the predicted and experienced outcomes. The shape (0 &lt; <italic>α</italic> &lt; 2) and loss aversion (0 &lt; <italic>λ</italic> &lt; 1) parameters control the shape of the utility (power) function and the effect of losses relative to gains, respectively. Values of <italic>α</italic> greater than 1 indicate that the utility of an outcome is convex, and values less than 1 indicate that the utility is concave. Values of <italic>λ</italic> greater than or less than 1 indicate greater or reduced sensitivity, respectively, to losses relative to gains. The consistency parameter (0 &lt; <italic>c</italic> &lt; 1) is an inverse-temperature parameter (refer to The Delay-Discounting Task for details).</p>
        <p>The PVL model with decay rule (PVL-decay) uses the same shape, loss aversion, and consistency parameters as the PVL-delta, but a recency parameter (0 &lt; <italic>A</italic> &lt; 1) is used for value updating. The recency parameter indicates how much the expected values of all decks are discounted on each trial.</p>
        <p>The PVL-delta model is nested within the Value-Plus-Perseverance (VPP) model, which is a hybrid model of PVL-delta and a heuristic strategy of perseverance. The perseverance decay rate (0 &lt; <italic>k</italic> &lt; 1) decays the perseverance strengths of all choices on each trial, akin to how PVL-decay’s recency parameter affects the expected value. The parameters for the impacts of gain (<inline-formula><mml:math id="m3"><mml:mo>−</mml:mo><mml:mi>∞</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>) and loss (<inline-formula><mml:math id="m4"><mml:mo>−</mml:mo><mml:mi>∞</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>) on perseverance reflect how the perseverance value changes after wins and losses, respectively; positive values reflect a tendency to make the same choice, and negative values a tendency to switch choices. The reinforcement-learning weight (0 &lt; <italic>ω</italic> &lt; 1) is a mixing parameter that controls how much decision weight is given to the reinforcement-learning versus the perseverance term. High versus low values reflect more versus less reliance on the reinforcement-learning term, respectively.</p>
      </sec>
    </sec>
    <sec>
      <title>The Orthogonalized Go/No-Go Task</title>
      <p>Animals use Pavlovian and instrumental controllers when taking action. The Pavlovian controller selects approaching/engaging actions with predictors of appetitive outcomes or avoiding/inhibiting actions with predictors of aversive outcomes. The instrumental controller, on the other hand, selects actions on the basis of the action–outcome contingencies of the environment. The two controllers typically cooperate, but sometimes they compete with each other (e.g., Dayan, Niv, Seymour, &amp; Daw, <xref rid="bib32" ref-type="bibr">2006</xref>). The orthogonalized go/no-go (GNG) task (Guitart-Masip et al., <xref rid="bib50" ref-type="bibr">2012</xref>) is designed to examine the interaction between the two controllers by orthogonalizing the action requirement (go vs. no go) versus the valence of the outcome (winning vs. avoiding losing money).</p>
      <p>Each trial of the orthogonal GNG task has three events in the following sequence: cue presentation, target detection, and outcome presentation. First, one of four cues is presented (“Go to win,” “Go to avoid (losing),” “NoGo to win,” or “NoGo to avoid”). After some delay, a target (“circle”) is presented on the screen, and subjects need to respond with either a <italic>go</italic> (press a button) or <italic>no go</italic> (withhold the button press). Then subjects receive a probabilistic (e.g., 80%) outcome. See Guitart-Masip et al. (<xref rid="bib50" ref-type="bibr">2012</xref>) for more details of the experimental design.</p>
      <p>The orthogonalized GNG task has been used to study decision-making in healthy populations (Cavanagh et al., <xref rid="bib23" ref-type="bibr">2013</xref>), age-related changes in midbrain structural integrity in older adults (Chowdhury, Guitart-Masip, Lambert, Dolan, &amp; Duzel, <xref rid="bib25" ref-type="bibr">2013</xref>), and negative symptoms of schizophrenia (Albrecht, Waltz, Cavanagh, Frank, &amp; Gold, <xref rid="bib10" ref-type="bibr">2016</xref>). The interaction between Pavlovian and instrumental controllers might also play a role in addiction problems (Guitart-Masip, Duzel, Dolan, &amp; Dayan, <xref rid="bib49" ref-type="bibr">2014</xref>). The hBayesDM package currently contains four different models for the orthogonalized GNG task:<list list-type="simple"><list-item><label>1. </label><p><code position="float" orientation="portrait" xml:space="preserve">gng_m1</code> (M1 in Guitart-Masip et al., <xref rid="bib50" ref-type="bibr">2012</xref>)</p><p>Lapse rate (0 &lt; <italic>ξ</italic> &lt; 1)</p><p>Learning rate (0 &lt; <italic>ϵ</italic> &lt; 1)</p><p>Effective size of a reinforcement (<inline-formula><mml:math id="m5"><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>ρ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p></list-item><list-item><label>2. </label><p><code position="float" orientation="portrait" xml:space="preserve">gng_m2</code> (M2 in Guitart-Masip et al., <xref rid="bib50" ref-type="bibr">2012</xref>)</p><p>Lapse rate (0 &lt; <italic>ξ</italic> &lt; 1)</p><p>Learning rate (0 &lt; <italic>ϵ</italic> &lt; 1)</p><p>Go bias (<inline-formula><mml:math id="m6"><mml:mo>−</mml:mo><mml:mi>∞</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>b</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p><p>Effective size of a reinforcement (<inline-formula><mml:math id="m7"><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>ρ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p></list-item><list-item><label>3. </label><p><code position="float" orientation="portrait" xml:space="preserve">gng_m3</code> (M3 in Guitart-Masip et al., <xref rid="bib50" ref-type="bibr">2012</xref>)</p><p>Lapse rate (0 &lt; <italic>ξ</italic> &lt; 1)</p><p>Learning rate (0 &lt; <italic>ϵ</italic> &lt; 1)</p><p>Go bias (<inline-formula><mml:math id="m8"><mml:mo>−</mml:mo><mml:mi>∞</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>b</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p><p>Pavlovian bias (<inline-formula><mml:math id="m9"><mml:mo>−</mml:mo><mml:mi>∞</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>π</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p><p>Effective size of a reinforcement (<inline-formula><mml:math id="m10"><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>ρ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p></list-item><list-item><label>4. </label><p><code position="float" orientation="portrait" xml:space="preserve">gng_m4</code> (M5 in Cavanagh et al., <xref rid="bib23" ref-type="bibr">2013</xref>) </p><p>Lapse rate (0 &lt; <italic>ξ</italic> &lt; 1)</p><p>Learning rate (0 &lt; <italic>ϵ</italic> &lt; 1)</p><p>Go bias (<inline-formula><mml:math id="m11"><mml:mo>−</mml:mo><mml:mi>∞</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>b</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p><p>Pavlovian bias (<inline-formula><mml:math id="m12"><mml:mo>−</mml:mo><mml:mi>∞</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>π</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p><p>Effective size of reward reinforcement (<inline-formula><mml:math id="m13"><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p><p>Effective size of punishment reinforcement (<inline-formula><mml:math id="m14"><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p></list-item></list></p>
      <sec>
        <title>GNG: Parameter descriptions</title>
        <p>All models for the GNG task include a lapse rate parameter (0 &lt; <italic>ξ</italic> &lt; 1), a learning rate parameter (0 &lt; <italic>ϵ</italic> &lt; 1; refer to IGT: Parameter descriptions for details), and a parameter for the effective size of reinforcement (<inline-formula><mml:math id="m15"><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>ρ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>). The lapse rate parameter captures the proportion of random choices made, regardless of the strength of their action probabilities. The <italic>ρ</italic> parameter determines the effective size of a reinforcement. The <code position="float" orientation="portrait" xml:space="preserve">gng_m4</code> model has separate effective size parameters for reward (<inline-formula><mml:math id="m16"><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>) and punishment (<inline-formula><mml:math id="m17"><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>), allowing for rewards and punishments to be evaluated differently.</p>
        <p>Three GNG models (<code position="float" orientation="portrait" xml:space="preserve">gng_m2</code>, <code position="float" orientation="portrait" xml:space="preserve">gng_m3</code>, and <code position="float" orientation="portrait" xml:space="preserve">gng_m4</code>) include a go bias parameter (<inline-formula><mml:math id="m18"><mml:mo>−</mml:mo><mml:mi>∞</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>b</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>). Go bias reflects a tendency to respond (<italic>go</italic>), regardless of the action–outcome associations; high or low values for <italic>b</italic> reflect a high or a low tendency to make a go (motor) response, respectively.</p>
        <p>Two GNG models (<code position="float" orientation="portrait" xml:space="preserve">gng_m3</code> and <code position="float" orientation="portrait" xml:space="preserve">gng_m4</code>) include a Pavlovian bias parameter (<inline-formula><mml:math id="m19"><mml:mo>−</mml:mo><mml:mi>∞</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>π</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>). Pavlovian bias reflects a tendency to make responses that are Pavlovian congruent: that is, to promote or inhibit <italic>go</italic>if the expected value of the stimulus is positive (appetitive) or negative (aversive), respectively.</p>
      </sec>
    </sec>
    <sec>
      <title>Probabilistic Reversal-Learning Task</title>
      <p>Environments often have higher-order structures, such as interdependencies between the stimuli, actions, and outcomes. In such environments, subjects need to infer and make use of the structures in order to make optimal decisions. In the probabilistic reversal-learning (PRL) task, higher-order structure exists such that the reward distributions of two stimuli are anticorrelated (e.g., if one option has a reward rate of 80%, the other option has a reward rate of [100 – 80]%, which is 20%). Subjects need to learn the higher-order structure and take it into account to optimize their decision-making and to maximize earnings.</p>
      <p>In a typical PRL task, two stimuli are presented to a subject. The choice of a “correct” or good stimulus will usually lead to a monetary gain (e.g., 70%), whereas the choice of an “incorrect” or bad stimulus will usually lead to a monetary loss. The reward contingencies will reverse at fixed points (e.g., Murphy, Michael, Robbins, &amp; Sahakian, <xref rid="bib83" ref-type="bibr">2003</xref>) or will be triggered by consecutive correct choices (Cools, Clark, Owen, &amp; Robbins, <xref rid="bib26" ref-type="bibr">2002</xref>; Hampton et al., <xref rid="bib52" ref-type="bibr">2006</xref>).</p>
      <p>The PRL task has been widely used to study reversal learning in healthy individuals (Cools et al., <xref rid="bib26" ref-type="bibr">2002</xref>; den Ouden et al., <xref rid="bib33" ref-type="bibr">2013</xref>; Gläscher et al., <xref rid="bib45" ref-type="bibr">2009</xref>). The PRL has been also used to study decision-making deficits associated with prefrontal cortex lesions (e.g., Fellows &amp; Farah, <xref rid="bib37" ref-type="bibr">2003</xref>; Rolls, Hornak, Wade, &amp; McGrath, <xref rid="bib95" ref-type="bibr">1994</xref>), as well as Parkinson’s disease (e.g., Cools, Lewis, Clark, Barker, &amp; Robbins, <xref rid="bib27" ref-type="bibr">2007</xref>; Swainson et al., <xref rid="bib109" ref-type="bibr">2000</xref>), schizophrenia (e.g., Waltz &amp; Gold, <xref rid="bib117" ref-type="bibr">2007</xref>), and cocaine dependence (Ersche, Roiser, Robbins, &amp; Sahakian, <xref rid="bib36" ref-type="bibr">2008</xref>). The hBayesDM package currently contains three models for PRL tasks:</p>
      <list list-type="simple">
        <list-item>
          <label>1. </label>
          <p><code position="float" orientation="portrait" xml:space="preserve">prl_ewa</code> (den Ouden et al., <xref rid="bib33" ref-type="bibr">2013</xref>)</p>
          <p>1 – Learning rate (0 &lt; <italic>φ</italic> &lt; 1)</p>
          <p>Experience decay (0 &lt; <italic>ρ</italic> &lt; 1)</p>
          <p>Inverse temperature (0 &lt; <italic>β</italic> &lt; 1)</p>
        </list-item>
        <list-item>
          <label>2. </label>
          <p><code position="float" orientation="portrait" xml:space="preserve">prl_fictitious</code> (Gläscher et al., <xref rid="bib45" ref-type="bibr">2009</xref>)</p>
          <p>Learning rate (0 &lt; <italic>η</italic> &lt; 1)</p>
          <p>Indecision point (0 &lt; <italic>α</italic> &lt; 1)</p>
          <p>Inverse temperature (0 &lt; <italic>β</italic> &lt; 1)</p>
        </list-item>
        <list-item>
          <label>3. </label>
          <p><code position="float" orientation="portrait" xml:space="preserve">prl_rp</code> (den Ouden et al., <xref rid="bib33" ref-type="bibr">2013</xref>)</p>
          <p>Reward learning rate (0 &lt; <italic>A</italic><sub><italic>rew</italic></sub> &lt; 1)</p>
          <p>Punishment learning rate (0 &lt; <italic>A</italic><sub><italic>pun</italic></sub> &lt; 1)</p>
          <p>Inverse temperature (0 &lt; <italic>β</italic> &lt; 1)</p>
        </list-item>
      </list>
      <sec>
        <title>PRL: Parameter descriptions</title>
        <p>All PRL models above contain learning rate parameters (refer to IGT: Parameter descriptions for details). The <code position="float" orientation="portrait" xml:space="preserve">prl_rp</code> model has separate learning rates for rewards (0 &lt; <italic>A</italic><sub><italic>rew</italic></sub> &lt; 1) and punishments (0 &lt; <italic>A</italic><sub><italic>pun</italic></sub> &lt; 1). In the <code position="float" orientation="portrait" xml:space="preserve">prl_ewa</code> model (Camerer &amp; Ho, <xref rid="bib21" ref-type="bibr">1999</xref>), low and high values of <italic>φ</italic> reflect more weight on recent and on past outcomes, respectively. All PRL models also contain an inverse-temperature parameter (refer to DDT: Parameter descriptions for details).</p>
        <p>The <code position="float" orientation="portrait" xml:space="preserve">prl_ewa</code> model proposed in den Ouden et al. (<xref rid="bib33" ref-type="bibr">2013</xref>) contains a decay rate parameter (0 &lt; <italic>ρ</italic> &lt;). The experienced weight of the chosen option is decayed in proportion to <italic>ρ</italic>, and 1 is added to the weight on each trial. Thus, a higher value of <italic>ρ</italic> indicates slower decaying or updating of the experienced weight.</p>
        <p>The <code position="float" orientation="portrait" xml:space="preserve">prl_fictitious</code> model contains an indecision point parameter (0 &lt; <italic>α</italic> &lt; 1). This point reflects a subject’s amount of bias or preference toward an option. High or low values for <italic>α</italic> indicate a greater or a lesser preference for one option over the other.</p>
      </sec>
    </sec>
    <sec>
      <title>Risk Aversion Task</title>
      <p>The risk aversion (RA; Sokol-Hessner, Camerer, &amp; Phelps, <xref rid="bib101" ref-type="bibr">2013</xref>; Sokol-Hessner et al., <xref rid="bib102" ref-type="bibr">2009</xref>) task is a description-based task (Hertwig, Barron, Weber, &amp; Erev, <xref rid="bib55" ref-type="bibr">2004</xref>) in which the possible outcomes of all options and their probabilities are provided to subjects on each trial. In the RA task, subjects choose either a sure option with a guaranteed amount or a risky option (i.e., gamble) with possible gains and/or loss amounts. Subjects are asked to choose which option they prefer (or whether they want to accept the gamble) on each trial. In the RA task, subjects per form two cognitive regulation (<italic>attend</italic> and <italic>regulate</italic>) conditions in a within-subjects design: in the attend condition, subjects are asked to focus on each choice in isolation, whereas in the regulate condition, subjects are asked to emphasize choices in their greater context (see Sokol-Hessner et al., <xref rid="bib102" ref-type="bibr">2009</xref>, for the details). The data published in Sokol-Hessner et al. (<xref rid="bib102" ref-type="bibr">2009</xref>) can be found using the following paths (these paths are also available in the RA model help files):</p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">path_to_attend_data = <bold>system.file</bold>("extdata/ra_data_attend.txt", package="hBayesDM")</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">path_to_regulate_data = <bold>system.file</bold>("extdata/ra_data_reappraisal. txt", package="hBayesDM").</code>
      </p>
      <p>The hBayesDM package currently contains three models for the RA and similar (e.g., Tom, Fox, Trepel, &amp; Poldrack, <xref rid="bib111" ref-type="bibr">2007</xref>) tasks:<list list-type="simple"><list-item><label>1. </label><p><code position="float" orientation="portrait" xml:space="preserve">ra_prospect</code> (Sokol-Hessner et al., <xref rid="bib102" ref-type="bibr">2009</xref>)</p><p>Loss aversion (0 &lt; <italic>λ</italic> &lt; 5)</p><p>Risk aversion (0 &lt; <italic>ρ</italic> &lt; 2)</p><p>Inverse temperature (<inline-formula><mml:math id="m20"><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>τ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p></list-item><list-item><label>2. </label><p><code position="float" orientation="portrait" xml:space="preserve">ra_noLA</code> (no loss aversion [LA] parameter; for tasks that involve only gains)</p><p>Risk aversion (0 &lt; <italic>ρ</italic> &lt; 2)</p></list-item><list-item><p>Inverse temperature (<inline-formula><mml:math id="m21"><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>τ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p></list-item><list-item><label>3. </label><p><code position="float" orientation="portrait" xml:space="preserve">ra_noRA</code> (no risk aversion [RA] parameter; see, e.g., Tom et al., <xref rid="bib111" ref-type="bibr">2007</xref>)</p><p>Loss aversion (0 &lt; <italic>λ</italic> &lt; 2)</p><p>Inverse temperature (<inline-formula><mml:math id="m22"><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>τ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>)</p></list-item></list></p>
      <sec>
        <title>RA: Parameter descriptions</title>
        <p>The <code position="float" orientation="portrait" xml:space="preserve">ra_prospect</code> model includes a loss aversion parameter (0 &lt; <italic>λ</italic> &lt; 5), a risk aversion parameter (0 &lt; <italic>ρ</italic> &lt; 2), and an inverse-temperature parameter (<inline-formula><mml:math id="m23"><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>τ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>). See DDT: Parameter descriptions for inverse temperature. The risk aversion and loss aversion parameters in the RA models are similar to those in the IGT models. However, in RA models they control the valuations of the possible choices under consideration, as opposed to the evaluation of outcomes after they are experienced (Rangel et al., <xref rid="bib92" ref-type="bibr">2008</xref>).</p>
        <p>The <code position="float" orientation="portrait" xml:space="preserve">ra_noLA</code> and <code position="float" orientation="portrait" xml:space="preserve">ra_noRA</code> models are nested within the <code position="float" orientation="portrait" xml:space="preserve">ra_prospect</code> model, with either loss aversion (<code position="float" orientation="portrait" xml:space="preserve">ra_noLA</code>) or risk aversion (<code position="float" orientation="portrait" xml:space="preserve">ra_noRA</code>) set to 1.</p>
      </sec>
    </sec>
    <sec>
      <title>Two-Armed Bandit Task</title>
      <p>Multi-armed bandit tasks or problems typically refer to situations in which gamblers decide which gamble or slot machine to play in order to maximize long-term gain. Many reinforcement-learning tasks and experience-based (Hertwig et al., <xref rid="bib55" ref-type="bibr">2004</xref>) tasks can be classified as bandit problems. In a typical two-armed bandit task, subjects are presented with two options (stimuli) on each trial. Feedback is given after a stimulus is chosen. Subjects are asked to maximize positive feedback as they make choices, and they are expected to learn stimulus–outcome contingencies from trial-by-trial experience. The hBayesDM package currently contains a simple model for a two-armed bandit task:</p>
      <list list-type="simple">
        <list-item>
          <label>1. </label>
          <p><code position="float" orientation="portrait" xml:space="preserve">bandit2arm_delta</code> (Hertwig et al., <xref rid="bib55" ref-type="bibr">2004</xref>)</p>
          <p>Learning rate (0 &lt; <italic>A</italic> &lt; 1)</p>
          <p>Inverse temperature (0 &lt; <italic>τ</italic> &lt; 1)</p>
        </list-item>
      </list>
      <sec>
        <title>Two-armed bandit: Parameter descriptions</title>
        <p>The <code position="float" orientation="portrait" xml:space="preserve">bandit2arm_delta</code> model uses the Rescorla–Wagner rule (see IGT: Parameter descriptions) for updating the expected value of the chosen option, along with the softmax choice rule with an inverse temperature (see DDT: Parameter descriptions).</p>
      </sec>
    </sec>
    <sec>
      <title>The Ultimatum Game (Norm-Training)</title>
      <p>The abilities to understand the social norms of an environment and to adaptively cope with those norms are critical for normal social functioning (Gu et al., <xref rid="bib48" ref-type="bibr">2015</xref>; Montague &amp; Lohrenz, <xref rid="bib82" ref-type="bibr">2007</xref>). The ultimatum game (UG) is a widely used social decision-making task that examines how individuals respond to deviations from social norms and adapt to norms in a changing environment.</p>
      <p>The UG involves two players: a proposer and a responder. On each trial, the proposer is given some amount of money to divide up amongst the two players. After deciding how to divide the money, an offer is made to the responder. The responder can either accept the offer (and the money is split as offered) or reject it (both players receive nothing). Previous studies have shown that the most common offer is approximately 50% of the total amount, and that “unfair” offers (&lt;∼20% of the total amount) are often rejected, even though it is optimal to accept any offer (Güth, Schmittberger, &amp; Schwarze, <xref rid="bib51" ref-type="bibr">1982</xref>; Sanfey, <xref rid="bib97" ref-type="bibr">2003</xref>; Thaler, <xref rid="bib110" ref-type="bibr">1988</xref>). A recent study examined the computational substrates of norm adjustment by using a norm-training UG in which subjects played the role of responder in a norm-changing environment (Xiang et al., <xref rid="bib123" ref-type="bibr">2013</xref>).</p>
      <p>The UG has been used to investigate the social decision-making of individuals with ventromedial prefrontal (Gu et al., <xref rid="bib48" ref-type="bibr">2015</xref>; Koenigs et al., <xref rid="bib67" ref-type="bibr">2007</xref>) and insular cortex (Gu et al., <xref rid="bib48" ref-type="bibr">2015</xref>) lesions, as well as of patients with schizophrenia (Agay, Kron, Carmel, Mendlovic, &amp; Levkovitz, <xref rid="bib1" ref-type="bibr">2008</xref>; Csukly, Polgár, Tombor, Réthelyi, &amp; Kéri, <xref rid="bib28" ref-type="bibr">2011</xref>). The hBayesDM package currently contains two models for the UG (or norm-training UG) in which subjects play the role of responder:</p>
      <list list-type="simple">
        <list-item>
          <label>1. </label>
          <p><code position="float" orientation="portrait" xml:space="preserve">ug_bayes</code> (Xiang et al., <xref rid="bib123" ref-type="bibr">2013</xref>)</p>
          <p>Envy (0 &lt; <italic>α</italic> &lt; 20)</p>
          <p>Guilt (0 &lt; <italic>β</italic> &lt; 10)</p>
          <p>Inverse temperature (0 &lt; <italic>τ</italic> &lt; 10)</p>
        </list-item>
        <list-item>
          <label>2. </label>
          <p><code position="float" orientation="portrait" xml:space="preserve">ug_delta</code> (Gu et al., <xref rid="bib48" ref-type="bibr">2015</xref>)</p>
          <p>Envy (0 &lt; <italic>α</italic> &lt; 20)</p>
          <p>Inverse temperature (0 &lt; <italic>τ</italic> &lt; 10)</p>
          <p>Norm adaptation rate (0 &lt; <italic>ϵ</italic> &lt; 1)</p>
        </list-item>
      </list>
      <sec>
        <title>UG: Parameter descriptions</title>
        <p>The <code position="float" orientation="portrait" xml:space="preserve">ug_bayes</code> model assumes that the subject (responder) behaves like a <italic>Bayesian ideal observer</italic> (Knill &amp; Pouget, <xref rid="bib66" ref-type="bibr">2004</xref>), so that the expected offer made by the proposer is updated in a Bayesian fashion. This is in contrast to the <code position="float" orientation="portrait" xml:space="preserve">ug_delta</code> model, which assumes that the subject (again the responder) updates the expected offer using a Rescorla–Wagner (delta) updating rule. Both the <code position="float" orientation="portrait" xml:space="preserve">ug_bayes</code> and <code position="float" orientation="portrait" xml:space="preserve">ug_delta</code> models contain envy (0 &lt; <italic>α</italic> &lt; 20) and inverse-temperature (0 &lt; <italic>τ</italic> &lt; 10; refer to DDT: Parameter descriptions for details) parameters. The envy parameter reflects sensitivity to norm prediction error (see below for the <code position="float" orientation="portrait" xml:space="preserve">ug_bayes</code> model), where higher or lower values indicate greater or lesser sensitivity, respectively. In the UG, prediction error reflects the difference between the expected and received offers.</p>
        <p>In the <code position="float" orientation="portrait" xml:space="preserve">ug_bayes</code> model, the utility of an offer is adjusted by two norm prediction errors: (1) negative prediction errors, multiplied by an envy parameter (0 &lt; <italic>α</italic> &lt; 20), and (2) positive prediction errors, multiplied by a guilt parameter (0 &lt; <italic>β</italic> &lt; 10). Higher and lower values for envy (<italic>α</italic>) and guilt (<italic>β</italic>) reflect greater and lesser sensitivity to negative and positive norm prediction errors, respectively. The <code position="float" orientation="portrait" xml:space="preserve">ug_delta</code> model includes only the envy parameter (Gu et al., <xref rid="bib48" ref-type="bibr">2015</xref>).</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>MATHEMATICAL FORMULATION OF HIERARCHICAL BAYESIAN MODELS</title>
    <p>In this section, we briefly describe HBA for readers interested in HBA or Bayesian frameworks in general. Then we illustrate how we programmed our models using the Stan software package (Carpenter et al., <xref rid="bib22" ref-type="bibr">2016</xref>) and how we formulated hierarchical structures for various types of model parameters (see Performing Hierarchial Bayesian Analysis With Stan). Readers who are not interested in the mathematical details may skip the Performing Hierarchial Bayesian Analysis With Stan section.</p>
    <p>Most computational models do not have closed-form solutions, so we need to estimate parameter values. Traditionally, parameters are estimated at the individual level with maximum likelihood estimation (MLE): getting point estimates that maximize the likelihood of data for each individual separately (e.g., Myung, <xref rid="bib84" ref-type="bibr">2003</xref>). However, the individual MLE estimates are often noisy and unreliable, especially when there are insufficient data, which is common in psychology or neuroscience experimental settings (cf. speeded choice-response time tasks). A group-level analysis (e.g., group-level MLE), which estimates a single set of parameters for the whole group of individuals, may generate more reliable estimates but inevitably ignores individual differences.</p>
    <p>For parameter estimation, the hBayesDM package uses HBA, which is a branch of Bayesian statistics. We will briefly explain why hierarchical approaches such as HBA have advantages over traditional MLE methods. In Bayesian statistics, we assume prior beliefs (i.e., prior distributions) for the model parameters and update the priors into posterior distributions given the data (e.g., the trial-by-trial choices and outcomes) using Bayes’s rule. If Bayesian inference is performed individually for each individual <italic>i</italic>:<disp-formula id="E1"><mml:math id="m24"><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>∫</mml:mo><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>′</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula></p>
    <p>Here, Θ<sub><italic>i</italic></sub> is the set of parameters of a model for individual <italic>i</italic> (e.g., <inline-formula><mml:math id="m25"><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3em"/></mml:mrow></mml:mfenced></mml:math></inline-formula>), <italic>D</italic><sub><italic>i</italic></sub> is the data, <italic>P</italic>(<italic>D</italic><sub><italic>i</italic></sub>|Θ<sub><italic>i</italic></sub>) is the <italic>likelihood</italic> (of the data given a set of parameters), <italic>P</italic>(<italic>D</italic><sub><italic>i</italic></sub>) is called the <italic>evidence</italic> (of the data being generated by this model), and <italic>P</italic>(Θ<sub><italic>i</italic></sub>) and <italic>P</italic>(Θ<sub><italic>i</italic></sub>|<italic>D</italic><sub><italic>i</italic></sub>) are the <italic>prior</italic> and <italic>posterior</italic> distributions of Θ<sub><italic>i</italic></sub> , respectively.</p>
    <p>In HBA, hyperparameters are introduced in addition to the individual parameters, as is illustrated in <xref ref-type="fig" rid="F2">Figure 2A</xref> (Gelman, Dunson, &amp; Vehtari, <xref rid="bib42" ref-type="bibr">2013</xref>; Kruschke, <xref rid="bib70" ref-type="bibr">2014</xref>). If we set the hyperparameters as <inline-formula><mml:math id="m26"><mml:mi>Φ</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3em"/></mml:mrow></mml:mfenced></mml:math></inline-formula>, with group-level normal means <italic>μ</italic><sub>(.)</sub> and standard deviations <italic>σ</italic><sub>(.)</sub>, the joint posterior distribution <inline-formula><mml:math id="m27"><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>Θ</mml:mi><mml:mo>,</mml:mo><mml:mi>Φ</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is<disp-formula id="E2"><mml:math id="m28"><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>Θ</mml:mi><mml:mo>,</mml:mo><mml:mi>Φ</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>Θ</mml:mi><mml:mo>,</mml:mo><mml:mi>Φ</mml:mi></mml:mrow></mml:mfenced><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>Θ</mml:mi><mml:mo>,</mml:mo><mml:mi>Φ</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>∝</mml:mo><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>Θ</mml:mi></mml:mrow></mml:mfenced><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>Θ</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>Φ</mml:mi></mml:mrow></mml:mfenced><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:math></disp-formula></p>
    <fig id="F2" orientation="portrait" position="float">
      <label><bold>Figure 2.</bold> </label>
      <caption>
        <p><bold>(A) A schematic illustration of hierarchical Bayesian analysis (HBA). In this example, the individual parameters are assumed to come from a group (hyper)parameter. (B) Results of a parameter recovery study (Ahn et al., <xref rid="bib4" ref-type="bibr">2011</xref>) between HBA and maximum likelihood estimation.</bold> Thirty subjects’ data from the Iowa gambling task were simulated using true parameters (black circles), and the parameters were estimated with hierarchical Bayesian analysis (blue squares = the individual posterior means) and individual maximum likelihood estimation (yellow triangles). The performance of the two approaches is shown for the loss aversion parameter (<italic>λ</italic>).</p>
      </caption>
      <graphic xlink:href="cpsy-01-24-g002"/>
    </fig>
    <p>The hierarchical structure of HBA leads to “shrinkage” effects (Gelman et al., <xref rid="bib42" ref-type="bibr">2013</xref>) in the individual estimates. Shrinkage effects, put simply, refer to when each individual’s estimates inform the group’s estimates, which in turn inform the estimates of all individuals. Consequently, the individual parameter estimates tend to be more stable and reliable, because commonalities among the individuals are captured and informed by the group tendencies (but see Future Directions section for the limitations and potential drawbacks of this approach). Such a hierarchical approach is particularly useful when the amount of information (e.g., the number of trials) from a single person is often too small to precisely estimate parameters at the individual level. A simulation study (Ahn, Krawitz, et al., <xref rid="bib4" ref-type="bibr">2011</xref>) empirically demonstrated that HBA outperforms individual MLE in parameter recovery (see <xref ref-type="fig" rid="F2">Figure 2B</xref>), which suggests that parameter values estimated with HBA might more accurately reflect individual differences in underlying neurocognitive processes than do those estimated with individual MLE. Importantly, HBA provides full posterior distributions instead of point estimates; thus, it provides rich information about the parameters. HBA also makes it straightforward to make group comparisons in a Bayesian fashion (e.g., by comparing clinical and nonclinical groups; see section Compare models [and groups] for an example). Recent studies in cognitive and decision sciences further confirmed the validity and usefulness of HBA and other hierarchical approaches (e.g., Ahn et al., <xref rid="bib8" ref-type="bibr">2014</xref>; Guitart-Masip et al., <xref rid="bib50" ref-type="bibr">2012</xref>; Huys et al., <xref rid="bib58" ref-type="bibr">2011</xref>; Katahira, <xref rid="bib65" ref-type="bibr">2016</xref>; Lee, <xref rid="bib71" ref-type="bibr">2011</xref>; Raja Beharelle, Polania, Hare, &amp; Ruff, <xref rid="bib91" ref-type="bibr">2015</xref>; Shiffrin, Lee, Kim, &amp; Wagenmakers, <xref rid="bib99" ref-type="bibr">2008</xref>).</p>
  </sec>
  <sec>
    <title>PERFORMING HIERARCHICAL BAYESIAN ANALYSIS WITH STAN</title>
    <p>In the hBayesDM package, posterior inference for all models is performed with a Markov chain Monte Carlo (MCMC) sampling scheme using the newly developed probabilistic programming language Stan (Carpenter et al., <xref rid="bib22" ref-type="bibr">2016</xref>) and its R instantiation, RStan (<ext-link ext-link-type="uri" xlink:href="http://mc-stan.org/interfaces/rstan">http://mc-stan.org/interfaces/rstan</ext-link>). Stan uses a specific MCMC sampler called Hamiltonian Monte Carlo (HMC) to perform sampling from the posterior distribution. During each iteration of HMC, derivatives of the density function, together with the auto-optimized Metropolis acceptance rate and step size and maximum steps, are utilized to find out the direction of the target posterior distribution (Carpenter et al., <xref rid="bib22" ref-type="bibr">2016</xref>). HMC offers more efficient sampling than conventional algorithms implemented in other software, such as BUGS (Lunn, Spiegelhalter, Thomas, &amp; Best, <xref rid="bib75" ref-type="bibr">2009</xref>; Lunn, Thomas, Best, &amp; Spiegelhalter, <xref rid="bib76" ref-type="bibr">2000</xref>) and JAGS (Plummer, <xref rid="bib89" ref-type="bibr">2003</xref>). Moreover, HMC works well even for complex models with high-dimensional model structures and highly correlated model parameters. A drawback of HMC is that it is not capable of directly sampling discrete parameters, because HMC uses derivatives of the density. However, one could marginalize the posterior density in order to obtain discrete outcomes. See the Stan reference manual (<ext-link ext-link-type="uri" xlink:href="http://mc-stan.org/documentation/">http://mc-stan.org/documentation/</ext-link>) and Kruschke (<xref rid="bib70" ref-type="bibr">2014</xref>, chap. 14) for a comprehensive description of HMC and Stan. To learn more about the basic foundations of MCMC, see Krushcke (<xref rid="bib70" ref-type="bibr">2014</xref>, chap. 7).</p>
    <p>To use the hBayesDM package, users do not need to know how to program in Stan. However, for those interested in understanding our models and Stan in general, we briefly introduce the general structure of model specification in Stan, followed by the detailed hierarchical parameter declaration and optimizing approaches that are utilized in hBayesDM. Finally, we describe how we calculate log likelihood and model fits inside Stan models.</p>
    <sec>
      <title>General Structure of Stan Model Specification</title>
      <p>Many useful features of BUGS were incorporated into Stan’s design; thus, Stan is similar to BUGS (or JAGS), and users who are familiar with BUGS will find Stan relatively easy to use (see the Stan reference manual, Appendix B; available at <ext-link ext-link-type="uri" xlink:href="http://mc-stan.org/documentation/">http://mc-stan.org/documentation/</ext-link>). There are six model blocks in the general structure of the Stan model specification, as listed below. Note that Stan implements sequential execution in its model specification, unlike BUGS and JAGS, in which the order of the code does not affect a model’s execution:</p>
    </sec>
    <sec>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      … data {</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      … read in external data …</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      }</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      transformed data {</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      … pre-processing of data …</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      }</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      parameters {</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">       … parameters to be sampled by HMC…</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      }</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      transformed parameters {</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      … pre-processing of parameters …</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      }</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      model {</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      … statistical/cognitive model …</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      }</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      generated quantities {</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      … post-processing of the model …</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      }</code>
      </p>
    </sec>
    <sec>
      <p>Note that the <sans-serif>data</sans-serif>, <sans-serif>parameters</sans-serif>, and <sans-serif>model</sans-serif> blocks are mandatory in Stan, whereas the <sans-serif>transformed data</sans-serif>, <sans-serif>transformed parameters</sans-serif>, and <sans-serif>generated quantities</sans-serif> blocks are optional. Nonetheless, we typically use all of these optional blocks in hBayesDM, for different purposes: (1) We use the <sans-serif>transformed data</sans-serif> block to maintain a concise programming style and assign the initial values. (2) We implement noncentered parameterization (a.k.a. the “Matt trick”) in the <sans-serif>transformed parameters</sans-serif> block to optimize sampling and reduce autocorrelation be tween the group-level parameters in our hierarchical models. Details will be explained in the Optimizing Approaches in Stan section of this tutorial. (3) We include the <sans-serif>generated quantities</sans-serif> section to explicitly calculate the log-likelihood of the corresponding model and compute out-of-sample prediction accuracy (see Computing Log-Likelihood Inside Stan Models) for model comparison.</p>
    </sec>
    <sec>
      <title>Hierarchical Parameter Declaration in Stan</title>
      <p>When declaring hierarchical parameters in hBayesDM with Stan, we assume that the individual parameters are drawn from group-level normal distributions. Normal and half-Cauchy distributions are used for the priors of the group-level normal means (<italic>μ</italic><sub>(.)</sub>) and standard deviations (<italic>σ</italic><sub>(.)</sub>), respectively. We employ flat (uniform) or weakly informative priors (Gelman et al., <xref rid="bib42" ref-type="bibr">2013</xref>) to minimize the influence of those priors on the posterior distributions when the sample sizes are small. We used standard normal priors for the group-level means (e.g., Lee, <xref rid="bib71" ref-type="bibr">2011</xref>; Shiffrin et al., <xref rid="bib99" ref-type="bibr">2008</xref>; Wetzels, Vandekerckhove, &amp; Tuerlinckx, <xref rid="bib119" ref-type="bibr">2010</xref>), which also makes it easy to optimize Stan codes (see Optimizing Approaches to Stan). For the group-level standard deviations, we used half-Cauchy prior distributions, which tend to give sharper and more reasonable estimates than uniform or inverse-Gaussian prior distributions (Gelman, <xref rid="bib41" ref-type="bibr">2006</xref>). According to the range of the parameters of interest, we introduce four ways of declaring hierarchical parameters: unbounded parameters, positive parameters, parameters bounded between 0 and 1, and parameters bounded between 0 and an upper limit <italic>U</italic>.</p>
      <p>For unbounded parameters (for illustration purposes, say <italic>ξ</italic> for a general individual parameter), we declare: <code position="float" orientation="portrait" xml:space="preserve">      </code><disp-formula id="E3"><mml:math id="m29"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mtext>Normal</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula>
<code position="float" orientation="portrait" xml:space="preserve">      </code><disp-formula id="E4"><mml:math id="m30"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mtext>half-Cauchy</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula>
<code position="float" orientation="portrait" xml:space="preserve">      </code><disp-formula id="E5"><mml:math id="m31"><mml:mi>ξ</mml:mi><mml:mo>∼</mml:mo><mml:mtext>Normal</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> where <italic>μ</italic><sub><italic>ξ</italic></sub> (group mean parameter) is drawn from a wide normal distribution, <italic>σ</italic><sub><italic>ξ</italic></sub> (group standard deviation parameter) is drawn from a positive half-Cauchy distribution, and <italic>ξ</italic> is distributed as a normal distribution with a mean of <italic>μ</italic><sub><italic>ξ</italic></sub> and a standard deviation of <italic>σ</italic><sub><italic>ξ</italic></sub>. Note that we use the wide normal distribution (weakly informative prior) so as to keep the prior bias minimum. Plus, the use of the positive half-Cauchy ensures that most of the density is between 0 and 10, while the HMC sampler is still able to visit beyond its upper bound, resulting in a soft constraint (Gelman et al., <xref rid="bib42" ref-type="bibr">2013</xref>).</p>
      <p>For positive parameters (e.g., the effective size of reinforcements in the orthogonalized GNG task), we apply an exponential transformation to constrain an unbounded parameter to be greater than 0, such that the transformed prior is exclusively positive and avoids extreme values. Note that this results in a small bias toward zero. In hBayesDM, we define:<disp-formula><mml:math id="M1"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mtext>Normal</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula><disp-formula><mml:math id="M2"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mtext>half-Cauchy</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula><disp-formula><mml:math id="M3"><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi><mml:mo>∼</mml:mo><mml:mtext>Normal</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula><disp-formula><mml:math id="M4"><mml:mi>ξ</mml:mi><mml:mo>=</mml:mo><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula></p>
      <p>For parameters that are bounded between 0 and 1 (e.g., learning rate), we use the inverse probit transformation (the cumulative distribution function of a unit normal distribution) to convert the unconstrained values into this range. In fact, given the mathematical relationship between the probability density function (pdf ) and the cumulative density function (cdf ) of the unit normal distribution, this transformation guarantees that the converted prior will be uniformly distributed between 0 and 1. Several studies have demonstrated the robustness and effectiveness of this transformation (e.g., Ahn et al., <xref rid="bib8" ref-type="bibr">2014</xref>; Wetzels et al., <xref rid="bib119" ref-type="bibr">2010</xref>). To effectively implement this, Stan provides a fast approximation of the inverse probit transformation (i.e., the <code position="float" orientation="portrait" xml:space="preserve">Phi_approx</code> function), which we adopted:<disp-formula><mml:math id="M5"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mtext>Normal</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula><disp-formula><mml:math id="M6"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mtext>half-Cauchy</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula><disp-formula><mml:math id="M7"><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi><mml:mo>∼</mml:mo><mml:mtext>Normal</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula><disp-formula><mml:math id="M8"><mml:mi>ξ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mtext>Probit</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula></p>
      <p>For parameters that are bounded between 0 and an upper limit <italic>U</italic> (e.g., inverse softmax temperature, loss aversion in the RA task), we simply adapt the declaration rule for [0, 1] parameters and multiply it by the upper limit <italic>U</italic>. Likewise, the converted prior is distributed as a uniform distribution between 0 and <italic>U</italic>. If <italic>U</italic> is relatively small (less than ∼20), we use this approach instead of using a positive parameter (with an exponential transformation) in order to keep the prior bias minimal. When we use such an upper bound, the posterior fits are checked to ensure that the parameter estimates are not very close to the boundary. Formally, we declare:<disp-formula><mml:math id="M9"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mtext>Normal</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula><disp-formula><mml:math id="M10"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mtext>half-Cauchy</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula><disp-formula><mml:math id="M11"><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi><mml:mo>∼</mml:mo><mml:mtext>Normal</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula><disp-formula><mml:math id="M12"><mml:mi>ξ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mtext>Probit</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi><mml:mo>·</mml:mo><mml:mi>U</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula></p>
      <p>As is shown above, we do not employ truncated sampling in declaring the hierarchical parameters because hard constraints (e.g., <italic>ξ</italic> ∼ Normal(0,1)T[0,<italic>U</italic>]) may harm the HMC sampling algorithm and return poorly converging posterior distributions (Carpenter et al., <xref rid="bib22" ref-type="bibr">2016</xref>). If users want to build their own hierarchical Bayesian models for their research, they can refer to our practice of standardizing the parameter declarations.</p>
    </sec>
    <sec>
      <title>Optimizing Approaches in Stan</title>
      <p>Hierarchical models often suffer from highly correlated group-level parameters in their posterior distributions, creating challenges in terms of model convergence and estimation time (Gelman et al., <xref rid="bib42" ref-type="bibr">2013</xref>; Kruschke, <xref rid="bib70" ref-type="bibr">2014</xref>). To address these challenges, we practice reparameterization and vectorization in order to optimize the model specification in hBayesDM.</p>
      <p>A Normal(<italic>μ</italic>,<italic>σ</italic>) distribution, like other distributions in the location–scale distribution family, can be reparameterized to be sampled from a unit normal distribution that is multiplied by the scale parameter <italic>σ</italic> and then shifted with the location parameter <italic>μ</italic>. Formally,<disp-formula id="E6"><mml:math id="m32"><mml:mi>ξ</mml:mi><mml:mo>∼</mml:mo><mml:mtext>Normal</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula>is mathematically equivalent to<disp-formula><mml:math id="M13"><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi><mml:mo>∼</mml:mo><mml:mtext>Normal</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula><mml:math id="M14"><mml:mi>ξ</mml:mi><mml:mo>∼</mml:mo><mml:mtext>Normal</mml:mtext><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ξ</mml:mi><mml:mi>′</mml:mi><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:math></disp-formula></p>
      <p>Such transformation is referred to as <italic>noncentered parameterization</italic> (a.k.a. the “Matt trick”) by the Stan Development Team (<xref rid="bib104" ref-type="bibr">2016</xref>), and it effectively reduces the dependence between <italic>μ</italic><sub><italic>ξ</italic></sub>, <italic>ξ</italic>, and <italic>σ</italic><sub><italic>ξ</italic></sub> and increases the effective sample size.</p>
      <p>In addition to reparameterization, we use vectorization to improve our MCMC sampling. For example, suppose that one experiment consists of <italic>N</italic> participants; then, its individual-level parameter <italic>ξ</italic> is an <italic>N</italic>-dimensional vector. Instead of declaring <italic>ξ</italic> as</p>
      <p>
        <disp-formula id="E7">
          <mml:math id="m33">
            <mml:mtext>for</mml:mtext>
            <mml:mspace width="1em"/>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:mi>n</mml:mi>
            <mml:mspace width="1em"/>
            <mml:mtext>in</mml:mtext>
            <mml:mspace width="1em"/>
            <mml:mn>1</mml:mn>
            <mml:mo>…</mml:mo>
            <mml:mi>N</mml:mi>
            <mml:mo stretchy="false">)</mml:mo>
            <mml:mo>,</mml:mo>
          </mml:math>
        </disp-formula>
        <disp-formula>
          <mml:math id="M15">
            <mml:msub>
              <mml:mrow>
                <mml:mi>ξ</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mo stretchy="false">[</mml:mo>
                <mml:mi>n</mml:mi>
                <mml:mo stretchy="false">]</mml:mo>
              </mml:mrow>
            </mml:msub>
            <mml:mo>∼</mml:mo>
            <mml:mtext>Normal</mml:mtext>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mi>μ</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>ξ</mml:mi>
              </mml:mrow>
            </mml:msub>
            <mml:mo>,</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mi>σ</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>ξ</mml:mi>
              </mml:mrow>
            </mml:msub>
            <mml:mo stretchy="false">)</mml:mo>
            <mml:mo>,</mml:mo>
          </mml:math>
        </disp-formula>
      </p>
      <p>we vectorize it as</p>
      <p><disp-formula id="E8"><mml:math id="m34"><mml:mi>ξ</mml:mi><mml:mo>∼</mml:mo><mml:mtext>Normal</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula>to make full use of Stan’s vectorization of all sampling statements. As a rule of thumb, one may want to use vectorization for as long as this is possible. All of hBayesDM’s models that implement both reparameterization and vectorization can be found in the directory <code position="float" orientation="portrait" xml:space="preserve">…\R\R-x.x.x\library\hBayesDM\stan</code>, or the path can be retrieved by calling the following R command: <code position="float" orientation="portrait" xml:space="preserve">file.path(.libPaths(), "hBayesDM",
                        "stan")</code>. Those interested in more details about optimizing Stan models can read the Stan reference manual (<ext-link ext-link-type="uri" xlink:href="http://mc-stan.org/documentation/">http://mc-stan.org/documentation/</ext-link>, chapter on “Optimizing Stan Code”).</p>
    </sec>
    <sec>
      <title>Computing Log-Likelihood Inside Stan Models</title>
      <p>The hBayesDM package provides two model performance indices: the leave-one-out infor mation criterion (LOOIC) and the widely applicable information criterion (WAIC). We follow Vehtari, Gelman, and Gabry (<xref rid="bib104" ref-type="bibr">2016</xref>) in computing and monitoring Stan’s pointwise log-likelihood in the <sans-serif>generated quantities</sans-serif> block. The generated quantities block serves as the postprocessing of the model, with its commands being executed only after the HMC sampling. Therefore, it does not significantly increase the time required for Bayesian inference. The generated quantities block is particularly useful when users intend to monitor pointwise log-likelihood (Vehtari et al., <xref rid="bib104" ref-type="bibr">2016</xref>), reproduce predictive values or obtain internal model variables. Practically, we initialize the pointwise log-likelihood to be 0 for each participant, then we repeat the same model of the “model” block in the generated quantities block, except we replace the sampling statement with the explicit computation of pointwise log-likelihood. Please be aware that in many RLDM tasks (especially RL tasks), choices on one trial are dependent on those on other trials. Therefore, instead of gathering the trial-by-trial log-likelihood, we sum them over per participant and obtain the pointwise log-likelihood at the participant level. Below is the pseudocode as an example of what is described above:</p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      model {</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      …</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">       for (i in 1:N) {</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">        for (t in 1:T) {</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">         Choice[i, t] ∼ categorical_logit(ev);</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      …</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      }</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      Generated quantities {</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      …</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">       for (i in 1:N) {</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">        log_lik[i] = 0;</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">        for (t in 1:T) {</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">         log_lik[i]=log_lik[i] + categorical_logit_lpmf(Choice[i, t] | ev);</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      …</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      }</code>
      </p>
      <p>Once we have the pointwise log-likelihood per participant, it is straightforward to compute both LOOIC and WAIC (Vehtari et al., <xref rid="bib104" ref-type="bibr">2016</xref>). Both LOOIC and WAIC provide estimates of the out-of-sample predictive accuracy in a fully Bayesian way, which samples new participants from the hierarchical group, generates new data from those new participants, and evaluates how well a model makes predictions about the new dataset. What makes LOOIC and WAIC more reliable than the Akaike information criterion (AIC; Akaike, <xref rid="bib9" ref-type="bibr">1987</xref>; Bozdogan, <xref rid="bib18" ref-type="bibr">1987</xref>) and the deviance information criterion (DIC; Spiegelhalter, Best, Carlin, &amp; van der Linde, <xref rid="bib103" ref-type="bibr">2002</xref>) is that both LOOIC and WAIC use the pointwise log-likelihood of the full Bayesian posterior distribution, whereas AIC and DIC use only point estimates to calculate the model evidence. We used the functions included in the loo package to (Vehtari et al., <xref rid="bib104" ref-type="bibr">2016</xref>) generate the LOOIC and WAIC values. Both LOOIC and WAIC are on the information criterion scale; thus, lower values of LOOIC or WAIC indicate better out-of-sample prediction accuracy of the candidate model.</p>
    </sec>
  </sec>
  <sec>
    <title>STEP-BY-STEP TUTORIALS FOR THE hBayesDM PACKAGE</title>
    <sec>
      <title>Installing hBayesDM: Prerequisites</title>
      <p>Before installing hBayesDM, it is necessary to have up-to-date versions of R (version 3.3.2 or later is recommended) and RStan on your machine. RStudio (<ext-link ext-link-type="uri" xlink:href="http://www.rstudio.com">www.rstudio.com</ext-link>) is not required but is strongly recommended. Typically, RStan can be installed just by entering the following command into the R console:</p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve"><bold>install.packages</bold>("rstan",
                                    dependencies=TRUE)</code>
      </p>
      <p>For Windows, it is necessary to install Rtools before installing RStan. Instructions for installing Rtools on a Windows machine can be found at this link (<ext-link ext-link-type="uri" xlink:href="https://github.com/stan-dev/rstan/wiki/Install-Rtools-for-Windows">https://github.com/stan-dev/rstan/wiki/Install-Rtools-for-Windows</ext-link>). After RStan (as well as Rtools, for Windows users) is installed, it is recommended to restart R (or RStudio) and test the installation before moving on to install hBayesDM. This can be accomplished by trying to fit the “Eight Schools” example that is provided on RStan’s Getting Started page (<ext-link ext-link-type="uri" xlink:href="https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started">https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started</ext-link>).</p>
    </sec>
    <sec>
      <title>Installing hBayesDM</title>
      <p>The hBayesDM package is available from the Comprehensive R Archive Network (CRAN) and GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/CCS-Lab/hBayesDM">https://github.com/CCS-Lab/hBayesDM</ext-link>). To install hBayesDM from CRAN, use the following call:</p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve"><bold>install.packages</bold>("hBayesDM",
                                    dependencies=TRUE)</code>
      </p>
      <p>For Mac or Linux computers, we recommend installing the latest version of hBayesDM from GitHub:</p>
      <p>
        <inline-graphic xlink:href="cpsy-01-24-g008.jpg"/>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve"><bold>if</bold> (!<bold>require</bold>(devtools)) install.packages("devtools")</code>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">devtools::<bold>install_github</bold>("CCS-Lab/hBayesDM")</code>
      </p>
      <p>Stan models installed through GitHub are precompiled, so the models will run immediately without additional compilation time. As of March 2017, this feature is not available for Windows computers yet.</p>
    </sec>
    <sec>
      <title>How to Use hBayesDM: Navigating</title>
      <p>After hBayesDM has been installed correctly, the package must be loaded into the current environment. Users will be able to access all the functions that are included in the package after hBayesDM is loaded. To load hBayesDM, use the following command:</p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve"><bold>library</bold>(hBayesDM)</code>
      </p>
      <p>After loading the package, users should see a message that displays the version number of the current hBayesDM install. For a list of all the models available in the package, one can refer to the package help files by using the following command:</p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve"><bold>?</bold>hBayesDM</code>
      </p>
      <p>This will bring up a help file that contains a general description of the package along with a list of all RLDM tasks and models that can be fit with hBayesDM. One can follow the links provided in the help file to find in-depth documentation describing how to fit each model.</p>
    </sec>
    <sec>
      <title>How to Use hBayesDM: Model Fitting</title>
      <p>The conceptual framework of computational modeling and the four steps of doing HBA with hBayesDM are illustrated graphically in <xref ref-type="fig" rid="F3">Figure 3</xref>. These steps are described in further detail below. To exemplify these steps, the four models of the orthogonalized GNG task will be fit and compared using the hBayesDM package. As a reminder, users can refer to the help file for any model to learn how to run a real-data example. Also, commands and input arguments for running or evaluating a model are very similar or the same for all models. Thus, if users learn how to run one model, they can also easily run other models.</p>
      <fig id="F3" orientation="portrait" position="float">
        <label><bold>Figure 3.</bold> </label>
        <caption>
          <p><bold>Pipeline for performing computational modeling with hBayesDM.</bold> Four steps are involved in hierarchical Bayesian analysis (HBA): (1) preparing the data, (2) fitting the candidate models, (3) extracting and visualizing the parameters and/or variables, and (4) model comparison (see the text for details).</p>
        </caption>
        <graphic xlink:href="cpsy-01-24-g003"/>
      </fig>
      <sec>
        <title>Prepare the data</title>
        <p>To begin, all subjects’ data (for the current analysis) should be combined into a single text (*.txt) file, in which rows represent trial-by-trial observations and columns represent the variables of interest. The first row of the text file must contain the column headers (i.e., the names) of the variables of interest.</p>
        <p>Subjects’ data must contain variable headers that are consistent with the column names specified in the model help file (see <xref ref-type="table" rid="T1">Table 1</xref>). For example, in the orthogonalized GNG task, the columns should be labeled “subjID,” “cue,” “keyPressed,” and “outcome,” where “subjID” is a subject-specific identifier, “cue” is a nominal integer specifying the cue shown on the given trial, “keyPressed” is a binary value representing whether a key was (1) or was not (0) pressed on the given trial, and “outcome” represents a positive (1), negative (–1), or neutral (0) outcome on the given trial. The text file may also contain other data/column headers, but only the aforementioned variables will be used for the modeling analysis. All of the information above for each model can be found in the package help files, which can be accessed with R’s help command (e.g., for the orthogonalized GNG Model 1, <code position="float" orientation="portrait" xml:space="preserve"><bold>?</bold>gng_m1)</code>. Across all the models implemented in hBayesDM, the number of trials within the data file is allowed to vary across subjects, but the file should contain no missing (N/A) data. If some trials do contain N/A data (e.g., <code position="float" orientation="portrait" xml:space="preserve">outcome=NA</code>), remove these trials before continuing. If trials containing N/A data are not removed prior to the model fitting, they will be removed automatically and the user will receive a warning message.</p>
        <p>Sample data can be retrieved from the package folder with the R command shown below. Note that the file name of sample (example) data for a given task is <bold>taskName_exampleData.txt</bold> (e.g., dd_exampleData.txt, igt_exampleData.txt, or gng_exampleData.txt):</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">dataPath = <bold>system.file</bold>("extdata/gng_exampleData.txt", package="hBayesDM")</code>
        </p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">gng_data = <bold>read.table</bold>(dataPath,
                                        header=TRUE)</code>
        </p>
        <p>If data are downloaded from an external source to "<code position="float" orientation="portrait" xml:space="preserve">/home/user1/Downloads</code>", the user may specify the path using a character string like the one below:</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">dataPath = "/home/user1/Downloads/gng_exampleData.txt"</code>
        </p>
      </sec>
      <sec>
        <title>Fit candidate models</title>
        <p>Since hBayesDM uses MCMC sampling to generate posterior distributions, many arguments may be passed to Stan through the model functions in order to fine-tune the sampling behavior. Some arguments can also be used for user convenience. <xref ref-type="table" rid="T2">Table 2</xref> shows the arguments that are common to all model functions in hBayesDM. Note that in the table an asterisk (*) denotes an argument that may unpredictably change the computation time and/or sampling behavior of the MCMC chains (Hoffman &amp; Gelman, <xref rid="bib57" ref-type="bibr">2014</xref>). For this reason, it is advised that only advanced users alter the default values of these arguments.</p>
        <table-wrap id="T2" orientation="portrait" position="float">
          <label><bold>Table 2.</bold> </label>
          <caption>
            <p>List of input arguments common to all model functions in the hBayesDM package</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr valign="bottom">
                <th align="left" rowspan="1" colspan="1">
                  <bold>Argument</bold>
                </th>
                <th align="left" rowspan="1" colspan="1">
                  <bold>Required From User</bold>
                </th>
                <th align="left" rowspan="1" colspan="1">
                  <bold>Description</bold>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">data</code>
                </td>
                <td align="left" rowspan="1" colspan="1">Yes (default = “choose”)</td>
                <td align="left" rowspan="1" colspan="1">Full path to text file containing data to be used for analysis</td>
              </tr>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">niter</code>
                </td>
                <td align="left" rowspan="1" colspan="1">No (default = 2,000 or higher)</td>
                <td align="left" rowspan="1" colspan="1">Number of (accepted) samples to be generated by Stan’s HMC sampler</td>
              </tr>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">nwarmup</code>
                </td>
                <td align="left" rowspan="1" colspan="1">No (default = 1,000)</td>
                <td align="left" rowspan="1" colspan="1">Number of (accepted) samples to be discarded from the beginning of the sampling procedure</td>
              </tr>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">ncore</code>
                </td>
                <td align="left" rowspan="1" colspan="1">No (default = 1)</td>
                <td align="left" rowspan="1" colspan="1">Number of CPUs to use for parallel computing</td>
              </tr>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">nchain</code>
                </td>
                <td align="left" rowspan="1" colspan="1">No (default = 4)</td>
                <td align="left" rowspan="1" colspan="1">Number of MCMC chains to run</td>
              </tr>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">nthin</code>
                </td>
                <td align="left" rowspan="1" colspan="1">No (default = 1)</td>
                <td align="left" rowspan="1" colspan="1">Every <italic>n</italic>th (accepted) sample from the sampling procedure will be saved. All other samples will be discarded</td>
              </tr>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">inits</code>
                </td>
                <td align="left" rowspan="1" colspan="1">No (default = “random”)</td>
                <td align="left" rowspan="1" colspan="1">Initial values for the HMC sampler</td>
              </tr>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">indPars</code>
                </td>
                <td align="left" rowspan="1" colspan="1">No (default = “mean”)</td>
                <td align="left" rowspan="1" colspan="1">How to summarize the parameters upon completion (mean, median, or mode)</td>
              </tr>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">saveDir</code>
                </td>
                <td align="left" rowspan="1" colspan="1">No (default = NULL)</td>
                <td align="left" rowspan="1" colspan="1">Path to directory where hBayesDM object should be saved upon completion</td>
              </tr>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">email</code>
                </td>
                <td align="left" rowspan="1" colspan="1">No (default = NULL)</td>
                <td align="left" rowspan="1" colspan="1">Email address that will be sent a message upon sampling completion</td>
              </tr>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">modelRegressor</code>
                </td>
                <td align="left" rowspan="1" colspan="1">No (default = FALSE)</td>
                <td align="left" rowspan="1" colspan="1">Exporting model-based regressors? TRUE or FALSE</td>
              </tr>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">*adapt_delta</code>
                </td>
                <td align="left" rowspan="1" colspan="1">No (default = 0.95)</td>
                <td align="left" rowspan="1" colspan="1">Acceptance probability of the HMC sampler</td>
              </tr>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">*stepsize</code>
                </td>
                <td align="left" rowspan="1" colspan="1">No (default = 1)</td>
                <td align="left" rowspan="1" colspan="1">Size of each leapfrog step that the MCMC sampler can take on each new iteration.</td>
              </tr>
              <tr valign="top">
                <td align="left" rowspan="1" colspan="1">
                  <code position="float" orientation="portrait" xml:space="preserve">*max_treedepth</code>
                </td>
                <td align="left" rowspan="1" colspan="1">No (default = 10)</td>
                <td align="left" rowspan="1" colspan="1">Number of leapfrog steps that the MCMC sampler can take on each new iteration.</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>Below, the <code position="float" orientation="portrait" xml:space="preserve">gng_m1</code> model is fit using the sample data that come with the package. The command indicates that three MCMC chains are to be run and three cores are to be used for parallel computing. Note that parallel computing is only useful for multiple chains; it is common to use one core per chain, to maximize sampling efficiency. If <code position="float" orientation="portrait" xml:space="preserve">"example"</code> is entered as an argument for <code position="float" orientation="portrait" xml:space="preserve">data</code>, hBayesDM will use the sample data for the task. Convenience arguments such as <code position="float" orientation="portrait" xml:space="preserve">saveDir</code> can be used to save the resulting model output to a local directory. This is useful when the model fitting is expected to take a long period of time and users want to ensure that the data are saved. Also, the <code position="float" orientation="portrait" xml:space="preserve">email</code> argument allows users to be notified by an e-mail message upon the completion of model fitting.</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">output1 = <bold>gng_m1</bold>("example",niter=2000,nwarmup=1000,nchain=4,</code>
        </p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">      ncore=4, saveDir="/data/Models",</code>
        </p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">      email="email@gmail.com")</code>
        </p>
        <p>A model function has default values for all arguments except <code position="float" orientation="portrait" xml:space="preserve">data</code>, so the command above is equivalent (aside from the <code position="float" orientation="portrait" xml:space="preserve">saveDir</code> and <code position="float" orientation="portrait" xml:space="preserve">email</code> arguments) to the more concise call below:</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">output1 = <bold>gng_m1</bold>("example",
                                        nchain=4, ncore=4)</code>
        </p>
        <p>If the <code position="float" orientation="portrait" xml:space="preserve">data</code> argument is left blank, a file browser window will appear, allowing the user to manually select the text file with their file browser. The default input arguments for each model were selected on the basis of our experience with the sampling behavior of each model with respect to the data we have access to. For each model being fitted, <code position="float" orientation="portrait" xml:space="preserve">niter</code> and <code position="float" orientation="portrait" xml:space="preserve">nwarmup</code> values (and control parameters, for advanced users) might need to be experimented with to ensure that the target posterior distributions will converge. Later sections will discuss convergence in more detail.</p>
        <p>Executing any model function command in hBayesDM will generate messages for the user within the R console, exemplified by <xref ref-type="fig" rid="F4">Figure 4A</xref>. It will take up to approximately 3 min (with the <code position="float" orientation="portrait" xml:space="preserve">gng_m1</code> model and "<code position="float" orientation="portrait" xml:space="preserve">example</code>" data) for the model fitting to complete. Note that you may get warning messages about “numerical problems” or that there are a certain number of “divergent transitions after warm-up.” When we check our models with example datasets, warning messages appear mostly at the beginning of the warm-up period, and very few divergent transitions occur after warm-up. In such cases, the warnings can be ignored. For a technical description of these (and other) sampling issues, see Appendix D of the Stan Reference Manual. When the model fitting is complete, the R console will print the message in <xref ref-type="fig" rid="F4">Figure 4B</xref>. The output data will be stored in <code position="float" orientation="portrait" xml:space="preserve">output1</code>, a class <code position="float" orientation="portrait" xml:space="preserve">hBayesDM</code> object containing a list with the six following elements:</p>
        <list list-type="simple">
          <list-item>
            <label>1. </label>
            <p><code position="float" orientation="portrait" xml:space="preserve">model</code>:</p>
            <p>Name of the fitted model (i.e., <code position="float" orientation="portrait" xml:space="preserve">output1$model</code> is <code position="float" orientation="portrait" xml:space="preserve">"gng_m1"</code>)</p>
          </list-item>
          <list-item>
            <label>2. </label>
            <p><code position="float" orientation="portrait" xml:space="preserve">allIndPars</code>:</p>
            <p>Summary of individual subjects’ parameters (default: posterior <italic>mean values of individual parameters</italic>). Users can also choose to use the posterior <italic>median</italic> or <italic>mode</italic> in the model function command (e.g., <code position="float" orientation="portrait" xml:space="preserve">indPars="mode"</code>). See <xref ref-type="fig" rid="F4">Figure 4C</xref> to view the values of <code position="float" orientation="portrait" xml:space="preserve">allIndPars</code> for <code position="float" orientation="portrait" xml:space="preserve">gng_m1</code>, printed to the R console.</p>
          </list-item>
          <list-item>
            <label>3. </label>
            <p><code position="float" orientation="portrait" xml:space="preserve">parVals</code>:</p>
            <p>Posterior MCMC samples for all parameters. Note that hyper (group) posterior mean parameters are indicated by <code position="float" orientation="portrait" xml:space="preserve">mu_PARAMETER</code> (e.g., <code position="float" orientation="portrait" xml:space="preserve">mu_xi, mu_ep, mu_rho</code>). These values are extracted from the <code position="float" orientation="portrait" xml:space="preserve">fit</code> element with RStan’s <code position="float" orientation="portrait" xml:space="preserve">extract</code>() function.</p>
          </list-item>
          <list-item>
            <label>4. </label>
            <p><code position="float" orientation="portrait" xml:space="preserve">fit</code>:</p>
            <p>An <code position="float" orientation="portrait" xml:space="preserve">rstan</code> object is the output of RStan’s <code position="float" orientation="portrait" xml:space="preserve">stan()</code> function. If users would like to use Rstan commands, the commands should be performed on this object. See <xref ref-type="fig" rid="F4">Figure 4D</xref> for a summary of <code position="float" orientation="portrait" xml:space="preserve">fit</code> printed to the R console.</p>
          </list-item>
          <list-item>
            <label>5. </label>
            <p><code position="float" orientation="portrait" xml:space="preserve">rawdata</code>:</p>
            <p>Raw trial-by-trial data used for HBA. The raw data are provided in the output to allow users to easily access them and compare the trial-by-trial model-based regressors (e.g., prediction errors) with the choice data.</p>
          </list-item>
          <list-item>
            <label>6. </label>
            <p><code position="float" orientation="portrait" xml:space="preserve">modelRegressor</code> (optional):</p>
            <p>Trial-by-trial model-based regressors, such as prediction errors, the value of the chosen option, and so forth. For each model, we preselected appropriate model-based regressors. Users can refer to the package help files for the details. Currently (version 0.3.0), this feature is available only for the orthogonalized GNG task.</p>
            <p>
              <fig id="F4" orientation="portrait" position="float">
                <label><bold>Figure 4.</bold> </label>
                <caption>
                  <p><bold>Outputs of model fitting and model summary.</bold> (A) Sample message displayed in the R console after a model function is called. Here, the Details section of the output shows information relevant to both the arguments passed to the function and the data specified by the user. The console also shows the progression of the MCMC sampling. (B) Upon completion of the model fitting, a message is presented to the user. (C, D) Displays from which users can retrieve summary statistics of the (C) individual model parameters and (D) Stan model fits (for the Stan fit object stored as <monospace>output1</monospace>).</p>
                </caption>
                <graphic xlink:href="cpsy-01-24-g004"/>
              </fig>
            </p>
          </list-item>
        </list>
      </sec>
      <sec>
        <title>Plot model parameters</title>
        <p>It is important to both visually and quantitatively diagnose MCMC performance (i.e., visually check whether the MCMC samples are well mixed and converge to stationary distributions). For visual diagnostics of hyper (group) parameters, users can call <code position="float" orientation="portrait" xml:space="preserve">plot.hBayesDM()</code> or just <code position="float" orientation="portrait" xml:space="preserve">plot(),</code> which searches for an extension function that contains the class name. The class of any hBayesDM output is <code position="float" orientation="portrait" xml:space="preserve">hBayesDM</code>. For a quantitative check on convergence, the Gelman–Rubin convergence diagnostic (Gelman &amp; Rubin, <xref rid="bib43" ref-type="bibr">1992</xref>) for each parameter is computed by RStan and stored in the <code position="float" orientation="portrait" xml:space="preserve">fit</code> element of the hBayesDM model output. These values may be seen in <xref ref-type="fig" rid="F4">Figure 4D</xref>, where <inline-formula><mml:math id="m35"><mml:mover accent="true"><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> (<code position="float" orientation="portrait" xml:space="preserve">Rhat</code>) is the Gelman–Rubin index used to assess the convergence of the MCMC samples. <inline-formula><mml:math id="m36"><mml:mover accent="true"><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> values close to 1.00 indicate that the MCMC chains have converged to stationary target distributions. Values greater than 1.1 are typically considered to represent inadequate convergence. For all models included in hBayesDM, the <inline-formula><mml:math id="m37"><mml:mover accent="true"><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> values are 1.00 for most parameters, or at most 1.04 when tested on the example datasets.</p>
        <p>Users can also use trace plots to visually check the MCMC samples. The command shown below (with the font size for the plot set to 11) shows how to use the <code position="float" orientation="portrait" xml:space="preserve">plot()</code> command to create trace plots of hyper (group) parameters (see <xref ref-type="fig" rid="F5">Figure 5A</xref> for an example):</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve"><bold>plot</bold>(output1, type="trace",
                                        fontSize=11)</code>
        </p>
        <p>The trace plots indicate that the MCMC samples are indeed well mixed and have converged, which is consistent with their <inline-formula><mml:math id="m38"><mml:mover accent="true"><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> values. Note that the plots in <xref ref-type="fig" rid="F5">Figure 5A</xref> exclude burn-in samples. Users can include burn-in (warm-up) MCMC samples to better understand the sampling behavior, if necessary. The following function call produces the plot in <xref ref-type="fig" rid="F5">Figure 5B</xref>, which includes burn-in samples:</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve"><bold>plot</bold>(output1, type="trace",
                                        inc_warmup=T)</code>
        </p>
        <p>Users can also plot the posterior distributions of the hyper (group) parameters with the default <code position="float" orientation="portrait" xml:space="preserve">plot()</code> function by not specifying the <code position="float" orientation="portrait" xml:space="preserve">type</code> argument. The following function call produces the plot in <xref ref-type="fig" rid="F5">Figure 5C</xref>:</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve"><bold>plot</bold>(output1)</code>
        </p>
        <fig id="F5" orientation="portrait" position="float">
          <label><bold>Figure 5.</bold> </label>
          <caption>
            <p><bold>Visualization of the parameters of the <monospace>gng_m1</monospace> model.</bold> (A) Trace plots for the group-level (hyper)parameters of the <monospace>gng_m1</monospace> model. The three chains show excellent mixing, suggesting that they have converged to their target distributions. (B) The same trace plots as in panel A; however, these versions also include the warm-up (burn-in) samples, highlighted by the gray back ground shading. (C) Posterior distributions of the group-level (hyper)parameters. (D) Individual-level posterior distributions. The red shading and tailed white areas represent the 80% and 95% kernel density estimates, respectively. Note that all plots above were generated directly from hBayesDM and RStan functions, with no further modifications.</p>
          </caption>
          <graphic xlink:href="cpsy-01-24-g005"/>
        </fig>
        <p>To visualize the individual parameters, users can use the <code position="float" orientation="portrait" xml:space="preserve">plotInd()</code> command. The following call plots each individual’s <italic>ϵ</italic> (learning rate) parameter (see <xref ref-type="fig" rid="F5">Figure 5D</xref>):</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve"><bold>plotInd</bold>(output1,
                                        "ep")</code>
        </p>
      </sec>
      <sec>
        <title>Compare models (and groups)</title>
        <p>To compare multiple models using LOOIC or WAIC values, the first step is to fit all models in the same manner as the <code position="float" orientation="portrait" xml:space="preserve">gng_m1</code> example above. The following commands will fit the rest of the orthogonalized GNG models available within hBayesDM:</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">output2 = <bold>gng_m2</bold>("example",
                                        nchain=4, ncore=4)</code>
        </p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">output3 = <bold>gng_m3</bold>("example",
                                        nchain=4, ncore=4)</code>
        </p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">output4 = <bold>gng_m4</bold>("example",
                                        nchain=4, ncore=4)</code>
        </p>
        <p>Note that each model should be checked for convergence in the same manner as <code position="float" orientation="portrait" xml:space="preserve">gng_m1</code>. If for any reason a model fails to converge, refit the model after model diagnostics (see Improving sampling performance in hBayesDM) or exclude the model from the model comparisons.</p>
        <p>Next, users can assess the model fits using the <code position="float" orientation="portrait" xml:space="preserve">printFit()</code> command, which is a convenient way to summarize the LOOIC and WAIC of all considered models. Assuming that all four models’ outputs are named <code position="float" orientation="portrait" xml:space="preserve">output1</code> (gng_m1), <code position="float" orientation="portrait" xml:space="preserve">output2</code> (gng_m2), <code position="float" orientation="portrait" xml:space="preserve">output3</code> (gng_m3), and <code position="float" orientation="portrait" xml:space="preserve">output4</code> (gng_m4), their model fits can be simultaneously summarized by the following command, the results of which are illustrated in </p>
        <p>
          <inline-graphic xlink:href="cpsy-01-24-g009.jpg"/>
        </p>
        <fig id="F6" orientation="portrait" position="float">
          <label><bold>Figure 6.</bold> </label>
          <caption>
            <p><bold>Bayesian model selection and group comparison.</bold> (A) Sample output of the <monospace>printFit()</monospace> command, which prints model performance indices (LOOIC and WAIC) for competing model(s). The resulting table shows the name of each model, followed by their LOOIC and WAIC values. Lower LOOIC and WAIC values correspond to better model performance. Here, <monospace>gng_m4</monospace> (highlighted with a dashed box) has the lowest values. (B) Results from the <monospace>plotHDI()</monospace> function, showing the 95% highest density interval (HDI) of the posterior distribution difference between two group parameters. The red bar indicates the 95% HDI.</p>
          </caption>
          <graphic xlink:href="cpsy-01-24-g006"/>
        </fig>
        <p>By default, the <code position="float" orientation="portrait" xml:space="preserve">printFit</code> function uses LOOIC, which is preferable to WAIC when there are influential observations (Vehtari et al., <xref rid="bib104" ref-type="bibr">2016</xref>). Lower LOOIC or WAIC values indicate better model performance; thus, Model 4 has the best LOOIC and WAIC, as compared to all other models. Users interested in more detailed information, including standard errors and the expected log pointwise predictive density (elpd), can use the <code position="float" orientation="portrait" xml:space="preserve">extract_ic()</code> function (e.g., <code position="float" orientation="portrait" xml:space="preserve">extract_ic(output3)</code>) to extract this information. Note that the <code position="float" orientation="portrait" xml:space="preserve">extract_ic()</code> function can be used only for a single model output, unlike <code position="float" orientation="portrait" xml:space="preserve">printFit()</code>.</p>
        <p>Other model comparison methods exist, including the simulation method (a.k.a. absolute model performance; Ahn et al., <xref rid="bib3" ref-type="bibr">2008</xref>; Ahn et al., <xref rid="bib8" ref-type="bibr">2014</xref>; Guitart-Masip et al., <xref rid="bib50" ref-type="bibr">2012</xref>; Steingroever, Wetzels, &amp; Wagenmakers, <xref rid="bib105" ref-type="bibr">2014</xref>), parameter recovery (Ahn, Krawitz, et al., <xref rid="bib4" ref-type="bibr">2011</xref>; Ahn et al., <xref rid="bib8" ref-type="bibr">2014</xref>), and the generalization criterion (Ahn et al., <xref rid="bib3" ref-type="bibr">2008</xref>; Busemeyer &amp; Wang, <xref rid="bib20" ref-type="bibr">2000</xref>). Models that show the best goodness of fit may not perform well according to other indices (e.g., Ahn et al., <xref rid="bib8" ref-type="bibr">2014</xref>), so it is recommended that researchers use multiple model comparison methods if this is at all possible.</p>
      </sec>
      <sec>
        <title>Group comparisons</title>
        <p>Having selected the best-fitting model, users may want to use that model to compare the parameter estimates of different populations. With a hierarchical Bayesian framework, users can compare the model parameters of multiple groups or within-subjects conditions in fully Bayesian ways (e.g., Ahn et al., <xref rid="bib8" ref-type="bibr">2014</xref>; Chan et al., <xref rid="bib24" ref-type="bibr">2014</xref>; Fridberg, Ahn, Kim, Bishara, &amp; Stout, <xref rid="bib39" ref-type="bibr">2010</xref>; Kruschke, <xref rid="bib70" ref-type="bibr">2014</xref>; Vassileva et al., <xref rid="bib112" ref-type="bibr">2013</xref>). The (posterior) distributions show the uncertainty in the estimated parameters, and we can use the posterior highest density interval (HDI) to summarize the uncertainty. The <italic>95% HDI</italic> refers to “the span of values that are most credible and cover 95% of the posterior distribution” (Kruschke, <xref rid="bib70" ref-type="bibr">2014</xref>). To examine the difference in a particular parameter between two groups, we can calculate the difference between the hyperdistributions across the groups and examine the credible interval of this difference (i.e., its 95% HDI; Kruschke, <xref rid="bib68" ref-type="bibr">2010</xref>, <xref rid="bib69" ref-type="bibr">2011</xref>). Note that this is different from testing a null hypothesis (e.g., whether or not two groups are the same on the parameter of interest), for which Bayesian hypothesis testing (e.g., the Bayes factor; Kass &amp; Raftery, <xref rid="bib64" ref-type="bibr">1995</xref>; Myung &amp; Pitt, <xref rid="bib85" ref-type="bibr">1997</xref>; Wagenmakers, <xref rid="bib116" ref-type="bibr">2007</xref>) or a region of practical equivalence (ROPE) around the null value should be used instead (Kruschke, <xref rid="bib69" ref-type="bibr">2011</xref>, <xref rid="bib70" ref-type="bibr">2014</xref>).</p>
        <p>As an example, we compare two groups’ model parameters in a Bayesian fashion. First, prepare each group’s data as separate text files:</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">data_group1 = " ∼/Project_folder/gng_data_group1.txt"</code>
        </p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">data_group2 = "∼/Project_folder/gng_data_group2.txt"</code>
        </p>
        <p>Here, <code position="float" orientation="portrait" xml:space="preserve">gng_data_group1.txt</code> and <code position="float" orientation="portrait" xml:space="preserve">gng_data_group2.txt</code> contain all the data for the Group 1 subjects and the Group 2 subjects, respectively. Next, the model is fit in the same manner as before for each group separately. We recommend using the same numbers of chains and MCMC samples for each group:</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">output_group1 = <bold>gng_m4</bold>(data_group1,nchain=4, ncore=4)</code>
        </p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">output_group2 = <bold>gng_m4</bold>(data_group2, nchain=4, ncore=4)</code>
        </p>
        <p>Make sure to check whether the MCMC samples are well mixed and converge to stationary distributions (see Plot model parameters). Next, compute the difference between the hyper (group) parameters of interest by making a simple subtraction. For example, if we want to compare the Pavlovian bias parameters (<italic>π</italic>) across the two groups:</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">diffDist = output_group1$parVals$mu_pi - output_group2$parVals$mu_pi</code>
        </p>
        <p>The command above subtracts the <code position="float" orientation="portrait" xml:space="preserve">mu_pi</code> parameter of Group 2 from that of Group 1. Note that these parameter values are stored within the <code position="float" orientation="portrait" xml:space="preserve">parVals</code> element of an hBayesDM object. To generate the credible interval of the difference between the groups, users can use the following command, which will print the 95% HDI to the R console:</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve"><bold>HDIofMCMC</bold>(diffDist)</code>
        </p>
        <p>Users can also visually inspect the 95% HDI with the following command (the 95% HDI is also printed to the R console in response to the command):</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve"><bold>plotHDI</bold>(diffDist)</code>
        </p>
        <p><xref ref-type="fig" rid="F6">Figure 6B</xref> shows the result of the <code position="float" orientation="portrait" xml:space="preserve">plotHDI</code>() command above. The red bar along the bottom of the plot encompasses the 95% HDI.</p>
      </sec>
      <sec>
        <title>Improving sampling performance in hBayesDM</title>
        <p>When chains fail to converge (e.g., <inline-formula><mml:math id="m39"><mml:mover accent="true"><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> &gt; 1.10 or the MCMC chains are poorly mixed when visually inspected), users are recommended to use different starting values for multiple chains or to modify several HMC sampling parameters to improve the performance. Users can set <code position="float" orientation="portrait" xml:space="preserve">inits="fixed"</code> to use initial values that are provided by the developers (e.g., <code position="float" orientation="portrait" xml:space="preserve">output=<bold>gng_m4</bold>("example",
                            inits="fixed")</code>) or can provide their own starting values (e.g., <code position="float" orientation="portrait" xml:space="preserve">inits=c(0.1, 0.2, 10)</code> for <code position="float" orientation="portrait" xml:space="preserve">gng_m1)</code>.</p>
        <p>With respect to the HMC sampling parameters, though a model’s performance may be model- and parameter-specific, we provide a general approach for users to experiment with. Three parameters are relevant for sampling performance: the Metropolis acceptance rate (<italic>δ</italic>, default = 0.95), the initial HMC step size (<italic>ε</italic>, default = 1.0), and the maximum HMC steps per iteration (<italic>L</italic>; i.e., the maximum tree depth, default = 10). We refer readers to the Stan help file<code position="float" orientation="portrait" xml:space="preserve">(?stan)</code> for more details. With default sampling parameters and sample datasets, all models implemented in the hBayesDM package showed excellent convergence and mixing of the MCMC chains. However, if users notice any signs of poor convergence or mixing, we suggest that they increase <italic>δ</italic>, decrease <italic>ε</italic>, and/or increase <italic>L</italic>. The adjustment in hBayesDM is illustrated below (taking <code position="float" orientation="portrait" xml:space="preserve">gng_m1</code> as an example):</p>
        <p>
          <code position="float" orientation="portrait" xml:space="preserve">output1=
                                        <bold>gng_m1</bold>("example",nchain=4,
                                        ncore=4, adapt_delta=0.99, stepsize=0.5,
                                        max_treedepth=20)</code>
        </p>
        <p>Be aware that such an adjustment might dramatically increase the model estimation time and does not necessarily guarantee improved sampling performance. The failure of an adjusted model estimate might further suggest that such a model is not suitable for the current dataset, and that one may need to consider using alternative models to fit the data. If users encounter a problem and would like to seek help from the hBayesDM developers, they can ask questions to our mailing list (<ext-link ext-link-type="uri" xlink:href="https://groups.google.com/forum/#!forum/hbayesdm-users">https://groups.google.com/forum/#!forum/hbayesdm-users</ext-link>).</p>
      </sec>
    </sec>
    <sec>
      <title>Extracting Trial-by-Trial Regressors for Model-Based fMRI/EEG Analysis</title>
      <p>In model-based fMRI or EEG (Mars et al., <xref rid="bib78" ref-type="bibr">2008</xref>; see, e.g., O’Doherty et al., <xref rid="bib88" ref-type="bibr">2007</xref>), model-based time series of a latent cognitive process are generated by computational models, and then the time-series data are regressed again using fMRI or EEG data. This model-based neuroimaging approach has been particularly popular in cognitive neuroscience (e.g., Ahn, Krawits, et al., 2011; Behrens, Woolrich, Walton, &amp; Rushworth, <xref rid="bib15" ref-type="bibr">2007</xref>; Daw et al., <xref rid="bib30" ref-type="bibr">2006</xref>; Gläscher, Daw, Dayan, &amp; Doherty, <xref rid="bib44" ref-type="bibr">2010</xref>; Gläscher et al., <xref rid="bib45" ref-type="bibr">2009</xref>; Hampton et al., <xref rid="bib52" ref-type="bibr">2006</xref>; Iglesias et al., <xref rid="bib60" ref-type="bibr">2013</xref>; Kable &amp; Glimcher, <xref rid="bib62" ref-type="bibr">2007</xref>; O’Doherty, Critchley, Deichmann, &amp; Dolan, <xref rid="bib86" ref-type="bibr">2003</xref>; O’Doherty et al., <xref rid="bib88" ref-type="bibr">2007</xref>; Xiang et al., <xref rid="bib123" ref-type="bibr">2013</xref>) to identify brain regions that presumably implement a cognitive process of interest.</p>
      <p>The hBayesDM package allows users to extract various model-based regressors that can be used for model-based fMRI or EEG analysis (see <xref ref-type="fig" rid="F7">Figure 7</xref>). All model-based regressors are contained in the <code position="float" orientation="portrait" xml:space="preserve">modelRegressor</code> element. Note that in the current version (0.3.0), only the orthogonalized GNG task provides model-based regressors. The hBayesDM package provides the following model-based regressors, and users can convolve these trial-by-trial data with a hemodynamic response function using their favorite package (e.g., in the SPM package [<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm/">www.fil.ion.ucl.ac.uk/spm/</ext-link>], users can use the <code position="float" orientation="portrait" xml:space="preserve">parametric modulation</code> command with a model-based regressor):<list list-type="simple"><list-item><label>1. </label><p>Stimulus value: <italic>V</italic><sub><italic>t</italic></sub>(<italic>s</italic><sub><italic>t</italic></sub>) (stored as <code position="float" orientation="portrait" xml:space="preserve">SV</code>; available in <code position="float" orientation="portrait" xml:space="preserve">gng_m3</code> and <code position="float" orientation="portrait" xml:space="preserve">gng_m4)</code></p></list-item><list-item><label>2. </label><p>Action value: <italic>Q</italic><sub><italic>t</italic></sub>(<italic>go</italic>) (stored as <code position="float" orientation="portrait" xml:space="preserve">Qgo</code>) and <italic>Q</italic><sub><italic>t</italic></sub>(<italic>NoGo</italic>) (stored as <code position="float" orientation="portrait" xml:space="preserve">Qnogo</code>)</p></list-item><list-item><label>3. </label><p>Action weight: <italic>W</italic><sub><italic>t</italic></sub>(<italic>go</italic>) (stored as <code position="float" orientation="portrait" xml:space="preserve">Wgo</code>) and <italic>W</italic><sub><italic>t</italic></sub>(<italic>NoGo</italic>) (stored as <code position="float" orientation="portrait" xml:space="preserve">Wnogo</code>)</p></list-item></list></p>
      <fig id="F7" orientation="portrait" position="float">
        <label><bold>Figure 7.</bold> </label>
        <caption>
          <p><bold>Steps of model-based fMRI.</bold> With the hBayesDM package, users can perform the steps highlighted in blue. Users need to use a neuroimaging tool of their choice (e.g., SPM) to perform the steps highlighted in red.</p>
        </caption>
        <graphic xlink:href="cpsy-01-24-g007"/>
      </fig>
      <p>For example, to retrieve the stimulus value (= <italic>V</italic><sub><italic>t</italic></sub>(<italic>s</italic><sub><italic>t</italic></sub>)) of Group 1 in the previous example (the output is saved as <code position="float" orientation="portrait" xml:space="preserve">output_group1</code>), type:</p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      </code>
        <inline-graphic xlink:href="cpsy-01-24-g010.jpg"/>
      </p>
      <p>Here, <code position="float" orientation="portrait" xml:space="preserve">sv_all</code> is an array (the number of rows = number of subjects, the number of columns = number of trials). Similarly, to retrieve action weight values (<italic>W</italic><sub><italic>t</italic></sub>(<italic>go</italic>) and (<italic>W</italic><sub><italic>t</italic></sub>(<italic>NoGo</italic>)), type:</p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      </code>
        <inline-graphic xlink:href="cpsy-01-24-g011.jpg"/>
      </p>
      <p>
        <code position="float" orientation="portrait" xml:space="preserve">      </code>
        <inline-graphic xlink:href="cpsy-01-24-g012.jpg"/>
      </p>
      <p>Users can use these values for each subject to perform model-based fMRI analysis with their favorite neuroimaging package (O’Doherty et al., <xref rid="bib88" ref-type="bibr">2007</xref>). Once the model-based regressors are entered as parametric modulators in a generalized linear model (GLM), neuroimaging tools convolve the regressors with the hemodynamic response function and construct a new GLM. For step-by-step tutorials for model-based fMRI, see the following online documents: <ext-link ext-link-type="uri" xlink:href="http://www.translationalneuromodeling.org/uploads/Mathys2016_SPMZurich_ModelBasedfMRI.pdf">www.translationalneuromodeling.org/uploads/Mathys2016_SPMZurich_ModelBasedfMRI.pdf</ext-link>; <ext-link ext-link-type="uri" xlink:href="http://www.translationalneuromodeling.org/uploads/DiaconescuAndreea_Model-based_fMRI.pdf">www.translationalneuromodeling.org/uploads/DiaconescuAndreea_Model-based_fMRI.pdf</ext-link>; <ext-link ext-link-type="uri" xlink:href="http://www.srndna.org/conference2015/files/2014/11/SRNDNA_RL_Modeling_wkshp2.pdf">www.srndna.org/conference2015/files/2014/11/SRNDNA_RL_Modeling_wkshp2.pdf</ext-link>.</p>
    </sec>
  </sec>
  <sec>
    <title>FUTURE DIRECTIONS</title>
    <p>In the current version, the hBayesDM package selectively implements seven commonly used RLDM tasks and their models, but we plan to expand the list of tasks and models so that the hBayesDM can handle an extensive list of RLDM tasks. Latent model-based regressors are available only for a single task, but they will be available for more tasks in a future release of the hBayesDM package. We also plan to develop a graphical user interface using the Shiny framework (<ext-link ext-link-type="uri" xlink:href="https://shiny.rstudio.com/">https://shiny.rstudio.com/</ext-link>), so that users can select a dataset and run models without any R programming knowledge.</p>
    <p>The hBayesDM package is useful for researchers across all levels of experience, including experts in computational modeling—hBayesDM systematically implements HBA of various computational models, and we find it useful and easier to build new models based on the existing framework. We welcome collaboration and others’ contributions to the package. We plan to release a more detailed tutorial on how to modify existing codes and build new models based on our framework.</p>
    <p>In our HBA framework, it is assumed that there is a single hypergroup across all subjects. Although this assumption allows more precise estimates with a modest number of subjects (Ahn, Krawitz, et al., <xref rid="bib4" ref-type="bibr">2011</xref>; Katahira, <xref rid="bib65" ref-type="bibr">2016</xref>), it might be invalid with a large (e.g., ˜1,000) number of subjects (Ahn &amp; Busemeyer, <xref rid="bib2" ref-type="bibr">2016</xref>; Ratcliff &amp; Childers, <xref rid="bib93" ref-type="bibr">2015</xref>). Bayesian hierarchical mixture approaches (Bartlema, Lee, Wetzels, &amp; Vanpaemel, <xref rid="bib11" ref-type="bibr">2014</xref>) or HBA on subgroups first clustered by behavioral indices might be alternative solutions when a large number of samples need to be fitted.</p>
    <p>In conclusion, the hBayesDM package will allow researchers with a minimal quantitative background to do cutting-edge hierarchical modeling of a variety of RLDM tasks. With hBayesDM, researchers can also easily generate the model-based regressors required for model-based fMRI/EEG analysis. It is our expectation that the hBayesDM package will contribute to the dissemination of computational modeling and computational psychiatric research for researchers in various fields, including mental health.</p>
  </sec>
  <sec>
    <title>AUTHOR CONTRIBUTIONS</title>
    <p>W.-Y.A. conceived and designed the project. W.-Y.A., N.H., and L.Z. programmed codes for the hierarchical Bayesian modeling. N.H. built an R package and wrote the help files. W.-Y.A., N.H., and L.Z. wrote the article.</p>
  </sec>
  <sec>
    <title>ACKNOWLEDGMENTS</title>
    <p>W.-Y.A. programmed prototypes for several of the tasks while he was advised by Jerome Busemeyer (for the Iowa gambling task) or P. Read Montague/Peter Dayan (for the orthogonalized go/no-go, two-step, and risk aversion tasks, as well as the ultimatum game). We thank them for their guidance and the resources provided to W.-Y.A. We thank Peter Sokol-Hessner for sharing data published in Sokol-Hessner et al. (<xref rid="bib102" ref-type="bibr">2009</xref>). L.Z. was partially supported by the German Research Foundation (DFG GRK 1247) and the Bernstein Computational Neuroscience Program of the German Federal Ministry of Education and Research (Grant 01GQ1006).</p>
  </sec>
</body>
<back>
  <ref-list>
    <title>REFERENCES</title>
    <ref id="bib1">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Agay</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Kron</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Carmel</surname><given-names>Z.</given-names></name>, <name name-style="western"><surname>Mendlovic</surname><given-names>S.</given-names></name>, &amp; <name name-style="western"><surname>Levkovitz</surname><given-names>Y.</given-names></name></person-group> (<year>2008</year>). <article-title>Ultimatum bargaining behavior of people affected by schizophrenia</article-title>. <source>Psychiatry Research</source>, <volume>157</volume>, <fpage>39</fpage>–<lpage>46</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.psychres.2006.03.026">10.1016/j.psychres.2006.03.026</ext-link><pub-id pub-id-type="pmid">17916386</pub-id></mixed-citation>
    </ref>
    <ref id="bib2">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ahn</surname><given-names>W.-Y.</given-names></name>, &amp; <name name-style="western"><surname>Busemeyer</surname><given-names>J. R.</given-names></name></person-group> (<year>2016</year>). <article-title>Challenges and promises for translating computational tools into clinical practice</article-title>. <source>Current Opinion in Behavioral Sciences</source>, <volume>11</volume>, <fpage>1</fpage>–<lpage>7</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.cobeha.2016.02.001">10.1016/j.cobeha.2016.02.001</ext-link><pub-id pub-id-type="pmid">27104211</pub-id></mixed-citation>
    </ref>
    <ref id="bib3">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ahn</surname><given-names>W.-Y.</given-names></name>, <name name-style="western"><surname>Busemeyer</surname><given-names>J. R.</given-names></name>, <name name-style="western"><surname>Wagenmakers</surname><given-names>E. J.</given-names></name>, &amp; <name name-style="western"><surname>Stout</surname><given-names>J. C.</given-names></name></person-group> (<year>2008</year>). <article-title>Comparison of decision learning models using the generalization criterion method</article-title>. <source>Cognitive Science</source>, <volume>32</volume>, <fpage>1376</fpage>–<lpage>1402</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1080/03640210802352992">10.1080/03640210802352992</ext-link><pub-id pub-id-type="pmid">21585458</pub-id></mixed-citation>
    </ref>
    <ref id="bib4">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ahn</surname><given-names>W.-Y.</given-names></name>, <name name-style="western"><surname>Krawitz</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Kim</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Busemeyer</surname><given-names>J. R.</given-names></name>, &amp; <name name-style="western"><surname>Brown</surname><given-names>J. W.</given-names></name></person-group> (<year>2011</year>). <article-title>A model-based fMRI analysis with hierarchical Bayesian parameter estimation</article-title>. <source>Journal of Neuroscience, Psychology, and Economics</source>, <volume>4</volume>, <fpage>95</fpage>–<lpage>110</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1037/a0020684">10.1037/a0020684</ext-link></mixed-citation>
    </ref>
    <ref id="bib5">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ahn</surname><given-names>W.-Y.</given-names></name>, <name name-style="western"><surname>Ramesh</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Moeller</surname><given-names>F. G.</given-names></name>, &amp; <name name-style="western"><surname>Vassileva</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>Utility of machine-learning approaches to identify behavioral markers for substance use disorders: Impulsivity dimensions as predictors of present cocaine dependence</article-title>. <source>Frontiers in Psychiatry</source>, <volume>7</volume>, <fpage>290</fpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.3389/fpsyt.2016.00034">10.3389/fpsyt.2016.00034</ext-link></mixed-citation>
    </ref>
    <ref id="bib6">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ahn</surname><given-names>W.-Y.</given-names></name>, <name name-style="western"><surname>Rass</surname><given-names>O.</given-names></name>, <name name-style="western"><surname>Fridberg</surname><given-names>D. J.</given-names></name>, <name name-style="western"><surname>Bishara</surname><given-names>A. J.</given-names></name>, <name name-style="western"><surname>Forsyth</surname><given-names>J. K.</given-names></name>, <name name-style="western"><surname>Breier</surname><given-names>A.</given-names></name>, … <name name-style="western"><surname>O’Donnell</surname><given-names>B. F.</given-names></name></person-group> (<year>2011</year>). <article-title>Temporal discounting of reward in patients with bipolar disorder and schizophrenia</article-title>. <source>Journal of Abnormal Psychology</source>, <volume>120</volume>, <fpage>911</fpage>–<lpage>921</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1037/a0023333">10.1037/a0023333</ext-link><pub-id pub-id-type="pmid">21875166</pub-id></mixed-citation>
    </ref>
    <ref id="bib7">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ahn</surname><given-names>W.-Y.</given-names></name>, &amp; <name name-style="western"><surname>Vassileva</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>Machine-learning identifies substance-specific behavioral markers for opiate and stimulant dependence</article-title>. <source>Drug and Alcohol Dependence</source>, <volume>161</volume>, <fpage>247</fpage>–<lpage>257</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.drugalcdep.2016.02.008">10.1016/j.drugalcdep.2016.02.008</ext-link><pub-id pub-id-type="pmid">26905209</pub-id></mixed-citation>
    </ref>
    <ref id="bib8">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ahn</surname><given-names>W.-Y.</given-names></name>, <name name-style="western"><surname>Vasilev</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>S.-H.</given-names></name>, <name name-style="western"><surname>Busemeyer</surname><given-names>J. R.</given-names></name>, <name name-style="western"><surname>Kruschke</surname><given-names>J. K.</given-names></name>, <name name-style="western"><surname>Bechara</surname><given-names>A.</given-names></name>, &amp; <name name-style="western"><surname>Vassileva</surname><given-names>J.</given-names></name></person-group> (<year>2014</year>). <article-title>Decision-making in stimulant and opiate addicts in protracted abstinence: Evidence from computational modeling with pure users</article-title>. <source>Frontiers in Psychology</source>, <volume>5</volume>, <fpage>849</fpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.3389/fpsyg.2014.00849">10.3389/fpsyg.2014.00849</ext-link><pub-id pub-id-type="pmid">25161631</pub-id></mixed-citation>
    </ref>
    <ref id="bib9">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Akaike</surname><given-names>H.</given-names></name></person-group> (<year>1987</year>). <article-title>Factor analysis and AIC</article-title>. <source>Psychometrika</source>, <volume>52</volume>, <fpage>317</fpage>–<lpage>332</lpage>.</mixed-citation>
    </ref>
    <ref id="bib10">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Albrecht</surname><given-names>M. A.</given-names></name>, <name name-style="western"><surname>Waltz</surname><given-names>J. A.</given-names></name>, <name name-style="western"><surname>Cavanagh</surname><given-names>J. F.</given-names></name>, <name name-style="western"><surname>Frank</surname><given-names>M. J.</given-names></name>, &amp; <name name-style="western"><surname>Gold</surname><given-names>J. M.</given-names></name></person-group> (<year>2016</year>). <article-title>Reduction of Pavlovian bias in schizophrenia: Enhanced effects in clozapine-administered patients</article-title>. <source>PLoS ONE</source>, <volume>11</volume>, <fpage>e0152781</fpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1371/journal.pone.0152781">10.1371/journal.pone.0152781</ext-link><pub-id pub-id-type="pmid">27044008</pub-id></mixed-citation>
    </ref>
    <ref id="bib11">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bartlema</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Wetzels</surname><given-names>R.</given-names></name>, &amp; <name name-style="western"><surname>Vanpaemel</surname><given-names>W.</given-names></name></person-group> (<year>2014</year>). <article-title>A Bayesian hierarchical mixture approach to individual differences: Case studies in selective attention and representation in category learning</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>59</volume>, <fpage>132</fpage>–<lpage>150</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.jmp.2013.12.002">10.1016/j.jmp.2013.12.002</ext-link></mixed-citation>
    </ref>
    <ref id="bib12">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bechara</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Damasio</surname><given-names>A. R.</given-names></name>, <name name-style="western"><surname>Damasio</surname><given-names>H.</given-names></name>, &amp; <name name-style="western"><surname>Anderson</surname><given-names>S. W.</given-names></name></person-group> (<year>1994</year>). <article-title>Insensitivity to future consequences following damage to human prefrontal cortex</article-title>. <source>Cognition</source>, <volume>50</volume>, <fpage>7</fpage>–<lpage>15</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/0010-0277(94)90018-3">10.1016/0010-0277(94)90018-3</ext-link><pub-id pub-id-type="pmid">8039375</pub-id></mixed-citation>
    </ref>
    <ref id="bib13">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bechara</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Denburg</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Hindes</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Anderson</surname><given-names>S. W.</given-names></name>, &amp; <name name-style="western"><surname>Nathan</surname><given-names>P. E.</given-names></name></person-group> (<year>2001</year>). <article-title>Decision-making deficits, linked to a dysfunctional ventromedial prefrontal cortex, revealed in alcohol and stimulant abusers</article-title>. <source>Neuropsychologia</source>, <volume>39</volume>, <fpage>376</fpage>–<lpage>389</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/S0028-3932(00)00136-6">10.1016/S0028-3932(00)00136-6</ext-link><pub-id pub-id-type="pmid">11164876</pub-id></mixed-citation>
    </ref>
    <ref id="bib14">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bechara</surname><given-names>A.</given-names></name>, &amp; <name name-style="western"><surname>Martin</surname><given-names>E. M.</given-names></name></person-group> (<year>2004</year>). <article-title>Impaired decision making related to working memory deficits in individuals with substance addictions</article-title>. <source>Neuropsychology</source>, <volume>18</volume>, <fpage>152</fpage>–<lpage>162</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1037/0894-4105.18.1.152">10.1037/0894-4105.18.1.152</ext-link><pub-id pub-id-type="pmid">14744198</pub-id></mixed-citation>
    </ref>
    <ref id="bib15">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Behrens</surname><given-names>T. E. J.</given-names></name>, <name name-style="western"><surname>Woolrich</surname><given-names>M. W.</given-names></name>, <name name-style="western"><surname>Walton</surname><given-names>M. E.</given-names></name>, &amp; <name name-style="western"><surname>Rushworth</surname><given-names>M. F. S.</given-names></name></person-group> (<year>2007</year>). <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nature Neuroscience</source>, <volume>10</volume>, <fpage>1214</fpage>–<lpage>1221</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1038/nn1954">10.1038/nn1954</ext-link><pub-id pub-id-type="pmid">17676057</pub-id></mixed-citation>
    </ref>
    <ref id="bib16">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bickel</surname><given-names>W. K.</given-names></name></person-group> (<year>2015</year>).<article-title>Discounting of delayed reward as an endophenotype</article-title>. <source>Biological Psychiatry</source>, <volume>77</volume>, <fpage>846</fpage>–<lpage>847</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.biopsych.2015.03.003">10.1016/j.biopsych.2015.03.003</ext-link><pub-id pub-id-type="pmid">25925716</pub-id></mixed-citation>
    </ref>
    <ref id="bib17">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bolla</surname><given-names>K. I.</given-names></name>, <name name-style="western"><surname>Eldreth</surname><given-names>D. A.</given-names></name>, <name name-style="western"><surname>London</surname><given-names>E. D.</given-names></name>, <name name-style="western"><surname>Kiehl</surname><given-names>K. A.</given-names></name>, <name name-style="western"><surname>Mouratidis</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Contoreggi</surname><given-names>C.</given-names></name>, … <name name-style="western"><surname>Ernst</surname><given-names>M.</given-names></name></person-group> (<year>2003</year>). <article-title>Orbitofrontal cortex dysfunction in abstinent cocaine abusers performing a decision-making task</article-title>. <source>NeuroImage</source>, <volume>19</volume>, <fpage>1085</fpage>–<lpage>1094</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/S1053-8119(03)00113-7">10.1016/S1053-8119(03)00113-7</ext-link><pub-id pub-id-type="pmid">12880834</pub-id></mixed-citation>
    </ref>
    <ref id="bib18">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bozdogan</surname><given-names>H.</given-names></name></person-group> (<year>1987</year>). <article-title>Model selection and Akaike’s Information Criterion (AIC): The general theory and its analytical extensions</article-title>. <source>Psychometrika</source>, <volume>52</volume>, <fpage>345</fpage>–<lpage>370</lpage>.</mixed-citation>
    </ref>
    <ref id="bib19">
      <mixed-citation publication-type="book" publisher-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Busemeyer</surname><given-names>J. R.</given-names></name>, <name name-style="western"><surname>Diederich</surname><given-names>A.</given-names></name></person-group> (<year>2010</year>). <source>Cognitive modeling</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Sage</publisher-name>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1037/e722292011-099">10.1037/e722292011-099</ext-link></mixed-citation>
    </ref>
    <ref id="bib20">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Busemeyer</surname><given-names>J. R.</given-names></name>, &amp; <name name-style="western"><surname>Wang</surname><given-names>Y.-M.</given-names></name></person-group> (<year>2000</year>). <article-title>Model comparisons and model selections on the basis of generalization criterion meth odology</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>44</volume>, <fpage>1</fpage>–<lpage>19</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1006/jmps.1999.1282">10.1006/jmps.1999.1282</ext-link><pub-id pub-id-type="pmid">10733854</pub-id></mixed-citation>
    </ref>
    <ref id="bib21">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Camerer</surname><given-names>C. F.</given-names></name>, &amp; <name name-style="western"><surname>Ho</surname><given-names>T.-H.</given-names></name></person-group> (<year>1999</year>). <article-title>Experienced-weighted attraction learning in normal form games</article-title>. <source>Econometrica</source>, <volume>67</volume>, <fpage>827</fpage>–<lpage>874</lpage>.</mixed-citation>
    </ref>
    <ref id="bib22">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Carpenter</surname><given-names>B.</given-names></name>, <name name-style="western"><surname>Gelman</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Hoffman</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Goodrich</surname><given-names>B.</given-names></name>, <name name-style="western"><surname>Betancourt</surname><given-names>M.</given-names></name>, … <name name-style="western"><surname>Riddell</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>). <article-title>Stan: A probabilistic pro gramming language</article-title>. <source>Journal of Statistical Software</source>, <volume>76</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>32</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.18637/jss.v076.i01">10.18637/jss.v076.i01</ext-link></mixed-citation>
    </ref>
    <ref id="bib23">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cavanagh</surname><given-names>J. F.</given-names></name>, <name name-style="western"><surname>Eisenberg</surname><given-names>I.</given-names></name>, <name name-style="western"><surname>Guitart-Masip</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Huys</surname><given-names>Q.</given-names></name>, &amp; <name name-style="western"><surname>Frank</surname><given-names>M. J.</given-names></name></person-group> (<year>2013</year>). <article-title>Frontal theta overrides Pavlovian learning biases</article-title>. <source>Journal of Neuroscience</source>, <volume>33</volume>, <fpage>8541</fpage>–<lpage>8548</lpage>.<pub-id pub-id-type="pmid">23658191</pub-id></mixed-citation>
    </ref>
    <ref id="bib24">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chan</surname><given-names>T. W. S.</given-names></name>, <name name-style="western"><surname>Ahn</surname><given-names>W.-Y.</given-names></name>, <name name-style="western"><surname>Bates</surname><given-names>J. E.</given-names></name>, <name name-style="western"><surname>Busemeyer</surname><given-names>J. R.</given-names></name>, <name name-style="western"><surname>Guillaume</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Redgrave</surname><given-names>G. W.</given-names></name>, … <name name-style="western"><surname>Courtet</surname><given-names>P.</given-names></name></person-group> (<year>2014</year>). <article-title>Differential impairments underlying decision making in anorexia nervosa and bulimia nervosa: A cognitive modeling analysis</article-title>. <source>International Journal of Eating Disorders</source>, <volume>47</volume>, <fpage>157</fpage>–<lpage>167</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1002/eat.22223">10.1002/eat.22223</ext-link><pub-id pub-id-type="pmid">24243480</pub-id></mixed-citation>
    </ref>
    <ref id="bib25">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chowdhury</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Guitart-Masip</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Lambert</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>R. J.</given-names></name>, &amp; <name name-style="western"><surname>Duzel</surname><given-names>E.</given-names></name></person-group> (<year>2013</year>). <article-title>Structural integrity of the substantia nigra and subthalamic nucleus predicts flexibility of instrumental learning in older-age individuals</article-title>, <volume>34</volume>, <fpage>2261</fpage>–<lpage>2270</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.neurobiolaging.2013.03.030">10.1016/j.neurobiolaging.2013.03.030</ext-link></mixed-citation>
    </ref>
    <ref id="bib26">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cools</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Clark</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Owen</surname><given-names>A. M.</given-names></name>, &amp; <name name-style="western"><surname>Robbins</surname><given-names>T. W.</given-names></name></person-group> (<year>2002</year>). <article-title>Defining the neural mechanisms of probabilistic reversal learning using event-related functional magnetic resonance imaging</article-title>. <source>Journal of Neuroscience</source>, <volume>22</volume>, <fpage>4563</fpage>–<lpage>4567</lpage>.<pub-id pub-id-type="pmid">12040063</pub-id></mixed-citation>
    </ref>
    <ref id="bib27">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cools</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Lewis</surname><given-names>S. J.</given-names></name>, <name name-style="western"><surname>Clark</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Barker</surname><given-names>R. A.</given-names></name>, &amp; <name name-style="western"><surname>Robbins</surname><given-names>T. W.</given-names></name></person-group> (<year>2007</year>). <article-title>L-DOPA disrupts activity in the nucleus accumbens during reversal learning in Parkinson’s disease</article-title>. <source>Neuropsychopharmacology</source>, <volume>32</volume>, <fpage>180</fpage>–<lpage>189</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1038/sj.npp.1301153">10.1038/sj.npp.1301153</ext-link><pub-id pub-id-type="pmid">16841074</pub-id></mixed-citation>
    </ref>
    <ref id="bib28">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Csukly</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Polgár</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Tombor</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Réthelyi</surname><given-names>J.</given-names></name>, &amp; <name name-style="western"><surname>Kéri</surname><given-names>S.</given-names></name></person-group> (<year>2011</year>). <article-title>Are patients with schizophrenia rational maximizers? Evidence from an ultimatum game study</article-title>. <source>Psychiatry Research</source>, <volume>187</volume>, <fpage>11</fpage>–<lpage>17</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.psychres.2010.10.005">10.1016/j.psychres.2010.10.005</ext-link><pub-id pub-id-type="pmid">21035194</pub-id></mixed-citation>
    </ref>
    <ref id="bib29">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Daunizeau</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Adam</surname><given-names>V.</given-names></name>, &amp; <name name-style="western"><surname>Rigoux</surname><given-names>L.</given-names></name></person-group> (<year>2014</year>). <article-title>VBA: A probabilistic treatment of nonlinear models for neurobiological and behavioural data</article-title>. <source>PLoS Computational Biology</source>, <volume>10</volume>, <fpage>e1003441</fpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1371/journal.pcbi.1003441">10.1371/journal.pcbi.1003441</ext-link><pub-id pub-id-type="pmid">24465198</pub-id></mixed-citation>
    </ref>
    <ref id="bib30">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Daw</surname><given-names>N. D.</given-names></name>, <name name-style="western"><surname>O’Doherty</surname><given-names>J. P.</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Seymour</surname><given-names>B.</given-names></name>, &amp; <name name-style="western"><surname>Dolan</surname><given-names>R. J.</given-names></name></person-group> (<year>2006</year>). <article-title>Cortical substrates for exploratory decisions in humans</article-title>. <source>Nature</source>, <volume>441</volume>, <fpage>876</fpage>–<lpage>879</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1038/nature04766">10.1038/nature04766</ext-link><pub-id pub-id-type="pmid">16778890</pub-id></mixed-citation>
    </ref>
    <ref id="bib31">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dayan</surname><given-names>P.</given-names></name>, &amp; <name name-style="western"><surname>Daw</surname><given-names>N. D.</given-names></name></person-group> (<year>2008</year>). <article-title>Decision theory, reinforcement learning, and the brain</article-title>. <source>Cognitive, Affective, and Behavioral Neuroscience</source>, <volume>8</volume>, <fpage>429</fpage>–<lpage>453</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.3758/CABN.8.4.429">10.3758/CABN.8.4.429</ext-link></mixed-citation>
    </ref>
    <ref id="bib32">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dayan</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Niv</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Seymour</surname><given-names>B.</given-names></name>, &amp; <name name-style="western"><surname>Daw</surname><given-names>N. D.</given-names></name></person-group> (<year>2006</year>). <article-title>The misbehavior of value and the discipline of the will</article-title>. <source>Neural Networks</source>, <volume>19</volume>, <fpage>1153</fpage>–<lpage>1160</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.neunet.2006.03.002">10.1016/j.neunet.2006.03.002</ext-link><pub-id pub-id-type="pmid">16938432</pub-id></mixed-citation>
    </ref>
    <ref id="bib33">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>den Ouden</surname><given-names>H. E. M.</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>N. D.</given-names></name>, <name name-style="western"><surname>Fernandez</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Elshout</surname><given-names>J. A.</given-names></name>, <name name-style="western"><surname>Rijpkema</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Hoogman</surname><given-names>M.</given-names></name>, … <name name-style="western"><surname>Cools</surname><given-names>R.</given-names></name></person-group> (<year>2013</year>). <article-title>Dissociable effects of dopamine and serotonin on reversal learning</article-title>. <source>Neuron</source>, <volume>80</volume>, <fpage>1090</fpage>–<lpage>1100</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.neuron.2013.08.030">10.1016/j.neuron.2013.08.030</ext-link><pub-id pub-id-type="pmid">24267657</pub-id></mixed-citation>
    </ref>
    <ref id="bib34">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ebert</surname><given-names>J.</given-names></name>, &amp; <name name-style="western"><surname>Prelec</surname><given-names>D.</given-names></name></person-group> (<year>2007</year>). <article-title>The fragility of time: Time-insensitivity and valuation of the near and far future</article-title>. <source>Management Science</source>, <volume>53</volume>, <fpage>1423</fpage>–<lpage>1438</lpage>.</mixed-citation>
    </ref>
    <ref id="bib35">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Erev</surname><given-names>I.</given-names></name>, <name name-style="western"><surname>Ert</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Roth</surname><given-names>A. E.</given-names></name>, <name name-style="western"><surname>Haruvy</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Herzog</surname><given-names>S. M.</given-names></name>, <name name-style="western"><surname>Hau</surname><given-names>R.</given-names></name>, … <name name-style="western"><surname>Lebiere</surname><given-names>C.</given-names></name></person-group> (<year>2010</year>). <article-title>A choice prediction competition: Choices from experience and from description</article-title>. <source>Journal of Behavioral Decision Making</source>, <volume>23</volume>, <fpage>15</fpage>–<lpage>47</lpage>.</mixed-citation>
    </ref>
    <ref id="bib36">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ersche</surname><given-names>K. D.</given-names></name>, <name name-style="western"><surname>Roiser</surname><given-names>J. P.</given-names></name>, <name name-style="western"><surname>Robbins</surname><given-names>T. W.</given-names></name>, &amp; <name name-style="western"><surname>Sahakian</surname><given-names>B. J.</given-names></name></person-group> (<year>2008</year>). <article-title>Chronic cocaine but not chronic amphetamine use is associated with perseverative responding in humans</article-title>. <source>Psychopharmacology</source>, <volume>197</volume>, <fpage>421</fpage><lpage>431</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1007/s00213-007-1051-1">10.1007/s00213-007-1051-1</ext-link><pub-id pub-id-type="pmid">18214445</pub-id></mixed-citation>
    </ref>
    <ref id="bib37">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fellows</surname><given-names>L. K.</given-names></name>, &amp; <name name-style="western"><surname>Farah</surname><given-names>M. J.</given-names></name></person-group> (<year>2003</year>). <article-title>Ventromedial frontal cortex mediates affective shifting in humans: Evidence from a reversal learning paradigm</article-title>. <source>Brain</source>, <volume>126</volume>, <fpage>1830</fpage>–<lpage>1837</lpage>.<pub-id pub-id-type="pmid">12821528</pub-id></mixed-citation>
    </ref>
    <ref id="bib38">
      <mixed-citation publication-type="book" publisher-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Forstmann</surname><given-names>B. U.</given-names></name><name name-style="western"><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name></person-group><year>2015</year>). <source>An introduction to model-based cognitive neuroscience</source>. <publisher-loc>Berlin, Germany</publisher-loc>: <publisher-name>Springer</publisher-name>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1007/978-1-4939-2236-9">10.1007/978-1-4939-2236-9</ext-link></mixed-citation>
    </ref>
    <ref id="bib39">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fridberg</surname><given-names>D. J.</given-names></name>, <name name-style="western"><surname>Ahn</surname><given-names>W.-Y.</given-names></name>, <name name-style="western"><surname>Kim</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Bishara</surname><given-names>A. J.</given-names></name>, &amp; <name name-style="western"><surname>Stout</surname><given-names>J. C.</given-names></name></person-group> (<year>2010</year>). <article-title>Cognitive mechanisms underlying risky decision-making in chronic cannabis users</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>54</volume>, <fpage>28</fpage>–<lpage>38</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.jmp.2009.10.002">10.1016/j.jmp.2009.10.002</ext-link><pub-id pub-id-type="pmid">20419064</pub-id></mixed-citation>
    </ref>
    <ref id="bib40">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Friston</surname><given-names>K. J.</given-names></name>, <name name-style="western"><surname>Stephan</surname><given-names>K. E.</given-names></name>, <name name-style="western"><surname>Montague</surname><given-names>P. R.</given-names></name>, &amp; <name name-style="western"><surname>Dolan</surname><given-names>R. J.</given-names></name></person-group> (<year>2014</year>). <article-title>Computational psychiatry: The brain as a phantastic organ</article-title>. <source>Lancet: Psychiatry</source>, <volume>1</volume>, <fpage>148</fpage>–<lpage>158</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/S2215-0366(14)70">10.1016/S2215-0366(14)70</ext-link>
<ext-link ext-link-type="uri" xlink:href="https://dx.275-5">275-5</ext-link><pub-id pub-id-type="pmid">26360579</pub-id></mixed-citation>
    </ref>
    <ref id="bib41">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gelman</surname><given-names>A.</given-names></name></person-group> (<year>2006</year>). <article-title>Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper)</article-title>. <source>Bayesian Analysis</source>, <volume>1</volume>, <fpage>515</fpage>–<lpage>534</lpage>.</mixed-citation>
    </ref>
    <ref id="bib42">
      <mixed-citation publication-type="book" publisher-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Gelman</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Dunson</surname><given-names>D. B.</given-names></name>, <name name-style="western"><surname>Vehtari</surname><given-names>A.</given-names></name></person-group> (<year>2013</year>). <source>Bayesian data analysis</source> (<edition>3rd ed.</edition>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>CRC Press</publisher-name>.</mixed-citation>
    </ref>
    <ref id="bib43">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gelman</surname><given-names>A.</given-names></name>, &amp; <name name-style="western"><surname>Rubin</surname><given-names>D. B.</given-names></name></person-group> (<year>1992</year>). <article-title>Inference from iterative simulation using multiple sequences</article-title>. <source>Statistical Science</source>, <volume>7</volume>, <fpage>457</fpage>–<lpage>472</lpage>.</mixed-citation>
    </ref>
    <ref id="bib44">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gläscher</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>N. D.</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P.</given-names></name>, &amp; <name name-style="western"><surname>Doherty</surname><given-names>J. P. O.</given-names></name></person-group> (<year>2010</year>). <article-title>States versus rewards: Dissociable neural prediction error signals underlying model-based and model-free reinforcement learning</article-title>. <source>Neuron</source>, <volume>66</volume>, <fpage>585</fpage>–<lpage>595</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.neuron.2010.04.016">10.1016/j.neuron.2010.04.016</ext-link><pub-id pub-id-type="pmid">20510862</pub-id></mixed-citation>
    </ref>
    <ref id="bib45">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gläscher</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Hampton</surname><given-names>A. N.</given-names></name>, &amp; <name name-style="western"><surname>O’Doherty</surname><given-names>J. P.</given-names></name></person-group> (<year>2009</year>). <article-title>Determining a role for ventromedial prefrontal cortex in encoding action-based value signals during reward-related decision making</article-title>. <source>Cerebral Cortex</source>, <volume>19</volume>, <fpage>483</fpage>–<lpage>495</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1093/cercor/bhn098">10.1093/cercor/bhn098</ext-link><pub-id pub-id-type="pmid">18550593</pub-id></mixed-citation>
    </ref>
    <ref id="bib46">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Grant</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Contoreggi</surname><given-names>C.</given-names></name>, &amp; <name name-style="western"><surname>London</surname><given-names>E. D.</given-names></name></person-group> (<year>2000</year>). <article-title>Drug abusers show impaired performance in a laboratory test of decision making</article-title>. <source>Neuropsychologia</source>, <volume>38</volume>, <fpage>1180</fpage>–<lpage>1187</lpage>.<pub-id pub-id-type="pmid">10838152</pub-id></mixed-citation>
    </ref>
    <ref id="bib47">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Green</surname><given-names>L.</given-names></name>, &amp; <name name-style="western"><surname>Myerson</surname><given-names>J.</given-names></name></person-group> (<year>2004</year>). <article-title>A Discounting framework for choice with delayed and probabilistic rewards</article-title>. <source>Psychological Bulletin</source>, <volume>130</volume>, <fpage>769</fpage>–<lpage>792</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1037/0033-2909.130.5.769">10.1037/0033-2909.130.5.769</ext-link><pub-id pub-id-type="pmid">15367080</pub-id></mixed-citation>
    </ref>
    <ref id="bib48">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gu</surname><given-names>X.</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>X.</given-names></name>, <name name-style="western"><surname>Hula</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Xu</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Lohrenz</surname><given-names>T. M.</given-names></name>, … <name name-style="western"><surname>Montague</surname><given-names>P. R.</given-names></name></person-group> (<year>2015</year>). <article-title>Necessary, yet dissociable contributions of the insular and ventromedial prefrontal cortices to norm adaptation: Computational and lesion evidence in humans</article-title>. <source>Journal of Neuroscience</source>, <volume>35</volume>, <fpage>467</fpage>–<lpage>473</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1523/JNEUROSCI.2906-14.2015">10.1523/JNEUROSCI.2906-14.2015</ext-link><pub-id pub-id-type="pmid">25589742</pub-id></mixed-citation>
    </ref>
    <ref id="bib49">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Guitart-Masip</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Duzel</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>R.</given-names></name>, &amp; <name name-style="western"><surname>Dayan</surname><given-names>P.</given-names></name></person-group> (<year>2014</year>). <article-title>Action versus valence in decision making</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>18</volume>, <fpage>194</fpage>–<lpage>202</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.tics.2014.01.003">10.1016/j.tics.2014.01.003</ext-link><pub-id pub-id-type="pmid">24581556</pub-id></mixed-citation>
    </ref>
    <ref id="bib50">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Guitart-Masip</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Huys</surname><given-names>Q. J. M.</given-names></name>, <name name-style="western"><surname>Fuentemilla</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Duzel</surname><given-names>E.</given-names></name>, &amp; <name name-style="western"><surname>Dolan</surname><given-names>R. J.</given-names></name></person-group> (<year>2012</year>). <article-title>Go and no-go learning in reward and punishment: Interactions between affect and effect</article-title>. <source>NeuroImage</source>, <volume>62</volume>, <fpage>154</fpage>–<lpage>166</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.neuroimage.2012.04.024">10.1016/j.neuroimage.2012.04.024</ext-link><pub-id pub-id-type="pmid">22548809</pub-id></mixed-citation>
    </ref>
    <ref id="bib51">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Güth</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Schmittberger</surname><given-names>R.</given-names></name>, &amp; <name name-style="western"><surname>Schwarze</surname><given-names>B.</given-names></name></person-group> (<year>1982</year>). <article-title>An experimental analysis of ultimatum bargaining</article-title>. <source>Journal of Economic Behavior and Organization</source>, <volume>3</volume>, <fpage>367</fpage>–<lpage>388</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/0167-2681(82)">10.1016/0167-2681(82)</ext-link></mixed-citation>
    </ref>
    <ref id="bib52">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hampton</surname><given-names>A. N.</given-names></name>, <name name-style="western"><surname>Bossaerts</surname><given-names>P.</given-names></name>, &amp; <name name-style="western"><surname>O’Doherty</surname><given-names>J. P.</given-names></name></person-group> (<year>2006</year>). <article-title>The role of the ventromedial prefrontal cortex in abstract state-based infer ence during decision making in humans</article-title>. <source>Journal of Neuroscience</source>, <volume>26</volume>, <fpage>8360</fpage>–<lpage>8367</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1523/JNEUROSCI.1010-06.2006">10.1523/JNEUROSCI.1010-06.2006</ext-link><pub-id pub-id-type="pmid">16899731</pub-id></mixed-citation>
    </ref>
    <ref id="bib53">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Heerey</surname><given-names>E. A.</given-names></name>, <name name-style="western"><surname>Matveeva</surname><given-names>T. M.</given-names></name>, &amp; <name name-style="western"><surname>Gold</surname><given-names>J. M.</given-names></name></person-group> (<year>2011</year>). <article-title>Imagining the future: Degraded representations of future reward and events in schizophrenia</article-title>. <source>Journal of Abnormal Psychology</source>, <volume>120</volume>, <fpage>483</fpage>–<lpage>489</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1037/a0021810">10.1037/a0021810</ext-link><pub-id pub-id-type="pmid">21171727</pub-id></mixed-citation>
    </ref>
    <ref id="bib54">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Heerey</surname><given-names>E. A.</given-names></name>, <name name-style="western"><surname>Robinson</surname><given-names>B. M.</given-names></name>, <name name-style="western"><surname>McMahon</surname><given-names>R. P.</given-names></name>, &amp; <name name-style="western"><surname>Gold</surname><given-names>J. M.</given-names></name></person-group> (<year>2007</year>). <article-title>Delay discounting in schizophrenia</article-title>. <source>Cognitive Neuropsychiatry</source>, <volume>12</volume>, <fpage>213</fpage>–<lpage>221</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1080/13546800601005900">10.1080/13546800601005900</ext-link><pub-id pub-id-type="pmid">17453902</pub-id></mixed-citation>
    </ref>
    <ref id="bib55">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hertwig</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Barron</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Weber</surname><given-names>E. U.</given-names></name>, &amp; <name name-style="western"><surname>Erev</surname><given-names>I.</given-names></name></person-group> (<year>2004</year>). <article-title>Decisions from experience and the effect of rare events in risky choice</article-title>. <source>Psychological Science</source>, <volume>15</volume>, <fpage>534</fpage>–<lpage>539</lpage>.<pub-id pub-id-type="pmid">15270998</pub-id></mixed-citation>
    </ref>
    <ref id="bib56">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hinson</surname><given-names>J. M.</given-names></name>, <name name-style="western"><surname>Jameson</surname><given-names>T. L.</given-names></name>, &amp; <name name-style="western"><surname>Whitney</surname><given-names>P.</given-names></name></person-group> (<year>2003</year>). <article-title>Impulsive decision making and working memory</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>29</volume>, <fpage>298</fpage>–<lpage>306</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1037/0278-7393.29.2.298">10.1037/0278-7393.29.2.298</ext-link></mixed-citation>
    </ref>
    <ref id="bib57">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hoffman</surname><given-names>M. D.</given-names></name>, &amp; <name name-style="western"><surname>Gelman</surname><given-names>A.</given-names></name></person-group> (<year>2014</year>). <article-title>The No-U-Turn Sampler: Adaptively setting path lengths in Hamiltonian Monte Carlo</article-title>. <source>Journal of Machine Learning Research</source>, <volume>15</volume>, <fpage>1593</fpage>–<lpage>1623</lpage>.</mixed-citation>
    </ref>
    <ref id="bib58">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huys</surname><given-names>Q. J. M.</given-names></name>, <name name-style="western"><surname>Cools</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Gölzer</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Friedel</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Heinz</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>R. J.</given-names></name>, &amp; <name name-style="western"><surname>Dayan</surname><given-names>P.</given-names></name></person-group> (<year>2011</year>). <article-title>Disentangling the roles of approach, activation and valence in instrumental and Pavlovian responding</article-title>. <source>PLoS Computational Biology</source>, <volume>7</volume>, <fpage>e1002028</fpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1371/journal.pcbi.1002028.t002">10.1371/journal.pcbi.1002028.t002</ext-link><pub-id pub-id-type="pmid">21556131</pub-id></mixed-citation>
    </ref>
    <ref id="bib59">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huys</surname><given-names>Q. J. M.</given-names></name>, <name name-style="western"><surname>Maia</surname><given-names>T. V.</given-names></name>, &amp; <name name-style="western"><surname>Frank</surname><given-names>M. J.</given-names></name></person-group> (<year>2016</year>). <article-title>Computational psychiatry as a bridge from neuroscience to clinical applications</article-title>. <source>Nature Neuroscience</source>, <volume>19</volume>, <fpage>404</fpage><lpage>413</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1038/nn.4238">10.1038/nn.4238</ext-link><pub-id pub-id-type="pmid">26906507</pub-id></mixed-citation>
    </ref>
    <ref id="bib60">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Iglesias</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Mathys</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Brodersen</surname><given-names>K. H.</given-names></name>, <name name-style="western"><surname>Kasper</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Piccirelli</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>den Ouden</surname><given-names>H. E. M.</given-names></name>, &amp; <name name-style="western"><surname>Stephan</surname><given-names>K. E.</given-names></name></person-group> (<year>2013</year>). <article-title>Hierarchical pre diction errors in midbrain and basal forebrain during sensory learning</article-title>. <source>Neuron</source>, <volume>80</volume>, <fpage>519</fpage>–<lpage>530</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.neuron.2013.09.009">10.1016/j.neuron.2013.09.009</ext-link><pub-id pub-id-type="pmid">24139048</pub-id></mixed-citation>
    </ref>
    <ref id="bib61">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Insel</surname><given-names>T. R.</given-names></name></person-group> (<year>2014</year>).<article-title>The NIMH Research Domain Criteria (RDoc) Project: Precision medicine for psychiatry</article-title>. <source>American Journal of Psychiatry</source>, <volume>171</volume>, <fpage>395</fpage>–<lpage>397</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1176/appi.ajp.2014.14020138">10.1176/appi.ajp.2014.14020138</ext-link><pub-id pub-id-type="pmid">24687194</pub-id></mixed-citation>
    </ref>
    <ref id="bib62">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kable</surname><given-names>J. W.</given-names></name>, &amp; <name name-style="western"><surname>Glimcher</surname><given-names>P. W.</given-names></name></person-group> (<year>2007</year>). <article-title>The neural correlates of subjective value during intertemporal choice</article-title>. <source>Nature Neuroscience</source>, <volume>10</volume>, <fpage>1625</fpage>–<lpage>1633</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1038/nn2007">10.1038/nn2007</ext-link><pub-id pub-id-type="pmid">17982449</pub-id></mixed-citation>
    </ref>
    <ref id="bib63">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kaelbling</surname><given-names>L. P.</given-names></name>, <name name-style="western"><surname>Littman</surname><given-names>M. L.</given-names></name>, &amp; <name name-style="western"><surname>Moore</surname><given-names>A. W.</given-names></name></person-group> (<year>1996</year>). <article-title>Reinforcement learning: A survey</article-title>. <source>Journal of Artificial Intelligence Research</source>, <volume>4</volume>, <fpage>237</fpage>–<lpage>285</lpage>.</mixed-citation>
    </ref>
    <ref id="bib64">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kass</surname><given-names>R. E.</given-names></name>, &amp; <name name-style="western"><surname>Raftery</surname><given-names>A. E.</given-names></name></person-group> (<year>1995</year>). <article-title>Bayes factors</article-title>. <source>Journal of the American Statistical Association</source>, <volume>90</volume>, <fpage>773</fpage>–<lpage>795</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1080/01621459.1995.10476572">10.1080/01621459.1995.10476572</ext-link></mixed-citation>
    </ref>
    <ref id="bib65">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Katahira</surname><given-names>K.</given-names></name></person-group> (<year>2016</year>). <article-title>How hierarchical models improve point estimates of model parameters at the individual level</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>73</volume>, <fpage>37</fpage>–<lpage>58</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.jmp.2016.03.007">10.1016/j.jmp.2016.03.007</ext-link></mixed-citation>
    </ref>
    <ref id="bib66">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Knill</surname><given-names>D. C.</given-names></name>, &amp; <name name-style="western"><surname>Pouget</surname><given-names>A.</given-names></name></person-group> (<year>2004</year>). <article-title>The Bayesian brain: The role of uncertainty in neural coding and computation</article-title>. <source>Trends in Neurosciences</source>, <volume>27</volume>, <fpage>712</fpage>–<lpage>719</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.tins.2004.10.007">10.1016/j.tins.2004.10.007</ext-link><pub-id pub-id-type="pmid">15541511</pub-id></mixed-citation>
    </ref>
    <ref id="bib67">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Koenigs</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Young</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Adolphs</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Tranel</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Cushman</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Hauser</surname><given-names>M.</given-names></name>, &amp; <name name-style="western"><surname>Damasio</surname><given-names>A.</given-names></name></person-group> (<year>2007</year>). <article-title>Damage to the prefrontal cortex increases utilitarian moral judgements</article-title>. <source>Nature</source>, <volume>446</volume>, <fpage>908</fpage>–<lpage>911</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1038/nature05631">10.1038/nature05631</ext-link><pub-id pub-id-type="pmid">17377536</pub-id></mixed-citation>
    </ref>
    <ref id="bib68">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kruschke</surname><given-names>J. K.</given-names></name></person-group> (<year>2010</year>). <article-title>What to believe: Bayesian methods for data analysis</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>14</volume>, <fpage>293</fpage>–<lpage>300</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.tics.2010.05.001">10.1016/j.tics.2010.05.001</ext-link><pub-id pub-id-type="pmid">20542462</pub-id></mixed-citation>
    </ref>
    <ref id="bib69">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kruschke</surname><given-names>J. K.</given-names></name></person-group> (<year>2011</year>). <article-title>Bayesian assessment of null values via parameter estimation and model comparison</article-title>. <source>Perspectives on Psychological Science</source>, <volume>6</volume>, <fpage>299</fpage>–<lpage>312</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1177/1745691611406925">10.1177/1745691611406925</ext-link><pub-id pub-id-type="pmid">26168520</pub-id></mixed-citation>
    </ref>
    <ref id="bib70">
      <mixed-citation publication-type="book" publisher-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Kruschke</surname><given-names>J. K.</given-names></name></person-group> (<year>2014</year>). <source>Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan</source> (<edition>2nd ed.</edition>). <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</mixed-citation>
    </ref>
    <ref id="bib71">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>M. D.</given-names></name></person-group> (<year>2011</year>). <article-title>How cognitive modeling can benefit from hierarchical Bayesian models</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>55</volume>, <fpage>1</fpage>–<lpage>7</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.jmp.2010.08.013">10.1016/j.jmp.2010.08.013</ext-link></mixed-citation>
    </ref>
    <ref id="bib72">
      <mixed-citation publication-type="book" publisher-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Lewandowsky</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Farrell</surname><given-names>S.</given-names></name></person-group> (<year>2010</year>). <source>Computational modeling in cognition: Principles and practice</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Sage</publisher-name>.</mixed-citation>
    </ref>
    <ref id="bib73">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Schiller</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Schoenbaum</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Phelps</surname><given-names>E. A.</given-names></name>, &amp; <name name-style="western"><surname>Daw</surname><given-names>N. D.</given-names></name></person-group> (<year>2011</year>). <article-title>Differential roles of human striatum and amygdala in associative learning</article-title>. <source>Nature Neuroscience</source>, <volume>14</volume>, <fpage>1250</fpage>–<lpage>1252</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1038/nn.2904">10.1038/nn.2904</ext-link><pub-id pub-id-type="pmid">21909088</pub-id></mixed-citation>
    </ref>
    <ref id="bib74">
      <mixed-citation publication-type="book" publisher-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Luce</surname><given-names>R. D.</given-names></name></person-group> (<year>1959</year>). <source>Individual choice behavior: A theoretical analysis</source>. <publisher-loc>Mineola, NY</publisher-loc>: <publisher-name>Dover</publisher-name>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1037/14396-000">10.1037/14396-000</ext-link></mixed-citation>
    </ref>
    <ref id="bib75">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lunn</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Spiegelhalter</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Thomas</surname><given-names>A.</given-names></name>, &amp; <name name-style="western"><surname>Best</surname><given-names>N.</given-names></name></person-group> (<year>2009</year>). <article-title>The BUGS project: Evolution, critique and future directions</article-title>. <source>Statistics in Medicine</source>, <volume>28</volume>, <fpage>3049</fpage>–<lpage>3067</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1002/sim.3680">10.1002/sim.3680</ext-link><pub-id pub-id-type="pmid">19630097</pub-id></mixed-citation>
    </ref>
    <ref id="bib76">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lunn</surname><given-names>D. J.</given-names></name>, <name name-style="western"><surname>Thomas</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Best</surname><given-names>N.</given-names></name>, &amp; <name name-style="western"><surname>Spiegelhalter</surname><given-names>D.</given-names></name></person-group> (<year>2000</year>). <article-title>WinBUGS—a Bayesian modelling framework: Concepts, structure, and extensibility</article-title>. <source>Statistics and Computing</source>, <volume>10</volume>, <fpage>325</fpage>–<lpage>337</lpage>.</mixed-citation>
    </ref>
    <ref id="bib77">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>MacKillop</surname><given-names>J.</given-names></name></person-group> (<year>2013</year>). <article-title>Integrating behavioral economics and behavioral genetics: Delayed reward discounting as an endophenotype for addictive disorders</article-title>. <source>Journal of the Experimental Analysis of Behavior</source>, <volume>99</volume>, <fpage>14</fpage>–<lpage>31</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1002/jeab.4">10.1002/jeab.4</ext-link><pub-id pub-id-type="pmid">23344986</pub-id></mixed-citation>
    </ref>
    <ref id="bib78">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mars</surname><given-names>R. B.</given-names></name>, <name name-style="western"><surname>Debener</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Gladwin</surname><given-names>T. E.</given-names></name>, <name name-style="western"><surname>Harrison</surname><given-names>L. M.</given-names></name>, <name name-style="western"><surname>Haggard</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Rothwell</surname><given-names>J. C.</given-names></name>, &amp; <name name-style="western"><surname>Bestmann</surname><given-names>S.</given-names></name></person-group> (<year>2008</year>). <article-title>Trial-by-trial fluctuations in the event-related electroencephalogram reflect dynamic changes in the degree of surprise</article-title>. <source>Journal of Neuroscience</source>, <volume>28</volume>, <fpage>12539</fpage>–<lpage>12545</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1523/JNEUROSCI.2925-08.2008">10.1523/JNEUROSCI.2925-08.2008</ext-link><pub-id pub-id-type="pmid">19020046</pub-id></mixed-citation>
    </ref>
    <ref id="bib79">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Matzke</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Love</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Wiecki</surname><given-names>T. V.</given-names></name>, <name name-style="western"><surname>Brown</surname><given-names>S. D.</given-names></name>, <name name-style="western"><surname>Logan</surname><given-names>G. D.</given-names></name>, &amp; <name name-style="western"><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name></person-group> (<year>2013</year>). <article-title>Release the BEESTS: Bayesian estimation of ex-Gaussian stop-signal reaction time distributions</article-title>. <source>Frontiers in Psychology</source>, <volume>4</volume>, <fpage>918</fpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.3389/fpsyg.2013.00918">10.3389/fpsyg.2013.00918</ext-link><pub-id pub-id-type="pmid">24339819</pub-id></mixed-citation>
    </ref>
    <ref id="bib80">
      <mixed-citation publication-type="book" publisher-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Mazur</surname><given-names>J. E.</given-names></name></person-group> (<year>1987</year>). <article-title>An adjusting procedure for studying delayed reinforcement</article-title>. In <person-group person-group-type="editor"><name name-style="western"><surname>Commons</surname><given-names>M. L.</given-names></name>, <name name-style="western"><surname>Mazur</surname><given-names>J. E.</given-names></name>, <name name-style="western"><surname>Nevin</surname><given-names>J. A.</given-names></name>, &amp; <name name-style="western"><surname>Rachlin</surname><given-names>H.</given-names></name></person-group> (Eds.), <source>Quantitative analyses of behavior</source> (<volume>Vol. 5</volume>, pp. <fpage>55</fpage>–<lpage>73</lpage>). <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</mixed-citation>
    </ref>
    <ref id="bib81">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Montague</surname><given-names>P. R.</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>R. J.</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>K. J.</given-names></name>, &amp; <name name-style="western"><surname>Dayan</surname><given-names>P.</given-names></name></person-group> (<year>2012</year>). <article-title>Computational psychiatry</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>16</volume>, <fpage>72</fpage>–<lpage>80</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.tics.2011.11.018">10.1016/j.tics.2011.11.018</ext-link><pub-id pub-id-type="pmid">22177032</pub-id></mixed-citation>
    </ref>
    <ref id="bib82">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Montague</surname><given-names>P. R.</given-names></name>, &amp; <name name-style="western"><surname>Lohrenz</surname><given-names>T.</given-names></name></person-group> (<year>2007</year>). <article-title>To detect and correct: Norm violations and their enforcement</article-title>. <source>Neuron</source>, <volume>56</volume>, <fpage>14</fpage>–<lpage>18</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.neuron.2007.09.020">10.1016/j.neuron.2007.09.020</ext-link><pub-id pub-id-type="pmid">17920011</pub-id></mixed-citation>
    </ref>
    <ref id="bib83">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Murphy</surname><given-names>F. C.</given-names></name>, <name name-style="western"><surname>Michael</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Robbins</surname><given-names>T. W.</given-names></name>, &amp; <name name-style="western"><surname>Sahakian</surname><given-names>B. J.</given-names></name></person-group> (<year>2003</year>). <article-title>Neuropsychological impairment in patients with major depressive disorder: The effects of feedback on task performance</article-title>. <source>Psychological Medicine</source>, <volume>33</volume>, <fpage>455</fpage>–<lpage>467</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1017/S0033291702007018">10.1017/S0033291702007018</ext-link><pub-id pub-id-type="pmid">12701666</pub-id></mixed-citation>
    </ref>
    <ref id="bib84">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Myung</surname><given-names>I.-J.</given-names></name></person-group> (<year>2003</year>). <article-title>Tutorial on maximum likelihood estimation</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>47</volume>, <fpage>90</fpage>–<lpage>100</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/S0022-2496(02)00028-7">10.1016/S0022-2496(02)00028-7</ext-link></mixed-citation>
    </ref>
    <ref id="bib85">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Myung</surname><given-names>I.-J.</given-names></name>, &amp; <name name-style="western"><surname>Pitt</surname><given-names>M. A.</given-names></name></person-group> (<year>1997</year>). <article-title>Applying Occam’s razor in modeling cognition: A Bayesian approach</article-title>. <source>Psychonomic Bulletin &amp; Review</source>, <volume>4</volume>, <fpage>79</fpage>–<lpage>95</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.3758/BF03210778">10.3758/BF03210778</ext-link></mixed-citation>
    </ref>
    <ref id="bib86">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>O’Doherty</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Critchley</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Deichmann</surname><given-names>R.</given-names></name>, &amp; <name name-style="western"><surname>Dolan</surname><given-names>R. J.</given-names></name></person-group> (<year>2003</year>). <article-title>Dissociating valence of outcome from behavioral control in human orbital and ventral prefrontal cortices</article-title>. <source>Journal of Neuroscience</source>, <volume>23</volume>, <fpage>7931</fpage>–<lpage>7939</lpage>.<pub-id pub-id-type="pmid">12944524</pub-id></mixed-citation>
    </ref>
    <ref id="bib87">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>O’Doherty</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Schultz</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Deichmann</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>K.</given-names></name>, &amp; <name name-style="western"><surname>Dolan</surname><given-names>R. J.</given-names></name></person-group> (<year>2004</year>). <article-title>Dissociable roles of ventral and dorsal striatum in instrumental conditioning</article-title>. <source>Science</source>, <volume>304</volume>, <fpage>452</fpage>–<lpage>454</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1126/science.1094285">10.1126/science.1094285</ext-link><pub-id pub-id-type="pmid">15087550</pub-id></mixed-citation>
    </ref>
    <ref id="bib88">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>O’Doherty</surname><given-names>J. P.</given-names></name>, <name name-style="western"><surname>Hampton</surname><given-names>A.</given-names></name>, &amp; <name name-style="western"><surname>Kim</surname><given-names>H.</given-names></name></person-group> (<year>2007</year>). <article-title>Model-based fMRI and its application to reward learning and decision making</article-title>. <source>Annals of the New York Academy of Sciences</source>, <volume>1104</volume>, <fpage>35</fpage>–<lpage>53</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1196/annals.1390.022">10.1196/annals.1390.022</ext-link><pub-id pub-id-type="pmid">17416921</pub-id></mixed-citation>
    </ref>
    <ref id="bib89">
      <mixed-citation publication-type="other" publisher-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Plummer</surname><given-names>M.</given-names></name></person-group> (<year>2003</year>, March). <source>JAGS: A program for analysis of Bayes ian graphical models using Gibbs sampling</source>. <comment>Article presented at the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), Vienna, Austria</comment>.</mixed-citation>
    </ref>
    <ref id="bib90">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rachlin</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Raineri</surname><given-names>A.</given-names></name>, &amp; <name name-style="western"><surname>Cross</surname><given-names>D.</given-names></name></person-group> (<year>1991</year>). <article-title>Subjective probability and delay</article-title>. <source>Journal of the Experimental Analysis of Behavior</source>, <volume>55</volume>, <fpage>233</fpage>–<lpage>244</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1901/jeab.1991.55-233">10.1901/jeab.1991.55-233</ext-link><pub-id pub-id-type="pmid">2037827</pub-id></mixed-citation>
    </ref>
    <ref id="bib91">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Raja Beharelle</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Polania</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Hare</surname><given-names>T. A.</given-names></name>, &amp; <name name-style="western"><surname>Ruff</surname><given-names>C. C.</given-names></name></person-group> (<year>2015</year>). <article-title>Transcranial stimulation over frontopolar cortex elucidates the choice attributes and neural mechanisms used to resolve exploration–exploitation trade-offs</article-title>. <source>Journal of Neuroscience</source>, <volume>35</volume>, <fpage>14544</fpage>–<lpage>14556</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1523/JNEUROSCI.2322-15.2015">10.1523/JNEUROSCI.2322-15.2015</ext-link><pub-id pub-id-type="pmid">26511245</pub-id></mixed-citation>
    </ref>
    <ref id="bib92">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rangel</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Camerer</surname><given-names>C. F.</given-names></name>, &amp; <name name-style="western"><surname>Montague</surname><given-names>P. R.</given-names></name></person-group> (<year>2008</year>). <article-title>A framework for studying the neurobiology of value-based decision making</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>9</volume>, <fpage>545</fpage>–<lpage>556</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1038/nrn2357">10.1038/nrn2357</ext-link><pub-id pub-id-type="pmid">18545266</pub-id></mixed-citation>
    </ref>
    <ref id="bib93">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ratcliff</surname><given-names>R.</given-names></name>, &amp; <name name-style="western"><surname>Childers</surname><given-names>R.</given-names></name></person-group> (<year>2015</year>). <article-title>Individual differences and fitting methods for the two-choice diffusion model of decision making</article-title>. <source>Decision</source>, <volume>2</volume>, <fpage>237</fpage>–<lpage>279</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1037/dec0000030">10.1037/dec0000030</ext-link></mixed-citation>
    </ref>
    <ref id="bib94">
      <mixed-citation publication-type="book" publisher-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Rescorla</surname><given-names>R. A.</given-names></name>, &amp; <name name-style="western"><surname>Wagner</surname><given-names>A. R.</given-names></name></person-group> (<year>1972</year>). <article-title>A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement</article-title>. In <person-group person-group-type="editor"><name name-style="western"><surname>Black</surname><given-names>A. H.</given-names></name> &amp; <name name-style="western"><surname>Prokasy</surname><given-names>W. F.</given-names></name></person-group> (Eds.), <source>Classical conditioning II: Current research and theory</source> (pp. <fpage>64</fpage>–<lpage>99</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Appleton-Century-Crofts</publisher-name>.</mixed-citation>
    </ref>
    <ref id="bib95">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rolls</surname><given-names>E. T.</given-names></name>, <name name-style="western"><surname>Hornak</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Wade</surname><given-names>D.</given-names></name>, &amp; <name name-style="western"><surname>McGrath</surname><given-names>J.</given-names></name></person-group> (<year>1994</year>). <article-title>Emotion-related learning in patients with social and emotional changes associated with frontal lobe damage</article-title>. <source>Journal of Neurology, Neurosurgery, and Psychiatry</source>, <volume>57</volume>, <fpage>1518</fpage>–<lpage>1524</lpage>.</mixed-citation>
    </ref>
    <ref id="bib96">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Samuelson</surname><given-names>P. A.</given-names></name></person-group> (<year>1937</year>). <article-title>A note on measurement of utility</article-title>. <source>Review of Economic Studies</source>, <volume>4</volume>, <fpage>155</fpage>–<lpage>161</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.2307/2967612">10.2307/2967612</ext-link></mixed-citation>
    </ref>
    <ref id="bib97">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sanfey</surname><given-names>A. G.</given-names></name></person-group> (<year>2003</year>). <article-title>The neural basis of economic decision-making in the Ultimatum Game</article-title>. <source>Science</source>, <volume>300</volume>, <fpage>1755</fpage>–<lpage>1758</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1126/science.1082976">10.1126/science.1082976</ext-link><pub-id pub-id-type="pmid">12805551</pub-id></mixed-citation>
    </ref>
    <ref id="bib98">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shamosh</surname><given-names>N. A.</given-names></name>, <name name-style="western"><surname>DeYoung</surname><given-names>C. G.</given-names></name>, <name name-style="western"><surname>Green</surname><given-names>A. E.</given-names></name>, <name name-style="western"><surname>Reis</surname><given-names>D. L.</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>M. R.</given-names></name>, <name name-style="western"><surname>Conway</surname><given-names>A. R. A.</given-names></name>, … <name name-style="western"><surname>Gray</surname><given-names>J. R.</given-names></name></person-group> (<year>2008</year>). <article-title>Individual differences in delay discounting: Relation to intelligence, working memory, and anterior prefrontal cortex</article-title>. <source>Psychological Science</source>, <volume>19</volume>, <fpage>904</fpage>–<lpage>911</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1111/j.1467-9280.2008.02175.x">10.1111/j.1467-9280.2008.02175.x</ext-link><pub-id pub-id-type="pmid">18947356</pub-id></mixed-citation>
    </ref>
    <ref id="bib99">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shiffrin</surname><given-names>R. M.</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>M. D.</given-names></name>, <name name-style="western"><surname>Kim</surname><given-names>W.</given-names></name>, &amp; <name name-style="western"><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name></person-group> (<year>2008</year>). <article-title>A survey of model evaluation approaches with a tutorial on hierarchical Bayesian methods</article-title>. <source>Cognitive Science</source>, <volume>32</volume>, <fpage>1248</fpage>–<lpage>1284</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1080/03640210802414826">10.1080/03640210802414826</ext-link><pub-id pub-id-type="pmid">21585453</pub-id></mixed-citation>
    </ref>
    <ref id="bib100">
      <mixed-citation publication-type="other" publisher-type="web"><person-group person-group-type="author"><name name-style="western"><surname>Singmann</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Brown</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Gretton</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Heathcote</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Voss</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Voss</surname><given-names>J.</given-names></name>, &amp; <name name-style="western"><surname>Terry</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>). <article-title>rtdists: Response time distributions [Software]</article-title>. Retrieved from <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=rtdists">CRAN.R-project.org/package=rtdists</ext-link></mixed-citation>
    </ref>
    <ref id="bib101">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sokol-Hessner</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Camerer</surname><given-names>C. F.</given-names></name>, &amp; <name name-style="western"><surname>Phelps</surname><given-names>E. A.</given-names></name></person-group> (<year>2013</year>). <article-title>Emotion regulation reduces loss aversion and decreases amygdala responses to losses</article-title>. <source>Social Cognitive and Affective Neuroscience</source>, <volume>8</volume>, <fpage>341</fpage>–<lpage>350</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1093/scan/nss002">10.1093/scan/nss002</ext-link><pub-id pub-id-type="pmid">22275168</pub-id></mixed-citation>
    </ref>
    <ref id="bib102">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sokol-Hessner</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Hsu</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Curley</surname><given-names>N. G.</given-names></name>, <name name-style="western"><surname>Delgado</surname><given-names>M. R.</given-names></name>, <name name-style="western"><surname>Camerer</surname><given-names>C. F.</given-names></name>, &amp; <name name-style="western"><surname>Phelps</surname><given-names>E. A.</given-names></name></person-group> (<year>2009</year>). <article-title>Thinking like a trader selectively reduces individuals’ loss aversion</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>106</volume>, <fpage>5035</fpage>–<lpage>5040</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1073/pnas.0806761106">10.1073/pnas.0806761106</ext-link></mixed-citation>
    </ref>
    <ref id="bib103">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Spiegelhalter</surname><given-names>D. J.</given-names></name>, <name name-style="western"><surname>Best</surname><given-names>N. G.</given-names></name>, <name name-style="western"><surname>Carlin</surname><given-names>B. P.</given-names></name>, &amp; <name name-style="western"><surname>van der Linde</surname><given-names>A.</given-names></name></person-group> (<year>2002</year>). <article-title>Bayesian measures of model complexity and fit</article-title>. <source>Journal of the Royal Statistical Society: Series B</source>, <volume>64</volume>, <fpage>583</fpage>–<lpage>639</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1111/1467-9868.00353">10.1111/1467-9868.00353</ext-link></mixed-citation>
    </ref>
    <ref id="bib104">
      <mixed-citation publication-type="other" publisher-type="web"><collab collab-type="author">Stan Development Team</collab>. (<year>2016</year>). <article-title>RStan: The R interface to Stan</article-title>. <comment>R package version 2.14.1. Retrieved from <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/rstan/citation.html">https://cran.r-project.org/web/packages/rstan/citation.html</ext-link></comment></mixed-citation>
    </ref>
    <ref id="bib105">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Steingroever</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Wetzels</surname><given-names>R.</given-names></name>, &amp; <name name-style="western"><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name></person-group> (<year>2014</year>). <article-title>Absolute performance of reinforcement-learning models for the Iowa Gambling Task</article-title>. <source>Decision</source>, <volume>1</volume>, <fpage>161</fpage>–<lpage>183</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1037/dec0000005">10.1037/dec0000005</ext-link></mixed-citation>
    </ref>
    <ref id="bib106">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stephan</surname><given-names>K. E.</given-names></name>, <name name-style="western"><surname>Bach</surname><given-names>D. R.</given-names></name>, <name name-style="western"><surname>Fletcher</surname><given-names>P. C.</given-names></name>, <name name-style="western"><surname>Flint</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Frank</surname><given-names>M. J.</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>K. J.</given-names></name>, … <name name-style="western"><surname>Breakspear</surname><given-names>M.</given-names></name></person-group> (<year>2016</year>). <article-title>Charting the land scape of priority problems in psychiatry, part 1: Classification and diagnosis</article-title>. <source>Lancet: Psychiatry</source>, <volume>3</volume>, <fpage>77</fpage>–<lpage>83</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/S2215-0366(15)00361-2">10.1016/S2215-0366(15)00361-2</ext-link><pub-id pub-id-type="pmid">26573970</pub-id></mixed-citation>
    </ref>
    <ref id="bib107">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stephan</surname><given-names>K. E.</given-names></name>, <name name-style="western"><surname>Binder</surname><given-names>E. B.</given-names></name>, <name name-style="western"><surname>Breakspear</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Johnstone</surname><given-names>E. C.</given-names></name>, <name name-style="western"><surname>Meyer-Lindenberg</surname><given-names>A.</given-names></name>, … <name name-style="western"><surname>Friston</surname><given-names>K. J.</given-names></name></person-group> (<year>2016</year>). <article-title>Charting the landscape of priority problems in psychiatry, part 2: Pathogenesis and aetiology</article-title>. <source>Lancet: Psychiatry</source>, <volume>3</volume>, <fpage>84</fpage>–<lpage>90</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/S2215-0366(15)00360-0">10.1016/S2215-0366(15)00360-0</ext-link><pub-id pub-id-type="pmid">26573969</pub-id></mixed-citation>
    </ref>
    <ref id="bib108">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stephan</surname><given-names>K. E.</given-names></name>, <name name-style="western"><surname>Iglesias</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Heinzle</surname><given-names>J.</given-names></name>, &amp; <name name-style="western"><surname>Diaconescu</surname><given-names>A. O.</given-names></name></person-group> (<year>2015</year>). <article-title>Translational perspectives for computational neuroimaging</article-title>. <source>Neuron</source>, <volume>87</volume>, <fpage>716</fpage>–<lpage>732</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.neuron.2015.07.008">10.1016/j.neuron.2015.07.008</ext-link><pub-id pub-id-type="pmid">26291157</pub-id></mixed-citation>
    </ref>
    <ref id="bib109">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Swainson</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Rogers</surname><given-names>R. D.</given-names></name>, <name name-style="western"><surname>Sahakian</surname><given-names>B. J.</given-names></name>, <name name-style="western"><surname>Summers</surname><given-names>B. A.</given-names></name>, <name name-style="western"><surname>Polkey</surname><given-names>C. E.</given-names></name>, &amp; <name name-style="western"><surname>Robbins</surname><given-names>T. W.</given-names></name></person-group> (<year>2000</year>). <article-title>Probabilistic learning and reversal deficits in patients with Parkinson’s disease or frontal or temporal lobe lesions: Possible adverse effects of dopaminergic medication</article-title>. <source>Neuropsychologia</source>, <volume>38</volume>, <fpage>596</fpage>–<lpage>612</lpage>.<pub-id pub-id-type="pmid">10689037</pub-id></mixed-citation>
    </ref>
    <ref id="bib110">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Thaler</surname><given-names>R. H.</given-names></name></person-group> (<year>1988</year>). <article-title>Anomalies: The ultimatum game</article-title>. <source>Journal of Economic Perspectives</source>, <volume>2</volume>, <fpage>195</fpage>–<lpage>206</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.2307/1942788">10.2307/1942788</ext-link></mixed-citation>
    </ref>
    <ref id="bib111">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tom</surname><given-names>S. M.</given-names></name>, <name name-style="western"><surname>Fox</surname><given-names>C. R.</given-names></name>, <name name-style="western"><surname>Trepel</surname><given-names>C.</given-names></name>, &amp; <name name-style="western"><surname>Poldrack</surname><given-names>R. A.</given-names></name></person-group> (<year>2007</year>). <article-title>The neural basis of loss aversion in decision-making under risk</article-title>. <source>Science</source>, <volume>315</volume>, <fpage>515</fpage>–<lpage>518</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1126/science.1134239">10.1126/science.1134239</ext-link><pub-id pub-id-type="pmid">17255512</pub-id></mixed-citation>
    </ref>
    <ref id="bib112">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vassileva</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Ahn</surname><given-names>W.-Y.</given-names></name>, <name name-style="western"><surname>Weber</surname><given-names>K. M.</given-names></name>, <name name-style="western"><surname>Busemeyer</surname><given-names>J. R.</given-names></name>, <name name-style="western"><surname>Stout</surname><given-names>J. C.</given-names></name>, <name name-style="western"><surname>Gonzalez</surname><given-names>R.</given-names></name>, &amp; <name name-style="western"><surname>Cohen</surname><given-names>M. H.</given-names></name></person-group> (<year>2013</year>). <article-title>Computational modeling reveals distinct effects of HIV and history of drug use on decision-making processes in women</article-title>. <source>PLoS ONE</source>, <volume>8</volume>, <fpage>e68962</fpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1371/journal.pone.0068962">10.1371/journal.pone.0068962</ext-link><pub-id pub-id-type="pmid">23950880</pub-id></mixed-citation>
    </ref>
    <ref id="bib113">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vassileva</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Gonzalez</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Bechara</surname><given-names>A.</given-names></name>, &amp; <name name-style="western"><surname>Martin</surname><given-names>E. M.</given-names></name></person-group> (<year>2007</year>). <article-title>Are all drug addicts impulsive? Effects of antisociality and extent of multidrug use on cognitive and motor impulsivity</article-title>. <source>Addictive Behaviors</source>, <volume>32</volume>, <fpage>3071</fpage>–<lpage>3076</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.addbeh.2007.04.017">10.1016/j.addbeh.2007.04.017</ext-link><pub-id pub-id-type="pmid">17507173</pub-id></mixed-citation>
    </ref>
    <ref id="bib124">
      <mixed-citation publication-type="other" publisher-type="web"><person-group person-group-type="author"><name name-style="western"><surname>Vehtari</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Gelman</surname><given-names>A.</given-names></name>, &amp; <name name-style="western"><surname>Gabry</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>Practical Bayesian model evaluation using leave-one-out cross-validation andWAIC</article-title>. <ext-link ext-link-type="uri" xlink:href="https://arXiv:1507.04544">arXiv:1507.04544</ext-link></mixed-citation>
    </ref>
    <ref id="bib114">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vincent</surname><given-names>B. T.</given-names></name></person-group> (<year>2016</year>). <article-title>Hierarchical Bayesian estimation and hypothesis testing for delay discounting tasks</article-title>. <source>Behavior Research Methods</source>, <volume>48</volume>, <fpage>1608</fpage>–<lpage>1620</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.3758/s13428-015-0672-2">10.3758/s13428-015-0672-2</ext-link><pub-id pub-id-type="pmid">26542975</pub-id></mixed-citation>
    </ref>
    <ref id="bib115">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wabersich</surname><given-names>D.</given-names></name>, &amp; <name name-style="western"><surname>Vandekerckhove</surname><given-names>J.</given-names></name></person-group> (<year>2014</year>). <article-title>The RWiener package: An R package providing distribution functions for the Wiener diffusion model</article-title>. <source>R Journal</source>, <volume>6</volume>, <fpage>49</fpage>–<lpage>56</lpage>. Retrieved from <ext-link ext-link-type="uri" xlink:href="https://journal.r-project.org/archive/2014-1/vandekerckhove-wabersich.pdf">https://journal.r-project.org/archive/2014-1/vandekerckhove-wabersich.pdf</ext-link></mixed-citation>
    </ref>
    <ref id="bib116">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name></person-group> (<year>2007</year>). <article-title>A practical solution to the pervasive problems of <italic>p</italic> values</article-title>. <source>Psychonomic Bulletin &amp; Review</source>, <volume>14</volume>, <fpage>779</fpage>–<lpage>804</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.3758/BF03194105">10.3758/BF03194105</ext-link><pub-id pub-id-type="pmid">18087943</pub-id></mixed-citation>
    </ref>
    <ref id="bib117">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Waltz</surname><given-names>J. A.</given-names></name>, &amp; <name name-style="western"><surname>Gold</surname><given-names>J. M.</given-names></name></person-group> (<year>2007</year>). <article-title>Probabilistic reversal learning impairments in schizophrenia: Further evidence of orbitofrontal dysfunction</article-title>. <source>Schizophrenia Research</source>, <volume>93</volume>, <fpage>296</fpage>–<lpage>303</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.schres.2007.03.010">10.1016/j.schres.2007.03.010</ext-link><pub-id pub-id-type="pmid">17482797</pub-id></mixed-citation>
    </ref>
    <ref id="bib118">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>X.-J.</given-names></name>, &amp; <name name-style="western"><surname>Krystal</surname><given-names>J. H.</given-names></name></person-group> (<year>2014</year>). <article-title>Computational psychiatry</article-title>. <source>Neuron</source>, <volume>84</volume>, <fpage>638</fpage>–<lpage>654</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.neuron.2014.10.018">10.1016/j.neuron.2014.10.018</ext-link><pub-id pub-id-type="pmid">25442941</pub-id></mixed-citation>
    </ref>
    <ref id="bib119">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wetzels</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Vandekerckhove</surname><given-names>J.</given-names></name>, &amp; <name name-style="western"><surname>Tuerlinckx</surname><given-names>F.</given-names></name></person-group> (<year>2010</year>). <article-title>Bayesian parameter estimation in the Expectancy Valence model of the Iowa Gambling Task</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>54</volume>, <fpage>14</fpage>–<lpage>27</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1016/j.jmp.2008.12.001">10.1016/j.jmp.2008.12.001</ext-link></mixed-citation>
    </ref>
    <ref id="bib120">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wiecki</surname><given-names>T. V.</given-names></name>, <name name-style="western"><surname>Poland</surname><given-names>J.</given-names></name>, &amp; <name name-style="western"><surname>Frank</surname><given-names>M. J.</given-names></name></person-group> (<year>2015</year>). <article-title>Model-based cognitive neuroscience approaches to computational psychiatry: Clustering and classification</article-title>. <source>Clinical Psychological Science</source>, <volume>3</volume>, <fpage>378</fpage>–<lpage>399</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1177/2167702614565359">10.1177/2167702614565359</ext-link></mixed-citation>
    </ref>
    <ref id="bib121">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wiecki</surname><given-names>T. V.</given-names></name>, <name name-style="western"><surname>Sofer</surname><given-names>I.</given-names></name>, &amp; <name name-style="western"><surname>Frank</surname><given-names>M. J.</given-names></name></person-group> (<year>2013</year>). <article-title>HDDM: Hierarchical Bayesian estimation of the drift-diffusion model in Python</article-title>. <source>Frontiers in Neuroinformatics</source>, <volume>7</volume>, <fpage>14</fpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.3389/fninf.2013.00014">10.3389/fninf.2013.00014</ext-link><pub-id pub-id-type="pmid">23935581</pub-id></mixed-citation>
    </ref>
    <ref id="bib122">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Worthy</surname><given-names>D. A.</given-names></name>, <name name-style="western"><surname>Pang</surname><given-names>B.</given-names></name>, &amp; <name name-style="western"><surname>Byrne</surname><given-names>K. A.</given-names></name></person-group> (<year>2013</year>). <article-title>Decomposing the roles of perseveration and expected value representation in models of the Iowa gambling task</article-title>. <source>Frontiers in Psychology</source>, <volume>4</volume>, <fpage>640</fpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.3389/fpsyg.2013.00640">10.3389/fpsyg.2013.00640</ext-link><pub-id pub-id-type="pmid">24137137</pub-id></mixed-citation>
    </ref>
    <ref id="bib123">
      <mixed-citation publication-type="journal" publisher-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xiang</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>Lohrenz</surname><given-names>T.</given-names></name>, &amp; <name name-style="western"><surname>Montague</surname><given-names>P. R.</given-names></name></person-group> (<year>2013</year>). <article-title>Computational substrates of norms and their violations during social exchange</article-title>. <source>Journal of Neuroscience</source>, <volume>33</volume>, <fpage>1099</fpage>–<lpage>1108</lpage>. doi:<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.1523/JNEUROSCI.1642-12.2013">10.1523/JNEUROSCI.1642-12.2013</ext-link><pub-id pub-id-type="pmid">23325247</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
