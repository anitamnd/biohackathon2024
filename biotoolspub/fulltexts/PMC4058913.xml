<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-id journal-id-type="hwp">bioinfo</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">4058913</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btu293</article-id>
    <article-id pub-id-type="publisher-id">btu293</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Ismb 2014 Proceedings Papers Committee</subject>
        <subj-group subj-group-type="heading">
          <subject>Original Papers</subject>
          <subj-group subj-group-type="heading">
            <subject>Gene Regulation and Transcriptomics</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Graph-regularized dual Lasso for robust eQTL mapping</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Cheng</surname>
          <given-names>Wei</given-names>
        </name>
        <xref ref-type="aff" rid="btu293-AFF1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Xiang</given-names>
        </name>
        <xref ref-type="aff" rid="btu293-AFF1">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Guo</surname>
          <given-names>Zhishan</given-names>
        </name>
        <xref ref-type="aff" rid="btu293-AFF1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shi</surname>
          <given-names>Yu</given-names>
        </name>
        <xref ref-type="aff" rid="btu293-AFF1">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Wei</given-names>
        </name>
        <xref ref-type="aff" rid="btu293-AFF1">
          <sup>4</sup>
        </xref>
        <xref ref-type="corresp" rid="btu293-COR1">*</xref>
      </contrib>
    </contrib-group>
    <aff id="btu293-AFF1"><sup>1</sup>Department of Computer Science, UNC at Chapel Hill, Chapel Hill, NC 27599, <sup>2</sup>Department of EECS, Case Western Reserve University, OH 44106, USA <sup>3</sup>Department of Mathematics, University of Science and Technology of China, Hefei 23002, China and <sup>4</sup>Department of Computer Science, University of California, Los Angeles, CA 90095, USA</aff>
    <author-notes>
      <corresp id="btu293-COR1">*To whom correspondence should be addressed.</corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>15</day>
      <month>6</month>
      <year>2014</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>11</day>
      <month>6</month>
      <year>2014</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>11</day>
      <month>6</month>
      <year>2014</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="epub"/>. -->
    <volume>30</volume>
    <issue>12</issue>
    <fpage>i139</fpage>
    <lpage>i148</lpage>
    <permissions>
      <copyright-statement>© The Author 2014. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2014</copyright-year>
      <license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/3.0">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/3.0/">http://creativecommons.org/licenses/by-nc/3.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <abstract>
      <p><bold>Motivation:</bold> As a promising tool for dissecting the genetic basis of complex traits, expression quantitative trait loci (eQTL) mapping has attracted increasing research interest. An important issue in eQTL mapping is how to effectively integrate networks representing interactions among genetic markers and genes. Recently, several Lasso-based methods have been proposed to leverage such network information. Despite their success, existing methods have three common limitations: (i) a preprocessing step is usually needed to cluster the networks; (ii) the incompleteness of the networks and the noise in them are not considered; (iii) other available information, such as location of genetic markers and pathway information are not integrated.</p>
      <p><bold>Results:</bold> To address the limitations of the existing methods, we propose Graph-regularized Dual Lasso (GDL), a robust approach for eQTL mapping. GDL integrates the correlation structures among genetic markers and traits simultaneously. It also takes into account the incompleteness of the networks and is robust to the noise. GDL utilizes graph-based regularizers to model the prior networks and does not require an explicit clustering step. Moreover, it enables further refinement of the partial and noisy networks. We further generalize GDL to incorporate the location of genetic makers and gene-pathway information. We perform extensive experimental evaluations using both simulated and real datasets. Experimental results demonstrate that the proposed methods can effectively integrate various available priori knowledge and significantly outperform the state-of-the-art eQTL mapping methods.</p>
      <p><bold>Availability:</bold> Software for both C++ version and Matlab version is available at <ext-link ext-link-type="uri" xlink:href="http://www.cs.unc.edu/~weicheng/">http://www.cs.unc.edu/∼weicheng/</ext-link>.</p>
      <p>
        <bold>Contact:</bold>
        <email>weiwang@cs.ucla.edu</email>
      </p>
      <p><bold>Supplementary information:</bold><ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu293/-/DC1">Supplementary data</ext-link> are available at <italic>Bioinformatics</italic> online.</p>
    </abstract>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 INTRODUCTION</title>
    <p>Expression quantitative trait loci (eQTL) mapping aims at identifying single nucleotide polymorphisms (SNPs) that influence the expression level of genes. It has been widely applied to dissect genetic basis of complex traits (<xref rid="btu293-B2" ref-type="bibr">Bochner, 2003</xref>; <xref rid="btu293-B22" ref-type="bibr">Michaelson <italic>et al.</italic>, 2009</xref>). Several important issues need to be considered in eQTL mapping. First, the number of SNPs is usually much larger than the number of samples (<xref rid="btu293-B26" ref-type="bibr">Tibshirani, 1996</xref>). Second, the existence of confounding factors, such as expression heterogeneity, may result in spurious associations (<xref rid="btu293-B20" ref-type="bibr">Listgarten <italic>et al.</italic>, 2010</xref>). Third, SNPs (and genes) usually work together to cause variation in complex traits (<xref rid="btu293-B22" ref-type="bibr">Michaelson <italic>et al.</italic>, 2009</xref>). The interplay among SNPs and the interplay among genes can be represented as networks and used as prior knowledge (<xref rid="btu293-B23" ref-type="bibr">Musani <italic>et al.</italic>, 2007</xref>; <xref rid="btu293-B25" ref-type="bibr">Pujana <italic>et al.</italic>, 2007</xref>). However, such prior knowledge is far from being complete and may contain a lot of noises. Developing effective models to address these issues in eQTL studies has recently attracted increasing research interests (<xref rid="btu293-B1" ref-type="bibr">Biganzoli <italic>et al.</italic>, 2006</xref>; <xref rid="btu293-B14" ref-type="bibr">Kim and Xing, 2012</xref>; <xref rid="btu293-B17" ref-type="bibr">Lee and Xing, 2012</xref>; <xref rid="btu293-B18" ref-type="bibr">Lee <italic>et al.</italic>, 2010</xref>).</p>
    <p>In eQTL studies, two types of networks can be utilized. One is the genetic interaction network (<xref rid="btu293-B6" ref-type="bibr">Charles Boone and Andrews, 2007</xref>). Modeling genetic interaction (e.g. epistatic effect between SNPs) is essential to understanding the genetic basis of common diseases, since many diseases are complex traits (<xref rid="btu293-B15" ref-type="bibr">Lander, 2011</xref>). Another type of network is the network among traits, such as the protein–protein interaction (PPI) network or the gene co-expression network. Interacting proteins or genes in a PPI network are likely to be functionally related, i.e. part of a protein complex or in the same biological pathway (<xref rid="btu293-B27" ref-type="bibr">von Mering <italic>et al.</italic>, 2002</xref>). Effectively utilizing such prior network information can significantly improve the performance of eQTL mapping (<xref rid="btu293-B17" ref-type="bibr">Lee and Xing, 2012</xref>; <xref rid="btu293-B18" ref-type="bibr">Lee <italic>et al.</italic>, 2010</xref>).</p>
    <p><xref ref-type="fig" rid="btu293-F1">Figure 1</xref> shows an example of eQTL mapping with prior network knowledge. The interactions among SNPs and genes are represented by matrices <bold>S</bold> and <bold>G</bold><bold>,</bold> respectively. The goal of eQTL mapping is to infer associations between SNPs and genes represented by the coefficient matrix <bold>W</bold>. Suppose that SNP ② is strongly associated with gene Ⓒ. Using the network prior, the moderate association between SNP ① and gene Ⓐ may be identified since ① and <inline-formula><mml:math id="n6"><mml:mrow><mml:mo>②</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Ⓐ</mml:mi></mml:mrow></mml:math></inline-formula> and Ⓒ have interactions.
<fig id="btu293-F1" position="float"><label>Fig. 1.</label><caption><p>Examples of prior knowledge on genetic-interaction network <bold>S</bold> and gene–gene interactions represented by PPI network or gene co-expression network <bold>G</bold>. <bold>W</bold> is the regression coefficients to be learned</p></caption><graphic xlink:href="btu293f1"/></fig></p>
    <p>To leverage the network prior knowledge, several methods based on Lasso have been proposed (<xref rid="btu293-B1" ref-type="bibr">Biganzoli <italic>et al.</italic>, 2006</xref>; <xref rid="btu293-B14" ref-type="bibr">Kim and Xing, 2012</xref>; <xref rid="btu293-B17" ref-type="bibr">Lee and Xing, 2012</xref>; <xref rid="btu293-B18" ref-type="bibr">Lee <italic>et al.</italic>, 2010</xref>). In <xref rid="btu293-B1" ref-type="bibr">Biganzoli <italic>et al.</italic> (2006)</xref>, the group-Lasso penalty is applied to model the genetic interaction network. In (<xref rid="btu293-B14" ref-type="bibr">Kim and Xing, 2012</xref>) and (<xref rid="btu293-B18" ref-type="bibr">Lee <italic>et al.</italic>, 2010</xref>), the authors consider groupings of genes and apply a multi-task Lasso penalty. In (<xref rid="btu293-B17" ref-type="bibr">Lee and Xing, 2012</xref>), the authors further extend the model to consider grouping information of both SNPs and genes. These methods apply a ‘hard’ clustering of SNPs (genes) so that a SNP (gene) cannot belong to multiple groups. However, a SNP may affect multiple genes and a gene may function in multiple pathways. To address this limitation, in (<xref rid="btu293-B12" ref-type="bibr">Jenatton <italic>et al.</italic>, 2011</xref>), the authors develop a model allowing overlap between different groups.</p>
    <p>Despite their success, there are three common limitations of these group penalty based approaches. First, a clustering step is usually needed to obtain the grouping information. To address this limitation, (<xref rid="btu293-B13" ref-type="bibr">Kim and Xing, 2009</xref>; <xref rid="btu293-B19" ref-type="bibr">Li and Li, 2008</xref>) introduce a network-based fusion penalty on the genes. However, this method does not consider the genetic-interaction network. A two-graph-guided multi-task Lasso approach is developed in (<xref rid="btu293-B7" ref-type="bibr">Chen <italic>et al.</italic>, 2012</xref>) to make use of gene co-expression network and SNP-correlation network. However, this method does not consider the network prior knowledge. The second limitation of the existing methods is that they do not take into consideration the incompleteness of the networks and the noise in them (<xref rid="btu293-B27" ref-type="bibr">von Mering <italic>et al.</italic>, 2002</xref>). For example, PPI networks may contain false interactions and miss true interactions (<xref rid="btu293-B27" ref-type="bibr">von Mering <italic>et al.</italic>, 2002</xref>). Directly using the grouping penalty inferred from the noisy and partial prior networks may introduce new bias and thus impair the performance. Third, in addition to the network information, other prior knowledge, such as location of genetic markers and gene-pathway information are also available. The existing methods cannot incorporate such information.</p>
    <p>To address the limitations of the existing methods, we propose a novel approach, Graph-regularized Dual Lasso (GDL), which simultaneously learns the association between SNPs and genes and refines the prior networks. To support ‘soft’ clustering (allowing genes and SNPs to be members of multiple clusters), we adopt the graph regularizer to encode structured penalties from the prior networks. The penalties encourage the connected nodes (SNPs/genes) to have similar coefficients. This enables us to find multiple-correlated genetic markers with pleiotropic effects that affect multiple-correlated genes jointly. To tackle the problem of noisy and incomplete prior networks, we exploit the <italic>duality</italic> between learning the associations and refining the prior networks to achieve smoother regularization. That is, learning regression coefficients can help to refine the prior networks, and vice versa. For example, in <xref ref-type="fig" rid="btu293-F1">Figure 1</xref>, if SNPs ③ and ④ have strong associations with the same group of genes, they are likely to have interaction, which is not captured in the prior network. An ideal model should allow to update the prior network according to the learned regression coefficients. GDL can also incorporate other available prior knowledge such as the physical location of SNPs and biology pathways to which the genes belong. The resultant optimization problem is convex and can be efficiently solved by using an alternating minimization procedure. We perform extensive empirical evaluation of the proposed method using both simulated and real eQTL datasets. The results demonstrate that GDL is robust to the incomplete and noisy prior knowledge and can significantly improve the accuracy of eQTL mapping compared to the state-of-the-art methods.</p>
  </sec>
  <sec id="SEC2">
    <title>2 BACKGROUND: LINEAR REGRESSION WITH GRAPH REGULARIZER</title>
    <p>Throughout the article, we assume that, for each sample, the SNPs and genes are represented by column vectors. Important notations are listed in <xref ref-type="table" rid="btu293-T1">Table 1</xref>. Let <inline-formula><mml:math id="n10"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math></inline-formula> represent the <italic>K</italic> SNPs in the study, where <inline-formula><mml:math id="n11"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> is a random variable corresponding to the <italic>i</italic>-th SNP (e.g. 0, 1, 2 may encode the homozygous major allele, heterozygous allele and homozygous minor allele, respectively). Let <inline-formula><mml:math id="n12"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>z</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math></inline-formula> represent expression levels of the <italic>N</italic> genes in the study, where <italic>z<sub>j</sub></italic> is a continuous random variable corresponding to the <italic>j</italic>-th gene. The traditional linear regression model for association mapping between <bold>x</bold> and <bold>z</bold> is
<disp-formula id="btu293-M1"><label>(1)</label><mml:math id="n13"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>z</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi><mml:mi>x</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold">ϵ</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <bold>z</bold> is a linear function of <bold>x</bold> with coefficient matrix <bold>W</bold> and <bold><italic>μ</italic></bold> is an <inline-formula><mml:math id="n15"><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> translation factor vector. And <bold>ϵ</bold> is the additive noise of Gaussian distribution with zero-mean and variance <inline-formula><mml:math id="n17"><mml:mrow><mml:mi>γ</mml:mi><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> where <italic>γ</italic> is a scalar. That is, <inline-formula><mml:math id="n18"><mml:mrow><mml:mi mathvariant="bold">ϵ</mml:mi><mml:mo>∼</mml:mo><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>0</mml:mn></mml:mstyle><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.
<table-wrap id="btu293-T1" position="float"><label>Table 1.</label><caption><p>Summary of notations</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th align="center" rowspan="1" colspan="1">Symbols</th><th align="center" rowspan="1" colspan="1">Description</th></tr></thead><tbody align="left"><tr><td rowspan="1" colspan="1"><italic>K</italic></td><td rowspan="1" colspan="1">Number of SNPs</td></tr><tr><td rowspan="1" colspan="1"><italic>N</italic></td><td rowspan="1" colspan="1">Number of genes</td></tr><tr><td rowspan="1" colspan="1"><italic>D</italic></td><td rowspan="1" colspan="1">Number of samples</td></tr><tr><td rowspan="1" colspan="1"><inline-formula><mml:math id="n19"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula></td><td rowspan="1" colspan="1">The SNP matrix data</td></tr><tr><td rowspan="1" colspan="1"><inline-formula><mml:math id="n20"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula></td><td rowspan="1" colspan="1">The gene matrix data</td></tr><tr><td rowspan="1" colspan="1"><inline-formula><mml:math id="n21"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>L</mml:mi></mml:mstyle><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula></td><td rowspan="1" colspan="1">A low-rank matrix</td></tr><tr><td rowspan="1" colspan="1"><inline-formula><mml:math id="n22"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula></td><td rowspan="1" colspan="1">The input affinity matrices of the genetic-interaction network</td></tr><tr><td rowspan="1" colspan="1"><inline-formula><mml:math id="n23"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula></td><td rowspan="1" colspan="1">The input affinity matrices of the network of traits</td></tr><tr><td rowspan="1" colspan="1"><inline-formula><mml:math id="n24"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula></td><td rowspan="1" colspan="1">The refined affinity matrices of the genetic-interaction network</td></tr><tr><td rowspan="1" colspan="1"><inline-formula><mml:math id="n25"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula></td><td rowspan="1" colspan="1">The refined affinity matrices of the network of traits</td></tr><tr><td rowspan="1" colspan="1"><inline-formula><mml:math id="n26"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula></td><td rowspan="1" colspan="1">The coefficient matrix to be inferred</td></tr><tr><td rowspan="1" colspan="1"><inline-formula><mml:math id="n27"><mml:mrow><mml:msup><mml:mi mathvariant="script" class="calligraphy">R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula></td><td rowspan="1" colspan="1">The graph regularizer from the genetic-interaction network</td></tr><tr><td rowspan="1" colspan="1"><inline-formula><mml:math id="n28"><mml:mrow><mml:msup><mml:mi mathvariant="script" class="calligraphy">R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula></td><td rowspan="1" colspan="1">The graph regularizer from the PPI network</td></tr><tr><td rowspan="1" colspan="1"><inline-formula><mml:math id="n29"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo>,</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></td><td rowspan="1" colspan="1">A non-negative distance measure</td></tr></tbody></table></table-wrap></p>
    <p>The question now is how to define an appropriate objective function over <bold>W</bold> that (i) can effectively incorporate the prior network knowledge, and (ii) is robust to the noise and incompleteness in the prior knowledge. Next, we first briefly review Lasso and its variations and then introduce the proposed GDL method.</p>
    <sec id="SEC2.1">
      <title>2.1 Lasso and LORS</title>
      <p>Lasso (<xref rid="btu293-B26" ref-type="bibr">Tibshirani, 1996</xref>) is a method for estimating the regression coefficients <bold>W</bold> using <inline-formula><mml:math id="n30"><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> penalty for sparsity. It has been widely used for association mapping problems. Let <inline-formula><mml:math id="n31"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>d</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>d</mml:mi><mml:mo>≤</mml:mo><mml:mi>D</mml:mi><mml:mo>}</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> be the SNP matrix and <inline-formula><mml:math id="n32"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>z</mml:mi></mml:mstyle><mml:mi>d</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>d</mml:mi><mml:mo>≤</mml:mo><mml:mi>D</mml:mi><mml:mo>}</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> be the gene-expression matrix. Each column of <bold>X</bold> and <bold>Z</bold> stands for one sample. The objective function of Lasso is
<disp-formula id="btu293-M2"><label>(2)</label><mml:math id="n33"><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo></mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi><mml:mi>X</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle><mml:mo stretchy="false">|</mml:mo><mml:msubsup><mml:mo stretchy="false">|</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="n34"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>F</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denotes the Frobenius norm, <inline-formula><mml:math id="n35"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the <inline-formula><mml:math id="n36"><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm, <inline-formula><mml:math id="n37"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> is an <inline-formula><mml:math id="n38"><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:math></inline-formula> vector of all 1’s, <italic>η</italic> is the empirical parameter for the <inline-formula><mml:math id="n39"><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> penalty and <inline-formula><mml:math id="n40"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:math></inline-formula> is the parameter (also called weight) matrix parameterizing the space of linear functions mapping from <bold>X</bold> to <bold>Z</bold>.</p>
      <p>Confounding factors, such as unobserved covariates, experimental artifacts and unknown environmental perturbations, may mask real signals and lead to spurious findings. LORS (<xref rid="btu293-B28" ref-type="bibr">Yang <italic>et al.</italic>, 2013</xref>) uses a low-rank matrix <inline-formula><mml:math id="n41"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>L</mml:mi></mml:mstyle><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> to account for the variations caused by hidden factors. The objective function of LORS is
<disp-formula id="btu293-M3"><label>(3)</label><mml:math id="n42"><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo></mml:mrow><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>L</mml:mi></mml:mstyle></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi><mml:mi>X</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle><mml:mo>−</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>L</mml:mi></mml:mstyle><mml:mo stretchy="false">|</mml:mo><mml:msubsup><mml:mo stretchy="false">|</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>L</mml:mi></mml:mstyle><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mo>*</mml:mo></mml:msub></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="n43"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mo>*</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> is the nuclear norm, <italic>η</italic> is the empirical parameter for the <inline-formula><mml:math id="n44"><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> penalty to control the sparsity of <bold>W</bold> and <italic>λ</italic> is the regularization parameter to control the rank of <bold>L</bold>. <bold>L</bold> is a low-rank matrix assuming that there are only a small number of hidden factors influencing the gene-expression levels.</p>
    </sec>
    <sec id="SEC2.2">
      <title>2.2 Graph-regularized Lasso</title>
      <p>To incorporate the network prior knowledge, group sparse Lasso (<xref rid="btu293-B1" ref-type="bibr">Biganzoli <italic>et al.</italic>, 2006</xref>), multi-task Lasso (<xref rid="btu293-B24" ref-type="bibr">Obozinski and Taskar, 2006</xref>) and SIOL(<xref rid="btu293-B17" ref-type="bibr">Lee and Xing, 2012</xref>) have been proposed. Group sparse Lasso makes use of grouping information of SNPs; multi-task Lasso makes use of grouping information of genes, while SIOL uses information from both networks. A common drawback of these methods is that the number of groups (SNP and gene clusters) has to be predetermined. To overcome this drawback, we propose to use two graph regularizers to encode the prior network information. Compared with the previous group penalty-based methods, our method does not need to pre-cluster the networks and thus may obtain smoother regularization. Moreover, these methods do not consider confounding factors that may mask real signals and lead to spurious findings. In this article, we further incorporate the idea in LORS (<xref rid="btu293-B28" ref-type="bibr">Yang <italic>et al.</italic>, 2013</xref>) to tackle the confounding factors simultaneously.</p>
      <p>Let <inline-formula><inline-graphic xlink:href="btu293i1.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="btu293i10.jpg"/></inline-formula> be the affinity matrices of the genetic interaction network (e.g. epistatic effect between SNPs) and network of traits (e.g. PPI network or gene co-expression network), and <inline-formula><inline-graphic xlink:href="btu293i11.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="btu293i12.jpg"/></inline-formula> be their degree matrices. Given the two networks, we can employ a pairwise comparison between <inline-formula><inline-graphic xlink:href="btu293i13.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="btu293i14.jpg"/></inline-formula> if SNPs <italic>i</italic> and <italic>j</italic> are closely related, <inline-formula><inline-graphic xlink:href="btu293i15.jpg"/></inline-formula> is small. The pairwise comparison can be naturally encoded in the <italic>weighted fusion penalty</italic>
<inline-formula><inline-graphic xlink:href="btu293i16.jpg"/></inline-formula> This penalty will enforce <inline-formula><inline-graphic xlink:href="btu293i17.jpg"/></inline-formula> for closely related SNP pairs (with large <inline-formula><inline-graphic xlink:href="btu293i18.jpg"/></inline-formula> value). Then, the graph regularizer from the genetic-interaction network takes the following form
<disp-formula id="btu293-M4"><label>(4)</label><graphic xlink:href="btu293m4.jpg" position="float"/></disp-formula>
</p>
      <p>Similarly, the graph regularizer for the network of traits is
<disp-formula id="btu293-M5"><label>(5)</label><mml:math id="n57"><mml:mrow><mml:msup><mml:mi mathvariant="script" class="calligraphy">R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
These two regularizers encourage the connected nodes in a graph to have similar coefficients. A heavy penalty occurs if the learned-regression coefficients for neighboring SNPs (genes) are disparate. <inline-formula><mml:math id="n58"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="n59"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are known as the combinatorial graph Laplacian, which are positive semi-definite (<xref rid="btu293-B8" ref-type="bibr">Chung, 1997</xref>). Graph-regularized Lasso (G-Lasso) solves the following optimization problem
<disp-formula id="btu293-M6"><label>(6)</label><graphic xlink:href="btu293m6.jpg" position="float"/></disp-formula>
where <inline-formula><mml:math id="n61"><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> are regularization parameters.</p>
    </sec>
  </sec>
  <sec id="SEC3">
    <title>3 GDL</title>
    <p>In eQTL studies, the prior knowledge is usually incomplete and contains noise. It is desirable to refine the prior networks according to the learned regression coefficients. There is a <inline-formula><mml:math id="n62"><mml:mrow><mml:mi>d</mml:mi><mml:mi>u</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:math></inline-formula> between the prior networks and the regression coefficients: learning coefficients can help to refine the prior networks, and vice versa. This leads to mutual reinforcement when learning the two parts simultaneously.</p>
    <p>Next, we introduce the GDL. We further relax the constraints from the prior networks (two graph regularizers) introduced in Section 2.2, and integrate the G-Lasso and the dual refinement of graphs into a unified objective function
<disp-formula id="btu293-M7"><label>(7)</label><graphic xlink:href="btu293m7.jpg" position="float"/></disp-formula>
where <inline-formula><mml:math id="n64"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> are positive parameters controlling the extent to which the refined networks should be consistent with the original prior networks. <inline-formula><mml:math id="n65"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="n66"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mi>G</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are the degree matrices of <bold>S</bold> and <bold>G</bold>. Note that the objective function considers the non-negativity of <bold>S</bold> and <bold>G</bold>. As an extension, the model can be easily extended to incorporate prior knowledge from multiple sources. We only need to revise the last two terms in <xref ref-type="disp-formula" rid="btu293-M7">Equation (7)</xref> to <inline-formula><mml:math id="n67"><mml:mrow><mml:mi>γ</mml:mi><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>f</mml:mi></mml:msubsup><mml:mo stretchy="false">|</mml:mo></mml:mstyle><mml:mo stretchy="false">|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msubsup><mml:mo stretchy="false">|</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>ρ</mml:mi><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>e</mml:mi></mml:msubsup><mml:mo stretchy="false">|</mml:mo></mml:mstyle><mml:mo stretchy="false">|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msubsup><mml:mo stretchy="false">|</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> where <italic>f</italic> and <italic>e</italic> are the number of sources for genetic interaction networks and gene trait networks, respectively.</p>
    <sec id="SEC3.1">
      <title>3.1 Optimization: an alternating minimization approach</title>
      <p>In this section, we present an alternating scheme to optimize the objective function in <xref ref-type="disp-formula" rid="btu293-M7">Equation (7)</xref> based on block coordinate techniques. We divide the variables into three sets: {<bold>L</bold>}, {<bold>S</bold>, <bold>G</bold>} and <inline-formula><mml:math id="n68"><mml:mrow><mml:mo>{</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>}</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> We iteratively update one set of variables while fixing the other two sets. This procedure continues until convergence. Since the objective function is convex, the algorithm will converge to a global optima. The optimization process is as follows. The detailed algorithm is included in the <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu293/-/DC1">Supplementary Material</ext-link> (Algorithm 1).</p>
      <p>(1) While fixing <inline-formula><mml:math id="n69"><mml:mrow><mml:mo>{</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mtext>
</mml:mtext><mml:mo>{</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> optimize <inline-formula><mml:math id="n70"><mml:mrow><mml:mo>{</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>L</mml:mi></mml:mstyle><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> using singular value decomposition (SVD).
<statement><title>L<sc>emma</sc> 3.1</title><p>(<xref rid="btu293-B21" ref-type="bibr">Mazumder <italic>et al.</italic>, 2010</xref>) Suppose that matrix <bold>A</bold> has rank <italic>r</italic>. The solution to the optimization problem
<disp-formula id="btu293-M8"><label>(8)</label><mml:math id="n71"><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo></mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>B</mml:mi></mml:mstyle></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>B</mml:mi></mml:mstyle><mml:mo stretchy="false">|</mml:mo><mml:msubsup><mml:mo stretchy="false">|</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>B</mml:mi></mml:mstyle><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mo>*</mml:mo></mml:msub></mml:mrow></mml:math></disp-formula>
is given by <inline-formula><mml:math id="n72"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>H</mml:mi></mml:mstyle><mml:mi>λ</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="n73"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>H</mml:mi></mml:mstyle><mml:mi>λ</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mi>λ</mml:mi></mml:msub><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>V</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="n74"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mi>λ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo><mml:mtext>
</mml:mtext><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi><mml:mi>D</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>V</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math></inline-formula>is the Singular Value Decomposition (SVD) of <inline-formula><mml:math id="n75"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mtext>
</mml:mtext><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="n76"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula></p></statement>
</p>
      <p>Thus, for fixed <inline-formula><mml:math id="n77"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> the formula for updating <bold>L</bold> is
<disp-formula id="btu293-M9"><label>(9)</label><mml:math id="n78"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>L</mml:mi></mml:mstyle><mml:mo>←</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>H</mml:mi></mml:mstyle><mml:mi>λ</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi><mml:mi>X</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
      <p>(2) While fixing <inline-formula><mml:math id="n79"><mml:mrow><mml:mo>{</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mtext>
</mml:mtext><mml:mo>{</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>L</mml:mi></mml:mstyle><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> optimize <inline-formula><mml:math id="n80"><mml:mrow><mml:mo>{</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> using semi-non-negative matrix factorization (semi-NMF) multiplicative updating on <bold>S</bold> and <bold>G</bold> iteratively (<xref rid="btu293-B10" ref-type="bibr">Ding <italic>et al.</italic>, 2010</xref>). For the optimization with non-negative constraints, our updating rule is based on the following two theorems. The proofs of the theorems are given in Section 3.2.
<statement><title>T<sc>heorem</sc> 3.2</title><p>For fixed <inline-formula><mml:math id="n81"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>L</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:mtext>
</mml:mtext><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:mrow></mml:math></inline-formula> and <bold><italic>G</italic></bold>, updating <bold><italic>S</italic></bold> according to <xref ref-type="disp-formula" rid="btu293-M10">Equation (10)</xref> monotonically decreases the value of the objective function in <xref ref-type="disp-formula" rid="btu293-M7">Equation (7)</xref> until convergence.
<disp-formula id="btu293-M10"><label>(10)</label><mml:math id="n82"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>←</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>○</mml:mo><mml:mfrac><mml:mrow><mml:mi>α</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>γ</mml:mi><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>γ</mml:mi><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mtext>diag</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>J</mml:mi></mml:mstyle><mml:mi>K</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="n83"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>J</mml:mi></mml:mstyle><mml:mi>K</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a <inline-formula><mml:math id="n84"><mml:mrow><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula> matrix of all 1’s<italic>.</italic>
<inline-formula><mml:math id="n85"><mml:mrow><mml:mo>○</mml:mo><mml:mo>,</mml:mo><mml:mtext>
</mml:mtext><mml:mfrac><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> are element-wise operators. Since <inline-formula><mml:math id="n86"><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:mrow></mml:math></inline-formula> may take mixed signs, we denote <inline-formula><mml:math id="n87"><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>−</mml:mo></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="n88"><mml:mrow><mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>
<italic>and</italic>
<inline-formula><mml:math id="n89"><mml:mrow><mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mn>2.</mml:mn></mml:mrow></mml:math></inline-formula></p></statement>
<statement><title>T<sc>heorem</sc> 3.3.</title><p>For fixed <inline-formula><mml:math id="n90"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>L</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:mtext>
</mml:mtext><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:mrow></mml:math></inline-formula> and <bold>S</bold>, updating <bold>G</bold> according to <xref ref-type="disp-formula" rid="btu293-M11">Equation (11)</xref> monotonically decreases the value of the objective function in <xref ref-type="disp-formula" rid="btu293-M7">Equation (7)</xref> until convergence.
<disp-formula id="btu293-M11"><label>(11)</label><mml:math id="n91"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mo>←</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mo>○</mml:mo><mml:mfrac><mml:mrow><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>ρ</mml:mi><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>ρ</mml:mi><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mtext>diag</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>J</mml:mi></mml:mstyle><mml:mi>N</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="n92"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>J</mml:mi></mml:mstyle><mml:mi>N</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is an <inline-formula><mml:math id="n93"><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> matrix of all 1’s.</p></statement>
</p>
      <p>The above two theorems are derived from the Karush–Kuhn–Tucker (KKT) complementarity condition (<xref rid="btu293-B3" ref-type="bibr">Boyd and Vandenberghe, 2004</xref>). We show the updating rule for <bold>S</bold> below. The analysis for <bold>G</bold> is similar and omitted. We first formulate the Lagrange function of <bold>S</bold> for optimization
<disp-formula id="btu293-M12"><label>(12)</label><mml:math id="n94"><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mi>S</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msubsup><mml:mo stretchy="false">|</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
      <p>The partial derivative of the Lagrange function with respect to <bold>S</bold> is
<disp-formula id="btu293-M13"><label>(13)</label><mml:math id="n95"><mml:mrow><mml:msub><mml:mo>∇</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle></mml:msub><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>γ</mml:mi><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>γ</mml:mi><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mtext>diag</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>J</mml:mi></mml:mstyle><mml:mi>K</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
      <p>Using the KKT complementarity condition for the non-negative constraint on <bold>S</bold>, we have
<disp-formula id="btu293-M14"><label>(14)</label><mml:math id="n96"><mml:mrow><mml:msub><mml:mo>∇</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle></mml:msub><mml:mi>L</mml:mi><mml:mo>○</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>0</mml:mn></mml:mstyle><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
      <p>The above formula leads to the updating rule for <bold>S</bold> in <xref ref-type="disp-formula" rid="btu293-M10">Equation (10)</xref>. It has been shown that the multiplicative updating algorithm has first order convergence rate (<xref rid="btu293-B10" ref-type="bibr">Ding <italic>et al.</italic>, 2010</xref>).</p>
      <p>(3) While fixing <inline-formula><mml:math id="n97"><mml:mrow><mml:mo>{</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>L</mml:mi></mml:mstyle><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mtext>
</mml:mtext><mml:mo>{</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> optimize <inline-formula><mml:math id="n98"><mml:mrow><mml:mo>{</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> using the coordinate descent algorithm.</p>
      <p>Because we use the <inline-formula><mml:math id="n99"><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> penalty on <bold>W</bold>, we can use the coordinate descent algorithm for the optimization of <bold>W</bold>, which gives the following updating formula:
<disp-formula id="btu293-M15"><label>(15)</label><mml:math id="n100"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>η</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle></mml:msub><mml:mo>−</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>β</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle></mml:msub><mml:mo>−</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="n101"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> and
<disp-formula id="btu293-M16"><label>(16)</label><graphic xlink:href="btu293m16.jpg" position="float"/></disp-formula>
</p>
      <p>The solution of updating <bold><italic>μ</italic></bold> can be derived by setting <inline-formula><mml:math id="n104"><mml:mrow><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:msub><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> which gives
<disp-formula id="btu293-M17"><label>(17)</label><mml:math id="n105"><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi><mml:mi>X</mml:mi></mml:mstyle></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow><mml:mi>D</mml:mi></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
    </sec>
    <sec id="SEC3.2">
      <title>3.2 Convergence analysis</title>
      <p>In the following, we investigate the convergence of the algorithm. First, we study the convergence for the second step. We use the auxiliary-function approach (<xref rid="btu293-B16" ref-type="bibr">Lee and Seung, 2000</xref>) to analyze the convergence of the multiplicative updating formulas. Here we first introduce the definition of auxiliary function.
<statement><title>D<sc>efinition</sc> 3.4</title><p>Given a function <italic>L</italic>(<italic>h</italic>) of any parameter <italic>h</italic>, a function <inline-formula><mml:math id="n106"><mml:mrow><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>∼</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is an auxiliary function for <italic>L</italic>(<italic>h</italic>) if the conditions
<disp-formula id="btu293-M18"><label>(18)</label><mml:math id="n107"><mml:mrow><mml:mi>Z</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>∼</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mspace width=".3em"/><mml:mtext>and</mml:mtext><mml:mspace width=".3em"/><mml:mi>Z</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
are satisfied for any given <inline-formula><mml:math id="n108"><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>∼</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> (<xref rid="btu293-B16" ref-type="bibr">Lee and Seung, 2000</xref>).</p></statement>
<statement><title>L<sc>emma</sc> 3.5</title><p>If Z is an auxiliary function for function <italic>L(h)</italic>, then <italic>L(h)</italic> is non-increasing under the update (<xref rid="btu293-B16" ref-type="bibr">Lee and Seung, 2000</xref>).
<disp-formula id="btu293-M19"><label>(19)</label><mml:math id="n109"><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mtext>argmin</mml:mtext></mml:mrow><mml:mi>h</mml:mi></mml:munder><mml:mi>Z</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
</p></statement>
<statement><title>T<sc>heorem</sc> 3.6</title><p>Let <inline-formula><mml:math id="n110"><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denote the Lagrange function of <bold><italic>S</italic></bold> for optimization. The following function
<disp-formula id="btu293-M20"><label>(20)</label><graphic xlink:href="btu293m20.jpg" position="float"/></disp-formula>
</p><p>is an auxiliary function for <inline-formula><mml:math id="n112"><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> Furthermore, it is a convex function in <bold><italic>S</italic></bold> and its global minimum is
<disp-formula id="btu293-M21"><label>(21)</label><mml:math id="n113"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="true">∼</mml:mo></mml:mover><mml:mo>○</mml:mo><mml:mfrac><mml:mrow><mml:mi>α</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>γ</mml:mi><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>γ</mml:mi><mml:mover accent="true"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="true">∼</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mtext>diag</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>J</mml:mi></mml:mstyle><mml:mi>K</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
</p></statement>
<statement><title>T<sc>heorem</sc> 3.6</title><p>can be proved using a similar idea to that in (<xref rid="btu293-B9" ref-type="bibr">Ding <italic>et al.</italic>, 2006</xref>) by validating (i) <inline-formula><mml:math id="n114"><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="true">∼</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> (ii) <inline-formula><mml:math id="n115"><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (iii) <inline-formula><mml:math id="n116"><mml:mrow><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="true">∼</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is convex with respect to <bold>S</bold>. The formal proof is provided in the <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu293/-/DC1">Supplementary Material</ext-link>.</p></statement>
<statement><title>T<sc>heorem</sc> 3.7</title><p>Updating <bold>S</bold> using <xref ref-type="disp-formula" rid="btu293-M10">Equation (10)</xref> will monotonically decrease the value of the objective in <xref ref-type="disp-formula" rid="btu293-M7">Equation (7)</xref>, the objective is invariant if and only if <bold>S</bold> is at a stationary point.</p></statement>
<statement><title>P<sc>roof</sc></title><p>By Lemma 3.5 and Theorem 3.6, for each subsequent iteration of updating <bold>S</bold>, we have <inline-formula><mml:math id="n117"><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>0</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>0</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>0</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mtext>
</mml:mtext><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>0</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mn>...</mml:mn><mml:mo>≥</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mtext>Iter</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Thus <inline-formula><mml:math id="n118"><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> monotonically decreases. Since the objective function <xref ref-type="disp-formula" rid="btu293-M7">Equation (7)</xref> is obviously bounded below, the correctness of Theorem 3.2 is proved. Theorem 3.3 can be proved similarly. □</p></statement>
</p>
      <p>In addition to Theorem 3.7, since the computation of <bold>L</bold> in the first step decreases the value of the objective in <xref ref-type="disp-formula" rid="btu293-M7">Equation (7)</xref>, and the coordinate descent algorithm for updating <bold>W</bold> in the third step also monotonically decreases the value of the objective, the algorithm is guaranteed to converge.</p>
    </sec>
  </sec>
  <sec id="SEC4">
    <title>4 GENERALIZED GDL</title>
    <p>In this section, we extend our model to incorporate additional prior knowledge such as SNP locations and biological pathways. If the physical locations of two SNPs are close or two genes belong to the same pathway, they are likely to have interactions. Such information can be integrated to help refine the prior networks.</p>
    <p>Continue with our example in <xref ref-type="fig" rid="btu293-F1">Figure 1</xref>. If SNPs ③ and ④ affect the same set of genes (Ⓑ and Ⓓ), and at the same time, they are close to each other, then it is likely there exists interaction between ③ and ④.</p>
    <p>Formally, we would like to solve the following optimization problem
<disp-formula id="btu293-M22"><label>(22)</label><graphic xlink:href="btu293m22.jpg" position="float"/></disp-formula>
Here <inline-formula><mml:math id="n126"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo>,</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a non-negative distance measure. Note that the Euclidean distance is used in previous sections. <bold>S</bold> and <bold>G</bold> are initially given by inputs <inline-formula><mml:math id="n127"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="n128"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> We refer to this generalized model as the generalized GDL (GGDL). GGDL executes the following two steps iteratively until the termination condition is met: (i) update <bold>W</bold> while fixing <bold>S</bold> and <bold>G</bold> and (ii) update <bold>S</bold> and <bold>G</bold> according to <bold>W</bold>, while guarantee that both <inline-formula><inline-graphic xlink:href="btu293i2.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="btu293i3.jpg"/></inline-formula> decrease.</p>
    <p>These two steps are based on the aforementioned duality between learning <bold>W</bold> and refining <bold>S</bold> and <bold>G</bold>. The detailed algorithm is provided in the <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu293/-/DC1">Supplementary Material</ext-link>. Next, we illustrate the updating process assuming that <bold>S</bold> and <bold>G</bold> are unweighted graphs. It can be easily extended to weighted graphs.</p>
    <p>Step 1 can be done by using the coordinate decent algorithm. In Step 2, to guarantee that both <inline-formula><inline-graphic xlink:href="btu293i4.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="btu293i5a.jpg"/></inline-formula><inline-formula><inline-graphic xlink:href="btu293i5b.jpg"/></inline-formula> decrease, we can maintain a fixed number of 1’s in <bold>S</bold> and <bold>G</bold>. Taking <bold>G</bold> as an example, once <inline-formula><mml:math id="n133"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is selected to change from 0 to 1, another element <inline-formula><mml:math id="n134"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>′</mml:mo><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="n135"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>′</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>′</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> should be changed from 1 to 0.</p>
    <p>The selection of (<italic>i</italic>, <italic>j</italic>) and <inline-formula><mml:math id="n136"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>′</mml:mo><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>′</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is based on the ranking of <inline-formula><mml:math id="n137"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (<inline-formula><mml:math id="n138"><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>). Specifically, we examine κ pairs (the choice of κ depends on the user’s belief in the quality of the prior network. For example, it can be 5% of all (<italic>i</italic>, <italic>j</italic>) pairs) with the smallest distances. Among them, we pick those having no edges in <bold>G</bold>. Let <inline-formula><mml:math id="n139"><mml:mrow><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> be this set of pairs. Accordingly, we examine κ pairs with the largest distances. Among these pairs, we pick up only those having an edge in <bold>G</bold>. Let <inline-formula><mml:math id="n140"><mml:mrow><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> be this set of pairs. The elements of <bold>G</bold> corresponding to pairs in <inline-formula><mml:math id="n141"><mml:mrow><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> are candidates for updating from 0 to 1, since these pairs of genes are associated with similar SNPs. Similarly, elements of <bold>G</bold> corresponding to pairs in <inline-formula><mml:math id="n142"><mml:mrow><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> are candidates for updating from 1 to 0.</p>
    <p>In this process, the prior knowledge of gene pathways can be easily incorporated to better refine <bold>G</bold>. For instance, we can further require that only the gene pairs in <inline-formula><mml:math id="n143"><mml:mrow><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> belonging to the same pathway are eligible for updating, and only the gene pairs in <inline-formula><mml:math id="n144"><mml:mrow><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> belonging to different pathways are eligible for updating. We denote the set of gene pairs eligible for updating by <inline-formula><mml:math id="n145"><mml:mrow><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>′</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="n146"><mml:mrow><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>′</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> respectively. Then, we choose <inline-formula><mml:math id="n147"><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>′</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo>,</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>′</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> pairs in set <inline-formula><mml:math id="n148"><mml:mrow><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>′</mml:mo></mml:mrow></mml:math></inline-formula> with smallest <inline-formula><mml:math id="n149"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (<inline-formula><mml:math id="n150"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>′</mml:mo></mml:mrow></mml:math></inline-formula>) and update <inline-formula><mml:math id="n151"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> from 0 to 1. Similarly, we choose <inline-formula><mml:math id="n152"><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>′</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo>,</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>′</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> pairs in set <inline-formula><mml:math id="n153"><mml:mrow><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>′</mml:mo></mml:mrow></mml:math></inline-formula> with largest <inline-formula><mml:math id="n154"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>′</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>′</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (<inline-formula><mml:math id="n155"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>′</mml:mo><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>′</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script" class="calligraphy">P</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>′</mml:mo></mml:mrow></mml:math></inline-formula>) and update <inline-formula><mml:math id="n156"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>′</mml:mo><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> from 1 to 0.</p>
    <p>Obviously, all <inline-formula><mml:math id="n157"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>’s are smaller than <inline-formula><mml:math id="n158"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>′</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>′</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> if <inline-formula><mml:math id="n159"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>&lt;</mml:mo><mml:mfrac><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>4</mml:mn></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> Thus, <inline-formula><inline-graphic xlink:href="btu293i6.jpg"/></inline-formula> is guaranteed to decrease. The updating process for <bold>S</bold> is similar except that we compare columns rather than rows of <bold>W</bold> and use SNP locations rather than pathway information for evaluating the eligibility for updating. The updating process ends when no such pairs can be found so that switching their values will result in a decrease of the objective function.</p>
    <p>The convergence of GGDL can be observed as follows. The decrease of the objective function value in the first step is straightforward since we minimize it using coordinate decent. In the second step, the change of the objective function value is given by
<disp-formula id="btu293-M23"><label>(23)</label><mml:math id="n161"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mo>*</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mo>*</mml:mo><mml:msub><mml:mi>j</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mo>*</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:mo>*</mml:mo><mml:msub><mml:mi>j</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>′</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mi>j</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>*</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>′</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mi>j</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>′</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
which is always negative. Thus, in each iteration, the objective function value decreases. Since the objective function is non-negative, the process eventually converges.
<statement><title>T<sc>heorem</sc> 4.1</title><p>GGDL converges to the global optimum if both <inline-formula><inline-graphic xlink:href="btu293i7.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="btu293i8.jpg"/></inline-formula> are convex to <bold>W</bold><italic>.</italic></p></statement>
<statement><title>P<sc>roof</sc>:</title><p>The last two terms in <xref ref-type="disp-formula" rid="btu293-M22">Equation (22)</xref> are linear with respect to <bold>S</bold> and <bold>G</bold>, and convex to <bold>W</bold> according to the conditions listed. Thus the objective function is convex over all variables. A convergent result to the global optimum can be guaranteed. □</p></statement>
</p>
  </sec>
  <sec id="SEC5">
    <title>5 EXPERIMENTS</title>
    <p>In this section, we perform extensive experiments to evaluate the performance of the proposed methods. We use both simulated datasets and real yeast eQTL dataset (<xref rid="btu293-B4" ref-type="bibr">Brem <italic>et al.</italic>, 2005</xref>). For comparison, we select several state-of-the-art methods, including SIOL (<xref rid="btu293-B17" ref-type="bibr">Lee and Xing, 2012</xref>), two graph guided multi-task lasso (mtlasso2G) (<xref rid="btu293-B7" ref-type="bibr">Chen <italic>et al.</italic>, 2012</xref>), sparse group Lasso (<xref rid="btu293-B1" ref-type="bibr">Biganzoli <italic>et al.</italic>, 2006</xref>), sparse multi-task Lasso (<xref rid="btu293-B1" ref-type="bibr">Biganzoli <italic>et al.</italic>, 2006</xref>), LORS (<xref rid="btu293-B28" ref-type="bibr">Yang <italic>et al.</italic>, 2013</xref>) and Lasso (<xref rid="btu293-B26" ref-type="bibr">Tibshirani, 1996</xref>). For all the methods, the tuning parameters were learned using cross validation.</p>
    <sec id="SEC5.1">
      <title>5.1 Simulation study</title>
      <p>We first evaluate the performance of the selected methods using simulation study. Note that GGDL requires additional prior knowledge and will be evaluated using real dataset.</p>
      <p>We adopt the same setup for the simulation study as that in (<xref rid="btu293-B17" ref-type="bibr">Lee and Xing, 2012</xref>; <xref rid="btu293-B28" ref-type="bibr">Yang <italic>et al.</italic>, 2013</xref>) and generate synthetic datasets as follows. 100 SNPs are randomly selected from the yeast eQTL dataset (<xref rid="btu293-B4" ref-type="bibr">Brem <italic>et al.</italic>, 2005</xref>) (112 samples). Ten gene-expression profiles are generated by <inline-formula><mml:math id="n164"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Z</mml:mi></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:msub><mml:mo>Ξ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (<inline-formula><mml:math id="n165"><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>), where <inline-formula><mml:math id="n166"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mspace width=".1em"/><mml:mo>∼</mml:mo><mml:mspace width=".2em"/><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>I</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (<inline-formula><mml:math id="n167"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) denotes Gaussian noise. <inline-formula><mml:math id="n168"><mml:mrow><mml:msub><mml:mo>Ξ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is used to model non-genetic effects, which is drawn from <inline-formula><mml:math id="n169"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>0</mml:mn></mml:mstyle><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mi>Σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="n170"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>. Σ is generated by <inline-formula><mml:math id="n171"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="n172"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mo>×</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="n173"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula>
<italic>C</italic> is the number of hidden factors and is set to 10 by default. The association matrix <bold>W</bold> is generated as follows. Three sets of randomly selected four SNPs are associated with three gene clusters (1–3), (4–6), (7–10), respectively. In addition, one SNP is associated with two gene clusters (1–3) and (4–6), and one SNP is associated with all genes. The association strength is set to 1 for all selected SNPs. The clustering structures among SNPs and genes serve as the <italic>ground truth</italic> of the prior network knowledge. Only two of the three SNP (gene) clusters are used in <bold>W</bold> to simulate incomplete prior knowledge.</p>
      <p><xref ref-type="fig" rid="btu293-F2">Figure 2</xref> shows the estimated <bold>W</bold> matrix by various methods. The <italic>x</italic>-axis represents traits (1–10) and <italic>y</italic>-axis represents SNPs (1–100). From the figure, we can see that GDL is more effective than G-Lasso. This is because the dual refinement enables more robust model. G-Lasso outperforms SIOL and mtlasso2G, indicating that the graph regularizer provides a smoother regularization than the hard clustering based penalty. In addition, SIOL and mtlasso2G do not consider confounding factors. SIOL and mtlasso2G outperform multi-task Lasso and sparse group Lasso since it uses both SNP and gene grouping information, while multi-task Lasso and sparse group Lasso only use one of them. We also observe that all methods utilizing prior grouping knowledge outperform LORS and Lasso which cannot incorporate prior knowledge. LORS outperforms Lasso since it considers the confounding factors.
<fig id="btu293-F2" position="float"><label>Fig. 2.</label><caption><p>Ground truth of matrix <bold>W</bold> and that estimated by different methods. The <italic>x</italic>-axis represents traits and <italic>y</italic>-axis represents SNPs. Normalized absolute values of regression coefficients are used. Darker color implies stronger association</p></caption><graphic xlink:href="btu293f2"/></fig></p>
      <p>The ground-truth networks, prior networks and GDL-refined networks are shown in <xref ref-type="fig" rid="btu293-F3">Figure 3</xref>. Note that only a portion of the ground-truth networks are used as prior networks. In particular, the information related to gene cluster (7–10) is missing in the prior networks. We observe that the refined matrix <bold>G</bold> well captures the missing grouping information of gene cluster (7–10). Similarly, many missing pairwise relationships in <bold>S</bold> are recovered in the refined matrix (points in red ellipses).
<fig id="btu293-F3" position="float"><label>Fig. 3.</label><caption><p>The ground truth networks, prior partial networks and the refined networks</p></caption><graphic xlink:href="btu293f3"/></fig></p>
      <p>Using 50 simulated datasets with different Gaussian noise (<inline-formula><mml:math id="n174"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="n175"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> we compare the proposed methods with alternative state-of-the-art approaches. For each setting, we use 30 samples for test and 82 samples for training. We report the averaged result from 50 realizations. <xref ref-type="fig" rid="btu293-F4">Figure 4</xref> shows the ROC curves of TPR-FPR for performance comparison, together with the areas under the precision-recall curve (AUCs) (<xref rid="btu293-B7" ref-type="bibr">Chen <italic>et al.</italic>, 2012</xref>). The association strengths between SNPs and genes are set to be 0.1, 1 and 3, respectively. It is clear that GDL outperforms all alternative methods by effectively using and refining the prior network knowledge. We also computed test errors. On average, GDL achieved the best test error rate of 0.9122, and the order of the other methods in terms of the test errors is: G-Lasso (0.9276), SIOL (0.9485), Mtlasso2G (0.9521), Multi-task Lasso (0.9723), Sparse group Lasso (0.9814), LORS (1.0429) and Lasso (1.2153).
<fig id="btu293-F4" position="float"><label>Fig. 4.</label><caption><p>Power curves for synthetic data. The left plots show the ROC curve, where our model GDL achieved maximum power. The black solid line denotes what random guessing would have achieved. The right plots illustrate the areas under the precision-recall curve (AUCs) of different methods</p></caption><graphic xlink:href="btu293f4"/></fig></p>
      <p>To evaluate the effectiveness of dual refinement, we compare GDL and G-Lasso since the only difference between these two methods is whether the prior networks are refined during the optimization process. We add noises to the prior networks by randomly shuffling the elements in them. Furthermore, we use the signal-to-noise ratio defined as <inline-formula><mml:math id="n176"><mml:mrow><mml:mtext>SNR</mml:mtext><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi><mml:mi>X</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:mo>Ξ</mml:mo><mml:mo>+</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>E</mml:mi></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> (<xref rid="btu293-B28" ref-type="bibr">Yang <italic>et al.</italic>, 2013</xref>) to measure the noise ratio in the eQTL datasets. Here, we fix <inline-formula><mml:math id="n177"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> and use different <italic>σ</italic>’s to control SNR.</p>
      <p><xref ref-type="fig" rid="btu293-F5">Figure 5</xref> shows the results for different SNRs. For a fixed SNR, we vary the percentage of noises in the prior networks and compare the performance of selected methods. From the results, we can see that G-Lasso is more sensitive to noises in the prior networks than GDL is. Moreover, when the SNR is low, the advantage of GDL is more prominent. These results indicate using dual refinement can dramatically improve the accuracy of the identified associations.
<fig id="btu293-F5" position="float"><label>Fig. 5.</label><caption><p>The areas under the TPR-FPR curve (AUCs) of Lasso, LORS, G-Lasso and GDL. In each panel, we vary the percentage of noises in the prior networks <inline-formula><mml:math id="n178"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="n179"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula></p></caption><graphic xlink:href="btu293f5"/></fig></p>
    </sec>
    <sec id="SEC5.2">
      <title>5.2 Yeast eQTL study</title>
      <p>We apply the proposed methods to a yeast (<italic>Saccharomyces cerevisiae</italic>) eQTL dataset of 112 yeast segregants generated from a cross of two inbred strains (<xref rid="btu293-B4" ref-type="bibr">Brem <italic>et al.</italic>, 2005</xref>). The dataset originally includes expression profiles of 6229 gene-expression traits and genotype profiles of 2956 SNPs. After removing SNPs with &gt;10% missing values and merging consecutive SNPs high linkage disequilibrium, we get 1017 SNPs with unique genotypes (<xref rid="btu293-B11" ref-type="bibr">Huang <italic>et al.</italic>, 2009</xref>). After removing the ones with missing values, 4474 expression profiles are selected. The genetic interaction network is generated as in (<xref rid="btu293-B17" ref-type="bibr">Lee and Xing, 2012</xref>). We use the PPI network downloaded from BioGRID (<ext-link ext-link-type="uri" xlink:href="http://thebiogrid.org/">http://thebiogrid.org/</ext-link>) to represent the prior network among genes. It takes ∼1 day for GGDL, and ∼10 h for GDL to run into completion.</p>
    </sec>
    <sec id="SEC5.2.1">
      <title>5.2.1 <italic>cis</italic>- and <italic>trans</italic>-enrichment analysis</title>
      <p>We follow the standard <italic>cis</italic>-enrichment analysis (<xref rid="btu293-B20" ref-type="bibr">Listgarten <italic>et al.</italic>, 2010</xref>) to compare the performance of two competing models. The intuition behind <italic>cis</italic>-enrichment analysis is that more <italic>cis</italic>-acting SNPs are expected than <italic>trans</italic>-acting SNPs. A two-step procedure is used in the <italic>cis</italic>-enrichment analysis (<xref rid="btu293-B20" ref-type="bibr">Listgarten <italic>et al.</italic>, 2010</xref>): (i) for each model, we apply a one-tailed Mann–Whitney test on each SNP to test the null hypothesis that the model ranks its <italic>cis</italic> hypotheses no better than its <italic>trans</italic> hypotheses, (ii) for each pair of models compared, we perform a two-tailed paired Wilcoxon sign-rank test on the <italic>P</italic>-values obtained from the previous step. The null hypothesis is that the median difference of the <italic>P</italic>-values in the Mann–Whitney test for each SNP is zero. The <italic>trans</italic>-enrichment is implemented using similar strategy (<xref rid="btu293-B5" ref-type="bibr">Brem <italic>et al.</italic>, 2003</xref>), in which genes regulated by transcription factors (obtained from <ext-link ext-link-type="uri" xlink:href="http://www.yeastract.com/download.php">http://www.yeastract.com/download.php</ext-link>) are used as <italic>trans</italic>-acting signals.</p>
      <p>In addition to the methods evaluated in the simulation study, GGDL is also evaluated here (with <inline-formula><mml:math id="n180"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>100000</mml:mn><mml:mo>,</mml:mo><mml:mtext>
</mml:mtext><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>15</mml:mn><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) (for GDL, <inline-formula><mml:math id="n181"><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>15</mml:mn><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>15</mml:mn><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> The Euclidean distance is used as the distance metric. We rank pairs of SNPs and genes according to the learned <bold>W</bold>. <bold>S</bold> is refined if the locations of the two SNPs are &lt;500 bp. <bold>G</bold> is refined if the two genes are in the same pathway. The pathway information is downloaded from Saccharomyces Genome Database [SGD (<ext-link ext-link-type="uri" xlink:href="http://www.yeastgenome.org/">http://www.yeastgenome.org/</ext-link>)].</p>
      <p>The results of pairwise comparison of selected models are shown in <xref ref-type="table" rid="btu293-T2">Table 2</xref>. In this table, a <italic>P</italic>-value shows how significant a method on the left column outperforms a method in the top row in terms of <italic>cis</italic> and <italic>trans</italic> enrichments. We observe that the proposed GGDL and GDL have significantly better enrichment scores than the other models. By incorporating genomic location and pathway information, GGDL performs better than GDL with <italic>P</italic>-value &lt; 0.0001. The effectiveness of the dual refinement on prior graphs is demonstrated by GDL’s better performance over G-Lasso. Note that the performance ranking of these models is consistent with that in the simulation study.
<table-wrap id="btu293-T2" position="float"><label>Table 2.</label><caption><p>Pairwise comparison of different models using <italic>cis</italic>-enrichment and <italic>trans</italic>-enrichment analysis</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">GDL</th><th rowspan="1" colspan="1">G-Lasso</th><th rowspan="1" colspan="1">SIOL</th><th rowspan="1" colspan="1">Mtlasso2G</th><th rowspan="1" colspan="1">Multi-task</th><th rowspan="1" colspan="1">Sparse group</th><th rowspan="1" colspan="1">LORS</th><th rowspan="1" colspan="1">Lasso</th></tr></thead><tbody align="left"><tr><td colspan="9" rowspan="1"><italic>Cis</italic>-enrichment</td></tr><tr><td rowspan="1" colspan="1">    GGDL</td><td rowspan="1" colspan="1">0.0003</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td></tr><tr><td rowspan="1" colspan="1">    GDL</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">0.0009</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td></tr><tr><td rowspan="1" colspan="1">    G-Lasso</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td></tr><tr><td rowspan="1" colspan="1">    SIOL</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">0.1213</td><td rowspan="1" colspan="1">0.0331</td><td rowspan="1" colspan="1">0.0173</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td></tr><tr><td rowspan="1" colspan="1">    Mtlasso2G</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">0.0487</td><td rowspan="1" colspan="1">0.0132</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td></tr><tr><td rowspan="1" colspan="1">    Multi-task</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">0.4563</td><td rowspan="1" colspan="1">0.4132</td><td rowspan="1" colspan="1">&lt;0.0001</td></tr><tr><td rowspan="1" colspan="1">    Sparse group</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">0.4375</td><td rowspan="1" colspan="1">&lt;0.0001</td></tr><tr><td rowspan="1" colspan="1">    LORS</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">&lt;0.0001</td></tr><tr><td colspan="9" rowspan="1"><italic>Trans</italic>-enrichment</td></tr><tr><td rowspan="1" colspan="1">    GGDL</td><td rowspan="1" colspan="1">0.0881</td><td rowspan="1" colspan="1">0.0119</td><td rowspan="1" colspan="1">0.0102</td><td rowspan="1" colspan="1">0.0063</td><td rowspan="1" colspan="1">0.0006</td><td rowspan="1" colspan="1">0.0003</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td></tr><tr><td rowspan="1" colspan="1">    GDL</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">0.0481</td><td rowspan="1" colspan="1">0.0253</td><td rowspan="1" colspan="1">0.0211</td><td rowspan="1" colspan="1">0.0176</td><td rowspan="1" colspan="1">0.0004</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td></tr><tr><td rowspan="1" colspan="1">    G-Lasso</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">0.0312</td><td rowspan="1" colspan="1">0.0253</td><td rowspan="1" colspan="1">0.0183</td><td rowspan="1" colspan="1">0.0007</td><td rowspan="1" colspan="1">&lt;0.0001</td><td rowspan="1" colspan="1">&lt;0.0001</td></tr><tr><td rowspan="1" colspan="1">    SIOL</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">0.1976</td><td rowspan="1" colspan="1">0.1053</td><td rowspan="1" colspan="1">0.0044</td><td rowspan="1" colspan="1">0.0005</td><td rowspan="1" colspan="1">&lt;0.0001</td></tr><tr><td rowspan="1" colspan="1">    Mtlasso2G</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">0.1785</td><td rowspan="1" colspan="1">0.0061</td><td rowspan="1" colspan="1">0.0009</td><td rowspan="1" colspan="1">&lt;0.0001</td></tr><tr><td rowspan="1" colspan="1">    Multi-task</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">0.0235</td><td rowspan="1" colspan="1">0.0042</td><td rowspan="1" colspan="1">0.0011</td></tr><tr><td rowspan="1" colspan="1">    Sparse group</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">0.0075</td><td rowspan="1" colspan="1">0.0041</td></tr><tr><td rowspan="1" colspan="1">    LORS</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">–</td><td rowspan="1" colspan="1">0.2059</td></tr></tbody></table></table-wrap></p>
      <p>The top-1000 significant associations given by GGDL, GDL and G-Lasso are shown in <xref ref-type="fig" rid="btu293-F6">Figure 6</xref>. We can see that GGDL and GDL have stronger <italic>cis</italic>-regulatory signals than G-Lasso does. In total, these methods each detected ∼6000 associations according to non-zero <bold>W</bold> values. We estimate FDR using 50 permutations as proposed in (<xref rid="btu293-B28" ref-type="bibr">Yang <italic>et al.</italic>, 2013</xref>). With FDR ≤ 0.01, GGDL obtains ∼4500 significant associations. The plots of all identified significant associations for different methods are given in the <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu293/-/DC1">Supplementary Material</ext-link>.
<fig id="btu293-F6" position="float"><label>Fig. 6.</label><caption><p>The top-1000 significant associations identified by different methods. In each plot, the <italic>x</italic>-axis represents SNPs and <italic>y</italic>-axis represents genes. Both SNPs and genes are arranged by their locations in the genome</p></caption><graphic xlink:href="btu293f6"/></fig></p>
    </sec>
    <sec id="SEC5.2.2">
      <title>5.2.2 Refinement of the prior networks</title>
      <p>To investigate to what extend GGDL is able to refine the prior networks and study the effect of different parameter settings on κ, we intentionally change 75% elements in the original prior PPI network and genetic-interaction network to random noises. We feed the new networks to GGDL and evaluate the refined networks. The results are shown in <xref ref-type="fig" rid="btu293-F7">Figure 7</xref>. We can see that for both PPI and genetic-interaction networks, many elements are recovered by GGDL. This demonstrates the effectiveness of GGDL. Moreover, when the number of SNP (gene) pairs (κ) examined for updating reaches 100 000, both PPI and genetic-iteration networks are well refined.
<fig id="btu293-F7" position="float"><label>Fig. 7.</label><caption><p>Ratio of correct interactions refined when varying κ. The initial input networks only contain 25% correct interactions</p></caption><graphic xlink:href="btu293f7"/></fig></p>
    </sec>
    <sec id="SEC5.2.3">
      <title>5.2.3 Hotspots analysis</title>
      <p>In this section, we study whether GGDL can help detect more biologically relevant associations than the alternatives. Specifically, we examine the hotspots which affect &gt;10 gene traits (<xref rid="btu293-B17" ref-type="bibr">Lee and Xing, 2012</xref>). The top-15 hotspots detected by GGDL are listed in <xref ref-type="table" rid="btu293-T3">Table 3</xref>. The top-15 hotspots detected by other methods are included in the <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu293/-/DC1">Supplementary Material</ext-link>. From <xref ref-type="table" rid="btu293-T3">Table 3</xref>, we observe that for all hotspots, the associated genes are enriched with at least one GO category. Note that GGDL and GDL detect one hotspot (12), which cannot be detected by G-Lasso. They also detect one hotspot (6), which can not be detected by SIOL. The number of hotspots that are significant enriched is listed in <xref ref-type="table" rid="btu293-T4">Table 4</xref>. From the table, we can see that GGDL slightly outperforms GDL since it incorporates the location of SNPs and gene-pathway information.
<table-wrap id="btu293-T3" position="float"><label>Table 3.</label><caption><p>Summary of the top-15 hotspots detected by GGDL</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1">ID</th><th rowspan="1" colspan="1">Size<xref ref-type="table-fn" rid="btu293-TF1"><sup>a</sup></xref></th><th rowspan="1" colspan="1">Loci<xref ref-type="table-fn" rid="btu293-TF1"><sup>b</sup></xref></th><th rowspan="1" colspan="1">GO<xref ref-type="table-fn" rid="btu293-TF1"><sup>c</sup></xref></th><th rowspan="1" colspan="1">Hits<xref ref-type="table-fn" rid="btu293-TF1"><sup>d</sup></xref></th><th rowspan="1" colspan="1">GDL (all)<sup>e</sup></th><th rowspan="1" colspan="1">GDL (hits)<sup>f</sup></th><th rowspan="1" colspan="1">G-Lasso(all)<sup>g</sup></th><th rowspan="1" colspan="1">G-Lasso(hits)<sup>h</sup></th><th rowspan="1" colspan="1">SIOL(all)<sup>i</sup></th><th rowspan="1" colspan="1">SIOL(hits)<italic><sup>j</sup></italic></th><th rowspan="1" colspan="1">LORS(all)<italic><sup>k</sup></italic></th><th rowspan="1" colspan="1">LORS(hits)<italic><sup>l</sup></italic></th></tr></thead><tbody align="left"><tr><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">31</td><td rowspan="1" colspan="1">XII:1056097</td><td rowspan="1" colspan="1">(1)***</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">31</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">32</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">31</td><td rowspan="1" colspan="1">7</td></tr><tr><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">28</td><td rowspan="1" colspan="1">III:81832..92391</td><td rowspan="1" colspan="1">(2)**</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">29</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">28</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">58</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">4</td></tr><tr><td rowspan="1" colspan="1"><monospace>3</monospace></td><td rowspan="1" colspan="1"><monospace>28</monospace></td><td rowspan="1" colspan="1"><monospace>XII:1056103</monospace></td><td rowspan="1" colspan="1"><monospace>(1)</monospace>***</td><td rowspan="1" colspan="1"><monospace>7</monospace></td><td rowspan="1" colspan="1"><monospace>29</monospace></td><td rowspan="1" colspan="1"><monospace>6</monospace></td><td rowspan="1" colspan="1"><monospace>28</monospace></td><td rowspan="1" colspan="1"><monospace>6</monospace></td><td rowspan="1" colspan="1"><monospace>1</monospace></td><td rowspan="1" colspan="1"><monospace>1</monospace></td><td rowspan="1" colspan="1"><monospace>2</monospace></td><td rowspan="1" colspan="1"><monospace>0</monospace></td></tr><tr><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">27</td><td rowspan="1" colspan="1">III:79091</td><td rowspan="1" colspan="1">(2)***</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">29</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">28</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">28</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">2</td></tr><tr><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">27</td><td rowspan="1" colspan="1">III:175799..177850</td><td rowspan="1" colspan="1">(3)*</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">26</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">23</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">9</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">4</td></tr><tr><td rowspan="1" colspan="1"><italic>6</italic></td><td rowspan="1" colspan="1"><italic>27</italic></td><td rowspan="1" colspan="1"><italic>XII:1059925..1059930</italic></td><td rowspan="1" colspan="1"><italic>(1)</italic>***</td><td rowspan="1" colspan="1"><italic>7</italic></td><td rowspan="1" colspan="1"><italic>27</italic></td><td rowspan="1" colspan="1"><italic>7</italic></td><td rowspan="1" colspan="1"><italic>27</italic></td><td rowspan="1" colspan="1"><italic>7</italic></td><td rowspan="1" colspan="1"><italic>0</italic></td><td rowspan="1" colspan="1"><italic>0</italic></td><td rowspan="1" colspan="1"><italic>5</italic></td><td rowspan="1" colspan="1"><italic>1</italic></td></tr><tr><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">25</td><td rowspan="1" colspan="1">III:105042</td><td rowspan="1" colspan="1">(2)***</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">23</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">25</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">4</td></tr><tr><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">23</td><td rowspan="1" colspan="1">III:201166..201167</td><td rowspan="1" colspan="1">(3)***</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">23</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">13</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">23</td><td rowspan="1" colspan="1">3</td></tr><tr><td rowspan="1" colspan="1">9</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">XII:1054278..1054302</td><td rowspan="1" colspan="1">(1)***</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">26</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">24</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">24</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">12</td><td rowspan="1" colspan="1">4</td></tr><tr><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">21</td><td rowspan="1" colspan="1">III:100213</td><td rowspan="1" colspan="1">(2)**</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">23</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">23</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">1</td></tr><tr><td rowspan="1" colspan="1">11</td><td rowspan="1" colspan="1">20</td><td rowspan="1" colspan="1">III:209932</td><td rowspan="1" colspan="1">(3)*</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">21</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">16</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">15</td><td rowspan="1" colspan="1">4</td></tr><tr><td rowspan="1" colspan="1"><bold>12</bold></td><td rowspan="1" colspan="1"><bold>20</bold></td><td rowspan="1" colspan="1"><bold>XII:659357..662627</bold></td><td rowspan="1" colspan="1"><bold>(4)*</bold></td><td rowspan="1" colspan="1"><bold>4</bold></td><td rowspan="1" colspan="1"><bold>19</bold></td><td rowspan="1" colspan="1"><bold>4</bold></td><td rowspan="1" colspan="1"><bold>3</bold></td><td rowspan="1" colspan="1"><bold>0</bold></td><td rowspan="1" colspan="1"><bold>37</bold></td><td rowspan="1" colspan="1"><bold>9</bold></td><td rowspan="1" colspan="1"><bold>36</bold></td><td rowspan="1" colspan="1"><bold>6</bold></td></tr><tr><td rowspan="1" colspan="1">13</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">III:210748..210748</td><td rowspan="1" colspan="1">(5)*</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">24</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">11</td><td rowspan="1" colspan="1">4</td></tr><tr><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">VIII:111679..111680</td><td rowspan="1" colspan="1">(6)*</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">20</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">12</td><td rowspan="1" colspan="1">2</td></tr><tr><td rowspan="1" colspan="1">15</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">VIII:111682..111690</td><td rowspan="1" colspan="1">(7)**</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">21</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">20</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">57</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">3</td></tr><tr><td colspan="3" rowspan="1">Total hits</td><td colspan="2" rowspan="1">75</td><td colspan="2" rowspan="1">74</td><td colspan="2" rowspan="1">70</td><td colspan="2" rowspan="1">59</td><td colspan="2" rowspan="1">49</td></tr></tbody></table><table-wrap-foot><fn id="btu293-TF1"><p><sup>a</sup>Number of genes associated with the hotspot <sup>b</sup>The chromosome position of the hotspot. <sup>c</sup>The most significant GO category enriched with the associated gene set. The enrichment test was performed using DAVID (<xref rid="btu293-B11" ref-type="bibr">Huang <italic>et al.</italic>, 2009</xref>). The gene function is defined by GO category. The involved GO categories are: (i) telomere maintenance via recombination; (ii) branched chain family amino acid biosynthetic process; (iii). regulation of mating-type specific transcription, DNA-dependent; (iv) sterol biosynthetic process; (v) pheromone-dependent signal transduction involved in conjugation with cellular fusion; (vi) cytogamy; (vii) response to pheromone. <sup>d</sup>Number of genes that have enriched GO categories. <sup>e,g,I,k</sup>Number of associated genes that can also be identified using GDL, G-Lasso, SIOL and LORS, respectively. <sup>f,h,j,l</sup>Number of genes that have enriched GO categories and can also be identified by GDL, G-Lasso, SIOL and LORS, respectively. Among these hotspots, hotspot (12) in bold cannot be detected by G-Lasso. Hotspot (6) in italic cannot be detected by SIOL. Hotspot (3) in teletype cannot be detected by LORS. Adjusted <italic>P</italic>-values using permutation tests. *10<sup>–2</sup>∼10<sup>−3</sup>, **10<sup>−3</sup>∼10<sup>−5</sup>, ***10<sup>−5</sup>∼10<sup>−10</sup>.</p></fn></table-wrap-foot></table-wrap>
<table-wrap id="btu293-T4" position="float"><label>Table 4.</label><caption><p>Hotspots detected by different methods</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">GGDL</th><th rowspan="1" colspan="1">GDL</th><th rowspan="1" colspan="1">G-Lasso</th><th rowspan="1" colspan="1">SIOL</th><th rowspan="1" colspan="1">LORS</th></tr></thead><tbody align="left"><tr><td rowspan="1" colspan="1">Number of hotspots significantly enriched (top 15 hotposts)</td><td rowspan="1" colspan="1">15</td><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">13</td><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">9</td></tr><tr><td rowspan="1" colspan="1">Number of total reported hotspots (size &gt; 10)</td><td rowspan="1" colspan="1">65</td><td rowspan="1" colspan="1">82</td><td rowspan="1" colspan="1">96</td><td rowspan="1" colspan="1">89</td><td rowspan="1" colspan="1">64</td></tr><tr><td rowspan="1" colspan="1">Number of hotspots significantly enriched</td><td rowspan="1" colspan="1">45</td><td rowspan="1" colspan="1">56</td><td rowspan="1" colspan="1">61</td><td rowspan="1" colspan="1">53</td><td rowspan="1" colspan="1">41</td></tr><tr><td rowspan="1" colspan="1">Ratio of significantly enriched hotspots (%)</td><td rowspan="1" colspan="1">70</td><td rowspan="1" colspan="1">68</td><td rowspan="1" colspan="1">64</td><td rowspan="1" colspan="1">60</td><td rowspan="1" colspan="1">56</td></tr></tbody></table></table-wrap></p>
    </sec>
  </sec>
  <sec>
    <title>6 DISCUSSION</title>
    <p>As a promising tool for dissecting the genetic basis of common diseases, eQTL study has attracted increasing research interest. The traditional eQTL methods focus on testing the associations between individual SNPs and gene expression traits. A major drawback of this approach is that it cannot model the joint effect of a set of SNPs on a set of genes, which may correspond to biological pathways.</p>
    <p>Recent advancement in high-throughput biology has made a variety of biological interaction networks available. Effectively integrating such prior knowledge is essential for accurate and robust eQTL mapping. However, the prior networks are often noisy and incomplete. In this article, we propose novel graph-regularized-regression models to take into account the prior networks of SNPs and genes simultaneously. Exploiting the duality between the learned coefficients and incomplete prior networks enables more robust model. We also generalize our model to integrate other types of information, such as SNP locations and gene pathways. The experimental results on both simulated and real eQTL datasets demonstrate that our models outperform alternative methods. In particular, the proposed dual refinement regularization can significantly improve the performance of eQTL mapping.</p>
    <p><italic>Funding</italic>: <funding-source>National Institutes of Health</funding-source> (grants <award-id>R01HG006703</award-id> and <award-id>P50 GM076468-08</award-id>); <award-id>NSF IIS-1313606</award-id>; <award-id>NSF IIS-1162374</award-id> and <award-id>IIS-1218036</award-id>.</p>
    <p><italic>Conflict of Interest</italic>: none declared.</p>
  </sec>
</body>
<back>
  <ref-list>
    <title>REFERENCES</title>
    <ref id="btu293-B1">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Biganzoli</surname>
            <given-names>EM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Artificial neural network for the joint modelling of discrete cause-specific hazards</article-title>
        <source>Artif. Intell. Med.</source>
        <year>2006</year>
        <volume>37</volume>
        <fpage>119</fpage>
        <lpage>130</lpage>
        <pub-id pub-id-type="pmid">16730963</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B2">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bochner</surname>
            <given-names>BR</given-names>
          </name>
        </person-group>
        <article-title>New technologies to assess genotype henotype relationships</article-title>
        <source>Nat. Rev. Genet.</source>
        <year>2003</year>
        <volume>4</volume>
        <fpage>309</fpage>
        <lpage>314</lpage>
        <pub-id pub-id-type="pmid">12671661</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B3">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Boyd</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Vandenberghe</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <source>Convex Optimization</source>
        <year>2004</year>
        <publisher-loc>Cambridge</publisher-loc>
        <publisher-name>Cambridge University Press</publisher-name>
      </element-citation>
    </ref>
    <ref id="btu293-B4">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brem</surname>
            <given-names>RB</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Genetic interactions between polymorphisms that affect gene expression in yeast</article-title>
        <source>Nature</source>
        <year>2005</year>
        <volume>436</volume>
        <fpage>701</fpage>
        <lpage>703</lpage>
        <pub-id pub-id-type="pmid">16079846</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B5">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brem</surname>
            <given-names>YG</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Trans-acting regulatory variation in <italic>Saccharomyces cerevisiae</italic> and the role of transcription factors</article-title>
        <source>Nat. Genet.</source>
        <year>2003</year>
        <volume>35</volume>
        <fpage>57</fpage>
        <lpage>64</lpage>
        <pub-id pub-id-type="pmid">12897782</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B6">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Charles Boone</surname>
            <given-names>HB</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Exploring genetic interactions and networks with yeast</article-title>
        <source>Nat. Rev. Genet.</source>
        <year>2007</year>
        <volume>8</volume>
        <fpage>437C449</fpage>
        <pub-id pub-id-type="pmid">17510664</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B7">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A two-graph guided multi-task lasso approach for eqtl mapping</article-title>
        <year>2012</year>
        <comment>In <italic>AISTATS</italic>, pp. 208–217. La Palma, Canary Islands</comment>
      </element-citation>
    </ref>
    <ref id="btu293-B8">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Chung</surname>
            <given-names>FRK</given-names>
          </name>
        </person-group>
        <article-title>Spectral graph theory (reprinted with corrections)</article-title>
        <source>CBMS: Conference Board of the Mathematical Sciences, Regional Conference Series</source>
        <year>1997</year>
        <volume>Vol. 92</volume>
        <publisher-loc>Washington, DC</publisher-loc>
        <publisher-name>Published for the Conference Board of the Mathematical Sciences</publisher-name>
      </element-citation>
    </ref>
    <ref id="btu293-B9">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Orthogonal nonnegative matrix t-factorizations for clustering</article-title>
        <year>2006</year>
        <comment>In <italic>KDD</italic>, ACM, New York, pp. 126–135</comment>
      </element-citation>
    </ref>
    <ref id="btu293-B10">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>CHQ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Convex and semi-nonnegative matrix factorizations</article-title>
        <source>IEEE Trans. Pattern Anal. Mach. Intell.</source>
        <year>2010</year>
        <volume>32</volume>
        <fpage>45</fpage>
        <lpage>55</lpage>
        <pub-id pub-id-type="pmid">19926898</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B11">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>DAW</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Systematic and integrative analysis of large gene lists using DAVID bioinformatics resources</article-title>
        <source>Nat. Protoc.</source>
        <year>2009</year>
        <volume>4</volume>
        <fpage>44</fpage>
        <lpage>57</lpage>
        <pub-id pub-id-type="pmid">19131956</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B12">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jenatton</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Structured variable selection with sparsity-inducing norms</article-title>
        <source>JMLR</source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>2777</fpage>
        <lpage>2824</lpage>
      </element-citation>
    </ref>
    <ref id="btu293-B13">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Xing</surname>
            <given-names>EP</given-names>
          </name>
        </person-group>
        <article-title>Statistical estimation of correlated genome associations to a quantitative trait network</article-title>
        <source>PLoS Genet.</source>
        <year>2009</year>
        <volume>5</volume>
        <fpage>e1000587</fpage>
        <pub-id pub-id-type="pmid">19680538</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B14">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Xing</surname>
            <given-names>EP</given-names>
          </name>
        </person-group>
        <article-title>Tree-guided group lasso for multi-response regression with structured sparsity, with applications to eQTL mapping</article-title>
        <source>Ann. Appl. Stat.</source>
        <year>2012</year>
        <volume>6</volume>
        <fpage>1095</fpage>
        <lpage>1117</lpage>
      </element-citation>
    </ref>
    <ref id="btu293-B15">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lander</surname>
            <given-names>ES</given-names>
          </name>
        </person-group>
        <article-title>Initial impact of the sequencing of the human genome</article-title>
        <source>Nature</source>
        <year>2011</year>
        <volume>470</volume>
        <fpage>187</fpage>
        <lpage>197</lpage>
        <pub-id pub-id-type="pmid">21307931</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B16">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>DD</given-names>
          </name>
          <name>
            <surname>Seung</surname>
            <given-names>HS</given-names>
          </name>
        </person-group>
        <article-title>Algorithms for non-negative matrix factorization</article-title>
        <source>NIPS</source>
        <year>2000</year>
        <volume>13</volume>
        <fpage>556</fpage>
        <lpage>562</lpage>
      </element-citation>
    </ref>
    <ref id="btu293-B17">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Xing</surname>
            <given-names>EP</given-names>
          </name>
        </person-group>
        <article-title>Leveraging input and output structures for joint mapping of epistatic and marginal eQTLs</article-title>
        <source>Bioinformatics</source>
        <year>2012</year>
        <volume>28</volume>
        <fpage>i137</fpage>
        <lpage>i146</lpage>
        <pub-id pub-id-type="pmid">22689753</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B18">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Adaptive multi-task lasso: with application to eQTL detection</article-title>
        <source>NIPS</source>
        <year>2010</year>
        <comment>pp. 1306–1314, Vancouver, British Columbia, Canada</comment>
      </element-citation>
    </ref>
    <ref id="btu293-B19">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Network-constrained regularization and variable selection for analysis of genomic data</article-title>
        <source>Bioinformatics</source>
        <year>2008</year>
        <volume>24</volume>
        <fpage>1175</fpage>
        <lpage>1182</lpage>
        <pub-id pub-id-type="pmid">18310618</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B20">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Listgarten</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Correction for hidden confounders in the genetic analysis of gene expression</article-title>
        <source>Proc. Natl Acad. Sci. USA.</source>
        <year>2010</year>
        <volume>107</volume>
        <fpage>16465</fpage>
        <lpage>16470</lpage>
        <pub-id pub-id-type="pmid">20810919</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B21">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mazumder</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Spectral regularization algorithms for learning large incomplete matrices</article-title>
        <source>JMLR</source>
        <year>2010</year>
        <volume>11</volume>
        <fpage>2287</fpage>
        <lpage>2322</lpage>
        <pub-id pub-id-type="pmid">21552465</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B22">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Michaelson</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Detection and interpretation of expression quantitative trait loci (eQTL)</article-title>
        <source>Methods</source>
        <year>2009</year>
        <volume>48</volume>
        <fpage>265</fpage>
        <lpage>276</lpage>
        <pub-id pub-id-type="pmid">19303049</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B23">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Musani</surname>
            <given-names>SK</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Detection of gene x gene interactions in genome-wide association studies of human population data</article-title>
        <source>Hum. Hered.</source>
        <year>2007</year>
        <volume>63</volume>
        <fpage>67</fpage>
        <lpage>84</lpage>
        <pub-id pub-id-type="pmid">17283436</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B24">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Obozinski</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Taskar</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Multi-task feature selection</article-title>
        <year>2006</year>
        <comment><italic>Technical report 709</italic>. Statistics Department, University of California, Berkeley</comment>
      </element-citation>
    </ref>
    <ref id="btu293-B25">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pujana</surname>
            <given-names>MA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Network modeling links breast cancer susceptibility and centrosome dysfunction</article-title>
        <source>Nat. Genet.</source>
        <year>2007</year>
        <volume>39</volume>
        <fpage>1338</fpage>
        <lpage>1349</lpage>
        <pub-id pub-id-type="pmid">17922014</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B26">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Regression shrinkage and selection via the lasso</article-title>
        <source>J. Royal. Statist. Soc. B</source>
        <year>1996</year>
        <volume>58</volume>
        <fpage>267</fpage>
        <lpage>288</lpage>
      </element-citation>
    </ref>
    <ref id="btu293-B27">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>von Mering</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Comparative assessment of large-scale data sets of protein-protein interactions</article-title>
        <source>Nature</source>
        <year>2002</year>
        <volume>417</volume>
        <fpage>399</fpage>
        <lpage>403</lpage>
        <pub-id pub-id-type="pmid">12000970</pub-id>
      </element-citation>
    </ref>
    <ref id="btu293-B28">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Accounting for non-genetic factors by low-rank representation and sparse regression for eQTL mapping</article-title>
        <source>Bioinformatics</source>
        <year>2013</year>
        <volume>29</volume>
        <fpage>1026</fpage>
        <lpage>1034</lpage>
        <pub-id pub-id-type="pmid">23419377</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
