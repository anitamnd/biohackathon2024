<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.0 20120330//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.0?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Genome Res</journal-id>
    <journal-id journal-id-type="iso-abbrev">Genome Res</journal-id>
    <journal-id journal-id-type="hwp">genome</journal-id>
    <journal-id journal-id-type="pmc">genome</journal-id>
    <journal-id journal-id-type="publisher-id">GENOME</journal-id>
    <journal-title-group>
      <journal-title>Genome Research</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1088-9051</issn>
    <issn pub-type="epub">1549-5469</issn>
    <publisher>
      <publisher-name>Cold Spring Harbor Laboratory Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">4448687</article-id>
    <article-id pub-id-type="pmid">25883319</article-id>
    <article-id pub-id-type="medline">9509184</article-id>
    <article-id pub-id-type="doi">10.1101/gr.176552.114</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Method</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>An efficient and scalable analysis framework for variant extraction and refinement from population-scale DNA sequence data</article-title>
      <alt-title alt-title-type="left-running">Jun et al.</alt-title>
      <alt-title alt-title-type="right-running">Efficient and scalable variant calling framework</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Jun</surname>
          <given-names>Goo</given-names>
        </name>
        <xref ref-type="aff" rid="af1">1</xref>
        <xref ref-type="aff" rid="af2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wing</surname>
          <given-names>Mary Kate</given-names>
        </name>
        <xref ref-type="aff" rid="af2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Abecasis</surname>
          <given-names>Gonçalo R.</given-names>
        </name>
        <xref ref-type="aff" rid="af2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kang</surname>
          <given-names>Hyun Min</given-names>
        </name>
        <xref ref-type="aff" rid="af2">2</xref>
      </contrib>
    </contrib-group>
    <aff id="af1"><label>1</label>Human Genetics Center, School of Public Health, The University of Texas Health Science Center at Houston, Houston, Texas 77030, USA;</aff>
    <aff id="af2"><label>2</label>Center for Statistical Genetics and Department of Biostatistics, University of Michigan School of Public Health, Ann Arbor, Michigan 48109, USA</aff>
    <author-notes>
      <corresp>Corresponding author: <email>hmkang@umich.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>6</month>
      <year>2015</year>
    </pub-date>
    <volume>25</volume>
    <issue>6</issue>
    <fpage>918</fpage>
    <lpage>925</lpage>
    <history>
      <date date-type="received">
        <day>31</day>
        <month>3</month>
        <year>2014</year>
      </date>
      <date date-type="accepted">
        <day>13</day>
        <month>4</month>
        <year>2015</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>
        <ext-link ext-link-type="uri" xlink:href="http://genome.cshlp.org/site/misc/terms.xhtml">© 2015 Jun et al.; Published by Cold Spring Harbor Laboratory Press</ext-link>
      </copyright-statement>
      <copyright-year>2015</copyright-year>
      <license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This article is distributed exclusively by Cold Spring Harbor Laboratory Press for the first six months after the full-issue publication date (see <ext-link ext-link-type="uri" xlink:href="http://genome.cshlp.org/site/misc/terms.xhtml">http://genome.cshlp.org/site/misc/terms.xhtml</ext-link>). After six months, it is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="918.pdf"/>
    <abstract>
      <p>The analysis of next-generation sequencing data is computationally and statistically challenging because of the massive volume of data and imperfect data quality. We present GotCloud, a pipeline for efficiently detecting and genotyping high-quality variants from large-scale sequencing data. GotCloud automates sequence alignment, sample-level quality control, variant calling, filtering of likely artifacts using machine-learning techniques, and genotype refinement using haplotype information. The pipeline can process thousands of samples in parallel and requires less computational resources than current alternatives. Experiments with whole-genome and exome-targeted sequence data generated by the 1000 Genomes Project show that the pipeline provides effective filtering against false positive variants and high power to detect true variants. Our pipeline has already contributed to variant detection and genotyping in several large-scale sequencing projects, including the 1000 Genomes Project and the NHLBI Exome Sequencing Project. We hope it will now prove useful to many medical sequencing studies.</p>
    </abstract>
    <funding-group>
      <award-group id="funding-1">
        <funding-source>National Institutes of Health <named-content content-type="funder-id">http://dx.doi.org/10.13039/100000002</named-content></funding-source>
      </award-group>
      <award-group id="funding-2">
        <funding-source>National Human Genome Research Institute <named-content content-type="funder-id">http://dx.doi.org/10.13039/100000051</named-content></funding-source>
        <award-id>U01 HG006513</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <p>The cost of human genome sequencing has declined rapidly, powered by advances in massively parallel sequencing technologies. This has made possible the collection of genomic information on an unprecedented scale and made large-scale sequencing a practical strategy for biological and medical studies. An initial step for nearly all sequencing studies is to detect variant sites among sampled individuals and genotype them. This analysis is challenging because errors in high-throughput sequence data are much more common than true genomic variation. There are diverse sources of trouble (base-calling errors, alignment artifacts, contaminant reads derived from other samples), and the resulting errors are often correlated. The analysis is also computationally and statistically challenging because of the volume of data involved. Using standard formats, raw sequence reads for a single deeply (30×) sequenced human genome require &gt;100 gigabytes (GB) of storage.</p>
  <p>Several tools are now available to process next-generation sequencing data. For example, the Genome Analysis Toolkit (GATK) (<xref rid="JUNGR176552C6" ref-type="bibr">DePristo et al. 2011</xref>), SAMtools (<xref rid="JUNGR176552C9" ref-type="bibr">Li 2011</xref>), and SNPTools (<xref rid="JUNGR176552C13" ref-type="bibr">Wang et al. 2013</xref>) are used for variant discovery and genotyping from small to moderate numbers of sequenced samples. However, as the number of sequenced genomes grows, analysis becomes increasingly challenging, requiring complex data processing steps, division of sequence data into many small regions, management and scheduling of analysis jobs, and often, prohibitive demands on computing resources. A tempting approach to alleviate computational burden is to process samples in small batches, but this can lead to reduced power for rare variant discovery and systematic differences between samples processed in different batches.</p>
  <p>There is a pressing need for software pipelines that support large-scale medical sequencing studies that will be made possible by decreased sequencing costs. Desirable features for such pipelines include (1) scalability to tens of thousands of samples; (2) the ability to easily stop and resume analyses; (3) the option to carry out incremental analyses as new samples are sequenced; (4) flexibility to accommodate different study designs: shallow and deep sequencing, whole-genome, whole-exome, or small targeted experiments; and, of course, (5) high-quality genotyping and variant discovery.</p>
  <p>Here, we describe and evaluate our flexible and efficient sequence analysis software pipeline, Genomes on the Cloud (GotCloud). We show that GotCloud delivers high-quality variant sites and accurate genotypes across thousands of samples. We describe the strategies to systematically divide processing of very large data sets into manageable pieces. We also demonstrate novel automated frameworks for filtering sequencing and alignment artifacts from variant calls as well as for accurate genotyping using haplotype information.</p>
  <sec sec-type="results" id="s1">
    <title>Results</title>
    <p>GotCloud offers a comprehensive pipeline including sequence alignment, post-alignment processing and quality control, variant calling, variant filtering, and haplotype-aware genotype refinement, as described in the Methods section (<xref ref-type="fig" rid="JUNGR176552F1">Fig. 1</xref>). In this section we highlight and evaluate key features of GotCloud, including the computational efficiency and the robustness of variant calling and filtering, compared with GATK UnifiedGenotyper. Our GotCloud variant calling pipeline has been used in many large genome and exome sequencing studies, each with thousands of samples (<xref ref-type="table" rid="JUNGR176552TB1">Table 1</xref>).</p>
    <fig id="JUNGR176552F1" orientation="portrait" position="float">
      <label>Figure 1.</label>
      <caption>
        <p>Outline of GotCloud variant calling pipeline.</p>
      </caption>
      <graphic xlink:href="918f01"/>
    </fig>
    <table-wrap id="JUNGR176552TB1" orientation="portrait" position="float">
      <label>Table 1.</label>
      <caption>
        <p>GotCloud pipeline in large-scale sequencing studies</p>
      </caption>
      <graphic xlink:href="918tb01"/>
    </table-wrap>
    <fig id="JUNGR176552F2" orientation="portrait" position="float">
      <label>Figure 2.</label>
      <caption>
        <p>Computational costs of GATK UnifiedGenotyper and GotCloud pipelines. (<italic>A</italic>) Runtime estimated for whole-genome (6×) and whole-exome (60×) sequence data running with 40 parallel sessions on a four-node minicluster with 48 physical CPU cores. For GATK, runtimes for 1000 samples are extrapolated from analyses of a single 5-Mb block of Chromosome 20. For all other analyses, no extrapolation was used. (<italic>B</italic>) Peak memory usage estimates averaged over Chromosome 20 chunks.</p>
      </caption>
      <graphic xlink:href="918f02"/>
    </fig>
    <sec id="s1a">
      <title>Evaluation of computational efficiency</title>
      <p>Using low-coverage genome and exome data sets from the 1000 Genomes Project, we evaluate the computational efficiency of GotCloud using a minicluster with four dedicated computing nodes, where each node has 48 physical CPU cores and 64 GB of main memory. <xref ref-type="fig" rid="JUNGR176552F2">Figure 2</xref>A summarizes the total computational costs as a function of sample size, comparing the GotCloud variant calling pipeline and the GATK UnifiedGenotyper.</p>
      <p>For low-coverage genomes, total runtimes for both GotCloud and GATK increase at a faster than linear rate with sample size, because increased sample size increases not only the number of samples (and the amount of sequence data) to process but also results in more discovered variant sites, which must be inspected in each sample for genotyping and variant filtering. For both low-coverage genomes and deep exomes, GotCloud ran faster than GATK, most noticeably for analyses of &gt;500 samples. This speed advantage increases gradually. For analysis of 1000 low-coverage samples, GotCloud took ∼5700 CPU hours, whereas GATK took ∼16,500 CPU hours. Similarly, for 1000 exomes, GotCloud took ∼750 CPU hours and GATK took ∼2930 CPU hours.</p>
      <p>GotCloud also maintains an efficient memory footprint (<xref ref-type="fig" rid="JUNGR176552F2">Fig. 2</xref>B). While GATK required &gt;7 GB of memory to analyze a thousand exomes, GotCloud on average required &lt;1 GB of memory. In memory-bound computing environments with a large number of concurrent processes, which is a common practice for large-scale sequencing studies, GotCloud can host approximately 10 times more concurrent processes than GATK.</p>
      <p>Unlike low-coverage genomes, the runtime for deep exomes grows almost linearly with sample size, because the majority of computational effort is spent on the “pileup” step that summarizes deep sequence data, whereas little time is spent on the “glfMultiples” variant calling processes due to the relatively small target size (Supplemental Fig. 1).</p>
    </sec>
    <sec id="s1b">
      <title>Evaluation of variant detection sensitivity</title>
      <p>We next assessed the variant detection sensitivity of GotCloud and GATK with increasing sample sizes for low-coverage genomes. For both GATK and GotCloud, the number of detected variants per sample increased as more samples were analyzed together (<xref ref-type="table" rid="JUNGR176552TB2">Tables 2</xref>, <xref ref-type="table" rid="JUNGR176552TB3">3</xref>; Supplemental Table S3), particularly when the coverage was low. This is consistent with our expectation because variants shared between samples are more likely to be detected when the information across samples is combined (<xref rid="JUNGR176552C16" ref-type="bibr">Li et al. 2010</xref>).</p>
      <table-wrap id="JUNGR176552TB2" orientation="portrait" position="float">
        <label>Table 2.</label>
        <caption>
          <p>Summary of variant calling results and the effect of filtering for low-pass sequence data</p>
        </caption>
        <graphic xlink:href="918tb02"/>
      </table-wrap>
      <table-wrap id="JUNGR176552TB3" orientation="portrait" position="float">
        <label>Table 3.</label>
        <caption>
          <p>Comparison of SNP call sets (unfiltered and filtered) between GATK UnifiedGenotyper and GotCloud for low-coverage genome data</p>
        </caption>
        <graphic xlink:href="918tb03"/>
      </table-wrap>
      <p>We calculated the fraction of detected variants among the polymorphic variants in HumanExome BeadChip arrays as a measure of variant detection sensitivity. We excluded the variants included in the Omni2.5 SNP genotyping array, which was used for training the SVM filters. As expected, GotCloud's HumanExome BeadChip sensitivity for low-coverage data increased from 71.4% to 75.3% as the sample size increased from 10 to 1000 (<xref ref-type="fig" rid="JUNGR176552F3">Fig. 3</xref>A). For deep exome data, the sensitivity also increased from 90.8% to 94.2% (<xref ref-type="fig" rid="JUNGR176552F3">Fig. 3</xref>B). GATK showed lower sensitivity both for low-coverage data (67.4%–71.5%), and deep exome data (78.3%–89.6%). GotCloud consistently showed higher variant detection sensitivity than GATK in every comparison.</p>
      <fig id="JUNGR176552F3" orientation="portrait" position="float">
        <label>Figure 3.</label>
        <caption>
          <p>Variant discovery sensitivity comparison of GotCloud and GATK using HumanExome BeadChip excluding the SNPs contained in Omni2.5 array, because Omni2.5 variants are used to train variant filters in GotCloud and GATK. GotCloud results are shown for unfiltered (raw) and SVM-filtered sets, and GATK results are shown for unfiltered and VQSR-filtered sets, across low-coverage genome (<italic>A</italic>) and exome data (<italic>B</italic>).</p>
        </caption>
        <graphic xlink:href="918f03"/>
      </fig>
    </sec>
    <sec id="s1c">
      <title>Evaluation of variant filtering</title>
      <p>We evaluated the quality of filtered variant calls by looking at the transition to transversion ratio (Ts/Tv). To complement the sensitivity analysis, we evaluated the quality of the filtered calls using the HumanExome BeadChip sensitivity described above.</p>
      <p>Previous studies report whole-genome Ts/Tv between 2.1 and 2.3 (<xref rid="JUNGR176552C6" ref-type="bibr">DePristo et al. 2011</xref>), but the exact value is affected by allele frequency, GC content, proportion of CpG sites, natural selection, and other factors. Instead of setting a specific target Ts/Tv value, we compared the Ts/Tv between “known” SNPs (those in dbSNP) and “novel” SNPs (those not in dbSNP). We used dbSNP version 129, which is the latest release without variants from next-generation sequencing. Large differences in Ts/Tv between known and novel SNPs suggest that the “novel” SNP list likely includes variants with unusual properties, indicating potential false positives.</p>
      <p>In GotCloud's two-step filtering process (<xref ref-type="fig" rid="JUNGR176552F1">Fig. 1</xref>), variants with lower quality are first identified by applying individual hard filters (Supplemental Table S1), and variants failing multiple hard filters are used as negative examples to train a support vector machine (SVM) classifier (See Methods for details). In our analysis of 1000 low-coverage samples, the difference of Ts/Tv between known (2.29) and novel (2.16) SNPs was high before SVM filtering, suggesting that novel SNPs have a lower quality than known SNPs. After SVM filtering, known (2.33) and novel (2.32) SNPs have similar Ts/Tv, suggesting that many false positive SNPs were filtered out. The trend was similar for all other sample sizes.</p>
      <p>Our SVM filter reduces the variant detection sensitivity by only a small amount. The HumanExome BeadChip sensitivity was reduced by only 0.5%–0.9% after removing 8%–13% of the unfiltered calls, suggesting that the vast majority of SNPs filtered out are likely false positives (<xref ref-type="fig" rid="JUNGR176552F3">Fig. 3</xref>). The variant quality score recalibration (VQSR) filter from GATK reduced sensitivity by 0.1%–2.4% after removing 1.6%–25% of the unfiltered calls, across different sample sizes.</p>
      <p>In exomes, we expect higher Ts/Tv than in other regions because degeneracy of the genetic code means that selection against variants that alter protein sequence preferentially removes transversion alleles from the population, as reported in previous studies on population-scale exome sequencing (<xref rid="JUNGR176552C17" ref-type="bibr">Tennessen et al. 2012</xref>; <xref rid="JUNGR176552C15" ref-type="bibr">Fu et al. 2013</xref>). Differences between known and novel SNPs are also expected as a result of natural selection since protein-coding variants (which are more often transversions) tend to be rarer than variants that do not alter protein sequence (which are more often transitions). To facilitate interpretation, we stratify the analysis of exome samples and examine nonsynonymous variants that alter protein sequence separately from synonymous variants that do not.</p>
      <p>In exome sequencing, we again observed that (within each functional category) Ts/Tv for known and novel variants became much more similar after filtering (Supplemental Table S2). With 1000 exomes, Ts/Tv at nonsynonymous SNPs were 2.24 and 1.61 for known and novel variants before filtering, which became 2.33 and 2.31, respectively, after filtering. For synonymous SNPs, Ts/Tv of 5.40 and 4.05 for known and novel variants before filtering became 5.55 and 5.49 after filtering. We expect that filtering becomes progressively more effective with larger sample sizes because the SVM classifier can better learn how to use diagnostics such as allele balance in heterozygotes and strand preference for the reference when more data are available. This expectation is confirmed by inspection of <xref ref-type="table" rid="JUNGR176552TB2">Table 2</xref> and Supplemental Table S2, where differences between known and novel variants after filtering become progressively smaller as sample size increases.</p>
      <p>Because multiple features are combined to construct SVM classifiers, GotCloud's SVM filtering outperforms the filtering approach using any individual feature. We ordered variants based on each individual feature, and evaluated the Ts/Tv of variants after applying the filters based on a single feature (<xref ref-type="fig" rid="JUNGR176552F4">Fig. 4</xref>A) and the HumanExome BeadChip sensitivity lost by applying each filter (<xref ref-type="fig" rid="JUNGR176552F4">Fig. 4</xref>B). SVM filtering showed the largest separation of Ts/Tv between filtered-in and filtered-out variants (2.32 versus 1.20) and the smallest loss of HumanExome BeadChip sensitivity (0.5%). Some filters based on individual features, such as StrandBias or AlleleBalance, achieved similar separation of Ts/Tv to SVM filters but showed &gt;5× larger (2.8%–3.2%) loss of HumanExome BeadChip sensitivity. Our results demonstrate that the SVM filter provides an automatic and powerful framework to distinguish likely true and false variants.</p>
      <fig id="JUNGR176552F4" orientation="portrait" position="float">
        <label>Figure 4.</label>
        <caption>
          <p>Comparison of SVM filtering with hard filtering based on a single feature. (<italic>A</italic>) Ts/Tv of filtered-in (PASS) and filtered-out (FAIL) variants using different filters. Variants are ordered by a single variant feature and a fixed fraction of variants (8%) are filtered out to match the variant counts with the default SVM filter. Absolute values are used for StrandBias correlation and CycleBias correlation. (<italic>B</italic>) Percentage of filtered-out HumanExome BeadChip (Omni2.5) variants among those that are polymorphic in the array genotypes.</p>
        </caption>
        <graphic xlink:href="918f04"/>
      </fig>
    </sec>
    <sec id="s1d">
      <title>Portability of SVM decision rules</title>
      <p>GotCloud provides robust filtering for small targeted sequencing experiments in most cases, because SVM requires only a small number of positive and negative labels to find a decision boundary. In some cases, however, the number of labeled variants may be too small to develop adequate training models. GotCloud allows the transferring of SVM classification models across data sets. Our classification model is robust to the differences in feature distribution between data sets because the filtering is based on quantile-normalized feature space. We applied our model-transfer filtering trained from whole-exome sequencing data of independent samples onto small subsets of exome sequencing data, mimicking small target sequencing of 10 kb to 10 Mb. We used 500 exome samples from the 1000 Genomes Project to train the SVM classifier, and used another 500 nonoverlapping exome samples to simulate small target sequencing. Our results demonstrate that the model-transfer filtering provides higher novel Ts/Tv than the self-trained SVM filtering trained within only the target regions, especially when the target region was smaller (<xref ref-type="fig" rid="JUNGR176552F5">Fig. 5</xref>). In the experiment with the smallest target region of 10 kb, the self-trained model shows some differences between known (2.32) and novel (2.25) Ts/Tv for nonsynonymous SNPs, while the transfer model shows smaller differences between known (2.35) and novel (2.33) Ts/Tv. In our experimental setup where there is little or no systematic difference between the data sets, model-transfer filtering appears to perform as good as the self-trained SVM, even for large target regions. Based on our experiences, when there are systematic differences between the sequencing data sets, the self-trained model will likely perform better when the target region is large (e.g., &gt;1 Mb).</p>
      <fig id="JUNGR176552F5" orientation="portrait" position="float">
        <label>Figure 5.</label>
        <caption>
          <p>Impact of model-transfer filtering on the variant quality. The vertical axis represents Ts/Tv for novel SNPs for model-transferred SVM and self-trained SVM filters. Ts/Tv for known SNPs are ∼3.5, which is higher than novel SNPs because known SNPs contain a larger fraction of synonymous SNPs. The horizontal axis represents the size of targeted regions randomly selected from 500 whole-exome sequences. The transferred model is trained on nonoverlapping 500 exome data.</p>
        </caption>
        <graphic xlink:href="918f05"/>
      </fig>
    </sec>
    <sec id="s1e">
      <title>Effect of trimming overlapping fragments</title>
      <p>One of the previously undocumented ways that GotCloud improves the quality of the variant lists is to appropriately account for overlapping fragments in paired end reads. Read pairs derived from small fragments may often overlap using our stand-alone tool <italic>bamUtil clipOverlap</italic>. If errors occur in the PCR amplification step, these overlapping fragments will carry errors forward to both paired reads. In these cases, a single-base sequencing error may appear to be two independent mismatches, resulting in false positive SNP calls. GotCloud, by default, trims the overlapping fragment with lower sequencing quality to avoid these artifacts. This artifact is more problematic for very rare variants where filtering based on multisample statistics is not as useful; hence we evaluated our approach by analyzing Ts/Tv ratios for the singletons, which are the variants with the lowest possible allele count (AC = 1). Our evaluation with low-coverage sequencing data demonstrates that the Ts/Tv of novel singletons substantially decreases from 2.21 to 1.97 if the overlapping fragments are not accounted for properly (<xref ref-type="fig" rid="JUNGR176552F6">Fig. 6</xref>).</p>
      <fig id="JUNGR176552F6" orientation="portrait" position="float">
        <label>Figure 6.</label>
        <caption>
          <p>Comparison of known and novel Ts/Tv with and without trimming overlapping reads for 1000 low-coverage Chromosome 20 sequences from the 1000 Genomes Project. Overlapping fragments lowers novel Ts/Tv and the effect is more eminent in the singletons (with allele count of one).</p>
        </caption>
        <graphic xlink:href="918f06"/>
      </fig>
    </sec>
    <sec id="s1f">
      <title>Haplotype-aware genotype refinement</title>
      <p>GotCloud also provides an automated pipeline to parallelize haplotype-aware genotype refinement. We evaluated the benefits of haplotype-aware refinement for low-coverage whole genomes. SVM-filtered VCF files were supplied to Beagle (50 rounds), and Beagle haplotypes were used to seed ThunderVCF (20 rounds). We measured nonreference genotype concordances using Omni2.5 array genotypes (<xref ref-type="fig" rid="JUNGR176552F7">Fig. 7</xref>). For 10 samples, nonreference discordance was reduced from 10.0% before refinement to 6.56% after Beagle refinement, and then further reduced to 5.36% after ThunderVCF. Since haplotype-aware refinement depends on the number of available haplotypes, the improvements were greater with more samples. After refinement, the nonreference discordance for the 100 sample experiment was reduced from 10.38% to 2.37%, and for 1000 samples it was reduced from 10.21% to 1.48%, consistent with our previous experiments (<xref rid="JUNGR176552C11" ref-type="bibr">Li et al. 2011</xref>; <xref rid="JUNGR176552C1" ref-type="bibr">The 1000 Genomes Project Consortium 2012</xref>).</p>
      <fig id="JUNGR176552F7" orientation="portrait" position="float">
        <label>Figure 7.</label>
        <caption>
          <p>Nonreference genotype concordance for low-pass genome data calculated using Omni2.5 array genotypes. The haplotype-aware refinement steps significantly improve genotype accuracy, especially with larger sample sizes.</p>
        </caption>
        <graphic xlink:href="918f07"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s2">
    <title>Discussion</title>
    <p>The GotCloud pipeline provides an efficient and flexible framework for analyses of large-scale sequence data. Experimental results show that GotCloud discovers and genotypes high-quality SNPs by combining population-based multisample calling and machine-learning-based filtering. It also requires less computational time and has a smaller memory footprint than the popular GATK pipeline. GotCloud provides a complete end-to-end pipeline from raw sequence data to variant calls, to haplotype-aware genotype refinement that substantially improves accuracy for low-pass whole-genome sequencing.</p>
    <p>GotCloud achieves a small memory footprint even with many deeply sequenced samples because the “pileup” step summarizes one sample at a time into a compact likelihood representation that is largely independent of sequencing depth. Once data for each sample has been summarized, variant calling reviews “pileup” results for many samples, one region at a time, using much less computing resources than would be required for accessing BAM files directly. The advantages of this approach will become more marked as sequencing depth increases. As a result, GotCloud can process larger sample sizes with the same memory or (by accommodating more parallel processes) achieve an even greater speed advantage.</p>
    <p>Another advantage of separating the “pileup” and the “variant calling” steps is the possibility of incremental processing. Large-scale DNA sequencing studies can take many years of time and effort, and it is common to produce sequence data in multiple batches and generate multiple iterations of the variant calls for intermediate analyses and quality assurance. When a new batch of samples is added for a new round of variant calling, GotCloud needs to run the time-consuming pileup step only on the new samples, while one-pass pipelines need to reprocess all BAM files at each iteration of the analysis. For example, consider a scenario where an additional 200 exome sequencing samples are added to the 1000 existing samples (<xref ref-type="fig" rid="JUNGR176552F2">Fig. 2</xref>A; Supplemental Fig. 1B). To generate a new SNP set over all 1200 samples, GotCloud requires ∼150 CPU hours for pileup of the 200 new samples and &lt;50 CPU hours for glfMultiples to regenerate variant lists, achieving ∼75% of reduction in computing time compared with the case of doing everything from scratch.</p>
    <p>The GotCloud pipeline has customizable options such as the size of genomic chunks to be processed in parallel, the regions for targeted sequencing, and filtering parameters. Default parameter settings are provided for common study designs, but these parameters can be changed to leverage expert knowledge based on sequencing protocol, study design, objectives, and computing environments.</p>
    <p>For filtering, default parameters (Supplemental Table S1) should be adequate for most scenarios, because the final SVM-filtered results from GotCloud are not very sensitive to any single threshold. When generating a variant ranking strategy, the SVM classifier combines information across the many variants that fail multiple hard filters, unlike the hard-filtering approach where one inadequate threshold directly affects the filtering results. For unusual scenarios such as drastic changes in sequencing technologies used, we provide detailed guidelines for parameter tuning in the user's manual (<uri xlink:href="http://www.gotcloud.org">http://www.gotcloud.org</uri>).</p>
    <p>In summary, GotCloud is an efficient, flexible, scalable, and integrated framework that can transform raw sequence data into high-quality variants calls and genotypes. GotCloud has already proven useful in several large-scale sequencing studies. With unprecedented growth of the sequencing throughput now enabling us to produce tens of thousands of deep genomes, we expect that GotCloud will continue to contribute to our common goal of completing the map of human genetic variation and its consequences. GotCloud is under active development with several key improvements expected in the near future and will continue to include updates to cutting edge open source methods.</p>
  </sec>
  <sec sec-type="methods" id="s3">
    <title>Methods</title>
    <p>An overview of our GotCloud pipeline is given in <xref ref-type="fig" rid="JUNGR176552F1">Figure 1</xref>. GotCloud combines several components, including: alignment, variant calling, variant filtering, and genotype refinement. The alignment step takes raw sequence reads stored in FASTQ files as input and generates sample level sequence quality summaries and binary sequence aligned/mapped (BAM) files as output. Subsequent steps take these BAM files as input and generate progressively more refined variant call format (VCF) files as output. The variant calling, filtering, and genotyping steps consist of four major tasks: building a pileup summary of variation per individual, identifying an initial set of variant sites, filtering poor quality variants and, finally, an optional genotype refinement step which is recommended for whole-genome sequence data and improves initial genotype calls by leveraging haplotype information.</p>
    <p>Each processing step is divided into a series of small tasks and file dependencies are managed by the GNU make utility. GNU make handles scheduling of the different tasks and deploys tasks in highly parallel environments, such as high-performance computing clusters. Dividing work into thousands of small jobs increases memory efficiency, avoiding monolithic steps that must process many terabytes of data directly. In the remainder of the Methods section, we provide additional details on each step.</p>
    <sec id="s3a">
      <title>Automated sequence alignment, post-processing, and quality assessment</title>
      <p>The first step of analysis with GotCloud is to align raw sequence reads (in FASTQ format) to the reference genome and post-process the aligned reads (in BAM format) to be ready for variant calling. GotCloud uses widely available alignment software, such as BWA (<xref rid="JUNGR176552C10" ref-type="bibr">Li and Durbin 2009</xref>) and MOSAiK (<xref rid="JUNGR176552C14" ref-type="bibr">Zhao et al. 2013</xref>), to generate initial BAM files. After the initial alignment, each BAM file is sorted by genomic coordinates and post-processed to remove duplicated reads and recalibrate base quality scores in a computationally and memory efficient manner using our <italic>bamUtil</italic> tool included in GotCloud. After these steps, several quality control metrics (such as the number of mapped reads, base-quality distribution, insert size distribution, GC bias profile, sample identity checks, and estimated DNA sample contamination) are produced and stored into summary files (<xref rid="JUNGR176552C8" ref-type="bibr">Jun et al. 2012</xref>; <xref rid="JUNGR176552C12" ref-type="bibr">Li et al. 2013</xref>). These quality assessment steps provide a snapshot of data quality and help identify problems such as low library complexity, insufficient read depth, DNA sample swaps, and sample contamination. Removal of poor performing samples at early steps of the analysis chain helps improve the overall quality of study results.</p>
    </sec>
    <sec id="s3b">
      <title>Parallelized and incremental variant discovery</title>
      <p>GotCloud's variant discovery step generates an initial unfiltered VCF from a set of BAM files, based on two major tasks–pileup and glfMultiples. The first task, “pileup,” summarizes overlapping bases for each position one sample at a time and produces genotype likelihood files by calculating the probability of observed bases given hypothetical true genotypes at each genomic position. GotCloud uses a modified version of SAMtools to generate genotype likelihoods for all 10 possible diploid SNP genotypes and store them in GLF format (<xref rid="JUNGR176552C9" ref-type="bibr">Li 2011</xref>). This “pileup” task processes one sample at time and the resulting genotype likelihood files are divided into short chromosomal segments to facilitate downstream analyses. When a read pair has overlapping fragments due to short insert size, the fragment with lower average base quality is trimmed to avoid false positive variants due to PCR artifacts.</p>
      <p>The second task, “glfMultiples,” reviews the “pileup” results of the same chromosomal segment across all samples to identify variant sites. The computational complexity of the glfMultiples step is largely insensitive to sequencing depth and increases almost linearly with the number of samples and the length of the genome targeted for analysis. As a result, GotCloud can efficiently handle thousands of deeply sequenced samples together, which is challenging for most variant callers. Our multisample SNP caller, glfMultiples, uses a naïve Bayes model to compute the probability that an alternative allele is present given observed data and a population-based prior. It has high power to detect shared variants among individuals, especially with large numbers of sequenced samples. A more detailed description of glfMultiples algorithm is provided by <xref rid="JUNGR176552C11" ref-type="bibr">Li et al. (2011)</xref>.</p>
    </sec>
    <sec id="s3c">
      <title>Variant filtering by leveraging machine-learning methods</title>
      <p>High-throughput sequencing reads are prone to sequencing errors and alignment artifacts. As a result, initial variant site lists typically contain many false positives. To improve the quality of variant lists, we apply a filtering step that evaluates a series of features at each potential site. Using machine-learning techniques, these features are then used to identify the highest quality variants and reduce the number of false positive variants.</p>
      <p>Features for each potential site are extracted from BAM files one sample at a time in a highly parallelized manner, and the results are organized into small files each representing a short stretch of the genome. We calculate features reflecting site-specific sequencing quality, such as sequencing depth and the fraction of bases with low-quality scores, and features reflecting the quality of the evidence for a variant, such as the fraction of bases with the reference allele in heterozygous samples (allele balance) and the correlation between observed alleles and the read direction (strand bias). The complete list of features is provided in Supplemental Table 1. Most of these become progressively more informative as they are cumulated across many samples. For example, observing that 75% of bases match the reference allele in a single heterozygous sample is not strong evidence of an artifact, but the same observation averaged across many heterozygotes can suggest systematic biases due to mapping artifacts or the existence of nearby complex variants.</p>
      <p>One possible approach for combining many features together for variant filtering is to set thresholds for each feature based on expert knowledge (“hard filtering”). This is extremely laborious to calibrate and hard to replicate across different data sets. We utilize a machine-learning-based approach, based on support vector machines (SVM) that combine all available features into a variant quality score (<xref rid="JUNGR176552C5" ref-type="bibr">Cortes and Vapnik 1995</xref>). GotCloud uses an open-source implementation of SVM, libSVM (<xref rid="JUNGR176552C4" ref-type="bibr">Chang and Lin 2011</xref>).</p>
      <p>To train the classifier, we first generate a list of positive and negative examples. We utilize external information to generate a list of likely true positives and use an initial set of hard filters to generate a list of likely false positives. By default, the list of likely true positives is the union of array-based polymorphic sites identified from the HapMap Project (The <xref rid="JUNGR176552C7" ref-type="bibr">International HapMap Consortium 2007</xref>) and the 1000 Genomes Project (<xref rid="JUNGR176552C11" ref-type="bibr">Li et al. 2011</xref>; <xref rid="JUNGR176552C1" ref-type="bibr">The 1000 Genomes Project Consortium 2012</xref>). Lists of likely false positives are seeded with sites that fail multiple stringent hard-filters, set as shown in Supplemental Table 1. The SVM classifier defines a decision boundary in the high-dimensional coordinate space defined by all available features, maximizing the distance between the decision boundary and the likely true false positives. We utilize the commonly used radial basis function (RBF) kernel (<xref rid="JUNGR176552C2" ref-type="bibr">Amari and Wu 1999</xref>).</p>
      <p>GotCloud also offers the ability to transfer a SVM model to another data set. This is especially useful for small targeted sequencing experiments where sufficient positive and negative examples might not be available for training (because of limited overlap with HapMap or 1000 Genome site lists, for example). Once a SVM classifier is trained on a large data set, the model can be stored and reused for filtering of other smaller-sized sequencing studies. In our experience, model-transfer SVM will likely perform better than self-trained SVM when the target region is &lt;1 Mb.</p>
    </sec>
    <sec id="s3d">
      <title>Haplotype-aware genotype refinement</title>
      <p>The final step of the GotCloud pipeline is genotype refinement. In this step, genotype calls are refined using haplotype information. This step is based on the observation that genotypes at any site are likely to be similar for individuals that share a stretch of sequence (or haplotype) surrounding that site. In the 1000 Genomes Project Consortium analyses, haplotype-based genotype refinement improved genotype accuracy of low-coverage whole-genome data, resulting in genotype accuracies for low-coverage data that were similar to those for deeply sequenced exomes (<xref rid="JUNGR176552C1" ref-type="bibr">The 1000 Genomes Project Consortium 2012</xref>), in sites shared by multiple individuals. Haplotype-based genotype refinement is especially useful for improving genotype accuracy for low-coverage whole-genome sequences and also for phasing whole-genome sequences for any coverage, although at the expense of additional computational cost (<xref ref-type="table" rid="JUNGR176552TB1">Table 1</xref>). The procedure is less useful for targeted exome sequencing, because identifying shared haplotypes is challenging without long contiguous stretches of sequence.</p>
      <p>GotCloud uses two tools for genotype refinement: Beagle (<xref rid="JUNGR176552C3" ref-type="bibr">Browning and Yu 2009</xref>) and ThunderVCF (<xref rid="JUNGR176552C11" ref-type="bibr">Li et al. 2011</xref>). Beagle is computationally efficient, but the resulting haplotypes can be made more accurate by additionally running ThunderVCF, which is based on a model used by MaCH (<xref rid="JUNGR176552C16" ref-type="bibr">Li et al. 2010</xref>). As shown in the 1000 Genomes Project (<xref rid="JUNGR176552C1" ref-type="bibr">The 1000 Genomes Project Consortium 2012</xref>), initializing ThunderVCF with Beagle-phased haplotypes further improves genotype accuracies of Beagle-phased haplotypes, and is much faster than running ThunderVCF alone from random haplotypes. This two-step approach is implemented in GotCloud's genotype refinement pipeline.</p>
    </sec>
    <sec id="s3e">
      <title>Experimental setup</title>
      <p>To evaluate the performance of the GotCloud pipeline, we analyzed Chromosome 20 across 1000 low-coverage (∼6x) genomes and 1000 deep exomes. Low-coverage genomes were randomly selected from Phase 3 data of the 1000 Genomes Project and have an average sequencing depth of 5.9× (standard deviation: 2.7). Exomes were randomly selected from Phase 1 data of the 1000 Genomes Project and have an average on target depth of 86× (standard deviation: 35). For the targeted sequencing experiment with a 1 Mb or smaller region, we randomly selected from the Phase 3 exomes, by randomly selecting up to 1 Mb of regions within the exome target region. For comparison, we also ran analyses using the GATK UnifiedGenotyper (<xref rid="JUNGR176552C6" ref-type="bibr">DePristo et al. 2011</xref>) with default options. Overall runtimes were estimated using a four-node cluster with 48 physical CPU cores, running 40 parallel sessions. For the 1000 sample GATK experiment, we used Chromosome 20 data and extrapolated the number into the whole genome due to larger memory footprints. Peak memory usages are measured by averaging over Chromosome 20 using 5-Mb chunks. When evaluating the sensitivity of variant discovery, we used HumanExome BeadChip variants polymorphic in the sequenced samples, excluding variants included in the Omni2.5 arrays that are also used for positive labels in SVM filtering.</p>
    </sec>
    <sec id="s3f">
      <title>Software availability</title>
      <p>The GotCloud pipeline is available for public download (<uri xlink:href="http://www.gotcloud.org">http://www.gotcloud.org</uri>) and is prepared for several different cloud computing environments, including the Amazon Web Services (AWS) Elastic Computer Cloud (EC2). It is also possible to run GotCloud on single machines for small projects.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="PMC_1" content-type="local-data">
      <caption>
        <title>Supplemental Material</title>
      </caption>
      <media mimetype="text" mime-subtype="html" xlink:href="supp_25_6_918__index.html"/>
      <media xlink:role="associated-file" mimetype="application" mime-subtype="pdf" xlink:href="supp_gr.176552.114_Supp_FigS1.pdf"/>
      <media xlink:role="associated-file" mimetype="application" mime-subtype="pdf" xlink:href="supp_gr.176552.114_Supp_TableS1.pdf"/>
      <media xlink:role="associated-file" mimetype="application" mime-subtype="pdf" xlink:href="supp_gr.176552.114_Supp_TableS2.pdf"/>
      <media xlink:role="associated-file" mimetype="application" mime-subtype="pdf" xlink:href="supp_gr.176552.114_Supp_TableS3.pdf"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>We thank the 1000 Genomes Project Consortium for making the sequence data publicly available. We thank Michael Boehnke for valuable feedback on the manuscript. This research was funded through grants from the National Institutes of Health (National Human Genome Research Institute; U01 HG006513).</p>
  </ack>
  <fn-group>
    <fn fn-type="supplementary-material">
      <p>[Supplemental material is available for this article.]</p>
    </fn>
    <fn>
      <p>Article published online before print. Article, supplemental material, and publication date are at <ext-link ext-link-type="uri" xlink:href="http://www.genome.org/cgi/doi/10.1101/gr.176552.114">http://www.genome.org/cgi/doi/10.1101/gr.176552.114</ext-link>.</p>
    </fn>
  </fn-group>
  <ref-list>
    <title>References</title>
    <ref id="JUNGR176552C1">
      <mixed-citation publication-type="journal"><collab>The 1000 Genomes Project Consortium</collab>. <year>2012</year><article-title>An integrated map of genetic variation from 1,092 human genomes</article-title>. <source>Nature</source><volume>491</volume>: <fpage>56</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">23128226</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C2">
      <mixed-citation publication-type="journal"><string-name><surname>Amari</surname><given-names>S</given-names></string-name>, <string-name><surname>Wu</surname><given-names>S</given-names></string-name>. <year>1999</year><article-title>Improving support vector machine classifiers by modifying kernel functions</article-title>. <source>Neural Netw</source><volume>12</volume>: <fpage>783</fpage>–<lpage>789</lpage>.<pub-id pub-id-type="pmid">12662656</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C3">
      <mixed-citation publication-type="journal"><string-name><surname>Browning</surname><given-names>BL</given-names></string-name>, <string-name><surname>Yu</surname><given-names>Z</given-names></string-name>. <year>2009</year><article-title>Simultaneous genotype calling and haplotype phasing improves genotype accuracy and reduces false-positive associations for genome-wide association studies</article-title>. <source>Am J Hum Genet</source><volume>85</volume>: <fpage>847</fpage>–<lpage>861</lpage>.<pub-id pub-id-type="pmid">19931040</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C4">
      <mixed-citation publication-type="journal"><string-name><surname>Chang</surname><given-names>CC</given-names></string-name>, <string-name><surname>Lin</surname><given-names>CJ</given-names></string-name>. <year>2011</year><article-title>LIBSVM: a library for support vector machines</article-title>. <source>ACM Trans Intell Syst Technol</source><volume>2</volume>: <fpage>27:1</fpage>–<lpage>27:27</lpage>.</mixed-citation>
    </ref>
    <ref id="JUNGR176552C5">
      <mixed-citation publication-type="journal"><string-name><surname>Cortes</surname><given-names>C</given-names></string-name>, <string-name><surname>Vapnik</surname><given-names>V</given-names></string-name>. <year>1995</year><article-title>Support-vector networks</article-title>. <source>Mach Learn</source><volume>20</volume>: <fpage>273</fpage>–<lpage>297</lpage>.</mixed-citation>
    </ref>
    <ref id="JUNGR176552C6">
      <mixed-citation publication-type="journal"><string-name><surname>DePristo</surname><given-names>MA</given-names></string-name>, <string-name><surname>Banks</surname><given-names>E</given-names></string-name>, <string-name><surname>Poplin</surname><given-names>R</given-names></string-name>, <string-name><surname>Garimella</surname><given-names>KV</given-names></string-name>, <string-name><surname>Maguire</surname><given-names>JR</given-names></string-name>, <string-name><surname>Hartl</surname><given-names>C</given-names></string-name>, <string-name><surname>Philippakis</surname><given-names>AA</given-names></string-name>, <string-name><surname>del Angel</surname><given-names>G</given-names></string-name>, <string-name><surname>Rivas</surname><given-names>MA</given-names></string-name>, <string-name><surname>Hanna</surname><given-names>M</given-names></string-name>, <etal/><year>2011</year><article-title>A framework for variation discovery and genotyping using next-generation DNA sequencing data</article-title>. <source>Nat Genet</source><volume>43</volume>: <fpage>491</fpage>–<lpage>498</lpage>.<pub-id pub-id-type="pmid">21478889</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C15">
      <mixed-citation publication-type="journal"><string-name><surname>Fu</surname><given-names>W</given-names></string-name>, <string-name><surname>O'Connor</surname><given-names>TD</given-names></string-name>, <string-name><surname>Jun</surname><given-names>G</given-names></string-name>, <string-name><surname>Kang</surname><given-names>HM</given-names></string-name>, <string-name><surname>Abecasis</surname><given-names>G</given-names></string-name>, <string-name><surname>Leal</surname><given-names>SM</given-names></string-name>, <string-name><surname>Gabriel</surname><given-names>S</given-names></string-name>, <string-name><surname>Rieder</surname><given-names>MJ</given-names></string-name>, <string-name><surname>Altshuler</surname><given-names>D</given-names></string-name>, <string-name><surname>Shendure</surname><given-names>J</given-names></string-name>, <etal/><year>2013</year><article-title>Analysis of 6,515 exomes reveals the recent origin of most human protein-coding variants</article-title>. <source>Nature</source><volume>493</volume>: <fpage>216</fpage>–<lpage>220</lpage>.<pub-id pub-id-type="pmid">23201682</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C7">
      <mixed-citation publication-type="journal"><collab>The International HapMap Consortium</collab>. <year>2007</year><article-title>A second generation human haplotype map of over 3.1 million SNPs</article-title>. <source>Nature</source><volume>449</volume>: <fpage>851</fpage>–<lpage>861</lpage>.<pub-id pub-id-type="pmid">17943122</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C8">
      <mixed-citation publication-type="journal"><string-name><surname>Jun</surname><given-names>G</given-names></string-name>, <string-name><surname>Filckinger</surname><given-names>M</given-names></string-name>, <string-name><surname>Hetrick</surname><given-names>KN</given-names></string-name>, <string-name><surname>Romm</surname><given-names>JM</given-names></string-name>, <string-name><surname>Doheny</surname><given-names>KF</given-names></string-name>, <string-name><surname>Abecasis</surname><given-names>GR</given-names></string-name>, <string-name><surname>Boehnke</surname><given-names>M</given-names></string-name>, <string-name><surname>Kang</surname><given-names>HM</given-names></string-name>. <year>2012</year><article-title>Detecting and estimating contamination of human DNA samples in sequencing and array-based genotype data</article-title>. <source>Am J Hum Genet</source><volume>91</volume>: <fpage>839</fpage>–<lpage>848</lpage>.<pub-id pub-id-type="pmid">23103226</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C9">
      <mixed-citation publication-type="journal"><string-name><surname>Li</surname><given-names>H</given-names></string-name>. <year>2011</year><article-title>A statistical framework for SNP calling, mutation discovery, association mapping and population genetical parameter estimation from sequencing data</article-title>. <source>Bioinformatics</source><volume>27</volume>: <fpage>2987</fpage>–<lpage>2993</lpage>.<pub-id pub-id-type="pmid">21903627</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C10">
      <mixed-citation publication-type="journal"><string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Durbin</surname><given-names>R</given-names></string-name>. <year>2009</year><article-title>Fast and accurate short read alignment with Burrows-Wheeler transform</article-title>. <source>Bioinformatics</source><volume>25</volume>: <fpage>1754</fpage>–<lpage>1760</lpage>.<pub-id pub-id-type="pmid">19451168</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C16">
      <mixed-citation publication-type="journal"><string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Willer</surname><given-names>CJ</given-names></string-name>, <string-name><surname>Ding</surname><given-names>J</given-names></string-name>, <string-name><surname>Scheet</surname><given-names>P</given-names></string-name>, <string-name><surname>Abecasis</surname><given-names>GR</given-names></string-name>. <year>2010</year><article-title>MaCH: using sequence and genotype data to estimate haplotypes and unobserved genotypes</article-title>. <source>Genet Epidemiol</source><volume>34</volume>: <fpage>816</fpage>–<lpage>834</lpage>.<pub-id pub-id-type="pmid">21058334</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C11">
      <mixed-citation publication-type="journal"><string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Sidore</surname><given-names>C</given-names></string-name>, <string-name><surname>Kang</surname><given-names>HM</given-names></string-name>, <string-name><surname>Boehnke</surname><given-names>M</given-names></string-name>, <string-name><surname>Abecasis</surname><given-names>GR</given-names></string-name>. <year>2011</year><article-title>Low-coverage sequencing: implications for design of complex trait association studies</article-title>. <source>Genome Res</source><volume>21</volume>: <fpage>940</fpage>–<lpage>951</lpage>.<pub-id pub-id-type="pmid">21460063</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C12">
      <mixed-citation publication-type="journal"><string-name><surname>Li</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhan</surname><given-names>X</given-names></string-name>, <string-name><surname>Wing</surname><given-names>M</given-names></string-name>, <string-name><surname>Anderson</surname><given-names>P</given-names></string-name>, <string-name><surname>Kang</surname><given-names>HM</given-names></string-name>, <string-name><surname>Abecasis</surname><given-names>GR</given-names></string-name>. <year>2013</year><article-title>QPLOT: a quality assessment tool for next generation sequencing data</article-title>. <source>Biomed Res Int</source><volume>2013</volume>: <fpage>865181</fpage>.<pub-id pub-id-type="pmid">24319692</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C17">
      <mixed-citation publication-type="journal"><string-name><surname>Tennessen</surname><given-names>JA</given-names></string-name>, <string-name><surname>Bigham</surname><given-names>AW</given-names></string-name>, <string-name><surname>O'Connor</surname><given-names>TD</given-names></string-name>, <string-name><surname>Fu</surname><given-names>W</given-names></string-name>, <string-name><surname>Kenny</surname><given-names>EE</given-names></string-name>, <string-name><surname>Gravel</surname><given-names>S</given-names></string-name>, <string-name><surname>McGee</surname><given-names>S</given-names></string-name>, <string-name><surname>Do</surname><given-names>R</given-names></string-name>, <string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Jun</surname><given-names>G</given-names></string-name>. <year>2012</year><article-title>Evolution and functional impact of rare coding variation from deep sequencing of human exomes</article-title>. <source>Science</source><volume>337</volume>: <fpage>64</fpage>–<lpage>69</lpage>.<pub-id pub-id-type="pmid">22604720</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C13">
      <mixed-citation publication-type="journal"><string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Lu</surname><given-names>J</given-names></string-name>, <string-name><surname>Yu</surname><given-names>J</given-names></string-name>, <string-name><surname>Gibbs</surname><given-names>RA</given-names></string-name>, <string-name><surname>Yu</surname><given-names>F</given-names></string-name>. <year>2013</year><article-title>An integrative variant analysis pipeline for accurate genotype/haplotype inference in population NGS data</article-title>. <source>Genome Res</source><volume>23</volume>: <fpage>833</fpage>–<lpage>842</lpage>.<pub-id pub-id-type="pmid">23296920</pub-id></mixed-citation>
    </ref>
    <ref id="JUNGR176552C14">
      <mixed-citation publication-type="journal"><string-name><surname>Zhao</surname><given-names>M</given-names></string-name>, <string-name><surname>Lee</surname><given-names>W</given-names></string-name>, <string-name><surname>Garrison</surname><given-names>EP</given-names></string-name>, <string-name><surname>Marth</surname><given-names>GT</given-names></string-name>. <year>2013</year><article-title>SSW library: an SIMD Smith-Waterman C/C++ library for use in genomic applications</article-title>. <source>PLoS One</source><volume>8</volume>: <fpage>e82138</fpage>.<pub-id pub-id-type="pmid">24324759</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
