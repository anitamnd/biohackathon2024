<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?covid-19-tdm?>
<?noissn?>
<front>
  <journal-meta>
    <journal-id journal-id-type="publisher-id">978-3-030-53288-8</journal-id>
    <journal-id journal-id-type="doi">10.1007/978-3-030-53288-8</journal-id>
    <journal-id journal-id-type="nlm-ta">Computer Aided Verification</journal-id>
    <journal-title-group>
      <journal-title>Computer Aided Verification</journal-title>
      <journal-subtitle>32nd International Conference, CAV 2020, Los Angeles, CA, USA, July 21–24, 2020, Proceedings, Part I</journal-subtitle>
    </journal-title-group>
    <isbn publication-format="print">978-3-030-53287-1</isbn>
    <isbn publication-format="electronic">978-3-030-53288-8</isbn>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7363192</article-id>
    <article-id pub-id-type="publisher-id">1</article-id>
    <article-id pub-id-type="doi">10.1007/978-3-030-53288-8_1</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>NNV: The Neural Network Verification Tool for Deep Neural Networks and Learning-Enabled Cyber-Physical Systems</article-title>
    </title-group>
    <contrib-group content-type="book editors">
      <contrib contrib-type="editor">
        <name>
          <surname>Lahiri</surname>
          <given-names>Shuvendu K.</given-names>
        </name>
        <address>
          <email>shuvendu.lahiri@microsoft.com</email>
        </address>
        <xref ref-type="aff" rid="Aff8">8</xref>
      </contrib>
      <contrib contrib-type="editor">
        <name>
          <surname>Wang</surname>
          <given-names>Chao</given-names>
        </name>
        <address>
          <email>wang626@usc.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff9">9</xref>
      </contrib>
      <aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="GRID">grid.419815.0</institution-id><institution-id institution-id-type="ISNI">0000 0001 2181 3404</institution-id><institution>Microsoft Research Lab, </institution></institution-wrap>Redmond, WA USA </aff>
      <aff id="Aff9"><label>9</label><institution-wrap><institution-id institution-id-type="GRID">grid.42505.36</institution-id><institution-id institution-id-type="ISNI">0000 0001 2156 6853</institution-id><institution>University of Southern California, </institution></institution-wrap>Los Angeles, CA USA </aff>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Tran</surname>
          <given-names>Hoang-Dung</given-names>
        </name>
        <xref ref-type="aff" rid="Aff10">10</xref>
        <xref ref-type="aff" rid="Aff11">11</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yang</surname>
          <given-names>Xiaodong</given-names>
        </name>
        <xref ref-type="aff" rid="Aff10">10</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Manzanas Lopez</surname>
          <given-names>Diego</given-names>
        </name>
        <xref ref-type="aff" rid="Aff10">10</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Musau</surname>
          <given-names>Patrick</given-names>
        </name>
        <xref ref-type="aff" rid="Aff10">10</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Nguyen</surname>
          <given-names>Luan Viet</given-names>
        </name>
        <xref ref-type="aff" rid="Aff12">12</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xiang</surname>
          <given-names>Weiming</given-names>
        </name>
        <xref ref-type="aff" rid="Aff14">14</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bak</surname>
          <given-names>Stanley</given-names>
        </name>
        <xref ref-type="aff" rid="Aff13">13</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Johnson</surname>
          <given-names>Taylor T.</given-names>
        </name>
        <address>
          <email>taylor.johnson@vanderbilt.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff10">10</xref>
      </contrib>
      <aff id="Aff10"><label>10</label><institution-wrap><institution-id institution-id-type="GRID">grid.24434.35</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 0060</institution-id><institution>University of Nebraska, </institution></institution-wrap>Lincoln, USA </aff>
      <aff id="Aff11"><label>11</label><institution-wrap><institution-id institution-id-type="GRID">grid.152326.1</institution-id><institution-id institution-id-type="ISNI">0000 0001 2264 7217</institution-id><institution>Vanderbilt University, </institution></institution-wrap>Nashville, USA </aff>
      <aff id="Aff12"><label>12</label><institution-wrap><institution-id institution-id-type="GRID">grid.266231.2</institution-id><institution-id institution-id-type="ISNI">0000 0001 2175 167X</institution-id><institution>University of Dayton, </institution></institution-wrap>Dayton, USA </aff>
      <aff id="Aff13"><label>13</label><institution-wrap><institution-id institution-id-type="GRID">grid.36425.36</institution-id><institution-id institution-id-type="ISNI">0000 0001 2216 9681</institution-id><institution>Stony Brook University, </institution></institution-wrap>Stony Brook, USA </aff>
      <aff id="Aff14"><label>14</label><institution-wrap><institution-id institution-id-type="GRID">grid.410427.4</institution-id><institution-id institution-id-type="ISNI">0000 0001 2284 9329</institution-id><institution>Augusta University, </institution></institution-wrap>Augusta, USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>13</day>
      <month>06</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>13</day>
      <month>06</month>
      <year>2020</year>
    </pub-date>
    <volume>12224</volume>
    <fpage>3</fpage>
    <lpage>17</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2020</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made.</license-p>
        <license-p>The images or other third party material in this chapter are included in the chapter's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">This paper presents the Neural Network Verification (NNV) software tool, a set-based verification framework for deep neural networks (DNNs) and learning-enabled cyber-physical systems (CPS). The crux of NNV is a collection of reachability algorithms that make use of a variety of set representations, such as polyhedra, star sets, zonotopes, and abstract-domain representations. NNV supports both exact (sound and complete) and over-approximate (sound) reachability algorithms for verifying safety and robustness properties of feed-forward neural networks (FFNNs) with various activation functions. For learning-enabled CPS, such as closed-loop control systems incorporating neural networks, NNV provides exact and over-approximate reachability analysis schemes for linear plant models and FFNN controllers with piecewise-linear activation functions, such as ReLUs. For similar neural network control systems (NNCS) that instead have nonlinear plant models, NNV supports over-approximate analysis by combining the star set analysis used for FFNN controllers with zonotope-based analysis for nonlinear plant dynamics building on CORA. We evaluate NNV using two real-world case studies: the first is safety verification of ACAS Xu networks, and the second deals with the safety verification of a deep learning-based adaptive cruise control system.</p>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Neural networks</kwd>
      <kwd>Machine learning</kwd>
      <kwd>Cyber-physical systems</kwd>
      <kwd>Verification</kwd>
      <kwd>Autonomy</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Editor(s) (if applicable) and The Author(s) 2020</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>issue license</meta-name>
        <meta-value><bold>Open Access</bold> This book is licensed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made.
The images or other third party material in this book are included in the book's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the book's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <graphic position="anchor" xlink:href="495638_1_En_1_Figa_HTML" id="MO1"/>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par2">Deep neural networks (DNNs) have quickly become one of the most widely used tools for dealing with complex and challenging problems in numerous domains, such as image classification
[<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR25">25</xref>], function approximation, and natural language translation
[<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR18">18</xref>]. Recently, DNNs have been used in safety-critical cyber-physical systems (CPS), such as autonomous vehicles
[<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR52">52</xref>] and air traffic collision avoidance systems
[<xref ref-type="bibr" rid="CR21">21</xref>]. Although utilizing DNNs in safety-critical applications can demonstrate considerable performance benefits, assuring the safety and robustness of these systems is challenging because DNNs possess complex non-linear characteristics. Moreover, it has been demonstrated that their behavior can be unpredictable due to slight perturbations in their inputs (i.e., adversarial perturbations) 
[<xref ref-type="bibr" rid="CR36">36</xref>].<fig id="Fig1"><label>Fig. 1.</label><caption><p>An overview of NNV and its major modules and components.</p></caption><graphic xlink:href="495638_1_En_1_Fig1_HTML" id="MO2"/></fig>
</p>
    <p id="Par3">In this paper, we introduce the NNV (<bold>N</bold>eural <bold>N</bold>etwork <bold>V</bold>erification) tool, which is a software framework that performs set-based verification for DNNs and learning-enabled CPS, known colloquially as neural network control systems (NNCS) as shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref><xref ref-type="fn" rid="Fn1">1</xref>. NNV provides a set of reachability algorithms that can compute both the exact and over-approximate reachable sets of DNNs and NNCSs using a variety of set representations such as polyhedra
[<xref ref-type="bibr" rid="CR40">40</xref>, <xref ref-type="bibr" rid="CR53">53</xref>–<xref ref-type="bibr" rid="CR56">56</xref>], star sets
[<xref ref-type="bibr" rid="CR29">29</xref>, <xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>, <xref ref-type="bibr" rid="CR41">41</xref>], zonotopes
[<xref ref-type="bibr" rid="CR32">32</xref>], and abstract domain representations
[<xref ref-type="bibr" rid="CR33">33</xref>]. The reachable set obtained from NNV contains all possible states of a DNN from bounded input sets or of a NNCS from sets of initial states of a plant model. NNV declares a DNN or a NNCS to be safe if, and only if, their reachable sets do not violate safety properties (i.e., have a non-empty intersection with any state satisfying the negation of the safety property). If a safety property is violated, NNV can construct a complete set of counter-examples demonstrating the set of all possible unsafe initial inputs and states by using the star-based exact reachability algorithm
[<xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR41">41</xref>]. To speed up computation, NNV uses parallel computing, as the majority of the reachability algorithms in NNV are more efficient when executed on multi-core platforms and clusters.</p>
    <p id="Par5">NNV has been successfully applied to safety verification and robustness analysis of several real-world DNNs, primarily feedforward neural networks (FFNNs) and convolutional neural networks (CNNs), as well as learning-enabled CPS. To highlight NNV’s capabilities, we present brief experimental results from two case studies. The first compares methods for safety verification of the ACAS Xu networks
[<xref ref-type="bibr" rid="CR21">21</xref>], and the second presents safety verification of a learning-based adaptive cruise control (ACC) system.</p>
    <p id="Par6">
      <table-wrap id="Tab1">
        <label>Table 1.</label>
        <caption>
          <p>Overview of major features available in NNV. Links refer to relevant files/classes in the NNV codebase. BN refers to batch normalization layers, FC to fully-connected layers, AvgPool to average pooling layers, Conv to convolutional layers, and MaxPool to max pooling layers.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left">Feature</th>
              <th align="left">Exact analysis</th>
              <th align="left">Over-approximate analysis</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left">Components</td>
              <td align="left"><ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/tree/cav2020/code/nnv/engine/nn/fnn">FFNN</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/tree/cav2020/code/nnv/engine/nn/cnn">CNN</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/tree/cav2020/code/nnv/engine/nncs">NNCS</ext-link></td>
              <td align="left"><ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/tree/cav2020/code/nnv/engine/nn/fnn">FFNN</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/tree/cav2020/code/nnv/engine/nn/cnn">CNN</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/tree/cav2020/code/nnv/engine/nncs">NNCS</ext-link></td>
            </tr>
            <tr>
              <td align="left">Plant dynamics (for NNCS)</td>
              <td align="left">
                <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nncs/LinearODE.m">Linear ODE</ext-link>
              </td>
              <td align="left"><ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nncs/LinearODE.m">Linear ODE</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nncs/NonLinearODE.m">Nonlinear ODE</ext-link></td>
            </tr>
            <tr>
              <td align="left">Discrete/Continuous (for NNCS)</td>
              <td align="left">Discrete Time</td>
              <td align="left">Discrete Time, Continuous Time</td>
            </tr>
            <tr>
              <td align="left">Activation functions</td>
              <td align="left"><ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/fnn/ReLU.m">ReLU</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/fnn/SatLin.m">Satlin</ext-link></td>
              <td align="left"><ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/fnn/ReLU.m">ReLU</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/fnn/SatLin.m">Satlin</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/fnn/LogSig.m">Sigmoid</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/fnn/TanSig.m">Tanh</ext-link></td>
            </tr>
            <tr>
              <td align="left">CNN Layers</td>
              <td align="left"><ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/cnn/MaxPooling2DLayer.m">MaxPool</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/cnn/Conv2DLayer.m">Conv</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/cnn/BatchNormalizationLayer.m">BN</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/cnn/AveragePooling2DLayer.m">AvgPool</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/cnn/FullyConnectedLayer.m">FC</ext-link></td>
              <td align="left"><ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/cnn/MaxPooling2DLayer.m">MaxPool</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/cnn/Conv2DLayer.m">Conv</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/cnn/BatchNormalizationLayer.m">BN</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/cnn/AveragePooling2DLayer.m">AvgPool</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/nn/cnn/FullyConnectedLayer.m">FC</ext-link></td>
            </tr>
            <tr>
              <td align="left">Reachability methods</td>
              <td align="left"><ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/set/Star.m">Star</ext-link>, Polyhedron, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/set/ImageStar.m">ImageStar</ext-link></td>
              <td align="left"><ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/set/Star.m">Star</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/set/Zono.m">Zonotope</ext-link>, Abstract-domain, <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/set/ImageStar.m">ImageStar</ext-link></td>
            </tr>
            <tr>
              <td align="left">Reachable set/Flow-pipe Visualization</td>
              <td align="left">Yes</td>
              <td align="left">Yes</td>
            </tr>
            <tr>
              <td align="left">Parallel computing</td>
              <td align="left">Yes</td>
              <td align="left">Partially supported</td>
            </tr>
            <tr>
              <td align="left">Safety verification</td>
              <td align="left">Yes</td>
              <td align="left">Yes</td>
            </tr>
            <tr>
              <td align="left">Falsification</td>
              <td align="left">Yes</td>
              <td align="left">Yes</td>
            </tr>
            <tr>
              <td align="left">Robustness verification (for FFNN/CNN)</td>
              <td align="left">Yes</td>
              <td align="left">Yes</td>
            </tr>
            <tr>
              <td align="left">Counterexample generation</td>
              <td align="left">Yes</td>
              <td align="left">Yes</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </p>
  </sec>
  <sec id="Sec2">
    <title>Overview and Features</title>
    <p id="Par7">NNV is an object-oriented toolbox written in Matlab, which was chosen in part due to the prevalence of Matlab/Simulink in the design of CPS. NNV uses the MPT toolbox 
[<xref ref-type="bibr" rid="CR26">26</xref>] for polytope-based reachability analysis and visualization
[<xref ref-type="bibr" rid="CR40">40</xref>], and makes use of CORA
[<xref ref-type="bibr" rid="CR3">3</xref>] for zonotope-based reachability analysis of nonlinear plant models 
[<xref ref-type="bibr" rid="CR38">38</xref>]. NNV also utilizes the Neural Network Model Transformation Tool (NNMT) for transforming neural network models from Keras and Tensorflow into Matlab using the Open Neural Network Exchange (ONNX) format, and the Hybrid Systems Model Transformation and Translation tool (HyST) 
[<xref ref-type="bibr" rid="CR5">5</xref>] for plant configuration. NNV makes use of YALMIP 
[<xref ref-type="bibr" rid="CR27">27</xref>] for some optimization problems and MatConvNet 
[<xref ref-type="bibr" rid="CR46">46</xref>] for some CNN operations.</p>
    <p id="Par8">The NNV toolbox contains two main modules: a <italic>computation engine</italic> and an <italic>analyzer</italic>, shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. The computation engine module consists of four subcomponents: 1) the <italic>FFNN constructor</italic>, 2) the <italic>NNCS constructor</italic>, 3) <italic>the reachability solvers</italic>, and 4) <italic>the evaluator</italic>. The FFNN constructor takes a network configuration file as an input and generates a FFNN object. The NNCS constructor takes the FFNN object and the plant configuration, which describes the dynamics of a system, as inputs and then creates an NNCS object. Depending on the application, either the FFNN (or NNCS) object will be fed into a reachability solver to compute the reachable set of the FFNN (or NNCS) from a given initial set of states. Then, the obtained reachable set will be passed to the analyzer module. The analyzer module consists of three subcomponents: 1) a <italic>visualizer</italic>, 2) a <italic>safety checker</italic>, and 3) a <italic>falsifier</italic>. The visualizer can be called to plot the obtained reachable set. Given a safety specification, the safety checker can reason about the safety of the FFNN or NNCS with respect to the specification. When an exact (sound and complete) reachability solver is used, such as the star-based solver, the safety checker can return either “safe,” or “unsafe” along with a set of counterexamples. When an over-approximate (sound) reachability solver is used, such as the zonotope-based scheme or the approximate star-based solvers, the safety checker can return either “safe” or “<italic>uncertain</italic>” (unknown). In this case, the falsifier automatically calls the evaluator to generate simulation traces to find a counterexample. If the falsifier can find a counterexample, then NNV returns unsafe. Otherwise, it returns unknown. Table <xref rid="Tab1" ref-type="table">1</xref> shows a summary of the major features of NNV.<fig id="Fig2"><label>Fig. 2.</label><caption><p>Architecture of a typical neural network control system (NNCS).</p></caption><graphic xlink:href="495638_1_En_1_Fig2_HTML" id="MO3"/></fig>
</p>
  </sec>
  <sec id="Sec3">
    <title>Set Representations and Reachability Algorithms</title>
    <p id="Par9">NNV implements a set of reachability algorithms for <italic>sequential</italic> FFNNs and CNNs, as well as NNCS with FFNN controllers as shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. The reachable set of a sequential FFNN is computed layer-by-layer. The output reachable set of a layer is the input set of the next layer in the network.</p>
    <sec id="Sec4">
      <title>Polyhedron
[<xref ref-type="bibr" rid="CR40">40</xref>]</title>
      <p id="Par10">The polyhedron reachability algorithm computes the exact polyhedron reachable set of a FFNN with ReLU activation functions. The exact reachability computation of layer <italic>L</italic> in a FFNN is done as follows. First, we construct the affine mapping <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{I}$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq1.gif"/></alternatives></inline-formula> of the input polyhedron set <italic>I</italic>, using the weight matrix <italic>W</italic> and the bias vector <italic>b</italic>, i.e., <inline-formula id="IEq2"><alternatives><tex-math id="M2">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{I} = W\times I + b$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq2.gif"/></alternatives></inline-formula>. Then, the exact reachable set of the layer <inline-formula id="IEq3"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R_L$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq3.gif"/></alternatives></inline-formula> is constructed by executing a sequence of stepReLU operations, i.e., <inline-formula id="IEq4"><alternatives><tex-math id="M4">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R_{L} = stepReLU_n(stepReLU_{n-1}(\cdots (stepReLU_1(\bar{I}))))$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq4.gif"/></alternatives></inline-formula>. Since a <italic>stepReLU</italic> operation can split a polyhedron into two new polyhedra, the exact reachable set of a layer in a FFNN is usually a union of polyhedra. The polyhedron reachability algorithm is computationally expensive because computing affine mappings with polyhedra is costly. Additionally, when computing the reachable set, the polyhedron approach extensively uses the expensive conversion between the H-representation and the V-representation. These are the main drawbacks that limit the scalability of the polyhedron approach. Despite that, we extend the polyhedron reachability algorithm for NNCSs with FFNN controllers. However, the propagation of polyhedra in NNCS may lead to a large degree of conservativeness in the computed reachable set
[<xref ref-type="bibr" rid="CR38">38</xref>].</p>
    </sec>
    <sec id="Sec5">
      <title>Star Set
[<xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR41">41</xref>] (<ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/set/Star.m">code</ext-link>)</title>
      <p id="Par11">The star set is an efficient set representation for simulation-based verification of large linear systems
[<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR42">42</xref>] where the superposition property of a linear system can be exploited in the analysis. It has been shown in
[<xref ref-type="bibr" rid="CR41">41</xref>] that the star set is also suitable for reachability analysis of FFNNs. In contrast to polyhedra, the affine mapping and intersection with a half space of a star set is more easily computed. NNV implements an enhanced version of the exact and over-approximate reachability algorithms for FFNNs proposed in
[<xref ref-type="bibr" rid="CR41">41</xref>] by minimizing the number of LP optimization problems that need to be solved in the computation. The exact algorithm that makes use of star sets is similar to the polyhedron method that makes use of <italic>stepReLU</italic> operations. However, it is much faster and more scalable than the polyhedron method because of the advantage that star sets have in affine mapping and intersection. The approximate algorithm obtains an over-approximation of the exact reachable set by approximating the exact reachable set after applying an activation function, e.g., ReLU, Tanh, Sigmoid. We refer readers to
[<xref ref-type="bibr" rid="CR41">41</xref>] for a detailed discussion of star-set reachability algorithms for FFNNs.</p>
      <p id="Par12">We note that NNV implements enhanced versions of earlier star-based reachability algorithms
[<xref ref-type="bibr" rid="CR41">41</xref>]. Particularly, we minimize the number of linear programming (LP) optimization problems that must be solved in order to construct the reachable set of a FFNN by quickly estimating the ranges of all of the states in the star set using only the ranges of the predicate variables. Additionally, the extensions of the star reachability algorithms to NNCS with linear plant models can eliminate the explosion of conservativeness in the polyhedron method
[<xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>]. The reason behind this is that in star sets, the relationship between the plant state variables and the control inputs is preserved in the computation since they are defined by a unique set of predicate variables. We refer readers to
[<xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>] for a detailed discussion of the extensions of the star-based reachability algorithms for NNCSs with linear/nonlinear plant models.</p>
    </sec>
    <sec id="Sec6">
      <title>Zonotope
[<xref ref-type="bibr" rid="CR32">32</xref>] (<ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/set/Zono.m">code</ext-link>)</title>
      <p id="Par13">NNV implements the zonotope reachability algorithms proposed in
[<xref ref-type="bibr" rid="CR32">32</xref>] for FFNNs. Similar to the over-approximate algorithm using star sets, the zonotope algorithm computes an over-approximation of the exact reachable set of a FFNN. Although the zonotope reachability algorithm is very fast and scalable, it produces a very conservative reachable set in comparison to the star set method as shown in
[<xref ref-type="bibr" rid="CR41">41</xref>]. Consequently, zonotope-based reachability algorithms are usually only more efficient for very small input sets. As an example it can be more suitable for robustness certification.</p>
    </sec>
    <sec id="Sec7">
      <title>Abstract Domain
[<xref ref-type="bibr" rid="CR33">33</xref>]</title>
      <p id="Par14">NNV implements the abstract domain reachability algorithm proposed in
[<xref ref-type="bibr" rid="CR33">33</xref>] for FFNNs. NNV’s abstract domain reachability algorithm specifies an abstract domain as a star set and estimates the <italic>over-approximate ranges</italic> of the states based on the ranges of the new introduced predicate variables. We note that better ranges of the states can be computed by solving LP optimization. However, better ranges come with more computation time.</p>
    </sec>
    <sec id="Sec8">
      <title>ImageStar Set
[<xref ref-type="bibr" rid="CR37">37</xref>] (<ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/blob/cav2020/code/nnv/engine/set/ImageStar.m">code</ext-link>)</title>
      <p id="Par15">NNV recently introduced a new set representation called the ImageStar for use in the verification of deep convolutional neural networks (CNNs). Briefly, the ImageStar is a generalization of the star set where the anchor and generator vectors are replaced by multi-channel images. The ImageStar is efficient in the analysis of convolutional layers, average pooling layers, and fully connected layers, whereas max pooling layers and ReLU layers consume most of the computation time. NNV implements exact and over-approximate reachability algorithms using the ImageStar for serial CNNs. In short, using the ImageStar, we can analyze the robustness under adversarial attacks of the real-world VGG16 and VGG19 deep perception networks
[<xref ref-type="bibr" rid="CR31">31</xref>] that consist of <inline-formula id="IEq5"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${&gt;}100$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq5.gif"/></alternatives></inline-formula> million parameters 
[<xref ref-type="bibr" rid="CR37">37</xref>].</p>
    </sec>
  </sec>
  <sec id="Sec9">
    <title>Evaluation</title>
    <p id="Par16">The experiments presented in this section were performed on a desktop with the following configuration: Intel Core i7-6700 CPU @ 3.4 GHz 8 core Processor, 64 GB Memory, and 64-bit Ubuntu 16.04.3 LTS OS.</p>
    <sec id="Sec10">
      <title>Safety Verification of ACAS Xu Networks</title>
      <p id="Par17">We evaluate NNV in comparison to Reluplex
[<xref ref-type="bibr" rid="CR22">22</xref>], Marabou
[<xref ref-type="bibr" rid="CR23">23</xref>], and ReluVal
[<xref ref-type="bibr" rid="CR49">49</xref>], by considering the verification of safety property <inline-formula id="IEq6"><alternatives><tex-math id="M6">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _3$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq6.gif"/></alternatives></inline-formula> and <inline-formula id="IEq7"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _4$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq7.gif"/></alternatives></inline-formula> of the ACAS Xu neural networks
[<xref ref-type="bibr" rid="CR21">21</xref>] for all 45 networks.<xref ref-type="fn" rid="Fn2">2</xref> All the experiments were done using 4 cores for computation. The results are summarized in Table <xref rid="Tab2" ref-type="table">2</xref> where (SAT) denotes the networks are safe, (UNSAT) is unsafe, and (UNK) is unknown. We note that (UNK) may occur due to the conservativeness of the reachability analysis scheme. Detailed verification results are presented in the appendix of the extended version of this paper 
[<xref ref-type="bibr" rid="CR44">44</xref>]. For a fast comparison with other tools, we also tested a subset of the inputs for Property 1–4 on all the 45 networks. We note that the polyhedron method
[<xref ref-type="bibr" rid="CR40">40</xref>] achieves a timeout on most of networks, and therefore, we neglect this method in the comparison.<table-wrap id="Tab2"><label>Table 2.</label><caption><p>Verification results of ACAS Xu networks.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">ACAS XU <inline-formula id="IEq10"><alternatives><tex-math id="M8">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _3$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq10.gif"/></alternatives></inline-formula></th><th align="left" rowspan="2">SAT</th><th align="left" rowspan="2">UNSAT</th><th align="left" rowspan="2">UNK</th><th align="left" colspan="3">TIMEOUT</th><th align="left" rowspan="2">TIME(s)</th></tr><tr><th align="left">1 h</th><th align="left">2 h</th><th align="left">10 h</th></tr></thead><tbody><tr><td align="left">Reluplex</td><td align="left">3</td><td align="left">42</td><td align="left">0</td><td align="left">2</td><td align="left">0</td><td align="left">0</td><td align="left">28454</td></tr><tr><td align="left">Marabou</td><td align="left">3</td><td align="left">42</td><td align="left">0</td><td align="left">1</td><td align="left">0</td><td align="left">0</td><td align="left">19466</td></tr><tr><td align="left">Marabou DnC</td><td align="left">3</td><td align="left">42</td><td align="left">0</td><td align="left">3</td><td align="left">3</td><td align="left">1</td><td align="left">111880</td></tr><tr><td align="left">ReluVal</td><td align="left">3</td><td align="left">42</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">416</td></tr><tr><td align="left">Zonotope</td><td align="left">0</td><td align="left">2</td><td align="left">43</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">3</td></tr><tr><td align="left">Abstract Domain</td><td align="left">0</td><td align="left">0</td><td align="left">45</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">8</td></tr><tr><td align="left">NNV Exact Star</td><td align="left">3</td><td align="left">42</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">1371</td></tr><tr><td align="left">NNV Appr. Star</td><td align="left">0</td><td align="left">29</td><td align="left">16</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">52</td></tr><tr><td align="left">ACAS XU <inline-formula id="IEq11"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _4$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq11.gif"/></alternatives></inline-formula></td><td align="left" colspan="7"/></tr><tr><td align="left">Reluplex</td><td align="left">3</td><td align="left">42</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">11880</td></tr><tr><td align="left">Marabou</td><td align="left">3</td><td align="left">42</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">8470</td></tr><tr><td align="left">Marabou DnC</td><td align="left">3</td><td align="left">42</td><td align="left">0</td><td align="left">2</td><td align="left">2</td><td align="left">0</td><td align="left">25110</td></tr><tr><td align="left">ReluVal</td><td align="left">3</td><td align="left">42</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">27</td></tr><tr><td align="left">Zonotope</td><td align="left">0</td><td align="left">1</td><td align="left">44</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">5</td></tr><tr><td align="left">Abstract Domain</td><td align="left">0</td><td align="left">0</td><td align="left">45</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">7</td></tr><tr><td align="left">NNV Exact Star</td><td align="left">3</td><td align="left">42</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">470</td></tr><tr><td align="left">NNV Appr. Star</td><td align="left">0</td><td align="left">32</td><td align="left">13</td><td align="left">0</td><td align="left">0</td><td align="left">0</td><td align="left">19</td></tr></tbody></table></table-wrap>
</p>
      <p id="Par19"><bold>Verification Time.</bold> For property <inline-formula id="IEq12"><alternatives><tex-math id="M10">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _3$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq12.gif"/></alternatives></inline-formula>, NNV’s exact-star method is about <inline-formula id="IEq13"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$20.7{\times }$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq13.gif"/></alternatives></inline-formula> faster than Reluplex, <inline-formula id="IEq14"><alternatives><tex-math id="M12">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$14.2{\times }$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq14.gif"/></alternatives></inline-formula> faster than Marabou, <inline-formula id="IEq15"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$81.6{\times }$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq15.gif"/></alternatives></inline-formula> faster than Marabou-DnC (i.e., divide and conquer method). The approximate star method is <inline-formula id="IEq16"><alternatives><tex-math id="M14">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$547{\times }$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq16.gif"/></alternatives></inline-formula> faster than Reluplex, <inline-formula id="IEq17"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$374\times $$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq17.gif"/></alternatives></inline-formula> faster than Marabou, <inline-formula id="IEq18"><alternatives><tex-math id="M16">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$2151{\times }$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq18.gif"/></alternatives></inline-formula> faster than Marabou-DnC, and <inline-formula id="IEq19"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$8{\times }$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq19.gif"/></alternatives></inline-formula> faster than ReluVal. For property <inline-formula id="IEq20"><alternatives><tex-math id="M18">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _4$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq20.gif"/></alternatives></inline-formula>, NNV’s exact-star method is <inline-formula id="IEq21"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$25.3{\times }$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq21.gif"/></alternatives></inline-formula> faster than Reluplex, <inline-formula id="IEq22"><alternatives><tex-math id="M20">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$18.0{\times }$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq22.gif"/></alternatives></inline-formula> faster than Marabou, <inline-formula id="IEq23"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$53.4{\times }$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq23.gif"/></alternatives></inline-formula> faster than Marabou-DnC, while the approximate star method is <inline-formula id="IEq24"><alternatives><tex-math id="M22">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$625{\times }$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq24.gif"/></alternatives></inline-formula> faster than Reluplex, <inline-formula id="IEq25"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$445{\times }$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq25.gif"/></alternatives></inline-formula> faster than Marabou, <inline-formula id="IEq26"><alternatives><tex-math id="M24">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1321{\times }$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq26.gif"/></alternatives></inline-formula> faster than Marabou-DnC.</p>
      <p id="Par20"><bold>Conservativeness.</bold> The approximate star method is much less conservative than the zonotope and abstract domain methods. This is illustrated since it can verify more networks than the zonotope and abstract domain methods, and is because it obtains a tighter over-approximate reachable set. For property <inline-formula id="IEq27"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _3$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq27.gif"/></alternatives></inline-formula>, the zonotope and abstract domain methods can prove safety of 2/45 networks, (<inline-formula id="IEq28"><alternatives><tex-math id="M26">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$4.44\%$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq28.gif"/></alternatives></inline-formula>) and 0/45 networks, (<inline-formula id="IEq29"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0\%$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq29.gif"/></alternatives></inline-formula>) respectively, while NNV’s approximate star method can prove safety of 29/45 networks, (<inline-formula id="IEq30"><alternatives><tex-math id="M28">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$64.4\%$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq30.gif"/></alternatives></inline-formula>). For property <inline-formula id="IEq31"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _4$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq31.gif"/></alternatives></inline-formula>, the zonotope and abstract domain method can prove safety of 1/45 networks, (<inline-formula id="IEq32"><alternatives><tex-math id="M30">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$2.22\%$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq32.gif"/></alternatives></inline-formula>) and 0/45 networks, (<inline-formula id="IEq33"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.00\%$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq33.gif"/></alternatives></inline-formula>) respectively while the approximate star method can prove safety of 32/45, (<inline-formula id="IEq34"><alternatives><tex-math id="M32">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$71.11\%$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq34.gif"/></alternatives></inline-formula>).</p>
    </sec>
    <sec id="Sec11">
      <title>Safety Verification of Adaptive Cruise Control System</title>
      <p id="Par21">To illustrate how NNV can be used to verify/falsify safety properties of learning-enabled CPS, we analyze a learning-based ACC system 
[<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR38">38</xref>], in which the ego (following) vehicle has a radar sensor to measure the distance to the lead vehicle in the same lane, <inline-formula id="IEq35"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_{rel}$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq35.gif"/></alternatives></inline-formula>, as well as the relative velocity of the lead vehicle, <inline-formula id="IEq36"><alternatives><tex-math id="M34">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V_{rel}$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq36.gif"/></alternatives></inline-formula>. The ego vehicle has two control modes. In speed control mode, it travels at a driver-specified set speed <inline-formula id="IEq37"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V_{set} = 30$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq37.gif"/></alternatives></inline-formula>, and in spacing control mode, it maintains a safe distance from the lead vehicle, <inline-formula id="IEq38"><alternatives><tex-math id="M36">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_{safe}$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq38.gif"/></alternatives></inline-formula>. We train a neural network with 5 layers of 20 neurons per layer with ReLU activation functions to control the ego vehicle using a control period of 0.1 s.</p>
      <p id="Par22">We investigate safety of the learning-based ACC system with two types of plant dynamics: 1) a discrete linear plant, and 2) a nonlinear continuous plant governed by the following differential equations:<disp-formula id="Equ1"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned}&amp;\dot{x}_{lead}(t) = v_{lead}(t),~\dot{v}_{lead}(t) = \gamma _{lead},&amp;\dot{\gamma }_{lead}(t) = -2 \gamma _{lead}(t) + 2a_{lead} - \mu v^2_{lead}(t), \\&amp;\dot{x}_{ego}(t) = v_{ego}(t),~\dot{v}_{ego}(t) = \gamma _{ego},&amp;\dot{\gamma }_{ego}(t) = -2 \gamma _{ego}(t) + 2a_{ego} - \mu v^2_{ego}(t), \end{aligned}$$\end{document}</tex-math><graphic xlink:href="495638_1_En_1_Chapter_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq39"><alternatives><tex-math id="M38">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{lead} (x_{ego})$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq39.gif"/></alternatives></inline-formula>, <inline-formula id="IEq40"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_{lead} (v_{ego})$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq40.gif"/></alternatives></inline-formula> and <inline-formula id="IEq41"><alternatives><tex-math id="M40">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma _{lead} (\gamma _{ego})$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq41.gif"/></alternatives></inline-formula> are the position, velocity and acceleration of the lead (ego) vehicle respectively. <inline-formula id="IEq42"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a_{lead}(a_{ego})$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq42.gif"/></alternatives></inline-formula> is the acceleration control input applied to the lead (ego) vehicle, and <inline-formula id="IEq43"><alternatives><tex-math id="M42">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu = 0.0001$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq43.gif"/></alternatives></inline-formula> is a friction parameter. To obtain a discrete linear model of the plant, we let <inline-formula id="IEq44"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu = 0$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq44.gif"/></alternatives></inline-formula> and discretize the corresponding linear continuous model using a zero-order hold on the inputs with a sample time of 0.1 s (i.e., the control period).</p>
      <p id="Par23"><bold>Verification Problem.</bold> The scenario we are interested in is when the two vehicles are operating at a safe distance between them and the ego vehicle is in speed control mode. In this state the lead vehicle driver suddenly decelerates with <inline-formula id="IEq45"><alternatives><tex-math id="M44">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a_{lead} = -5$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq45.gif"/></alternatives></inline-formula> to reduce the speed. We want to verify if the neural network controller on the ego vehicle will decelerate to maintain a safe distance between the two vehicles. To guarantee safety, we require that <inline-formula id="IEq46"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_{rel} = x_{lead} - x_{ego} \ge D_{safe} = D_{default} + T_{gap} \times v_{ego}$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq46.gif"/></alternatives></inline-formula> where <inline-formula id="IEq47"><alternatives><tex-math id="M46">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T_{gap} = 1.4$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq47.gif"/></alternatives></inline-formula> s and <inline-formula id="IEq48"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_{default} = 10$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq48.gif"/></alternatives></inline-formula>. Our analysis investigates whether the safety requirement holds during the 5 s after the lead vehicle decelerates. We consider safety of the system under the following initial conditions: <inline-formula id="IEq49"><alternatives><tex-math id="M48">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{lead}(0) \in [90, 92]$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq49.gif"/></alternatives></inline-formula>, <inline-formula id="IEq50"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_{lead}(0) \in [20, 30]$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq50.gif"/></alternatives></inline-formula>, <inline-formula id="IEq51"><alternatives><tex-math id="M50">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma _{lead}(0) = \gamma _{ego}(0) = 0$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq51.gif"/></alternatives></inline-formula>, <inline-formula id="IEq52"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_{ego}(0) \in [30, 30.5]$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq52.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq53"><alternatives><tex-math id="M52">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{ego} \in [30, 31]$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq53.gif"/></alternatives></inline-formula>.<table-wrap id="Tab3"><label>Table 3.</label><caption><p>Verification results for ACC system with different plant models, where <italic>VT</italic> is the verification time (in seconds).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">v_lead(0)</th><th align="left" colspan="2">Linear plant      </th><th align="left" colspan="2">Nonlinear plant</th></tr><tr><th align="left"><italic>Safety</italic>   </th><th align="left"><italic>VT</italic>(<italic>s</italic>)      </th><th align="left"><italic>Safety</italic>   </th><th align="left"><italic>VT</italic>(<italic>s</italic>)</th></tr></thead><tbody><tr><td align="left">[29, 30]</td><td align="left">SAFE</td><td align="left">9.60</td><td align="left">UNSAFE   </td><td align="left">346.62</td></tr><tr><td align="left">[28, 29]</td><td align="left">SAFE</td><td align="left">9.45</td><td align="left">UNSAFE   </td><td align="left">277.50</td></tr><tr><td align="left">[27, 28]</td><td align="left">SAFE</td><td align="left">9.82</td><td align="left">UNSAFE   </td><td align="left">289.70</td></tr><tr><td align="left">[26, 27]</td><td align="left">UNSAFE</td><td align="left">17.80</td><td align="left">UNSAFE   </td><td align="left">315.60</td></tr><tr><td align="left">[25, 26]</td><td align="left">UNSAFE</td><td align="left">19.24</td><td align="left">UNSAFE   </td><td align="left">305.56</td></tr><tr><td align="left">[24, 25]</td><td align="left">UNSAFE</td><td align="left">18.12</td><td align="left">UNSAFE   </td><td align="left">372.00</td></tr></tbody></table></table-wrap>
</p>
      <p id="Par24"><bold>Verification Results.</bold> For linear dynamics, NNV can compute both the exact and over-approximate reachable sets of the ACC system in bounded time steps, while for nonlinear dynamics, NNV constructs an over-approximation of the reachable sets. The verification results for linear and nonlinear models using the over-approximate star method are presented in Table <xref rid="Tab3" ref-type="table">3</xref>, which shows that safety of the ACC system depends on the initial velocity of the lead vehicle. When the initial velocity of the lead vehicle is smaller than 27 (m/s), the ACC system with the discrete plant model is unsafe. Using the exact star method, NNV can construct a <italic>complete</italic> set of counter-example inputs. When the over-approximate star method is used, if there is a potential safety violation, NNV simulates the system with 1000 random inputs from the input set to find counter examples. If a counterexample is found, the system is <italic>UNSAFE</italic>, otherwise, NNV returns a safety result of <italic>UNKNOWN</italic>. Figure <xref rid="Fig3" ref-type="fig">3</xref> visualizes the reachable sets of the relative distance <inline-formula id="IEq54"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_{rel}$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq54.gif"/></alternatives></inline-formula> between two vehicles versus the required safe distance <inline-formula id="IEq55"><alternatives><tex-math id="M54">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_{safe}$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq55.gif"/></alternatives></inline-formula> over time for two cases of initial velocities of the lead vehicle: <inline-formula id="IEq56"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_{lead}(0) \in [29, 30]$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq56.gif"/></alternatives></inline-formula> and <inline-formula id="IEq57"><alternatives><tex-math id="M56">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_{lead}(0) \in [24, 25]$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq57.gif"/></alternatives></inline-formula>. We can see that in the first case, <inline-formula id="IEq58"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_{ref} \ge D_{safe}$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq58.gif"/></alternatives></inline-formula> for all 50 time steps stating that the system is safe. In the second case, <inline-formula id="IEq59"><alternatives><tex-math id="M58">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_{ref} &lt; D_{safe}$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq59.gif"/></alternatives></inline-formula> in some control steps, so the system is unsafe. NNV supports a <italic>reachLive</italic> method to perform analysis and reachable set visualization on-the-fly to help the user observe the behavior of the system during verification.</p>
      <p id="Par25">The verification results for the ACC system with the nonlinear model are all <italic>UNSAFE</italic>, which is surprising. Since the neural network controller of the ACC system was trained with the linear model, it works quite well for the linear model. However, when a small friction term is added to the linear model to form a nonlinear model, the neural network controller’s performance, in terms of safety, is significantly reduced. This problem raises an important issue in training neural network controllers using simulation data, and these schemes may not work in real systems since there is always a mismatch between the plant model in the simulation engine and the real system.<fig id="Fig3"><label>Fig. 3.</label><caption><p>Two scenarios of the ACC system. In the first (top) scenario (<inline-formula id="IEq60"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_{lead}(0) \in [29, 30]$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq60.gif"/></alternatives></inline-formula> m/s), safety is guaranteed, <inline-formula id="IEq61"><alternatives><tex-math id="M60">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_{rel} \ge D_{safe}$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq61.gif"/></alternatives></inline-formula>. In the second scenario (bottom) (<inline-formula id="IEq62"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_{lead}(0) \in [24,~25]$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq62.gif"/></alternatives></inline-formula> m/s), safety is violated since <inline-formula id="IEq63"><alternatives><tex-math id="M62">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_{ref} &lt; D_{safe}$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq63.gif"/></alternatives></inline-formula> in some control steps.</p></caption><graphic xlink:href="495638_1_En_1_Fig3_HTML" id="MO5"/></fig>
</p>
      <p id="Par26"><bold>Verification Times.</bold> As shown in Table <xref rid="Tab3" ref-type="table">3</xref>, the approximate analysis of the ACC system with discrete linear plant model is fast and can be done in 84 s. NNV also supports exact analysis, but is computationally expensive as it constructs all reachable states. Because there are splits in the reachable sets of the neural network controller, the number of star sets in the reachable set of the plant increases quickly over time 
[<xref ref-type="bibr" rid="CR38">38</xref>]. In contrast, the over-approximate method computes the interval hull of all reachable sets at each time step, and maintains a single reachable set of the plant throughout the computation. This makes the over-approximate method faster than the exact method. In terms of plant models, the nonlinear model requires more computation time than the linear one. As shown in Table <xref rid="Tab3" ref-type="table">3</xref>, the verification for the linear model using the over-approximate method is <inline-formula id="IEq64"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$22.7{\times }$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq64.gif"/></alternatives></inline-formula> faster on average than of the nonlinear model.</p>
    </sec>
  </sec>
  <sec id="Sec12">
    <title>Related Work</title>
    <p id="Par27">NNV was inspired by recent work in the emerging fields of neural network and machine learning verification. For the “open-loop” verification problem (verification of DNNs), many efficient techniques have been proposed, such as SMT-based methods
[<xref ref-type="bibr" rid="CR22">22</xref>, <xref ref-type="bibr" rid="CR23">23</xref>, <xref ref-type="bibr" rid="CR30">30</xref>], mixed-integer linear programming methods
[<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR28">28</xref>], set-based methods
[<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR32">32</xref>, <xref ref-type="bibr" rid="CR33">33</xref>, <xref ref-type="bibr" rid="CR48">48</xref>, <xref ref-type="bibr" rid="CR50">50</xref>, <xref ref-type="bibr" rid="CR53">53</xref>, <xref ref-type="bibr" rid="CR57">57</xref>], and optimization methods
[<xref ref-type="bibr" rid="CR51">51</xref>, <xref ref-type="bibr" rid="CR58">58</xref>]. For the “closed-loop” verification problem (NCCS verification), we note that the Verisig approach
[<xref ref-type="bibr" rid="CR20">20</xref>] is efficient for NNCS with nonlinear plants and with Sigmoid and Tanh activation functions. Additionally, the recent regressive polynomial rule inference approach
[<xref ref-type="bibr" rid="CR34">34</xref>] is efficient for safety verification of NNCS with nonlinear plant models and ReLU activation functions. The satisfiability modulo convex (SMC) approach
[<xref ref-type="bibr" rid="CR35">35</xref>] is also promising for NNCS with discrete linear plants, as it provides both soundness and completeness guarantees. ReachNN 
[<xref ref-type="bibr" rid="CR19">19</xref>] is a recent approach that can efficiently control the conservativeness in the reachability analysis of NNCS with nonlinear plants and ReLU, Sigmoid, and Tanh activation functions in the controller. In 
[<xref ref-type="bibr" rid="CR54">54</xref>], a novel simulation-guided approach has been developed to reduce significantly the computation cost for verification of NNCS. In other learning-enabled systems, falsification and testing-based approaches
[<xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR45">45</xref>] have shown a significant promise in enhancing the safety of systems where perception components and neural networks interact with the physical world. Finally, there is significant related work in the domain of safe reinforcement learning 
[<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR47">47</xref>, <xref ref-type="bibr" rid="CR59">59</xref>], and combining guarantees from NNV with those provided in these methods would be interesting to explore.</p>
  </sec>
  <sec id="Sec13">
    <title>Conclusions</title>
    <p id="Par28">We presented NNV, a software tool for the verification of DNNs and learning-enabled CPS. NNV provides a collection of reachability algorithms that can be used to verify safety (and robustness) of real-world DNNs, as well as learning-enabled CPS, such as the ACC case study. For closed-loop systems, NNV can compute the exact and over-approximate reachable sets of a NNCS with linear plant models. For NNCS with nonlinear plants, NNV computes an over-approximate reachable set and uses it to verify safety, but can also automatically falsify the system to find counterexamples.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn id="Fn1">
      <label>1</label>
      <p id="Par4">The source code for NNV is publicly available: <ext-link ext-link-type="uri" xlink:href="https://github.com/verivital/nnv/">https://github.com/verivital/nnv/</ext-link>. A CodeOcean capsule 
[<xref ref-type="bibr" rid="CR43">43</xref>] is also available: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.24433/CO.0221760.v1">https://doi.org/10.24433/CO.0221760.v1</ext-link>.</p>
    </fn>
    <fn id="Fn2">
      <label>2</label>
      <p id="Par18">We omit properties <inline-formula id="IEq8"><alternatives><tex-math id="M64">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _1$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq8.gif"/></alternatives></inline-formula> and <inline-formula id="IEq9"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _2$$\end{document}</tex-math><inline-graphic xlink:href="495638_1_En_1_Chapter_IEq9.gif"/></alternatives></inline-formula> for space and due to their long runtimes, but they can be reproduced in the artifact.</p>
    </fn>
    <fn>
      <p>The material presented in this paper is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) through contract number FA8750-18-C-0089, the National Science Foundation (NSF) under grant numbers SHF 1910017 and FMitF 1918450, and the Air Force Office of Scientific Research (AFOSR) through award numbers FA9550-18-1-0122 and FA9550-19-1-0288. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation thereon. Any opinions, finding, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of AFOSR, DARPA, or NSF.</p>
    </fn>
  </fn-group>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <mixed-citation publication-type="other">Model Predictive Control Toolbox. The MathWorks Inc., Natick, Massachusetts (2019). <ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com/help/mpc/ug/adaptive-cruise-control-using-model-predictive-controller.html">https://www.mathworks.com/help/mpc/ug/adaptive-cruise-control-using-model-predictive-controller.html</ext-link></mixed-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <mixed-citation publication-type="other">Alshiekh, M., Bloem, R., Ehlers, R., Könighofer, B., Niekum, S., Topcu, U.: Safe reinforcement learning via shielding. In: Thirty-Second AAAI Conference on Artificial Intelligence (2018)</mixed-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <mixed-citation publication-type="other">Althoff, M.: An introduction to cora 2015. In: Proceedings of the Workshop on Applied Verification for Continuous and Hybrid Systems (2015)</mixed-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <mixed-citation publication-type="other">Anderson, G., Pailoor, S., Dillig, I., Chaudhuri, S.: Optimization and abstraction: A synergistic approach for analyzing neural network robustness. In: Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2019, pp. 731–744. Association for Computing Machinery, New York (2019)</mixed-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <mixed-citation publication-type="other">Bak, S., Bogomolov, S., Johnson, T.T.: Hyst: a source transformation and translation tool for hybrid automaton models. In: Proceedings of the 18th International Conference on Hybrid Systems: Computation and Control, pp. 128–133. ACM (2015)</mixed-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Bak</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Duggirala</surname>
            <given-names>PS</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Majumdar</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Kunčak</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Simulation-equivalent reachability of large linear systems with inputs</article-title>
        <source>Computer Aided Verification</source>
        <year>2017</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>401</fpage>
        <lpage>420</lpage>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">Bak, S., Tran, H.D., Johnson, T.T.: Numerical verification of affine systems with up to a billion dimensions. In: Proceedings of the 22nd ACM International Conference on Hybrid Systems: Computation and Control, pp. 23–32. ACM (2019)</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">Bojarski, M., et al.: End to end learning for self-driving cars (2016). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1604.07316">arXiv:1604.07316</ext-link></mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Chen, C., Seff, A., Kornhauser, A., Xiao, J.: Deepdriving: Learning affordance for direct perception in autonomous driving. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 2722–2730 (2015)</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">Cireşan, D., Meier, U., Schmidhuber, J.: Multi-column deep neural networks for image classification (2012). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1202.2745">arXiv:1202.2745</ext-link></mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Collobert, R., Weston, J.: A unified architecture for natural language processing: Deep neural networks with multitask learning. In: Proceedings of the 25th International Conference on Machine Learning, pp. 160–167. ACM (2008)</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Dreossi, T., Donzé, A., Seshia, S.A.: Compositional falsification of cyber-physical systems with machine learning components. In: NASA Formal Methods Symposium, pp. 357–372. Springer (2017)</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Dreossi</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Dillig</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Tasiran</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title><sc>VerifAI</sc>: A toolkit for the formal design and analysis of artificial intelligence-based systems</article-title>
        <source>Computer Aided Verification</source>
        <year>2019</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>432</fpage>
        <lpage>442</lpage>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Dutta, S., Jha, S., Sanakaranarayanan, S., Tiwari, A.: Output range analysis for deep neural networks (2017). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1709.09130">arXiv:1709.09130</ext-link></mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Fulton</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Platzer</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Vojnar</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Verifiably safe off-model reinforcement learning</article-title>
        <source>Tools and Algorithms for the Construction and Analysis of Systems</source>
        <year>2019</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>413</fpage>
        <lpage>430</lpage>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Gatys, L.A., Ecker, A.S., Bethge, M.: Image style transfer using convolutional neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2414–2423 (2016)</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Gehr, T., Mirman, M., Drachsler-Cohen, D., Tsankov, P., Chaudhuri, S., Vechev, M.: Ai 2: Safety and robustness certification of neural networks with abstract interpretation. In: 2018 IEEE Symposium on Security and Privacy (SP) (2018)</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Goldberg</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>A primer on neural network models for natural language processing</article-title>
        <source>J. Artif. Intell. Res.</source>
        <year>2016</year>
        <volume>57</volume>
        <fpage>345</fpage>
        <lpage>420</lpage>
        <pub-id pub-id-type="doi">10.1613/jair.4992</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Huang, C., Fan, J., Li, W., Chen, X., Zhu, Q.: Reachnn: Reachability analysis of neural-network controlled systems (2019). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1906.10654">arXiv:1906.10654</ext-link></mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Ivanov, R., Weimer, J., Alur, R., Pappas, G.J., Lee, I.: Verisig: verifying safety properties of hybrid systems with neural network controllers. In: Hybrid Systems: Computation and Control (HSCC) (2019)</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Julian, K.D., Lopez, J., Brush, J.S., Owen, M.P., Kochenderfer, M.J.: Policy compression for aircraft collision avoidance systems. In: 2016 IEEE/AIAA 35th Digital Avionics Systems Conference (DASC), pp. 1–10. IEEE (2016)</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Katz</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Barrett</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Dill</surname>
            <given-names>DL</given-names>
          </name>
          <name>
            <surname>Julian</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Kochenderfer</surname>
            <given-names>MJ</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Majumdar</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Kunčak</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Reluplex: An efficient SMT solver for verifying deep neural networks</article-title>
        <source>Computer Aided Verification</source>
        <year>2017</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>97</fpage>
        <lpage>117</lpage>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Katz</surname>
            <given-names>G</given-names>
          </name>
          <etal/>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Dillig</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Tasiran</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The marabou framework for verification and analysis of deep neural networks</article-title>
        <source>Computer Aided Verification</source>
        <year>2019</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>443</fpage>
        <lpage>452</lpage>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Kouvaros, P., Lomuscio, A.: Formal verification of cnn-based perception systems (2018). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1811.11373">arXiv:1811.11373</ext-link></mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Advances in Neural Information Processing Systems, pp. 1097–1105 (2012)</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Kvasnica</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Grieder</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Baotić</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Morari</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Alur</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Pappas</surname>
            <given-names>GJ</given-names>
          </name>
        </person-group>
        <article-title>Multi-parametric toolbox (MPT)</article-title>
        <source>Hybrid Systems: Computation and Control</source>
        <year>2004</year>
        <publisher-loc>Heidelberg</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>448</fpage>
        <lpage>462</lpage>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Löfberg, J.: Yalmip : A toolbox for modeling and optimization in MATLAB. In: Proceedings of the CACSD Conference,Taipei, Taiwan (2004). <ext-link ext-link-type="uri" xlink:href="http://users.isy.liu.se/johanl/yalmip">http://users.isy.liu.se/johanl/yalmip</ext-link></mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Lomuscio, A., Maganti, L.: An approach to reachability analysis for feed-forward relu neural networks (2017). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1706.07351">arXiv:1706.07351</ext-link></mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Lopez, D.M., Musau, P., Tran, H.D., Johnson, T.T.: Verification of closed-loop systems with neural network controllers. In: Frehse, G., Althoff, M. (eds.) ARCH19, 6th International Workshop on Applied Verification of Continuous and Hybrid Systems, EPiC Series in Computing, vol. 61, pp. 201–210. EasyChair (2019)</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Pulina</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Tacchella</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Touili</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Cook</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Jackson</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>An abstraction-refinement approach to verification of artificial neural networks</article-title>
        <source>Computer Aided Verification</source>
        <year>2010</year>
        <publisher-loc>Heidelberg</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>243</fpage>
        <lpage>257</lpage>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition (2014). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1409.1556">arXiv:1409.1556</ext-link></mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">Singh, G., Gehr, T., Mirman, M., Püschel, M., Vechev, M.: Fast and effective robustness certification. In: Advances in Neural Information Processing Systems, pp. 10825–10836 (2018)</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Singh, G., Gehr, T., Püschel, M., Vechev, M.: An abstract domain for certifying neural networks. Proc. ACM Program. Lang. <bold>3</bold>(POPL), 1–30 (2019). Article 41</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <mixed-citation publication-type="other">Dutta, S., Chen, X., Sankaranarayanan, S.: Reachability analysis for neural feedback systems using regressive polynomial rule inference. In: Hybrid Systems: Computation and Control (HSCC) (2019)</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Sun, X., Khedr, H., Shoukry, Y.: Formal verification of neural network controlled autonomous systems. In: Hybrid Systems: Computation and Control (HSCC) (2019)</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Szegedy, C., et al.: Intriguing properties of neural networks (2013). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1312.6199">arXiv:1312.6199</ext-link></mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Tran, H.D., Bak, S., Xiang, W., Johnson, T.T.: Verification of deep convolutional neural networks using imagestars. In: 32nd International Conference on Computer-Aided Verification (CAV). Springer (2020)</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Tran, H.D., Cei, F., Lopez, D.M., Johnson, T.T., Koutsoukos, X.: Safety verification of cyber-physical systems with reinforcement learning control. In: ACM SIGBED International Conference on Embedded Software (EMSOFT 2019). ACM (2019)</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Tran, H.D., Cei, F., Lopez, D.M., Johnson, T.T., Koutsoukos, X.: Safety verification of cyber-physical systems with reinforcement learning control (July 2019)</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">Tran, H.D., et al.: Parallelizable reachability analysis algorithms for feed-forward neural networks. In: 7th International Conference on Formal Methods in Software Engineering (FormaliSE2019), Montreal, Canada (2019)</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">Tran, H.D., et al.: Star-based reachability analysis for deep neural networks. In: 23rd International Symposium on Formal Methods, FM 2019. Springer International Publishing (2019)</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <mixed-citation publication-type="other">Tran, H.D., Nguyen, L.V., Hamilton, N., Xiang, W., Johnson, T.T.: Reachability analysis for high-index linear differential algebraic equations (daes). In: 17th International Conference on Formal Modeling and Analysis of Timed Systems (FORMATS 2019). Springer International Publishing (2019)</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Tran, H.D., et al.: NNV: The neural network verification tool for deep neural networks and learning-enabled cyber-physical systems (CodeOcean Capsule) (2020). <pub-id pub-id-type="doi">10.24433/CO.0221760.v1</pub-id></mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <mixed-citation publication-type="other">Tran, H.D., et al.: NNV: The neural network verification tool for deep neural networks and learning-enabled cyber-physical systems (2020). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2004.05519">arXiv:2004.05519</ext-link></mixed-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <mixed-citation publication-type="other">Tuncali, C.E., Fainekos, G., Ito, H., Kapinski, J.: Simulation-based adversarial test generation for autonomous vehicles with machine learning components (2018). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1804.06760">arXiv:1804.06760</ext-link></mixed-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <mixed-citation publication-type="other">Vedaldi, A., Lenc, K.: Matconvnet: Convolutional neural networks for matlab. In: Proceedings of the 23rd ACM International Conference on Multimedia, pp. 689–692. ACM (2015)</mixed-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <mixed-citation publication-type="other">Verma, A., Murali, V., Singh, R., Kohli, P., Chaudhuri, S.: Programmatically interpretable reinforcement learning. In: Dy, J., Krause, A. (eds.) Proceedings of the 35th International Conference on Machine Learning, Proceedings of Machine Learning Research, PMLR, 10–15 Jul 2018, vol. 80, pp. 5045–5054 (2018)</mixed-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <mixed-citation publication-type="other">Wang, S., Pei, K., Whitehouse, J., Yang, J., Jana, S.: Efficient formal safety analysis of neural networks. In: Advances in Neural Information Processing Systems, pp. 6369–6379 (2018)</mixed-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <mixed-citation publication-type="other">Wang, S., Pei, K., Whitehouse, J., Yang, J., Jana, S.: Formal security analysis of neural networks using symbolic intervals. In: 27th USENIX Security Symposium (USENIX Security 18). USENIX Association, Baltimore (2018)</mixed-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <mixed-citation publication-type="other">Wang, S., Pei, K., Whitehouse, J., Yang, J., Jana, S.: Formal security analysis of neural networks using symbolic intervals (2018). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1804.10829">arXiv:1804.10829</ext-link></mixed-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <mixed-citation publication-type="other">Weng, T.W., et al.: Towards fast computation of certified robustness for relu networks (2018). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1804.09699">arXiv:1804.09699</ext-link></mixed-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <mixed-citation publication-type="other">Wu, B., Iandola, F.N., Jin, P.H., Keutzer, K.: Squeezedet: Unified, small, low power fully convolutional neural networks for real-time object detection for autonomous driving. In: CVPR Workshops, pp. 446–454 (2017)</mixed-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Tran</surname>
            <given-names>HD</given-names>
          </name>
          <name>
            <surname>Johnson</surname>
            <given-names>TT</given-names>
          </name>
        </person-group>
        <article-title>Output reachable set estimation and verification for multilayer neural networks</article-title>
        <source>IEEE Trans. Neural Netw. Learn. Syst.</source>
        <year>2018</year>
        <volume>29</volume>
        <issue>11</issue>
        <fpage>5777</fpage>
        <lpage>5783</lpage>
        <pub-id pub-id-type="doi">10.1109/TNNLS.2018.2808470</pub-id>
        <pub-id pub-id-type="pmid">29993822</pub-id>
      </element-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <mixed-citation publication-type="other">Xiang, W., Tran, H.D., Yang, X., Johnson, T.T.: Reachable set estimation for neural network control systems: A simulation-guided approach. IEEE Trans. Neural Netw. Learn. Syst. 1–10 (2020)</mixed-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <mixed-citation publication-type="other">Xiang, W., Tran, H.D., Johnson, T.T.: Reachable set computation and safety verification for neural networks with relu activations (2017). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1712.08163">arXiv:1712.08163</ext-link></mixed-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <mixed-citation publication-type="other">Xiang, W., Tran, H.D., Johnson, T.T.: Specification-guided safety verification for feedforward neural networks. In: AAAI Spring Symposium on Verification of Neural Networks (2019)</mixed-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <mixed-citation publication-type="other">Yang, X., Tran, H.D., Xiang, W., Johnson, T.: Reachability analysis for feed-forward neural networks using face lattices (2020). arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2003.01226">arXiv:2003.01226</ext-link></mixed-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <mixed-citation publication-type="other">Zhang, H., Weng, T.W., Chen, P.Y., Hsieh, C.J., Daniel, L.: Efficient neural network robustness certification with general activation functions. In: Advances in Neural Information Processing Systems, pp. 4944–4953 (2018)</mixed-citation>
    </ref>
    <ref id="CR59">
      <label>59.</label>
      <mixed-citation publication-type="other">Zhu, H., Xiong, Z., Magill, S., Jagannathan, S.: An inductive synthesis framework for verifiable reinforcement learning. In: Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2019, pp. 686–701. Association for Computing Machinery, New York (2019)</mixed-citation>
    </ref>
  </ref-list>
</back>
