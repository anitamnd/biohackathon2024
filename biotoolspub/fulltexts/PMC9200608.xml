<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20050630//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformation</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformation</journal-id>
    <journal-id journal-id-type="publisher-id">Bioinformation</journal-id>
    <journal-title-group>
      <journal-title>Bioinformation</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0973-8894</issn>
    <issn pub-type="epub">0973-2063</issn>
    <publisher>
      <publisher-name>Biomedical Informatics</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9200608</article-id>
    <article-id pub-id-type="publisher-id">97320630018036</article-id>
    <article-id pub-id-type="doi">10.6026/97320630018036</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Fast-HBR: Fast hash based duplicate read remover</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Altayyar</surname>
          <given-names>Sami</given-names>
        </name>
        <xref rid="A1" ref-type="aff">1</xref>
        <xref rid="COR1" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Artoli</surname>
          <given-names>Abdel Monim</given-names>
        </name>
        <xref rid="A1" ref-type="aff">1</xref>
      </contrib>
      <aff id="A1"><label>1</label>Department of Computer Science, College of Computer and Information Sciences, King Saud University, P.O. Box 51178, Riyadh 11543, Saudi Arabia</aff>
    </contrib-group>
    <author-notes>
      <corresp id="COR1"><label>*</label>Sami Altayyar <email>436107303@student.ksu.edu.sa</email><email>aartoli@ksu.edu.sa</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>31</day>
      <month>1</month>
      <year>2022</year>
    </pub-date>
    <volume>18</volume>
    <issue>1</issue>
    <fpage>36</fpage>
    <lpage>40</lpage>
    <history>
      <date date-type="received">
        <day>13</day>
        <month>11</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>29</day>
        <month>11</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>11</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Â© 2022 Biomedical Informatics</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/3.0/</ali:license_ref>
        <license-p>This is an Open Access article which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly credited. This is distributed under the terms of the Creative Commons Attribution License.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>The Next-Generation Sequencing (NGS) platforms produce massive amounts of data to analyze various features in environmental samples. These data contain multiple duplicate reads which impact the analyzing process efficiency and accuracy. We describe
Fast-HBR, a fast and memory-efficient duplicate reads removing tool without a reference genome using de-novo principles. It uses hash tables to represent reads in integer value to minimize memory usage for faster manipulation. Fast-HBR is faster and
has less memory footprint when compared with the state of the art De-novo duplicate removing tools. Fast-HBR implemented in Python 3 is available at https://github.com/Sami-Altayyar/Fast-HBR.</p>
    </abstract>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>Background:</title>
    <p>The number of the publicly available NGS projects tripled from 1200 in 2017 to 3500 in 2020 [<xref rid="R01" ref-type="bibr">1</xref>-<xref rid="R02" ref-type="bibr">2</xref>]. Therefore, preprocessing of data is essential to reduce the size of the data
with an adequate level of data quality [<xref rid="R03" ref-type="bibr">3</xref>]. One of the preprocessing steps that reduce the dataset size is removing duplicate reads in the dataset. This step is essential for sequence-based algorithms since duplicate
reads affect the algorithm accuracy [<xref rid="R04" ref-type="bibr">4</xref>]. Removing duplicate reads may reduce the assembly algorithms consumption of RAM [<xref rid="R05" ref-type="bibr">5</xref>]. Duplicate reads removal tools are either reference based
or de novo. Some examples of de novo tools are CD-HIT [<xref rid="R06" ref-type="bibr">6</xref>], FastUniq [<xref rid="R07" ref-type="bibr">7</xref>] and Fulcrum [<xref rid="R08" ref-type="bibr">8</xref>]. Available de novo tools include NGS Reads Treatment
[<xref rid="R09" ref-type="bibr">9</xref>], Nubeam-dedup [<xref rid="R05" ref-type="bibr">5</xref>], BioSeqZip [<xref rid="R10" ref-type="bibr">10</xref>] and Minirmd [<xref rid="R11" ref-type="bibr">11</xref>]. NGS Reads Treatment [<xref rid="R09" ref-type="bibr">9</xref>]
is a hash-based tool that uses Cuckoo Filter [<xref rid="R12" ref-type="bibr">12</xref>] which is a probabilistic data structure. The authors elsewhere [<xref rid="R05" ref-type="bibr">5</xref>] developed the Nubeam-dedup tool that uses Nubeam
[<xref rid="R13" ref-type="bibr">13</xref>] to represent each read as a number by calculating a product of matrices that represent nucleotides in the read. The BioSeqZip [<xref rid="R10" ref-type="bibr">10</xref>] tool starts by splitting the reads into small
chunks, and then it sorts them alphabetically with memory limiting feature having long processing time. Minirmd [<xref rid="R11" ref-type="bibr">11</xref>] with the help of k-minimizer [<xref rid="R14" ref-type="bibr">14</xref>] clusters the reads into groups,
where each group will contain reads that have the same k-minimizer in the same position. Therefore, it is of interest to describe Fast-HBR, a fast and memory-efficient duplicate reads removing tool without a reference genome using de-novo principles.</p>
  </sec>
  <sec id="s2">
    <title>Methodology:</title>
    <p>Fast-HBR is implemented in Python 3. Therefore, it is platform-independent. The source code is available at https://github.com/Sami-Altayyar/Fast-HBR. It uses Python's built-in hash function to represent reads (in nucleotide or amino acid level) as an
integer value. The reads hash value is stored in a set and each new read hash value will compare to the set items to decide if it is duplicate or not. The input files are either a single-end or paired-end, and it could process the files with reverse complement
removing option or without it.</p>
  </sec>
  <sec id="s2a">
    <title>Single-end files:</title>
    <p>In single-end files, each read is independent; therefore its evaluation process will depend only on its hash value. Fast-HBR will starts by creating a set (UniqSet) to store all unique hash values. After that, it extracts from the input file one read at a
time and then calculate the hash value (HV1) of the read. Depending on HV1 and the reverse complement removing option, Fast-HBR will have three cases. In the first case, if HV1 is in UniqSet, the read will consider a duplicate and will be discarded. In the
second case, if HV1 is not in UniqSet and the reverse complement removing option is not activated, then HV1 will be added to UniqSet and the read will be written in the output file. In the third case, if HV1 is not in UniqSet and the reverse complement removing
option is activated, Fast-HBR will calculate the hash value of the reverse complement of the read (HV2). If HV2 is in UniqSet the read will consider a duplicate and will be discarded. Otherwise, the read is unique and then only HV1 will be added to UniqSet and
the read will be written in the output file.</p>
    <p>We consider the input reads and their reverse and the hash values for the reads and the reverse as shown in <xref rid="F1" ref-type="fig">Figure 1A</xref>. In the beginning, the reads R1 and R2 are unique and therefore their hash values would be added to
UniqSet as in <xref rid="F1" ref-type="fig">Figure 1B</xref>. For R3, its hash value (111222) is in UniqSet therefore R3 would be considered as duplicate read, and it will be discarded. Regarding read R4, the read hash value (123123) is not in UniqSet therefore
if the reverse complement option is not active it will be considered a unique read and its hash value would be added to UniqSet as in <xref rid="F1" ref-type="fig">Figure 1C</xref>, but if the reverse complement option is active, the hash value of the read
reverse complement RV4 (101010) is in UniqSet and it will be considered as duplicate read and discarded.Finally, the read R5 hash value (101234) is not in UniqSet and its reverse complement hash value (001122) is not in UniqSet. Therefore, if the reverse
complement option is active or not the read R5 is unique and the hash value of it (101234) would be added to UniqSet. <xref rid="F1" ref-type="fig">Figure 1D</xref> shows the final UniqSet if the reverse complement option is active and
<xref rid="F1" ref-type="fig">Figure 1E</xref> if the reverse complement option is not active. Fast-HBR will not calculate the reverse complement hash unless it is necessary, which will minimize computational operations to the minimum. On the other hand, since
we store only HV1 of unique reads in UniqSet, the number of elements in UniqSet will be less than or equal to the number of reads in the file. Consequently, the memory would be used efficiently, especially because the hash values in UniqSet are integers.</p>
  </sec>
  <sec id="s2b">
    <title>Paired-end files:</title>
    <p>For paired-end file processing, Fast-HBR would create a set (UniqSet) to store unique hash values. For each pair of reads i (R i1, R i2), if the reverse complement removing option is not activated, Fast-HBR would calculate the hash value (HV) as the hash
of the concatenation of the two reads (Hash (R i1 concatenate R i2)). Then, if HV is present in UniqSet the reads pair (R i1, R i2) would be considered as a duplicate. Otherwise, the reads pair (R i1, R i2) is unique and will be written to the output file and
HV would be added to UniqSet. The second case is when the reverse complement removing option is active as shown in <xref rid="F1" ref-type="fig">Figure 1</xref>. Here, the change is the calculation of HV. It would be the sum of the hash value of R i1 plus the
hash value of R i2. Therefore, if the pair reads in position (i) swapped in other position (j) in the file, they will have the same HV value and should be considered as a duplicate. Either with or without the reverse complement removing option, this methodology
would guarantee that each pair of reads would represent by only one integer value. Because of that, the number of elements in UniqSet will be less than or equal to the number of pairs of reads, which lets Fast-HBR deal with memory more efficiently.</p>
  </sec>
  <sec id="s3">
    <title>Results and Discussion:</title>
    <p>Results obtained using Fast-HBR is tabulated in Table 2(see PDF), Table 3(see PDF) and Table 4(see PDF). Comparisons with NGS Reads Treatment [<xref rid="R09" ref-type="bibr">9</xref>], Nubeam-dedup [<xref rid="R05" ref-type="bibr">5</xref>], BioSeqZip
[<xref rid="R10" ref-type="bibr">10</xref>] and Minirmd [<xref rid="R11" ref-type="bibr">11</xref>] similar state of the art De novo tools are shown. The Linux bash command time was used to calculate the time spent by each tool and the tool's maximum memory
usage. In this comparison, six datasets were used, three are single-end datasets (SRR10315305, SRR13555429 &amp; SRR13555395) and three paired-end datasets (SRR681003, SRR837669, SRR6424061) and Table 1(see PDF) shows the datasets information. We run the
tools on King Abdulaziz University's High Performance Computing Center (Aziz Supercomputer) (http://hpc.kau.edu.sa), where all tools run on normal nodes which equipped with 24 processors and 96GB memory. Because NGS Reads Treatment [<xref rid="R09" ref-type="bibr">9</xref>]
and BioSeqZip [<xref rid="R10" ref-type="bibr">10</xref>] do not support the reverse complement removing option, we had to conduct two comparisons for each dataset. First, all five tools were compared without the reverse complement removing option, and the
second comparison is only between Fast-HBR, Nubeam-dedup [<xref rid="R05" ref-type="bibr">5</xref>] and Minirmd [<xref rid="R11" ref-type="bibr">11</xref>] while with reverse complement removing option is activated.</p>
    <p>NGS Reads Treatment [<xref rid="R09" ref-type="bibr">9</xref>] with a different number of threads (16, 24, 32) was very slow and was not able to complete the processing of five datasets (SRR13555429, SRR13555395, SRR681003, SRR837669, SRR6424061) because it
exceeds the limited time for the job which is 48 hours. Minirmd [<xref rid="R11" ref-type="bibr">11</xref>] consumes a huge amount of memory and it failed to complete the processing of four datasets (SRR13555429, SRR13555395, SRR837669, SRR6424061) because of
a memory error. Moreover, Nubeam-dedup [<xref rid="R05" ref-type="bibr">5</xref>] was able to process all datasets except SRR6424061 when the reverse complement removing option is activated because of memory error. On the other hand, Fast-HBR and BioSeqZip
[<xref rid="R10" ref-type="bibr">10</xref>] were able to process all datasets successfully. We note that BioSeqZip [<xref rid="R10" ref-type="bibr">10</xref>] has the ability to limit the memory usage (default 4GB) and we try to increase its memory limit to
16GB, 32GB, and 64GB, but the tool failed to complete the process and cause a memory error, therefore, we run the tool with its default's memory limit.</p>
    <p>Table 2(see PDF) shows the number of removed reads in each dataset after applying the tools. Minirmd [<xref rid="R11" ref-type="bibr">11</xref>] was the tool that removed the smallest number of duplicated reads. On the other hand, the remaining tools were
able to remove the same number of duplicated reads except for Nubeam-dedup [<xref rid="R05" ref-type="bibr">5</xref>] in one dataset (SRR6424061) where it considered a slightly a greater number of reads as duplicated reads. The results of the tools regarding
CPU time and memory footprint are tabulated in Table 3 and Table 4(see PDF). Table 3(see PDF) shows the results when the tools applied on the datasets without the reverse complement removing option, where Table 4(see PDF) contains the results when the reverse
complement removing option is activated.</p>
    <p>Fast-HBR was the tool with the least CPU time in all single-end datasets in either case with or without reverse complement removing option. It was able to outperform the tool with the second least CPU time by a percentage that varies from 10% to 37%. In
the paired-end datasets, Fast-HBR was the tool with the least CPU time in two of the three datasets and the outperform percentage in these two datasets varies from 23% to 67%. Generally, Fast-HBR was the tool with the least CPU time in ten out of twelve possible
cases of processing datasets. Finally, the processing time for the tools when reverse complement is not activated is shown in <xref rid="F2" ref-type="fig">Figure 2</xref> while <xref rid="F3" ref-type="fig">Figure 3</xref> shows the processing time for the
tools when reverse complement activated and here we should mention that NGS Reads Treatment [<xref rid="R09" ref-type="bibr">9</xref>] and Minirmd [<xref rid="R11" ref-type="bibr">11</xref>] are removed from the figures because they were not able to complete
most of the datasets. BioSeqZip [<xref rid="R10" ref-type="bibr">10</xref>] consume almost the same memory amount in all datasets because of its memory limit control. Therefore, it has a smaller memory footprint than Fast-HBR in all datasets except SRR10315305.
If we exclude BioSeqZip [<xref rid="R10" ref-type="bibr">10</xref>] because it caused memory error when we try to increase the memory limit, Fast-HBR consumes the least memory in all paired-end datasets with or without the reverse complement removing option.
Moreover, when the reverse complement removing option is activated, Fast-HBR has the least memory footprint while processing all datasets. By comparing each tool's memory consumption when the reverse complement is not active (Table 3 - see PDF) and when the
reverse complement is activated (Table 4 - see PDF), we noted that the amount of memory used by the Fast-HBR is almost unchanged whether the reverse complement option is enabled or not. On the other hand, when the reverse complement option is enabled the memory
footprint of Nubeam-dedup [<xref rid="R05" ref-type="bibr">5</xref>] almost doubled.</p>
  </sec>
  <sec id="s4">
    <title>Conclusion:</title>
    <p>We describe a de novo tool named Fast-HBR to remove duplicated reads in the meta-genomics data to reduce the dataset size which will benefit the meta-genomics analyzing pipelines. Fast-HBR represents each read to a single integer value by using hashing
algorithms and hash tables for memory efficiency and speed. Fast-HBR shows the least computational requirement in validation. The CPU time required by it was less than the second-best tool Nubeam-dedup [<xref rid="R05" ref-type="bibr">5</xref>] by at least
10% and up to 67%. Moreover, Fast-HBR is the least memory consumption tool in all paired-end datasets using the reverse complement removing option.</p>
  </sec>
</body>
<back>
  <ack>
    <p>The authors would like to thank Deanship of scientific research in King Saud University for funding and supporting this research through the initiative of DSR Graduate Students Research Support (GSR).</p>
  </ack>
  <fn-group>
    <fn id="FN2" fn-type="COI-statement">
      <p>The authors declare no conflict of interest.</p>
    </fn>
  </fn-group>
  <fn-group>
    <fn id="FN" fn-type="other">
      <p>
        <bold>Edited by P Kangueane</bold>
      </p>
    </fn>
  </fn-group>
  <fn-group>
    <fn id="FN1" fn-type="other">
      <p><bold>Citation: </bold>Altayyar &amp; Monim Artoli, Bioinformation 18(1):36-40 (2022)</p>
    </fn>
  </fn-group>
  <fn-group>
    <fn id="FN3" fn-type="other">
      <p><bold>Declaration on Publication Ethics:</bold> The author's state that they adhere with COPE guidelines on publishing ethics as described elsewhere at https://publicationethics.org/.
The authors also undertake that they are not associated with any other third party (governmental or non-governmental agencies) linking with any form of unethical issues connecting to this publication. The authors also declare
that they are not withholding any information that is misleading to the publisher in regard to this article.</p>
    </fn>
  </fn-group>
  <fn-group>
    <fn id="FN4" fn-type="other">
      <p><bold>Declaration on official E-mail: </bold> The corresponding author declares that official e-mail from their institution is not available for all authors.</p>
    </fn>
  </fn-group>
  <fn-group>
    <fn id="FN5" fn-type="other">
      <p><bold>License statement: </bold> This is an Open Access article which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly
credited. This is distributed under the terms of the Creative Commons Attribution License</p>
    </fn>
  </fn-group>
  <fn-group>
    <fn id="FN6" fn-type="other">
      <p><bold>Comments from readers: </bold> Articles published in BIOINFORMATION are open for relevant post publication comments and criticisms, which will be published immediately linking to
the original article without open access charges. Comments should be concise, coherent and critical in less than 1000 words.</p>
    </fn>
  </fn-group>
  <ref-list>
    <title>References</title>
    <ref id="R01">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mitchell</surname>
            <given-names>AL</given-names>
          </name>
          <etal/>
        </person-group>
        <source>Nucleic Acids Research </source>
        <year>2018</year>
        <volume>46</volume>
        <fpage>D726</fpage>
        <?supplied-pmid 29069476?>
        <pub-id pub-id-type="pmid">29069476</pub-id>
      </element-citation>
    </ref>
    <ref id="R02">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mitchell</surname>
            <given-names>AL</given-names>
          </name>
          <etal/>
        </person-group>
        <source>Nucleic Acids Research </source>
        <year>2020</year>
        <volume>48</volume>
        <fpage>D570</fpage>
        <?supplied-pmid 31696235?>
        <pub-id pub-id-type="pmid">31696235</pub-id>
      </element-citation>
    </ref>
    <ref id="R03">
      <label>3</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Exposito</surname>
            <given-names>RR</given-names>
          </name>
          <etal/>
        </person-group>
        <source>Bioinformatics </source>
        <year>2017</year>
        <volume>33</volume>
        <fpage>2762</fpage>
        <?supplied-pmid 28475668?>
        <pub-id pub-id-type="pmid">28475668</pub-id>
      </element-citation>
    </ref>
    <ref id="R04">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Manconi</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <source>BMC Bioinformatics </source>
        <year>2016</year>
        <volume>17</volume>
        <fpage>346</fpage>
        <?supplied-pmid 28185553?>
        <pub-id pub-id-type="pmid">28185553</pub-id>
      </element-citation>
    </ref>
    <ref id="R05">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dai</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Guan</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <source>Bioinformatics </source>
        <year>2020</year>
        <volume>36</volume>
        <fpage>3254</fpage>
        <?supplied-pmid 32091581?>
        <pub-id pub-id-type="pmid">32091581</pub-id>
      </element-citation>
    </ref>
    <ref id="R06">
      <label>6</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Godzik</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <source>Bioinformatics </source>
        <year>2006</year>
        <volume>22</volume>
        <fpage>1658</fpage>
        <?supplied-pmid 16731699?>
        <pub-id pub-id-type="pmid">16731699</pub-id>
      </element-citation>
    </ref>
    <ref id="R07">
      <label>7</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <source>PloS One </source>
        <year>2012</year>
        <volume>7</volume>
        <fpage>e52249</fpage>
        <?supplied-pmid 23284954?>
        <pub-id pub-id-type="pmid">23284954</pub-id>
      </element-citation>
    </ref>
    <ref id="R08">
      <label>8</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Burriesci</surname>
            <given-names>MS</given-names>
          </name>
          <etal/>
        </person-group>
        <source>Bioinformatics </source>
        <year>2012</year>
        <volume>28</volume>
        <fpage>1324</fpage>
        <?supplied-pmid 22419786?>
        <pub-id pub-id-type="pmid">22419786</pub-id>
      </element-citation>
    </ref>
    <ref id="R09">
      <label>9</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gaia</surname>
            <given-names>ASC</given-names>
          </name>
          <etal/>
        </person-group>
        <source>Scientific Reports </source>
        <year>2019</year>
        <volume>9</volume>
        <fpage>1</fpage>
        <?supplied-pmid 31406180?>
        <pub-id pub-id-type="pmid">30626917</pub-id>
      </element-citation>
    </ref>
    <ref id="R10">
      <label>10</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Urgese</surname>
            <given-names>G</given-names>
          </name>
          <etal/>
        </person-group>
        <source>Bioinformatics </source>
        <year>2020</year>
        <volume>36</volume>
        <fpage>2705</fpage>
        <?supplied-pmid 31999333?>
        <pub-id pub-id-type="pmid">31999333</pub-id>
      </element-citation>
    </ref>
    <ref id="R11">
      <label>11</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <source>Bioinformatics </source>
        <year>2021</year>
        <volume>37</volume>
        <fpage>1604</fpage>
        <?supplied-pmid 33112385?>
        <pub-id pub-id-type="pmid">33112385</pub-id>
      </element-citation>
    </ref>
    <ref id="R12">
      <label>12</label>
      <element-citation publication-type="journal" id="element-citation12">
        <person-group person-group-type="author">
          <name>
            <surname>Pagh</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Rodler</surname>
            <given-names>FF</given-names>
          </name>
        </person-group>
        <source>Journal of Algorithms </source>
        <year>2004</year>
        <volume>51</volume>
        <fpage>122</fpage>
      </element-citation>
      <element-citation publication-type="webpage" id="element-citation13">
        <pub-id pub-id-type="doi">10.1016/j.jalgor.2003.12.002</pub-id>
      </element-citation>
    </ref>
    <ref id="R13">
      <label>13</label>
      <element-citation publication-type="webpage">
        <comment>
          <ext-link xlink:href="https://www.biorxiv.org/" ext-link-type="uri">https://www.biorxiv.org/</ext-link>
        </comment>
      </element-citation>
    </ref>
    <ref id="R14">
      <label>14</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Roberts</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <source>Bioinformatics </source>
        <year>2004</year>
        <volume>20</volume>
        <fpage>3363</fpage>
        <?supplied-pmid 15256412?>
        <pub-id pub-id-type="pmid">15256412</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig position="float" id="F1">
    <label>Figure 1</label>
    <caption>
      <p>Fast-HBR methodology illustrated using an example.</p>
    </caption>
    <graphic xlink:href="97320630018036F1" position="float"/>
  </fig>
  <fig position="float" id="F2">
    <label>Figure 2</label>
    <caption>
      <p>Processing time for the used datasets without reverse complement removing option.</p>
    </caption>
    <graphic xlink:href="97320630018036F2" position="float"/>
  </fig>
  <fig position="float" id="F3">
    <label>Figure 3</label>
    <caption>
      <p>Processing time for the used datasets with reverse complement removing option. It should be noted that Nubeam-dedup was not able to complete processing SRR6424061 dataset.</p>
    </caption>
    <graphic xlink:href="97320630018036F3" position="float"/>
  </fig>
</floats-group>
