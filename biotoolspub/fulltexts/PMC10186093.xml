<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10186093</article-id>
    <article-id pub-id-type="pmid">34478488</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btab634</article-id>
    <article-id pub-id-type="publisher-id">btab634</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Notes</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Bioimage Informatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CellProfiler Analyst 3.0: accessible data exploration and machine learning for image analysis</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Stirling</surname>
          <given-names>David R</given-names>
        </name>
        <aff><institution>Imaging Platform, Broad Institute of MIT and Harvard</institution>, Cambridge, MA 02142, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Carpenter</surname>
          <given-names>Anne E</given-names>
        </name>
        <aff><institution>Imaging Platform, Broad Institute of MIT and Harvard</institution>, Cambridge, MA 02142, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-9640-9318</contrib-id>
        <name>
          <surname>Cimini</surname>
          <given-names>Beth A</given-names>
        </name>
        <xref rid="btab634-cor1" ref-type="corresp"/>
        <aff><institution>Imaging Platform, Broad Institute of MIT and Harvard</institution>, Cambridge, MA 02142, <country country="US">USA</country></aff>
        <!--bcimini@broadinstitute.org-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Xu</surname>
          <given-names>Jinbo</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btab634-cor1">To whom correspondence should be addressed. <email>bcimini@broadinstitute.org</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>11</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-09-03">
      <day>03</day>
      <month>9</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>03</day>
      <month>9</month>
      <year>2021</year>
    </pub-date>
    <volume>37</volume>
    <issue>21</issue>
    <fpage>3992</fpage>
    <lpage>3994</lpage>
    <history>
      <date date-type="received">
        <day>20</day>
        <month>7</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>27</day>
        <month>8</month>
        <year>2021</year>
      </date>
      <date date-type="editorial-decision">
        <day>30</day>
        <month>8</month>
        <year>2021</year>
      </date>
      <date date-type="corrected-typeset">
        <day>12</day>
        <month>9</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Â© The Author(s) 2021. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btab634.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Summary</title>
        <p>Image-based experiments can yield many thousands of individual measurements describing each object of interest, such as cells in microscopy screens. CellProfiler Analyst is a free, open-source software package designed for the exploration of quantitative image-derived data and the training of machine learning classifiers with an intuitive user interface. We have now released CellProfiler Analyst 3.0, which in addition to enhanced performance adds support for neural network classifiers, identifying rare object subsets, and direct transfer of objects of interest from visualization tools into the Classifier tool for use as training data. This release also increases interoperability with the recently released CellProfiler 4, making it easier for users to detect and measure particular classes of objects in their analyses.</p>
      </sec>
      <sec id="s2">
        <title>Availability</title>
        <p>CellProfiler Analyst binaries for Windows and MacOS are freely available for download at <ext-link xlink:href="https://cellprofileranalyst.org/" ext-link-type="uri">https://cellprofileranalyst.org/</ext-link>. Source code is implemented in Python 3 and is available at <ext-link xlink:href="https://github.com/CellProfiler/CellProfiler-Analyst/" ext-link-type="uri">https://github.com/CellProfiler/CellProfiler-Analyst/</ext-link>. A sample dataset is available at <ext-link xlink:href="https://cellprofileranalyst.org/examples" ext-link-type="uri">https://cellprofileranalyst.org/examples</ext-link>, based on images freely available from the Broad Bioimage Benchmark Collection.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R35 GM122547</award-id>
        <award-id>P41 GM135019</award-id>
        <award-id>2020-225720</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Chan Zuckerberg Initiative DAF</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Silicon Valley Community Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/100000923</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="3"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Background</title>
    <p>With the increasing adoption of high-throughput microscopy, scientists have been able to generate large datasets containing thousands of individual images. This necessitates automated computational analysis to efficiently derive biological insights from the raw data. Free software packages such as ImageJ (<xref rid="btab634-B12" ref-type="bibr">Schneider <italic toggle="yes">et al.</italic>, 2012</xref>) and CellProfiler (<xref rid="btab634-B9" ref-type="bibr">McQuin <italic toggle="yes">et al.</italic>, 2018</xref>) allow users to extract hundreds or thousands of numerical measurements from their image data, but it is ultimately on the user to determine which of these features are relevant to the biological problem being investigated. Spreadsheet programs are familiar but lack features and integration with source images that biologists often need. CellProfiler Analyst is a data exploration package for helping users to explore and extract information from large datasets, including (but not limited to) those produced by CellProfiler pipelines (<xref rid="btab634-B7" ref-type="bibr">Jones <italic toggle="yes">et al.,</italic> 2008</xref>). The software includes several tools for users to visualize and filter their datasets, alongside tools for training machine learning classifier models within a convenient graphical user interface that is geared toward working with image data (<xref rid="btab634-B2" ref-type="bibr">Dao <italic toggle="yes">et al.,</italic> 2016</xref>). While other tools such as Ilastik (<xref rid="btab634-B1" ref-type="bibr">Berg <italic toggle="yes">et al.,</italic> 2019</xref>) and Advanced Cell Classifier (<xref rid="btab634-B11" ref-type="bibr">Piccinini <italic toggle="yes">et al.</italic>, 2017</xref>) can provide a GUI for training classifiers with image-based data, these do not include data exploration and visualization tools like those in CellProfiler Analyst. These tools provide an intuitive interface for scientists to explore their data in forms such as histograms and scatter plots, though without the advanced statistical tools or extreme customizability of a pure programming language. Herein we present CellProfiler Analyst 3.0, which includes major performance improvements and new features that improve the utility of the software.</p>
  </sec>
  <sec>
    <title>2 General changes</title>
    <p>We ported CellProfiler Analyst to the Python 3 programming language to ensure compatibility with future operating systems after the official Python 2 end-of-life in 2020. We also revised the programâs builds to package all Java dependencies within the main installer, which dramatically simplifies the installation process. In addition, we added a faster imageio-based image loader to supplement the existing bioformats-based implementation (<xref rid="btab634-B13" ref-type="bibr">Silvester <italic toggle="yes">et al</italic>., 2020</xref>). While bioformats provides broader file format compatibility, imageio allows for common image formats to be loaded more efficiently, which greatly improves the time to generate object thumbnails. At present neither of these loaders supports accessing only partial sections of an image, which may be an area for further development to handle large files produced by whole slide imaging.</p>
    <p>CellProfiler Analyst 3.0 can export machine learning models that are compatible with CellProfiler 4.2+, allowing the resulting classifiers to be directly embedded into CellProfiler pipelines. This maintains and expands upon the interoperability between the two programs.</p>
  </sec>
  <sec>
    <title>3 New features</title>
    <p>We added a dimensionality reduction tool to help users visualize the variance within high-dimensional datasets (<xref rid="btab634-F1" ref-type="fig">Fig.Â 1A</xref>). This is particularly important when creating classifiers that can identify rare images in a set; rare outliers are needed for training but may be difficult to find through random sampling. When the dataset contains thousands of measurements users can struggle to identify those which reveal these outliers. Dimensionality reduction allows the numerous measurements generated by CellProfiler to be condensed into a smaller subset of features which represent the overall variance in the dataset. This provides a more manageable series of features which the user can then explore.</p>
    <fig position="float" id="btab634-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>Improvements in CellProfiler Analyst 3.0. <bold>a</bold>) Screenshot of the new Dimensionality Reduction tool, using principal component analysis with the example dataset. Marker colors represent classification results from a previously generated classifier. The lasso tool has been activated to select objects of interest, which can then be used to train a classifier. <bold>b</bold>) Comparison of execution time between CPA 2.2 and CPA 3.0 when loading a training set of 600 objects in 13 classes. <bold>c</bold>) Execution time to run the training sequence for a FastGentleBoosting classifier. <bold>d</bold>) Time taken to score 45â000 objects using a FastGentleBoosting classifier. <bold>e</bold>) Execution time to score a single image containing 130 objects, then annotate results onto a preview image.</p>
      </caption>
      <graphic xlink:href="btab634f1" position="float"/>
    </fig>
    <p>This tool supports multiple common reduction techniques including principal component analysis (<xref rid="btab634-B10" ref-type="bibr">Pearson 1901</xref>), Feature Agglomeration (<xref rid="btab634-B6" ref-type="bibr">Jain <italic toggle="yes">et al.,</italic> 1999</xref>) and t-Distributed Stochastic Neighbor Embedding (<xref rid="btab634-B14" ref-type="bibr">van der Maaten and Hinton 2008</xref>). The resulting components can be visualized on a scatter plot, which can color individual objects by class if the classification was previously performed on the dataset. As with other tools, users can create gates to isolate specific populations for further analysis.</p>
    <p>We improved the gating functionality so that gates drawn in plotting tools are immediately made available within the Classifier tool, rather than having to be manually converted into filters. The dimensionality reduction tool contains a new lasso tool for selecting objects of interest through drawing a custom polygon. Right-click menu options allow the selected objects to be sent directly to an open Classifier window for use as training data. These improvements simplify the process of finding populations of interest and creating training sets for machine learning models in the Classifier.</p>
    <p>In the Classifier tool we added support for automatic rescaling of input data, based on the scikit-learn StandardScaler implementation (<xref rid="btab634-B4" ref-type="bibr">Pedregosa <italic toggle="yes">et al.,</italic> 2011</xref>). This improves the performance of certain classifier types (such as K-Neighbors) that are skewed by the absolute values of measurements. It also now supports tunable neural network classifiers based on the scikit-learn MLPClassifier class (<xref rid="btab634-B5" ref-type="bibr">Hinton 1989</xref>), which can be useful for performing complex non-linear classification tasks. New keyboard shortcuts for sorting objects into classification bins provide a more rapid means of generating training sets than dragging-and-dropping.</p>
  </sec>
  <sec>
    <title>4 Performance improvements</title>
    <p>We improved performance in several areas of the Classifier tool. We optimized loading of previously saved training sets by batching objects during database fetching, reducing the loading time for a sample dataset by over 10-fold (<xref rid="btab634-F1" ref-type="fig">Fig.Â 1B</xref>). We also found that removing redundant database calls and unnecessary caching steps during classifier model training reduced processing time by 90% (<xref rid="btab634-F1" ref-type="fig">Fig.Â 1C</xref>).</p>
    <p>Database handling improvements were also made in the functions for scoring the datasets after training. These refinements produced a modest improvement in the performance of the âscore allâ (<xref rid="btab634-F1" ref-type="fig">Fig.Â 1D</xref>) function. We further optimized the âscore imageâ function by revising the workflow for fetching object coordinates, which significantly reduced the time taken to display a scoring preview overlay (<xref rid="btab634-F1" ref-type="fig">Fig.Â 1E</xref>). Usability improvements to the image viewer include a shortcut to resize the image to fit the window and a table display outlining counts of each class found in the image.</p>
  </sec>
  <sec>
    <title>5 Future directions</title>
    <p>The next major frontier for phenotype classification is to train deep learning models straight from raw pixels rather than requiring a separate feature extraction step (<xref rid="btab634-B8" ref-type="bibr">Lucas <italic toggle="yes">et al.,</italic> 2021</xref>). Enabling scoring of phenotypes that fall along a continuum rather than into discrete bins would also be useful, as we recently found in red blood cell aging (<xref rid="btab634-B3" ref-type="bibr">Doan <italic toggle="yes">et al.,</italic> 2020</xref>). A remaining limitation in our software is that only MySQL and SQLite databases can be accessed, though migrating toward using packages such as sqlalchemy could expand on compatibility in the future. Ultimately, maintaining CellProfiler Analyst as an up-to-date resource for users to explore high-dimensional, image-based data without needing to code will help the biology community for years to come.</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors would like to thank Pearl Ryder, Erin Weisbart, Jane Hung, David Dao, Egor Zindy and Mario Emmenlauer for contributions to bug fixes and testing of pre-release versions of this software. They also thank all the members of the bioimaging community who have provided feedback and suggestions which have helped to guide this work.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by the National Institutes of Health grants (R35 GM122547 and P41 GM135019 to A.E.C.). This project has been made possible in part by grant number 2020-225720 to B.A.C. from the Chan Zuckerberg Initiative DAF, an advised fund of the Silicon Valley Community Foundation. The funders had no role in study design, data collection and analysis, decision to publish, or manuscript preparation.</p>
      <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btab634-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berg</surname><given-names>S.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) <article-title>Ilastik: interactive machine learning for (bio)image analysis</article-title>. <source>Nat. Methods</source>, <volume>16</volume>, <fpage>1226</fpage>â<lpage>1232</lpage>.<pub-id pub-id-type="pmid">31570887</pub-id></mixed-citation>
    </ref>
    <ref id="btab634-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dao</surname><given-names>D.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2016</year>) <article-title>CellProfiler analyst: interactive data exploration, analysis and classification of large biological image sets</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>3210</fpage>â<lpage>3212</lpage>.<pub-id pub-id-type="pmid">27354701</pub-id></mixed-citation>
    </ref>
    <ref id="btab634-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Doan</surname><given-names>M.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) <article-title>Objective assessment of stored blood quality by deep learning</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>117</volume>, <fpage>21381</fpage>â<lpage>21390</lpage>.<pub-id pub-id-type="pmid">32839303</pub-id></mixed-citation>
    </ref>
    <ref id="btab634-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hinton</surname><given-names>G.E.</given-names></string-name></person-group> (<year>1989</year>) <article-title>Connectionist learning procedures</article-title>. <source>Artif. Intell</source>., <volume>40</volume>, <fpage>185</fpage>â<lpage>234</lpage>.</mixed-citation>
    </ref>
    <ref id="btab634-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jain</surname><given-names>A.K.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>1999</year>) <article-title>Data clustering</article-title>. <source>ACM Comput. Surv</source>., <volume>31</volume>, <fpage>264</fpage>â<lpage>323</lpage>.</mixed-citation>
    </ref>
    <ref id="btab634-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jones</surname><given-names>T.R.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2008</year>) <article-title>CellProfiler analyst: data exploration and analysis software for complex image-based screens</article-title>. <source>BMC Bioinformatics</source>, <volume>9</volume>, <fpage>482</fpage>.<pub-id pub-id-type="pmid">19014601</pub-id></mixed-citation>
    </ref>
    <ref id="btab634-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lucas</surname><given-names>A.M.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2021</year>) <article-title>Open-source deep-learning software for bioimage segmentation</article-title>. <source>Mol. Biol. Cell</source>, <volume>32</volume>, <fpage>823</fpage>â<lpage>829</lpage>.<pub-id pub-id-type="pmid">33872058</pub-id></mixed-citation>
    </ref>
    <ref id="btab634-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McQuin</surname><given-names>C.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2018</year>) <article-title>CellProfiler 3.0: next-generation image processing for biology</article-title>. <source>PLoS Biol</source>., <volume>16</volume>, <fpage>e2005970</fpage>.<pub-id pub-id-type="pmid">29969450</pub-id></mixed-citation>
    </ref>
    <ref id="btab634-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pearson</surname><given-names>K.</given-names></string-name></person-group> (<year>1901</year>) <article-title>LIII. On lines and planes of closest fit to systems of points in space</article-title>. <source>Lond Edinburgh Dublin Philos. Mag. J. Sci</source>., <volume>2</volume>, <fpage>559</fpage>â<lpage>572</lpage>.</mixed-citation>
    </ref>
    <ref id="btab634-B4">
      <mixed-citation publication-type="book">Pedregosa, F. <italic toggle="yes">et al</italic>. (<year>2011</year>). <source>Scikit-learn: machine learning in Python</source>. <italic toggle="yes">JMLR</italic>, 12, 2825â2830. </mixed-citation>
    </ref>
    <ref id="btab634-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Piccinini</surname><given-names>F.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) <article-title>Advanced cell classifier: user-friendly machine-learning-based software for discovering phenotypes in high-content imaging data</article-title>. <source>Cell Syst</source>., <volume>4</volume>, <fpage>651</fpage>â<lpage>655.e5</lpage>.<pub-id pub-id-type="pmid">28647475</pub-id></mixed-citation>
    </ref>
    <ref id="btab634-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schneider</surname><given-names>C.A.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2012</year>) <article-title>NIH image to ImageJ: 25 years of image analysis</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>671</fpage>â<lpage>675</lpage>.<pub-id pub-id-type="pmid">22930834</pub-id></mixed-citation>
    </ref>
    <ref id="btab634-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Silvester</surname><given-names>S.</given-names></string-name></person-group> Â <etal>et al</etal> Â <year>2020</year>. Imageio/imageio, July. doi:10.5281/zenodo.4972048.</mixed-citation>
    </ref>
    <ref id="btab634-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van der Maaten</surname><given-names>L.</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>G.</given-names></string-name></person-group> (<year>2008</year>) <article-title>Visualizing data using T-SNE</article-title>. <source>J. Mach. Learn. Res</source>., <volume>9</volume>, <fpage>2579</fpage>â<lpage>2605</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
