<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//IEEE//DTD IEEE Journals JATS-based DTD v1.7//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journals.dtd?>
<?SourceDTD.Version 1-7?>
<?ConverterInfo.XSLTName ieeejats2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">IEEE J Biomed Health Inform</journal-id>
    <journal-id journal-id-type="iso-abbrev">IEEE J Biomed Health Inform</journal-id>
    <journal-id journal-id-type="publisher-id">0047701</journal-id>
    <journal-id journal-id-type="publisher-id">JBHI</journal-id>
    <journal-id journal-id-type="coden">IJBHA9</journal-id>
    <journal-title-group>
      <journal-title>Ieee Journal of Biomedical and Health Informatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">2168-2194</issn>
    <issn pub-type="epub">2168-2208</issn>
    <publisher>
      <publisher-name>IEEE</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8127616</article-id>
    <article-id pub-id-type="pmid">33119516</article-id>
    <article-id pub-id-type="doi">10.1109/JBHI.2020.3034863</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Clustering-Based Dual Deep Learning Architecture for Detecting Red Blood Cells in Malaria Diagnostic Smears</article-title>
    </title-group>
    <contrib-group>
      <contrib id="contrib1" contrib-type="author" corresp="yes">
        <?contrib-id orcid|0000-0001-5339-8081?>
        <name-alternatives>
          <name content-type="display">
            <surname>Kassim</surname>
            <given-names>Yasmin M.</given-names>
          </name>
          <name content-type="index">
            <surname>Kassim</surname>
            <given-names>Yasmin M.</given-names>
          </name>
        </name-alternatives>
        <xref ref-type="aff" rid="aff1">1</xref>
        <email>yasmin.kassim@nih.gov</email>
      </contrib>
      <contrib id="contrib2" contrib-type="author">
        <?contrib-id orcid|0000-0003-2663-1380?>
        <name-alternatives>
          <name content-type="display">
            <surname>Palaniappan</surname>
            <given-names>Kannappan</given-names>
          </name>
          <name content-type="index">
            <surname>Palaniappan</surname>
            <given-names>Kannappan</given-names>
          </name>
        </name-alternatives>
        <xref ref-type="aff" rid="aff2">2</xref>
        <email>palaniappank@missouri.edu</email>
      </contrib>
      <contrib id="contrib3" contrib-type="author">
        <?contrib-id orcid|0000-0002-8334-7450?>
        <name-alternatives>
          <name content-type="display">
            <surname>Yang</surname>
            <given-names>Feng</given-names>
          </name>
          <name content-type="index">
            <surname>Yang</surname>
            <given-names>Feng</given-names>
          </name>
        </name-alternatives>
        <xref ref-type="aff" rid="aff1">1</xref>
        <email>feng.yang2@nih.gov</email>
      </contrib>
      <contrib id="contrib4" contrib-type="author">
        <name-alternatives>
          <name content-type="display">
            <surname>Poostchi</surname>
            <given-names>Mahdieh</given-names>
          </name>
          <name content-type="index">
            <surname>Poostchi</surname>
            <given-names>Mahdieh</given-names>
          </name>
        </name-alternatives>
        <xref ref-type="aff" rid="aff1">1</xref>
        <email>mahdieh.p82@gmail.com</email>
      </contrib>
      <contrib id="contrib5" contrib-type="author">
        <name-alternatives>
          <name content-type="display">
            <surname>Palaniappan</surname>
            <given-names>Nila</given-names>
          </name>
          <name content-type="index">
            <surname>Palaniappan</surname>
            <given-names>Nila</given-names>
          </name>
        </name-alternatives>
        <xref ref-type="aff" rid="aff3">3</xref>
        <email>nila.palaniappan@gmail.com</email>
      </contrib>
      <contrib id="contrib6" contrib-type="author">
        <?contrib-id orcid|0000-0002-5355-0562?>
        <name-alternatives>
          <name content-type="display">
            <surname>Maude</surname>
            <given-names>Richard J</given-names>
          </name>
          <name content-type="index">
            <surname>Maude</surname>
            <given-names>Richard J</given-names>
          </name>
        </name-alternatives>
        <xref ref-type="aff" rid="aff4">4</xref>
        <xref ref-type="aff" rid="aff5">5</xref>
        <xref ref-type="aff" rid="aff6">6</xref>
        <email>richard@tropmedres.ac</email>
      </contrib>
      <contrib id="contrib7" contrib-type="author">
        <?contrib-id orcid|0000-0002-0040-1387?>
        <name-alternatives>
          <name content-type="display">
            <surname>Antani</surname>
            <given-names>Sameer</given-names>
          </name>
          <name content-type="index">
            <surname>Antani</surname>
            <given-names>Sameer</given-names>
          </name>
        </name-alternatives>
        <xref ref-type="aff" rid="aff1">1</xref>
        <email>santani@mail.nih.gov</email>
      </contrib>
      <contrib id="contrib8" contrib-type="author">
        <?contrib-id orcid|0000-0001-6877-4318?>
        <name-alternatives>
          <name content-type="display">
            <surname>Jaeger</surname>
            <given-names>Stefan</given-names>
          </name>
          <name content-type="index">
            <surname>Jaeger</surname>
            <given-names>Stefan</given-names>
          </name>
        </name-alternatives>
        <xref ref-type="aff" rid="aff1">1</xref>
        <email>stefan.jaeger@nih.gov</email>
      </contrib>
      <author-comment>
        <p>
          <italic>(Corresponding author: Yasmin M. Kassim; Stefan Jaeger.)</italic>
        </p>
      </author-comment>
    </contrib-group>
    <aff id="aff1">
      <label>1</label>
      <institution-wrap>
        <institution content-type="division">Lister Hill National Center for Biomedical Communications</institution>
        <institution content-type="institution">National Library of Medicine</institution>
        <institution-id content-type="institution" institution-id-type="ringgold">10952</institution-id>
      </institution-wrap>
      <city>Bethesda</city>
      <state>MD</state>
      <postal-code>20894</postal-code>
      <country>USA</country>
    </aff>
    <aff id="aff2">
      <label>2</label>
      <institution-wrap>
        <institution content-type="division">EECS Department</institution>
        <institution content-type="institution">University of Missouri-Columbia</institution>
        <institution-id content-type="institution" institution-id-type="ringgold">14716</institution-id>
      </institution-wrap>
      <city>Columbia</city>
      <state>MO</state>
      <postal-code>65211</postal-code>
      <country>USA</country>
    </aff>
    <aff id="aff3">
      <label>3</label>
      <institution-wrap>
        <institution content-type="division">School of Medicine</institution>
        <institution content-type="institution">University of Missouri-Kansas City</institution>
        <institution-id content-type="institution" institution-id-type="ringgold">12273</institution-id>
      </institution-wrap>
      <city>Kansas City</city>
      <state>MO</state>
      <postal-code>64110</postal-code>
      <country>USA</country>
    </aff>
    <aff id="aff4">
      <label>4</label>
      <institution-wrap>
        <institution content-type="division">Mahidol-Oxford Tropical Medicine Research Unit</institution>
        <institution content-type="institution">Mahidol University</institution>
        <institution-id content-type="institution" institution-id-type="ringgold">26687</institution-id>
      </institution-wrap>
      <city>Bangkok</city>
      <postal-code>10400</postal-code>
      <country>Thailand</country>
    </aff>
    <aff id="aff5">
      <label>5</label>
      <institution-wrap>
        <institution content-type="division">Centre for Tropical Medicine and Global Health, Nuffield Department of Medicine</institution>
        <institution content-type="institution">University of Oxford</institution>
        <institution-id content-type="institution" institution-id-type="ringgold">6396</institution-id>
      </institution-wrap>
      <city>Oxford</city>
      <postal-code>OX3 7LG</postal-code>
      <country>U.K.</country>
    </aff>
    <aff id="aff6">
      <label>6</label>
      <institution-wrap>
        <institution content-type="division">Harvard TH Chan School of Public Health</institution>
        <institution content-type="institution">Harvard University</institution>
        <institution-id content-type="institution" institution-id-type="ringgold">1857</institution-id>
      </institution-wrap>
      <city>Boston</city>
      <state>MA</state>
      <postal-code>02115</postal-code>
      <country>USA</country>
    </aff>
    <pub-date pub-type="collection" iso-8601-date="2021-05">
      <month>5</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-10-29">
      <day>29</day>
      <month>10</month>
      <year>2020</year>
    </pub-date>
    <volume>25</volume>
    <issue>5</issue>
    <fpage>1735</fpage>
    <lpage>1746</lpage>
    <history>
      <date date-type="received" iso-8601-date="2020-02-16">
        <day>16</day>
        <month>2</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd" iso-8601-date="2020-09-09">
        <day>09</day>
        <month>9</month>
        <year>2020</year>
      </date>
      <date date-type="accepted" iso-8601-date="2020-09-30">
        <day>30</day>
        <month>9</month>
        <year>2020</year>
      </date>
      <date date-type="currentversion" iso-8601-date="2021-05-11">
        <day>11</day>
        <month>5</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-year>2020</copyright-year>
      <copyright-holder content-type="Author"/>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link></license-p>
      </license>
    </permissions>
    <self-uri content-type="xml" xlink:type="simple">jbhi-kassim-3034863.xml</self-uri>
    <self-uri content-type="print" xlink:type="simple">jbhi-kassim-3034863.pdf</self-uri>
    <self-uri content-type="online" xlink:type="simple">jbhi-kassim-3034863.pdf</self-uri>
    <self-uri content-type="NIH-pdf" xlink:type="simple">jbhi-aam-3034863.pdf</self-uri>
    <self-uri content-type="WELLCOMETRUST-pdf" xlink:type="simple">jbhi-aam-3034863.pdf</self-uri>
    <abstract>
      <p>Computer-assisted algorithms have become a mainstay of biomedical applications to improve accuracy and reproducibility of repetitive tasks like manual segmentation and annotation. We propose a novel pipeline for red blood cell detection and counting in thin blood smear microscopy images, named RBCNet, using a dual deep learning architecture. RBCNet consists of a U-Net first stage for <italic>cell-cluster</italic> or superpixel segmentation, followed by a second refinement stage Faster R-CNN for detecting small cell objects within the connected component clusters. RBCNet uses cell clustering instead of region proposals, which is robust to cell fragmentation, is highly scalable for detecting small objects or fine scale morphological structures in very large images, can be trained using non-overlapping tiles, and during inference is adaptive to the scale of cell-clusters with a low memory footprint. We tested our method on an archived collection of human malaria smears with nearly 200,000 labeled cells across 965 images from 193 patients, acquired in Bangladesh, with each patient contributing five images. Cell detection accuracy using RBCNet was higher than 97<inline-formula><tex-math id="M1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\%$\end{document}</tex-math></inline-formula>. The novel dual cascade RBCNet architecture provides more accurate cell detections because the foreground cell-cluster masks from U-Net adaptively guide the detection stage, resulting in a notably higher true positive and lower false alarm rates, compared to traditional and other deep learning methods. The RBCNet pipeline implements a crucial step towards automated malaria diagnosis.</p>
    </abstract>
    <kwd-group kwd-group-type="AuthorFree">
      <kwd>Red blood cells (RBCs)</kwd>
      <kwd>white blood cells (WBCs)</kwd>
      <kwd>deep learning</kwd>
      <kwd>faster R-CNN</kwd>
      <kwd>connected components</kwd>
      <kwd>semantic segmentation</kwd>
      <kwd>superpixel</kwd>
      <kwd>U-Net</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution content-type="institution">Intramural Research Program</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution content-type="institution">Mahidol-Oxford Tropical Medicine Research Unit</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution content-type="institution">Wellcome Trust of Great Britain</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="fundref">10.13039/100000065</institution-id>
            <institution content-type="institution">National Institute of Neurological Disorders and Stroke</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01NS110915</award-id>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution content-type="institution">U.S. Army Research Laboratory</institution>
          </institution-wrap>
        </funding-source>
        <award-id>W911NF-1820285</award-id>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution content-type="institution">NSF</institution>
          </institution-wrap>
        </funding-source>
        <award-id>1950873</award-id>
      </award-group>
      <funding-statement>This research was supported by the Intramural Research Program of NIH, NLM, and Lister Hill National Center for Biomedical Communications. Mahidol-Oxford Tropical Medicine Research Unit is funded by the Wellcome Trust of Great Britain. This work was supported in part by awards from the U.S. NIH National Institute of Neurological Disorders and Stroke R01NS110915 (KP), in part by the U.S. Army Research Laboratory project W911NF-1820285 (KP), and in part by NSF 1950873 (KP).</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="9"/>
      <table-count count="4"/>
      <ref-count count="54"/>
      <page-count count="12"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <label>I.</label>
    <title>Introduction</title>
    <p>Malaria is a leading cause of death worldwide <xref rid="ref1" ref-type="bibr">[1]</xref>. The parasitic infectious disease can be transmitted easily to human through mosquito bites that result in over 200 million infections and 400 thousand deaths every year, with children under five accounting for the majority of all malaria deaths worldwide. Although the highest risk region is sub-Saharan Africa, half the world's population is at risk. The disease begins with common cold symptoms such as fever, headache, and chills; which if not treated, may lead to severe complications such as kidney failure, anemia, pulmonary edema, abnormal liver function, cerebral malaria, neuro-disability, seizures, and ultimately death.</p>
    <p>Millions of blood smears are examined for malaria parasites by microscopists every year to determine whether a person is infected or not <xref rid="ref1" ref-type="bibr">[1]</xref>, <xref rid="ref2" ref-type="bibr">[2]</xref>. This procedure requires several steps, beginning with collecting blood smears, staining them and examining the slides to identify different cells and observe infected ones. Manual counting and detection is tedious, costly, slow, and depends on the skills and expertise of the microscopist. Automated algorithms based on machine learning and image processing have the potential to provide fast, cheap, and reliable malaria diagnosis, avoiding erroneous detections that usually occur with manual examination. Recently, convolutional neural networks have become very popular for solving problems in machine learning and computer vision <xref rid="ref3" ref-type="bibr">[3]</xref>–<xref rid="ref4" ref-type="bibr"/><xref rid="ref5" ref-type="bibr">[5]</xref> as the model learns and computes distinctive features from the data without any human intervention. However, these so-called deep learning techniques (DL) need a large amount of annotated data and processing power to learn the weights to produce a predictive model. In the medical field, obtaining labeled data is a bottleneck because it requires expert knowledge. Specifically, for malaria screening and diagnosis, developing accurate automatic blood cell detection is particularly challenging. Different blood smear images can vary in staining, resolution, illumination, cell shape, appearance, color, contrast and debris. Furthermore, cells can clump together, making identification of individual cells harder, and staining artifacts can confuse fragile image analysis methods. Nevertheless, several algorithms and techniques <xref rid="ref6" ref-type="bibr">[6]</xref> have been developed with the goal to replace manual diagnosis, decrease cost, and speed up diagnosis.</p>
    <sec id="sec1a">
      <label>A.</label>
      <title>Related Work</title>
      <p>Most malaria screening and diagnosis algorithms <xref rid="ref6" ref-type="bibr">[6]</xref> begin with finding the foreground masks using simple thresholding methods such as Otsu's method <xref rid="ref7" ref-type="bibr">[7]</xref>–<xref rid="ref8" ref-type="bibr"/><xref rid="ref9" ref-type="bibr"/><xref rid="ref10" ref-type="bibr">[10]</xref>, k-means <xref rid="ref11" ref-type="bibr">[11]</xref>, <xref rid="ref12" ref-type="bibr">[12]</xref>, adaptive histogram thresholding <xref rid="ref13" ref-type="bibr">[13]</xref>–<xref rid="ref14" ref-type="bibr"/><xref rid="ref15" ref-type="bibr">[15]</xref>, or Zack thresholding <xref rid="ref16" ref-type="bibr">[16]</xref>, followed by different techniques to separate touching cells, which is arguably the main challenge in cell detection. Among those methods are distance transform, watershed, morphological operations, and active contours. Watershed <xref rid="ref17" ref-type="bibr">[17]</xref> and Active contours <xref rid="ref18" ref-type="bibr">[18]</xref>, <xref rid="ref19" ref-type="bibr">[19]</xref> are considered superior traditional techniques for cell detection. Although CNNs are now very popular and robust in solving various biomedical problems <xref rid="ref20" ref-type="bibr">[20]</xref>–<xref rid="ref21" ref-type="bibr"/><xref rid="ref22" ref-type="bibr"/><xref rid="ref23" ref-type="bibr"/><xref rid="ref24" ref-type="bibr"/><xref rid="ref25" ref-type="bibr">[25]</xref>, there has not been as much work reported for red blood cell (RBC) detection. Most of the existing methods are for classification between different types of cell images <xref rid="ref26" ref-type="bibr">[26]</xref>–<xref rid="ref27" ref-type="bibr"/><xref rid="ref28" ref-type="bibr">[28]</xref> or between infected and uninfected cells, while the core step for detecting and counting cells still depends upon traditional methods. In Liang <italic>et al.</italic>
<xref rid="ref29" ref-type="bibr">[29]</xref>, the classification of infected and uninfected cells relies on a convolutional neural network; however, Active contour <xref rid="ref18" ref-type="bibr">[18]</xref>, <xref rid="ref19" ref-type="bibr">[19]</xref> is used to segment the cells. In Dong <italic>et al.</italic>
<xref rid="ref30" ref-type="bibr">[30]</xref>, the authors studied automatic identification of malaria infected cells using deep learning methods, but they segmented images using thresholding techniques and morphological operations, while their cell separation depends upon Hough Circle transform. In Bibin <italic>et al.</italic>
<xref rid="ref31" ref-type="bibr">[31]</xref>, the authors propose a deep belief network (DBN) to differentiate between infected and uninfected cells, using a level set method to segment stained objects <xref rid="ref32" ref-type="bibr">[32]</xref>. In Gopakumar <italic>et al.</italic>
<xref rid="ref33" ref-type="bibr">[33]</xref>, the authors present an automated CNN-based framework to classify a region around the candidate locations as either infected or healthy. Those candidate locations are found by thresholding operations, specifically by looking only at regional intensity minima since stained parasite regions usually appear darker than other pixels. In Rajaraman <italic>et al.</italic>
<xref rid="ref34" ref-type="bibr">[34]</xref>, the authors use a level-set based algorithm to detect and segment the RBCs, and then use several pre-trained Convolutional Neural Networks (CNN) to classify parasitized and uninfected cells. In Loganathan <italic>et al.</italic>
<xref rid="ref35" ref-type="bibr">[35]</xref>, the authors use the entropy estimation method to detect RBCs, then separate the touching cells using distance transform and random walk algorithm, followed by diseased RBCs classification by a deep CNN architecture. In Molina-Cabello <italic>et al.</italic>
<xref rid="ref36" ref-type="bibr">[36]</xref>, the authors use Hough Circle transform for cell detection and artificial neural networks for classification as either RBC or not RBC.</p>
      <p>There are a few recent papers in the literature that use CNN for RBC detection. In Faliu <italic>et al.</italic>
<xref rid="ref37" ref-type="bibr">[37]</xref>, the authors present two models to extract RBCs from holographic images based on convolutional neural networks. However, in the inference stage, the trained model was used to predict each pixel in the image which is computationally expensive and time consuming for large image sizes. In addition, for their best model, they also use internal markers from watershed algorithm to separate the cells. In Yang <italic>et al.</italic>
<xref rid="ref38" ref-type="bibr">[38]</xref>, the authors detect and classify cells using Faster R-CNN <xref rid="ref39" ref-type="bibr">[39]</xref>. They use microscopic images with size equal to <inline-formula><tex-math id="M2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$659\times 493$\end{document}</tex-math></inline-formula> which is considered the ideal size as input for Faster R-CNN network. However, their images have a small number of cells, while in our paper, the image size is <inline-formula><tex-math id="M3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$5312\times 2988$\end{document}</tex-math></inline-formula> with dense cells. In Hung. <italic>et al.</italic>
<xref rid="ref40" ref-type="bibr">[40]</xref>, the authors use Faster R-CNN for detecting the cells; nevertheless, it lacks important details. The authors mention that the network is trained by cropping tiles with size <inline-formula><tex-math id="M4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$448\times 448$\end{document}</tex-math></inline-formula>, but it is not clear how they test their trained model and whether they get the prediction on the full images or tiles. The authors trained their network using only four patients and tested only on one patient. Compared to their work, in our present paper, we train with 33 patients and test with 193 patients. This manuscript is an extended version of a brief abstract which has preliminary results for few experiments published in <xref rid="ref41" ref-type="bibr">[41]</xref>.</p>
    </sec>
    <sec id="sec1b">
      <label>B.</label>
      <title>Contribution and Novelty</title>
      <p>In our study, we present RBCNet, a novel algorithm based on a dual deep-network architecture to segment cells: U-Net  <xref rid="ref42" ref-type="bibr">[42]</xref> first separates touching cells and cell clusters in the produced binary mask, followed by Faster R-CNN <xref rid="ref39" ref-type="bibr">[39]</xref> performing the final cell detection. The novelty behind combining these two well known deep learning networks is in detecting highly overlapped RBCs in large blood smear images. In particular, our approach is scalable to large blood smear images (<inline-formula><tex-math id="M5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$5312\times 2988$\end{document}</tex-math></inline-formula> pixels) featuring high cell densities, where cells are relatively small objects compared to the overall image size. We train our dual deep-network architecture with image tiles to ensure fast training with a reasonable number of cells in each tile and relatively large tile size to cell size ratio, while presenting connected components to the network instead of regular tiles in the testing stage avoids cutting off cells. Detecting small objects in large images is an ongoing area of research and our study could be a robust solution that eliminates the limitations of the regular strategy which is problematic for cells residing on tile boundaries that usually affect the overall accuracy, as discussed in detail in <xref ref-type="sec" rid="sec3">Section III</xref>. Additionally, we compare our work with 11 methods (traditional and deep learning) with several combinations and testing strategies. We have made the RBCNet code available here: <uri xlink:type="simple" xlink:href="https://github.com/nlm-malaria/RBCNet">https://github.com/nlm-malaria/RBCNet</uri></p>
    </sec>
    <sec id="sec1c">
      <label>C.</label>
      <title>Motivation, Challenges, and Proposed Pipeline</title>
      <p>There are several challenges that motivated us to build our dual pipeline: Our image size is large <inline-formula><tex-math id="M6">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$5312\times 2988$\end{document}</tex-math></inline-formula> compared to the relatively small cell size; further, microscopy smears vary in cell shape, density, illumination, and color. Applying Faster R-CNN or any other object detection network directly to an entire image is computationally expensive, especially with recent object detection networks that have multiple training stages as Faster R-CNN. Object detection networks are usually applied to images for which the shortest side is around 600 pixels, whereas the shortest side in our images is 2988.</p>
      <p>We have developed a novel dual deep architecture based cell segmentation pipeline for segmenting a dense set of RBCs in large thin smear microscopy images as part of an end-to-end fieldable system for rapid fully automated malaria diagnosis <xref rid="ref43" ref-type="bibr">[43]</xref>. The RBCNet pipeline shown in <xref ref-type="fig" rid="fig1">Fig. 1</xref> consists of two stages including a U-Net architecture with connected component labeling for detecting and extracting cell cluster foreground masks. The second stage uses a Faster R-CNN architecture for refining the cell clusters into individual cells with accurate boundaries. The two stage cascade architecture is individually trained using malaria thin smear microscopy imagery as described in <xref ref-type="sec" rid="sec2">Section II</xref>. The key idea is that U-Net architecture guides the detection process in the inference stage by providing robust candidates (clusters of cells) as input to a Faster R-CNN network rather than the standard way of tiling the image. Our pipeline is a robust solution to various challenges imposed by large size images with dense objects.</p>
      <fig id="fig1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>Visualization of our RBCNet pipeline with two stages: training and testing. In the training stage, U-Net and Faster R-CNN are used to train on raw image tiles, while in the inference stage, we apply a Faster R-CNN trained network to cell cluster raw image regions corresponding to the connected components produced by U-Net.</p>
        </caption>
        <graphic xlink:href="kassi1-3034863"/>
      </fig>
    </sec>
  </sec>
  <sec id="sec2">
    <label>II.</label>
    <title>Malaria Data Set and Methodology</title>
    <p><bold>Dataset:</bold> We tested our proposed pipeline for RBC cell detection with archived thin blood smear images from human patients acquired from Chittagong Medical College Hospital in Bangladesh. Giemsa-stained thin-blood smear slides were collected from <italic>Plasmodium falciparum</italic> infected patients and healthy controls and photographed using a smartphone camera. The slide images were manually annotated by an expert, de-identified, and archived. The Institutional Review Board (IRB) at the National Library of Medicine (NLM), National Institutes of Health (NIH) granted approval to carry out the study within its facilities (IRB<inline-formula><tex-math id="M7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\#$\end{document}</tex-math></inline-formula>12972). We publish the data here: <uri xlink:type="simple" xlink:href="ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/NIH-NLM-ThinBloodSmearsPf/">ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/NIH-NLM-ThinBloodSmearsPf/</uri></p>
    <p>All images have three color channels with image dimensions of <inline-formula><tex-math id="M8">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$5312 \times 2988$\end{document}</tex-math></inline-formula> pixels. Because images are captured through the eyepiece of the microscope, the visual region is circular. We divided the data set into two parts: a polygon set and a point set. The difference between these two sets lies in the annotation method. In the polygon set, all red blood cells and white blood cells (WBC) have been outlined manually with polygons using the Firefly annotation tool <xref rid="ref44" ref-type="bibr">[44]</xref>,<xref ref-type="fn" rid="fn1"><sup>1</sup></xref><fn id="fn1"><label><sup>1</sup></label><p><uri xlink:type="simple" xlink:href="http://www.firefly.cs.missouri.edu">http://www.firefly.cs.missouri.edu</uri>.</p></fn> whereas in the point set, cells have been marked by placing a point on each cell, as illustrated in <xref ref-type="fig" rid="fig2">Figure 2</xref>. We use the polygon set for training and the point set for evaluation. The polygon set consists of 165 blood smear images from 33 patients, with each patient contributing five slides. The point set consists of 800 images from 160 patients. The total number of RBCs is 34,213 and 162,450 in the polygon and point set, respectively.</p>
    <fig id="fig2" orientation="portrait" position="float">
      <label>Fig. 2.</label>
      <caption>
        <p>Our Bangladesh data set is divided into two sets according to annotation scheme: (a) Polygon set, cell outlines annotated by polygons for network training, contains 165 images from 33 patients, each patient contributes with 5 images, total number of RBCs is 34,213. (b) Point set, annotated by placing a dot on each cell, used for network evaluation, contains 800 images from 160 patients, each patient contributes with 5 images, total number of RBCs is 162,450.</p>
      </caption>
      <graphic xlink:href="kassi2-3034863"/>
    </fig>
    <p><bold>RBCNet architecture and training step:</bold> RBCNet consists of U-Net <xref rid="ref42" ref-type="bibr">[42]</xref> and Faster R-CNN <xref rid="ref39" ref-type="bibr">[39]</xref>. U-Net <xref rid="ref42" ref-type="bibr">[42]</xref> is one type of semantic segmentation networks which means pixel-wise labeling so that each pixel in the image has a unique class or category. Most existing networks classify objects such as cars, people, airplanes, etc. However, U-Net is designed for biomedical segmentation <xref rid="ref45" ref-type="bibr">[45]</xref>. U-Net consists of two paths forming a U-shape: a contraction and an expansion path. The contraction path consists of four blocks, where each block has two convolutions, two ReLUs, and one max pooling layer. The expansion path has also four blocks; however, upsampling is used rather than downsampling, and concatenation followed by regular convolution operations. The contraction path enables the network to learn context, whereas the expansion path preserves the spatial information. This design is very important for our work. It allows retrieving high resolution feature maps and preserving image details such as cell boundaries.</p>
    <p>In Faster R-CNN <xref rid="ref39" ref-type="bibr">[39]</xref>, a convolutional neural network like VGG-16 is typically used as the feature extraction backbone. VGG-16 is 16 layers deep and has been optimized to classify images with 1000 classes for the ImageNet competition (ILSVR 2014). However, in our case, we have just a two class task to identify RBC versus background; additionally our cells are small and have a relatively homogeneous appearance and texture. So instead of using a deep backbone like VGG-16 or ResNet-50 for Faster R-CNN, we designed a <italic>customized</italic> CNN backbone with fewer layers for cell feature extraction consisting of nine layers: one input layer, two convolutional plus ReLU layers, followed by one pooling layer, then two fully connected layers, a softmax layer and a final classification layer. For training RBCNet, we use labeled fixed size tiles for both U-Net and the customized Faster R-CNN, <inline-formula><tex-math id="M9">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$256 \times 256$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$128 \times 228$\end{document}</tex-math></inline-formula> respectively, for fast training and obtained a robust learned RBCNet model. The details of our cross validation experiments are in <xref ref-type="sec" rid="sec2a">Section II-A</xref>.</p>
    <p><bold>Inference Step:</bold> Using the trained models of U-Net and Faster R-CNN, we proposed RBCNet, a robust pipeline for cell segmentation shown in <xref ref-type="fig" rid="fig3">Fig. 3</xref>. The flowchart begins with reading the input image and ends with detecting all RBCs. The shaded box describes Step 6 which combines the information from U-Net with Faster R-CNN inferencing. Step 6 loops over each extracted connected component (image object mask region) and applies the trained deep architecture of Faster R-CNN to localize each cell using a detection bounding box. See <xref ref-type="fig" rid="fig6">Figure 6</xref> for some examples.</p>
    <fig id="fig3" orientation="portrait" position="float">
      <label>Fig. 3.</label>
      <caption>
        <p>RBCNet inference flowchart starts with reading an input image, applying U-Net and Faster R-CNN, and ends with saving all detected cell bounding boxes.</p>
      </caption>
      <graphic xlink:href="kassi3-3034863"/>
    </fig>
    <fig id="fig4" orientation="portrait" position="float">
      <label>Fig. 4.</label>
      <caption>
        <p>Examples of our RBCNet cell detection results showing RBCs and WBCs in different colors, shapes, and illumination conditions (cropped ROIs at original resolution). Our proposed RBCNet pipeline successfully detects RBCs and filters out WBCs in all these cases.</p>
      </caption>
      <graphic xlink:href="kassi4-3034863"/>
    </fig>
    <fig id="fig5" orientation="portrait" position="float">
      <label>Fig. 5.</label>
      <caption>
        <p>Evaluating detection accuracy for counting RBCs using one-to-one matching assessment with the confusion matrix shown in the upper right. Upper left figure shows examples of TP, FP, and FN. For point correspondences we do not use specificity or TN rate as most of the image pixels are TN. In the bottom row the yellow bounding boxes are RBCNet algorithm detections and the green points are the expert's manual ground-truth point annotations.</p>
      </caption>
      <graphic xlink:href="kassi5-3034863"/>
    </fig>
    <fig id="fig6" orientation="portrait" position="float">
      <label>Fig. 6.</label>
      <caption>
        <p>Three examples of cell clumps of different sizes for which our dual deep network architecture pipeline <bold>RBCNet</bold> successfully identifies individual cells. The examples show the connected components generated from the U-Net foreground mask and the bounding boxes of individual cells detected by our Faster R-CNN model. The first column shows the field of view for the raw image, the second column shows the binary mask produced by U-Net, and the third column shows the connected component labeling for U-Net's binary mask. In the fourth column are zoomed-in examples of connected components for which Faster R-CNN detects all cells. Green dots represent the gold standard ground- truth (GT) annotation. The last column visualizes all bounding boxes for all cell clumps superimposed on the raw image. Combination of U-Net training using tiles along with connected component labeling for the output mask enables cells and cell clusters (i.e. touching or overlapping cells) to be accurately detected and segmented across tile boundaries. The cell clusters identified by U-Net typically have smooth borders and very little fragmentation.</p>
      </caption>
      <graphic xlink:href="kassi6-3034863"/>
    </fig>
    <p><bold>Post-Processing Step:</bold> Our algorithm filters out any bounding box satisfying Eq. <xref ref-type="disp-formula" rid="deqn1">1</xref> as a leukocyte or white blood cell (WBC) and saves all remaining bounding boxes for evaluation.
<disp-formula id="deqn1"><tex-math id="M11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}
\begin{equation*}
\sum _{c=0}^{n} f(\mu -\epsilon -I_c) &gt; T \tag{1}
\end{equation*}
\end{document}</tex-math></disp-formula>
where
<disp-formula><tex-math id="M12">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}
\begin{equation*}
f(x) = \left\lbrace \begin{array}{lll}0 &amp;\text{ if } x \leq 0 &amp;\text{RBC pixel} \\
1 &amp;\text{ otherwise},&amp; \text{WBC pixel} \end{array} \right.
\end{equation*}
\end{document}</tex-math></disp-formula>
and <inline-formula><tex-math id="M13">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$n$\end{document}</tex-math></inline-formula> is the number of foreground pixels within each detection, <inline-formula><tex-math id="M14">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$I_c$\end{document}</tex-math></inline-formula> is the intensity value for each pixel, <inline-formula><tex-math id="M15">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$T$\end{document}</tex-math></inline-formula> is a predefined threshold, and <inline-formula><tex-math id="M16">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\epsilon$\end{document}</tex-math></inline-formula> is a heuristic estimate on how much darker a WBC is, on average, compared to the mean intensity <inline-formula><tex-math id="M17">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\mu$\end{document}</tex-math></inline-formula>. WBCs are up to three times larger than RBCs and are usually darker than RBCs. We found that thresholding on the number of dark pixels typically associated with WBC detections using Eq. <xref ref-type="disp-formula" rid="deqn1">1</xref> is a good solution. According to Eq. <xref ref-type="disp-formula" rid="deqn1">1</xref>, we detect and filter out any bounding box as a WBC object if it contains more than <inline-formula><tex-math id="M18">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$T$\end{document}</tex-math></inline-formula> pixels of sufficient darkness. See <xref ref-type="fig" rid="fig4">Fig. 4</xref> for some examples of patches that have both RBCs and WBCs, and where our algorithm filters out all WBCs successfully.</p>
    <sec id="sec2a">
      <label>A.</label>
      <title>Cross Validation</title>
      <p>In our work, we evaluate both the polygon set and the point set. To evaluate our RBCNet on our polygon set (33 patients), we apply 11-fold cross validation on patient level. In each fold, we use the imagery of 30 patients (150 images) for training and exclude three patients (15 images) for testing. To evaluate the point set (160 patients), we train all the images in the polygon set. <xref ref-type="table" rid="table1">Table I</xref> illustrates the data statistics of our experiments. All experiments ran for 20 epochs on an Nvidia GeForce GTX 1080Ti GPU. For U-Net and Faster R-CNN, we use implementations provided by the Neural network toolbox in MATLAB <xref rid="ref46" ref-type="bibr">[46]</xref>.</p>
      <table-wrap id="table1" orientation="portrait" position="float">
        <label>TABLE I</label>
        <caption>
          <title>Experimental Setup for Training our Dual Deep Learning Architecture</title>
        </caption>
        <alternatives>
          <graphic xlink:href="kassi.t1-3034863"/>
          <table frame="box" rules="all" cellpadding="5">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th colspan="1" rowspan="1">Data Set</th>
                <th colspan="1" rowspan="1"># of Patients</th>
                <th colspan="1" rowspan="1"># of Images</th>
                <th colspan="1" rowspan="1"># of Cells</th>
                <th colspan="1" rowspan="1">Cross Validation</th>
                <th colspan="1" rowspan="1">Training (#Images/Fold) (#Patients/fold)</th>
                <th colspan="1" rowspan="1">Testing (#Images/Fold) (#Patients/Fold)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td colspan="1" rowspan="1">Polygon Set</td>
                <td colspan="1" rowspan="1">33</td>
                <td colspan="1" rowspan="1">165</td>
                <td colspan="1" rowspan="1">34,226</td>
                <td colspan="1" rowspan="1">11 - Fold</td>
                <td colspan="1" rowspan="1">150 images from 30 patients</td>
                <td colspan="1" rowspan="1">15 images from 3 patients</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Point Set</td>
                <td colspan="1" rowspan="1">160</td>
                <td colspan="1" rowspan="1">800</td>
                <td colspan="1" rowspan="1">162,443</td>
                <td colspan="1" rowspan="1">Train all images in polygon set</td>
                <td colspan="1" rowspan="1">165 images from 33 patients</td>
                <td colspan="1" rowspan="1">800 images from 160 patients</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>During training the Faster R-CNN stage, the input images are rescaled from <inline-formula><tex-math id="M19">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$5312 \times 2988$\end{document}</tex-math></inline-formula> to 0.3 of their original size. Using <inline-formula><tex-math id="M20">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$128 \times 228$\end{document}</tex-math></inline-formula> rectangular tiles, the smaller image size of <inline-formula><tex-math id="M21">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$1594 \times 896$\end{document}</tex-math></inline-formula> results in tiles with a higher density of RBCs (smaller cell sizes) within each tile. Specifically, each tile has about 7 to 15 RBCs and there are about 49 tiles per image. However, we only consider the tiles within the field of view and exclude all of the black background tiles. So, the number of tiles used per image is about 25, which leads to a training set of 3750 tiles (25 tiles/image <inline-formula><tex-math id="M22">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\times 150$\end{document}</tex-math></inline-formula> images) used in each fold. We use a small subset of the training tiles for validation (about 100 tiles) to monitor the accuracy and loss during training, which determines if more epochs or training samples are needed. For evaluating on our point set (160 patients with 800 images), we first train on all the images in our polygon set (165 images from 33 patients) by generating a training set with 4125 tiles (25 tiles/image <inline-formula><tex-math id="M23">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\times 165$\end{document}</tex-math></inline-formula> images).</p>
      <p>Faster R-CNN training happens in four phases: Phase 1 and 2 train the region proposal and detection networks. In the last two phases a single combined network is trained for detection. We use a higher learning rate in Phase 1 and 2, equal to 0.001, then for the last two phases, we decrease the learning rate to 0.0001 because the last two phases are just to fine tune the network weights. The network is trained from scratch. The number of layers and parameters have been selected after extensive trials for several configurations. We train U-Net in a similar fashion (i.e. same cross validation scheme). Our objective is to learn a robust U-Net model for predicting accurate foreground masks because our proposed approach depends on this mask during the inference stage. We generate training data by randomly cropping 100 patches per image, with dimensions of <inline-formula><tex-math id="M24">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$256 \times 256$\end{document}</tex-math></inline-formula>, and by augmenting them through random rotation, reflection, and scaling to increase the number of examples for a more robust training. In this way, we create eight additional patches for each single patch, which increases our training set to <inline-formula><tex-math id="M25">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$120{,}000$\end{document}</tex-math></inline-formula> patches <inline-formula><tex-math id="M26">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$(150 \times 100 \times 8)$\end{document}</tex-math></inline-formula> for training each fold to evaluate the polygon set. Similarly, to evaluate the point set, we augment the training data of the polygon set to create a larger training set consisting of <inline-formula><tex-math id="M27">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$132{,}000$\end{document}</tex-math></inline-formula> patches <inline-formula><tex-math id="M28">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$(165 \times 100 \times 8)$\end{document}</tex-math></inline-formula>. On this larger training data, U-Net needs 20 epochs to converge. We trained the network using stochastic gradient descent with momentum (SGDM) optimization. The bias term of all convolutional layers is initialized to zero and convolution layer weights in the encoder and decoder sub-networks are initialized using the ‘He’ weight initialization method <xref rid="ref47" ref-type="bibr">[47]</xref>. We accelerate the training by setting a high learning rate equal to 0.05; however, to prevent the gradients of the network from exploding, we enable a gradient clipping threshold equal to 0.05, and clip the gradients if their L2-norm exceeds the given threshold.</p>
    </sec>
    <sec id="sec2b">
      <label>B.</label>
      <title>Performance Metrics</title>
      <p>We evaluate the red blood cell detection algorithms based on a one-to-one matching between point annotations in our ground-truth, which represent individual cells identified by an expert microscopist, and the detected cells. To evaluate our cell detection quantitatively, we apply the following evaluation scheme, which is also visualized in <xref ref-type="fig" rid="fig5">Fig. 5</xref>:
<list list-type="simple"><list-item><label>1)</label><p>If a detected bounding box contains just one point in the labeled data, consider it a true positive (TP).</p></list-item><list-item><label>2)</label><p>If the bounding box contains more than one point, consider the one which is closest to the center of the bounding box as a TP. Remaining points are either TP if there are other bounding boxes containing each of them, otherwise are missed detections so false negatives (FN).</p></list-item><list-item><label>3)</label><p>If any point is not contained in a box, label it as a false negative (FN).</p></list-item><list-item><label>4)</label><p>If a bounding box does not contain any point, then label this detection as a false positive (FP).</p></list-item></list> Our evaluation considers the standard performance metrics Recall, Precision, and F1-measure for evaluating our RBCNet cell detection results and comparing them to the expert gold standard. Recall is a statistical measure used to quantify how well an algorithm detects objects, or cells in our case. While Precision assesses how robust it is in avoiding false detections,
<disp-formula><tex-math id="M29">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}
\begin{equation*}
Recall= \frac{TP}{TP+FN},\quad Precision= \frac{TP}{TP+FP}.
\end{equation*}
\end{document}</tex-math></disp-formula>
The F1 measure combines Precision and Recall, using the harmonic mean between the two,
<disp-formula><tex-math id="M30">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}
\begin{equation*}
F1\text {-}measure = 2\cdot \frac{Recall \cdot Precision}{Recall+Precision}.
\end{equation*}
\end{document}</tex-math></disp-formula></p>
    </sec>
  </sec>
  <sec id="sec3">
    <label>III.</label>
    <title>Experimental Evaluation of RBCNet</title>
    <p>In this section, we first address the various methods and strategies that we have used to detect the cells in our data set in <xref ref-type="sec" rid="sec3a">III-A</xref>, then we describe and discuss the results in <xref ref-type="sec" rid="sec3b">III-B</xref>.</p>
    <sec id="sec3a">
      <label>A.</label>
      <title>Comparisons and Testing Strategies</title>
      <p>Several methods and experiments have been tested and conducted to detect cells in our thin smear data set including our proposed RBCNet. We divide them into four groups:</p>
      <p><italic>1) Traditional methods:</italic> We compare our algorithm results with two state-of-the-art traditional methods in cell detection: Active contour <xref rid="ref18" ref-type="bibr">[18]</xref>, <xref rid="ref19" ref-type="bibr">[19]</xref> and Watershed <xref rid="ref17" ref-type="bibr">[17]</xref>. These two algorithms are the core of most existing papers to localize and separate cells, as we discussed in <xref ref-type="sec" rid="sec1a">Section I-A</xref>. They are considered superior for their efficiency to detect cells based on specific criteria and without the need to train and validate deep networks or acquiring GT labeling. However, these methods may fail for images with extreme and challenging conditions. Furthermore, the optimization of hyper-parameters for Active contours can be computationally expensive.</p>
      <p><italic>2) Instance segmentation DL methods:</italic> Instance segmentation methods provide automatic delineation for each object in the image on pixel-level. These methods may fail to produce a robust separation with images that are too dense with overlapping small objects such as our cell images. They can succeed in separating some cells but leave others as clumps of cells. We utilize three popular deep learning architectures: SegNet <xref rid="ref48" ref-type="bibr">[48]</xref>, U-Net <xref rid="ref42" ref-type="bibr">[42]</xref>, and DeepLabV3+ <xref rid="ref49" ref-type="bibr">[49]</xref>.</p>
      <p><italic>3) Object detection DL methods:</italic> We utilize four state of the art object detection networks: Faster R-CNN <xref rid="ref39" ref-type="bibr">[39]</xref>, You Look Only Once (YOLO) <xref rid="ref50" ref-type="bibr">[50]</xref>, Single Shot Detection (SSD) <xref rid="ref51" ref-type="bibr">[51]</xref>, and Mask R-CNN <xref rid="ref52" ref-type="bibr">[52]</xref>. They are all trained from scratch using the same number of tiles and share the same parameters. All networks can accept a small or regular image size dimension (<inline-formula><tex-math id="M31">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\leq$\end{document}</tex-math></inline-formula> 600), however, they cannot work with extremely large image size dimensions. The only solution is to train the networks using tiles. However, tiling can be problematic in the inference stage because of cell fragmentation, specifically, when object density is high. We follow four strategies in the testing stage: testing using the full image after resizing it to smaller dimensions, testing with non-overlapping tiles, testing with overlapping-tiles, and finally testing with overlapping-tiles with non maximum suppression (NMS) to remove replicated bounding boxes for a cell. NMS has been widely used as post processing for many computer vision applications, including object detection <xref rid="ref53" ref-type="bibr">[53]</xref>, <xref rid="ref54" ref-type="bibr">[54]</xref>. NMS keeps the bounding boxes with a high confidence score and eliminates the nearby windows with lower confidence scores. The testing scores for all testing strategies are discussed in <xref ref-type="sec" rid="sec3b">Section III-B</xref>. Our proposed dual network architecture addresses all the limitations produced by the tiling process and considers a different strategy in the testing stage.</p>
      <p><italic>4) Proposed dual deep learning networks:</italic> Our proposed dual networks solve the detection limitations for the tiling process in the testing stage for dense and large images. They detect tiles with cell clumps, obtained by an instance segmentation DL method, which are not prone to cell fragmentation. Furthermore, better cell delineation, resulting from Instance segmentation methods, leads to smaller cell clumps and more accurate detection results. We use three combined networks: SegNet+Faster R-CNN, U-Net+YOLO, and our proposed RBCNet (U-Net+Faster R-CNN). Although several other combinations are possible, we only try these three combinations for several reasons discussed in <xref ref-type="sec" rid="sec3b">Section III-B</xref>.</p>
    </sec>
    <sec id="sec3b">
      <label>B.</label>
      <title>Experimental Results with Discussion</title>
      <p><xref ref-type="table" rid="table2">Tables II</xref> and <xref ref-type="table" rid="table3">III</xref> display the experimental results for the experiments conducted using the methods described in <xref ref-type="sec" rid="sec3a">Section III-A</xref>.</p>
      <table-wrap id="table2" orientation="portrait" position="float">
        <label>TABLE II</label>
        <caption>
          <title>Segmentation Accuracy for our RBC Polygon Set, Using 11-fold Cross Validation. For Each Experiment, the Training Set Contains Tiles From 150 Images, and the Test Set Contains 15 Images. We Conducted t-Tests Using the F1-Measure Between our Proposed RBCNet Dual Network (U-Net+Faster RCNN) and Other Methods. All p-Values are &lt; 0.001, Indicating That the Differences Between Groups are Statistically Significant</title>
        </caption>
        <alternatives>
          <graphic xlink:href="kassi.t2-3034863"/>
          <table frame="box" rules="all" cellpadding="5">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th colspan="1" rowspan="1">Method <inline-formula><tex-math id="M32">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\backslash$\end{document}</tex-math></inline-formula> Evaluation Metrics</th>
                <th colspan="1" rowspan="1">F1-Measure <inline-formula><tex-math id="M33">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm SD$\end{document}</tex-math></inline-formula></th>
                <th colspan="1" rowspan="1">Precision <inline-formula><tex-math id="M34">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm SD$\end{document}</tex-math></inline-formula></th>
                <th colspan="1" rowspan="1">Recall <inline-formula><tex-math id="M35">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm SD$\end{document}</tex-math></inline-formula></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td colspan="4" rowspan="1">
                  <bold>Traditional methods</bold>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Watershed <xref rid="ref17" ref-type="bibr">[17]</xref></td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M36">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$94.62 \pm 5.62$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M37">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$96.50 \pm 2.01$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M38">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$93.34\pm 9.28$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Active contour <xref rid="ref18" ref-type="bibr">[18]</xref>, <xref rid="ref19" ref-type="bibr">[19]</xref></td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M39">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$96.33 \pm 1.97$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M40">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$95.64 \pm 2.31$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M41">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$97.11\pm 3.02$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="4" rowspan="1">
                  <bold>Instance segmentation deep learning methods</bold>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">SegNet <xref rid="ref48" ref-type="bibr">[48]</xref></td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M42">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$55.97 \pm 23.1$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M43">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$84.20 \pm 10.2$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M44">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$45.45 \pm 24.3$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">U-Net <xref rid="ref42" ref-type="bibr">[42]</xref></td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M45">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$87.06 \pm 13.3$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M46">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$93.48 \pm 4.5$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M47">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$83.33 \pm 17.6$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">DeepLab v3+ <xref rid="ref49" ref-type="bibr">[49]</xref></td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M48">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$74.59 \pm 24.4$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M49">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$91.97 \pm 3.4$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M50">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$68.37\pm 28.2$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="4" rowspan="1">
                  <bold>Object detection deep learning methods</bold>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Faster R-CNN <xref rid="ref39" ref-type="bibr">[39]</xref> on overlapping-tiles + NMS</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M51">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$91.19\pm 2.51$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M52">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$90.39\pm 3.85$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M53">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$92.47\pm 3.34$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Yolo <xref rid="ref50" ref-type="bibr">[50]</xref> on overlapping-tiles + NMS</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M54">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$96.13 \pm 1.72$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M55">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$97.09 \pm 1.79$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M56">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$95.27\pm 3.19$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">SSD <xref rid="ref51" ref-type="bibr">[51]</xref> on overlapping-tiles + NMS</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M57">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$87.26 \pm 2.52$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M58">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$89.63 \pm 3.06$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M59">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$85.18 \pm 4.17$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Mask R-CNN <xref rid="ref52" ref-type="bibr">[52]</xref> on overlapping-tiles + NMS</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M60">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$95.62 +1.57$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M61">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$98.39\pm 1.12$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M62">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$93.05 +2.82$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="4" rowspan="1">
                  <bold>Proposed dual deep learning networks</bold>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">SegNet + Faster R-CNN</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M63">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$96.80\pm 2.03$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M64">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$ 96.16 \pm 2.03$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M65">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$97.53 \pm 3.37$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">U-Net + YOLO</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M66">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$96.07 \pm 6.42$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M67">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\bf 98.58}\pm 1.29$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M68">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$94.23\pm 9.36$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1"><bold>RBCNet</bold> (U-Net + Faster R-CNN)</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M69">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\bf 97.76} \pm 1.71$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M70">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$97.51\pm 1.58$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M71">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\bf 98.07}\pm 2.97$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <table-wrap id="table3" orientation="portrait" position="float">
        <label>TABLE III</label>
        <caption>
          <title>Detection Accuracy for Our RBC Point Set. All Training Data of the Polygon Set (165 Images) has Been Used to Generate the Training Model to Test 800 Images From 160 Patients. The t-Tests Between Our Proposed Dual RBCNet and Other Methods Have P-Values &lt; 0.001, Indicating That the Differences Between Groups are Statistically Significant</title>
        </caption>
        <alternatives>
          <graphic xlink:href="kassi.t3-3034863"/>
          <table frame="box" rules="all" cellpadding="5">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th colspan="1" rowspan="1">Method <inline-formula><tex-math id="M72">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\backslash$\end{document}</tex-math></inline-formula> Evaluation Metrics</th>
                <th colspan="1" rowspan="1">F1-Measure <inline-formula><tex-math id="M73">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm SD$\end{document}</tex-math></inline-formula></th>
                <th colspan="1" rowspan="1">Precision <inline-formula><tex-math id="M74">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm SD$\end{document}</tex-math></inline-formula></th>
                <th colspan="1" rowspan="1">Recall <inline-formula><tex-math id="M75">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm SD$\end{document}</tex-math></inline-formula></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td colspan="4" rowspan="1">
                  <bold>Traditional methods</bold>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Watershed <xref rid="ref17" ref-type="bibr">[17]</xref></td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M76">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$94.31 \pm 9.07$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M77">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$95.56 \pm 7.84$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M78">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$93.51 \pm 11.26$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Active contour<xref rid="ref18" ref-type="bibr">[18]</xref>, <xref rid="ref19" ref-type="bibr">[19]</xref></td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M79">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$95.66 \pm 7.98$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M80">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$94.99 \pm 7.87$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M81">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$96.44 \pm 8.60$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="4" rowspan="1">
                  <bold>Instance segmentation deep learning methods</bold>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">SegNet <xref rid="ref48" ref-type="bibr">[48]</xref></td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M82">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$71.54 \pm 19.1$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M83">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$92.27 \pm 5.4$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M84">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$61.46 \pm 22.4$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">U-Net <xref rid="ref42" ref-type="bibr">[42]</xref></td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M85">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$91.93 \pm 9.05$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M86">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$ 95.41 \pm 2.71$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M87">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$89.72 \pm 12.8$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">DeepLab v3+ <xref rid="ref49" ref-type="bibr">[49]</xref></td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M88">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$79.44 \pm 19.4$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M89">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$92.10 \pm 3.6$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M90">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$73.75 \pm 23.9$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="4" rowspan="1">
                  <bold>Object detection deep learning methods</bold>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Faster R-CNN <xref rid="ref39" ref-type="bibr">[39]</xref> on overlapping-tiles + NMS</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M91">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$91.73\pm 5.23$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M92">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$88.58\pm 7.07$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M93">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$95.84\pm 6.68$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Yolo <xref rid="ref50" ref-type="bibr">[50]</xref> on overlapping-tiles + NMS</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M94">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$96.23\pm 1.42$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M95">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$97.86\pm 1.36$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M96">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$94.69\pm 2.23$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">SSD <xref rid="ref51" ref-type="bibr">[51]</xref> on overlapping-tiles + NMS</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M97">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$87.31\pm 2.39$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M98">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$89.45\pm 3.24$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M99">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$ 85.41\pm 3.58$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Mask R-CNN <xref rid="ref52" ref-type="bibr">[52]</xref> on overlapping-tiles + NMS</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M100">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$95.58\pm 1.64$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M101">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$98.05 \pm 1.25$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M102">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$93.28 \pm 2.83$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="4" rowspan="1">
                  <bold>Proposed dual deep learning networks</bold>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">SegNet + Faster R-CNN</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M103">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$97.52 \pm 1.49$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M104">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$97.23 \pm 1.58$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M105">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$97.86 \pm 2.52$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">U-Net + YOLO</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M106">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$96.00 \pm 5.86$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M107">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\bf 98.2}\pm 1.35$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M108">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$94.38\pm 8.99$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1"><bold>RBCNet</bold> (U-Net + Faster R-CNN)</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M109">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\bf 97.94}\pm 1.32$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M110">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$97.54 \pm 1.44$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M111">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$ {\bf 98.39} \pm 2.24$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p><italic>1) Watershed <xref rid="ref17" ref-type="bibr">[17]</xref> and Active contour <xref rid="ref18" ref-type="bibr">[18]</xref>, <xref rid="ref19" ref-type="bibr">[19]</xref>:</italic> Row 3 and 4 in <xref ref-type="table" rid="table2">Tables II</xref> and <xref ref-type="table" rid="table3">III</xref> show the quantitative results for Watershed and Active contour methods. Traditional methods may work very well for many images, but can fail suddenly when encountering challenging conditions because they depend on specific criteria, such as intensity or energy. This also becomes evident when comparing the differences between standard deviations (SDs). For example, in <xref ref-type="table" rid="table3">Table III</xref>, the SD for Watershed and Active contour is around six times higher than the SD of the results produced by our method. <xref ref-type="fig" rid="fig7">Fig. 7</xref> shows several examples where our prediction results differ from the predictions produced by Active contours. Our pipeline works consistently well for all regions, whereas Active contour results suffer from either under- or over-segmentation, which typically happens in regions with challenging conditions such as low contrast or illumination variation. RBCNet performs more robustly in the boundary regions, where cells are often only partly visible. For example, in sub-figure (f) of <xref ref-type="fig" rid="fig7">Figure 7</xref>, Active contour produces over-segmentation for partly visible cells in this region, whereas our pipeline predicts only the fully visible cells, which is a desirable feature closer to the human expert strategy. Comparing our RBCNet to traditional methods (Active contour and Watershed), the relative improvement is larger for the point set than for the polygon set. This is because the point set contains data from about five times more patients than the polygon set. Having more patients leads to a higher variability in terms of illumination, shape, and cell density, which poses problems to traditional approaches.</p>
      <fig id="fig7" orientation="portrait" position="float">
        <label>Fig. 7.</label>
        <caption>
          <p>Comparison between our RBCNet pipeline results and one of the very popular traditional methods in the literature for cell detection, based on Active contours <xref rid="ref18" ref-type="bibr">[18]</xref>, <xref rid="ref19" ref-type="bibr">[19]</xref>. Panels a,c, and e show the results of our proposed processing pipeline applied to several sample images. Panels b,d, and f show examples for the traditional Active contours method.</p>
        </caption>
        <graphic xlink:href="kassi7-3034863"/>
      </fig>
      <p><italic>2) Instance segmentation DL methods:</italic><xref ref-type="table" rid="table2">Tables II</xref> and <xref ref-type="table" rid="table3">III</xref> show the evaluation scores of SegNet <xref rid="ref48" ref-type="bibr">[48]</xref>, U-Net <xref rid="ref42" ref-type="bibr">[42]</xref>, and DeepLabV3+<xref rid="ref49" ref-type="bibr">[49]</xref>. U-Net performs better than other methods with F1-measure equal to 87% for the polygon set and 92% for the point set. For this reason, we choose U-Net to be part of our final dual network RBCNet.</p>
      <p><italic>3) Object detection networks with different tiling strategies:</italic> We discuss here the four tiling strategies mentioned in <xref ref-type="sec" rid="sec3a">III-A</xref> that are regularly used in the inference stage for object detection networks. We use Faster R-CNN for our analysis, see <xref ref-type="table" rid="table4">Table IV</xref>. Faster R-CNN has the advantage that it can accept any input size. Once the model is trained, we can apply it to both the full image or image tiles. We test our trained model on the full image as a first strategy because this is faster and easier. However, the results were not promising, as can be seen in <xref ref-type="table" rid="table4">Table IV</xref>. In particular, the recall is very low for this straightforward approach. Recall is equal to 66% for the polygon set and 69% for the point set. This is because the full image has a different size compared to the tiles used for training. The ratio of image to cell size is much larger than the ratio of tile size to cell size.</p>
      <table-wrap id="table4" orientation="portrait" position="float">
        <label>TABLE IV</label>
        <caption>
          <title>Detection Accuracy for Our RBC Polygon and Point Sets for Different Tiling Strategies Using Faster R-CNN <xref rid="ref51" ref-type="bibr">[51]</xref></title>
        </caption>
        <alternatives>
          <graphic xlink:href="kassi.t4-3034863"/>
          <table frame="box" rules="all" cellpadding="5">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th colspan="1" rowspan="1">Method<inline-formula><tex-math id="M112">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\backslash$\end{document}</tex-math></inline-formula> Evaluation Metrics</th>
                <th colspan="1" rowspan="1">F1-Measure <inline-formula><tex-math id="M113">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm SD$\end{document}</tex-math></inline-formula></th>
                <th colspan="1" rowspan="1">Precision <inline-formula><tex-math id="M114">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm SD$\end{document}</tex-math></inline-formula></th>
                <th colspan="1" rowspan="1">Recall <inline-formula><tex-math id="M115">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm SD$\end{document}</tex-math></inline-formula></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td colspan="4" rowspan="1">
                  <bold>Polygon set (33 patients /165 images)</bold>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Full image</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M116">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$76.33\pm 12.78$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M117">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$96.83\pm 1.59$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M118">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$66.13\pm 15.26$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Non-overlapping tiles</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M119">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$84.21\pm 3.76$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M120">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$93.64 \pm 2.27$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M121">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$77.11 \pm 6.39$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Overlapping-tiles</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M122">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$72.32\pm 2.59$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M123">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$59.27\pm 4.13$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M124">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$93.65\pm 3.03$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Overlapping-tiles + NMS</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M125">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$91.19\pm 2.51$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M126">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$90.39\pm 3.85$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M127">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$92.47\pm 3.34$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1"><bold>RBCNet</bold> (U-Net + Faster R-CNN)</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M128">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\bf 97.76} \pm 1.71$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M129">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\bf 97.51}\pm 1.58$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M130">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\bf 98.07}\pm 2.97$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="4" rowspan="1">
                  <bold>Point set (160 patients/ 800 images)</bold>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Full image</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M131">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$79.16\pm 13.11$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M132">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$95.57\pm 2.39$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M133">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$69.48\pm 17.28$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Non-overlapping tiles</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M134">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$85.55 \pm 6.27$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M135">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$92.56\pm 3.76$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M136">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$80.46\pm 10.31$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Overlapping-tiles</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M137">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$71.88\pm 4.69$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M138">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$57.95\pm 6.45$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M139">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$96.19\pm 6.57$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Overlapping-tiles + NMS</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M140">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$91.73\pm 5.23$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M141">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$88.58\pm 7.07$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M142">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$95.84\pm 6.68$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1"><bold>RBCNet</bold> (U-Net + Faster R-CNN)</td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M143">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$ {\bf 97.94} \pm 1.32$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M144">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$ {\bf 97.54} \pm 1.44$\end{document}</tex-math>
                  </inline-formula>
                </td>
                <td colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math id="M145">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$ {\bf 98.39} \pm 2.24$\end{document}</tex-math>
                  </inline-formula>
                </td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>A second strategy is to implement a tile-based inference stage, which is consistent with our tile-based training. <xref ref-type="table" rid="table4">Table IV</xref> shows the performance evaluation for Faster R-CNN on non-overlapping tiles. It is noticeable that the recall is still low because some cells are not detected, as they have been cut off by the tiling process.</p>
      <p>Therefore, a third strategy is to use overlapping tiles with an overlap ratio of 50%. In <xref ref-type="table" rid="table4">Table IV</xref>, Faster R-CNN on overlapping tiles shows our evaluation results for this strategy for both polygon and point set. We achieve a relatively high recall of 93.65% and 96.19%, respectively. However, using overlapping tiles leads to duplicate detection of some cells. For this reason, this strategy has the worst precision compared to other approaches in both tables, 59.27% and 57.95%. NMS leads to relatively good evaluation results, as shown in <xref ref-type="table" rid="table4">Table IV</xref> for both polygon and point set. Applying NMS increases the precision by 30%, with only a moderate loss in recall around 1%. We applied NMS with an overlap ratio of 0.5, which means it filters out all the bounding boxes that overlap more than 50%. Increasing the overlap ratio to higher values would decrease the recall because RBCs can overlap in dense cell clusters. According to our results listed in <xref ref-type="table" rid="table4">Table IV</xref>, Faster R-CNN on overlapping-tiles with NMS produces the best result compared to other tiling strategies. This has encouraged us to consider this strategy to produce good results for other object detection networks in <xref ref-type="table" rid="table2">Tables II</xref> and <xref ref-type="table" rid="table3">III</xref>.</p>
      <p><xref ref-type="fig" rid="fig9">Figure 9</xref> illustrates the output of Faster R-CNN using these four different strategies and shows how our RBCNet with U-Net masks performs significantly better than other inference approaches. Testing on full images and testing with non-overlapping tiles lead to a low recall as shown in panels [a and f] and panels [b and g], whereas testing with overlapping tiles leads to a low precision because some cells are predicted twice as shown in panels [c and h]. Applying NMS with an overlap ratio higher than 0.5 can remove some of the duplicate predictions; however, NMS cannot remove all the extra bounding boxes generated, see panels [d and i]. Our RBCNet in the last column provides the best detection performance. Red dots correspond to the cells that have not been detected (FN) while blue dots represent duplicate detections (FP).</p>
      <fig id="fig8" orientation="portrait" position="float">
        <label>Fig. 8.</label>
        <caption>
          <p>F1-measure versus IoU threshold for all experiments using the polygon set and 34,213 GT cells. The plot shows how the F1-measure decreases as the IoU threshold or overlap ratio is increased.</p>
        </caption>
        <graphic xlink:href="kassi8-3034863"/>
      </fig>
      <fig id="fig9" orientation="portrait" position="float">
        <label>Fig. 9.</label>
        <caption>
          <p>Output of Faster R-CNN for different input configurations: First column (a, f) shows Faster R-CNN applied to the full image, second column (b, g) shows Faster R-CNN results for non-overlapping tiles, third column (c, h) are Faster R-CNN results on overlapping tiles, fourth column (d, i) contains results with overlapping tiles and non-maximum suppression, and last column (e, j) shows results for our proposed method. Red dots <inline-formula><tex-math id="M146">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\color{red}{{\bullet}}$\end{document}</tex-math></inline-formula> represent false negatives and blue dots <inline-formula><tex-math id="M147">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\color{blue}{{\bullet}}$\end{document}</tex-math></inline-formula> represent false positives. Our results in the last column provide a better F1 measure in all cases compared to other inference schemes.</p>
        </caption>
        <graphic xlink:href="kassi9-3034863"/>
      </fig>
      <p><italic>4) Our proposed dual deep network architecture:</italic> The first combined architecture that we have tried is U-Net+YOLO as those two networks produce the highest DL F1-measure in both <xref ref-type="table" rid="table2">Tables II</xref> and <xref ref-type="table" rid="table3">III</xref>. However, we found that YOLO is sensitive to tile size and only responds well for tiles that have a similar dimension as the training tiles. It does not respond well for tiles with large cell clumps. Although the recall did not improve, it is noticeable that the precision increased because our method tested tiles with full clumps; not tiles with fragmented small cell objects. As a second trial, we choose Faster R-CNN, as it has the highest recall/detection in <xref ref-type="table" rid="table3">Table III</xref>. Note that we did not choose Mask R-CNN because it needs a larger set of polygon/segmentation mask training data, which is expensive and its acquisition takes longer. Mask R-CNN is also much slower than Faster R-CNN. Another advantage of Faster R-CNN is that it is more versatile and automatically adapts to different tile sizes. It accepts clumps/clusters with different numbers of cells or tile sizes for inference.</p>
      <p>Our proposed dual deep network architecture RBCNet takes advantage of U-Net to provide initial foreground masks as input to Faster R-CNN for cell identification. This dual architecture has the following advantages:</p>
      <p>U-Net can provide a foreground mask with the connected components of the corresponding image regions as input to Faster R-CNN. Using connected components as input to Faster R-CNN has the advantage that no cells will be cut-off, which happens in tile-based approaches. This results in higher true positive and lower false positive rates.</p>
      <p>Touching and overlapping cells are usually identified as a single clump by U-Net. Faster R-CNN is able to identify individual cells within clumps accurately and rarely produces a false detection in the background, even in places with illumination artifacts and other challenging conditions, because it is guided by the U-Net foreground mask.</p>
      <p>U-Net preserves the spatial details lost during down-sampling by concatenating the cropped feature maps with the corresponding maps through up-sampling. Preserving spatial details of RBCs improves segmentation because it leads to more robust candidates for Faster R-CNN. To illustrate this, replacing U-Net by SegNet <xref rid="ref48" ref-type="bibr">[48]</xref> shows the effects of preserving details through concatenation rather than just transferring max pooling indices to the decoder. Hence, SegNet does not preserve important neighboring information like U-Net.</p>
      <p>For all these combinations, we show the results in the last three rows of <xref ref-type="table" rid="table2">Tables II</xref> and <xref ref-type="table" rid="table3">III</xref>. Our proposed dual deep learning architecture RBCNet, using U-Net foreground mask with Faster R-CNN, outperformed all other methods evaluated with the F1-measure, with a very low standard deviation (SD). <xref ref-type="table" rid="table2">Tables II</xref> and <xref ref-type="table" rid="table3">III</xref> show our experimental results, where numbers in bold represent our best results. For the polygon set, we achieve an F1-measure, precision, and recall of 97.76%, 97.51%, and 98.07%, respectively. For our point set, we achieve 97.94%, 97.54%, and 98.39% correspondingly.</p>
      <p><xref ref-type="fig" rid="fig8">Fig. 8</xref> shows the F1-measure for the polygon set plotted versus the Intersection over Union (IoU) metric threshold between detected cells and the corresponding GTs. Although, we cannot produce the same plot for the point set because we do not have GT polygon annotations to determine the overlap, this plot gives us an idea about the robustness and stability of our architecture. It shows that the F1-measure decreases while the IoU overlap threshold increases. This is because the number of TPs decreases, and more cells become FPs, since detections have less than the required overlap with GT. Our dual RBCNet architecture is relatively stable against this IoU metric. F1-measure remains over 90% until the IoU overlap requirement becomes larger than 0.75. It is also noticeable that U-Net and Deeplab v3+ produce a relatively more stable F1-measure for IoU between 0.8 and 1. However, these two methods have an overall lower F1-measure.</p>
      <p>We also apply a t-Test to determine whether there is a significant difference between the means of our RBCNet and other methods in terms of F1-measure. We compute p-values that are less than 0.001 for all the experiments, which shows that the differences are statistically significant.</p>
      <p>For a straightforward implementation on a regular PC and without a GPU, the processing time varies between 20 and 60 seconds per image depending on the cell density. However, our method can be parallelized because RBC clusters can be processed independently, and in parallel. We estimate that this would reduce the total processing time significantly.</p>
    </sec>
  </sec>
  <sec id="sec4">
    <label>IV.</label>
    <title>Conclusion</title>
    <p>Our dual deep learning architecture RBCNet, which combines U-Net with Faster R-CNN, provides a robust solution for detecting RBCs in blood smear images characterized by a small ratio of cell object size to image size. For automated malaria screening, we tested our proposed pipeline on 965 images from different patients to detect single RBCs and to segment overlapping RBCs in cell clusters. By applying Faster R-CNN on a foreground mask produced by U-Net, we are able to outperform traditional cell detection methods, instance segmentation deep learning methods, and object detection deep learning methods. Our cell detection implements a crucial step towards automated malaria diagnosis. Future work will combine our cell detection pipeline with a cell classifier to differentiate between infected and uninfected cells.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgment</title>
    <p>We would like to thank Dr. Md Amir Hossain from Chittagong Medical College Hospital, Chittagong, Bangladesh, for allowing us to acquire blood smears and Dr. Kamolrat Silamut for taking images and doing the manual counting of cells.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="ref1">
      <label>[1]</label>
      <mixed-citation publication-type="report" publication-format="print"><collab>WHO</collab>, “<article-title>World malaria report 2019</article-title>,” World Health Organization, Geneva, Switzerland, , <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="ref2">
      <label>[2]</label>
      <mixed-citation publication-type="report" publication-format="print"><collab>WHO</collab>, “<article-title>Malaria microscopy quality assurance manual-version 2</article-title>,” World Health Organization, Geneva, Switzerland, , <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="ref3">
      <label>[3]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>A.</given-names><surname>Krizhevsky</surname></string-name>, <string-name><given-names>I.</given-names><surname>Sutskever</surname></string-name>, and <string-name><given-names>G. E</given-names><surname>Hinton</surname></string-name></person-group>, “<article-title>Imagenet classification with deep convolutional neural networks</article-title>,” in <source>Proc. Adv. Neural Inf. Process. Syst.</source>, <year>2012</year>, pp. <fpage>1097</fpage>–<lpage>1105</lpage>.</mixed-citation>
    </ref>
    <ref id="ref4">
      <label>[4]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>J.</given-names><surname>Schmidhuber</surname></string-name></person-group>, “<article-title>Deep learning in neural networks: An overview</article-title>,” <source>Neural Netw.</source>, vol. <volume>61</volume>, pp. <fpage>85</fpage>–<lpage>117</lpage>, <year>2015</year>.<pub-id pub-id-type="pmid">25462637</pub-id></mixed-citation>
    </ref>
    <ref id="ref5">
      <label>[5]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Y.</given-names><surname>LeCun</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Bengio</surname></string-name>, and <string-name><given-names>G.</given-names><surname>Hinton</surname></string-name></person-group>, “<article-title>Deep learning</article-title>,” <source>Nature</source>, vol. <volume>521</volume>, no. <issue>7553</issue>, pp. <fpage>436</fpage>–<lpage>444</lpage>, <year>2015</year>.<pub-id pub-id-type="pmid">26017442</pub-id></mixed-citation>
    </ref>
    <ref id="ref6">
      <label>[6]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Poostchi</surname></string-name>, <string-name><given-names>K.</given-names><surname>Silamut</surname></string-name>, <string-name><given-names>R. J.</given-names><surname>Maude</surname></string-name>, <string-name><given-names>S.</given-names><surname>Jaeger</surname></string-name>, and <string-name><given-names>G.</given-names><surname>Thoma</surname></string-name></person-group>, “<article-title>Image analysis and machine learning for detecting malaria</article-title>,” <source>Transl. Res.</source>, vol. <volume>194</volume>, pp. <fpage>36</fpage>–<lpage>55</lpage>, <year>2018</year>.<pub-id pub-id-type="pmid">29360430</pub-id></mixed-citation>
    </ref>
    <ref id="ref7">
      <label>[7]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Anggraini</surname></string-name>, <string-name><given-names>A. S.</given-names><surname>Nugroho</surname></string-name>, <string-name><given-names>C.</given-names><surname>Pratama</surname></string-name>, <string-name><given-names>I. E.</given-names><surname>Rozi</surname></string-name>, <string-name><given-names>V.</given-names><surname>Pragesjvara</surname></string-name>, and <string-name><given-names>M.</given-names><surname>Gunawan</surname></string-name></person-group>, “<article-title>Automated status identification of microscopic images obtained from malaria thin blood smears using bayes decision: A study case in plasmodium falciparum</article-title>,” in <source>Proc. Int. Conf. Adv. Comput. Sci. Inf. Syst.</source>, <season>Dec.</season>
<year>2011</year>, pp. <fpage>347</fpage>–<lpage>352</lpage>.</mixed-citation>
    </ref>
    <ref id="ref8">
      <label>[8]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>L.</given-names><surname>Malihi</surname></string-name>, <string-name><given-names>K.</given-names><surname>Ansari-Asl</surname></string-name>, and <string-name><given-names>A.</given-names><surname>Behbahani</surname></string-name></person-group>, “<article-title>Malaria parasite detection in giemsa-stained blood cell images</article-title>,” in <source>Proc. Iranian Conf. Mach. Vis. Image Process.</source>, <season>Sep.</season>
<year>2013</year>, pp. <fpage>360</fpage>–<lpage>365</lpage>.</mixed-citation>
    </ref>
    <ref id="ref9">
      <label>[9]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>S. S.</given-names><surname>Savkare</surname></string-name> and <string-name><given-names>S. P.</given-names><surname>Narote</surname></string-name></person-group>, “<article-title>Automated system for malaria parasite identification</article-title>,” in <source>Proc. Int. Conf. Commun., Inf. Comput. Technol.</source>, <season>Jan.</season>
<year>2015</year>, pp. <fpage>1</fpage>–<lpage>4</lpage>.</mixed-citation>
    </ref>
    <ref id="ref10">
      <label>[10]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>S. S.</given-names><surname>Devi</surname></string-name>, <string-name><given-names>A.</given-names><surname>Roy</surname></string-name>, <string-name><given-names>M.</given-names><surname>Sharma</surname></string-name>, and <string-name><given-names>R. H.</given-names><surname>Laskar</surname></string-name></person-group>, “<article-title>knnNN classification based erythrocyte separation in microscopic images of thin blood smear</article-title>,” in <source>Proc. Int. Conf. Comput. Intell. Netw.</source>, <season>Jan.</season>
<year>2016</year>, pp. <fpage>69</fpage>–<lpage>72</lpage>.</mixed-citation>
    </ref>
    <ref id="ref11">
      <label>[11]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>N.</given-names><surname>Abbas</surname></string-name></person-group><etal/>, “<article-title>Microscopic rgb color images enhancement for blood cells segmentation in ycbcr color space for k-means clustering</article-title>,” <source>J. Theor. Appl. Inf. Technol.</source>, vol. <volume>55</volume>, no. <issue>1</issue>, pp. <fpage>117</fpage>–<lpage>125</lpage>, <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="ref12">
      <label>[12]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>A. S.</given-names><surname>Abdul-Nasir</surname></string-name>, <string-name><given-names>M. Y.</given-names><surname>Mashor</surname></string-name>, and <string-name><given-names>Z.</given-names><surname>Mohamed</surname></string-name></person-group>, “<article-title>Colour image segmentation approach for detection of malaria parasites using various colour models and k-means clustering</article-title>,” <source>WSEAS Trans. Biol. Biomed.</source>, vol. <volume>10</volume>, no. <issue>1</issue>, pp. <fpage>41</fpage>–<lpage>55</lpage>, <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="ref13">
      <label>[13]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Halim</surname></string-name>, <string-name><given-names>T. R.</given-names><surname>Bretschneider</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Li</surname></string-name>, <string-name><given-names>P. R.</given-names><surname>Preiser</surname></string-name>, and <string-name><given-names>C.</given-names><surname>Kuss</surname></string-name></person-group>, “<article-title>Estimating malaria parasitaemia from blood smear images</article-title>,” in <source>Proc. Int. Conf. Control, Autom., Robot. Vis.</source>, <season>Dec.</season>
<year>2006</year>, pp. <fpage>1</fpage>–<lpage>6</lpage>.</mixed-citation>
    </ref>
    <ref id="ref14">
      <label>[14]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>B.</given-names><surname>Maiseli</surname></string-name>, <string-name><given-names>J.</given-names><surname>Mei</surname></string-name>, <string-name><given-names>H.</given-names><surname>Gao</surname></string-name>, <string-name><given-names>S.</given-names><surname>Yin</surname></string-name>, and <string-name><given-names>B.</given-names><surname>Maiseli</surname></string-name></person-group>, “<article-title>An automatic and cost-effective parasitemia identification framework for low-end microscopy imaging devices</article-title>,” in <source>Proc. Int. Conf. Mechatronics Control</source>, <season>Jul.</season>
<year>2014</year>, pp. <fpage>2048</fpage>–<lpage>2053</lpage>.</mixed-citation>
    </ref>
    <ref id="ref15">
      <label>[15]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>V. V.</given-names><surname>Makkapati</surname></string-name> and <string-name><given-names>R. M.</given-names><surname>Rao</surname></string-name></person-group>, “<article-title>Segmentation of malaria parasites in peripheral blood smear images</article-title>,” in <source specific-use="IEEE">Proc. IEEE Int. Conf. Acoust., Speech Signal Process.</source>, <season>Apr.</season>
<year>2009</year>, pp. <fpage>1361</fpage>–<lpage>1364</lpage>.</mixed-citation>
    </ref>
    <ref id="ref16">
      <label>[16]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>L. B</given-names><surname>Damahe</surname></string-name>, <string-name><given-names>R</given-names><surname>Krishna</surname></string-name>, and <string-name><given-names>N</given-names><surname>Janwe</surname></string-name></person-group>, “<article-title>Segmentation based approach to detect parasites and RBCs in blood cell images</article-title>,” <source>Int. J. Comput. Sci. Appl.</source>, vol. <volume>4</volume>, pp. <fpage>71</fpage>–<lpage>81</lpage>, <year>2011</year>.</mixed-citation>
    </ref>
    <ref id="ref17">
      <label>[17]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>J. M.</given-names><surname>Higgins</surname></string-name>, <string-name><given-names>D. T.</given-names><surname>Eddington</surname></string-name>, <string-name><given-names>S. N.</given-names><surname>Bhatia</surname></string-name>, and <string-name><given-names>L.</given-names><surname>Mahadevan</surname></string-name></person-group>, “<article-title>Statistical dynamics of flowing red blood cells by morphological image processing</article-title>,” <source>PLoS Comput. Biol.</source>, vol. <volume>5</volume>, no. <issue>2</issue>, <year>2009</year>, Art. no. <pub-id pub-id-type="art-access-id">e1000288</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref18">
      <label>[18]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>I.</given-names><surname>Ersoy</surname></string-name>, <string-name><given-names>F.</given-names><surname>Bunyak</surname></string-name>, <string-name><given-names>J. M.</given-names><surname>Higgins</surname></string-name>, and <string-name><given-names>K.</given-names><surname>Palaniappan</surname></string-name></person-group>, “<article-title>Coupled edge profile active contours for red blood cell flow analysis</article-title>,” in <source specific-use="IEEE">Proc. IEEE Int. Symp. Biomed. Imag.</source>, <year>2012</year>, pp. <fpage>748</fpage>–<lpage>751</lpage>.</mixed-citation>
    </ref>
    <ref id="ref19">
      <label>[19]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Poostchi</surname></string-name></person-group><etal/>, “<article-title>Malaria parasite detection and cell counting for human and mouse using thin blood smear microscopy</article-title>,” <source>J. Med. Imag.</source>, vol. <volume>5</volume>, no. <issue>4</issue>, <year>2018</year>, Art. no. <pub-id pub-id-type="art-access-id">044506</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref20">
      <label>[20]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>G.</given-names><surname>Litjens</surname></string-name></person-group><etal/>, “<article-title>A survey on deep learning in medical image analysis</article-title>,” <source>Med. Image Anal.</source>, vol. <volume>42</volume>, pp. <fpage>60</fpage>–<lpage>88</lpage>, <year>2017</year>.<pub-id pub-id-type="pmid">28778026</pub-id></mixed-citation>
    </ref>
    <ref id="ref21">
      <label>[21]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Y. M.</given-names><surname>Kassim</surname></string-name>, <string-name><given-names>O. V.</given-names><surname>Glinskii</surname></string-name>, <string-name><given-names>V. V.</given-names><surname>Glinsky</surname></string-name>, <string-name><given-names>V. H.</given-names><surname>Huxley</surname></string-name>, <string-name><given-names>G.</given-names><surname>Guidoboni</surname></string-name>, and <string-name><given-names>K.</given-names><surname>Palaniappan</surname></string-name></person-group>, “<article-title>Deep U-Net regression and hand-crafted feature fusion for accurate blood vessel segmentation</article-title>,” in <source specific-use="IEEE">Proc. IEEE Int. Conf. Image Process.</source>, <year>2019</year>, pp. <fpage>1445</fpage>–<lpage>1449</lpage>.</mixed-citation>
    </ref>
    <ref id="ref22">
      <label>[22]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>Kamnitsas</surname></string-name></person-group><etal/>, “<article-title>Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation</article-title>,” <source>Med. Image Anal.</source>, vol. <volume>36</volume>, pp. <fpage>61</fpage>–<lpage>78</lpage>, <year>2017</year>.<pub-id pub-id-type="pmid">27865153</pub-id></mixed-citation>
    </ref>
    <ref id="ref23">
      <label>[23]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>A.</given-names><surname>Hamidinekoo</surname></string-name>, <string-name><given-names>E.</given-names><surname>Denton</surname></string-name>, <string-name><given-names>A.</given-names><surname>Rampun</surname></string-name>, <string-name><given-names>K.</given-names><surname>Honnor</surname></string-name>, and <string-name><given-names>R.</given-names><surname>Zwiggelaar</surname></string-name></person-group>, “<article-title>Deep learning in mammography and breast histology, an overview and future trends</article-title>,” <source>Med. Image Anal.</source>, vol. <volume>47</volume>, pp. <fpage>45</fpage>–<lpage>67</lpage>, <year>2018</year>.<pub-id pub-id-type="pmid">29679847</pub-id></mixed-citation>
    </ref>
    <ref id="ref24">
      <label>[24]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Havaei</surname></string-name></person-group><etal/>, “<article-title>Brain tumor segmentation with deep neural networks</article-title>,” <source>Med. Image Anal.</source>, vol. <volume>35</volume>, pp. <fpage>18</fpage>–<lpage>31</lpage>, <year>2017</year>.<pub-id pub-id-type="pmid">27310171</pub-id></mixed-citation>
    </ref>
    <ref id="ref25">
      <label>[25]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Y. M</given-names><surname>Kassim</surname></string-name>, <string-name><given-names>R. J</given-names><surname>Maude</surname></string-name>, and <string-name><given-names>K.</given-names><surname>Palaniappan</surname></string-name></person-group>, “<article-title>Sensitivity of cross-trained deep cnns for retinal vessel extraction</article-title>,” in <source specific-use="IEEE">Proc. IEEE Eng. Med. Biol. Soc.</source>, <year>2018</year>, pp. <fpage>2736</fpage>–<lpage>2739</lpage>.</mixed-citation>
    </ref>
    <ref id="ref26">
      <label>[26]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Z.</given-names><surname>Alom</surname></string-name>, <string-name><given-names>C.</given-names><surname>Yakopcic</surname></string-name>, <string-name><given-names>T. M</given-names><surname>Taha</surname></string-name>, and <string-name><given-names>V. K</given-names><surname>Asari</surname></string-name></person-group>, “<article-title>Microscopic blood cell classification using inception recurrent residual convolutional neural networks</article-title>,” in <source specific-use="IEEE">Proc. IEEE Nat. Aerosp. Electron. Conf.</source>, <year>2018</year>, pp. <fpage>222</fpage>–<lpage>227</lpage>.</mixed-citation>
    </ref>
    <ref id="ref27">
      <label>[27]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Shafique</surname></string-name> and <string-name><given-names>S.</given-names><surname>Tehsin</surname></string-name></person-group>, “<article-title>Acute lymphoblastic leukemia detection and classification of its subtypes using pretrained deep convolutional neural networks</article-title>,” <source>Technol. Cancer Res. Treat.</source>, vol. <volume>17</volume>, pp. <fpage>1</fpage>–<lpage>7</lpage>, <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="ref28">
      <label>[28]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>G.</given-names><surname>Liang</surname></string-name>, <string-name><given-names>H.</given-names><surname>Hong</surname></string-name>, <string-name><given-names>W.</given-names><surname>Xie</surname></string-name>, and <string-name><given-names>L.</given-names><surname>Zheng</surname></string-name></person-group>, “<article-title>Combining convolutional neural network with recursive neural network for blood cell image classification</article-title>,” <source specific-use="IEEE">IEEE Access</source>, vol. <volume>6</volume>, pp. <fpage>36188</fpage>–<lpage>36197</lpage>, <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="ref29">
      <label>[29]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Z.</given-names><surname>Liang</surname></string-name></person-group><etal/>, “<article-title>CNN-based image analysis for malaria diagnosis</article-title>,” in <source specific-use="IEEE">Proc. IEEE Int. Conf. Bioinf. Biomed.</source>, <year>2016</year>, pp. <fpage>493</fpage>–<lpage>496</lpage>.</mixed-citation>
    </ref>
    <ref id="ref30">
      <label>[30]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Y.</given-names><surname>Dong</surname></string-name></person-group><etal/>, “<article-title>Evaluations of deep convolutional neural networks for automatic identification of malaria infected cells</article-title>,” in <source specific-use="IEEE">Proc. IEEE Int. Conf. Biomed. Health Informat.</source>, <year>2017</year>, pp. <fpage>101</fpage>–<lpage>104</lpage>.</mixed-citation>
    </ref>
    <ref id="ref31">
      <label>[31]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Bibin</surname></string-name>, <string-name><given-names>M. S.</given-names><surname>Nair</surname></string-name>, and <string-name><given-names>P.</given-names><surname>Punitha</surname></string-name></person-group>, “<article-title>Malaria parasite detection from peripheral blood smear images using deep belief networks</article-title>,” <source specific-use="IEEE">IEEE Access</source>, vol. <volume>5</volume>, pp. <fpage>9099</fpage>–<lpage>9108</lpage>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="ref32">
      <label>[32]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>A.</given-names><surname>Morar</surname></string-name>, <string-name><given-names>F.</given-names><surname>Moldoveanu</surname></string-name>, and <string-name><given-names>E.</given-names><surname>Groller</surname></string-name></person-group>, “<article-title>Image segmentation based on active contours without edges</article-title>,” in <source specific-use="IEEE">Proc. IEEE Int. Conf. Intell. Comput. Commun. Process.</source>, <year>2012</year>, pp. <fpage>213</fpage>–<lpage>220</lpage>.</mixed-citation>
    </ref>
    <ref id="ref33">
      <label>[33]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>G. P.</given-names><surname>Gopakumar</surname></string-name>, <string-name><given-names>M.</given-names><surname>Swetha</surname></string-name>, <string-name><given-names>G. Sai</given-names><surname>Siva</surname></string-name>, and <string-name><given-names>G. R K Sai</given-names><surname>Subrahmanyam</surname></string-name></person-group>, “<article-title>Convolutional neural network-based malaria diagnosis from focus stack of blood smear images acquired using custom-built slide scanner</article-title>,” <source>J. Biophotonics</source>, vol. <volume>11</volume>, no. <issue>3</issue>, <year>2018</year>, Art. no. <pub-id pub-id-type="art-access-id">e201700003</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref34">
      <label>[34]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Rajaraman</surname></string-name></person-group><etal/>, “<article-title>Pre-trained convolutional neural networks as feature extractors toward improved malaria parasite detection in thin blood smear images</article-title>,” <source>PeerJ</source>, vol. <volume>6</volume>, <year>2018</year>, Art. no. <pub-id pub-id-type="art-access-id">e4568</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref35">
      <label>[35]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>V</given-names><surname>Loganathan</surname></string-name></person-group>, “<article-title>Extraction of blood cell image classification using convolution neural network</article-title>,” <source>Int. J. Innov. Res. Adv. Eng.</source>, vol. <volume>6</volume>, pp. <fpage>2349</fpage>–<lpage>2163</lpage>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="ref36">
      <label>[36]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>M. A</given-names><surname>Molina-Cabello</surname></string-name>, <string-name><given-names>E.</given-names><surname>López-Rubio</surname></string-name>, <string-name><given-names>R. M</given-names><surname>Luque-Baena</surname></string-name>, <string-name><given-names>M.</given-names><surname>Rodríguez-Espinosa</surname></string-name>, and <string-name><given-names>K.</given-names><surname>Thurnhofer-Hemsi</surname></string-name></person-group>, “<article-title>Blood cell classification using the hough transform and convolutional neural networks</article-title>,” in <source>Proc. World Conf. Inf. Syst. Technol.</source>, <year>2018</year>, pp. <fpage>669</fpage>–<lpage>678</lpage>.</mixed-citation>
    </ref>
    <ref id="ref37">
      <label>[37]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>F.</given-names><surname>Yi</surname></string-name>, <string-name><given-names>I.</given-names><surname>Moon</surname></string-name>, and <string-name><given-names>B.</given-names><surname>Javidi</surname></string-name></person-group>, “<article-title>Automated red blood cells extraction from holographic images using fully convolutional neural networks</article-title>,” <source>Biomed. Opt. Exp.</source>, vol. <volume>8</volume>, no. <issue>10</issue>, pp. <fpage>4466</fpage>–<lpage>4479</lpage>, <season>Oct.</season>
<year>2017</year>.</mixed-citation>
    </ref>
    <ref id="ref38">
      <label>[38]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Yang</surname></string-name>, <string-name><given-names>B.</given-names><surname>Fang</surname></string-name>, <string-name><given-names>W.</given-names><surname>Tang</surname></string-name>, <string-name><given-names>X.</given-names><surname>Wu</surname></string-name>, <string-name><given-names>J.</given-names><surname>Qian</surname></string-name>, and <string-name><given-names>W.</given-names><surname>Yang</surname></string-name></person-group>, “<article-title>Faster r-cnn based microscopic cell detection</article-title>,” in <source>Proc. Int. Conf. Secur. Pattern Anal. Cybern.</source>, <year>2017</year>, pp. <fpage>345</fpage>–<lpage>350</lpage>.</mixed-citation>
    </ref>
    <ref id="ref39">
      <label>[39]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Ren</surname></string-name>, <string-name><given-names>K.</given-names><surname>He</surname></string-name>, <string-name><given-names>R.</given-names><surname>Girshick</surname></string-name>, and <string-name><given-names>J.</given-names><surname>Sun</surname></string-name></person-group>, “<article-title>Faster R-CNN: Towards real-time object detection with region proposal networks</article-title>,” in <source>Proc. Adv. Neural Inf. Process. Syst. 28</source>, pp. <fpage>91</fpage>–<lpage>99</lpage>, <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="ref40">
      <label>[40]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>J.</given-names><surname>Hung</surname></string-name> and <string-name><given-names>A.</given-names><surname>Carpenter</surname></string-name></person-group>, “<article-title>Applying faster R-CNN for object detection on malaria images</article-title>,” in <source specific-use="IEEE">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops</source>, <year>2017</year>, pp. <fpage>808</fpage>–<lpage>813</lpage>.</mixed-citation>
    </ref>
    <ref id="ref41">
      <label>[41]</label>
      <mixed-citation publication-type="confproc" publication-format="online"><person-group person-group-type="author"><string-name><given-names>Y. M.</given-names><surname>Kassim</surname></string-name>, <string-name><given-names>K.</given-names><surname>Palaniappan</surname></string-name>, <string-name><given-names>R. J.</given-names><surname>Maude</surname></string-name>, <string-name><given-names>G.</given-names><surname>Thoma</surname></string-name>, and <string-name><given-names>S.</given-names><surname>Jaeger</surname></string-name></person-group>, “<article-title>Robust detection for malaria cells in thin blood smear microscopy using deep learning</article-title>,” in <source>Proc. Conf. Mach. Intell. Med. Imag.</source>
<year>2018</year>, [Online]. Available: <uri xlink:type="simple" xlink:href="https://cdn.ymaws.com/siim.org/resource/resmgr/mimi18/abstracts/18paper1-Kassim.pdf">https://cdn.ymaws.com/siim.org/resource/resmgr/mimi18/abstracts/18paper1-Kassim.pdf</uri></mixed-citation>
    </ref>
    <ref id="ref42">
      <label>[42]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>O.</given-names><surname>Ronneberger</surname></string-name>, <string-name><given-names>P.</given-names><surname>Fischer</surname></string-name>, and <string-name><given-names>T.</given-names><surname>Brox</surname></string-name></person-group>, “<article-title>U-Net: Convolutional networks for biomedical image segmentation</article-title>,” in <source>Med. Image Comput. Comput.-Assisted Intervention</source>, <year>2015</year>, pp. <fpage>234</fpage>–<lpage>241</lpage>.</mixed-citation>
    </ref>
    <ref id="ref43">
      <label>[43]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>F.</given-names><surname>Yang</surname></string-name></person-group><etal/>, “<article-title>Deep learning for smartphone-based malaria parasite detection in thick blood smears</article-title>,” <source specific-use="IEEE">IEEE J. Biomed. Health Inform.</source>, vol. <volume>24</volume>, no. <issue>5</issue>, pp. <fpage>1427</fpage>–<lpage>1438</lpage>, <month>5</month> <year>2020</year>.<pub-id pub-id-type="pmid">31545747</pub-id></mixed-citation>
    </ref>
    <ref id="ref44">
      <label>[44]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>U.</given-names><surname>Sampathkumar</surname></string-name>, <string-name><given-names>V. B. S.</given-names><surname>Prasath</surname></string-name>, <string-name><given-names>S.</given-names><surname>Meena</surname></string-name>, and <string-name><given-names>K.</given-names><surname>Palaniappan</surname></string-name></person-group>, “<article-title>Assisted ground truth generation using interactive segmentation on a visualization and annotation tool</article-title>,” in <source specific-use="IEEE">Proc. IEEE Appl. Imagery Pattern Recognit.</source>, <season>Oct.</season> <year>2016</year>, pp. <fpage>1</fpage>–<lpage>7</lpage>.</mixed-citation>
    </ref>
    <ref id="ref45">
      <label>[45]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>T.</given-names><surname>Falk</surname></string-name></person-group><etal/>, “<article-title>U-Net: Deep learning for cell counting, detection, and morphometry</article-title>,” <source>Nat. Methods</source>, vol. <volume>16</volume>, no. <issue>1</issue>, pp. <fpage>67</fpage>–<lpage>70</lpage>, <year>2019</year>.<pub-id pub-id-type="pmid">30559429</pub-id></mixed-citation>
    </ref>
    <ref id="ref46">
      <label>[46]</label>
      <mixed-citation publication-type="book" publication-format="print"><collab>MATLAB</collab>, <source>Neural Network Toolbox and Version R2018a</source>, <publisher-loc>Natick, MA, USA</publisher-loc>: <publisher-name>The MathWorks, Inc.</publisher-name>, <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="ref47">
      <label>[47]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>He</surname></string-name>, <string-name><given-names>X.</given-names><surname>Zhang</surname></string-name>, <string-name><given-names>S.</given-names><surname>Ren</surname></string-name>, and <string-name><given-names>J.</given-names><surname>Sun</surname></string-name></person-group>, “<article-title>Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</article-title>,” in <source specific-use="IEEE">Proc. IEEE Int. Conf. Comput. Vis.</source>, <year>2015</year>, pp. <fpage>1026</fpage>–<lpage>1034</lpage>.</mixed-citation>
    </ref>
    <ref id="ref48">
      <label>[48]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>V.</given-names><surname>Badrinarayanan</surname></string-name>, <string-name><given-names>A.</given-names><surname>Kendall</surname></string-name>, and <string-name><given-names>R.</given-names><surname>Cipolla</surname></string-name></person-group>, “<article-title>SegNet: A deep convolutional encoder-decoder architecture for image segmentation</article-title>,” <source specific-use="IEEE">IEEE Trans. Pattern Anal. Mach. Intell.</source>, vol. <volume>39</volume>, no. <issue>12</issue>, pp. <fpage>2481</fpage>–<lpage>2495</lpage>, <season>Dec.</season>
<year>2017</year>.<pub-id pub-id-type="pmid">28060704</pub-id></mixed-citation>
    </ref>
    <ref id="ref49">
      <label>[49]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>L.</given-names><surname>Chen</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Zhu</surname></string-name>, <string-name><given-names>G.</given-names><surname>Papandreou</surname></string-name>, <string-name><given-names>F.</given-names><surname>Schroff</surname></string-name>, and <string-name><given-names>H.</given-names><surname>Adam</surname></string-name></person-group>, “<article-title>Encoder-decoder with atrous separable convolution for semantic image segmentation</article-title>,” in <source specific-use="IEEE">Proc. IEEE Eur. Conf. Comput. Vis.</source>, <year>2018</year>, pp. <fpage>801</fpage>–<lpage>818</lpage>.</mixed-citation>
    </ref>
    <ref id="ref50">
      <label>[50]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>J.</given-names><surname>Redmon</surname></string-name> and <string-name><given-names>A.</given-names><surname>Farhadi</surname></string-name></person-group>, “<article-title>Yolo9000: Better, faster, stronger</article-title>,” in <source specific-use="IEEE">Proc. IEEE Conf. Comput. Vis. Pattern Recognit.</source>, <year>2017</year>, pp. <fpage>7263</fpage>–<lpage>7271</lpage>.</mixed-citation>
    </ref>
    <ref id="ref51">
      <label>[51]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>W.</given-names><surname>Liu</surname></string-name></person-group><etal/>, “<article-title>SSD: Single shot multibox detector</article-title>,” in <source specific-use="IEEE">Proc. IEEE Eur. Conf. Comput. Vis.</source>, <year>2016</year>, pp. <fpage>21</fpage>–<lpage>37</lpage>.</mixed-citation>
    </ref>
    <ref id="ref52">
      <label>[52]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>He</surname></string-name>, <string-name><given-names>G.</given-names><surname>Gkioxari</surname></string-name>, <string-name><given-names>P.</given-names><surname>Dollár</surname></string-name>, and <string-name><given-names>R.</given-names><surname>Girshick</surname></string-name></person-group>, “<article-title>Mask r-cnn</article-title>,” in <source specific-use="IEEE">Proc. IEEE Int. Conf. Comput. Vis.</source>, <year>2017</year>, pp. <fpage>2961</fpage>–<lpage>2969</lpage>.</mixed-citation>
    </ref>
    <ref id="ref53">
      <label>[53]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>P. F</given-names><surname>Felzenszwalb</surname></string-name>, <string-name><given-names>R. B</given-names><surname>Girshick</surname></string-name>, <string-name><given-names>D.</given-names><surname>McAllester</surname></string-name>, and <string-name><given-names>D.</given-names><surname>Ramanan</surname></string-name></person-group>, “<article-title>Object detection with discriminatively trained part-based models</article-title>,” <source specific-use="IEEE">IEEE Trans. Pattern Anal. Mach. Intell.</source>, vol. <volume>32</volume>, no. <issue>9</issue>, pp. <fpage>1627</fpage>–<lpage>1645</lpage>, <season>Sep.</season>
<year>2010</year>.<pub-id pub-id-type="pmid">20634557</pub-id></mixed-citation>
    </ref>
    <ref id="ref54">
      <label>[54]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>R.</given-names><surname>Girshick</surname></string-name>, <string-name><given-names>J.</given-names><surname>Donahue</surname></string-name>, <string-name><given-names>T.</given-names><surname>Darrell</surname></string-name>, and <string-name><given-names>J.</given-names><surname>Malik</surname></string-name></person-group>, “<article-title>Rich feature hierarchies for accurate object detection and semantic segmentation</article-title>,” in <source specific-use="IEEE">Proc. IEEE Conf. Comput. Vis. Pattern Recognit.</source>, <year>2014</year>, pp. <fpage>580</fpage>–<lpage>587</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
