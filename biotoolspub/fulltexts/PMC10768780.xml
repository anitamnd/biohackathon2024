<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Brief Bioinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Brief Bioinform</journal-id>
    <journal-id journal-id-type="publisher-id">bib</journal-id>
    <journal-title-group>
      <journal-title>Briefings in Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1467-5463</issn>
    <issn pub-type="epub">1477-4054</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10768780</article-id>
    <article-id pub-id-type="doi">10.1093/bib/bbad476</article-id>
    <article-id pub-id-type="publisher-id">bbad476</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Problem Solving Protocol</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>H2Opred: a robust and efficient hybrid deep learning model for predicting 2’-O-methylation sites in human RNA</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8086-6722</contrib-id>
        <name>
          <surname>Pham</surname>
          <given-names>Nhat Truong</given-names>
        </name>
        <!--truongpham96@skku.edu-->
        <aff><institution>Department of Integrative Biotechnology, College of Biotechnology and Bioengineering, Sungkyunkwan University</institution>, <addr-line>Suwon, 16419</addr-line>, <country country="KR">Republic of Korea</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rakkiyapan</surname>
          <given-names>Rajan</given-names>
        </name>
        <!--rakkiyappan.maths@buc.edu.in-->
        <aff><institution>Department of Mathematics, Bharathiar University</institution>, <addr-line>Coimbatore - 641046, Tamil Nadu</addr-line>, <country country="IN">India</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Park</surname>
          <given-names>Jongsun</given-names>
        </name>
        <!--starflr@infoboss.co.kr-->
        <aff><institution>InfoBoss inc. and InfoBoss Research Center, Gangnam-gu</institution>, <addr-line>Seoul 06278</addr-line>, <country country="KR">Republic of Korea</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Malik</surname>
          <given-names>Adeel</given-names>
        </name>
        <!--adeel@procarb.org-->
        <aff><institution>Institute of Intelligence Informatics Technology, Sangmyung University</institution>, <addr-line>Seoul, 03016</addr-line>, <country country="KR">Republic of Korea</country></aff>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-0697-9419</contrib-id>
        <name>
          <surname>Manavalan</surname>
          <given-names>Balachandran</given-names>
        </name>
        <!--bala2022@skku.edu-->
        <aff><institution>Department of Integrative Biotechnology, College of Biotechnology and Bioengineering, Sungkyunkwan University</institution>, <addr-line>Suwon, 16419</addr-line>, <country country="KR">Republic of Korea</country></aff>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="cor1">Corresponding authors. Adeel Malik, Institute of Intelligence Informatics Technology, 20, Hongjimun 2-gil, Jongno-gu, Seoul, Republic of Korea. Tel.: 02-2287-5288; Fax: 02-2287-0070; E-mail: <email>adeel@procarb.org</email>; Balachandran Manavalan, Department of Integrative Biotechnology, College of Biotechnology and Bioengineering, Sungkyunkwan University, Suwon 16419, Gyeonggi-do, Republic of Korea. Tel.: +82-31-299-4858; Fax: +82-31-290-7870; E-mail: <email>bala2022@skku.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2024-01-04">
      <day>04</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>04</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <volume>25</volume>
    <issue>1</issue>
    <elocation-id>bbad476</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>22</day>
        <month>11</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>28</day>
        <month>11</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2024</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="bbad476.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>2’-O-methylation (2OM) is the most common post-transcriptional modification of RNA. It plays a crucial role in RNA splicing, RNA stability and innate immunity. Despite advances in high-throughput detection, the chemical stability of 2OM makes it difficult to detect and map in messenger RNA. Therefore, bioinformatics tools have been developed using machine learning (ML) algorithms to identify 2OM sites. These tools have made significant progress, but their performances remain unsatisfactory and need further improvement. In this study, we introduced H2Opred, a novel hybrid deep learning (HDL) model for accurately identifying 2OM sites in human RNA. Notably, this is the first application of HDL in developing four nucleotide-specific models [adenine (A2OM), cytosine (C2OM), guanine (G2OM) and uracil (U2OM)] as well as a generic model (N2OM). H2Opred incorporated both stacked 1D convolutional neural network (1D-CNN) blocks and stacked attention-based bidirectional gated recurrent unit (Bi-GRU-Att) blocks. 1D-CNN blocks learned effective feature representations from 14 conventional descriptors, while Bi-GRU-Att blocks learned feature representations from five natural language processing-based embeddings extracted from RNA sequences. H2Opred integrated these feature representations to make the final prediction. Rigorous cross-validation analysis demonstrated that H2Opred consistently outperforms conventional ML-based single-feature models on five different datasets. Moreover, the generic model of H2Opred demonstrated a remarkable performance on both training and testing datasets, significantly outperforming the existing predictor and other four nucleotide-specific H2Opred models. To enhance accessibility and usability, we have deployed a user-friendly web server for H2Opred, accessible at <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>. This platform will serve as an invaluable tool for accurately predicting 2OM sites within human RNA, thereby facilitating broader applications in relevant research endeavors.</p>
    </abstract>
    <kwd-group>
      <kwd>2’-O-methylation sites</kwd>
      <kwd>convolutional neural network</kwd>
      <kwd>gated recurrent unit</kwd>
      <kwd>hybrid deep learning</kwd>
      <kwd>bioinformatics</kwd>
      <kwd>natural language processing</kwd>
    </kwd-group>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Research Foundation of Korea</institution>
            <institution-id institution-id-type="DOI">10.13039/501100003725</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Ministry of Science and ICT</institution>
            <institution-id institution-id-type="DOI">10.13039/501100014188</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>2021R1A2C1014338</award-id>
        <award-id>2021R1I1A1A01056363</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Korea Health Technology R&amp;D Project</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Korea Health Industry Development Institute</institution>
            <institution-id institution-id-type="DOI">10.13039/501100003710</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Ministry of Health and Welfare</institution>
            <institution-id institution-id-type="DOI">10.13039/100008903</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>HI23C0701</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="13"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec3">
    <title>INTRODUCTION</title>
    <p>The epitranscriptome involves chemical modification to messenger RNA (mRNA), influencing gene expression [<xref rid="ref1" ref-type="bibr">1</xref>]. While current epitranscriptome research has focused on base modifications, the ribose sugar can also be methylated at the 2′ position to form 2’-O-methylated nucleotides (2OM) [<xref rid="ref2" ref-type="bibr">2</xref>]. 2OM has been found in all types of RNA, including mRNA, ribosomal RNA (rRNA), transfer RNA (tRNA), micro RNA (miRNA), small nucleolar RNA (snoRNA) and PIWI-interacting RNA (piRNA) [<xref rid="ref3" ref-type="bibr">3</xref>]. The process of 2OM can be achieved through two distinct enzymatic routes: standalone methyltransferases and RNA-protein complex guided by Box C/D snoRNA, known as C/D-box snoRNPs. Standalone methyltransferases recognize their targets based on sequence and shape, while C/D-box snoRNPs are guided to their targets by snoRNAs [<xref rid="ref4" ref-type="bibr">4–6</xref>]. Consequently, 2OM can occur in all four canonical nucleotides (adenine, cytosine, guanine and uracil) and some non-standard nucleotides.</p>
    <p>Recent studies have shown that 2OM not only stabilized RNA but also involved in regulating gene expression and other cellular processes. For example, 2OM in RNA can be used by the innate immune system to distinguish between internal and external mRNA [<xref rid="ref6" ref-type="bibr">6</xref>]. HIV-1 evades detection by the MDA5 protein using the TRBP-FTSJ3 complex to add 2OM to its RNA [<xref rid="ref7" ref-type="bibr">7</xref>]. In human monocytes, 2OM RNA can suppress the release of pro-inflammatory cytokines [<xref rid="ref8" ref-type="bibr">8</xref>]. In yeast, specific 2OM sites in telomerase RNA affect how well telomerase functions [<xref rid="ref9" ref-type="bibr">9</xref>]. 2OM is also important for antibiotic resistance and cancer. However, much remains to be learned about the full range of roles that 2OM plays in RNA. Identifying 2OM sites in RNA is essential for understanding its functional significance, which is one of the important research topics in the community.</p>
    <p>Several experimental methods have been developed to accurately identify 2OM in RNA. These methods include perchloric acid (HClO4) hydrolysis, periodate oxidation hydrolysis, chromatography and mass spectrometry. However, these methods are labor-intensive, need specialized tools, can damage RNA samples and are challenging to use with minimal RNA. To overcome these limitations, high-throughput techniques based on deep sequencing have also been developed, such as Nm-seq [<xref rid="ref10" ref-type="bibr">10</xref>], RiboMeth-seq [<xref rid="ref11" ref-type="bibr">11</xref>], 2OMe-seq [<xref rid="ref12" ref-type="bibr">12</xref>], RibOxi-Seq [<xref rid="ref13" ref-type="bibr">13</xref>] and Nm-seq (a) [<xref rid="ref14" ref-type="bibr">14</xref>]. While these methods can identify 2OM at the transcriptome level, they are still costly, time-consuming and require specialized expertise. Therefore, computational methods have been developed to complement the experimental methods.</p>
    <p>Sun <italic toggle="yes">et al</italic>. [<xref rid="ref15" ref-type="bibr">15</xref>] developed RMBase, a database that contained 18 independent high-throughput sequencing data for studying RNA post-transcriptional modifications. The updated version, RMBase v2.0 [<xref rid="ref16" ref-type="bibr">16</xref>], contains data on 5096 2OM positions across three species, a significant increase from its predecessor’s 1209 entries. These databases serve as the foundation for developing computational methods to identify 2OM sites. Chen <italic toggle="yes">et al</italic>. [<xref rid="ref17" ref-type="bibr">17</xref>] constructed the first benchmarking dataset based on RMBase and developed a support vector machine (SVM)-based predictor. Using the same dataset, three more methods were proposed: iRNA-2OM [<xref rid="ref18" ref-type="bibr">18</xref>], identification of RNA 2OM using pseudo k-tuple nucleotide composition (iRNA-PseKNC(2methyl)) [<xref rid="ref19" ref-type="bibr">19</xref>] and an ensemble model by Huang <italic toggle="yes">et al</italic>. [<xref rid="ref20" ref-type="bibr">20</xref>]. Later, Zhou’s group developed two tools, NmSEER [<xref rid="ref21" ref-type="bibr">21</xref>] and NmSEER V2.0 [<xref rid="ref22" ref-type="bibr">22</xref>], based on different approaches and datasets. Li <italic toggle="yes">et al</italic>. [<xref rid="ref23" ref-type="bibr">23</xref>] proposed DeepOMe based on convolutional neural network (CNN) and bidirectional long short-term memory (Bi-LSTM) layers. Ao <italic toggle="yes">et al.</italic> [<xref rid="ref24" ref-type="bibr">24</xref>] developed NmRF using Chen’s dataset and RMBase v2.0, which achieved an excellent performance on three species. Yang <italic toggle="yes">et al</italic>. [<xref rid="ref25" ref-type="bibr">25</xref>] introduced i2OM by constructing a larger dataset based on <italic toggle="yes">Homo sapiens.</italic> Their study showed better performance using conventional machine learning (ML) approaches and two-step feature selection techniques. While these methods have made significant contributions to the field, there is still room for improvement.</p>
    <p>In this study, we introduced H2Opred, a novel hybrid deep learning (HDL) model, for accurately identifying 2OM sites. Remarkably, this is the first application of HDL in developing nucleotide-specific models [adenine (A2OM), cytosine (C2OM), guanine (G2OM) and uracil (U2OM)] as well as a generic model that integrated all nucleotide-specific datasets (N2OM). H2Opred included all these five models, each of which has been trained in a similar fashion. H2Opred leveraged a set of 14 conventional descriptors, encompassing binary profile features (BPF), nucleotide chemical properties (NCP), dinucleotide binary encoding (DBE), as well as type 1 and type 2 dinucleotide physicochemical properties (DPCP_1, DPCP_2), positional specifics of two nucleotides (PS2), Kmer, reverse complement Kmer patterns (RCKmer), electron–ion interaction pseudo potentials of trinucleotides (PseEIIP), composition of k-spaced nucleic acid pairs (CKSNAP), enhanced nucleic acid composition (ENAC), Z curve parameters capturing frequencies of phase-specific trinucleotides (Zcurve), a novel combination of adaptive skip dinucleotide composition with local position-specific dinucleotide frequency (ASLPN) and multivariate mutual information combined with accumulated nucleotide frequency (MMNF). Additionally, five natural language processing (NLP)-based embeddings, including the DNA-language model (DNABERT), sequence-to-vector (Seq2Vec), word-to-vector (Word2Vec), FastText and global vectors for word representation (GloVe), were utilized. All of these descriptors and embeddings were directly extracted from RNA sequences. H2Opred incorporated both stacked 1D convolutional neural network (1D-CNN) blocks and stacked attention-based bidirectional gated recurrent unit (Bi-GRU-Att) blocks to learn effective feature representations from 14 conventional descriptors and five NLP-based embeddings, respectively. These feature representations were then combined to make the final prediction. Ablation analysis showed that both 1D-CNN and Bi-GRU-Att blocks were essential for H2Opred’s optimal performance. The H2Opred models exhibited outstanding performance during cross-validation and independent testing, surpassing the capabilities of large-scale conventional ML-based single-feature models. Notably, the generic H2Opred model outperformed both the existing predictor and the four nucleotide-specific H2Opred models, demonstrating that the intelligent integration of conventional descriptors and pretrained model-based embeddings extracted from a large training dataset through HDL enhances both prediction accuracy and interpretability.</p>
  </sec>
  <sec id="sec4">
    <title>MATERIALS AND METHODS</title>
    <sec id="sec5">
      <title>Dataset</title>
      <p>We used the same benchmark dataset proposed by Yang <italic toggle="yes">et al</italic>. [<xref rid="ref25" ref-type="bibr">25</xref>], because it is the most recent, comprehensive and non-redundant dataset available. The authors obtained 2OM sites from two different sources: RMBase v2.0 [<xref rid="ref16" ref-type="bibr">16</xref>] and the recent experimental dataset generated by Nm-seq [<xref rid="ref10" ref-type="bibr">10</xref>] and deposited in the GEO database (GSE90164). In total, they obtained 7597 2OM sites distributed in CDS, 3’-UTR, 5’-UTR, intron, exon and intergenic regions, and containing almost all types of RNA (tRNAs, rRNAs, scRNAs, scaRNAs, snRNAs, snoRNAs, lincRNAs, protein-coding genes, pseudogenes, etc.). Since the majority of sequences from RMBase v2.0 have a sequence length of 41 bp (20 upstream and 20 downstream based with the center 2OM sites), the authors extracted the same sequence length from the experimental data. To generate negative samples, the authors employed the same strategies as previous studies and generated a large number of sequences. Subsequently, they applied CD-HIT [<xref rid="ref26" ref-type="bibr">26</xref>] with a threshold of 80% to remove redundant sequences, resulting in 6091 positive samples and 21 520 negative samples. To address class bias, which is a common problem when developing prediction models with imbalanced datasets [<xref rid="ref27" ref-type="bibr">27</xref>], the authors selected the same number of negative samples as positive samples. The authors then divided the dataset into four subsets, centered on A, U, C and G corresponding to A2OM, U2OM, C2OM and G2OM, respectively. The A2OM dataset contains 2176 training and 934 testing samples, the U2OM dataset contains 2236 training and 960 testing samples, the C2OM dataset contains 2278 training and 788 testing samples and the G2OM dataset contains 1832 training and 788 testing samples. Notably, all training and testing samples contain an equal number of positive and negative samples. It should be noted that we have used the same training datasets for the model development in this study. However, we used entirely different testing datasets to check the model transferability. Specifically, we supplemented the existing nucleotide-specific testing datasets with our own collections. Positive samples were collected from RMDisease v2.0 [<xref rid="ref28" ref-type="bibr">28</xref>], and excluded the redundant samples, resulting in 34, 82, 12 and 173 positive samples for A2OM, C2OM, G2OM and U2OM, respectively. Regarding the negative samples, we considered all possible chromosomes in <italic toggle="yes">H. sapiens</italic> and selected sequences with four different nucleotide bases as central residues, flanked by 20 nucleotides both upstream and downstream. From these, we randomly chose samples 10-fold larger in number than positive samples. Importantly, newly constructed samples were not present in the existing training and the testing datasets. Finally, we obtained 501 positive and 5010 negative samples for A2OM, 571 positive and 5710 negative samples for C2OM, 406 positive and 4060 negative samples for G2OM and 653 positive and 6530 negative samples for U2OM.</p>
    </sec>
    <sec id="sec6">
      <title>Feature extraction</title>
      <p>We used 14 conventional descriptors and five NLP-based embeddings to represent RNA sequences. The conventional descriptors covered different properties of sequence information and were widely used in bioinformatics [<xref rid="ref18" ref-type="bibr">18</xref>, <xref rid="ref29" ref-type="bibr">29</xref>, <xref rid="ref30" ref-type="bibr">30</xref>]. The NLP-based embeddings were trained on large datasets of DNA and RNA sequences to capture their linguistic features. The conventional descriptors included Kmer, BPF, NCP, DBE, DPCP_1, DPCP_2, PS2, RCKmer, PseEIIP, CKSNAP, ENAC, Zcurve, ASLPN and MMNF. The NLP-based embeddings included DNABERT, Seq2Vec, Word2vec, FastText and GloVe. A detailed description of these descriptors and embeddings is provided in the supplementary information.</p>
    </sec>
    <sec id="sec7">
      <title>Framework of H2Opred</title>
      <p>In this study, we proposed an HDL model to predict 2OM sites in human RNA sequences (<xref rid="f1" ref-type="fig">Figure 1</xref>). The HDL model consisted of stacked 1D-CNN blocks and stacked Bi-GRU-Att blocks, which learned and extracted both spatial and temporal-sequential feature representations from conventional descriptors and NLP-based embeddings. The details of these blocks are presented below.</p>
      <fig position="float" id="f1">
        <label>Figure 1</label>
        <caption>
          <p>The workflow of constructing H2Opred framework. (A) Four 2’-O-methylation (2OM) site types were collected and split into training and independent datasets, where the combined dataset was constructed by integrating all four 2OM site types together as well as removing redundancy and identical samples. (B) Subsequently, 14 conventional descriptors and five NLP-based embeddings were extracted and then fed into stacked convolutional neural network (1D-CNN) blocks and stacked attention-based bidirectional gated recurrent unit (Bi-GRU-Att) blocks to acquire spatial and temporal-sequential feature representations for final prediction model. (C) During the testing phase, the testing datasets were submitted to the web server, resulting in either 2OM or non-2OM sites. (Created with <ext-link xlink:href="http://www.biorender.com" ext-link-type="uri">BioRender.com</ext-link>).</p>
        </caption>
        <graphic xlink:href="bbad476f1" position="float"/>
      </fig>
    </sec>
    <sec id="sec8">
      <title>Stacked 1D-CNN</title>
      <p>To extract and learn the spatial feature representations from the RNA sequences, we designed a 1D-CNN block for each conventional descriptor. Inspired by the stacking CNN approach utilized in recent studies [<xref rid="ref31" ref-type="bibr">31–34</xref>], we developed 14 1D-CNN blocks and integrated them to handle the 14 conventional descriptors. Each 1D-CNN block consisted of three 1D convolutional (Conv1D) layers, three max pooling layers and one fully connected (FC) layer at the end. Given an input <inline-formula><tex-math notation="LaTeX" id="ineq01">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X{c}_{in}$\end{document}</tex-math></inline-formula> of (<inline-formula><tex-math notation="LaTeX" id="ineq02">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$B,{L}_{in},{C}_{in}$\end{document}</tex-math></inline-formula>), Conv1D will obtain an output <inline-formula><tex-math notation="LaTeX" id="ineq03">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X{c}_{out}$\end{document}</tex-math></inline-formula> of (<inline-formula><tex-math notation="LaTeX" id="ineq04">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$B,{L}_{out},{C}_{out}$\end{document}</tex-math></inline-formula>) as follows:</p>
      <disp-formula id="deqn01">
        <label>(1)</label>
        <tex-math notation="LaTeX" id="DmEquation1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} X{c}_{ou t}\left(B,{C}_{{ou t}_j}\right)= bc+\sum \limits_{k=0}^{C_{in}-1} Wc\left({C}_{ou{t}_j},k\right)\ast X{c}_{in}\left(B,k\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq05">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\ast$\end{document}</tex-math></inline-formula> denote the cross-correlation operation, <inline-formula><tex-math notation="LaTeX" id="ineq06">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$Wc$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq07">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$bc$\end{document}</tex-math></inline-formula> are weight and bias, <inline-formula><tex-math notation="LaTeX" id="ineq08">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$B$\end{document}</tex-math></inline-formula> is the batch size, <inline-formula><tex-math notation="LaTeX" id="ineq09">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${L}_{in}$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${C}_{in}$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${L}_{out}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq12">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${C}_{out}$\end{document}</tex-math></inline-formula> are the input length, the number of the input channels, output length and the number of the output channels, respectively, in which <inline-formula><tex-math notation="LaTeX" id="ineq13">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${L}_{out}$\end{document}</tex-math></inline-formula> can be computed as follows:</p>
      <disp-formula id="deqn02">
        <label>(2)</label>
        <tex-math notation="LaTeX" id="DmEquation2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {L}_{out}=1+\frac{L_{in}+2P-D\left(k-1\right)-1}{S}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq14">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$P$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq15">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$D$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq16">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\kappa$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq17">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$S$\end{document}</tex-math></inline-formula> are the padding size, dilation rate, kernel size and stride, respectively. Then, each Conv1D layer was passed through a ReLU (rectified linear unit) activation function, which can be defined as follows:</p>
      <disp-formula id="deqn03">
        <label>(3)</label>
        <tex-math notation="LaTeX" id="DmEquation3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} \mathrm{ReLU}(x)=\max \left(0,x\right). \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>To achieve dimensional reduction, we incorporated one max pooling layer immediately after each Conv1D layer. The operation of each max pooling layer is outlined as follows:</p>
      <disp-formula id="deqn04">
        <label>(4)</label>
        <tex-math notation="LaTeX" id="DmEquation4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} X{m}_{out}\left(B,{C}_j,k\right)=\underset{p=0,...,\kappa -1}{\max }X{m}_{in}\left(B,{C}_j,S\times k+p\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq18">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X{m}_{in}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq19">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X{m}_{out}$\end{document}</tex-math></inline-formula> are the input and output of the max pooling layer. It should be noted that only the length of the output changed after applying the max pooling layer. Finally, the feature representations were flattened and fed into an FC layer to produce the final feature representations. In addition, a dropout layer was applied after flattening the features to prevent overfitting. The configuration of each stacked 1D-CNN block was described in detail in the optimization process section.</p>
    </sec>
    <sec id="sec9">
      <title>Stacked Bi-GRU-Att</title>
      <p>To extract the temporal-sequential information from RNA sequences, we designed a Bi-GRU-Att block to capture temporal-sequential feature representations from each of five NLP-based embeddings extracted from RNA sequences. It should be noted that Bi-GRU was chosen over a single GRU because it can capture temporal-sequential feature representations in both the forward and backward directions of the sequence, resulting in more robust and informative feature representations. Additionally, Bi-GRU architecture was selected over LSTM or Bi-LSTM because it is simple and has fewer output gates, making it faster and more effective to train, especially with limited data. To address the challenge of not every feature representation equally informative for characterizing RNA sequence, we incorporated an attention mechanism [<xref rid="ref35" ref-type="bibr">35–38</xref>] to selectively focus on the most relevant and crucial feature representations for discriminating 2OM sites. The mathematical equations of each GRU can be expressed as follows:</p>
      <disp-formula id="deqn05">
        <label>(5)</label>
        <tex-math notation="LaTeX" id="DmEquation5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {u}_t=\sigma \left({W}_{iu}{x}_t+{U}_{hu}{h}_{\left(t-1\right)}+{b}_{iu}+{b}_{hu}\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn06">
        <label>(6)</label>
        <tex-math notation="LaTeX" id="DmEquation6">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {r}_t=\sigma \left({W}_{ir}{x}_t+{U}_{hr}{h}_{\left(t-1\right)}+{b}_{ir}+{b}_{hr}\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn07">
        <label>(7)</label>
        <tex-math notation="LaTeX" id="DmEquation7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} \qquad\quad{\tilde{\eta}}_t=\tau \left({W}_{i\tilde{\eta}}{x}_t+{r}_t\odot \left({U}_{h\tilde{\eta}}{h}_{\left(t-1\right)}+{b}_{h\tilde{\eta}}\right)+{b}_{i\tilde{\eta}}\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn08">
        <label>(8)</label>
        <tex-math notation="LaTeX" id="DmEquation8">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {h}_t=\left(1-{u}_t\right)\odot{\tilde{\eta}}_t+{u}_t\odot{h}_{\left(t-1\right)},\qquad\quad \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq20">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${u}_t$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq21">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${r}_t$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq22">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\tilde{\eta}}_t$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq23">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${h}_t$\end{document}</tex-math></inline-formula> represent the update gate, the reset gate, the new gate (or the hidden candidate status) and the hidden gate, respectively; <inline-formula><tex-math notation="LaTeX" id="ineq24">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${x}_t$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq25">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$W$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq26">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$U$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq27">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$b$\end{document}</tex-math></inline-formula> are the input vectors, the weight matrices and the bias vector; <inline-formula><tex-math notation="LaTeX" id="ineq28">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\sigma$\end{document}</tex-math></inline-formula> denotes the sigmoid function, <inline-formula><tex-math notation="LaTeX" id="ineq29">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\tau$\end{document}</tex-math></inline-formula> denotes the tanh function and <inline-formula><tex-math notation="LaTeX" id="ineq30">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\odot$\end{document}</tex-math></inline-formula> denotes the Hadamard product.</p>
      <p>And the mathematical equations of attention mechanism can be defined as follows:</p>
      <disp-formula id="deqn09">
        <label>(9)</label>
        <tex-math notation="LaTeX" id="DmEquation9">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {A}_{ij}={x}_a^T\tau \left({W}_a{h}_i+b\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn10">
        <label>(10)</label>
        <tex-math notation="LaTeX" id="DmEquation10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {\alpha}_{ij}=\frac{e^{\left({A}_{ij}\right)}}{\sum \limits_{t=1}^T{e}^{\left({A}_{ij}\right)}},\qquad\ \ \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn11">
        <label>(11)</label>
        <tex-math notation="LaTeX" id="DmEquation11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {c}_i=\sum \limits_{j=1}^T{\alpha}_{ij}{h}_j, \qquad\ \ \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq31">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${x}_a$\end{document}</tex-math></inline-formula> is the random initialization vector, <inline-formula><tex-math notation="LaTeX" id="ineq32">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${A}_{ij}$\end{document}</tex-math></inline-formula> is the attention weight, <inline-formula><tex-math notation="LaTeX" id="ineq33">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${h}_i=\left[{\overrightarrow{h}}_t;{\overleftarrow{h}}_t\right]$\end{document}</tex-math></inline-formula> is the output of Bi-GRU at the time step <inline-formula><tex-math notation="LaTeX" id="ineq34">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t$\end{document}</tex-math></inline-formula> that concatenates both forward and backward information, <inline-formula><tex-math notation="LaTeX" id="ineq35">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$T=41$\end{document}</tex-math></inline-formula> is the length of the input sequence, <inline-formula><tex-math notation="LaTeX" id="ineq36">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\alpha}_{ij}$\end{document}</tex-math></inline-formula> is the output score of the attention weight by applying SoftMax function and <inline-formula><tex-math notation="LaTeX" id="ineq37">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${c}_i$\end{document}</tex-math></inline-formula> is the attention output.</p>
      <p>Motivated by the stacking recurrent neural network-based approaches employed in recent studies [<xref rid="ref39" ref-type="bibr">39</xref>, <xref rid="ref40" ref-type="bibr">40</xref>], we developed five Bi-GRU-Att blocks that were subsequently combined to handle the five NLP-bassed embeddings. Notably, each Bi-GRU-Att block contained two Bi-GRU layers, followed by an attention layer and an FC layer. The hidden state generated by the first Bi-GRU layer was used as the input of the second Bi-GRU layer. For more details on the specific configuration of the Bi-GRU-Att blocks, please refer to the optimization process section.</p>
    </sec>
    <sec id="sec10">
      <title>Optimization process of H2Opred</title>
      <p>We conducted a comprehensive optimization process to select the best model for constructing H2Opred. <xref rid="sup1" ref-type="supplementary-material">Table S1</xref> represents our parameter search range implemented in this study. Importantly, we used 5-fold cross-validation during the training phase to tune the hyperparameters within the specified search range and determine the optimal set of hyperparameters.</p>
      <p>Here, the binary cross-entropy loss function (<inline-formula><tex-math notation="LaTeX" id="ineq38">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${L}_{BCE}$\end{document}</tex-math></inline-formula>) was used as an objective function to optimize the parameters during training model, which can be defined as follows:</p>
      <disp-formula id="deqn12">
        <label>(12)</label>
        <tex-math notation="LaTeX" id="DmEquation12">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {L}_{BCE}=\frac{1}{N_s}\sum \limits_{s=1}^{N_s}{y}_s\log \left(\wp \left({\hat{y}}_s\right)\right)+\left(1-{y}_s\right)\log \left(1-\wp \left({\hat{y}}_s\right)\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq39">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${N}_s$\end{document}</tex-math></inline-formula> is the number of samples, <inline-formula><tex-math notation="LaTeX" id="ineq40">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$s=\mathrm{1...}{N}_s$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq41">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${y}_s$\end{document}</tex-math></inline-formula> is the ground truth label and <inline-formula><tex-math notation="LaTeX" id="ineq42">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\hat{y}}_s$\end{document}</tex-math></inline-formula> is the predicted label. In addition, it should be noted that <inline-formula><tex-math notation="LaTeX" id="ineq43">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\wp \left({\hat{y}}_s\right)$\end{document}</tex-math></inline-formula> represents the probability of 2OM and <inline-formula><tex-math notation="LaTeX" id="ineq44">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$1-\wp \left({\hat{y}}_s\right)$\end{document}</tex-math></inline-formula> represents the probability of non-2OM.</p>
    </sec>
    <sec id="sec11">
      <title>Performance evaluation metrics</title>
      <p>In this study, several commonly used performance evaluation metrics [<xref rid="ref41" ref-type="bibr">41–43</xref>] were utilized to evaluate the model performance during training, independent testing as well as comparison, which included accuracy (ACC), Mathews correlation coefficient (MCC), sensitivity (Sn), specificity (Sp), precision (PRE), area under the receiver operating characteristic curve (AUC) and F1-score. Their mathematical equations can be expressed as follows:</p>
      <disp-formula id="deqn13">
        <label>(13)</label>
        <tex-math notation="LaTeX" id="DmEquation13">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} ACC=\frac{TP+ TN}{TP+ TN+ FP+ FN}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn14">
        <label>(14)</label>
        <tex-math notation="LaTeX" id="DmEquation14">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} MCC=\frac{TP\times TN- FP\times FN}{\sqrt{\left( TP+ FP\right)\times \left( TP+ FN\right)\times \left( TN+ FP\right)\times \left( TN+ FN\right)}}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn15">
        <label>(15)</label>
        <tex-math notation="LaTeX" id="DmEquation15">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} Sn=\frac{TP}{TP+ FN}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn16">
        <label>(16)</label>
        <tex-math notation="LaTeX" id="DmEquation16">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} Sp=\frac{TN}{TN+ FP}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn17">
        <label>(17)</label>
        <tex-math notation="LaTeX" id="DmEquation17">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} PRE=\frac{TP}{TP+ FP}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn18">
        <label>(18)</label>
        <tex-math notation="LaTeX" id="DmEquation18">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} F1- score=\frac{2\times TP}{2\times TP+ FP+ FN}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where TP represents the count of test results that correctly match with positive samples, TN represents the count of test results that correctly match with negative samples, FP stands for the count of test results that incorrectly indicate positive samples and FN denotes the count of test results that incorrectly indicate negative samples.</p>
    </sec>
  </sec>
  <sec id="sec12">
    <title>RESULTS AND DISCUSSION</title>
    <sec id="sec13">
      <title>Assessment of conventional descriptors using 11 different ML algorithms on the training and independent testing datasets</title>
      <p>Inspired by previous studies [<xref rid="ref29" ref-type="bibr">29</xref>, <xref rid="ref44" ref-type="bibr">44</xref>], we evaluated 14 conventional RNA sequence descriptors that capture different aspects of sequence information, such as composition, position-specific, physicochemical properties and sequence order. To quantify the intrinsic capability of these feature descriptors for distinguishing 2OM from non-2OM in different datasets, we evaluated the performance of each descriptor using 11 conventional ML-based classifiers (including random forest (RF), extremely randomized trees (ERT), gradient boosting trees (GBT), AdaBoost trees (ABT), extreme GBT (XGBT), SVM, deep neural network (DNN), light GBT (LGBT), decision trees (DT), logistic regression (LR) and catBoost (CB)) by means of randomized 10-fold cross-validation procedure. This technique helps to prevent model overfitting during training [<xref rid="ref45" ref-type="bibr">45</xref>, <xref rid="ref46" ref-type="bibr">46</xref>].</p>
      <p>In total, we generated 616 models (154 models * 4 datasets) during the training and assessed its transferability with the independent testing datasets (<xref rid="sup1" ref-type="supplementary-material">Figures S1</xref>–<xref rid="sup1" ref-type="supplementary-material">S4</xref>). We were more interested in the discriminative capability of the feature descriptors than in the performance of any specific classifier. To get an overview of how well each descriptor performed, we averaged the ACC of the 11 classifiers-based models trained on each descriptor and the results were shown in <xref rid="f2" ref-type="fig">Figure 2A</xref>. All of these descriptors achieved reasonable performance on the A2OM, C2OM and G2OM datasets, with average ACC in the ranges of 0.768–0.844, 0.747–0.825 and 0.755–0.826, respectively. However, the performance on the U2OM dataset was significantly lower, with average ACC in the range of 0.674–0.711. After evaluating the performance of 616 models on the independent testing datasets (<xref rid="f2" ref-type="fig">Figure 2B</xref>), we observed that the average performance of each descriptor on the independent testing datasets was similar to that on the training datasets, with the U2OM dataset being the most challenging dataset. Specifically, the average ACC of the descriptors on the independent testing datasets ranged from 0.752 to 0.885 for A2OM, 0.736 to 0.877 for C2OM, 0.751 to 0.863 for G2OM and 0.695 to 0.791 for U2OM. Out of the 14 descriptors, DPCP_2, Kmer and PS2 performed the best on the training datasets, with ACC of 0.837–0.844 for A2OM, 0.822–0.825 for C2OM and 0.815–0.826 for G2OM. Notably, DPCP_2 and PS2 maintained a similar level of performance on the corresponding testing datasets. Since each of the descriptors captures different aspects of sequence information, we included all 14 conventional descriptors in the construction of an HDL framework.</p>
      <fig position="float" id="f2">
        <label>Figure 2</label>
        <caption>
          <p>Average accuracy (ACC) achieved by 11 conventional ML-based classifiers for each of the 14 conventional descriptors. The comparative performance of four nucleotide-specific models is shown for training datasets (A) and testing datasets (B).</p>
        </caption>
        <graphic xlink:href="bbad476f2" position="float"/>
      </fig>
    </sec>
    <sec id="sec14">
      <title>Evaluation of H2Opred for 2OM site prediction on the training and independent testing datasets</title>
      <p>H2Opred was constructed using an HDL approach (see Materials and methods section). This approach combined stacked 1D-CNN blocks to learn effective feature representations from 14 conventional descriptors, and stacked Bi-GRU-Att blocks to learn feature representations from five NLP-based embeddings. These feature representations were then combined to make the final prediction. <xref rid="f3" ref-type="fig">Figure 3</xref> compares the performance of H2Opred with two individual approaches, 1D-CNN and Bi-GRU-Att. Among the 1D-CNN and Bi-GRU-Att models, 1D-CNN achieved consistently better performance on four training datasets, with improvement in MCCs of 0.09%, 1.60%, 2.60% and 0.06% for A2OM, C2OM, G2OM and U2OM, respectively. When combining these two models, H2Opred achieved MCC and ACC of 0.762 and 0.881 in A2OM, 0.732 and 0.865 in C2OM, 0.715 and 0.856 in G2OM and 0.603 and 0.801 in U2OM. Specifically, H2Opred outperformed 1D-CNN on three training datasets (A2OM, C2OM and G2OM), and achieved similar performance on the U2OM dataset. Overfitting occurs when the ML model learns the training data too well, and is unable to generalize to new data. To avoid overfitting, it is important to evaluate the model’s performance on the independent testing datasets.</p>
      <fig position="float" id="f3">
        <label>Figure 3</label>
        <caption>
          <p>Comparison of nucleotide-specific H2Opred models and individual stacking models (1D-CNN and Bi-GRU-Att) on the training and testing datasets. Performance on the A2OM training (A) and testing (B) datasets, C2OM training (C) and testing (D) datasets, G2OM training (E) and testing (F) datasets, and U2OM training (G) and testing (H) datasets.</p>
        </caption>
        <graphic xlink:href="bbad476f3" position="float"/>
      </fig>
      <p>We comprehensively evaluated the three deep learning models on four different testing datasets. In contrast to training performance, Bi-GRU-Att consistently outperformed 1D-CNN across all testing datasets, with improvement in MCCs of 2.57%, 4.04%, 1.09% and 4.31% for A2OM, C2OM, G2OM and U2OM, respectively, as shown in <xref rid="f3" ref-type="fig">Figure 3</xref>. However, H2Opred significantly outperformed both 1D-CNN and Bi-GRU-Att on all four testing datasets. Specifically, H2Opred improved MCC by 1.84–4.41% in A2OM, 1.23–5.27% in C2OM, 4.64–5.72% in G2OM and 1.23–5.53% in U2OM compared with Bi-GRU-Att and 1D-CNN, respectively. Overall, H2Opred demonstrated superior performance compared with both 1D-CNN and Bi-GRU-Att, exhibiting consistent performance across both training and testing datasets. To highlight the advantages of H2Opred, we compared its performance against the top five conventional ML-based single-feature models for each of the four nucleotide-specific models. As illustrated in <xref rid="sup1" ref-type="supplementary-material">Figure S5</xref>, H2Opred achieved significantly better results than the conventional ML-based single-feature models on both training and independent datasets. These findings suggest that H2Opred possesses greater stability and generalizability across diverse data scenarios, because it can learn effective feature representations by combining conventional descriptors with NLP-based embeddings.</p>
    </sec>
    <sec id="sec15">
      <title>Cross nucleotide-specific model validation</title>
      <p>We assessed the transferability of nucleotide-specific models to different testing datasets. We examined whether A2OM model is transferable to other types (C2OM, G2OM and U2OM), and vice versa, as shown in <xref rid="f4" ref-type="fig">Figure 4</xref>. When the A2OM testing dataset was evaluated with the other three trained models (G2OM, C2OM and U2OM), they achieved the ACC in the range of 0.830 to 0.916, the AUC in the range of 0.917 to 0.934 and the MCC in the range of 0.466 to 0.609. Similarly, the trained A2OM, G2OM and U2OM models achieved the ACC in the range of 0.822 to 0.925, the AUC in the range of 0.914 to 0.924 and the MCC in the range 0.434 to 0.600 on the C2OM testing dataset; the trained A2OM, C2OM and U2OM models achieved the ACC in the range of 0.796 to 0.906, the AUC in the range of 0.906 to 0.944 and the MCC in the range of 0.416 to 0.592 on the G2OM testing dataset; and the trained A2OM, C2OM and G2OM models achieved the ACC in the range of 0.905 to 0.915, the AUC in the range of 0.879 to 0.894 and the MCC in the range of 0.480 to 0.505 on the U2OM testing dataset. Overall, these analyses highlight that a nucleotide-specific model can be effectively transferrable to other nucleotides with satisfactory accuracy. Previous studies [<xref rid="ref10" ref-type="bibr">10</xref>, <xref rid="ref25" ref-type="bibr">25</xref>] have highlighted those four different nucleotides shares similar motif patterns at 2OM sites. This prompted us to investigate whether developing a generic model by integrating four different nucleotides could enhance the prediction performance compared with individual nucleotide-specific models.</p>
      <fig position="float" id="f4">
        <label>Figure 4</label>
        <caption>
          <p>Heat map illustrating the cross-nucleotide model validation based on the testing datasets. Each nucleotide-specific model is evaluated with its own dataset as well as the remaining three nucleotide-specific datasets. The performance is assessed using three metrics: (A) Mathews correlation coefficient (MCC), (B) accuracy (ACC) and (C) area under the receiver operating characteristic curve (AUC).</p>
        </caption>
        <graphic xlink:href="bbad476f4" position="float"/>
      </fig>
    </sec>
    <sec id="sec16">
      <title>Development of a generic model</title>
      <p>To develop a generic model, we integrated the four nucleotide-specific datasets and eliminated redundant sequences using CD-HIT, resulting in 4256 positive and 4255 negative samples. The generic model was then built using the same approach outlined for the nucleotide-specific models. The results demonstrated that the generic model achieved MCC, Sn, Sp, ACC and AUC of 0.719, 0.840, 0.876, 0.858 and 0.937, respectively, during training. The corresponding values on the testing dataset were 0.602, 0.828, 0.918, 0.910 and 0.946, respectively (<xref rid="sup1" ref-type="supplementary-material">Figure S6</xref>). We compared the generic model’s performance with the individual nucleotide-specific models in two ways: (i) we averaged the performance of four nucleotide-specific models and compared it with the generic model. <xref rid="sup1" ref-type="supplementary-material">Figure S6</xref> shows that the generic approach consistently outperformed the nucleotide-specific approach in terms of MCC, ACC and AUC on both training and testing datasets. (ii) We categorized generic model’s predictions based on nucleotide specificity and compared them with the individual nucleotide-specific models. <xref rid="f5" ref-type="fig">Figure 5</xref> illustrates that the generic model marginally improved MCC, ACC and AUC on G2OM and U2OM, and significantly improved on the other two nucleotide training datasets. However, the generic model significantly outperformed all four nucleotide-specific models on the independent testing datasets. In addition, we developed 154 conventional models, as previously mentioned for the development of nucleotide-specific models, to investigate whether any of these models surpassed the performance of the HDL-based generic model. As illustrated in <xref rid="sup1" ref-type="supplementary-material">Figure S7</xref>, the HDL-based generic model consistently outperformed the top five best models based on the MCC among the conventional models on both training and independent datasets, highlighting the significance of the HDL approach implemented in H2Opred.</p>
      <fig position="float" id="f5">
        <label>Figure 5</label>
        <caption>
          <p>Performance of the generic model for each of the four nucleotides is compared with the corresponding nucleotide-specific models. The comparison is shown for both the (A) training dataset and (B) testing dataset.</p>
        </caption>
        <graphic xlink:href="bbad476f5" position="float"/>
      </fig>
      <p>Unlike individual nucleotides, 2OM occurs on the ribose moiety rather than specific modification sites like 5-methyl cytosine (m5C) and 6-methyl adenosine (m6A). As 2OM is not directly linked to nucleotide bases, using a generic dataset instead of nucleotide-specific datasets would be more appropriate since such datasets lack biological significance. Overall, the enhanced performance of our generic model can be attributed primarily to the larger training dataset.</p>
    </sec>
    <sec id="sec17">
      <title>Comparison of H2Opred models with the state-of-the art predictors on the independent testing datasets</title>
      <p>To further demonstrate the superiority of H2Opred models, we tried to compare them with four previously published methods: NmSEER v2.0, NmRF, DeepOMe and i2OM. However, we encountered challenges in extracting prediction results from the given sequence when using NmSEER v2.0 and DeepOMe. Therefore, we excluded these two methods from our comparative analysis and focused on NmRF and i2OM. Upon scrutinizing the performance of these two state-of-the-art predictors, we found that NmRF performed poorly, with results approaching random prediction levels (<xref rid="sup1" ref-type="supplementary-material">Figure S8</xref>). This makes NmRF unsuitable for genome-wide predictions. The primary reason for this subpar performance is that NmRF was trained on a substantially different dataset with a smaller number of samples than our models and i2OM. Comparing nucleotide-specific H2Opred models and i2OM directly is more straightforward and insightful because they were trained on the same datasets, allowing for a more meaningful evaluation of their respective performances. However, the generic H2Opred model was trained on different and larger training dataset. Owing to the challenges in accessing results from the i2OM web server, we utilized the standalone program (<ext-link xlink:href="https://github.com/yangmoo1010/i2OM" ext-link-type="uri">https://github.com/yangmoo1010/i2OM</ext-link>) to compute the results.</p>
      <p><xref rid="f6" ref-type="fig">Figure 6</xref> clearly shows that the generic H2Opred model achieved the best performance across all testing datasets. Compared with i2OM, the generic H2Opred model demonstrated significant improvements across several key metrics, including MCC, ACC, AUC and F1-score. Specifically, on the A2OM testing dataset, the generic H2Opred model achieved 45.44% improvement in MCC, 46.00% in ACC, 9.16% in AUC and 43.16% in F1-score. Similarly, on the C2OM testing dataset, the generic H2Opred model outperformed i2OM with improvements of 10.05% in MCC, 3.31% in ACC, 3.40% in AUC and 9.52% in F1-score. The advantages of the generic H2Opred model were evident on the G2OM testing dataset, where it achieved improvements of 7.03% in MCC, 2.49% in ACC, 2.35% in AUC and 6.74% in F1-score. On the U2OM testing dataset, the generic H2Opred model achieved with remarkable improvements of 28.10% in MCC, 11.64% in ACC, 15.42% in AUC and 24.73% in F1-score. Furthermore, the generic H2Opred model consistently outperformed the nucleotide-specific H2Opred models across all datasets, demonstrating the significant of a larger training on performance improvement. These results highlight the stability and excellence of proposed H2Opred models, making H2Opred as an effective and valuable computational tool for the precise identification of RNA 2OM sites.</p>
      <fig position="float" id="f6">
        <label>Figure 6</label>
        <caption>
          <p>Comparison of the performance of different H2Opred models and the state-of-the-art i2OM predictor on four testing datasets. (A) A2OM, (B) C2OM, (C) G2OM and (D) U2OM.</p>
        </caption>
        <graphic xlink:href="bbad476f6" position="float"/>
      </fig>
    </sec>
    <sec id="sec18">
      <title>Visualization of learned features</title>
      <p>In this section, we focused on the best generic model and visualized the learned features extracted by 1D-CNN, Bi-GRU-Att and H2Opred to understand the abstractions generated by these deep learning architectures. We employed UMAP, a novel dimensionality reduction technique, to reduce the original features into a 2D vector. <xref rid="f7" ref-type="fig">Figure 7</xref> shows that the feature representations learned by Bi-GRU-Att showed minimal overlap between 2OM and non-2OM sites, while those learned by 1D-CNN showed more overlapping samples. However, the feature representations learned by H2Opred showed a clear separation of 2OM and non-2OM samples on the generic training dataset. This suggests that H2Opred is capable of extracting the most informative and discriminative features through 1D-CNN and Bi-GRU-Att. The feature representation patterns observed in the training dataset follows a similar on the testing dataset for three deep learning architectures, demonstrating that the model is able to learn robust representations of the 2OM and non-2OM sites from training datasets, which can be generalized to new data.</p>
      <fig position="float" id="f7">
        <label>Figure 7</label>
        <caption>
          <p>UMAP visualization of the learned feature representations of three models (1D-CNN, Bi-GRU-Att and H2Opred) on the generic training (A–C) and independent testing (D–F) datasets.</p>
        </caption>
        <graphic xlink:href="bbad476f7" position="float"/>
      </fig>
      <p>Through UMAP visualization, we demonstrated that conventional feature descriptors and NLP-based embeddings can be mapped into meaningful representations through the HDL approach. This suggests that H2Opred can capture complex relationships between different features, which is not possible with conventional ML-based single-feature models. Consequently, H2Opred consistently outperformed other deep learning-based models and conventional ML-based single-feature models, making it a promising tool for identifying 2OM sites in the human genome.</p>
    </sec>
    <sec id="sec19">
      <title>Web server implementation</title>
      <p>H2Opred, a user-friendly web server for predicting RNA 2OM sites, is now freely available at <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>. The website also provides access to all training and testing datasets employed in this study. To use H2Opred, users can either upload a file containing multiple FASTA sequences or input one or more query sequences in FASTA format. The input sequence must be in the FASTA format and exactly 41 bp long. Users are then be prompted to select their model of choice (N2OM, A2OM, G2OM, C2OM or U2OM) before job submission. If no model is selected, the N2OM model will be employed automatically. Upon successful job completion, the results are presented on a dedicated interface, allowing users to easily view and analyze the findings. Additionally, users have the option to download the results in CSV format for future reference.</p>
    </sec>
  </sec>
  <sec id="sec20">
    <title>CONCLUSION</title>
    <p>2OM is a common post-transcriptional modification with important implications for various biological functions. Understanding its distribution within RNA can provide insights into its mechanism of action. In this study, we introduced a novel HDL model called H2Opred, to accurately identify 2OM sites from primary RNA sequences. We first identified 14 conventional descriptors and evaluated their discriminative patterns using the 11 ML-based classifiers. We then used stacked 1D-CNN to learn the feature representations from these conventional descriptors. Next, we used NLP-based embeddings derived from RNA sequence and trained using stacked Bi-GRU-Att to capture more diverse facets of feature representations. Finally, we integrated these two distinct feature representations to make final prediction. Rigorous cross-validation and independent testing on different datasets showed that H2Opred achieved a more balanced performance and consistently outperformed the two deep learning architectures as well as several hundreds of ML-based single-feature models.</p>
    <p>In contrast to individual nucleotides, which have specific modification sites like m5C and m6A, 2OM occurs on the ribose moiety, a structural component of RNA. Therefore, developing 2OM site prediction model using the nucleotide-specific datasets lacks biological significance. Indeed, our cross-nucleotide model analysis demonstrated the transferability of nucleotide-specific models across other nucleotide datasets, suggesting that a generic model can be developed by integrating all nucleotide-specific datasets. To this end, we developed a generic model that showed significant improvement on both training and testing datasets compared with the nucleotide-specific models. In the H2Opred webserver, we have incorporated both the four nucleotide-specific models and a generic model. Notably, each of these models demonstrated superior performance over the existing predictor i2OM across all evaluation metrics on the independent testing datasets. This suggests that our HDL framework integrated conventional descriptors with NLP-based embeddings to significantly improve prediction performance. To make H2Opred widely accessible and user-friendly, we have launched a dedicated web server at <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>. We believe that this online platform will be invaluable for researchers seeking to accurately predict 2OM sites in human RNA, advancing scientific progress in this field. The current approach can be extended to other RNA post-transcriptional prediction sites [<xref rid="ref47" ref-type="bibr">47</xref>], RNA subcellular localization [<xref rid="ref48" ref-type="bibr">48</xref>] and peptide therapeutic function prediction [<xref rid="ref27" ref-type="bibr">27</xref>].</p>
    <p>H2Opred has shown significant promise in predicting 2OM sites, but there are areas for further refinement. The proposed model was trained on a larger dataset than existing methods. However, we can further enhance the model performance by incorporating new data as it becomes available. We integrated conventional descriptors with NLP-based embeddings through an HDL framework, but future work could explore other methodologies, such as contrastive learning [<xref rid="ref49" ref-type="bibr">49</xref>, <xref rid="ref50" ref-type="bibr">50</xref>], ensemble or stacking approaches based on conventional ML classifiers [<xref rid="ref51" ref-type="bibr">51</xref>], hybrid feature approach [<xref rid="ref52" ref-type="bibr">52</xref>], feature representation learning [<xref rid="ref53" ref-type="bibr">53</xref>] and iterative feature refinement [<xref rid="ref54" ref-type="bibr">54</xref>, <xref rid="ref55" ref-type="bibr">55</xref>]. Beyond conventional descriptors and NLP-based embeddings, the topological structure of RNA sequences also plays an important role in defining their functions. To improve feature representation, we could incorporate predicted structural information within the HDL framework. Currently, H2Opred is still a ‘black box’, limiting its ability to explain its decisions. In the future, we aspire to develop a model that is not only accurate but also interpretable, providing tangible and actionable biological insights.</p>
    <boxed-text id="box01" position="float">
      <sec id="sec21z">
        <title>Key Points</title>
        <list list-type="bullet">
          <list-item>
            <p>We introduced a novel HDL model called H2Opred for accurately identifying 2’-O-methylation (2OM) sites in human RNA.</p>
          </list-item>
          <list-item>
            <p>H2Opred used a combination of stacked 1D-CNN and Bi-GRU-Att blocks to learn effective feature representation from 14 conventional descriptors and five NLP-based embeddings, respectively. Subsequently, these representations were combined to make the final prediction.</p>
          </list-item>
          <list-item>
            <p>A novel generic model has been developed, driven by cross-nucleotide model analysis, significantly outperforming nucleotide-specific models and the existing predictor when tested on large samples of an independent dataset.</p>
          </list-item>
          <list-item>
            <p>H2Opred is now available as a web server at <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>, providing an invaluable tool for predicting 2OM sites in human RNA.</p>
          </list-item>
        </list>
      </sec>
    </boxed-text>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>H2Opred_SI_bbad476</label>
      <media xlink:href="h2opred_si_bbad476.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="bbad476-ack">
    <title>ACKNOWLEDGEMENTS</title>
    <p>The authors would like to thank the Korea Institute of Science and Technology Information (KISTI) and Korea Bio Data Station (K-BDS) with computing resources including technical support. We thank Nattanong Bupi for his assistance in creating the figure, and CBBL members for their valuable discussion.</p>
  </ack>
  <sec id="sec23">
    <title>FUNDING</title>
    <p>This work was supported by the National Research Foundation of Korea (NRF) funded by the Ministry of Science and ICT (2021R1A2C1014338 and 2021R1I1A1A01056363), and Korea Health Technology R&amp;D Project grant through the Korea Health Industry Development Institute (KHIDI) funded by the Ministry of Health &amp; Welfare, Republic of Korea (HI23C0701).</p>
  </sec>
  <sec sec-type="data-availability" id="sec24">
    <title>DATA AVAILABILITY</title>
    <p>Web server and all the processed data used in this study can be accessed via <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>.</p>
  </sec>
  <notes id="bio3">
    <title>Author Biographies</title>
    <p><bold>Nhat Truong Pham</bold> is a Ph.D. student at the Computational Biology and Bioinformatics Laboratory, Department of Integrative Biotechnology, Sungkyunkwan University, Republic of Korea. His research interests include artificial intelligence, bioinformatics, computational biology and medicine, deep learning, machine learning, signal processing and XAI and optimization.</p>
    <sec sec-type="author-bio" id="sec26">
      <p><bold>Rajan Rakkiyappan</bold> is a professor in the Department of Mathematics at Bharathiar University in Tamil Nadu, India. His research interests include neural networks, stability theory, data-driven machine learning, bioinformatics and computational biology.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27">
      <p><bold>Jongsun Park</bold> is a co-CEO and CTO of Infoboss Inc, Republic of Korea. His research interests include bioinformatics, genomics, deep learning, machine learning, bio big data, plant/insect taxonomy and phylogenetics.</p>
    </sec>
    <sec sec-type="author-bio" id="sec28">
      <p><bold>Adeel Malik</bold> is a Research Professor at the Institute of Intelligence Informatics Technology, Sangmyung University, Seoul, Republic of Korea. His research interests include machine learning, computational biology and comparative genomics.</p>
    </sec>
    <sec sec-type="author-bio" id="sec29">
      <p><bold>Balachandran Manavalan</bold> is an Assistant Professor at the Department of Integrative Biotechnology, Sungkyunkwan University, Republic of Korea. He is also an associate member of Korea Institute for Advanced Study, Republic of Korea. His research interests include artificial intelligence, bioinformatics, machine learning, big data and functional genomics.</p>
    </sec>
  </notes>
  <ref-list id="bib1">
    <title>References</title>
    <ref id="ref1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname><given-names>BS</given-names></string-name>, <string-name><surname>Roundtree</surname><given-names>IA</given-names></string-name>, <string-name><surname>He</surname><given-names>C</given-names></string-name></person-group>. <article-title>Post-transcriptional gene regulation by mRNA modifications</article-title>. <source>Nat Rev Mol Cell Biol</source><year>2017</year>;<volume>18</volume>:<fpage>31</fpage>–<lpage>42</lpage>.<pub-id pub-id-type="pmid">27808276</pub-id></mixed-citation>
    </ref>
    <ref id="ref2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Machnicka</surname><given-names>MA</given-names></string-name>, <string-name><surname>Milanowska</surname><given-names>K</given-names></string-name>, <string-name><surname>Osman Oglou</surname><given-names>O</given-names></string-name>, <string-name><surname>Purta</surname><given-names>E</given-names></string-name>, <string-name><surname>Kurkowska</surname><given-names>M</given-names></string-name>, <string-name><surname>Olchowik</surname><given-names>A</given-names></string-name>, <string-name><surname>Januszewski</surname><given-names>W</given-names></string-name>, <string-name><surname>Kalinowski</surname><given-names>S</given-names></string-name>, <string-name><surname>Dunin-Horkawicz</surname><given-names>S</given-names></string-name>, <string-name><surname>Rother</surname><given-names>KM</given-names></string-name>, <string-name><surname>Helm</surname><given-names>M</given-names></string-name>, <string-name><surname>Bujnicki</surname><given-names>JM</given-names></string-name>, <string-name><surname>Grosjean</surname><given-names>H</given-names></string-name></person-group><article-title>MODOMICS: a database of RNA modification pathways--2013 update</article-title>, <source>Nucleic Acids Res</source> 2013;<volume>41</volume>:<fpage>D262</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">23118484</pub-id>
</mixed-citation>
    </ref>
    <ref id="ref3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ayadi</surname><given-names>L</given-names></string-name>, <string-name><surname>Galvanin</surname><given-names>A</given-names></string-name>, <string-name><surname>Pichot</surname><given-names>F</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RNA ribose methylation (2′-O-methylation): occurrence, biosynthesis and biological functions</article-title>. <source>Biochim Biophys Acta</source><year>2019</year>;<volume>1862</volume>:<fpage>253</fpage>–<lpage>69</lpage>.</mixed-citation>
    </ref>
    <ref id="ref4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Daffis</surname><given-names>S</given-names></string-name>, <string-name><surname>Szretter</surname><given-names>KJ</given-names></string-name>, <string-name><surname>Schriewer</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>2'-O methylation of the viral mRNA cap evades host restriction by IFIT family members</article-title>. <source>Nature</source><year>2010</year>;<volume>468</volume>:<fpage>452</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">21085181</pub-id></mixed-citation>
    </ref>
    <ref id="ref5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>J</given-names></string-name>, <string-name><surname>Lai</surname><given-names>S</given-names></string-name>, <string-name><surname>Jia</surname><given-names>R</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Structural basis for site-specific ribose methylation by box C/D RNA protein complexes</article-title>. <source>Nature</source><year>2011</year>;<volume>469</volume>:<fpage>559</fpage>–<lpage>63</lpage>.<pub-id pub-id-type="pmid">21270896</pub-id></mixed-citation>
    </ref>
    <ref id="ref6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zust</surname><given-names>R</given-names></string-name>, <string-name><surname>Cervantes-Barragan</surname><given-names>L</given-names></string-name>, <string-name><surname>Habjan</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Ribose 2'-O-methylation provides a molecular signature for the distinction of self and non-self mRNA dependent on the RNA sensor Mda5</article-title>. <source>Nat Immunol</source><year>2011</year>;<volume>12</volume>:<fpage>137</fpage>–<lpage>43</lpage>.<pub-id pub-id-type="pmid">21217758</pub-id></mixed-citation>
    </ref>
    <ref id="ref7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ringeard</surname><given-names>M</given-names></string-name>, <string-name><surname>Marchand</surname><given-names>V</given-names></string-name>, <string-name><surname>Decroly</surname><given-names>E</given-names></string-name>, <etal>et al.</etal></person-group><article-title>FTSJ3 is an RNA 2′-O-methyltransferase recruited by HIV to avoid innate immune sensing</article-title>. <source>Nature</source><year>2019</year>;<volume>565</volume>:<fpage>500</fpage>–<lpage>4</lpage>.<pub-id pub-id-type="pmid">30626973</pub-id></mixed-citation>
    </ref>
    <ref id="ref8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gehrig</surname><given-names>S</given-names></string-name>, <string-name><surname>Eberle</surname><given-names>M-E</given-names></string-name>, <string-name><surname>Botschen</surname><given-names>F</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Identification of modifications in microbial, native tRNA that suppress immunostimulatory activity</article-title>. <source>J Exp Med</source><year>2012</year>;<volume>209</volume>:<fpage>225</fpage>–<lpage>33</lpage>.<pub-id pub-id-type="pmid">22312113</pub-id></mixed-citation>
    </ref>
    <ref id="ref9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>C</given-names></string-name>, <string-name><surname>Yu</surname><given-names>Y-T</given-names></string-name></person-group>. <article-title>Targeted 2′-O methylation at a nucleotide within the pseudoknot of telomerase RNA reduces telomerase activity in vivo</article-title>. <source>Mol Cell Biol</source><year>2010</year>;<volume>30</volume>:<fpage>4368</fpage>–<lpage>78</lpage>.<pub-id pub-id-type="pmid">20647541</pub-id></mixed-citation>
    </ref>
    <ref id="ref10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dai</surname><given-names>Q</given-names></string-name>, <string-name><surname>Moshitch-Moshkovitz</surname><given-names>S</given-names></string-name>, <string-name><surname>Han</surname><given-names>D</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Nm-seq maps 2'-O-methylation sites in human mRNA with base precision</article-title>. <source>Nat Methods</source><year>2017</year>;<volume>14</volume>:<fpage>695</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">28504680</pub-id></mixed-citation>
    </ref>
    <ref id="ref11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krogh</surname><given-names>N</given-names></string-name>, <string-name><surname>Birkedal</surname><given-names>U</given-names></string-name>, <string-name><surname>Nielsen</surname><given-names>H</given-names></string-name></person-group>. <article-title>RiboMeth-seq: profiling of 2'-O-me in RNA</article-title>. <source>Methods Mol Biol</source><year>2017</year>;<volume>1562</volume>:<fpage>189</fpage>–<lpage>209</lpage>.<pub-id pub-id-type="pmid">28349462</pub-id></mixed-citation>
    </ref>
    <ref id="ref12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Incarnato</surname><given-names>D</given-names></string-name>, <string-name><surname>Anselmi</surname><given-names>F</given-names></string-name>, <string-name><surname>Morandi</surname><given-names>E</given-names></string-name>, <etal>et al.</etal></person-group><article-title>High-throughput single-base resolution mapping of RNA 2ʹ-O-methylated residues</article-title>. <source>Nucleic Acids Res</source><year>2017</year>;<volume>45</volume>:<fpage>1433</fpage>–<lpage>41</lpage>.<pub-id pub-id-type="pmid">28180324</pub-id></mixed-citation>
    </ref>
    <ref id="ref13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Pirnie</surname><given-names>SP</given-names></string-name>, <string-name><surname>Carmichael</surname><given-names>GG</given-names></string-name></person-group>. <article-title>High-throughput and site-specific identification of 2'-O-methylation sites using ribose oxidation sequencing (RibOxi-seq)</article-title>. <source>RNA</source><year>2017</year>;<volume>23</volume>:<fpage>1303</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">28495677</pub-id></mixed-citation>
    </ref>
    <ref id="ref14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hsu</surname><given-names>PJ</given-names></string-name>, <string-name><surname>Fei</surname><given-names>Q</given-names></string-name>, <string-name><surname>Dai</surname><given-names>Q</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Single base resolution mapping of 2'-O-methylation sites in human mRNA and in 3′ terminal ends of small RNAs</article-title>. <source>Methods</source><year>2019</year>;<volume>156</volume>:<fpage>85</fpage>–<lpage>90</lpage>.<pub-id pub-id-type="pmid">30471344</pub-id></mixed-citation>
    </ref>
    <ref id="ref15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>WJ</given-names></string-name>, <string-name><surname>Li</surname><given-names>JH</given-names></string-name>, <string-name><surname>Liu</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RMBase: a resource for decoding the landscape of RNA modifications from high-throughput sequencing data</article-title>. <source>Nucleic Acids Res</source><year>2016</year>;<volume>44</volume>:<fpage>D259</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">26464443</pub-id></mixed-citation>
    </ref>
    <ref id="ref16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xuan</surname><given-names>JJ</given-names></string-name>, <string-name><surname>Sun</surname><given-names>WJ</given-names></string-name>, <string-name><surname>Lin</surname><given-names>PH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RMBase v2.0: deciphering the map of RNA modifications from epitranscriptome sequencing data</article-title>. <source>Nucleic Acids Res</source><year>2018</year>;<volume>46</volume>:<fpage>D327</fpage>–<lpage>34</lpage>.<pub-id pub-id-type="pmid">29040692</pub-id></mixed-citation>
    </ref>
    <ref id="ref17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>W</given-names></string-name>, <string-name><surname>Feng</surname><given-names>P</given-names></string-name>, <string-name><surname>Tang</surname><given-names>H</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Identifying 2'-O-methylationation sites by integrating nucleotide chemical properties and nucleotide compositions</article-title>. <source>Genomics</source><year>2016</year>;<volume>107</volume>:<fpage>255</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">27191866</pub-id></mixed-citation>
    </ref>
    <ref id="ref18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>H</given-names></string-name>, <string-name><surname>Lv</surname><given-names>H</given-names></string-name>, <string-name><surname>Ding</surname><given-names>H</given-names></string-name>, <etal>et al.</etal></person-group><article-title>iRNA-2OM: a sequence-based predictor for identifying 2'-O-methylation sites in Homo sapiens</article-title>. <source>J Comput Biol</source><year>2018</year>;<volume>25</volume>:<fpage>1266</fpage>–<lpage>77</lpage>.<pub-id pub-id-type="pmid">30113871</pub-id></mixed-citation>
    </ref>
    <ref id="ref19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tahir</surname><given-names>M</given-names></string-name>, <string-name><surname>Tayara</surname><given-names>H</given-names></string-name>, <string-name><surname>Chong</surname><given-names>KT</given-names></string-name></person-group>. <article-title>iRNA-PseKNC(2methyl): identify RNA 2'-O-methylation sites by convolution neural network and Chou's pseudo components</article-title>. <source>J Theor Biol</source><year>2019</year>;<volume>465</volume>:<fpage>1</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">30590059</pub-id></mixed-citation>
    </ref>
    <ref id="ref20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>QL</given-names></string-name>, <string-name><surname>Wang</surname><given-names>L</given-names></string-name>, <string-name><surname>Han</surname><given-names>SG</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Identification of 2'-O-methylation site by investigating multi-feature extracting techniques</article-title>. <source>Comb Chem High Throughput Screen</source><year>2020</year>;<volume>23</volume>:<fpage>527</fpage>–<lpage>35</lpage>.<pub-id pub-id-type="pmid">32334499</pub-id></mixed-citation>
    </ref>
    <ref id="ref21">
      <label>21.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Cui</surname><given-names>Q</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name></person-group>. <part-title>NmSEER: A Prediction Tool for 2’-O-Methylation (Nm) Sites Based on Random Forest</part-title>. In: <source>Intelligent Computing Theories and Application: 14th International Conference, ICIC 2018</source>, <conf-loc>Wuhan, China</conf-loc>, <conf-date>August 15–18</conf-date>. <comment>Proceedings, Part I 14. 2018</comment>. Springer, <year>2018</year>;<volume>10954</volume>:pp. <fpage>893</fpage>–<lpage>900</lpage>.</mixed-citation>
    </ref>
    <ref id="ref22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Cui</surname><given-names>Q</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name></person-group>. <article-title>NmSEER V2.0: a prediction tool for 2'-O-methylation sites based on random forest and multi-encoding combination</article-title>. <source>BMC Bioinformatics</source><year>2019</year>;<volume>20</volume>:<fpage>690</fpage>.<pub-id pub-id-type="pmid">31874624</pub-id></mixed-citation>
    </ref>
    <ref id="ref23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Chen</surname><given-names>L</given-names></string-name>, <string-name><surname>Huang</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>DeepOMe: a web server for the prediction of 2'-O-me sites based on the hybrid CNN and BLSTM architecture</article-title>. <source>Front Cell Dev Biol</source><year>2021</year>;<volume>9</volume>:<fpage>686894</fpage>.<pub-id pub-id-type="pmid">34055810</pub-id></mixed-citation>
    </ref>
    <ref id="ref24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ao</surname><given-names>C</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <string-name><surname>Yu</surname><given-names>L</given-names></string-name></person-group>. <article-title>NmRF: identification of multispecies RNA 2'-O-methylation modification sites from RNA sequences</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:bbab480.</mixed-citation>
    </ref>
    <ref id="ref25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>YH</given-names></string-name>, <string-name><surname>Ma</surname><given-names>CY</given-names></string-name>, <string-name><surname>Gao</surname><given-names>D</given-names></string-name>, <etal>et al.</etal></person-group><article-title>i2OM: toward a better prediction of 2'-O-methylation in human RNA</article-title>. <source>Int J Biol Macromol</source><year>2023</year>;<volume>239</volume>:<fpage>124247</fpage>.<pub-id pub-id-type="pmid">37003392</pub-id></mixed-citation>
    </ref>
    <ref id="ref26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Niu</surname><given-names>B</given-names></string-name>, <string-name><surname>Gao</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CD-HIT suite: a web server for clustering and comparing biological sequences</article-title>. <source>Bioinformatics</source><year>2010</year>;<volume>26</volume>:<fpage>680</fpage>–<lpage>2</lpage>.<pub-id pub-id-type="pmid">20053844</pub-id></mixed-citation>
    </ref>
    <ref id="ref27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <string-name><surname>Manavalan</surname><given-names>B</given-names></string-name>, <string-name><surname>Hwan Shin</surname><given-names>T</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Machine intelligence in peptide therapeutics: a next-generation tool for rapid disease screening</article-title>. <source>Med Res Rev</source><year>2020</year>;<volume>40</volume>:<fpage>1276</fpage>–<lpage>314</lpage>.<pub-id pub-id-type="pmid">31922268</pub-id></mixed-citation>
    </ref>
    <ref id="ref28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname><given-names>B</given-names></string-name>, <string-name><surname>Wang</surname><given-names>X</given-names></string-name>, <string-name><surname>Liang</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RMDisease V2.0: an updated database of genetic variants that affect RNA modifications with disease and trait implication</article-title>. <source>Nucleic Acids Res</source><year>2023</year>;<volume>51</volume>:<fpage>D1388</fpage>–<lpage>96</lpage>.<pub-id pub-id-type="pmid">36062570</pub-id></mixed-citation>
    </ref>
    <ref id="ref29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manavalan</surname><given-names>B</given-names></string-name>, <string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <string-name><surname>Shin</surname><given-names>TH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Meta-4mCpred: a sequence-based meta-predictor for accurate DNA 4mC site prediction using effective feature representation</article-title>. <source>Mol Ther Nucleic Acids</source><year>2019</year>;<volume>16</volume>:<fpage>733</fpage>–<lpage>44</lpage>.<pub-id pub-id-type="pmid">31146255</pub-id></mixed-citation>
    </ref>
    <ref id="ref30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiang</surname><given-names>J</given-names></string-name>, <string-name><surname>Song</surname><given-names>B</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>m5UPred: a web server for the prediction of RNA 5-Methyluridine sites from sequences</article-title>. <source>Mol Ther Nucleic Acids</source><year>2020</year>;<volume>22</volume>:<fpage>742</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">33230471</pub-id></mixed-citation>
    </ref>
    <ref id="ref31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahmed</surname><given-names>S</given-names></string-name>, <string-name><surname>Muhammod</surname><given-names>R</given-names></string-name>, <string-name><surname>Khan</surname><given-names>ZH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>ACP-MHCNN: an accurate multi-headed deep-convolutional neural network to predict anticancer peptides</article-title>. <source>Sci Rep</source><year>2021</year>;<volume>11</volume>:<fpage>23676</fpage>.<pub-id pub-id-type="pmid">34880291</pub-id></mixed-citation>
    </ref>
    <ref id="ref32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ge</surname><given-names>F</given-names></string-name>, <string-name><surname>Li</surname><given-names>C</given-names></string-name>, <string-name><surname>Iqbal</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>VPatho: a deep learning-based two-stage approach for accurate prediction of gain-of-function and loss-of-function variants</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:bbac535.</mixed-citation>
    </ref>
    <ref id="ref33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Guo</surname><given-names>X</given-names></string-name>, <string-name><surname>Bi</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Digerati - a multipath parallel hybrid deep learning framework for the identification of mycobacterial PE/PPE proteins</article-title>. <source>Comput Biol Med</source><year>2023</year>;<volume>163</volume>:<elocation-id>107155</elocation-id>.<pub-id pub-id-type="pmid">37356289</pub-id></mixed-citation>
    </ref>
    <ref id="ref34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Li</surname><given-names>C</given-names></string-name>, <etal>et al.</etal></person-group><article-title>iAMPCN: a deep-learning approach for identifying antimicrobial peptides and their functional activities</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:bbad240.</mixed-citation>
    </ref>
    <ref id="ref35">
      <label>35.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bahdanau</surname><given-names>D</given-names></string-name>, <string-name><surname>Cho</surname><given-names>K</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>Y</given-names></string-name></person-group>. <article-title>Neural machine translation by jointly learning to align and translate</article-title>. <comment>arXiv preprint arXiv:1409.0473 2014</comment>.</mixed-citation>
    </ref>
    <ref id="ref36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pham</surname><given-names>NT</given-names></string-name>, <string-name><surname>Dang</surname><given-names>DNM</given-names></string-name>, <string-name><surname>Nguyen</surname><given-names>ND</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Hybrid data augmentation and deep attention-based dilated convolutional-recurrent neural networks for speech emotion recognition</article-title>. <source>Expert Syst Appl</source><year>2023</year>;<volume>230</volume>:<elocation-id>120608</elocation-id>.</mixed-citation>
    </ref>
    <ref id="ref37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>G</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Feng</surname><given-names>P</given-names></string-name>, <etal>et al.</etal></person-group><article-title>IPs-GRUAtt: an attention-based bidirectional gated recurrent unit network for predicting phosphorylation sites of SARS-CoV-2 infection</article-title>. <source>Mol Ther Nucleic Acids</source><year>2023</year>;<volume>32</volume>:<fpage>28</fpage>–<lpage>35</lpage>.<pub-id pub-id-type="pmid">36908648</pub-id></mixed-citation>
    </ref>
    <ref id="ref38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Liu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Xu</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Leveraging the attention mechanism to improve the identification of DNA N6-methyladenine sites</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:bbab351.</mixed-citation>
    </ref>
    <ref id="ref39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahmed</surname><given-names>S</given-names></string-name>, <string-name><surname>Kabir</surname><given-names>M</given-names></string-name>, <string-name><surname>Arif</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>DeepPPSite: a deep learning-based model for analysis and prediction of phosphorylation sites using efficient sequence information</article-title>. <source>Anal Biochem</source><year>2021</year>;<volume>612</volume>:<fpage>113955</fpage>.<pub-id pub-id-type="pmid">32949607</pub-id></mixed-citation>
    </ref>
    <ref id="ref40">
      <label>40.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tang</surname><given-names>X</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>P</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Deep6mAPred: a CNN and Bi-LSTM-based deep learning method for predicting DNA N6-methyladenosine sites across plant species</article-title>. <source>Methods</source><year>2022</year>;<volume>204</volume>:<fpage>142</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">35477057</pub-id></mixed-citation>
    </ref>
    <ref id="ref41">
      <label>41.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>ZY</given-names></string-name>, <string-name><surname>Ning</surname><given-names>L</given-names></string-name>, <string-name><surname>Ye</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>iLoc-miRNA: extracellular/intracellular miRNA prediction using deep BiLSTM with attention mechanism</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:bbac395.</mixed-citation>
    </ref>
    <ref id="ref42">
      <label>42.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>Z</given-names></string-name>, <string-name><surname>Huang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>PSnoD: identifying potential snoRNA-disease associations based on bounded nuclear norm regularization</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:bbac240.</mixed-citation>
    </ref>
    <ref id="ref43">
      <label>43.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ge</surname><given-names>F</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Prediction of multiple types of RNA modifications via biological language model</article-title>. <source>IEEE/ACM Trans Comput Biol Bioinform</source><year>2023</year>;<volume>20</volume>(<issue>5</issue>):3205–14.</mixed-citation>
    </ref>
    <ref id="ref44">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>R</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Guo</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>ATTIC is an integrated approach for predicting A-to-I RNA editing sites in three species</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:<fpage>bbad170</fpage>.<pub-id pub-id-type="pmid">37150785</pub-id></mixed-citation>
    </ref>
    <ref id="ref45">
      <label>45.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Yang</surname><given-names>B</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Bastion3: a two-layer ensemble predictor of type III secreted effectors</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>2017</fpage>–<lpage>28</lpage>.<pub-id pub-id-type="pmid">30388198</pub-id></mixed-citation>
    </ref>
    <ref id="ref46">
      <label>46.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shoombuatong</surname><given-names>W</given-names></string-name>, <string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <string-name><surname>Pitti</surname><given-names>T</given-names></string-name>, <etal>et al.</etal></person-group><article-title>THRONE: a new approach for accurate prediction of human RNA N7-methylguanosine sites</article-title>. <source>J Mol Biol</source><year>2022</year>;<volume>434</volume>:<fpage>167549</fpage>.<pub-id pub-id-type="pmid">35662472</pub-id></mixed-citation>
    </ref>
    <ref id="ref47">
      <label>47.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <string-name><surname>Xing</surname><given-names>P</given-names></string-name>, <string-name><surname>Wei</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Gene2vec: gene subsequence embedding for prediction of mammalian N(6)-methyladenosine sites from mRNA</article-title>. <source>RNA</source><year>2019</year>;<volume>25</volume>:<fpage>205</fpage>–<lpage>18</lpage>.<pub-id pub-id-type="pmid">30425123</pub-id></mixed-citation>
    </ref>
    <ref id="ref48">
      <label>48.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yuan</surname><given-names>GH</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>GZ</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RNAlight: a machine learning model to identify nucleotide features determining RNA subcellular localization</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:bbac509.</mixed-citation>
    </ref>
    <ref id="ref49">
      <label>49.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>X</given-names></string-name>, <string-name><surname>Jin</surname><given-names>J</given-names></string-name>, <string-name><surname>Wang</surname><given-names>R</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CACPP: a contrastive learning-based Siamese network to identify anticancer peptides based on sequence only</article-title>. <source>J Chem Inf Model</source><year>2023</year>.</mixed-citation>
    </ref>
    <ref id="ref50">
      <label>50.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Wei</surname><given-names>L</given-names></string-name>, <string-name><surname>Ye</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>SiameseCPP: a sequence-based Siamese network to predict cell-penetrating peptides by contrastive learning</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:bbac545.</mixed-citation>
    </ref>
    <ref id="ref51">
      <label>51.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Charoenkwan</surname><given-names>P</given-names></string-name>, <string-name><surname>Chiangjong</surname><given-names>W</given-names></string-name>, <string-name><surname>Nantasenamat</surname><given-names>C</given-names></string-name>, <etal>et al.</etal></person-group><article-title>StackIL6: a stacking ensemble model for improving the prediction of IL-6 inducing peptides</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:bbab172.</mixed-citation>
    </ref>
    <ref id="ref52">
      <label>52.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Wei</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>6mA-RicePred: a method for identifying DNA N (6)-Methyladenine sites in the rice genome based on feature fusion</article-title>. <source>Front Plant Sci</source><year>2020</year>;<volume>11</volume>:<fpage>4</fpage>.<pub-id pub-id-type="pmid">32076430</pub-id></mixed-citation>
    </ref>
    <ref id="ref53">
      <label>53.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hasan</surname><given-names>MM</given-names></string-name>, <string-name><surname>Schaduangrat</surname><given-names>N</given-names></string-name>, <string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>HLPpred-Fuse: improved and robust prediction of hemolytic peptide and its activity by fusing multiple feature representation</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>3350</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">32145017</pub-id></mixed-citation>
    </ref>
    <ref id="ref54">
      <label>54.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wei</surname><given-names>L</given-names></string-name>, <string-name><surname>Su</surname><given-names>R</given-names></string-name>, <string-name><surname>Luan</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Iterative feature representations improve N4-methylcytosine site prediction</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>4930</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">31099381</pub-id></mixed-citation>
    </ref>
    <ref id="ref55">
      <label>55.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manavalan</surname><given-names>B</given-names></string-name>, <string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <string-name><surname>Shin</surname><given-names>TH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Computational prediction of species-specific yeast DNA replication origin via iterative feature representation</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:bbaa304.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Brief Bioinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Brief Bioinform</journal-id>
    <journal-id journal-id-type="publisher-id">bib</journal-id>
    <journal-title-group>
      <journal-title>Briefings in Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1467-5463</issn>
    <issn pub-type="epub">1477-4054</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10768780</article-id>
    <article-id pub-id-type="doi">10.1093/bib/bbad476</article-id>
    <article-id pub-id-type="publisher-id">bbad476</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Problem Solving Protocol</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>H2Opred: a robust and efficient hybrid deep learning model for predicting 2’-O-methylation sites in human RNA</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8086-6722</contrib-id>
        <name>
          <surname>Pham</surname>
          <given-names>Nhat Truong</given-names>
        </name>
        <!--truongpham96@skku.edu-->
        <aff><institution>Department of Integrative Biotechnology, College of Biotechnology and Bioengineering, Sungkyunkwan University</institution>, <addr-line>Suwon, 16419</addr-line>, <country country="KR">Republic of Korea</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rakkiyapan</surname>
          <given-names>Rajan</given-names>
        </name>
        <!--rakkiyappan.maths@buc.edu.in-->
        <aff><institution>Department of Mathematics, Bharathiar University</institution>, <addr-line>Coimbatore - 641046, Tamil Nadu</addr-line>, <country country="IN">India</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Park</surname>
          <given-names>Jongsun</given-names>
        </name>
        <!--starflr@infoboss.co.kr-->
        <aff><institution>InfoBoss inc. and InfoBoss Research Center, Gangnam-gu</institution>, <addr-line>Seoul 06278</addr-line>, <country country="KR">Republic of Korea</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Malik</surname>
          <given-names>Adeel</given-names>
        </name>
        <!--adeel@procarb.org-->
        <aff><institution>Institute of Intelligence Informatics Technology, Sangmyung University</institution>, <addr-line>Seoul, 03016</addr-line>, <country country="KR">Republic of Korea</country></aff>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-0697-9419</contrib-id>
        <name>
          <surname>Manavalan</surname>
          <given-names>Balachandran</given-names>
        </name>
        <!--bala2022@skku.edu-->
        <aff><institution>Department of Integrative Biotechnology, College of Biotechnology and Bioengineering, Sungkyunkwan University</institution>, <addr-line>Suwon, 16419</addr-line>, <country country="KR">Republic of Korea</country></aff>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="cor1">Corresponding authors. Adeel Malik, Institute of Intelligence Informatics Technology, 20, Hongjimun 2-gil, Jongno-gu, Seoul, Republic of Korea. Tel.: 02-2287-5288; Fax: 02-2287-0070; E-mail: <email>adeel@procarb.org</email>; Balachandran Manavalan, Department of Integrative Biotechnology, College of Biotechnology and Bioengineering, Sungkyunkwan University, Suwon 16419, Gyeonggi-do, Republic of Korea. Tel.: +82-31-299-4858; Fax: +82-31-290-7870; E-mail: <email>bala2022@skku.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2024-01-04">
      <day>04</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>04</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <volume>25</volume>
    <issue>1</issue>
    <elocation-id>bbad476</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>22</day>
        <month>11</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>28</day>
        <month>11</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2024</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="bbad476.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>2’-O-methylation (2OM) is the most common post-transcriptional modification of RNA. It plays a crucial role in RNA splicing, RNA stability and innate immunity. Despite advances in high-throughput detection, the chemical stability of 2OM makes it difficult to detect and map in messenger RNA. Therefore, bioinformatics tools have been developed using machine learning (ML) algorithms to identify 2OM sites. These tools have made significant progress, but their performances remain unsatisfactory and need further improvement. In this study, we introduced H2Opred, a novel hybrid deep learning (HDL) model for accurately identifying 2OM sites in human RNA. Notably, this is the first application of HDL in developing four nucleotide-specific models [adenine (A2OM), cytosine (C2OM), guanine (G2OM) and uracil (U2OM)] as well as a generic model (N2OM). H2Opred incorporated both stacked 1D convolutional neural network (1D-CNN) blocks and stacked attention-based bidirectional gated recurrent unit (Bi-GRU-Att) blocks. 1D-CNN blocks learned effective feature representations from 14 conventional descriptors, while Bi-GRU-Att blocks learned feature representations from five natural language processing-based embeddings extracted from RNA sequences. H2Opred integrated these feature representations to make the final prediction. Rigorous cross-validation analysis demonstrated that H2Opred consistently outperforms conventional ML-based single-feature models on five different datasets. Moreover, the generic model of H2Opred demonstrated a remarkable performance on both training and testing datasets, significantly outperforming the existing predictor and other four nucleotide-specific H2Opred models. To enhance accessibility and usability, we have deployed a user-friendly web server for H2Opred, accessible at <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>. This platform will serve as an invaluable tool for accurately predicting 2OM sites within human RNA, thereby facilitating broader applications in relevant research endeavors.</p>
    </abstract>
    <kwd-group>
      <kwd>2’-O-methylation sites</kwd>
      <kwd>convolutional neural network</kwd>
      <kwd>gated recurrent unit</kwd>
      <kwd>hybrid deep learning</kwd>
      <kwd>bioinformatics</kwd>
      <kwd>natural language processing</kwd>
    </kwd-group>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Research Foundation of Korea</institution>
            <institution-id institution-id-type="DOI">10.13039/501100003725</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Ministry of Science and ICT</institution>
            <institution-id institution-id-type="DOI">10.13039/501100014188</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>2021R1A2C1014338</award-id>
        <award-id>2021R1I1A1A01056363</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Korea Health Technology R&amp;D Project</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Korea Health Industry Development Institute</institution>
            <institution-id institution-id-type="DOI">10.13039/501100003710</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Ministry of Health and Welfare</institution>
            <institution-id institution-id-type="DOI">10.13039/100008903</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>HI23C0701</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="13"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec3">
    <title>INTRODUCTION</title>
    <p>The epitranscriptome involves chemical modification to messenger RNA (mRNA), influencing gene expression [<xref rid="ref1" ref-type="bibr">1</xref>]. While current epitranscriptome research has focused on base modifications, the ribose sugar can also be methylated at the 2′ position to form 2’-O-methylated nucleotides (2OM) [<xref rid="ref2" ref-type="bibr">2</xref>]. 2OM has been found in all types of RNA, including mRNA, ribosomal RNA (rRNA), transfer RNA (tRNA), micro RNA (miRNA), small nucleolar RNA (snoRNA) and PIWI-interacting RNA (piRNA) [<xref rid="ref3" ref-type="bibr">3</xref>]. The process of 2OM can be achieved through two distinct enzymatic routes: standalone methyltransferases and RNA-protein complex guided by Box C/D snoRNA, known as C/D-box snoRNPs. Standalone methyltransferases recognize their targets based on sequence and shape, while C/D-box snoRNPs are guided to their targets by snoRNAs [<xref rid="ref4" ref-type="bibr">4–6</xref>]. Consequently, 2OM can occur in all four canonical nucleotides (adenine, cytosine, guanine and uracil) and some non-standard nucleotides.</p>
    <p>Recent studies have shown that 2OM not only stabilized RNA but also involved in regulating gene expression and other cellular processes. For example, 2OM in RNA can be used by the innate immune system to distinguish between internal and external mRNA [<xref rid="ref6" ref-type="bibr">6</xref>]. HIV-1 evades detection by the MDA5 protein using the TRBP-FTSJ3 complex to add 2OM to its RNA [<xref rid="ref7" ref-type="bibr">7</xref>]. In human monocytes, 2OM RNA can suppress the release of pro-inflammatory cytokines [<xref rid="ref8" ref-type="bibr">8</xref>]. In yeast, specific 2OM sites in telomerase RNA affect how well telomerase functions [<xref rid="ref9" ref-type="bibr">9</xref>]. 2OM is also important for antibiotic resistance and cancer. However, much remains to be learned about the full range of roles that 2OM plays in RNA. Identifying 2OM sites in RNA is essential for understanding its functional significance, which is one of the important research topics in the community.</p>
    <p>Several experimental methods have been developed to accurately identify 2OM in RNA. These methods include perchloric acid (HClO4) hydrolysis, periodate oxidation hydrolysis, chromatography and mass spectrometry. However, these methods are labor-intensive, need specialized tools, can damage RNA samples and are challenging to use with minimal RNA. To overcome these limitations, high-throughput techniques based on deep sequencing have also been developed, such as Nm-seq [<xref rid="ref10" ref-type="bibr">10</xref>], RiboMeth-seq [<xref rid="ref11" ref-type="bibr">11</xref>], 2OMe-seq [<xref rid="ref12" ref-type="bibr">12</xref>], RibOxi-Seq [<xref rid="ref13" ref-type="bibr">13</xref>] and Nm-seq (a) [<xref rid="ref14" ref-type="bibr">14</xref>]. While these methods can identify 2OM at the transcriptome level, they are still costly, time-consuming and require specialized expertise. Therefore, computational methods have been developed to complement the experimental methods.</p>
    <p>Sun <italic toggle="yes">et al</italic>. [<xref rid="ref15" ref-type="bibr">15</xref>] developed RMBase, a database that contained 18 independent high-throughput sequencing data for studying RNA post-transcriptional modifications. The updated version, RMBase v2.0 [<xref rid="ref16" ref-type="bibr">16</xref>], contains data on 5096 2OM positions across three species, a significant increase from its predecessor’s 1209 entries. These databases serve as the foundation for developing computational methods to identify 2OM sites. Chen <italic toggle="yes">et al</italic>. [<xref rid="ref17" ref-type="bibr">17</xref>] constructed the first benchmarking dataset based on RMBase and developed a support vector machine (SVM)-based predictor. Using the same dataset, three more methods were proposed: iRNA-2OM [<xref rid="ref18" ref-type="bibr">18</xref>], identification of RNA 2OM using pseudo k-tuple nucleotide composition (iRNA-PseKNC(2methyl)) [<xref rid="ref19" ref-type="bibr">19</xref>] and an ensemble model by Huang <italic toggle="yes">et al</italic>. [<xref rid="ref20" ref-type="bibr">20</xref>]. Later, Zhou’s group developed two tools, NmSEER [<xref rid="ref21" ref-type="bibr">21</xref>] and NmSEER V2.0 [<xref rid="ref22" ref-type="bibr">22</xref>], based on different approaches and datasets. Li <italic toggle="yes">et al</italic>. [<xref rid="ref23" ref-type="bibr">23</xref>] proposed DeepOMe based on convolutional neural network (CNN) and bidirectional long short-term memory (Bi-LSTM) layers. Ao <italic toggle="yes">et al.</italic> [<xref rid="ref24" ref-type="bibr">24</xref>] developed NmRF using Chen’s dataset and RMBase v2.0, which achieved an excellent performance on three species. Yang <italic toggle="yes">et al</italic>. [<xref rid="ref25" ref-type="bibr">25</xref>] introduced i2OM by constructing a larger dataset based on <italic toggle="yes">Homo sapiens.</italic> Their study showed better performance using conventional machine learning (ML) approaches and two-step feature selection techniques. While these methods have made significant contributions to the field, there is still room for improvement.</p>
    <p>In this study, we introduced H2Opred, a novel hybrid deep learning (HDL) model, for accurately identifying 2OM sites. Remarkably, this is the first application of HDL in developing nucleotide-specific models [adenine (A2OM), cytosine (C2OM), guanine (G2OM) and uracil (U2OM)] as well as a generic model that integrated all nucleotide-specific datasets (N2OM). H2Opred included all these five models, each of which has been trained in a similar fashion. H2Opred leveraged a set of 14 conventional descriptors, encompassing binary profile features (BPF), nucleotide chemical properties (NCP), dinucleotide binary encoding (DBE), as well as type 1 and type 2 dinucleotide physicochemical properties (DPCP_1, DPCP_2), positional specifics of two nucleotides (PS2), Kmer, reverse complement Kmer patterns (RCKmer), electron–ion interaction pseudo potentials of trinucleotides (PseEIIP), composition of k-spaced nucleic acid pairs (CKSNAP), enhanced nucleic acid composition (ENAC), Z curve parameters capturing frequencies of phase-specific trinucleotides (Zcurve), a novel combination of adaptive skip dinucleotide composition with local position-specific dinucleotide frequency (ASLPN) and multivariate mutual information combined with accumulated nucleotide frequency (MMNF). Additionally, five natural language processing (NLP)-based embeddings, including the DNA-language model (DNABERT), sequence-to-vector (Seq2Vec), word-to-vector (Word2Vec), FastText and global vectors for word representation (GloVe), were utilized. All of these descriptors and embeddings were directly extracted from RNA sequences. H2Opred incorporated both stacked 1D convolutional neural network (1D-CNN) blocks and stacked attention-based bidirectional gated recurrent unit (Bi-GRU-Att) blocks to learn effective feature representations from 14 conventional descriptors and five NLP-based embeddings, respectively. These feature representations were then combined to make the final prediction. Ablation analysis showed that both 1D-CNN and Bi-GRU-Att blocks were essential for H2Opred’s optimal performance. The H2Opred models exhibited outstanding performance during cross-validation and independent testing, surpassing the capabilities of large-scale conventional ML-based single-feature models. Notably, the generic H2Opred model outperformed both the existing predictor and the four nucleotide-specific H2Opred models, demonstrating that the intelligent integration of conventional descriptors and pretrained model-based embeddings extracted from a large training dataset through HDL enhances both prediction accuracy and interpretability.</p>
  </sec>
  <sec id="sec4">
    <title>MATERIALS AND METHODS</title>
    <sec id="sec5">
      <title>Dataset</title>
      <p>We used the same benchmark dataset proposed by Yang <italic toggle="yes">et al</italic>. [<xref rid="ref25" ref-type="bibr">25</xref>], because it is the most recent, comprehensive and non-redundant dataset available. The authors obtained 2OM sites from two different sources: RMBase v2.0 [<xref rid="ref16" ref-type="bibr">16</xref>] and the recent experimental dataset generated by Nm-seq [<xref rid="ref10" ref-type="bibr">10</xref>] and deposited in the GEO database (GSE90164). In total, they obtained 7597 2OM sites distributed in CDS, 3’-UTR, 5’-UTR, intron, exon and intergenic regions, and containing almost all types of RNA (tRNAs, rRNAs, scRNAs, scaRNAs, snRNAs, snoRNAs, lincRNAs, protein-coding genes, pseudogenes, etc.). Since the majority of sequences from RMBase v2.0 have a sequence length of 41 bp (20 upstream and 20 downstream based with the center 2OM sites), the authors extracted the same sequence length from the experimental data. To generate negative samples, the authors employed the same strategies as previous studies and generated a large number of sequences. Subsequently, they applied CD-HIT [<xref rid="ref26" ref-type="bibr">26</xref>] with a threshold of 80% to remove redundant sequences, resulting in 6091 positive samples and 21 520 negative samples. To address class bias, which is a common problem when developing prediction models with imbalanced datasets [<xref rid="ref27" ref-type="bibr">27</xref>], the authors selected the same number of negative samples as positive samples. The authors then divided the dataset into four subsets, centered on A, U, C and G corresponding to A2OM, U2OM, C2OM and G2OM, respectively. The A2OM dataset contains 2176 training and 934 testing samples, the U2OM dataset contains 2236 training and 960 testing samples, the C2OM dataset contains 2278 training and 788 testing samples and the G2OM dataset contains 1832 training and 788 testing samples. Notably, all training and testing samples contain an equal number of positive and negative samples. It should be noted that we have used the same training datasets for the model development in this study. However, we used entirely different testing datasets to check the model transferability. Specifically, we supplemented the existing nucleotide-specific testing datasets with our own collections. Positive samples were collected from RMDisease v2.0 [<xref rid="ref28" ref-type="bibr">28</xref>], and excluded the redundant samples, resulting in 34, 82, 12 and 173 positive samples for A2OM, C2OM, G2OM and U2OM, respectively. Regarding the negative samples, we considered all possible chromosomes in <italic toggle="yes">H. sapiens</italic> and selected sequences with four different nucleotide bases as central residues, flanked by 20 nucleotides both upstream and downstream. From these, we randomly chose samples 10-fold larger in number than positive samples. Importantly, newly constructed samples were not present in the existing training and the testing datasets. Finally, we obtained 501 positive and 5010 negative samples for A2OM, 571 positive and 5710 negative samples for C2OM, 406 positive and 4060 negative samples for G2OM and 653 positive and 6530 negative samples for U2OM.</p>
    </sec>
    <sec id="sec6">
      <title>Feature extraction</title>
      <p>We used 14 conventional descriptors and five NLP-based embeddings to represent RNA sequences. The conventional descriptors covered different properties of sequence information and were widely used in bioinformatics [<xref rid="ref18" ref-type="bibr">18</xref>, <xref rid="ref29" ref-type="bibr">29</xref>, <xref rid="ref30" ref-type="bibr">30</xref>]. The NLP-based embeddings were trained on large datasets of DNA and RNA sequences to capture their linguistic features. The conventional descriptors included Kmer, BPF, NCP, DBE, DPCP_1, DPCP_2, PS2, RCKmer, PseEIIP, CKSNAP, ENAC, Zcurve, ASLPN and MMNF. The NLP-based embeddings included DNABERT, Seq2Vec, Word2vec, FastText and GloVe. A detailed description of these descriptors and embeddings is provided in the supplementary information.</p>
    </sec>
    <sec id="sec7">
      <title>Framework of H2Opred</title>
      <p>In this study, we proposed an HDL model to predict 2OM sites in human RNA sequences (<xref rid="f1" ref-type="fig">Figure 1</xref>). The HDL model consisted of stacked 1D-CNN blocks and stacked Bi-GRU-Att blocks, which learned and extracted both spatial and temporal-sequential feature representations from conventional descriptors and NLP-based embeddings. The details of these blocks are presented below.</p>
      <fig position="float" id="f1">
        <label>Figure 1</label>
        <caption>
          <p>The workflow of constructing H2Opred framework. (A) Four 2’-O-methylation (2OM) site types were collected and split into training and independent datasets, where the combined dataset was constructed by integrating all four 2OM site types together as well as removing redundancy and identical samples. (B) Subsequently, 14 conventional descriptors and five NLP-based embeddings were extracted and then fed into stacked convolutional neural network (1D-CNN) blocks and stacked attention-based bidirectional gated recurrent unit (Bi-GRU-Att) blocks to acquire spatial and temporal-sequential feature representations for final prediction model. (C) During the testing phase, the testing datasets were submitted to the web server, resulting in either 2OM or non-2OM sites. (Created with <ext-link xlink:href="http://www.biorender.com" ext-link-type="uri">BioRender.com</ext-link>).</p>
        </caption>
        <graphic xlink:href="bbad476f1" position="float"/>
      </fig>
    </sec>
    <sec id="sec8">
      <title>Stacked 1D-CNN</title>
      <p>To extract and learn the spatial feature representations from the RNA sequences, we designed a 1D-CNN block for each conventional descriptor. Inspired by the stacking CNN approach utilized in recent studies [<xref rid="ref31" ref-type="bibr">31–34</xref>], we developed 14 1D-CNN blocks and integrated them to handle the 14 conventional descriptors. Each 1D-CNN block consisted of three 1D convolutional (Conv1D) layers, three max pooling layers and one fully connected (FC) layer at the end. Given an input <inline-formula><tex-math notation="LaTeX" id="ineq01">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X{c}_{in}$\end{document}</tex-math></inline-formula> of (<inline-formula><tex-math notation="LaTeX" id="ineq02">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$B,{L}_{in},{C}_{in}$\end{document}</tex-math></inline-formula>), Conv1D will obtain an output <inline-formula><tex-math notation="LaTeX" id="ineq03">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X{c}_{out}$\end{document}</tex-math></inline-formula> of (<inline-formula><tex-math notation="LaTeX" id="ineq04">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$B,{L}_{out},{C}_{out}$\end{document}</tex-math></inline-formula>) as follows:</p>
      <disp-formula id="deqn01">
        <label>(1)</label>
        <tex-math notation="LaTeX" id="DmEquation1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} X{c}_{ou t}\left(B,{C}_{{ou t}_j}\right)= bc+\sum \limits_{k=0}^{C_{in}-1} Wc\left({C}_{ou{t}_j},k\right)\ast X{c}_{in}\left(B,k\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq05">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\ast$\end{document}</tex-math></inline-formula> denote the cross-correlation operation, <inline-formula><tex-math notation="LaTeX" id="ineq06">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$Wc$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq07">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$bc$\end{document}</tex-math></inline-formula> are weight and bias, <inline-formula><tex-math notation="LaTeX" id="ineq08">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$B$\end{document}</tex-math></inline-formula> is the batch size, <inline-formula><tex-math notation="LaTeX" id="ineq09">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${L}_{in}$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${C}_{in}$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${L}_{out}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq12">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${C}_{out}$\end{document}</tex-math></inline-formula> are the input length, the number of the input channels, output length and the number of the output channels, respectively, in which <inline-formula><tex-math notation="LaTeX" id="ineq13">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${L}_{out}$\end{document}</tex-math></inline-formula> can be computed as follows:</p>
      <disp-formula id="deqn02">
        <label>(2)</label>
        <tex-math notation="LaTeX" id="DmEquation2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {L}_{out}=1+\frac{L_{in}+2P-D\left(k-1\right)-1}{S}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq14">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$P$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq15">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$D$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq16">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\kappa$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq17">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$S$\end{document}</tex-math></inline-formula> are the padding size, dilation rate, kernel size and stride, respectively. Then, each Conv1D layer was passed through a ReLU (rectified linear unit) activation function, which can be defined as follows:</p>
      <disp-formula id="deqn03">
        <label>(3)</label>
        <tex-math notation="LaTeX" id="DmEquation3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} \mathrm{ReLU}(x)=\max \left(0,x\right). \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>To achieve dimensional reduction, we incorporated one max pooling layer immediately after each Conv1D layer. The operation of each max pooling layer is outlined as follows:</p>
      <disp-formula id="deqn04">
        <label>(4)</label>
        <tex-math notation="LaTeX" id="DmEquation4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} X{m}_{out}\left(B,{C}_j,k\right)=\underset{p=0,...,\kappa -1}{\max }X{m}_{in}\left(B,{C}_j,S\times k+p\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq18">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X{m}_{in}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq19">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X{m}_{out}$\end{document}</tex-math></inline-formula> are the input and output of the max pooling layer. It should be noted that only the length of the output changed after applying the max pooling layer. Finally, the feature representations were flattened and fed into an FC layer to produce the final feature representations. In addition, a dropout layer was applied after flattening the features to prevent overfitting. The configuration of each stacked 1D-CNN block was described in detail in the optimization process section.</p>
    </sec>
    <sec id="sec9">
      <title>Stacked Bi-GRU-Att</title>
      <p>To extract the temporal-sequential information from RNA sequences, we designed a Bi-GRU-Att block to capture temporal-sequential feature representations from each of five NLP-based embeddings extracted from RNA sequences. It should be noted that Bi-GRU was chosen over a single GRU because it can capture temporal-sequential feature representations in both the forward and backward directions of the sequence, resulting in more robust and informative feature representations. Additionally, Bi-GRU architecture was selected over LSTM or Bi-LSTM because it is simple and has fewer output gates, making it faster and more effective to train, especially with limited data. To address the challenge of not every feature representation equally informative for characterizing RNA sequence, we incorporated an attention mechanism [<xref rid="ref35" ref-type="bibr">35–38</xref>] to selectively focus on the most relevant and crucial feature representations for discriminating 2OM sites. The mathematical equations of each GRU can be expressed as follows:</p>
      <disp-formula id="deqn05">
        <label>(5)</label>
        <tex-math notation="LaTeX" id="DmEquation5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {u}_t=\sigma \left({W}_{iu}{x}_t+{U}_{hu}{h}_{\left(t-1\right)}+{b}_{iu}+{b}_{hu}\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn06">
        <label>(6)</label>
        <tex-math notation="LaTeX" id="DmEquation6">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {r}_t=\sigma \left({W}_{ir}{x}_t+{U}_{hr}{h}_{\left(t-1\right)}+{b}_{ir}+{b}_{hr}\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn07">
        <label>(7)</label>
        <tex-math notation="LaTeX" id="DmEquation7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} \qquad\quad{\tilde{\eta}}_t=\tau \left({W}_{i\tilde{\eta}}{x}_t+{r}_t\odot \left({U}_{h\tilde{\eta}}{h}_{\left(t-1\right)}+{b}_{h\tilde{\eta}}\right)+{b}_{i\tilde{\eta}}\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn08">
        <label>(8)</label>
        <tex-math notation="LaTeX" id="DmEquation8">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {h}_t=\left(1-{u}_t\right)\odot{\tilde{\eta}}_t+{u}_t\odot{h}_{\left(t-1\right)},\qquad\quad \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq20">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${u}_t$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq21">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${r}_t$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq22">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\tilde{\eta}}_t$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq23">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${h}_t$\end{document}</tex-math></inline-formula> represent the update gate, the reset gate, the new gate (or the hidden candidate status) and the hidden gate, respectively; <inline-formula><tex-math notation="LaTeX" id="ineq24">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${x}_t$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq25">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$W$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq26">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$U$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq27">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$b$\end{document}</tex-math></inline-formula> are the input vectors, the weight matrices and the bias vector; <inline-formula><tex-math notation="LaTeX" id="ineq28">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\sigma$\end{document}</tex-math></inline-formula> denotes the sigmoid function, <inline-formula><tex-math notation="LaTeX" id="ineq29">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\tau$\end{document}</tex-math></inline-formula> denotes the tanh function and <inline-formula><tex-math notation="LaTeX" id="ineq30">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\odot$\end{document}</tex-math></inline-formula> denotes the Hadamard product.</p>
      <p>And the mathematical equations of attention mechanism can be defined as follows:</p>
      <disp-formula id="deqn09">
        <label>(9)</label>
        <tex-math notation="LaTeX" id="DmEquation9">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {A}_{ij}={x}_a^T\tau \left({W}_a{h}_i+b\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn10">
        <label>(10)</label>
        <tex-math notation="LaTeX" id="DmEquation10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {\alpha}_{ij}=\frac{e^{\left({A}_{ij}\right)}}{\sum \limits_{t=1}^T{e}^{\left({A}_{ij}\right)}},\qquad\ \ \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn11">
        <label>(11)</label>
        <tex-math notation="LaTeX" id="DmEquation11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {c}_i=\sum \limits_{j=1}^T{\alpha}_{ij}{h}_j, \qquad\ \ \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq31">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${x}_a$\end{document}</tex-math></inline-formula> is the random initialization vector, <inline-formula><tex-math notation="LaTeX" id="ineq32">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${A}_{ij}$\end{document}</tex-math></inline-formula> is the attention weight, <inline-formula><tex-math notation="LaTeX" id="ineq33">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${h}_i=\left[{\overrightarrow{h}}_t;{\overleftarrow{h}}_t\right]$\end{document}</tex-math></inline-formula> is the output of Bi-GRU at the time step <inline-formula><tex-math notation="LaTeX" id="ineq34">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t$\end{document}</tex-math></inline-formula> that concatenates both forward and backward information, <inline-formula><tex-math notation="LaTeX" id="ineq35">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$T=41$\end{document}</tex-math></inline-formula> is the length of the input sequence, <inline-formula><tex-math notation="LaTeX" id="ineq36">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\alpha}_{ij}$\end{document}</tex-math></inline-formula> is the output score of the attention weight by applying SoftMax function and <inline-formula><tex-math notation="LaTeX" id="ineq37">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${c}_i$\end{document}</tex-math></inline-formula> is the attention output.</p>
      <p>Motivated by the stacking recurrent neural network-based approaches employed in recent studies [<xref rid="ref39" ref-type="bibr">39</xref>, <xref rid="ref40" ref-type="bibr">40</xref>], we developed five Bi-GRU-Att blocks that were subsequently combined to handle the five NLP-bassed embeddings. Notably, each Bi-GRU-Att block contained two Bi-GRU layers, followed by an attention layer and an FC layer. The hidden state generated by the first Bi-GRU layer was used as the input of the second Bi-GRU layer. For more details on the specific configuration of the Bi-GRU-Att blocks, please refer to the optimization process section.</p>
    </sec>
    <sec id="sec10">
      <title>Optimization process of H2Opred</title>
      <p>We conducted a comprehensive optimization process to select the best model for constructing H2Opred. <xref rid="sup1" ref-type="supplementary-material">Table S1</xref> represents our parameter search range implemented in this study. Importantly, we used 5-fold cross-validation during the training phase to tune the hyperparameters within the specified search range and determine the optimal set of hyperparameters.</p>
      <p>Here, the binary cross-entropy loss function (<inline-formula><tex-math notation="LaTeX" id="ineq38">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${L}_{BCE}$\end{document}</tex-math></inline-formula>) was used as an objective function to optimize the parameters during training model, which can be defined as follows:</p>
      <disp-formula id="deqn12">
        <label>(12)</label>
        <tex-math notation="LaTeX" id="DmEquation12">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {L}_{BCE}=\frac{1}{N_s}\sum \limits_{s=1}^{N_s}{y}_s\log \left(\wp \left({\hat{y}}_s\right)\right)+\left(1-{y}_s\right)\log \left(1-\wp \left({\hat{y}}_s\right)\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq39">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${N}_s$\end{document}</tex-math></inline-formula> is the number of samples, <inline-formula><tex-math notation="LaTeX" id="ineq40">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$s=\mathrm{1...}{N}_s$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq41">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${y}_s$\end{document}</tex-math></inline-formula> is the ground truth label and <inline-formula><tex-math notation="LaTeX" id="ineq42">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\hat{y}}_s$\end{document}</tex-math></inline-formula> is the predicted label. In addition, it should be noted that <inline-formula><tex-math notation="LaTeX" id="ineq43">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\wp \left({\hat{y}}_s\right)$\end{document}</tex-math></inline-formula> represents the probability of 2OM and <inline-formula><tex-math notation="LaTeX" id="ineq44">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$1-\wp \left({\hat{y}}_s\right)$\end{document}</tex-math></inline-formula> represents the probability of non-2OM.</p>
    </sec>
    <sec id="sec11">
      <title>Performance evaluation metrics</title>
      <p>In this study, several commonly used performance evaluation metrics [<xref rid="ref41" ref-type="bibr">41–43</xref>] were utilized to evaluate the model performance during training, independent testing as well as comparison, which included accuracy (ACC), Mathews correlation coefficient (MCC), sensitivity (Sn), specificity (Sp), precision (PRE), area under the receiver operating characteristic curve (AUC) and F1-score. Their mathematical equations can be expressed as follows:</p>
      <disp-formula id="deqn13">
        <label>(13)</label>
        <tex-math notation="LaTeX" id="DmEquation13">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} ACC=\frac{TP+ TN}{TP+ TN+ FP+ FN}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn14">
        <label>(14)</label>
        <tex-math notation="LaTeX" id="DmEquation14">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} MCC=\frac{TP\times TN- FP\times FN}{\sqrt{\left( TP+ FP\right)\times \left( TP+ FN\right)\times \left( TN+ FP\right)\times \left( TN+ FN\right)}}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn15">
        <label>(15)</label>
        <tex-math notation="LaTeX" id="DmEquation15">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} Sn=\frac{TP}{TP+ FN}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn16">
        <label>(16)</label>
        <tex-math notation="LaTeX" id="DmEquation16">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} Sp=\frac{TN}{TN+ FP}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn17">
        <label>(17)</label>
        <tex-math notation="LaTeX" id="DmEquation17">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} PRE=\frac{TP}{TP+ FP}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn18">
        <label>(18)</label>
        <tex-math notation="LaTeX" id="DmEquation18">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} F1- score=\frac{2\times TP}{2\times TP+ FP+ FN}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where TP represents the count of test results that correctly match with positive samples, TN represents the count of test results that correctly match with negative samples, FP stands for the count of test results that incorrectly indicate positive samples and FN denotes the count of test results that incorrectly indicate negative samples.</p>
    </sec>
  </sec>
  <sec id="sec12">
    <title>RESULTS AND DISCUSSION</title>
    <sec id="sec13">
      <title>Assessment of conventional descriptors using 11 different ML algorithms on the training and independent testing datasets</title>
      <p>Inspired by previous studies [<xref rid="ref29" ref-type="bibr">29</xref>, <xref rid="ref44" ref-type="bibr">44</xref>], we evaluated 14 conventional RNA sequence descriptors that capture different aspects of sequence information, such as composition, position-specific, physicochemical properties and sequence order. To quantify the intrinsic capability of these feature descriptors for distinguishing 2OM from non-2OM in different datasets, we evaluated the performance of each descriptor using 11 conventional ML-based classifiers (including random forest (RF), extremely randomized trees (ERT), gradient boosting trees (GBT), AdaBoost trees (ABT), extreme GBT (XGBT), SVM, deep neural network (DNN), light GBT (LGBT), decision trees (DT), logistic regression (LR) and catBoost (CB)) by means of randomized 10-fold cross-validation procedure. This technique helps to prevent model overfitting during training [<xref rid="ref45" ref-type="bibr">45</xref>, <xref rid="ref46" ref-type="bibr">46</xref>].</p>
      <p>In total, we generated 616 models (154 models * 4 datasets) during the training and assessed its transferability with the independent testing datasets (<xref rid="sup1" ref-type="supplementary-material">Figures S1</xref>–<xref rid="sup1" ref-type="supplementary-material">S4</xref>). We were more interested in the discriminative capability of the feature descriptors than in the performance of any specific classifier. To get an overview of how well each descriptor performed, we averaged the ACC of the 11 classifiers-based models trained on each descriptor and the results were shown in <xref rid="f2" ref-type="fig">Figure 2A</xref>. All of these descriptors achieved reasonable performance on the A2OM, C2OM and G2OM datasets, with average ACC in the ranges of 0.768–0.844, 0.747–0.825 and 0.755–0.826, respectively. However, the performance on the U2OM dataset was significantly lower, with average ACC in the range of 0.674–0.711. After evaluating the performance of 616 models on the independent testing datasets (<xref rid="f2" ref-type="fig">Figure 2B</xref>), we observed that the average performance of each descriptor on the independent testing datasets was similar to that on the training datasets, with the U2OM dataset being the most challenging dataset. Specifically, the average ACC of the descriptors on the independent testing datasets ranged from 0.752 to 0.885 for A2OM, 0.736 to 0.877 for C2OM, 0.751 to 0.863 for G2OM and 0.695 to 0.791 for U2OM. Out of the 14 descriptors, DPCP_2, Kmer and PS2 performed the best on the training datasets, with ACC of 0.837–0.844 for A2OM, 0.822–0.825 for C2OM and 0.815–0.826 for G2OM. Notably, DPCP_2 and PS2 maintained a similar level of performance on the corresponding testing datasets. Since each of the descriptors captures different aspects of sequence information, we included all 14 conventional descriptors in the construction of an HDL framework.</p>
      <fig position="float" id="f2">
        <label>Figure 2</label>
        <caption>
          <p>Average accuracy (ACC) achieved by 11 conventional ML-based classifiers for each of the 14 conventional descriptors. The comparative performance of four nucleotide-specific models is shown for training datasets (A) and testing datasets (B).</p>
        </caption>
        <graphic xlink:href="bbad476f2" position="float"/>
      </fig>
    </sec>
    <sec id="sec14">
      <title>Evaluation of H2Opred for 2OM site prediction on the training and independent testing datasets</title>
      <p>H2Opred was constructed using an HDL approach (see Materials and methods section). This approach combined stacked 1D-CNN blocks to learn effective feature representations from 14 conventional descriptors, and stacked Bi-GRU-Att blocks to learn feature representations from five NLP-based embeddings. These feature representations were then combined to make the final prediction. <xref rid="f3" ref-type="fig">Figure 3</xref> compares the performance of H2Opred with two individual approaches, 1D-CNN and Bi-GRU-Att. Among the 1D-CNN and Bi-GRU-Att models, 1D-CNN achieved consistently better performance on four training datasets, with improvement in MCCs of 0.09%, 1.60%, 2.60% and 0.06% for A2OM, C2OM, G2OM and U2OM, respectively. When combining these two models, H2Opred achieved MCC and ACC of 0.762 and 0.881 in A2OM, 0.732 and 0.865 in C2OM, 0.715 and 0.856 in G2OM and 0.603 and 0.801 in U2OM. Specifically, H2Opred outperformed 1D-CNN on three training datasets (A2OM, C2OM and G2OM), and achieved similar performance on the U2OM dataset. Overfitting occurs when the ML model learns the training data too well, and is unable to generalize to new data. To avoid overfitting, it is important to evaluate the model’s performance on the independent testing datasets.</p>
      <fig position="float" id="f3">
        <label>Figure 3</label>
        <caption>
          <p>Comparison of nucleotide-specific H2Opred models and individual stacking models (1D-CNN and Bi-GRU-Att) on the training and testing datasets. Performance on the A2OM training (A) and testing (B) datasets, C2OM training (C) and testing (D) datasets, G2OM training (E) and testing (F) datasets, and U2OM training (G) and testing (H) datasets.</p>
        </caption>
        <graphic xlink:href="bbad476f3" position="float"/>
      </fig>
      <p>We comprehensively evaluated the three deep learning models on four different testing datasets. In contrast to training performance, Bi-GRU-Att consistently outperformed 1D-CNN across all testing datasets, with improvement in MCCs of 2.57%, 4.04%, 1.09% and 4.31% for A2OM, C2OM, G2OM and U2OM, respectively, as shown in <xref rid="f3" ref-type="fig">Figure 3</xref>. However, H2Opred significantly outperformed both 1D-CNN and Bi-GRU-Att on all four testing datasets. Specifically, H2Opred improved MCC by 1.84–4.41% in A2OM, 1.23–5.27% in C2OM, 4.64–5.72% in G2OM and 1.23–5.53% in U2OM compared with Bi-GRU-Att and 1D-CNN, respectively. Overall, H2Opred demonstrated superior performance compared with both 1D-CNN and Bi-GRU-Att, exhibiting consistent performance across both training and testing datasets. To highlight the advantages of H2Opred, we compared its performance against the top five conventional ML-based single-feature models for each of the four nucleotide-specific models. As illustrated in <xref rid="sup1" ref-type="supplementary-material">Figure S5</xref>, H2Opred achieved significantly better results than the conventional ML-based single-feature models on both training and independent datasets. These findings suggest that H2Opred possesses greater stability and generalizability across diverse data scenarios, because it can learn effective feature representations by combining conventional descriptors with NLP-based embeddings.</p>
    </sec>
    <sec id="sec15">
      <title>Cross nucleotide-specific model validation</title>
      <p>We assessed the transferability of nucleotide-specific models to different testing datasets. We examined whether A2OM model is transferable to other types (C2OM, G2OM and U2OM), and vice versa, as shown in <xref rid="f4" ref-type="fig">Figure 4</xref>. When the A2OM testing dataset was evaluated with the other three trained models (G2OM, C2OM and U2OM), they achieved the ACC in the range of 0.830 to 0.916, the AUC in the range of 0.917 to 0.934 and the MCC in the range of 0.466 to 0.609. Similarly, the trained A2OM, G2OM and U2OM models achieved the ACC in the range of 0.822 to 0.925, the AUC in the range of 0.914 to 0.924 and the MCC in the range 0.434 to 0.600 on the C2OM testing dataset; the trained A2OM, C2OM and U2OM models achieved the ACC in the range of 0.796 to 0.906, the AUC in the range of 0.906 to 0.944 and the MCC in the range of 0.416 to 0.592 on the G2OM testing dataset; and the trained A2OM, C2OM and G2OM models achieved the ACC in the range of 0.905 to 0.915, the AUC in the range of 0.879 to 0.894 and the MCC in the range of 0.480 to 0.505 on the U2OM testing dataset. Overall, these analyses highlight that a nucleotide-specific model can be effectively transferrable to other nucleotides with satisfactory accuracy. Previous studies [<xref rid="ref10" ref-type="bibr">10</xref>, <xref rid="ref25" ref-type="bibr">25</xref>] have highlighted those four different nucleotides shares similar motif patterns at 2OM sites. This prompted us to investigate whether developing a generic model by integrating four different nucleotides could enhance the prediction performance compared with individual nucleotide-specific models.</p>
      <fig position="float" id="f4">
        <label>Figure 4</label>
        <caption>
          <p>Heat map illustrating the cross-nucleotide model validation based on the testing datasets. Each nucleotide-specific model is evaluated with its own dataset as well as the remaining three nucleotide-specific datasets. The performance is assessed using three metrics: (A) Mathews correlation coefficient (MCC), (B) accuracy (ACC) and (C) area under the receiver operating characteristic curve (AUC).</p>
        </caption>
        <graphic xlink:href="bbad476f4" position="float"/>
      </fig>
    </sec>
    <sec id="sec16">
      <title>Development of a generic model</title>
      <p>To develop a generic model, we integrated the four nucleotide-specific datasets and eliminated redundant sequences using CD-HIT, resulting in 4256 positive and 4255 negative samples. The generic model was then built using the same approach outlined for the nucleotide-specific models. The results demonstrated that the generic model achieved MCC, Sn, Sp, ACC and AUC of 0.719, 0.840, 0.876, 0.858 and 0.937, respectively, during training. The corresponding values on the testing dataset were 0.602, 0.828, 0.918, 0.910 and 0.946, respectively (<xref rid="sup1" ref-type="supplementary-material">Figure S6</xref>). We compared the generic model’s performance with the individual nucleotide-specific models in two ways: (i) we averaged the performance of four nucleotide-specific models and compared it with the generic model. <xref rid="sup1" ref-type="supplementary-material">Figure S6</xref> shows that the generic approach consistently outperformed the nucleotide-specific approach in terms of MCC, ACC and AUC on both training and testing datasets. (ii) We categorized generic model’s predictions based on nucleotide specificity and compared them with the individual nucleotide-specific models. <xref rid="f5" ref-type="fig">Figure 5</xref> illustrates that the generic model marginally improved MCC, ACC and AUC on G2OM and U2OM, and significantly improved on the other two nucleotide training datasets. However, the generic model significantly outperformed all four nucleotide-specific models on the independent testing datasets. In addition, we developed 154 conventional models, as previously mentioned for the development of nucleotide-specific models, to investigate whether any of these models surpassed the performance of the HDL-based generic model. As illustrated in <xref rid="sup1" ref-type="supplementary-material">Figure S7</xref>, the HDL-based generic model consistently outperformed the top five best models based on the MCC among the conventional models on both training and independent datasets, highlighting the significance of the HDL approach implemented in H2Opred.</p>
      <fig position="float" id="f5">
        <label>Figure 5</label>
        <caption>
          <p>Performance of the generic model for each of the four nucleotides is compared with the corresponding nucleotide-specific models. The comparison is shown for both the (A) training dataset and (B) testing dataset.</p>
        </caption>
        <graphic xlink:href="bbad476f5" position="float"/>
      </fig>
      <p>Unlike individual nucleotides, 2OM occurs on the ribose moiety rather than specific modification sites like 5-methyl cytosine (m5C) and 6-methyl adenosine (m6A). As 2OM is not directly linked to nucleotide bases, using a generic dataset instead of nucleotide-specific datasets would be more appropriate since such datasets lack biological significance. Overall, the enhanced performance of our generic model can be attributed primarily to the larger training dataset.</p>
    </sec>
    <sec id="sec17">
      <title>Comparison of H2Opred models with the state-of-the art predictors on the independent testing datasets</title>
      <p>To further demonstrate the superiority of H2Opred models, we tried to compare them with four previously published methods: NmSEER v2.0, NmRF, DeepOMe and i2OM. However, we encountered challenges in extracting prediction results from the given sequence when using NmSEER v2.0 and DeepOMe. Therefore, we excluded these two methods from our comparative analysis and focused on NmRF and i2OM. Upon scrutinizing the performance of these two state-of-the-art predictors, we found that NmRF performed poorly, with results approaching random prediction levels (<xref rid="sup1" ref-type="supplementary-material">Figure S8</xref>). This makes NmRF unsuitable for genome-wide predictions. The primary reason for this subpar performance is that NmRF was trained on a substantially different dataset with a smaller number of samples than our models and i2OM. Comparing nucleotide-specific H2Opred models and i2OM directly is more straightforward and insightful because they were trained on the same datasets, allowing for a more meaningful evaluation of their respective performances. However, the generic H2Opred model was trained on different and larger training dataset. Owing to the challenges in accessing results from the i2OM web server, we utilized the standalone program (<ext-link xlink:href="https://github.com/yangmoo1010/i2OM" ext-link-type="uri">https://github.com/yangmoo1010/i2OM</ext-link>) to compute the results.</p>
      <p><xref rid="f6" ref-type="fig">Figure 6</xref> clearly shows that the generic H2Opred model achieved the best performance across all testing datasets. Compared with i2OM, the generic H2Opred model demonstrated significant improvements across several key metrics, including MCC, ACC, AUC and F1-score. Specifically, on the A2OM testing dataset, the generic H2Opred model achieved 45.44% improvement in MCC, 46.00% in ACC, 9.16% in AUC and 43.16% in F1-score. Similarly, on the C2OM testing dataset, the generic H2Opred model outperformed i2OM with improvements of 10.05% in MCC, 3.31% in ACC, 3.40% in AUC and 9.52% in F1-score. The advantages of the generic H2Opred model were evident on the G2OM testing dataset, where it achieved improvements of 7.03% in MCC, 2.49% in ACC, 2.35% in AUC and 6.74% in F1-score. On the U2OM testing dataset, the generic H2Opred model achieved with remarkable improvements of 28.10% in MCC, 11.64% in ACC, 15.42% in AUC and 24.73% in F1-score. Furthermore, the generic H2Opred model consistently outperformed the nucleotide-specific H2Opred models across all datasets, demonstrating the significant of a larger training on performance improvement. These results highlight the stability and excellence of proposed H2Opred models, making H2Opred as an effective and valuable computational tool for the precise identification of RNA 2OM sites.</p>
      <fig position="float" id="f6">
        <label>Figure 6</label>
        <caption>
          <p>Comparison of the performance of different H2Opred models and the state-of-the-art i2OM predictor on four testing datasets. (A) A2OM, (B) C2OM, (C) G2OM and (D) U2OM.</p>
        </caption>
        <graphic xlink:href="bbad476f6" position="float"/>
      </fig>
    </sec>
    <sec id="sec18">
      <title>Visualization of learned features</title>
      <p>In this section, we focused on the best generic model and visualized the learned features extracted by 1D-CNN, Bi-GRU-Att and H2Opred to understand the abstractions generated by these deep learning architectures. We employed UMAP, a novel dimensionality reduction technique, to reduce the original features into a 2D vector. <xref rid="f7" ref-type="fig">Figure 7</xref> shows that the feature representations learned by Bi-GRU-Att showed minimal overlap between 2OM and non-2OM sites, while those learned by 1D-CNN showed more overlapping samples. However, the feature representations learned by H2Opred showed a clear separation of 2OM and non-2OM samples on the generic training dataset. This suggests that H2Opred is capable of extracting the most informative and discriminative features through 1D-CNN and Bi-GRU-Att. The feature representation patterns observed in the training dataset follows a similar on the testing dataset for three deep learning architectures, demonstrating that the model is able to learn robust representations of the 2OM and non-2OM sites from training datasets, which can be generalized to new data.</p>
      <fig position="float" id="f7">
        <label>Figure 7</label>
        <caption>
          <p>UMAP visualization of the learned feature representations of three models (1D-CNN, Bi-GRU-Att and H2Opred) on the generic training (A–C) and independent testing (D–F) datasets.</p>
        </caption>
        <graphic xlink:href="bbad476f7" position="float"/>
      </fig>
      <p>Through UMAP visualization, we demonstrated that conventional feature descriptors and NLP-based embeddings can be mapped into meaningful representations through the HDL approach. This suggests that H2Opred can capture complex relationships between different features, which is not possible with conventional ML-based single-feature models. Consequently, H2Opred consistently outperformed other deep learning-based models and conventional ML-based single-feature models, making it a promising tool for identifying 2OM sites in the human genome.</p>
    </sec>
    <sec id="sec19">
      <title>Web server implementation</title>
      <p>H2Opred, a user-friendly web server for predicting RNA 2OM sites, is now freely available at <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>. The website also provides access to all training and testing datasets employed in this study. To use H2Opred, users can either upload a file containing multiple FASTA sequences or input one or more query sequences in FASTA format. The input sequence must be in the FASTA format and exactly 41 bp long. Users are then be prompted to select their model of choice (N2OM, A2OM, G2OM, C2OM or U2OM) before job submission. If no model is selected, the N2OM model will be employed automatically. Upon successful job completion, the results are presented on a dedicated interface, allowing users to easily view and analyze the findings. Additionally, users have the option to download the results in CSV format for future reference.</p>
    </sec>
  </sec>
  <sec id="sec20">
    <title>CONCLUSION</title>
    <p>2OM is a common post-transcriptional modification with important implications for various biological functions. Understanding its distribution within RNA can provide insights into its mechanism of action. In this study, we introduced a novel HDL model called H2Opred, to accurately identify 2OM sites from primary RNA sequences. We first identified 14 conventional descriptors and evaluated their discriminative patterns using the 11 ML-based classifiers. We then used stacked 1D-CNN to learn the feature representations from these conventional descriptors. Next, we used NLP-based embeddings derived from RNA sequence and trained using stacked Bi-GRU-Att to capture more diverse facets of feature representations. Finally, we integrated these two distinct feature representations to make final prediction. Rigorous cross-validation and independent testing on different datasets showed that H2Opred achieved a more balanced performance and consistently outperformed the two deep learning architectures as well as several hundreds of ML-based single-feature models.</p>
    <p>In contrast to individual nucleotides, which have specific modification sites like m5C and m6A, 2OM occurs on the ribose moiety, a structural component of RNA. Therefore, developing 2OM site prediction model using the nucleotide-specific datasets lacks biological significance. Indeed, our cross-nucleotide model analysis demonstrated the transferability of nucleotide-specific models across other nucleotide datasets, suggesting that a generic model can be developed by integrating all nucleotide-specific datasets. To this end, we developed a generic model that showed significant improvement on both training and testing datasets compared with the nucleotide-specific models. In the H2Opred webserver, we have incorporated both the four nucleotide-specific models and a generic model. Notably, each of these models demonstrated superior performance over the existing predictor i2OM across all evaluation metrics on the independent testing datasets. This suggests that our HDL framework integrated conventional descriptors with NLP-based embeddings to significantly improve prediction performance. To make H2Opred widely accessible and user-friendly, we have launched a dedicated web server at <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>. We believe that this online platform will be invaluable for researchers seeking to accurately predict 2OM sites in human RNA, advancing scientific progress in this field. The current approach can be extended to other RNA post-transcriptional prediction sites [<xref rid="ref47" ref-type="bibr">47</xref>], RNA subcellular localization [<xref rid="ref48" ref-type="bibr">48</xref>] and peptide therapeutic function prediction [<xref rid="ref27" ref-type="bibr">27</xref>].</p>
    <p>H2Opred has shown significant promise in predicting 2OM sites, but there are areas for further refinement. The proposed model was trained on a larger dataset than existing methods. However, we can further enhance the model performance by incorporating new data as it becomes available. We integrated conventional descriptors with NLP-based embeddings through an HDL framework, but future work could explore other methodologies, such as contrastive learning [<xref rid="ref49" ref-type="bibr">49</xref>, <xref rid="ref50" ref-type="bibr">50</xref>], ensemble or stacking approaches based on conventional ML classifiers [<xref rid="ref51" ref-type="bibr">51</xref>], hybrid feature approach [<xref rid="ref52" ref-type="bibr">52</xref>], feature representation learning [<xref rid="ref53" ref-type="bibr">53</xref>] and iterative feature refinement [<xref rid="ref54" ref-type="bibr">54</xref>, <xref rid="ref55" ref-type="bibr">55</xref>]. Beyond conventional descriptors and NLP-based embeddings, the topological structure of RNA sequences also plays an important role in defining their functions. To improve feature representation, we could incorporate predicted structural information within the HDL framework. Currently, H2Opred is still a ‘black box’, limiting its ability to explain its decisions. In the future, we aspire to develop a model that is not only accurate but also interpretable, providing tangible and actionable biological insights.</p>
    <boxed-text id="box01" position="float">
      <sec id="sec21z">
        <title>Key Points</title>
        <list list-type="bullet">
          <list-item>
            <p>We introduced a novel HDL model called H2Opred for accurately identifying 2’-O-methylation (2OM) sites in human RNA.</p>
          </list-item>
          <list-item>
            <p>H2Opred used a combination of stacked 1D-CNN and Bi-GRU-Att blocks to learn effective feature representation from 14 conventional descriptors and five NLP-based embeddings, respectively. Subsequently, these representations were combined to make the final prediction.</p>
          </list-item>
          <list-item>
            <p>A novel generic model has been developed, driven by cross-nucleotide model analysis, significantly outperforming nucleotide-specific models and the existing predictor when tested on large samples of an independent dataset.</p>
          </list-item>
          <list-item>
            <p>H2Opred is now available as a web server at <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>, providing an invaluable tool for predicting 2OM sites in human RNA.</p>
          </list-item>
        </list>
      </sec>
    </boxed-text>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>H2Opred_SI_bbad476</label>
      <media xlink:href="h2opred_si_bbad476.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="bbad476-ack">
    <title>ACKNOWLEDGEMENTS</title>
    <p>The authors would like to thank the Korea Institute of Science and Technology Information (KISTI) and Korea Bio Data Station (K-BDS) with computing resources including technical support. We thank Nattanong Bupi for his assistance in creating the figure, and CBBL members for their valuable discussion.</p>
  </ack>
  <sec id="sec23">
    <title>FUNDING</title>
    <p>This work was supported by the National Research Foundation of Korea (NRF) funded by the Ministry of Science and ICT (2021R1A2C1014338 and 2021R1I1A1A01056363), and Korea Health Technology R&amp;D Project grant through the Korea Health Industry Development Institute (KHIDI) funded by the Ministry of Health &amp; Welfare, Republic of Korea (HI23C0701).</p>
  </sec>
  <sec sec-type="data-availability" id="sec24">
    <title>DATA AVAILABILITY</title>
    <p>Web server and all the processed data used in this study can be accessed via <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>.</p>
  </sec>
  <notes id="bio3">
    <title>Author Biographies</title>
    <p><bold>Nhat Truong Pham</bold> is a Ph.D. student at the Computational Biology and Bioinformatics Laboratory, Department of Integrative Biotechnology, Sungkyunkwan University, Republic of Korea. His research interests include artificial intelligence, bioinformatics, computational biology and medicine, deep learning, machine learning, signal processing and XAI and optimization.</p>
    <sec sec-type="author-bio" id="sec26">
      <p><bold>Rajan Rakkiyappan</bold> is a professor in the Department of Mathematics at Bharathiar University in Tamil Nadu, India. His research interests include neural networks, stability theory, data-driven machine learning, bioinformatics and computational biology.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27">
      <p><bold>Jongsun Park</bold> is a co-CEO and CTO of Infoboss Inc, Republic of Korea. His research interests include bioinformatics, genomics, deep learning, machine learning, bio big data, plant/insect taxonomy and phylogenetics.</p>
    </sec>
    <sec sec-type="author-bio" id="sec28">
      <p><bold>Adeel Malik</bold> is a Research Professor at the Institute of Intelligence Informatics Technology, Sangmyung University, Seoul, Republic of Korea. His research interests include machine learning, computational biology and comparative genomics.</p>
    </sec>
    <sec sec-type="author-bio" id="sec29">
      <p><bold>Balachandran Manavalan</bold> is an Assistant Professor at the Department of Integrative Biotechnology, Sungkyunkwan University, Republic of Korea. He is also an associate member of Korea Institute for Advanced Study, Republic of Korea. His research interests include artificial intelligence, bioinformatics, machine learning, big data and functional genomics.</p>
    </sec>
  </notes>
  <ref-list id="bib1">
    <title>References</title>
    <ref id="ref1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname><given-names>BS</given-names></string-name>, <string-name><surname>Roundtree</surname><given-names>IA</given-names></string-name>, <string-name><surname>He</surname><given-names>C</given-names></string-name></person-group>. <article-title>Post-transcriptional gene regulation by mRNA modifications</article-title>. <source>Nat Rev Mol Cell Biol</source><year>2017</year>;<volume>18</volume>:<fpage>31</fpage>–<lpage>42</lpage>.<pub-id pub-id-type="pmid">27808276</pub-id></mixed-citation>
    </ref>
    <ref id="ref2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Machnicka</surname><given-names>MA</given-names></string-name>, <string-name><surname>Milanowska</surname><given-names>K</given-names></string-name>, <string-name><surname>Osman Oglou</surname><given-names>O</given-names></string-name>, <string-name><surname>Purta</surname><given-names>E</given-names></string-name>, <string-name><surname>Kurkowska</surname><given-names>M</given-names></string-name>, <string-name><surname>Olchowik</surname><given-names>A</given-names></string-name>, <string-name><surname>Januszewski</surname><given-names>W</given-names></string-name>, <string-name><surname>Kalinowski</surname><given-names>S</given-names></string-name>, <string-name><surname>Dunin-Horkawicz</surname><given-names>S</given-names></string-name>, <string-name><surname>Rother</surname><given-names>KM</given-names></string-name>, <string-name><surname>Helm</surname><given-names>M</given-names></string-name>, <string-name><surname>Bujnicki</surname><given-names>JM</given-names></string-name>, <string-name><surname>Grosjean</surname><given-names>H</given-names></string-name></person-group><article-title>MODOMICS: a database of RNA modification pathways--2013 update</article-title>, <source>Nucleic Acids Res</source> 2013;<volume>41</volume>:<fpage>D262</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">23118484</pub-id>
</mixed-citation>
    </ref>
    <ref id="ref3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ayadi</surname><given-names>L</given-names></string-name>, <string-name><surname>Galvanin</surname><given-names>A</given-names></string-name>, <string-name><surname>Pichot</surname><given-names>F</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RNA ribose methylation (2′-O-methylation): occurrence, biosynthesis and biological functions</article-title>. <source>Biochim Biophys Acta</source><year>2019</year>;<volume>1862</volume>:<fpage>253</fpage>–<lpage>69</lpage>.</mixed-citation>
    </ref>
    <ref id="ref4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Daffis</surname><given-names>S</given-names></string-name>, <string-name><surname>Szretter</surname><given-names>KJ</given-names></string-name>, <string-name><surname>Schriewer</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>2'-O methylation of the viral mRNA cap evades host restriction by IFIT family members</article-title>. <source>Nature</source><year>2010</year>;<volume>468</volume>:<fpage>452</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">21085181</pub-id></mixed-citation>
    </ref>
    <ref id="ref5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>J</given-names></string-name>, <string-name><surname>Lai</surname><given-names>S</given-names></string-name>, <string-name><surname>Jia</surname><given-names>R</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Structural basis for site-specific ribose methylation by box C/D RNA protein complexes</article-title>. <source>Nature</source><year>2011</year>;<volume>469</volume>:<fpage>559</fpage>–<lpage>63</lpage>.<pub-id pub-id-type="pmid">21270896</pub-id></mixed-citation>
    </ref>
    <ref id="ref6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zust</surname><given-names>R</given-names></string-name>, <string-name><surname>Cervantes-Barragan</surname><given-names>L</given-names></string-name>, <string-name><surname>Habjan</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Ribose 2'-O-methylation provides a molecular signature for the distinction of self and non-self mRNA dependent on the RNA sensor Mda5</article-title>. <source>Nat Immunol</source><year>2011</year>;<volume>12</volume>:<fpage>137</fpage>–<lpage>43</lpage>.<pub-id pub-id-type="pmid">21217758</pub-id></mixed-citation>
    </ref>
    <ref id="ref7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ringeard</surname><given-names>M</given-names></string-name>, <string-name><surname>Marchand</surname><given-names>V</given-names></string-name>, <string-name><surname>Decroly</surname><given-names>E</given-names></string-name>, <etal>et al.</etal></person-group><article-title>FTSJ3 is an RNA 2′-O-methyltransferase recruited by HIV to avoid innate immune sensing</article-title>. <source>Nature</source><year>2019</year>;<volume>565</volume>:<fpage>500</fpage>–<lpage>4</lpage>.<pub-id pub-id-type="pmid">30626973</pub-id></mixed-citation>
    </ref>
    <ref id="ref8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gehrig</surname><given-names>S</given-names></string-name>, <string-name><surname>Eberle</surname><given-names>M-E</given-names></string-name>, <string-name><surname>Botschen</surname><given-names>F</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Identification of modifications in microbial, native tRNA that suppress immunostimulatory activity</article-title>. <source>J Exp Med</source><year>2012</year>;<volume>209</volume>:<fpage>225</fpage>–<lpage>33</lpage>.<pub-id pub-id-type="pmid">22312113</pub-id></mixed-citation>
    </ref>
    <ref id="ref9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>C</given-names></string-name>, <string-name><surname>Yu</surname><given-names>Y-T</given-names></string-name></person-group>. <article-title>Targeted 2′-O methylation at a nucleotide within the pseudoknot of telomerase RNA reduces telomerase activity in vivo</article-title>. <source>Mol Cell Biol</source><year>2010</year>;<volume>30</volume>:<fpage>4368</fpage>–<lpage>78</lpage>.<pub-id pub-id-type="pmid">20647541</pub-id></mixed-citation>
    </ref>
    <ref id="ref10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dai</surname><given-names>Q</given-names></string-name>, <string-name><surname>Moshitch-Moshkovitz</surname><given-names>S</given-names></string-name>, <string-name><surname>Han</surname><given-names>D</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Nm-seq maps 2'-O-methylation sites in human mRNA with base precision</article-title>. <source>Nat Methods</source><year>2017</year>;<volume>14</volume>:<fpage>695</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">28504680</pub-id></mixed-citation>
    </ref>
    <ref id="ref11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krogh</surname><given-names>N</given-names></string-name>, <string-name><surname>Birkedal</surname><given-names>U</given-names></string-name>, <string-name><surname>Nielsen</surname><given-names>H</given-names></string-name></person-group>. <article-title>RiboMeth-seq: profiling of 2'-O-me in RNA</article-title>. <source>Methods Mol Biol</source><year>2017</year>;<volume>1562</volume>:<fpage>189</fpage>–<lpage>209</lpage>.<pub-id pub-id-type="pmid">28349462</pub-id></mixed-citation>
    </ref>
    <ref id="ref12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Incarnato</surname><given-names>D</given-names></string-name>, <string-name><surname>Anselmi</surname><given-names>F</given-names></string-name>, <string-name><surname>Morandi</surname><given-names>E</given-names></string-name>, <etal>et al.</etal></person-group><article-title>High-throughput single-base resolution mapping of RNA 2ʹ-O-methylated residues</article-title>. <source>Nucleic Acids Res</source><year>2017</year>;<volume>45</volume>:<fpage>1433</fpage>–<lpage>41</lpage>.<pub-id pub-id-type="pmid">28180324</pub-id></mixed-citation>
    </ref>
    <ref id="ref13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Pirnie</surname><given-names>SP</given-names></string-name>, <string-name><surname>Carmichael</surname><given-names>GG</given-names></string-name></person-group>. <article-title>High-throughput and site-specific identification of 2'-O-methylation sites using ribose oxidation sequencing (RibOxi-seq)</article-title>. <source>RNA</source><year>2017</year>;<volume>23</volume>:<fpage>1303</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">28495677</pub-id></mixed-citation>
    </ref>
    <ref id="ref14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hsu</surname><given-names>PJ</given-names></string-name>, <string-name><surname>Fei</surname><given-names>Q</given-names></string-name>, <string-name><surname>Dai</surname><given-names>Q</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Single base resolution mapping of 2'-O-methylation sites in human mRNA and in 3′ terminal ends of small RNAs</article-title>. <source>Methods</source><year>2019</year>;<volume>156</volume>:<fpage>85</fpage>–<lpage>90</lpage>.<pub-id pub-id-type="pmid">30471344</pub-id></mixed-citation>
    </ref>
    <ref id="ref15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>WJ</given-names></string-name>, <string-name><surname>Li</surname><given-names>JH</given-names></string-name>, <string-name><surname>Liu</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RMBase: a resource for decoding the landscape of RNA modifications from high-throughput sequencing data</article-title>. <source>Nucleic Acids Res</source><year>2016</year>;<volume>44</volume>:<fpage>D259</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">26464443</pub-id></mixed-citation>
    </ref>
    <ref id="ref16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xuan</surname><given-names>JJ</given-names></string-name>, <string-name><surname>Sun</surname><given-names>WJ</given-names></string-name>, <string-name><surname>Lin</surname><given-names>PH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RMBase v2.0: deciphering the map of RNA modifications from epitranscriptome sequencing data</article-title>. <source>Nucleic Acids Res</source><year>2018</year>;<volume>46</volume>:<fpage>D327</fpage>–<lpage>34</lpage>.<pub-id pub-id-type="pmid">29040692</pub-id></mixed-citation>
    </ref>
    <ref id="ref17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>W</given-names></string-name>, <string-name><surname>Feng</surname><given-names>P</given-names></string-name>, <string-name><surname>Tang</surname><given-names>H</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Identifying 2'-O-methylationation sites by integrating nucleotide chemical properties and nucleotide compositions</article-title>. <source>Genomics</source><year>2016</year>;<volume>107</volume>:<fpage>255</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">27191866</pub-id></mixed-citation>
    </ref>
    <ref id="ref18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>H</given-names></string-name>, <string-name><surname>Lv</surname><given-names>H</given-names></string-name>, <string-name><surname>Ding</surname><given-names>H</given-names></string-name>, <etal>et al.</etal></person-group><article-title>iRNA-2OM: a sequence-based predictor for identifying 2'-O-methylation sites in Homo sapiens</article-title>. <source>J Comput Biol</source><year>2018</year>;<volume>25</volume>:<fpage>1266</fpage>–<lpage>77</lpage>.<pub-id pub-id-type="pmid">30113871</pub-id></mixed-citation>
    </ref>
    <ref id="ref19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tahir</surname><given-names>M</given-names></string-name>, <string-name><surname>Tayara</surname><given-names>H</given-names></string-name>, <string-name><surname>Chong</surname><given-names>KT</given-names></string-name></person-group>. <article-title>iRNA-PseKNC(2methyl): identify RNA 2'-O-methylation sites by convolution neural network and Chou's pseudo components</article-title>. <source>J Theor Biol</source><year>2019</year>;<volume>465</volume>:<fpage>1</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">30590059</pub-id></mixed-citation>
    </ref>
    <ref id="ref20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>QL</given-names></string-name>, <string-name><surname>Wang</surname><given-names>L</given-names></string-name>, <string-name><surname>Han</surname><given-names>SG</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Identification of 2'-O-methylation site by investigating multi-feature extracting techniques</article-title>. <source>Comb Chem High Throughput Screen</source><year>2020</year>;<volume>23</volume>:<fpage>527</fpage>–<lpage>35</lpage>.<pub-id pub-id-type="pmid">32334499</pub-id></mixed-citation>
    </ref>
    <ref id="ref21">
      <label>21.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Cui</surname><given-names>Q</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name></person-group>. <part-title>NmSEER: A Prediction Tool for 2’-O-Methylation (Nm) Sites Based on Random Forest</part-title>. In: <source>Intelligent Computing Theories and Application: 14th International Conference, ICIC 2018</source>, <conf-loc>Wuhan, China</conf-loc>, <conf-date>August 15–18</conf-date>. <comment>Proceedings, Part I 14. 2018</comment>. Springer, <year>2018</year>;<volume>10954</volume>:pp. <fpage>893</fpage>–<lpage>900</lpage>.</mixed-citation>
    </ref>
    <ref id="ref22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Cui</surname><given-names>Q</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name></person-group>. <article-title>NmSEER V2.0: a prediction tool for 2'-O-methylation sites based on random forest and multi-encoding combination</article-title>. <source>BMC Bioinformatics</source><year>2019</year>;<volume>20</volume>:<fpage>690</fpage>.<pub-id pub-id-type="pmid">31874624</pub-id></mixed-citation>
    </ref>
    <ref id="ref23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Chen</surname><given-names>L</given-names></string-name>, <string-name><surname>Huang</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>DeepOMe: a web server for the prediction of 2'-O-me sites based on the hybrid CNN and BLSTM architecture</article-title>. <source>Front Cell Dev Biol</source><year>2021</year>;<volume>9</volume>:<fpage>686894</fpage>.<pub-id pub-id-type="pmid">34055810</pub-id></mixed-citation>
    </ref>
    <ref id="ref24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ao</surname><given-names>C</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <string-name><surname>Yu</surname><given-names>L</given-names></string-name></person-group>. <article-title>NmRF: identification of multispecies RNA 2'-O-methylation modification sites from RNA sequences</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:bbab480.</mixed-citation>
    </ref>
    <ref id="ref25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>YH</given-names></string-name>, <string-name><surname>Ma</surname><given-names>CY</given-names></string-name>, <string-name><surname>Gao</surname><given-names>D</given-names></string-name>, <etal>et al.</etal></person-group><article-title>i2OM: toward a better prediction of 2'-O-methylation in human RNA</article-title>. <source>Int J Biol Macromol</source><year>2023</year>;<volume>239</volume>:<fpage>124247</fpage>.<pub-id pub-id-type="pmid">37003392</pub-id></mixed-citation>
    </ref>
    <ref id="ref26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Niu</surname><given-names>B</given-names></string-name>, <string-name><surname>Gao</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CD-HIT suite: a web server for clustering and comparing biological sequences</article-title>. <source>Bioinformatics</source><year>2010</year>;<volume>26</volume>:<fpage>680</fpage>–<lpage>2</lpage>.<pub-id pub-id-type="pmid">20053844</pub-id></mixed-citation>
    </ref>
    <ref id="ref27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <string-name><surname>Manavalan</surname><given-names>B</given-names></string-name>, <string-name><surname>Hwan Shin</surname><given-names>T</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Machine intelligence in peptide therapeutics: a next-generation tool for rapid disease screening</article-title>. <source>Med Res Rev</source><year>2020</year>;<volume>40</volume>:<fpage>1276</fpage>–<lpage>314</lpage>.<pub-id pub-id-type="pmid">31922268</pub-id></mixed-citation>
    </ref>
    <ref id="ref28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname><given-names>B</given-names></string-name>, <string-name><surname>Wang</surname><given-names>X</given-names></string-name>, <string-name><surname>Liang</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RMDisease V2.0: an updated database of genetic variants that affect RNA modifications with disease and trait implication</article-title>. <source>Nucleic Acids Res</source><year>2023</year>;<volume>51</volume>:<fpage>D1388</fpage>–<lpage>96</lpage>.<pub-id pub-id-type="pmid">36062570</pub-id></mixed-citation>
    </ref>
    <ref id="ref29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manavalan</surname><given-names>B</given-names></string-name>, <string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <string-name><surname>Shin</surname><given-names>TH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Meta-4mCpred: a sequence-based meta-predictor for accurate DNA 4mC site prediction using effective feature representation</article-title>. <source>Mol Ther Nucleic Acids</source><year>2019</year>;<volume>16</volume>:<fpage>733</fpage>–<lpage>44</lpage>.<pub-id pub-id-type="pmid">31146255</pub-id></mixed-citation>
    </ref>
    <ref id="ref30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiang</surname><given-names>J</given-names></string-name>, <string-name><surname>Song</surname><given-names>B</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>m5UPred: a web server for the prediction of RNA 5-Methyluridine sites from sequences</article-title>. <source>Mol Ther Nucleic Acids</source><year>2020</year>;<volume>22</volume>:<fpage>742</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">33230471</pub-id></mixed-citation>
    </ref>
    <ref id="ref31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahmed</surname><given-names>S</given-names></string-name>, <string-name><surname>Muhammod</surname><given-names>R</given-names></string-name>, <string-name><surname>Khan</surname><given-names>ZH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>ACP-MHCNN: an accurate multi-headed deep-convolutional neural network to predict anticancer peptides</article-title>. <source>Sci Rep</source><year>2021</year>;<volume>11</volume>:<fpage>23676</fpage>.<pub-id pub-id-type="pmid">34880291</pub-id></mixed-citation>
    </ref>
    <ref id="ref32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ge</surname><given-names>F</given-names></string-name>, <string-name><surname>Li</surname><given-names>C</given-names></string-name>, <string-name><surname>Iqbal</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>VPatho: a deep learning-based two-stage approach for accurate prediction of gain-of-function and loss-of-function variants</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:bbac535.</mixed-citation>
    </ref>
    <ref id="ref33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Guo</surname><given-names>X</given-names></string-name>, <string-name><surname>Bi</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Digerati - a multipath parallel hybrid deep learning framework for the identification of mycobacterial PE/PPE proteins</article-title>. <source>Comput Biol Med</source><year>2023</year>;<volume>163</volume>:<elocation-id>107155</elocation-id>.<pub-id pub-id-type="pmid">37356289</pub-id></mixed-citation>
    </ref>
    <ref id="ref34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Li</surname><given-names>C</given-names></string-name>, <etal>et al.</etal></person-group><article-title>iAMPCN: a deep-learning approach for identifying antimicrobial peptides and their functional activities</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:bbad240.</mixed-citation>
    </ref>
    <ref id="ref35">
      <label>35.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bahdanau</surname><given-names>D</given-names></string-name>, <string-name><surname>Cho</surname><given-names>K</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>Y</given-names></string-name></person-group>. <article-title>Neural machine translation by jointly learning to align and translate</article-title>. <comment>arXiv preprint arXiv:1409.0473 2014</comment>.</mixed-citation>
    </ref>
    <ref id="ref36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pham</surname><given-names>NT</given-names></string-name>, <string-name><surname>Dang</surname><given-names>DNM</given-names></string-name>, <string-name><surname>Nguyen</surname><given-names>ND</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Hybrid data augmentation and deep attention-based dilated convolutional-recurrent neural networks for speech emotion recognition</article-title>. <source>Expert Syst Appl</source><year>2023</year>;<volume>230</volume>:<elocation-id>120608</elocation-id>.</mixed-citation>
    </ref>
    <ref id="ref37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>G</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Feng</surname><given-names>P</given-names></string-name>, <etal>et al.</etal></person-group><article-title>IPs-GRUAtt: an attention-based bidirectional gated recurrent unit network for predicting phosphorylation sites of SARS-CoV-2 infection</article-title>. <source>Mol Ther Nucleic Acids</source><year>2023</year>;<volume>32</volume>:<fpage>28</fpage>–<lpage>35</lpage>.<pub-id pub-id-type="pmid">36908648</pub-id></mixed-citation>
    </ref>
    <ref id="ref38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Liu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Xu</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Leveraging the attention mechanism to improve the identification of DNA N6-methyladenine sites</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:bbab351.</mixed-citation>
    </ref>
    <ref id="ref39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahmed</surname><given-names>S</given-names></string-name>, <string-name><surname>Kabir</surname><given-names>M</given-names></string-name>, <string-name><surname>Arif</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>DeepPPSite: a deep learning-based model for analysis and prediction of phosphorylation sites using efficient sequence information</article-title>. <source>Anal Biochem</source><year>2021</year>;<volume>612</volume>:<fpage>113955</fpage>.<pub-id pub-id-type="pmid">32949607</pub-id></mixed-citation>
    </ref>
    <ref id="ref40">
      <label>40.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tang</surname><given-names>X</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>P</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Deep6mAPred: a CNN and Bi-LSTM-based deep learning method for predicting DNA N6-methyladenosine sites across plant species</article-title>. <source>Methods</source><year>2022</year>;<volume>204</volume>:<fpage>142</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">35477057</pub-id></mixed-citation>
    </ref>
    <ref id="ref41">
      <label>41.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>ZY</given-names></string-name>, <string-name><surname>Ning</surname><given-names>L</given-names></string-name>, <string-name><surname>Ye</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>iLoc-miRNA: extracellular/intracellular miRNA prediction using deep BiLSTM with attention mechanism</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:bbac395.</mixed-citation>
    </ref>
    <ref id="ref42">
      <label>42.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>Z</given-names></string-name>, <string-name><surname>Huang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>PSnoD: identifying potential snoRNA-disease associations based on bounded nuclear norm regularization</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:bbac240.</mixed-citation>
    </ref>
    <ref id="ref43">
      <label>43.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ge</surname><given-names>F</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Prediction of multiple types of RNA modifications via biological language model</article-title>. <source>IEEE/ACM Trans Comput Biol Bioinform</source><year>2023</year>;<volume>20</volume>(<issue>5</issue>):3205–14.</mixed-citation>
    </ref>
    <ref id="ref44">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>R</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Guo</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>ATTIC is an integrated approach for predicting A-to-I RNA editing sites in three species</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:<fpage>bbad170</fpage>.<pub-id pub-id-type="pmid">37150785</pub-id></mixed-citation>
    </ref>
    <ref id="ref45">
      <label>45.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Yang</surname><given-names>B</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Bastion3: a two-layer ensemble predictor of type III secreted effectors</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>2017</fpage>–<lpage>28</lpage>.<pub-id pub-id-type="pmid">30388198</pub-id></mixed-citation>
    </ref>
    <ref id="ref46">
      <label>46.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shoombuatong</surname><given-names>W</given-names></string-name>, <string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <string-name><surname>Pitti</surname><given-names>T</given-names></string-name>, <etal>et al.</etal></person-group><article-title>THRONE: a new approach for accurate prediction of human RNA N7-methylguanosine sites</article-title>. <source>J Mol Biol</source><year>2022</year>;<volume>434</volume>:<fpage>167549</fpage>.<pub-id pub-id-type="pmid">35662472</pub-id></mixed-citation>
    </ref>
    <ref id="ref47">
      <label>47.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <string-name><surname>Xing</surname><given-names>P</given-names></string-name>, <string-name><surname>Wei</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Gene2vec: gene subsequence embedding for prediction of mammalian N(6)-methyladenosine sites from mRNA</article-title>. <source>RNA</source><year>2019</year>;<volume>25</volume>:<fpage>205</fpage>–<lpage>18</lpage>.<pub-id pub-id-type="pmid">30425123</pub-id></mixed-citation>
    </ref>
    <ref id="ref48">
      <label>48.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yuan</surname><given-names>GH</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>GZ</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RNAlight: a machine learning model to identify nucleotide features determining RNA subcellular localization</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:bbac509.</mixed-citation>
    </ref>
    <ref id="ref49">
      <label>49.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>X</given-names></string-name>, <string-name><surname>Jin</surname><given-names>J</given-names></string-name>, <string-name><surname>Wang</surname><given-names>R</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CACPP: a contrastive learning-based Siamese network to identify anticancer peptides based on sequence only</article-title>. <source>J Chem Inf Model</source><year>2023</year>.</mixed-citation>
    </ref>
    <ref id="ref50">
      <label>50.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Wei</surname><given-names>L</given-names></string-name>, <string-name><surname>Ye</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>SiameseCPP: a sequence-based Siamese network to predict cell-penetrating peptides by contrastive learning</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:bbac545.</mixed-citation>
    </ref>
    <ref id="ref51">
      <label>51.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Charoenkwan</surname><given-names>P</given-names></string-name>, <string-name><surname>Chiangjong</surname><given-names>W</given-names></string-name>, <string-name><surname>Nantasenamat</surname><given-names>C</given-names></string-name>, <etal>et al.</etal></person-group><article-title>StackIL6: a stacking ensemble model for improving the prediction of IL-6 inducing peptides</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:bbab172.</mixed-citation>
    </ref>
    <ref id="ref52">
      <label>52.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Wei</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>6mA-RicePred: a method for identifying DNA N (6)-Methyladenine sites in the rice genome based on feature fusion</article-title>. <source>Front Plant Sci</source><year>2020</year>;<volume>11</volume>:<fpage>4</fpage>.<pub-id pub-id-type="pmid">32076430</pub-id></mixed-citation>
    </ref>
    <ref id="ref53">
      <label>53.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hasan</surname><given-names>MM</given-names></string-name>, <string-name><surname>Schaduangrat</surname><given-names>N</given-names></string-name>, <string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>HLPpred-Fuse: improved and robust prediction of hemolytic peptide and its activity by fusing multiple feature representation</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>3350</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">32145017</pub-id></mixed-citation>
    </ref>
    <ref id="ref54">
      <label>54.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wei</surname><given-names>L</given-names></string-name>, <string-name><surname>Su</surname><given-names>R</given-names></string-name>, <string-name><surname>Luan</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Iterative feature representations improve N4-methylcytosine site prediction</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>4930</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">31099381</pub-id></mixed-citation>
    </ref>
    <ref id="ref55">
      <label>55.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manavalan</surname><given-names>B</given-names></string-name>, <string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <string-name><surname>Shin</surname><given-names>TH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Computational prediction of species-specific yeast DNA replication origin via iterative feature representation</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:bbaa304.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Brief Bioinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Brief Bioinform</journal-id>
    <journal-id journal-id-type="publisher-id">bib</journal-id>
    <journal-title-group>
      <journal-title>Briefings in Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1467-5463</issn>
    <issn pub-type="epub">1477-4054</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10768780</article-id>
    <article-id pub-id-type="doi">10.1093/bib/bbad476</article-id>
    <article-id pub-id-type="publisher-id">bbad476</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Problem Solving Protocol</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>H2Opred: a robust and efficient hybrid deep learning model for predicting 2’-O-methylation sites in human RNA</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8086-6722</contrib-id>
        <name>
          <surname>Pham</surname>
          <given-names>Nhat Truong</given-names>
        </name>
        <!--truongpham96@skku.edu-->
        <aff><institution>Department of Integrative Biotechnology, College of Biotechnology and Bioengineering, Sungkyunkwan University</institution>, <addr-line>Suwon, 16419</addr-line>, <country country="KR">Republic of Korea</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rakkiyapan</surname>
          <given-names>Rajan</given-names>
        </name>
        <!--rakkiyappan.maths@buc.edu.in-->
        <aff><institution>Department of Mathematics, Bharathiar University</institution>, <addr-line>Coimbatore - 641046, Tamil Nadu</addr-line>, <country country="IN">India</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Park</surname>
          <given-names>Jongsun</given-names>
        </name>
        <!--starflr@infoboss.co.kr-->
        <aff><institution>InfoBoss inc. and InfoBoss Research Center, Gangnam-gu</institution>, <addr-line>Seoul 06278</addr-line>, <country country="KR">Republic of Korea</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Malik</surname>
          <given-names>Adeel</given-names>
        </name>
        <!--adeel@procarb.org-->
        <aff><institution>Institute of Intelligence Informatics Technology, Sangmyung University</institution>, <addr-line>Seoul, 03016</addr-line>, <country country="KR">Republic of Korea</country></aff>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-0697-9419</contrib-id>
        <name>
          <surname>Manavalan</surname>
          <given-names>Balachandran</given-names>
        </name>
        <!--bala2022@skku.edu-->
        <aff><institution>Department of Integrative Biotechnology, College of Biotechnology and Bioengineering, Sungkyunkwan University</institution>, <addr-line>Suwon, 16419</addr-line>, <country country="KR">Republic of Korea</country></aff>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="cor1">Corresponding authors. Adeel Malik, Institute of Intelligence Informatics Technology, 20, Hongjimun 2-gil, Jongno-gu, Seoul, Republic of Korea. Tel.: 02-2287-5288; Fax: 02-2287-0070; E-mail: <email>adeel@procarb.org</email>; Balachandran Manavalan, Department of Integrative Biotechnology, College of Biotechnology and Bioengineering, Sungkyunkwan University, Suwon 16419, Gyeonggi-do, Republic of Korea. Tel.: +82-31-299-4858; Fax: +82-31-290-7870; E-mail: <email>bala2022@skku.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2024-01-04">
      <day>04</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>04</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <volume>25</volume>
    <issue>1</issue>
    <elocation-id>bbad476</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>22</day>
        <month>11</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>28</day>
        <month>11</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2024</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="bbad476.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>2’-O-methylation (2OM) is the most common post-transcriptional modification of RNA. It plays a crucial role in RNA splicing, RNA stability and innate immunity. Despite advances in high-throughput detection, the chemical stability of 2OM makes it difficult to detect and map in messenger RNA. Therefore, bioinformatics tools have been developed using machine learning (ML) algorithms to identify 2OM sites. These tools have made significant progress, but their performances remain unsatisfactory and need further improvement. In this study, we introduced H2Opred, a novel hybrid deep learning (HDL) model for accurately identifying 2OM sites in human RNA. Notably, this is the first application of HDL in developing four nucleotide-specific models [adenine (A2OM), cytosine (C2OM), guanine (G2OM) and uracil (U2OM)] as well as a generic model (N2OM). H2Opred incorporated both stacked 1D convolutional neural network (1D-CNN) blocks and stacked attention-based bidirectional gated recurrent unit (Bi-GRU-Att) blocks. 1D-CNN blocks learned effective feature representations from 14 conventional descriptors, while Bi-GRU-Att blocks learned feature representations from five natural language processing-based embeddings extracted from RNA sequences. H2Opred integrated these feature representations to make the final prediction. Rigorous cross-validation analysis demonstrated that H2Opred consistently outperforms conventional ML-based single-feature models on five different datasets. Moreover, the generic model of H2Opred demonstrated a remarkable performance on both training and testing datasets, significantly outperforming the existing predictor and other four nucleotide-specific H2Opred models. To enhance accessibility and usability, we have deployed a user-friendly web server for H2Opred, accessible at <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>. This platform will serve as an invaluable tool for accurately predicting 2OM sites within human RNA, thereby facilitating broader applications in relevant research endeavors.</p>
    </abstract>
    <kwd-group>
      <kwd>2’-O-methylation sites</kwd>
      <kwd>convolutional neural network</kwd>
      <kwd>gated recurrent unit</kwd>
      <kwd>hybrid deep learning</kwd>
      <kwd>bioinformatics</kwd>
      <kwd>natural language processing</kwd>
    </kwd-group>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Research Foundation of Korea</institution>
            <institution-id institution-id-type="DOI">10.13039/501100003725</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Ministry of Science and ICT</institution>
            <institution-id institution-id-type="DOI">10.13039/501100014188</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>2021R1A2C1014338</award-id>
        <award-id>2021R1I1A1A01056363</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Korea Health Technology R&amp;D Project</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Korea Health Industry Development Institute</institution>
            <institution-id institution-id-type="DOI">10.13039/501100003710</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Ministry of Health and Welfare</institution>
            <institution-id institution-id-type="DOI">10.13039/100008903</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>HI23C0701</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="13"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec3">
    <title>INTRODUCTION</title>
    <p>The epitranscriptome involves chemical modification to messenger RNA (mRNA), influencing gene expression [<xref rid="ref1" ref-type="bibr">1</xref>]. While current epitranscriptome research has focused on base modifications, the ribose sugar can also be methylated at the 2′ position to form 2’-O-methylated nucleotides (2OM) [<xref rid="ref2" ref-type="bibr">2</xref>]. 2OM has been found in all types of RNA, including mRNA, ribosomal RNA (rRNA), transfer RNA (tRNA), micro RNA (miRNA), small nucleolar RNA (snoRNA) and PIWI-interacting RNA (piRNA) [<xref rid="ref3" ref-type="bibr">3</xref>]. The process of 2OM can be achieved through two distinct enzymatic routes: standalone methyltransferases and RNA-protein complex guided by Box C/D snoRNA, known as C/D-box snoRNPs. Standalone methyltransferases recognize their targets based on sequence and shape, while C/D-box snoRNPs are guided to their targets by snoRNAs [<xref rid="ref4" ref-type="bibr">4–6</xref>]. Consequently, 2OM can occur in all four canonical nucleotides (adenine, cytosine, guanine and uracil) and some non-standard nucleotides.</p>
    <p>Recent studies have shown that 2OM not only stabilized RNA but also involved in regulating gene expression and other cellular processes. For example, 2OM in RNA can be used by the innate immune system to distinguish between internal and external mRNA [<xref rid="ref6" ref-type="bibr">6</xref>]. HIV-1 evades detection by the MDA5 protein using the TRBP-FTSJ3 complex to add 2OM to its RNA [<xref rid="ref7" ref-type="bibr">7</xref>]. In human monocytes, 2OM RNA can suppress the release of pro-inflammatory cytokines [<xref rid="ref8" ref-type="bibr">8</xref>]. In yeast, specific 2OM sites in telomerase RNA affect how well telomerase functions [<xref rid="ref9" ref-type="bibr">9</xref>]. 2OM is also important for antibiotic resistance and cancer. However, much remains to be learned about the full range of roles that 2OM plays in RNA. Identifying 2OM sites in RNA is essential for understanding its functional significance, which is one of the important research topics in the community.</p>
    <p>Several experimental methods have been developed to accurately identify 2OM in RNA. These methods include perchloric acid (HClO4) hydrolysis, periodate oxidation hydrolysis, chromatography and mass spectrometry. However, these methods are labor-intensive, need specialized tools, can damage RNA samples and are challenging to use with minimal RNA. To overcome these limitations, high-throughput techniques based on deep sequencing have also been developed, such as Nm-seq [<xref rid="ref10" ref-type="bibr">10</xref>], RiboMeth-seq [<xref rid="ref11" ref-type="bibr">11</xref>], 2OMe-seq [<xref rid="ref12" ref-type="bibr">12</xref>], RibOxi-Seq [<xref rid="ref13" ref-type="bibr">13</xref>] and Nm-seq (a) [<xref rid="ref14" ref-type="bibr">14</xref>]. While these methods can identify 2OM at the transcriptome level, they are still costly, time-consuming and require specialized expertise. Therefore, computational methods have been developed to complement the experimental methods.</p>
    <p>Sun <italic toggle="yes">et al</italic>. [<xref rid="ref15" ref-type="bibr">15</xref>] developed RMBase, a database that contained 18 independent high-throughput sequencing data for studying RNA post-transcriptional modifications. The updated version, RMBase v2.0 [<xref rid="ref16" ref-type="bibr">16</xref>], contains data on 5096 2OM positions across three species, a significant increase from its predecessor’s 1209 entries. These databases serve as the foundation for developing computational methods to identify 2OM sites. Chen <italic toggle="yes">et al</italic>. [<xref rid="ref17" ref-type="bibr">17</xref>] constructed the first benchmarking dataset based on RMBase and developed a support vector machine (SVM)-based predictor. Using the same dataset, three more methods were proposed: iRNA-2OM [<xref rid="ref18" ref-type="bibr">18</xref>], identification of RNA 2OM using pseudo k-tuple nucleotide composition (iRNA-PseKNC(2methyl)) [<xref rid="ref19" ref-type="bibr">19</xref>] and an ensemble model by Huang <italic toggle="yes">et al</italic>. [<xref rid="ref20" ref-type="bibr">20</xref>]. Later, Zhou’s group developed two tools, NmSEER [<xref rid="ref21" ref-type="bibr">21</xref>] and NmSEER V2.0 [<xref rid="ref22" ref-type="bibr">22</xref>], based on different approaches and datasets. Li <italic toggle="yes">et al</italic>. [<xref rid="ref23" ref-type="bibr">23</xref>] proposed DeepOMe based on convolutional neural network (CNN) and bidirectional long short-term memory (Bi-LSTM) layers. Ao <italic toggle="yes">et al.</italic> [<xref rid="ref24" ref-type="bibr">24</xref>] developed NmRF using Chen’s dataset and RMBase v2.0, which achieved an excellent performance on three species. Yang <italic toggle="yes">et al</italic>. [<xref rid="ref25" ref-type="bibr">25</xref>] introduced i2OM by constructing a larger dataset based on <italic toggle="yes">Homo sapiens.</italic> Their study showed better performance using conventional machine learning (ML) approaches and two-step feature selection techniques. While these methods have made significant contributions to the field, there is still room for improvement.</p>
    <p>In this study, we introduced H2Opred, a novel hybrid deep learning (HDL) model, for accurately identifying 2OM sites. Remarkably, this is the first application of HDL in developing nucleotide-specific models [adenine (A2OM), cytosine (C2OM), guanine (G2OM) and uracil (U2OM)] as well as a generic model that integrated all nucleotide-specific datasets (N2OM). H2Opred included all these five models, each of which has been trained in a similar fashion. H2Opred leveraged a set of 14 conventional descriptors, encompassing binary profile features (BPF), nucleotide chemical properties (NCP), dinucleotide binary encoding (DBE), as well as type 1 and type 2 dinucleotide physicochemical properties (DPCP_1, DPCP_2), positional specifics of two nucleotides (PS2), Kmer, reverse complement Kmer patterns (RCKmer), electron–ion interaction pseudo potentials of trinucleotides (PseEIIP), composition of k-spaced nucleic acid pairs (CKSNAP), enhanced nucleic acid composition (ENAC), Z curve parameters capturing frequencies of phase-specific trinucleotides (Zcurve), a novel combination of adaptive skip dinucleotide composition with local position-specific dinucleotide frequency (ASLPN) and multivariate mutual information combined with accumulated nucleotide frequency (MMNF). Additionally, five natural language processing (NLP)-based embeddings, including the DNA-language model (DNABERT), sequence-to-vector (Seq2Vec), word-to-vector (Word2Vec), FastText and global vectors for word representation (GloVe), were utilized. All of these descriptors and embeddings were directly extracted from RNA sequences. H2Opred incorporated both stacked 1D convolutional neural network (1D-CNN) blocks and stacked attention-based bidirectional gated recurrent unit (Bi-GRU-Att) blocks to learn effective feature representations from 14 conventional descriptors and five NLP-based embeddings, respectively. These feature representations were then combined to make the final prediction. Ablation analysis showed that both 1D-CNN and Bi-GRU-Att blocks were essential for H2Opred’s optimal performance. The H2Opred models exhibited outstanding performance during cross-validation and independent testing, surpassing the capabilities of large-scale conventional ML-based single-feature models. Notably, the generic H2Opred model outperformed both the existing predictor and the four nucleotide-specific H2Opred models, demonstrating that the intelligent integration of conventional descriptors and pretrained model-based embeddings extracted from a large training dataset through HDL enhances both prediction accuracy and interpretability.</p>
  </sec>
  <sec id="sec4">
    <title>MATERIALS AND METHODS</title>
    <sec id="sec5">
      <title>Dataset</title>
      <p>We used the same benchmark dataset proposed by Yang <italic toggle="yes">et al</italic>. [<xref rid="ref25" ref-type="bibr">25</xref>], because it is the most recent, comprehensive and non-redundant dataset available. The authors obtained 2OM sites from two different sources: RMBase v2.0 [<xref rid="ref16" ref-type="bibr">16</xref>] and the recent experimental dataset generated by Nm-seq [<xref rid="ref10" ref-type="bibr">10</xref>] and deposited in the GEO database (GSE90164). In total, they obtained 7597 2OM sites distributed in CDS, 3’-UTR, 5’-UTR, intron, exon and intergenic regions, and containing almost all types of RNA (tRNAs, rRNAs, scRNAs, scaRNAs, snRNAs, snoRNAs, lincRNAs, protein-coding genes, pseudogenes, etc.). Since the majority of sequences from RMBase v2.0 have a sequence length of 41 bp (20 upstream and 20 downstream based with the center 2OM sites), the authors extracted the same sequence length from the experimental data. To generate negative samples, the authors employed the same strategies as previous studies and generated a large number of sequences. Subsequently, they applied CD-HIT [<xref rid="ref26" ref-type="bibr">26</xref>] with a threshold of 80% to remove redundant sequences, resulting in 6091 positive samples and 21 520 negative samples. To address class bias, which is a common problem when developing prediction models with imbalanced datasets [<xref rid="ref27" ref-type="bibr">27</xref>], the authors selected the same number of negative samples as positive samples. The authors then divided the dataset into four subsets, centered on A, U, C and G corresponding to A2OM, U2OM, C2OM and G2OM, respectively. The A2OM dataset contains 2176 training and 934 testing samples, the U2OM dataset contains 2236 training and 960 testing samples, the C2OM dataset contains 2278 training and 788 testing samples and the G2OM dataset contains 1832 training and 788 testing samples. Notably, all training and testing samples contain an equal number of positive and negative samples. It should be noted that we have used the same training datasets for the model development in this study. However, we used entirely different testing datasets to check the model transferability. Specifically, we supplemented the existing nucleotide-specific testing datasets with our own collections. Positive samples were collected from RMDisease v2.0 [<xref rid="ref28" ref-type="bibr">28</xref>], and excluded the redundant samples, resulting in 34, 82, 12 and 173 positive samples for A2OM, C2OM, G2OM and U2OM, respectively. Regarding the negative samples, we considered all possible chromosomes in <italic toggle="yes">H. sapiens</italic> and selected sequences with four different nucleotide bases as central residues, flanked by 20 nucleotides both upstream and downstream. From these, we randomly chose samples 10-fold larger in number than positive samples. Importantly, newly constructed samples were not present in the existing training and the testing datasets. Finally, we obtained 501 positive and 5010 negative samples for A2OM, 571 positive and 5710 negative samples for C2OM, 406 positive and 4060 negative samples for G2OM and 653 positive and 6530 negative samples for U2OM.</p>
    </sec>
    <sec id="sec6">
      <title>Feature extraction</title>
      <p>We used 14 conventional descriptors and five NLP-based embeddings to represent RNA sequences. The conventional descriptors covered different properties of sequence information and were widely used in bioinformatics [<xref rid="ref18" ref-type="bibr">18</xref>, <xref rid="ref29" ref-type="bibr">29</xref>, <xref rid="ref30" ref-type="bibr">30</xref>]. The NLP-based embeddings were trained on large datasets of DNA and RNA sequences to capture their linguistic features. The conventional descriptors included Kmer, BPF, NCP, DBE, DPCP_1, DPCP_2, PS2, RCKmer, PseEIIP, CKSNAP, ENAC, Zcurve, ASLPN and MMNF. The NLP-based embeddings included DNABERT, Seq2Vec, Word2vec, FastText and GloVe. A detailed description of these descriptors and embeddings is provided in the supplementary information.</p>
    </sec>
    <sec id="sec7">
      <title>Framework of H2Opred</title>
      <p>In this study, we proposed an HDL model to predict 2OM sites in human RNA sequences (<xref rid="f1" ref-type="fig">Figure 1</xref>). The HDL model consisted of stacked 1D-CNN blocks and stacked Bi-GRU-Att blocks, which learned and extracted both spatial and temporal-sequential feature representations from conventional descriptors and NLP-based embeddings. The details of these blocks are presented below.</p>
      <fig position="float" id="f1">
        <label>Figure 1</label>
        <caption>
          <p>The workflow of constructing H2Opred framework. (A) Four 2’-O-methylation (2OM) site types were collected and split into training and independent datasets, where the combined dataset was constructed by integrating all four 2OM site types together as well as removing redundancy and identical samples. (B) Subsequently, 14 conventional descriptors and five NLP-based embeddings were extracted and then fed into stacked convolutional neural network (1D-CNN) blocks and stacked attention-based bidirectional gated recurrent unit (Bi-GRU-Att) blocks to acquire spatial and temporal-sequential feature representations for final prediction model. (C) During the testing phase, the testing datasets were submitted to the web server, resulting in either 2OM or non-2OM sites. (Created with <ext-link xlink:href="http://www.biorender.com" ext-link-type="uri">BioRender.com</ext-link>).</p>
        </caption>
        <graphic xlink:href="bbad476f1" position="float"/>
      </fig>
    </sec>
    <sec id="sec8">
      <title>Stacked 1D-CNN</title>
      <p>To extract and learn the spatial feature representations from the RNA sequences, we designed a 1D-CNN block for each conventional descriptor. Inspired by the stacking CNN approach utilized in recent studies [<xref rid="ref31" ref-type="bibr">31–34</xref>], we developed 14 1D-CNN blocks and integrated them to handle the 14 conventional descriptors. Each 1D-CNN block consisted of three 1D convolutional (Conv1D) layers, three max pooling layers and one fully connected (FC) layer at the end. Given an input <inline-formula><tex-math notation="LaTeX" id="ineq01">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X{c}_{in}$\end{document}</tex-math></inline-formula> of (<inline-formula><tex-math notation="LaTeX" id="ineq02">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$B,{L}_{in},{C}_{in}$\end{document}</tex-math></inline-formula>), Conv1D will obtain an output <inline-formula><tex-math notation="LaTeX" id="ineq03">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X{c}_{out}$\end{document}</tex-math></inline-formula> of (<inline-formula><tex-math notation="LaTeX" id="ineq04">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$B,{L}_{out},{C}_{out}$\end{document}</tex-math></inline-formula>) as follows:</p>
      <disp-formula id="deqn01">
        <label>(1)</label>
        <tex-math notation="LaTeX" id="DmEquation1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} X{c}_{ou t}\left(B,{C}_{{ou t}_j}\right)= bc+\sum \limits_{k=0}^{C_{in}-1} Wc\left({C}_{ou{t}_j},k\right)\ast X{c}_{in}\left(B,k\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq05">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\ast$\end{document}</tex-math></inline-formula> denote the cross-correlation operation, <inline-formula><tex-math notation="LaTeX" id="ineq06">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$Wc$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq07">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$bc$\end{document}</tex-math></inline-formula> are weight and bias, <inline-formula><tex-math notation="LaTeX" id="ineq08">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$B$\end{document}</tex-math></inline-formula> is the batch size, <inline-formula><tex-math notation="LaTeX" id="ineq09">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${L}_{in}$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${C}_{in}$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${L}_{out}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq12">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${C}_{out}$\end{document}</tex-math></inline-formula> are the input length, the number of the input channels, output length and the number of the output channels, respectively, in which <inline-formula><tex-math notation="LaTeX" id="ineq13">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${L}_{out}$\end{document}</tex-math></inline-formula> can be computed as follows:</p>
      <disp-formula id="deqn02">
        <label>(2)</label>
        <tex-math notation="LaTeX" id="DmEquation2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {L}_{out}=1+\frac{L_{in}+2P-D\left(k-1\right)-1}{S}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq14">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$P$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq15">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$D$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq16">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\kappa$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq17">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$S$\end{document}</tex-math></inline-formula> are the padding size, dilation rate, kernel size and stride, respectively. Then, each Conv1D layer was passed through a ReLU (rectified linear unit) activation function, which can be defined as follows:</p>
      <disp-formula id="deqn03">
        <label>(3)</label>
        <tex-math notation="LaTeX" id="DmEquation3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} \mathrm{ReLU}(x)=\max \left(0,x\right). \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>To achieve dimensional reduction, we incorporated one max pooling layer immediately after each Conv1D layer. The operation of each max pooling layer is outlined as follows:</p>
      <disp-formula id="deqn04">
        <label>(4)</label>
        <tex-math notation="LaTeX" id="DmEquation4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} X{m}_{out}\left(B,{C}_j,k\right)=\underset{p=0,...,\kappa -1}{\max }X{m}_{in}\left(B,{C}_j,S\times k+p\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq18">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X{m}_{in}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq19">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X{m}_{out}$\end{document}</tex-math></inline-formula> are the input and output of the max pooling layer. It should be noted that only the length of the output changed after applying the max pooling layer. Finally, the feature representations were flattened and fed into an FC layer to produce the final feature representations. In addition, a dropout layer was applied after flattening the features to prevent overfitting. The configuration of each stacked 1D-CNN block was described in detail in the optimization process section.</p>
    </sec>
    <sec id="sec9">
      <title>Stacked Bi-GRU-Att</title>
      <p>To extract the temporal-sequential information from RNA sequences, we designed a Bi-GRU-Att block to capture temporal-sequential feature representations from each of five NLP-based embeddings extracted from RNA sequences. It should be noted that Bi-GRU was chosen over a single GRU because it can capture temporal-sequential feature representations in both the forward and backward directions of the sequence, resulting in more robust and informative feature representations. Additionally, Bi-GRU architecture was selected over LSTM or Bi-LSTM because it is simple and has fewer output gates, making it faster and more effective to train, especially with limited data. To address the challenge of not every feature representation equally informative for characterizing RNA sequence, we incorporated an attention mechanism [<xref rid="ref35" ref-type="bibr">35–38</xref>] to selectively focus on the most relevant and crucial feature representations for discriminating 2OM sites. The mathematical equations of each GRU can be expressed as follows:</p>
      <disp-formula id="deqn05">
        <label>(5)</label>
        <tex-math notation="LaTeX" id="DmEquation5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {u}_t=\sigma \left({W}_{iu}{x}_t+{U}_{hu}{h}_{\left(t-1\right)}+{b}_{iu}+{b}_{hu}\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn06">
        <label>(6)</label>
        <tex-math notation="LaTeX" id="DmEquation6">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {r}_t=\sigma \left({W}_{ir}{x}_t+{U}_{hr}{h}_{\left(t-1\right)}+{b}_{ir}+{b}_{hr}\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn07">
        <label>(7)</label>
        <tex-math notation="LaTeX" id="DmEquation7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} \qquad\quad{\tilde{\eta}}_t=\tau \left({W}_{i\tilde{\eta}}{x}_t+{r}_t\odot \left({U}_{h\tilde{\eta}}{h}_{\left(t-1\right)}+{b}_{h\tilde{\eta}}\right)+{b}_{i\tilde{\eta}}\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn08">
        <label>(8)</label>
        <tex-math notation="LaTeX" id="DmEquation8">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {h}_t=\left(1-{u}_t\right)\odot{\tilde{\eta}}_t+{u}_t\odot{h}_{\left(t-1\right)},\qquad\quad \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq20">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${u}_t$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq21">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${r}_t$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq22">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\tilde{\eta}}_t$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq23">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${h}_t$\end{document}</tex-math></inline-formula> represent the update gate, the reset gate, the new gate (or the hidden candidate status) and the hidden gate, respectively; <inline-formula><tex-math notation="LaTeX" id="ineq24">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${x}_t$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq25">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$W$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq26">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$U$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ineq27">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$b$\end{document}</tex-math></inline-formula> are the input vectors, the weight matrices and the bias vector; <inline-formula><tex-math notation="LaTeX" id="ineq28">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\sigma$\end{document}</tex-math></inline-formula> denotes the sigmoid function, <inline-formula><tex-math notation="LaTeX" id="ineq29">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\tau$\end{document}</tex-math></inline-formula> denotes the tanh function and <inline-formula><tex-math notation="LaTeX" id="ineq30">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\odot$\end{document}</tex-math></inline-formula> denotes the Hadamard product.</p>
      <p>And the mathematical equations of attention mechanism can be defined as follows:</p>
      <disp-formula id="deqn09">
        <label>(9)</label>
        <tex-math notation="LaTeX" id="DmEquation9">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {A}_{ij}={x}_a^T\tau \left({W}_a{h}_i+b\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn10">
        <label>(10)</label>
        <tex-math notation="LaTeX" id="DmEquation10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {\alpha}_{ij}=\frac{e^{\left({A}_{ij}\right)}}{\sum \limits_{t=1}^T{e}^{\left({A}_{ij}\right)}},\qquad\ \ \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn11">
        <label>(11)</label>
        <tex-math notation="LaTeX" id="DmEquation11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {c}_i=\sum \limits_{j=1}^T{\alpha}_{ij}{h}_j, \qquad\ \ \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq31">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${x}_a$\end{document}</tex-math></inline-formula> is the random initialization vector, <inline-formula><tex-math notation="LaTeX" id="ineq32">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${A}_{ij}$\end{document}</tex-math></inline-formula> is the attention weight, <inline-formula><tex-math notation="LaTeX" id="ineq33">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${h}_i=\left[{\overrightarrow{h}}_t;{\overleftarrow{h}}_t\right]$\end{document}</tex-math></inline-formula> is the output of Bi-GRU at the time step <inline-formula><tex-math notation="LaTeX" id="ineq34">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t$\end{document}</tex-math></inline-formula> that concatenates both forward and backward information, <inline-formula><tex-math notation="LaTeX" id="ineq35">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$T=41$\end{document}</tex-math></inline-formula> is the length of the input sequence, <inline-formula><tex-math notation="LaTeX" id="ineq36">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\alpha}_{ij}$\end{document}</tex-math></inline-formula> is the output score of the attention weight by applying SoftMax function and <inline-formula><tex-math notation="LaTeX" id="ineq37">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${c}_i$\end{document}</tex-math></inline-formula> is the attention output.</p>
      <p>Motivated by the stacking recurrent neural network-based approaches employed in recent studies [<xref rid="ref39" ref-type="bibr">39</xref>, <xref rid="ref40" ref-type="bibr">40</xref>], we developed five Bi-GRU-Att blocks that were subsequently combined to handle the five NLP-bassed embeddings. Notably, each Bi-GRU-Att block contained two Bi-GRU layers, followed by an attention layer and an FC layer. The hidden state generated by the first Bi-GRU layer was used as the input of the second Bi-GRU layer. For more details on the specific configuration of the Bi-GRU-Att blocks, please refer to the optimization process section.</p>
    </sec>
    <sec id="sec10">
      <title>Optimization process of H2Opred</title>
      <p>We conducted a comprehensive optimization process to select the best model for constructing H2Opred. <xref rid="sup1" ref-type="supplementary-material">Table S1</xref> represents our parameter search range implemented in this study. Importantly, we used 5-fold cross-validation during the training phase to tune the hyperparameters within the specified search range and determine the optimal set of hyperparameters.</p>
      <p>Here, the binary cross-entropy loss function (<inline-formula><tex-math notation="LaTeX" id="ineq38">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${L}_{BCE}$\end{document}</tex-math></inline-formula>) was used as an objective function to optimize the parameters during training model, which can be defined as follows:</p>
      <disp-formula id="deqn12">
        <label>(12)</label>
        <tex-math notation="LaTeX" id="DmEquation12">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} {L}_{BCE}=\frac{1}{N_s}\sum \limits_{s=1}^{N_s}{y}_s\log \left(\wp \left({\hat{y}}_s\right)\right)+\left(1-{y}_s\right)\log \left(1-\wp \left({\hat{y}}_s\right)\right), \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where <inline-formula><tex-math notation="LaTeX" id="ineq39">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${N}_s$\end{document}</tex-math></inline-formula> is the number of samples, <inline-formula><tex-math notation="LaTeX" id="ineq40">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$s=\mathrm{1...}{N}_s$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ineq41">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${y}_s$\end{document}</tex-math></inline-formula> is the ground truth label and <inline-formula><tex-math notation="LaTeX" id="ineq42">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\hat{y}}_s$\end{document}</tex-math></inline-formula> is the predicted label. In addition, it should be noted that <inline-formula><tex-math notation="LaTeX" id="ineq43">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\wp \left({\hat{y}}_s\right)$\end{document}</tex-math></inline-formula> represents the probability of 2OM and <inline-formula><tex-math notation="LaTeX" id="ineq44">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$1-\wp \left({\hat{y}}_s\right)$\end{document}</tex-math></inline-formula> represents the probability of non-2OM.</p>
    </sec>
    <sec id="sec11">
      <title>Performance evaluation metrics</title>
      <p>In this study, several commonly used performance evaluation metrics [<xref rid="ref41" ref-type="bibr">41–43</xref>] were utilized to evaluate the model performance during training, independent testing as well as comparison, which included accuracy (ACC), Mathews correlation coefficient (MCC), sensitivity (Sn), specificity (Sp), precision (PRE), area under the receiver operating characteristic curve (AUC) and F1-score. Their mathematical equations can be expressed as follows:</p>
      <disp-formula id="deqn13">
        <label>(13)</label>
        <tex-math notation="LaTeX" id="DmEquation13">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} ACC=\frac{TP+ TN}{TP+ TN+ FP+ FN}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn14">
        <label>(14)</label>
        <tex-math notation="LaTeX" id="DmEquation14">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} MCC=\frac{TP\times TN- FP\times FN}{\sqrt{\left( TP+ FP\right)\times \left( TP+ FN\right)\times \left( TN+ FP\right)\times \left( TN+ FN\right)}}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn15">
        <label>(15)</label>
        <tex-math notation="LaTeX" id="DmEquation15">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} Sn=\frac{TP}{TP+ FN}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn16">
        <label>(16)</label>
        <tex-math notation="LaTeX" id="DmEquation16">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} Sp=\frac{TN}{TN+ FP}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn17">
        <label>(17)</label>
        <tex-math notation="LaTeX" id="DmEquation17">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} PRE=\frac{TP}{TP+ FP}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <disp-formula id="deqn18">
        <label>(18)</label>
        <tex-math notation="LaTeX" id="DmEquation18">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*} F1- score=\frac{2\times TP}{2\times TP+ FP+ FN}, \end{equation*}\end{document}</tex-math>
      </disp-formula>
      <p>where TP represents the count of test results that correctly match with positive samples, TN represents the count of test results that correctly match with negative samples, FP stands for the count of test results that incorrectly indicate positive samples and FN denotes the count of test results that incorrectly indicate negative samples.</p>
    </sec>
  </sec>
  <sec id="sec12">
    <title>RESULTS AND DISCUSSION</title>
    <sec id="sec13">
      <title>Assessment of conventional descriptors using 11 different ML algorithms on the training and independent testing datasets</title>
      <p>Inspired by previous studies [<xref rid="ref29" ref-type="bibr">29</xref>, <xref rid="ref44" ref-type="bibr">44</xref>], we evaluated 14 conventional RNA sequence descriptors that capture different aspects of sequence information, such as composition, position-specific, physicochemical properties and sequence order. To quantify the intrinsic capability of these feature descriptors for distinguishing 2OM from non-2OM in different datasets, we evaluated the performance of each descriptor using 11 conventional ML-based classifiers (including random forest (RF), extremely randomized trees (ERT), gradient boosting trees (GBT), AdaBoost trees (ABT), extreme GBT (XGBT), SVM, deep neural network (DNN), light GBT (LGBT), decision trees (DT), logistic regression (LR) and catBoost (CB)) by means of randomized 10-fold cross-validation procedure. This technique helps to prevent model overfitting during training [<xref rid="ref45" ref-type="bibr">45</xref>, <xref rid="ref46" ref-type="bibr">46</xref>].</p>
      <p>In total, we generated 616 models (154 models * 4 datasets) during the training and assessed its transferability with the independent testing datasets (<xref rid="sup1" ref-type="supplementary-material">Figures S1</xref>–<xref rid="sup1" ref-type="supplementary-material">S4</xref>). We were more interested in the discriminative capability of the feature descriptors than in the performance of any specific classifier. To get an overview of how well each descriptor performed, we averaged the ACC of the 11 classifiers-based models trained on each descriptor and the results were shown in <xref rid="f2" ref-type="fig">Figure 2A</xref>. All of these descriptors achieved reasonable performance on the A2OM, C2OM and G2OM datasets, with average ACC in the ranges of 0.768–0.844, 0.747–0.825 and 0.755–0.826, respectively. However, the performance on the U2OM dataset was significantly lower, with average ACC in the range of 0.674–0.711. After evaluating the performance of 616 models on the independent testing datasets (<xref rid="f2" ref-type="fig">Figure 2B</xref>), we observed that the average performance of each descriptor on the independent testing datasets was similar to that on the training datasets, with the U2OM dataset being the most challenging dataset. Specifically, the average ACC of the descriptors on the independent testing datasets ranged from 0.752 to 0.885 for A2OM, 0.736 to 0.877 for C2OM, 0.751 to 0.863 for G2OM and 0.695 to 0.791 for U2OM. Out of the 14 descriptors, DPCP_2, Kmer and PS2 performed the best on the training datasets, with ACC of 0.837–0.844 for A2OM, 0.822–0.825 for C2OM and 0.815–0.826 for G2OM. Notably, DPCP_2 and PS2 maintained a similar level of performance on the corresponding testing datasets. Since each of the descriptors captures different aspects of sequence information, we included all 14 conventional descriptors in the construction of an HDL framework.</p>
      <fig position="float" id="f2">
        <label>Figure 2</label>
        <caption>
          <p>Average accuracy (ACC) achieved by 11 conventional ML-based classifiers for each of the 14 conventional descriptors. The comparative performance of four nucleotide-specific models is shown for training datasets (A) and testing datasets (B).</p>
        </caption>
        <graphic xlink:href="bbad476f2" position="float"/>
      </fig>
    </sec>
    <sec id="sec14">
      <title>Evaluation of H2Opred for 2OM site prediction on the training and independent testing datasets</title>
      <p>H2Opred was constructed using an HDL approach (see Materials and methods section). This approach combined stacked 1D-CNN blocks to learn effective feature representations from 14 conventional descriptors, and stacked Bi-GRU-Att blocks to learn feature representations from five NLP-based embeddings. These feature representations were then combined to make the final prediction. <xref rid="f3" ref-type="fig">Figure 3</xref> compares the performance of H2Opred with two individual approaches, 1D-CNN and Bi-GRU-Att. Among the 1D-CNN and Bi-GRU-Att models, 1D-CNN achieved consistently better performance on four training datasets, with improvement in MCCs of 0.09%, 1.60%, 2.60% and 0.06% for A2OM, C2OM, G2OM and U2OM, respectively. When combining these two models, H2Opred achieved MCC and ACC of 0.762 and 0.881 in A2OM, 0.732 and 0.865 in C2OM, 0.715 and 0.856 in G2OM and 0.603 and 0.801 in U2OM. Specifically, H2Opred outperformed 1D-CNN on three training datasets (A2OM, C2OM and G2OM), and achieved similar performance on the U2OM dataset. Overfitting occurs when the ML model learns the training data too well, and is unable to generalize to new data. To avoid overfitting, it is important to evaluate the model’s performance on the independent testing datasets.</p>
      <fig position="float" id="f3">
        <label>Figure 3</label>
        <caption>
          <p>Comparison of nucleotide-specific H2Opred models and individual stacking models (1D-CNN and Bi-GRU-Att) on the training and testing datasets. Performance on the A2OM training (A) and testing (B) datasets, C2OM training (C) and testing (D) datasets, G2OM training (E) and testing (F) datasets, and U2OM training (G) and testing (H) datasets.</p>
        </caption>
        <graphic xlink:href="bbad476f3" position="float"/>
      </fig>
      <p>We comprehensively evaluated the three deep learning models on four different testing datasets. In contrast to training performance, Bi-GRU-Att consistently outperformed 1D-CNN across all testing datasets, with improvement in MCCs of 2.57%, 4.04%, 1.09% and 4.31% for A2OM, C2OM, G2OM and U2OM, respectively, as shown in <xref rid="f3" ref-type="fig">Figure 3</xref>. However, H2Opred significantly outperformed both 1D-CNN and Bi-GRU-Att on all four testing datasets. Specifically, H2Opred improved MCC by 1.84–4.41% in A2OM, 1.23–5.27% in C2OM, 4.64–5.72% in G2OM and 1.23–5.53% in U2OM compared with Bi-GRU-Att and 1D-CNN, respectively. Overall, H2Opred demonstrated superior performance compared with both 1D-CNN and Bi-GRU-Att, exhibiting consistent performance across both training and testing datasets. To highlight the advantages of H2Opred, we compared its performance against the top five conventional ML-based single-feature models for each of the four nucleotide-specific models. As illustrated in <xref rid="sup1" ref-type="supplementary-material">Figure S5</xref>, H2Opred achieved significantly better results than the conventional ML-based single-feature models on both training and independent datasets. These findings suggest that H2Opred possesses greater stability and generalizability across diverse data scenarios, because it can learn effective feature representations by combining conventional descriptors with NLP-based embeddings.</p>
    </sec>
    <sec id="sec15">
      <title>Cross nucleotide-specific model validation</title>
      <p>We assessed the transferability of nucleotide-specific models to different testing datasets. We examined whether A2OM model is transferable to other types (C2OM, G2OM and U2OM), and vice versa, as shown in <xref rid="f4" ref-type="fig">Figure 4</xref>. When the A2OM testing dataset was evaluated with the other three trained models (G2OM, C2OM and U2OM), they achieved the ACC in the range of 0.830 to 0.916, the AUC in the range of 0.917 to 0.934 and the MCC in the range of 0.466 to 0.609. Similarly, the trained A2OM, G2OM and U2OM models achieved the ACC in the range of 0.822 to 0.925, the AUC in the range of 0.914 to 0.924 and the MCC in the range 0.434 to 0.600 on the C2OM testing dataset; the trained A2OM, C2OM and U2OM models achieved the ACC in the range of 0.796 to 0.906, the AUC in the range of 0.906 to 0.944 and the MCC in the range of 0.416 to 0.592 on the G2OM testing dataset; and the trained A2OM, C2OM and G2OM models achieved the ACC in the range of 0.905 to 0.915, the AUC in the range of 0.879 to 0.894 and the MCC in the range of 0.480 to 0.505 on the U2OM testing dataset. Overall, these analyses highlight that a nucleotide-specific model can be effectively transferrable to other nucleotides with satisfactory accuracy. Previous studies [<xref rid="ref10" ref-type="bibr">10</xref>, <xref rid="ref25" ref-type="bibr">25</xref>] have highlighted those four different nucleotides shares similar motif patterns at 2OM sites. This prompted us to investigate whether developing a generic model by integrating four different nucleotides could enhance the prediction performance compared with individual nucleotide-specific models.</p>
      <fig position="float" id="f4">
        <label>Figure 4</label>
        <caption>
          <p>Heat map illustrating the cross-nucleotide model validation based on the testing datasets. Each nucleotide-specific model is evaluated with its own dataset as well as the remaining three nucleotide-specific datasets. The performance is assessed using three metrics: (A) Mathews correlation coefficient (MCC), (B) accuracy (ACC) and (C) area under the receiver operating characteristic curve (AUC).</p>
        </caption>
        <graphic xlink:href="bbad476f4" position="float"/>
      </fig>
    </sec>
    <sec id="sec16">
      <title>Development of a generic model</title>
      <p>To develop a generic model, we integrated the four nucleotide-specific datasets and eliminated redundant sequences using CD-HIT, resulting in 4256 positive and 4255 negative samples. The generic model was then built using the same approach outlined for the nucleotide-specific models. The results demonstrated that the generic model achieved MCC, Sn, Sp, ACC and AUC of 0.719, 0.840, 0.876, 0.858 and 0.937, respectively, during training. The corresponding values on the testing dataset were 0.602, 0.828, 0.918, 0.910 and 0.946, respectively (<xref rid="sup1" ref-type="supplementary-material">Figure S6</xref>). We compared the generic model’s performance with the individual nucleotide-specific models in two ways: (i) we averaged the performance of four nucleotide-specific models and compared it with the generic model. <xref rid="sup1" ref-type="supplementary-material">Figure S6</xref> shows that the generic approach consistently outperformed the nucleotide-specific approach in terms of MCC, ACC and AUC on both training and testing datasets. (ii) We categorized generic model’s predictions based on nucleotide specificity and compared them with the individual nucleotide-specific models. <xref rid="f5" ref-type="fig">Figure 5</xref> illustrates that the generic model marginally improved MCC, ACC and AUC on G2OM and U2OM, and significantly improved on the other two nucleotide training datasets. However, the generic model significantly outperformed all four nucleotide-specific models on the independent testing datasets. In addition, we developed 154 conventional models, as previously mentioned for the development of nucleotide-specific models, to investigate whether any of these models surpassed the performance of the HDL-based generic model. As illustrated in <xref rid="sup1" ref-type="supplementary-material">Figure S7</xref>, the HDL-based generic model consistently outperformed the top five best models based on the MCC among the conventional models on both training and independent datasets, highlighting the significance of the HDL approach implemented in H2Opred.</p>
      <fig position="float" id="f5">
        <label>Figure 5</label>
        <caption>
          <p>Performance of the generic model for each of the four nucleotides is compared with the corresponding nucleotide-specific models. The comparison is shown for both the (A) training dataset and (B) testing dataset.</p>
        </caption>
        <graphic xlink:href="bbad476f5" position="float"/>
      </fig>
      <p>Unlike individual nucleotides, 2OM occurs on the ribose moiety rather than specific modification sites like 5-methyl cytosine (m5C) and 6-methyl adenosine (m6A). As 2OM is not directly linked to nucleotide bases, using a generic dataset instead of nucleotide-specific datasets would be more appropriate since such datasets lack biological significance. Overall, the enhanced performance of our generic model can be attributed primarily to the larger training dataset.</p>
    </sec>
    <sec id="sec17">
      <title>Comparison of H2Opred models with the state-of-the art predictors on the independent testing datasets</title>
      <p>To further demonstrate the superiority of H2Opred models, we tried to compare them with four previously published methods: NmSEER v2.0, NmRF, DeepOMe and i2OM. However, we encountered challenges in extracting prediction results from the given sequence when using NmSEER v2.0 and DeepOMe. Therefore, we excluded these two methods from our comparative analysis and focused on NmRF and i2OM. Upon scrutinizing the performance of these two state-of-the-art predictors, we found that NmRF performed poorly, with results approaching random prediction levels (<xref rid="sup1" ref-type="supplementary-material">Figure S8</xref>). This makes NmRF unsuitable for genome-wide predictions. The primary reason for this subpar performance is that NmRF was trained on a substantially different dataset with a smaller number of samples than our models and i2OM. Comparing nucleotide-specific H2Opred models and i2OM directly is more straightforward and insightful because they were trained on the same datasets, allowing for a more meaningful evaluation of their respective performances. However, the generic H2Opred model was trained on different and larger training dataset. Owing to the challenges in accessing results from the i2OM web server, we utilized the standalone program (<ext-link xlink:href="https://github.com/yangmoo1010/i2OM" ext-link-type="uri">https://github.com/yangmoo1010/i2OM</ext-link>) to compute the results.</p>
      <p><xref rid="f6" ref-type="fig">Figure 6</xref> clearly shows that the generic H2Opred model achieved the best performance across all testing datasets. Compared with i2OM, the generic H2Opred model demonstrated significant improvements across several key metrics, including MCC, ACC, AUC and F1-score. Specifically, on the A2OM testing dataset, the generic H2Opred model achieved 45.44% improvement in MCC, 46.00% in ACC, 9.16% in AUC and 43.16% in F1-score. Similarly, on the C2OM testing dataset, the generic H2Opred model outperformed i2OM with improvements of 10.05% in MCC, 3.31% in ACC, 3.40% in AUC and 9.52% in F1-score. The advantages of the generic H2Opred model were evident on the G2OM testing dataset, where it achieved improvements of 7.03% in MCC, 2.49% in ACC, 2.35% in AUC and 6.74% in F1-score. On the U2OM testing dataset, the generic H2Opred model achieved with remarkable improvements of 28.10% in MCC, 11.64% in ACC, 15.42% in AUC and 24.73% in F1-score. Furthermore, the generic H2Opred model consistently outperformed the nucleotide-specific H2Opred models across all datasets, demonstrating the significant of a larger training on performance improvement. These results highlight the stability and excellence of proposed H2Opred models, making H2Opred as an effective and valuable computational tool for the precise identification of RNA 2OM sites.</p>
      <fig position="float" id="f6">
        <label>Figure 6</label>
        <caption>
          <p>Comparison of the performance of different H2Opred models and the state-of-the-art i2OM predictor on four testing datasets. (A) A2OM, (B) C2OM, (C) G2OM and (D) U2OM.</p>
        </caption>
        <graphic xlink:href="bbad476f6" position="float"/>
      </fig>
    </sec>
    <sec id="sec18">
      <title>Visualization of learned features</title>
      <p>In this section, we focused on the best generic model and visualized the learned features extracted by 1D-CNN, Bi-GRU-Att and H2Opred to understand the abstractions generated by these deep learning architectures. We employed UMAP, a novel dimensionality reduction technique, to reduce the original features into a 2D vector. <xref rid="f7" ref-type="fig">Figure 7</xref> shows that the feature representations learned by Bi-GRU-Att showed minimal overlap between 2OM and non-2OM sites, while those learned by 1D-CNN showed more overlapping samples. However, the feature representations learned by H2Opred showed a clear separation of 2OM and non-2OM samples on the generic training dataset. This suggests that H2Opred is capable of extracting the most informative and discriminative features through 1D-CNN and Bi-GRU-Att. The feature representation patterns observed in the training dataset follows a similar on the testing dataset for three deep learning architectures, demonstrating that the model is able to learn robust representations of the 2OM and non-2OM sites from training datasets, which can be generalized to new data.</p>
      <fig position="float" id="f7">
        <label>Figure 7</label>
        <caption>
          <p>UMAP visualization of the learned feature representations of three models (1D-CNN, Bi-GRU-Att and H2Opred) on the generic training (A–C) and independent testing (D–F) datasets.</p>
        </caption>
        <graphic xlink:href="bbad476f7" position="float"/>
      </fig>
      <p>Through UMAP visualization, we demonstrated that conventional feature descriptors and NLP-based embeddings can be mapped into meaningful representations through the HDL approach. This suggests that H2Opred can capture complex relationships between different features, which is not possible with conventional ML-based single-feature models. Consequently, H2Opred consistently outperformed other deep learning-based models and conventional ML-based single-feature models, making it a promising tool for identifying 2OM sites in the human genome.</p>
    </sec>
    <sec id="sec19">
      <title>Web server implementation</title>
      <p>H2Opred, a user-friendly web server for predicting RNA 2OM sites, is now freely available at <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>. The website also provides access to all training and testing datasets employed in this study. To use H2Opred, users can either upload a file containing multiple FASTA sequences or input one or more query sequences in FASTA format. The input sequence must be in the FASTA format and exactly 41 bp long. Users are then be prompted to select their model of choice (N2OM, A2OM, G2OM, C2OM or U2OM) before job submission. If no model is selected, the N2OM model will be employed automatically. Upon successful job completion, the results are presented on a dedicated interface, allowing users to easily view and analyze the findings. Additionally, users have the option to download the results in CSV format for future reference.</p>
    </sec>
  </sec>
  <sec id="sec20">
    <title>CONCLUSION</title>
    <p>2OM is a common post-transcriptional modification with important implications for various biological functions. Understanding its distribution within RNA can provide insights into its mechanism of action. In this study, we introduced a novel HDL model called H2Opred, to accurately identify 2OM sites from primary RNA sequences. We first identified 14 conventional descriptors and evaluated their discriminative patterns using the 11 ML-based classifiers. We then used stacked 1D-CNN to learn the feature representations from these conventional descriptors. Next, we used NLP-based embeddings derived from RNA sequence and trained using stacked Bi-GRU-Att to capture more diverse facets of feature representations. Finally, we integrated these two distinct feature representations to make final prediction. Rigorous cross-validation and independent testing on different datasets showed that H2Opred achieved a more balanced performance and consistently outperformed the two deep learning architectures as well as several hundreds of ML-based single-feature models.</p>
    <p>In contrast to individual nucleotides, which have specific modification sites like m5C and m6A, 2OM occurs on the ribose moiety, a structural component of RNA. Therefore, developing 2OM site prediction model using the nucleotide-specific datasets lacks biological significance. Indeed, our cross-nucleotide model analysis demonstrated the transferability of nucleotide-specific models across other nucleotide datasets, suggesting that a generic model can be developed by integrating all nucleotide-specific datasets. To this end, we developed a generic model that showed significant improvement on both training and testing datasets compared with the nucleotide-specific models. In the H2Opred webserver, we have incorporated both the four nucleotide-specific models and a generic model. Notably, each of these models demonstrated superior performance over the existing predictor i2OM across all evaluation metrics on the independent testing datasets. This suggests that our HDL framework integrated conventional descriptors with NLP-based embeddings to significantly improve prediction performance. To make H2Opred widely accessible and user-friendly, we have launched a dedicated web server at <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>. We believe that this online platform will be invaluable for researchers seeking to accurately predict 2OM sites in human RNA, advancing scientific progress in this field. The current approach can be extended to other RNA post-transcriptional prediction sites [<xref rid="ref47" ref-type="bibr">47</xref>], RNA subcellular localization [<xref rid="ref48" ref-type="bibr">48</xref>] and peptide therapeutic function prediction [<xref rid="ref27" ref-type="bibr">27</xref>].</p>
    <p>H2Opred has shown significant promise in predicting 2OM sites, but there are areas for further refinement. The proposed model was trained on a larger dataset than existing methods. However, we can further enhance the model performance by incorporating new data as it becomes available. We integrated conventional descriptors with NLP-based embeddings through an HDL framework, but future work could explore other methodologies, such as contrastive learning [<xref rid="ref49" ref-type="bibr">49</xref>, <xref rid="ref50" ref-type="bibr">50</xref>], ensemble or stacking approaches based on conventional ML classifiers [<xref rid="ref51" ref-type="bibr">51</xref>], hybrid feature approach [<xref rid="ref52" ref-type="bibr">52</xref>], feature representation learning [<xref rid="ref53" ref-type="bibr">53</xref>] and iterative feature refinement [<xref rid="ref54" ref-type="bibr">54</xref>, <xref rid="ref55" ref-type="bibr">55</xref>]. Beyond conventional descriptors and NLP-based embeddings, the topological structure of RNA sequences also plays an important role in defining their functions. To improve feature representation, we could incorporate predicted structural information within the HDL framework. Currently, H2Opred is still a ‘black box’, limiting its ability to explain its decisions. In the future, we aspire to develop a model that is not only accurate but also interpretable, providing tangible and actionable biological insights.</p>
    <boxed-text id="box01" position="float">
      <sec id="sec21z">
        <title>Key Points</title>
        <list list-type="bullet">
          <list-item>
            <p>We introduced a novel HDL model called H2Opred for accurately identifying 2’-O-methylation (2OM) sites in human RNA.</p>
          </list-item>
          <list-item>
            <p>H2Opred used a combination of stacked 1D-CNN and Bi-GRU-Att blocks to learn effective feature representation from 14 conventional descriptors and five NLP-based embeddings, respectively. Subsequently, these representations were combined to make the final prediction.</p>
          </list-item>
          <list-item>
            <p>A novel generic model has been developed, driven by cross-nucleotide model analysis, significantly outperforming nucleotide-specific models and the existing predictor when tested on large samples of an independent dataset.</p>
          </list-item>
          <list-item>
            <p>H2Opred is now available as a web server at <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>, providing an invaluable tool for predicting 2OM sites in human RNA.</p>
          </list-item>
        </list>
      </sec>
    </boxed-text>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>H2Opred_SI_bbad476</label>
      <media xlink:href="h2opred_si_bbad476.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="bbad476-ack">
    <title>ACKNOWLEDGEMENTS</title>
    <p>The authors would like to thank the Korea Institute of Science and Technology Information (KISTI) and Korea Bio Data Station (K-BDS) with computing resources including technical support. We thank Nattanong Bupi for his assistance in creating the figure, and CBBL members for their valuable discussion.</p>
  </ack>
  <sec id="sec23">
    <title>FUNDING</title>
    <p>This work was supported by the National Research Foundation of Korea (NRF) funded by the Ministry of Science and ICT (2021R1A2C1014338 and 2021R1I1A1A01056363), and Korea Health Technology R&amp;D Project grant through the Korea Health Industry Development Institute (KHIDI) funded by the Ministry of Health &amp; Welfare, Republic of Korea (HI23C0701).</p>
  </sec>
  <sec sec-type="data-availability" id="sec24">
    <title>DATA AVAILABILITY</title>
    <p>Web server and all the processed data used in this study can be accessed via <ext-link xlink:href="https://balalab-skku.org/H2Opred/" ext-link-type="uri">https://balalab-skku.org/H2Opred/</ext-link>.</p>
  </sec>
  <notes id="bio3">
    <title>Author Biographies</title>
    <p><bold>Nhat Truong Pham</bold> is a Ph.D. student at the Computational Biology and Bioinformatics Laboratory, Department of Integrative Biotechnology, Sungkyunkwan University, Republic of Korea. His research interests include artificial intelligence, bioinformatics, computational biology and medicine, deep learning, machine learning, signal processing and XAI and optimization.</p>
    <sec sec-type="author-bio" id="sec26">
      <p><bold>Rajan Rakkiyappan</bold> is a professor in the Department of Mathematics at Bharathiar University in Tamil Nadu, India. His research interests include neural networks, stability theory, data-driven machine learning, bioinformatics and computational biology.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27">
      <p><bold>Jongsun Park</bold> is a co-CEO and CTO of Infoboss Inc, Republic of Korea. His research interests include bioinformatics, genomics, deep learning, machine learning, bio big data, plant/insect taxonomy and phylogenetics.</p>
    </sec>
    <sec sec-type="author-bio" id="sec28">
      <p><bold>Adeel Malik</bold> is a Research Professor at the Institute of Intelligence Informatics Technology, Sangmyung University, Seoul, Republic of Korea. His research interests include machine learning, computational biology and comparative genomics.</p>
    </sec>
    <sec sec-type="author-bio" id="sec29">
      <p><bold>Balachandran Manavalan</bold> is an Assistant Professor at the Department of Integrative Biotechnology, Sungkyunkwan University, Republic of Korea. He is also an associate member of Korea Institute for Advanced Study, Republic of Korea. His research interests include artificial intelligence, bioinformatics, machine learning, big data and functional genomics.</p>
    </sec>
  </notes>
  <ref-list id="bib1">
    <title>References</title>
    <ref id="ref1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname><given-names>BS</given-names></string-name>, <string-name><surname>Roundtree</surname><given-names>IA</given-names></string-name>, <string-name><surname>He</surname><given-names>C</given-names></string-name></person-group>. <article-title>Post-transcriptional gene regulation by mRNA modifications</article-title>. <source>Nat Rev Mol Cell Biol</source><year>2017</year>;<volume>18</volume>:<fpage>31</fpage>–<lpage>42</lpage>.<pub-id pub-id-type="pmid">27808276</pub-id></mixed-citation>
    </ref>
    <ref id="ref2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Machnicka</surname><given-names>MA</given-names></string-name>, <string-name><surname>Milanowska</surname><given-names>K</given-names></string-name>, <string-name><surname>Osman Oglou</surname><given-names>O</given-names></string-name>, <string-name><surname>Purta</surname><given-names>E</given-names></string-name>, <string-name><surname>Kurkowska</surname><given-names>M</given-names></string-name>, <string-name><surname>Olchowik</surname><given-names>A</given-names></string-name>, <string-name><surname>Januszewski</surname><given-names>W</given-names></string-name>, <string-name><surname>Kalinowski</surname><given-names>S</given-names></string-name>, <string-name><surname>Dunin-Horkawicz</surname><given-names>S</given-names></string-name>, <string-name><surname>Rother</surname><given-names>KM</given-names></string-name>, <string-name><surname>Helm</surname><given-names>M</given-names></string-name>, <string-name><surname>Bujnicki</surname><given-names>JM</given-names></string-name>, <string-name><surname>Grosjean</surname><given-names>H</given-names></string-name></person-group><article-title>MODOMICS: a database of RNA modification pathways--2013 update</article-title>, <source>Nucleic Acids Res</source> 2013;<volume>41</volume>:<fpage>D262</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">23118484</pub-id>
</mixed-citation>
    </ref>
    <ref id="ref3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ayadi</surname><given-names>L</given-names></string-name>, <string-name><surname>Galvanin</surname><given-names>A</given-names></string-name>, <string-name><surname>Pichot</surname><given-names>F</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RNA ribose methylation (2′-O-methylation): occurrence, biosynthesis and biological functions</article-title>. <source>Biochim Biophys Acta</source><year>2019</year>;<volume>1862</volume>:<fpage>253</fpage>–<lpage>69</lpage>.</mixed-citation>
    </ref>
    <ref id="ref4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Daffis</surname><given-names>S</given-names></string-name>, <string-name><surname>Szretter</surname><given-names>KJ</given-names></string-name>, <string-name><surname>Schriewer</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>2'-O methylation of the viral mRNA cap evades host restriction by IFIT family members</article-title>. <source>Nature</source><year>2010</year>;<volume>468</volume>:<fpage>452</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">21085181</pub-id></mixed-citation>
    </ref>
    <ref id="ref5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>J</given-names></string-name>, <string-name><surname>Lai</surname><given-names>S</given-names></string-name>, <string-name><surname>Jia</surname><given-names>R</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Structural basis for site-specific ribose methylation by box C/D RNA protein complexes</article-title>. <source>Nature</source><year>2011</year>;<volume>469</volume>:<fpage>559</fpage>–<lpage>63</lpage>.<pub-id pub-id-type="pmid">21270896</pub-id></mixed-citation>
    </ref>
    <ref id="ref6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zust</surname><given-names>R</given-names></string-name>, <string-name><surname>Cervantes-Barragan</surname><given-names>L</given-names></string-name>, <string-name><surname>Habjan</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Ribose 2'-O-methylation provides a molecular signature for the distinction of self and non-self mRNA dependent on the RNA sensor Mda5</article-title>. <source>Nat Immunol</source><year>2011</year>;<volume>12</volume>:<fpage>137</fpage>–<lpage>43</lpage>.<pub-id pub-id-type="pmid">21217758</pub-id></mixed-citation>
    </ref>
    <ref id="ref7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ringeard</surname><given-names>M</given-names></string-name>, <string-name><surname>Marchand</surname><given-names>V</given-names></string-name>, <string-name><surname>Decroly</surname><given-names>E</given-names></string-name>, <etal>et al.</etal></person-group><article-title>FTSJ3 is an RNA 2′-O-methyltransferase recruited by HIV to avoid innate immune sensing</article-title>. <source>Nature</source><year>2019</year>;<volume>565</volume>:<fpage>500</fpage>–<lpage>4</lpage>.<pub-id pub-id-type="pmid">30626973</pub-id></mixed-citation>
    </ref>
    <ref id="ref8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gehrig</surname><given-names>S</given-names></string-name>, <string-name><surname>Eberle</surname><given-names>M-E</given-names></string-name>, <string-name><surname>Botschen</surname><given-names>F</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Identification of modifications in microbial, native tRNA that suppress immunostimulatory activity</article-title>. <source>J Exp Med</source><year>2012</year>;<volume>209</volume>:<fpage>225</fpage>–<lpage>33</lpage>.<pub-id pub-id-type="pmid">22312113</pub-id></mixed-citation>
    </ref>
    <ref id="ref9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>C</given-names></string-name>, <string-name><surname>Yu</surname><given-names>Y-T</given-names></string-name></person-group>. <article-title>Targeted 2′-O methylation at a nucleotide within the pseudoknot of telomerase RNA reduces telomerase activity in vivo</article-title>. <source>Mol Cell Biol</source><year>2010</year>;<volume>30</volume>:<fpage>4368</fpage>–<lpage>78</lpage>.<pub-id pub-id-type="pmid">20647541</pub-id></mixed-citation>
    </ref>
    <ref id="ref10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dai</surname><given-names>Q</given-names></string-name>, <string-name><surname>Moshitch-Moshkovitz</surname><given-names>S</given-names></string-name>, <string-name><surname>Han</surname><given-names>D</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Nm-seq maps 2'-O-methylation sites in human mRNA with base precision</article-title>. <source>Nat Methods</source><year>2017</year>;<volume>14</volume>:<fpage>695</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">28504680</pub-id></mixed-citation>
    </ref>
    <ref id="ref11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krogh</surname><given-names>N</given-names></string-name>, <string-name><surname>Birkedal</surname><given-names>U</given-names></string-name>, <string-name><surname>Nielsen</surname><given-names>H</given-names></string-name></person-group>. <article-title>RiboMeth-seq: profiling of 2'-O-me in RNA</article-title>. <source>Methods Mol Biol</source><year>2017</year>;<volume>1562</volume>:<fpage>189</fpage>–<lpage>209</lpage>.<pub-id pub-id-type="pmid">28349462</pub-id></mixed-citation>
    </ref>
    <ref id="ref12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Incarnato</surname><given-names>D</given-names></string-name>, <string-name><surname>Anselmi</surname><given-names>F</given-names></string-name>, <string-name><surname>Morandi</surname><given-names>E</given-names></string-name>, <etal>et al.</etal></person-group><article-title>High-throughput single-base resolution mapping of RNA 2ʹ-O-methylated residues</article-title>. <source>Nucleic Acids Res</source><year>2017</year>;<volume>45</volume>:<fpage>1433</fpage>–<lpage>41</lpage>.<pub-id pub-id-type="pmid">28180324</pub-id></mixed-citation>
    </ref>
    <ref id="ref13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Pirnie</surname><given-names>SP</given-names></string-name>, <string-name><surname>Carmichael</surname><given-names>GG</given-names></string-name></person-group>. <article-title>High-throughput and site-specific identification of 2'-O-methylation sites using ribose oxidation sequencing (RibOxi-seq)</article-title>. <source>RNA</source><year>2017</year>;<volume>23</volume>:<fpage>1303</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">28495677</pub-id></mixed-citation>
    </ref>
    <ref id="ref14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hsu</surname><given-names>PJ</given-names></string-name>, <string-name><surname>Fei</surname><given-names>Q</given-names></string-name>, <string-name><surname>Dai</surname><given-names>Q</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Single base resolution mapping of 2'-O-methylation sites in human mRNA and in 3′ terminal ends of small RNAs</article-title>. <source>Methods</source><year>2019</year>;<volume>156</volume>:<fpage>85</fpage>–<lpage>90</lpage>.<pub-id pub-id-type="pmid">30471344</pub-id></mixed-citation>
    </ref>
    <ref id="ref15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>WJ</given-names></string-name>, <string-name><surname>Li</surname><given-names>JH</given-names></string-name>, <string-name><surname>Liu</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RMBase: a resource for decoding the landscape of RNA modifications from high-throughput sequencing data</article-title>. <source>Nucleic Acids Res</source><year>2016</year>;<volume>44</volume>:<fpage>D259</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">26464443</pub-id></mixed-citation>
    </ref>
    <ref id="ref16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xuan</surname><given-names>JJ</given-names></string-name>, <string-name><surname>Sun</surname><given-names>WJ</given-names></string-name>, <string-name><surname>Lin</surname><given-names>PH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RMBase v2.0: deciphering the map of RNA modifications from epitranscriptome sequencing data</article-title>. <source>Nucleic Acids Res</source><year>2018</year>;<volume>46</volume>:<fpage>D327</fpage>–<lpage>34</lpage>.<pub-id pub-id-type="pmid">29040692</pub-id></mixed-citation>
    </ref>
    <ref id="ref17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>W</given-names></string-name>, <string-name><surname>Feng</surname><given-names>P</given-names></string-name>, <string-name><surname>Tang</surname><given-names>H</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Identifying 2'-O-methylationation sites by integrating nucleotide chemical properties and nucleotide compositions</article-title>. <source>Genomics</source><year>2016</year>;<volume>107</volume>:<fpage>255</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">27191866</pub-id></mixed-citation>
    </ref>
    <ref id="ref18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>H</given-names></string-name>, <string-name><surname>Lv</surname><given-names>H</given-names></string-name>, <string-name><surname>Ding</surname><given-names>H</given-names></string-name>, <etal>et al.</etal></person-group><article-title>iRNA-2OM: a sequence-based predictor for identifying 2'-O-methylation sites in Homo sapiens</article-title>. <source>J Comput Biol</source><year>2018</year>;<volume>25</volume>:<fpage>1266</fpage>–<lpage>77</lpage>.<pub-id pub-id-type="pmid">30113871</pub-id></mixed-citation>
    </ref>
    <ref id="ref19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tahir</surname><given-names>M</given-names></string-name>, <string-name><surname>Tayara</surname><given-names>H</given-names></string-name>, <string-name><surname>Chong</surname><given-names>KT</given-names></string-name></person-group>. <article-title>iRNA-PseKNC(2methyl): identify RNA 2'-O-methylation sites by convolution neural network and Chou's pseudo components</article-title>. <source>J Theor Biol</source><year>2019</year>;<volume>465</volume>:<fpage>1</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">30590059</pub-id></mixed-citation>
    </ref>
    <ref id="ref20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>QL</given-names></string-name>, <string-name><surname>Wang</surname><given-names>L</given-names></string-name>, <string-name><surname>Han</surname><given-names>SG</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Identification of 2'-O-methylation site by investigating multi-feature extracting techniques</article-title>. <source>Comb Chem High Throughput Screen</source><year>2020</year>;<volume>23</volume>:<fpage>527</fpage>–<lpage>35</lpage>.<pub-id pub-id-type="pmid">32334499</pub-id></mixed-citation>
    </ref>
    <ref id="ref21">
      <label>21.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Cui</surname><given-names>Q</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name></person-group>. <part-title>NmSEER: A Prediction Tool for 2’-O-Methylation (Nm) Sites Based on Random Forest</part-title>. In: <source>Intelligent Computing Theories and Application: 14th International Conference, ICIC 2018</source>, <conf-loc>Wuhan, China</conf-loc>, <conf-date>August 15–18</conf-date>. <comment>Proceedings, Part I 14. 2018</comment>. Springer, <year>2018</year>;<volume>10954</volume>:pp. <fpage>893</fpage>–<lpage>900</lpage>.</mixed-citation>
    </ref>
    <ref id="ref22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Cui</surname><given-names>Q</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name></person-group>. <article-title>NmSEER V2.0: a prediction tool for 2'-O-methylation sites based on random forest and multi-encoding combination</article-title>. <source>BMC Bioinformatics</source><year>2019</year>;<volume>20</volume>:<fpage>690</fpage>.<pub-id pub-id-type="pmid">31874624</pub-id></mixed-citation>
    </ref>
    <ref id="ref23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Chen</surname><given-names>L</given-names></string-name>, <string-name><surname>Huang</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>DeepOMe: a web server for the prediction of 2'-O-me sites based on the hybrid CNN and BLSTM architecture</article-title>. <source>Front Cell Dev Biol</source><year>2021</year>;<volume>9</volume>:<fpage>686894</fpage>.<pub-id pub-id-type="pmid">34055810</pub-id></mixed-citation>
    </ref>
    <ref id="ref24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ao</surname><given-names>C</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <string-name><surname>Yu</surname><given-names>L</given-names></string-name></person-group>. <article-title>NmRF: identification of multispecies RNA 2'-O-methylation modification sites from RNA sequences</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:bbab480.</mixed-citation>
    </ref>
    <ref id="ref25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>YH</given-names></string-name>, <string-name><surname>Ma</surname><given-names>CY</given-names></string-name>, <string-name><surname>Gao</surname><given-names>D</given-names></string-name>, <etal>et al.</etal></person-group><article-title>i2OM: toward a better prediction of 2'-O-methylation in human RNA</article-title>. <source>Int J Biol Macromol</source><year>2023</year>;<volume>239</volume>:<fpage>124247</fpage>.<pub-id pub-id-type="pmid">37003392</pub-id></mixed-citation>
    </ref>
    <ref id="ref26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Niu</surname><given-names>B</given-names></string-name>, <string-name><surname>Gao</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CD-HIT suite: a web server for clustering and comparing biological sequences</article-title>. <source>Bioinformatics</source><year>2010</year>;<volume>26</volume>:<fpage>680</fpage>–<lpage>2</lpage>.<pub-id pub-id-type="pmid">20053844</pub-id></mixed-citation>
    </ref>
    <ref id="ref27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <string-name><surname>Manavalan</surname><given-names>B</given-names></string-name>, <string-name><surname>Hwan Shin</surname><given-names>T</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Machine intelligence in peptide therapeutics: a next-generation tool for rapid disease screening</article-title>. <source>Med Res Rev</source><year>2020</year>;<volume>40</volume>:<fpage>1276</fpage>–<lpage>314</lpage>.<pub-id pub-id-type="pmid">31922268</pub-id></mixed-citation>
    </ref>
    <ref id="ref28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname><given-names>B</given-names></string-name>, <string-name><surname>Wang</surname><given-names>X</given-names></string-name>, <string-name><surname>Liang</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RMDisease V2.0: an updated database of genetic variants that affect RNA modifications with disease and trait implication</article-title>. <source>Nucleic Acids Res</source><year>2023</year>;<volume>51</volume>:<fpage>D1388</fpage>–<lpage>96</lpage>.<pub-id pub-id-type="pmid">36062570</pub-id></mixed-citation>
    </ref>
    <ref id="ref29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manavalan</surname><given-names>B</given-names></string-name>, <string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <string-name><surname>Shin</surname><given-names>TH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Meta-4mCpred: a sequence-based meta-predictor for accurate DNA 4mC site prediction using effective feature representation</article-title>. <source>Mol Ther Nucleic Acids</source><year>2019</year>;<volume>16</volume>:<fpage>733</fpage>–<lpage>44</lpage>.<pub-id pub-id-type="pmid">31146255</pub-id></mixed-citation>
    </ref>
    <ref id="ref30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiang</surname><given-names>J</given-names></string-name>, <string-name><surname>Song</surname><given-names>B</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>m5UPred: a web server for the prediction of RNA 5-Methyluridine sites from sequences</article-title>. <source>Mol Ther Nucleic Acids</source><year>2020</year>;<volume>22</volume>:<fpage>742</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">33230471</pub-id></mixed-citation>
    </ref>
    <ref id="ref31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahmed</surname><given-names>S</given-names></string-name>, <string-name><surname>Muhammod</surname><given-names>R</given-names></string-name>, <string-name><surname>Khan</surname><given-names>ZH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>ACP-MHCNN: an accurate multi-headed deep-convolutional neural network to predict anticancer peptides</article-title>. <source>Sci Rep</source><year>2021</year>;<volume>11</volume>:<fpage>23676</fpage>.<pub-id pub-id-type="pmid">34880291</pub-id></mixed-citation>
    </ref>
    <ref id="ref32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ge</surname><given-names>F</given-names></string-name>, <string-name><surname>Li</surname><given-names>C</given-names></string-name>, <string-name><surname>Iqbal</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>VPatho: a deep learning-based two-stage approach for accurate prediction of gain-of-function and loss-of-function variants</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:bbac535.</mixed-citation>
    </ref>
    <ref id="ref33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Guo</surname><given-names>X</given-names></string-name>, <string-name><surname>Bi</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Digerati - a multipath parallel hybrid deep learning framework for the identification of mycobacterial PE/PPE proteins</article-title>. <source>Comput Biol Med</source><year>2023</year>;<volume>163</volume>:<elocation-id>107155</elocation-id>.<pub-id pub-id-type="pmid">37356289</pub-id></mixed-citation>
    </ref>
    <ref id="ref34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Li</surname><given-names>C</given-names></string-name>, <etal>et al.</etal></person-group><article-title>iAMPCN: a deep-learning approach for identifying antimicrobial peptides and their functional activities</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:bbad240.</mixed-citation>
    </ref>
    <ref id="ref35">
      <label>35.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bahdanau</surname><given-names>D</given-names></string-name>, <string-name><surname>Cho</surname><given-names>K</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>Y</given-names></string-name></person-group>. <article-title>Neural machine translation by jointly learning to align and translate</article-title>. <comment>arXiv preprint arXiv:1409.0473 2014</comment>.</mixed-citation>
    </ref>
    <ref id="ref36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pham</surname><given-names>NT</given-names></string-name>, <string-name><surname>Dang</surname><given-names>DNM</given-names></string-name>, <string-name><surname>Nguyen</surname><given-names>ND</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Hybrid data augmentation and deep attention-based dilated convolutional-recurrent neural networks for speech emotion recognition</article-title>. <source>Expert Syst Appl</source><year>2023</year>;<volume>230</volume>:<elocation-id>120608</elocation-id>.</mixed-citation>
    </ref>
    <ref id="ref37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>G</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Feng</surname><given-names>P</given-names></string-name>, <etal>et al.</etal></person-group><article-title>IPs-GRUAtt: an attention-based bidirectional gated recurrent unit network for predicting phosphorylation sites of SARS-CoV-2 infection</article-title>. <source>Mol Ther Nucleic Acids</source><year>2023</year>;<volume>32</volume>:<fpage>28</fpage>–<lpage>35</lpage>.<pub-id pub-id-type="pmid">36908648</pub-id></mixed-citation>
    </ref>
    <ref id="ref38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Liu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Xu</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Leveraging the attention mechanism to improve the identification of DNA N6-methyladenine sites</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:bbab351.</mixed-citation>
    </ref>
    <ref id="ref39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahmed</surname><given-names>S</given-names></string-name>, <string-name><surname>Kabir</surname><given-names>M</given-names></string-name>, <string-name><surname>Arif</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>DeepPPSite: a deep learning-based model for analysis and prediction of phosphorylation sites using efficient sequence information</article-title>. <source>Anal Biochem</source><year>2021</year>;<volume>612</volume>:<fpage>113955</fpage>.<pub-id pub-id-type="pmid">32949607</pub-id></mixed-citation>
    </ref>
    <ref id="ref40">
      <label>40.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tang</surname><given-names>X</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>P</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Deep6mAPred: a CNN and Bi-LSTM-based deep learning method for predicting DNA N6-methyladenosine sites across plant species</article-title>. <source>Methods</source><year>2022</year>;<volume>204</volume>:<fpage>142</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">35477057</pub-id></mixed-citation>
    </ref>
    <ref id="ref41">
      <label>41.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>ZY</given-names></string-name>, <string-name><surname>Ning</surname><given-names>L</given-names></string-name>, <string-name><surname>Ye</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>iLoc-miRNA: extracellular/intracellular miRNA prediction using deep BiLSTM with attention mechanism</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:bbac395.</mixed-citation>
    </ref>
    <ref id="ref42">
      <label>42.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>Z</given-names></string-name>, <string-name><surname>Huang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>PSnoD: identifying potential snoRNA-disease associations based on bounded nuclear norm regularization</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:bbac240.</mixed-citation>
    </ref>
    <ref id="ref43">
      <label>43.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ge</surname><given-names>F</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Prediction of multiple types of RNA modifications via biological language model</article-title>. <source>IEEE/ACM Trans Comput Biol Bioinform</source><year>2023</year>;<volume>20</volume>(<issue>5</issue>):3205–14.</mixed-citation>
    </ref>
    <ref id="ref44">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>R</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Guo</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>ATTIC is an integrated approach for predicting A-to-I RNA editing sites in three species</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:<fpage>bbad170</fpage>.<pub-id pub-id-type="pmid">37150785</pub-id></mixed-citation>
    </ref>
    <ref id="ref45">
      <label>45.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Yang</surname><given-names>B</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Bastion3: a two-layer ensemble predictor of type III secreted effectors</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>2017</fpage>–<lpage>28</lpage>.<pub-id pub-id-type="pmid">30388198</pub-id></mixed-citation>
    </ref>
    <ref id="ref46">
      <label>46.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shoombuatong</surname><given-names>W</given-names></string-name>, <string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <string-name><surname>Pitti</surname><given-names>T</given-names></string-name>, <etal>et al.</etal></person-group><article-title>THRONE: a new approach for accurate prediction of human RNA N7-methylguanosine sites</article-title>. <source>J Mol Biol</source><year>2022</year>;<volume>434</volume>:<fpage>167549</fpage>.<pub-id pub-id-type="pmid">35662472</pub-id></mixed-citation>
    </ref>
    <ref id="ref47">
      <label>47.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <string-name><surname>Xing</surname><given-names>P</given-names></string-name>, <string-name><surname>Wei</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Gene2vec: gene subsequence embedding for prediction of mammalian N(6)-methyladenosine sites from mRNA</article-title>. <source>RNA</source><year>2019</year>;<volume>25</volume>:<fpage>205</fpage>–<lpage>18</lpage>.<pub-id pub-id-type="pmid">30425123</pub-id></mixed-citation>
    </ref>
    <ref id="ref48">
      <label>48.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yuan</surname><given-names>GH</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>GZ</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RNAlight: a machine learning model to identify nucleotide features determining RNA subcellular localization</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:bbac509.</mixed-citation>
    </ref>
    <ref id="ref49">
      <label>49.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>X</given-names></string-name>, <string-name><surname>Jin</surname><given-names>J</given-names></string-name>, <string-name><surname>Wang</surname><given-names>R</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CACPP: a contrastive learning-based Siamese network to identify anticancer peptides based on sequence only</article-title>. <source>J Chem Inf Model</source><year>2023</year>.</mixed-citation>
    </ref>
    <ref id="ref50">
      <label>50.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Wei</surname><given-names>L</given-names></string-name>, <string-name><surname>Ye</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>SiameseCPP: a sequence-based Siamese network to predict cell-penetrating peptides by contrastive learning</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:bbac545.</mixed-citation>
    </ref>
    <ref id="ref51">
      <label>51.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Charoenkwan</surname><given-names>P</given-names></string-name>, <string-name><surname>Chiangjong</surname><given-names>W</given-names></string-name>, <string-name><surname>Nantasenamat</surname><given-names>C</given-names></string-name>, <etal>et al.</etal></person-group><article-title>StackIL6: a stacking ensemble model for improving the prediction of IL-6 inducing peptides</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:bbab172.</mixed-citation>
    </ref>
    <ref id="ref52">
      <label>52.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Wei</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>6mA-RicePred: a method for identifying DNA N (6)-Methyladenine sites in the rice genome based on feature fusion</article-title>. <source>Front Plant Sci</source><year>2020</year>;<volume>11</volume>:<fpage>4</fpage>.<pub-id pub-id-type="pmid">32076430</pub-id></mixed-citation>
    </ref>
    <ref id="ref53">
      <label>53.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hasan</surname><given-names>MM</given-names></string-name>, <string-name><surname>Schaduangrat</surname><given-names>N</given-names></string-name>, <string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>HLPpred-Fuse: improved and robust prediction of hemolytic peptide and its activity by fusing multiple feature representation</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>3350</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">32145017</pub-id></mixed-citation>
    </ref>
    <ref id="ref54">
      <label>54.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wei</surname><given-names>L</given-names></string-name>, <string-name><surname>Su</surname><given-names>R</given-names></string-name>, <string-name><surname>Luan</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Iterative feature representations improve N4-methylcytosine site prediction</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>4930</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">31099381</pub-id></mixed-citation>
    </ref>
    <ref id="ref55">
      <label>55.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manavalan</surname><given-names>B</given-names></string-name>, <string-name><surname>Basith</surname><given-names>S</given-names></string-name>, <string-name><surname>Shin</surname><given-names>TH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Computational prediction of species-specific yeast DNA replication origin via iterative feature representation</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:bbaa304.</mixed-citation>
    </ref>
  </ref-list>
</back>
