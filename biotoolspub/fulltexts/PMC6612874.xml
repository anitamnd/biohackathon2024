<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6612874</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btz367</article-id>
    <article-id pub-id-type="publisher-id">btz367</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Ismb/Eccb 2019 Conference Proceedings</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Macromolecular Sequence, Structure, and Function</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DIFFUSE: predicting isoform functions from sequences and expression profiles via deep learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Hao</given-names>
        </name>
        <xref ref-type="aff" rid="btz367-aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shaw</surname>
          <given-names>Dipan</given-names>
        </name>
        <xref ref-type="aff" rid="btz367-aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zeng</surname>
          <given-names>Jianyang</given-names>
        </name>
        <xref ref-type="aff" rid="btz367-aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bu</surname>
          <given-names>Dongbo</given-names>
        </name>
        <xref ref-type="aff" rid="btz367-aff3">3</xref>
        <xref ref-type="aff" rid="btz367-aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-3833-4498</contrib-id>
        <name>
          <surname>Jiang</surname>
          <given-names>Tao</given-names>
        </name>
        <xref ref-type="aff" rid="btz367-aff1">1</xref>
        <xref ref-type="aff" rid="btz367-aff5">5</xref>
        <xref ref-type="corresp" rid="btz367-cor1"/>
        <!--<email>jiang@cs.ucr.edu</email>-->
      </contrib>
    </contrib-group>
    <aff id="btz367-aff1"><label>1</label>Department of Compute Science and Engineering, University of California, Riverside, CA, USA</aff>
    <aff id="btz367-aff2"><label>2</label>Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, China</aff>
    <aff id="btz367-aff3"><label>3</label>Key Lab of Intelligent Information Process, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China</aff>
    <aff id="btz367-aff4"><label>4</label>University of Chinese Academy of Sciences, Beijing, China</aff>
    <aff id="btz367-aff5"><label>5</label>Bioinformatics Division, BNRIST/Department of Computer Science and Technology, Tsinghua University, Beijing, China</aff>
    <author-notes>
      <corresp id="btz367-cor1">To whom correspondence should be addressed. <email>jiang@cs.ucr.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-07-05">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>35</volume>
    <issue>14</issue>
    <fpage>i284</fpage>
    <lpage>i294</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btz367.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Alternative splicing generates multiple isoforms from a single gene, greatly increasing the functional diversity of a genome. Although gene functions have been well studied, little is known about the specific functions of isoforms, making accurate prediction of isoform functions highly desirable. However, the existing approaches to predicting isoform functions are far from satisfactory due to at least two reasons: (i) unlike genes, isoform-level functional annotations are scarce. (ii) The information of isoform functions is concealed in various types of data including isoform sequences, co-expression relationship among isoforms, etc.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>In this study, we present a novel approach, DIFFUSE (Deep learning-based prediction of IsoForm FUnctions from Sequences and Expression), to predict isoform functions. To integrate various types of data, our approach adopts a hybrid framework by first using a deep neural network (DNN) to predict the functions of isoforms from their genomic sequences and then refining the prediction using a conditional random field (CRF) based on co-expression relationship. To overcome the lack of isoform-level ground truth labels, we further propose an iterative semi-supervised learning algorithm to train both the DNN and CRF together. Our extensive computational experiments demonstrate that DIFFUSE could effectively predict the functions of isoforms and genes. It achieves an average area under the receiver operating characteristics curve of 0.840 and area under the precision–recall curve of 0.581 over 4184 GO functional categories, which are significantly higher than the state-of-the-art methods. We further validate the prediction results by analyzing the correlation between functional similarity, sequence similarity, expression similarity and structural similarity, as well as the consistency between the predicted functions and some well-studied functional features of isoform sequences.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p><ext-link ext-link-type="uri" xlink:href="https://github.com/haochenucr/DIFFUSE">https://github.com/haochenucr/DIFFUSE</ext-link>.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">National Science Foundation</named-content>
          <named-content content-type="funder-identifier">10.13039/100000001</named-content>
        </funding-source>
        <award-id>IIS-1646333</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">National Natural Science Foundation of China</named-content>
          <named-content content-type="funder-identifier">10.13039/501100001809</named-content>
        </funding-source>
        <award-id>61772197, 31671369, 31770775, 61872216, 61472205 and 81630103</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">National Key Research and Development Program of China</named-content>
          <named-content content-type="funder-identifier">10.13039/501100012166</named-content>
        </funding-source>
        <award-id>2018YFC0910404 and 2018YFC0910405</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="11"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>In recent years, the study of functional genomics has expanded from the gene level to the transcript level. Due to alternative splicing, exons of multi-exon genes are selectively included in the transcription process, thus generating multiple isoforms from a single gene. Isoforms carry specific, sometimes distinct or even opposing, biological functions. Moreover, the expression of an isoform is often specific to tissue, developmental stage or environmental conditions, which is responsible for the diversity and adaptability of cellular activities (<xref rid="btz367-B43" ref-type="bibr">Sulakhe <italic>et al.</italic>, 2018</xref>; <xref rid="btz367-B47" ref-type="bibr">Wang <italic>et al.</italic>, 2008</xref>). Therefore, delineating the functions of isoforms is crucial to the study of functional complexity and diversity of genomes.</p>
    <p>Despite their importance, the specific functions of the vast majority of isoforms are still poorly understood to date. Although many well-established databases exist (<xref rid="btz367-B5" ref-type="bibr">Bairoch <italic>et al.</italic>, 2004</xref>; <xref rid="btz367-B22" ref-type="bibr">Kanehisa <italic>et al.</italic>, 2000</xref>) for gene functional annotation, very few functions have been annotated at the isoform level. Owing to the large number of isoforms, systematic and global analysis of isoform functions experimentally is impractical in a short period. Therefore, efficient computational methods that can provide high-throughput and accurate predictions of isoform functions are in great demand. Given the availability of annotated gene functions, supervised learning has been successfully applied for gene function prediction (<xref rid="btz367-B26" ref-type="bibr">Kulmanov <italic>et al.</italic>, 2017</xref>; <xref rid="btz367-B36" ref-type="bibr">Mostafavi <italic>et al.</italic>, 2008</xref>). In contrast, the lack of isoform-level functional ground truth annotation makes isoform function prediction much more challenging.</p>
    <p>Several methods have been proposed for isoform function prediction recently, including iMILP (<xref rid="btz367-B32" ref-type="bibr">Li <italic>et al.</italic>, 2014b</xref>), mi-SVM (<xref rid="btz367-B16" ref-type="bibr">Eksi <italic>et al.</italic>, 2013</xref>), WLRM (<xref rid="btz367-B34" ref-type="bibr">Luo <italic>et al.</italic>, 2017</xref>) and DeepIsoFun (<xref rid="btz367-B40" ref-type="bibr">Shaw <italic>et al.</italic>, 2018</xref>). The basic idea of these methods is to distribute the functional annotation of a gene to all of its isoforms using techniques such as multiple instance learning (MIL) and domain adaptation. However, these methods suffer from the limitation that they infer isoform functions from the information contained in expression profiles alone. The experimental results suggest that the prediction accuracy of these methods is less than desirable: the best area under the receiver operating characteristics curve (AUC) achieved by these methods is around 0.7 and the best area under the precision–recall curve (AUPRC) is around 0.3 (<xref rid="btz367-B40" ref-type="bibr">Shaw <italic>et al.</italic>, 2018</xref>).</p>
    <p>Different types of biological data may carry complementary information of isoform functions, and hence a systematic integration of such information might lead to a substantial improvement in prediction accuracy (<xref rid="btz367-B33" ref-type="bibr">Li <italic>et al.</italic>, 2016</xref>; <xref rid="btz367-B43" ref-type="bibr">Sulakhe <italic>et al.</italic>, 2018</xref>). In particular, we may divide informative biological data into the following two types. (i) <italic>Data of individual isoforms</italic>: An isoform sequence may contain some functional sites, say active or binding sites, signal peptides and motifs. These sites, although very short, could provide strong signals about the functions of an isoform. Another source of information is (evolutionarily) conserved domains. Compared with functional sites, conserved domains are much longer, and their conservation during the evolutionary process may imply their important biological functions. Both functional sites and conserved domains could be identified from an isoform sequence, and it is well-known that the presence or absence of such sequence features can significantly influence its functions. For example, <xref rid="btz367-B45" ref-type="bibr">Taneri <italic>et al.</italic> (2004)</xref> studied the impact of alternative splicing on transcription factors in mouse and reported that alternative splicing can delete DNA binding domains, generating tissue-specific protein isoforms with distinct functions. (ii) <italic>Data between isoforms</italic>: From the expression profiles of isoforms, we could easily identify the co-expression relationship between isoforms (<xref rid="btz367-B17" ref-type="bibr">Ellis <italic>et al.</italic>, 2012</xref>). This co-expression relationship has been used to predict isoform functions in the aforementioned methods as co-expressed isoforms tend to share similar biological functions. These two types of biological data come in different forms: the functional sites and conserved domains can be represented as strings while the co-expression relationship is usually represented as a network. How to integrate such different forms of data in isoform function prediction remains as a challenge.</p>
    <p>In this paper, we present a novel approach, named DIFFUSE (Deep learning-based prediction of IsoForm FUnctions from Sequences and Expression), that integrates both isoform sequences and expression profiles to predict isoform functions. Our approach goes through two stages to integrate various information into a unified predictive model. In the first stage, a deep neural network (DNN) is designed to capture features from isoform sequences and conserved domains. Taking the sequence and conserved domains of an isoform as the input, the DNN computes an initial score that measures how likely the isoform has the function under consideration. In the second stage, a conditional random field (CRF) is designed to exploit the co-expression relationship between isoforms. By combining the initial scores computed by the DNN with the co-expression relationship, the CRF assigns isoforms functional labels based on the initial scores while trying to keep highly co-expressed isoforms attaining the same labels. To overcome the lack of isoform-level training labels, we propose an iterative semi-supervised training algorithm based on the MIL framework similar to the one in (<xref rid="btz367-B3" ref-type="bibr">Andrews <italic>et al.</italic>, 2002</xref>). Specifically, our approach first initializes all isoforms of genes that have the function under consideration with positive labels and the other isoforms with negative labels. The initial functional labels are then used to train the model parameters. The new parameters of the model are next used to update the label of each isoform from positive genes. In each iteration, these two steps are performed alternately. Note that the isoforms of the same gene may be assigned different labels an update, which would encourage the model to capture features that can differentiate the functions of different isoforms.</p>
    <p>To evaluate the performance of DIFFUSE, we first measure its prediction accuracy using the gene-level functional annotation in Gene Ontology (GO) as done in <xref rid="btz367-B32" ref-type="bibr">Li <italic>et al.</italic> (2014b)</xref>, <xref rid="btz367-B16" ref-type="bibr">Eksi <italic>et al.</italic> (2013</xref>), <xref rid="btz367-B34" ref-type="bibr">Luo <italic>et al.</italic> (2017</xref>) and <xref rid="btz367-B40" ref-type="bibr">Shaw <italic>et al.</italic> (2018)</xref>. DIFFUSE achieves an average AUC of 0.840 and AUPRC of 0.581 over 4184 functional categories. We also compare DIFFUSE with the existing methods on several datasets. Four state-of-the-art isoform function prediction methods proposed in <xref rid="btz367-B32" ref-type="bibr">Li <italic>et al.</italic> (2014b)</xref>, <xref rid="btz367-B16" ref-type="bibr">Eksi <italic>et al.</italic> (2013</xref>), <xref rid="btz367-B34" ref-type="bibr">Luo <italic>et al.</italic> (2017</xref>) and <xref rid="btz367-B40" ref-type="bibr">Shaw <italic>et al.</italic> (2018)</xref> are included in the comparison. The results demonstrate that our method significantly outperforms the others. We further analyze the divergence of the predicted functions of isoforms from the same gene. The scarcity of experimentally verified isoform functions makes the validation of predicted functions difficult. We thus conduct a series of computational experiments to indirectly validate our predictions. More specifically, we first analyze how functional similarity is correlated with isoform sequence, expression and structural similarities. Our analysis shows that the similarity of predicted functions has higher correlation with isoform structural similarity than with sequence similarity or expression similarity, which accords previous studies (<xref rid="btz367-B21" ref-type="bibr">Illergård <italic>et al.</italic>, 2009</xref>). The predictions are then further validated by assessing their consistency with the presence or absence of some well-studied functional sequence features followed by a targeted literature search.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>Isoform sequences of the human genome are downloaded from the NCBI Reference Sequences database (RefSeq GRCh38.p12; <xref rid="btz367-B38" ref-type="bibr">Pruitt <italic>et al.</italic>, 2012</xref>). To ensure sequence quality, only manually curated RefSeq records are recruited in our computational experiments. The ‘Coding DNA Sequence’ (CDS) is extracted for each isoform using the RefSeq CDS annotation file. Two or more isoforms corresponding to the same CDS are treated as a single isoform. For each isoform, we search it against the NCBI Conserved Domain Database (Marchler-Bauer <italic>et al.</italic>, 2015) to acquire its conserved domains.</p>
      <p>Isoform expression profile data are obtained from the literature (<xref rid="btz367-B40" ref-type="bibr">Shaw <italic>et al.</italic>, 2018</xref>). It consists of human isoform RNA-seq data from the NCBI Reference Sequence Archive (SRA) (<xref rid="btz367-B30" ref-type="bibr">Leinonen <italic>et al.</italic>, 2011</xref>) consisting of 334 studies and 1735 experiments. Only isoforms that appear in both the sequence data and the expression data are kept. This results in a total of 39 375 isoforms from 19 303 genes consisting of 9032 multiple isoform genes (MIGs) and 10 271 single isoform genes (SIGs).</p>
      <p>We adopt the functional categories defined by GO, and download gene functional annotation from the UniProt Gene Ontology Annotation database (<xref rid="btz367-B20" ref-type="bibr">Huntley <italic>et al.</italic>, 2015</xref>). To ensure the annotation quality, we only keep manually curated GO terms and skip terms with the ‘IEA’ evidence code. Similar to (<xref rid="btz367-B32" ref-type="bibr">Li <italic>et al.</italic>, 2014b;</xref><xref rid="btz367-B40" ref-type="bibr">Shaw <italic>et al.</italic>, 2018</xref>), we also ignore GO terms that are too specific or general. Finally, 4184 GO terms associated with the numbers of genes in the range of 10–1000 are considered in this study.</p>
    </sec>
    <sec>
      <title>2.2 Methods</title>
      <sec>
        <label>2.2.1</label>
        <title>Overview</title>
        <p>As mentioned before, DIFFUSE predicts isoform functions by integrating the information of isoform sequences, conserved domains and expression profiles into a unified predictive model. More specifically, we train a model for each GO term. The inference procedure of the model consists of two stages. In the first stage, taking the sequence and conserved domains of an isoform as the input, the DNN computes an initial score in the range of [0, 1] measuring how likely the isoform has the GO term. In the second stage, the CRF makes a final prediction by considering both the initial scores and the co-expression relationship among isoforms. To overcome the lack of annotated isoform functions, we develop a semi-supervised algorithm following (<xref rid="btz367-B3" ref-type="bibr">Andrews <italic>et al.</italic>, 2002</xref>) to train both the DNN and CRF together iteratively. To help training the DNN, protein sequences from the SwissProt (<xref rid="btz367-B7" ref-type="bibr">Boutet <italic>et al.</italic>, 2016</xref>) database are also used as training data. To avoid potential information leak between the training and test data, we consider clusters of orthologous groups (COGs) and make sure that each COG is never split between the training and test data. A schematic illustration of DIFFUSE as well as the analyses to be performed in our study is given in <xref ref-type="fig" rid="btz367-F1">Figure 1</xref>, and more details of the method are discussed below.
</p>
        <fig id="btz367-F1" orientation="portrait" position="float">
          <label>Fig. 1.</label>
          <caption>
            <p>Overview of our computational pipeline. (<bold>a</bold>) Alternative splicing generates multiple isoforms from a gene with different sequences and expression profiles. (<bold>b</bold>) The DIFFUSE model contains two key components, a DNN and a CRF. The DNN consists of several layers and components including a CNN and an LSTM. Its input consists of trigrams generated from a CDS or protein sequence and conserved domains. It computes an initial score indicating how likely the output label is positive. The CRF can be represented as a complete graph <italic>G</italic> over variables <italic>y</italic>, which denote the labels of isoforms. Each unary clique or pairwise clique in <italic>G</italic> induces a unary potential or a pairwise potential denoted as <italic>ψ<sub>u</sub></italic> or <italic>ψ<sub>p</sub></italic>. The CRF makes predictions by minimizing a Gibbs energy composed of <italic>ψ<sub>u</sub></italic><sub>’</sub>s and <italic>ψ<sub>p</sub></italic><sub>’</sub>s. The initial scores are factored into <italic>ψ<sub>u</sub></italic><sub>’</sub>s while the co-expression relationship is factored into <italic>ψ<sub>p</sub></italic><sub>’</sub>s. The DNN and CRF are trained together using an iterative semi-supervised learning algorithm based on MIL, where the positive likelihood of each isoform is initialized with its initial score and then updated iteratively through the mean field approximation. (<bold>c</bold>) Several analyses are conducted in our study to support or validate our predicted isoform functions</p>
          </caption>
          <graphic xlink:href="btz367f1"/>
        </fig>
      </sec>
      <sec>
        <label>2.2.2</label>
        <title>Exploring sequence features using a DNN</title>
        <p>DNNs are known to be effective in capturing biological sequence features (<xref rid="btz367-B26" ref-type="bibr">Kulmanov <italic>et al.</italic>, 2017</xref>; <xref rid="btz367-B50" ref-type="bibr">Zhang <italic>et al.</italic>, 2017</xref>). Here, we design a DNN consisting of two components (<xref ref-type="fig" rid="btz367-F1">Fig. 1b</xref>) to capture informative features from isoform sequences and conserved domains, respectively. We use a convolutional neural network (CNN) to extract sequence features. Specifically, we first translate each isoform CDS to an amino acid sequence. Then, each sequence is represented as a series of overlapping trigrams, denoted as <italic>s</italic> = (<inline-formula id="IE1"><mml:math id="IM1"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>). Each trigram is embedded as a continuous vector by the dense embedding layer [denoted as embed(<inline-formula id="IE2"><mml:math id="IM2"><mml:mo>·</mml:mo></mml:math></inline-formula>)] (<xref rid="btz367-B6" ref-type="bibr">Bengio <italic>et al.</italic>, 2003</xref>). Note that the vector representations are optimized during the training process and thus are able to capture similarities between the trigrams. We then employ a 1D convolutional layer with multiple convolution filters [denoted as conv(<inline-formula id="IE3"><mml:math id="IM3"><mml:mo>·</mml:mo></mml:math></inline-formula>)] to scan the encoded sequence and detect the functional sites. After that, pooling [denoted as pool(<inline-formula id="IE4"><mml:math id="IM4"><mml:mo>·</mml:mo></mml:math></inline-formula>)] and dense [denoted as dense(<inline-formula id="IE5"><mml:math id="IM5"><mml:mo>·</mml:mo></mml:math></inline-formula>)] layers are used to reduce the dimensionality of the hidden features.</p>
        <p>A big challenge here is that the lengths of isoform sequences vary a lot. Due to the fixed size of pooling window and stride, the output size of a normal pooling layer depends on the length of the input sequence, which makes connecting the pooling layer to the following dense layer impossible. To address this problem, we adopt a ‘pyramid pooling’ layer in our model, which is widely used in computer vision (<xref rid="btz367-B18" ref-type="bibr">He <italic>et al.</italic>, 2014</xref>). We modify it, however, as a 1D pooling layer. The pyramid pooling layer can generate a fixed-length output regardless of the input sequence length. Specifically, it uses multi-level pooling bins. Pooling bins at different levels have sizes proportional to the sequence length with different ratios. The number of bins at each level is fixed. High level pooling bins capture global features while low level bins capture local features.</p>
        <p>Conserved domains are the building blocks of proteins. Their duplication, fusion and recombination during evolution produce proteins with novel structures and functions. In addition, the order of domains is also conserved during evolution (<xref rid="btz367-B27" ref-type="bibr">Kummerfeld <italic>et al.</italic>, 2009</xref>). Rearrangement of domains can influence functions of a protein. We use a recurrent neural network to capture domain features. Domain order information is considered in the network structure design. Specifically, we order the conserved domains of an isoform as a sequence, denoted as <italic>d</italic> = (<inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>), where each domain is represented by a unique ID. Then, we use the same dense embedding technique to embed each ID into a vector representation. To capture the order information of domains, we apply the recurrent layer with long short-term memory (LSTM) units [denoted as LSTM(<inline-formula id="IE7"><mml:math id="IM7"><mml:mo>·</mml:mo></mml:math></inline-formula>)] to process the encoded domain sequence. The output of the last LSTM unit is used as the feature vector from the domain component.</p>
        <p>Feature vectors from both the sequence and domain components are then concatenated to form a unified feature representation. Finally, the unified representation is fed into a logistic regression layer [denoted as logit(<inline-formula id="IE8"><mml:math id="IM8"><mml:mo>·</mml:mo></mml:math></inline-formula>)] to compute the initial score as follows. Formally, given isoform sequence <italic>s</italic> and sequence of domains <italic>d</italic>, the initial score computed as follows:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"/><mml:mtd columnalign="left"><mml:mrow><mml:mtext>InitialScore</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>logit</mml:mtext><mml:mo> </mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>dense</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"/><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>dense</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>pool</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>conv</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>embed</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"/><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>LSTM</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>embed</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec>
        <label>2.2.3</label>
        <title>Exploring co-expression relationship using a CRF</title>
        <p>The function of an isoform is sometimes determined by its interacting partners that are often co-expressed. To capture the co-expression relationship among isoforms, we design a CRF in the second stage (<xref ref-type="fig" rid="btz367-F1">Fig. 1b</xref>). Co-expression networks are first derived from the RNA-seq data. Specifically, we construct a co-expression network for each SRA study using the WGCNA algorithm (<xref rid="btz367-B29" ref-type="bibr">Langfelder <italic>et al.</italic>, 2008</xref>), which has been widely used in the studies of weighted correlation network analysis. To ensure the network quality, we only consider SRA studies with at least 10 experiments. This results in a total of 42 networks. For each pair of isoforms, the absolute value of the Pearson correlation coefficient (PCC) between their expression profiles is assigned as the corresponding edge weight using the soft threshold method of WGCNA.</p>
        <p>We denote the sequence, domains and expression profile of an isoform <italic>i</italic> as <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE10"><mml:math id="IM10"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE11"><mml:math id="IM11"><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and use a binary scalar <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> to denote its label, indicating whether the isoform has the function under consideration or not. The CRF model aims to assign each isoform a label by minimizing a Gibbs energy function, which is defined as:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mo>ψ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mo>ψ</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>The Gibbs energy is characterized by both the initial scores from the DNN and the co-expression relationship between isoforms. The unary potential <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:msub><mml:mrow><mml:mo>ψ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> comes from the initial scores, which is defined as <inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:msub><mml:mrow><mml:mo>ψ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mtext>InitialScore</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE15"><mml:math id="IM15"><mml:mrow><mml:msub><mml:mrow><mml:mo>ψ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>ψ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. The co-expression relationship is considered in the pairwise potential, which is defined as:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mrow><mml:msub><mml:mrow><mml:mo>ψ</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>μ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>l</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE16"><mml:math id="IM16"><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the edge weight between isoform <italic>i</italic> and isoform <italic>j</italic> in the <italic>l</italic>th co-expression network and <inline-formula id="IE17"><mml:math id="IM17"><mml:mrow><mml:mo>μ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a label compatibility function defined as <inline-formula id="IE18"><mml:math id="IM18"><mml:mrow><mml:mo>μ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> that is used to penalize highly co-expressed isoforms with differently assigned labels. The weights <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub> control the relative importance of the unary potential <italic>ψ<sub>u</sub></italic> and pairwise potential <italic>ψ<sub>p</sub></italic> in the Gibbs energy, and discussed in the following section.</p>
        <p>By finding a label assignment <inline-formula id="IE19"><mml:math id="IM19"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> that minimizes the Gibbs energy <inline-formula id="IE20"><mml:math id="IM20"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, we aim to assign each isoform an label with low unary energy and, at the same time, ensure that highly co-expressed isoforms get the same label. Because of the computational complexity of exact inference, we apply an efficient approximation algorithm named the mean field approximation similar to (<xref rid="btz367-B25" ref-type="bibr">Krähenbühl <italic>et al.</italic>, 2011</xref>). Here, minimizing the Gibbs energy is formulated as maximizing the following probability:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>Z</mml:mi></mml:mfrac><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE21"><mml:math id="IM21"><mml:mrow><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mo> </mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a normalization constant. Instead of computing the exact distribution <inline-formula id="IE22"><mml:math id="IM22"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, the approximation algorithm computes a distribution <inline-formula id="IE23"><mml:math id="IM23"><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> that minimizes the KL-divergence <inline-formula id="IE24"><mml:math id="IM24"><mml:mrow><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where the distribution <italic>Q</italic> is defined as a product of independent marginals:
<disp-formula id="E5"><label>(5)</label><mml:math id="M5"><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∏</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>Minimizing the KL-divergence yields the following iterative update equation:
<disp-formula id="E6"><label>(6)</label><mml:math id="M6"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mtext>exp</mml:mtext><mml:mo> </mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mrow><mml:mo>ψ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"/><mml:mtd columnalign="left"><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>l</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
        <p><italic>Q<sub>i</sub></italic> is initialized with the unary potential and updated iteratively according to <xref ref-type="disp-formula" rid="E6">Equation (6)</xref> until convergence, which gives the final output of our model.</p>
      </sec>
      <sec>
        <label>2.2.4</label>
        <title>Training the model with the MIL framework</title>
        <p>
          <boxed-text id="btz367-BOX1" position="float" orientation="portrait">
            <label>Algorithm 1:</label>
            <caption>
              <p> Model training</p>
            </caption>
            <p><bold>Initialization:</bold> Initialize the label <inline-formula id="IE25"><mml:math id="IM25"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> of each instance in a positive or negative bag as <inline-formula id="IE26"><mml:math id="IM26"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> or 0, respectively. Initialize DNN parameters <italic>w</italic> and CRF parameters <italic>θ</italic>.</p>
            <p><bold>Parameter update:</bold> Fix instance labels and update model parameters.</p>
            <p>1: Compute <inline-formula id="IE27"><mml:math id="IM27"><mml:mrow><mml:msub><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mi>w</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mtext>DNN</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo>:</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and use SGD to update <italic>w</italic>.</p>
            <p>2: Compute <inline-formula id="IE28"><mml:math id="IM28"><mml:mrow><mml:msub><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mo>θ</mml:mo></mml:msub><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mtext>CRF</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>θ</mml:mo><mml:mo>:</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and use L-BFGS-B to update <italic>θ</italic>.</p>
            <p><bold>Label update:</bold> Fix model parameters and update instance labels.</p>
            <p>3: <bold>for</bold> each instance <italic>i</italic> in positive bags <bold>do</bold></p>
            <p>4:  <inline-formula id="IE29"><mml:math id="IM29"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></p>
            <p>5: <bold>end for</bold></p>
            <p>6: <bold>for</bold> each positive bag <italic>b</italic><bold>do</bold></p>
            <p>7:  <bold>if</bold><inline-formula id="IE30"><mml:math id="IM30"><mml:mrow><mml:mi>max</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, for all instances <italic>i</italic> belonging to bag <italic>b</italic> then</p>
            <p>8:   <inline-formula id="IE31"><mml:math id="IM31"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, for all instances <italic>i</italic> belonging to bag <italic>b</italic></p>
            <p>9:   <inline-formula id="IE32"><mml:math id="IM32"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></p>
            <p>10:  <bold>end if</bold></p>
            <p>11: <bold>end for</bold></p>
          </boxed-text>
        </p>
        <p>Due to the lack of ground truth isoform labels, the conventional supervised training algorithm cannot be directly applied to our model. Hence, we adopt a semi-supervisd model training algorithm under the MIL framework similar to the one in (<xref rid="btz367-B3" ref-type="bibr">Andrews <italic>et al.</italic>, 2002</xref>), which is outlined in Algorithm 1. In the MIL framework, each gene is treated as a bag, the isoforms of a gene are treated as the instances in the bag, and only the ground truth labels of the bags (i.e. genes) are required. A positive bag refers to a gene that has the function under consideration. Clearly, a positive bag should contain at least one positive instance, while a negative bag should contain no positive instances. We first initialize the instances of positive bags with positive labels, and the others with negative labels. Then, the model parameters can be optimized with the initial labels in the normal supervised learning manner. In particular, given the training instances <inline-formula id="IE33"><mml:math id="IM33"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, the loss function in terms of the DNN parameters <italic>w</italic> is defined as the sum of the negative log likelihoods:
<disp-formula id="E7"><label>(7)</label><mml:math id="M7"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mtext>DNN</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo>:</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>InitialScore</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"/><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mtext>InitialScore</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
        <p>Gradients in terms of <italic>w</italic> can be computed and the stochastic gradient descent (SGD) algorithm is used to optimize <italic>w</italic>. Similarly, the CRF parameters <italic>θ</italic> are optimized by minimizing the negative log-likelihood <inline-formula id="IE34"><mml:math id="IM34"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mtext>CRF</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> using the L-BFGS-B algorithm (<xref rid="btz367-B52" ref-type="bibr">Zhu <italic>et al.</italic>, 1997</xref>), which is defined as:
<disp-formula id="E8"><label>(8)</label><mml:math id="M8"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mtext>CRF</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>θ</mml:mo><mml:mo>:</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
        <p>Here, the second term is a regularization term to reduce over-fitting, where <inline-formula id="IE35"><mml:math id="IM35"><mml:mrow><mml:msup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> is a free parameter that determines how much to penalize large weights. L-BFGS-B requires to compute the gradient of <inline-formula id="IE36"><mml:math id="IM36"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mtext>CRF</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> in terms of <italic>θ</italic>. However, the number of terms in <italic>Z</italic> of <inline-formula id="IE37"><mml:math id="IM37"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is exponential in the number of instances, making the gradient computation intractable. We therefore use an approximate gradient algorithm given in <xref rid="btz367-B44" ref-type="bibr">Sutton <italic>et al.</italic> (2012)</xref>, which approximates the true gradient by replacing <italic>P</italic> with the marginals <italic>Q</italic>:
<disp-formula id="E9"><label>(9)</label><mml:math id="M9"><mml:mtable><mml:mtr><mml:mtd><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mtext>CRF</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>θ</mml:mo><mml:mo>:</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>ψ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>ψ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="E10"><label>(10)</label><mml:math id="M10"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"/><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mtext>CRF</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>θ</mml:mo><mml:mo>:</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mo>ψ</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mo>ψ</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
        <p>After updating the parameters of the model, we perform inference for each instance in positive bags using the new model. Instance labels are then updated according to the inference: <inline-formula id="IE38"><mml:math id="IM38"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. For each positive bag, if all its instances are assigned with negative labels, we select the instance with the largest positive prediction score <inline-formula id="IE39"><mml:math id="IM39"><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in the bag as positive. The parameter update step and the label update step are repeated alternately until convergence.</p>
      </sec>
      <sec>
        <label>2.2.5</label>
        <title>Implementation details</title>
        <p>A large number of manually reviewed protein sequences with annotated GO terms are available on the SwissProt (<xref rid="btz367-B7" ref-type="bibr">Boutet <italic>et al.</italic>, 2016</xref>) database. Most proteins in the database represent the canonical isoforms of genes and therefore will not help improve the model’s ability to differentiate the isoform functions of the same gene. However, they are still precious resources that can help our DNN learn important functional features from sequences and domains. We download 89 459 eukaryotic (other than human) protein sequences with GO annotation from the SwissProt database. Conserved domain data are downloaded accordingly using the same method described before. The data are used to train the DNN. Specifically, given the sequence, domains and ground truth label of each protein instance, the initial score and loss of DNN are computed for the instance and then the loss is used to update the DNN parameters.</p>
        <p>We partition our data into the training, validation and test sets with the proportions of 70%, 10% and 20%, respectively. To avoid potential information leak (i.e. isoforms with very similar sequences and similar functions appear in different components of the partition), we split the data according to two criteria. First, we require that isoforms of the same gene are partitioned into the same set. Second, since our data contains proteins from different eukaryotes, we forbid orthologous genes to be split. In other words, we consider COGs (<xref rid="btz367-B46" ref-type="bibr">Tatusov <italic>et al.</italic>, 2000</xref>) and require that all genes of the same COG are partitioned together. COGs (10 308) are downloaded from the EggNOG database (Huerta-Cepas <italic>et al.</italic>, 2016). Note that the SwissProt proteins are only used for training our model and are not involved in testing. Hyperparameters of the model are manually tuned based on the model performance on the validation data. The validation data are then merged with the training data to train a final model for each GO term before we assess its performance in terms of AUC and AUPRC.</p>
        <p>In our computational experiments, the Adam optimizer (<xref rid="btz367-B23" ref-type="bibr">Kingma <italic>et al.</italic>, 2014</xref>) is used to optimize the DNN. The sizes of the embedding vectors for both amino acid trigrams and domain unique IDs are 32. We use 64 convolution filters with length 32 and stride 1. The pyramid pooling layer consists of pooling bins from four levels, with 1, 2, 4 and 8 bins at each level, respectively. To prevent over-fitting the model, the dropout (<xref rid="btz367-B42" ref-type="bibr">Srivastava <italic>et al.</italic>, 2014</xref>) technique is adopted. The DNN model is implemented using the Keras library with TensorFlow (<xref rid="btz367-B1" ref-type="bibr">Abadi <italic>et al.</italic>, 2016</xref>) as the backend. The SciPy package is used for implementing the L-BFGS-B algorithm. To accelerate the training process, NVIDIA K80 GPUs are used.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Results and validation</title>
    <p>In this section, we first evaluate the performance of DIFFUSE and the effectiveness of each component of the model. We then study the divergence of isoform functions predicted by our method from the same gene. To validate our predictions, we analyze the correlation between functional similarity, sequence similarity, expression similarity as well as structural similarity. The predicted functions are further validated by assessing their consistency with some well-studied functional sequence features. Finally, a targeted literature search is performed to directly confirm some of the isoform functions considered above.</p>
    <sec>
      <title>3.1 Prediction of isoform functions</title>
      <sec>
        <label>3.1.1</label>
        <title>Prediction performance of DIFFUSE</title>
        <p>Since annotated isoform functions are generally unavailable, following the evaluation procedure used in previous isoform function prediction studies (<xref rid="btz367-B16" ref-type="bibr">Eksi <italic>et al.</italic>, 2013</xref>; <xref rid="btz367-B32" ref-type="bibr">Li <italic>et al.</italic>, 2014b;</xref><xref rid="btz367-B34" ref-type="bibr">Luo <italic>et al.</italic>, 2017</xref>; <xref rid="btz367-B40" ref-type="bibr">Shaw <italic>et al.</italic>, 2018</xref>), we first evaluate the performance of our method using gene-level functional annotation. For each GO term, the maximum prediction score among the isoforms of a gene is taken to check its consistency with the gene annotation. To investigate how the prediction performance may be influenced by GO branches and the number of positive genes, we divide all the GO terms into 12 groups based on GO branch and term size, which is defined as the number of genes associated with a GO term. Specifically, we first divide GO terms into three groups based on the three main GO branches [i.e. Biological Process (BP), Molecular Function (MF) and Cellular Component (CC)]. Then, the terms of each group are divided into four subgroups with term sizes in the ranges of [10, 20], [21, 50], [51, 100] and [101, 1000], respectively. Both AUC and AUPRC are used to evaluate the performance for each GO term. Since the baseline for AUPRC (ratio of positive genes in the test set) is different for different GO terms, to make comparison across different groups more fair, we unify the AUPRC baseline as 0.1 for all terms by duplicating positive genes in the test set. Out of the 4184 GO terms, 3037 are in the BP group, 432 in CC and 715 in MF.</p>
        <p>The (numerical, also called macro) average AUC value for BP, CC and MF is 0.829, 0.850 and 0.881, and the average AUPRC values are 0.563, 0.586 and 0.656, respectively. The distributions of AUC and AUPRC values in different groups are shown in <xref ref-type="fig" rid="btz367-F2">Figure 2</xref>. Interestingly, we observe that more positive genes do not yield higher performance. The groups with the largest term sizes (i.e. range [101, 1000]) in fact have relatively low AUC and AUPRC values compared with the other groups. This phenomenon has been observed in several previous studies as well (<xref rid="btz367-B32" ref-type="bibr">Li <italic>et al.</italic>, 2014b</xref>; <xref rid="btz367-B40" ref-type="bibr">Shaw <italic>et al.</italic>, 2018</xref>). A possible explanation is that as the term size increases, the biological features (i.e. sequences and expression) of isoforms associated with a GO term become more heterogeneous and the correlation between the functional similarity and the similarities of the biological features decreases, as discussed in <xref rid="btz367-B40" ref-type="bibr">Shaw <italic>et al.</italic> (2018)</xref>.
</p>
        <fig id="btz367-F2" orientation="portrait" position="float">
          <label>Fig. 2.</label>
          <caption>
            <p>Performance evaluation in terms of AUC and AUPRC. GO terms are divided into groups based on the three main GO branches and term sizes. (<bold>a</bold>) Distributions of AUC scores over GO terms in different groups. (<bold>b</bold>) Distributions of AUPRC scores</p>
          </caption>
          <graphic xlink:href="btz367f2"/>
        </fig>
      </sec>
      <sec>
        <label>3.1.2</label>
        <title>Performance comparison with the existing methods</title>
        <p>We compare DIFFUSE with four state-of-the-art isoform function prediction methods including mi-SVM (<xref rid="btz367-B16" ref-type="bibr">Eksi <italic>et al.</italic>, 2013</xref>), iMILP (<xref rid="btz367-B32" ref-type="bibr">Li <italic>et al.</italic>, 2014b</xref>), WLRM (<xref rid="btz367-B34" ref-type="bibr">Luo <italic>et al.</italic>, 2017</xref>), and DeepIsoFun (<xref rid="btz367-B40" ref-type="bibr">Shaw <italic>et al.</italic>, 2018</xref>). The comparison focuses on a small set of GO terms, GO Slim (<xref rid="btz367-B11" ref-type="bibr">Consortium, 2004</xref>), which provides a broad overview of the ontology content. 96 GO terms are kept after the term size filtration aforementioned. To make a comprehensive comparison, besides the dataset analyzed above (called Dataset#1), we include two other datasets from the literature (<xref rid="btz367-B16" ref-type="bibr">Eksi <italic>et al.</italic>, 2013</xref>; <xref rid="btz367-B32" ref-type="bibr">Li <italic>et al.</italic>, 2014b</xref>). In particular, Dataset#2 contains RNA-seq data for 29 806 human isoforms of 18 923 genes, which were generated from 29 SRA human studies consisting of 455 experiments. Dataset#3 contains RNA-seq data for 16 191 mouse isoforms of 13 692 genes, which were generated from 116 SRA studies consisting of 365 experiments. The corresponding sequence, domain and annotation data are collected by following the same procedure described in Section 2. The average AUC and AUPRC values are reported in <xref rid="btz367-T1" ref-type="table">Table 1</xref>. Note that iMILP performs a three-class classification rather than two-class. While all other methods treat genes without a GO annotation as negatives of this GO term, iMILP selects negative genes according a more stringent criterion and treats the others as unknowns. Here, we assess the AUC and AUPRC of iMILP based only on the positive genes and selected negative genes, which might incur some favorable bias for the method. Nonetheless, significant improvements by our method have been observed. DIFFUSE achieves improvements of 14.5%, 14.7% and 14.7% in terms of AUC and 84.5%, 83.9% and 81.9% in terms of AUPRC over the best performance of the other methods on the three datasets, respectively. Some example receiver operating characteristic curves and precision–recall curves on two GO terms achieved by the methods are illustrated in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S3a–d</xref>. The performance of DIFFUSE on the training data is given in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref> to show that the model is not grossly overtrained.</p>
        <table-wrap id="btz367-T1" orientation="portrait" position="float">
          <label>Table 1.</label>
          <caption>
            <p>Comparison between DIFFUSE and other isoform function prediction methods</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="2" colspan="1">Method</th>
                <th colspan="2" rowspan="1">Dataset#1<hr/></th>
                <th colspan="2" rowspan="1">Dataset#2<hr/></th>
                <th colspan="2" rowspan="1">Dataset#3<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1">AUC</th>
                <th rowspan="1" colspan="1">AUPRC</th>
                <th rowspan="1" colspan="1">AUC</th>
                <th rowspan="1" colspan="1">AUPRC</th>
                <th rowspan="1" colspan="1">AUC</th>
                <th rowspan="1" colspan="1">AUPRC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">DIFFUSE</td>
                <td rowspan="1" colspan="1">
                  <bold>0.835</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.585</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.828</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.537</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.817</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.524</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">DeepIsoFun</td>
                <td rowspan="1" colspan="1">0.729</td>
                <td rowspan="1" colspan="1">0.280</td>
                <td rowspan="1" colspan="1">0.722</td>
                <td rowspan="1" colspan="1">0.257</td>
                <td rowspan="1" colspan="1">0.712</td>
                <td rowspan="1" colspan="1">0.231</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">WLRM</td>
                <td rowspan="1" colspan="1">0.685</td>
                <td rowspan="1" colspan="1">0.265</td>
                <td rowspan="1" colspan="1">0.667</td>
                <td rowspan="1" colspan="1">0.237</td>
                <td rowspan="1" colspan="1">0.672</td>
                <td rowspan="1" colspan="1">0.201</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">mi-SVM</td>
                <td rowspan="1" colspan="1">0.668</td>
                <td rowspan="1" colspan="1">0.248</td>
                <td rowspan="1" colspan="1">0.671</td>
                <td rowspan="1" colspan="1">0.221</td>
                <td rowspan="1" colspan="1">0.706</td>
                <td rowspan="1" colspan="1">0.235</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">iMILP<xref ref-type="table-fn" rid="tblfn1"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">0.678</td>
                <td rowspan="1" colspan="1">0.317</td>
                <td rowspan="1" colspan="1">0.662</td>
                <td rowspan="1" colspan="1">0.292</td>
                <td rowspan="1" colspan="1">0.639</td>
                <td rowspan="1" colspan="1">0.288</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <label>a</label>
              <p>Since iMILP classifies an isoform into three classes rather than two classes for a given GO term (i.e. positive, negative or unknown), we measure its AUC and AUPRC values using only the positive and negative classes. The best performance values are highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <label>3.1.3</label>
        <title>Analyzing the effects of model components</title>
        <p>To evaluate the contribution of some key components and biological features used in our model, we perform an ablation study by removing these components/features from model and measuring how the performance of the model is affected. Specifically, we remove the CRF component, conserved domain features and sequence features from DIFFUSE, respectively, and test its performance on GO Slim. We observe that the average AUC drops 1.7% (from 0.835 to 0.821) and the average AUPRC drops 7.5% (from 0.585 to 0.541) without the CRF. The average AUC drops 3.7% (from 0.835 to 0.804) and the average AUPRC drops 21.2% (from 0.585 to 0.461) without using conserved domains. The average AUC drops 4.6% (from 0.835 to 0.797) and the average AUPRC drops 27.9% (from 0.585 to 0.422) without using sequences (<xref ref-type="fig" rid="btz367-F3">Fig. 3a</xref>). The results suggest that the CRF component is very effective in capturing the co-expression relationship and conserved domains contain important functional information (as known before), and both contribute significantly to the performance of DIFFUSE. Moreover, although conserved domains are extracted from sequences, they cannot completely replace sequences. Some example receiver operating characteristic curves and precision–recall curves on two GO terms achieved by the above four variants of DIFFUSE are illustrated in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S3e–h</xref>.
</p>
        <fig id="btz367-F3" orientation="portrait" position="float">
          <label>Fig. 3.</label>
          <caption>
            <p>(<bold>a</bold>) The average AUC and AUPRC values over the terms in GO Slim for DIFFUSE (blue), DIFFUSE without CRF (green), DIFFUSE without using conserved domains (pink) and DIFFUSE without using sequences (yellow). (<bold>b</bold>) Average importance scores for conserved domain regions and non-conserved domain regions are calculated for each isoform-GO term pair. There is a clearly a significant difference between these two regions as supported by the one-sided Wilcoxon test (****<italic>P</italic> &lt; 0.0001)</p>
          </caption>
          <graphic xlink:href="btz367f3"/>
        </fig>
      </sec>
      <sec>
        <label>3.1.4</label>
        <title>Importance of local sequence features in function prediction</title>
        <p>Deep learning models are usually considered as ‘black boxes’. In the bioinformatics domain, however, understanding the rationales behind decisions made by a model is very important to the potential users of the model. Here, we use the saliency map (<xref rid="btz367-B41" ref-type="bibr">Simonyan <italic>et al.</italic>, 2013</xref>), a deep learning visualization technique, to help us understand what parts of an isoform sequence are most influential in the classification decision. Briefly, a saliency map calculates the derivative of the output of the DNN with respect to the variable at each input position, so we can see the influence of each position of the input sequence on the output score. We denote the value of derivative at each position as its ‘importance score’. The Keras-vis tool (<xref rid="btz367-B24" ref-type="bibr">Kotikalapudi <italic>et al.</italic>, 2017</xref>) is used to calculate the saliency map and the method in <xref rid="btz367-B28" ref-type="bibr">Lanchantin <italic>et al.</italic> (2017)</xref> is used to obtain the importance score of each amino acid residue of the input sequence. Since conserved domains are known to be rich in functional sites, residues inside conserved domains are expected to have higher importance scores on average.</p>
        <p>To test this hypothesis, for each isoform-GO pair, we compute a saliency map and calculate the importance score for each amino acid residue of the isoform. For each saliency map, we calculate the average importance score of all amino acid residues inside conserved domains and that of all amino acid residues outside conserved domains, respectively. As expected, we observe significantly higher average importance scores in conserved domains (<xref ref-type="fig" rid="btz367-F3">Fig. 3b</xref>).</p>
      </sec>
      <sec>
        <label>3.1.5</label>
        <title>Analyzing the divergence of isoform functions</title>
        <p>Delineating the specific functions of the isoforms is the ultimate goal of isoform function prediction. Hence, it would be useful to analyze the divergence of the predicted functions of the isoforms from each gene, as done in <xref rid="btz367-B32" ref-type="bibr">Li <italic>et al.</italic> (2014b)</xref> and <xref rid="btz367-B40" ref-type="bibr">Shaw <italic>et al.</italic> (2018)</xref>. We estimate the similarity of predicted functions for each pair of isoforms in terms of the semantic similarity score using GOssTo (<xref rid="btz367-B9" ref-type="bibr">Caniza <italic>et al.</italic>, 2014</xref>), again considering the three GO branches separately. The semantic dissimilarity score of two isoforms is then defined as one minus their similarity score. For each MIG, the functional divergence of its isoforms is calculated by averaging the semantic dissimilarity scores of all pairs of its isoforms sharing predicted functions in the same GO branch. Out of the 9032 MIGs, 8924 (5444 or 5521) MIGs have at least two isoforms assigned GO terms in the BP (CC or MF, respectively) branch by DIFFUSE. Among these MIGs, 90.3% (8060 out of 8924), 81.1% (4415 out of 5444) and 76.5% (4222 out of 5521) are estimated to have functional divergent isoforms (i.e. semantic dissimilarity scores greater than 0) with respect to BP, CC and MF, respectively. The dissimilarity score distributions for MIGs that have functional divergent isoforms are shown in <xref ref-type="fig" rid="btz367-F4">Figure 4</xref>, where the mean score values are 0.490, 0.482 and 0.411 for BP, CC and MF, respectively. A similar pattern of distributions was observed in a previous study (<xref rid="btz367-B32" ref-type="bibr">Li <italic>et al.</italic>, 2014b</xref>).
</p>
        <fig id="btz367-F4" orientation="portrait" position="float">
          <label>Fig. 4.</label>
          <caption>
            <p>Distributions of semantic dissimilarity scores of MIGs that have functionally divergent isoforms. The range of semantic dissimilarity score [0, 1] is equally divided into 20 bins. For each bin, we count how many MIGs have semantic dissimilarity scores in this range. The three GO branches are considered separately</p>
          </caption>
          <graphic xlink:href="btz367f4"/>
        </fig>
        <p>As discussed above, functional divergence among isoforms of the same gene is expected. It remains unclear, however, to what extent isoforms have divergent functions. Therefore, we further investigate the functional divergence of isoforms by testing its consistency with the (protein) structural divergence of isoforms. In other words, for a gene with isoforms that share similar functions (i.e. low semantic dissimilarity score), the protein structures of these isoforms are expected to be similar, and vice versa. The protein structure of an isoform can be represented as a contact map, which is a 2D matrix of distance between all possible amino acid residue pairs and can be used to estimate protein structural similarities. Contact maps are predicted using the RaptorX (<xref rid="btz367-B37" ref-type="bibr">Peng <italic>et al.</italic>, 2011</xref>) server. Due to the computational intensity of contact map prediction, we predict contact maps for isoforms of 300 randomly selected MIGs with at most 500 amino acids. For each GO branch separately, we divide the genes into two groups by the median semantic dissimilarity score, resulting in a high functional similarity group and a low functional similarity group. For each gene, we calculate the average structural similarity score over all its isoform pairs, measured by the Contact Map Overlap using the software AI-Eigen (<xref rid="btz367-B15" ref-type="bibr">Di Lena <italic>et al.</italic>, 2010</xref>). As anticipated, we observe significantly higher structural similarities between isoforms of MIGs in the high functional similarity groups for all three GO branches (<xref ref-type="fig" rid="btz367-F5">Fig. 5</xref>).
</p>
        <fig id="btz367-F5" orientation="portrait" position="float">
          <label>Fig. 5.</label>
          <caption>
            <p>Average structural similarity between isoforms of MIGs with low or high functional similarities. Significant differences are observed in all the GO branches according to the Kruskal–Wallis tests (with <italic>P</italic>-values ***<italic>P </italic>=<italic> </italic>5.77e-04, **<italic>P </italic>=<italic> </italic>2.50e-03 and **<italic>P </italic>=<italic> </italic>3.30e-03 for BP, CC and MF, respectively). Note that the semantic dissimilarity score can only be calculated for MIGs containing two or more isoforms with GO terms in the same branch. This results in 296 (167 or 155) out of the 300 MIGs considered for the BP (CC or MF) branch</p>
          </caption>
          <graphic xlink:href="btz367f5"/>
        </fig>
      </sec>
    </sec>
    <sec>
      <title>3.2 Validation of predicted isoform functions</title>
      <p>The scarcity of experimentally verified functions of isoforms raises a great a challenge to the validation of our predicted isoform functions. To address this challenge, we first indirectly validate the predicted functions by analyzing how they are correlated with isoform sequences, expression as well as protein structures. The predictions are further validated by evaluating their consistency with some well-studied UniProt sequence features related to functions. Finally, we directly validate a small set of predicted isoform functions analyzed above by a targeted literature search.</p>
      <sec>
        <label>3.2.1</label>
        <title>Correlations between functional, sequence and expression similarities</title>
        <p>Our method is based on the assumption that isoforms with similar sequences and/or expression profiles should have similar functions. To check that our predicted functions indeed have this property, we test whether similar biological features indeed lead to similar predictions and vice versa, as done in <xref rid="btz367-B40" ref-type="bibr">Shaw <italic>et al.</italic> (2018)</xref>. (Hence, this is more of a sanity check on our computational model than a proper validation of our predicted isoform functions.) We group the 39 375 isoforms into 2492 clusters with sizes in the range of [10, 20] based on hierarchical clustering, where the bit score of BLAST (<xref rid="btz367-B2" ref-type="bibr">Altschul <italic>et al.</italic>, 1997</xref>) is used to measure the pairwise distance of isoforms. Then the average functional similarity, sequence similarity and expression similarity are estimated over all isoform pairs within each cluster. Different from the last subsection, here the functional similarity between isoforms is measured by the negative value of the Euclidean distance between their predicted functions (as two vectors). The expression similarity is measured by the PCC of two expression profiles and the sequence similarity is measured by the pairwise global alignment score of two isoform protein sequences normalized by the alignment length. Each similarity is normalized to the range of [0, 1]. Then, the PCC is used to measure the pairwise correlations between functional similarity, sequence similarity and expression similarity, as shown in <xref ref-type="fig" rid="btz367-F6">Figure 6</xref>. Clearly, isoforms with similar sequences or expression profiles tend to have similar predicted functions. Interestingly, functional similarity seems to be more correlated with sequence similarity than with expression similarity and only a moderate correlation is found between sequence similarity and expression similarity, which explains why these two biological features can be combined to improve function prediction. To further verify these isoform-level correlations, we perform the same computational experiment at the gene level where the gene functional annotation, the longest isoform sequence of each gene and gene expression profiles are used to estimate the above three similarities. Very similar PCC values are obtained as shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S1</xref>.
</p>
        <fig id="btz367-F6" orientation="portrait" position="float">
          <label>Fig. 6.</label>
          <caption>
            <p>Correlations between functional similarity, sequence similarity and expression similarity. The isoforms are grouped into 2492 clusters by hierarchical clustering. The average pairwise functional similarity, sequence similarity and expression similarity are estimated for the isoforms in each cluster. The PCC is used to measure the strength of correlation</p>
          </caption>
          <graphic xlink:href="btz367f6"/>
        </fig>
      </sec>
      <sec>
        <label>3.2.2</label>
        <title>Correlation between functional and structural similarities</title>
        <p>Previous studies (<xref rid="btz367-B21" ref-type="bibr">Illergård <italic>et al.</italic>, 2009</xref>) have shown that protein structures are more conserved than sequences. Hence, isoforms with similar functions are expected to have more similar structures than sequences. We further test how the predicted functions are correlated with protein structures represented as contact maps. Again, we download contact maps from the RaptorX server for 1500 isoforms of MIGs. We focus on MIGs rather than SIGs in this test since the functions of their isoforms are currently unknown. The isoforms are grouped into 99 clusters with sizes in the range of [10, 20] and the average functional similarity, sequence similarity and structural similarity are measured for each cluster using the same methods described above. As expected, a higher PCC is found between functional similarity and structural similarity (<xref ref-type="fig" rid="btz367-F7">Fig. 7</xref>). Furthermore, we perform the same computational experiment on 600 random SIGs using their annotated functions and obtain a consistent PCC between functional similarity and structural similarity (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S2</xref>). These analyzes indirectly support our prediction results.
</p>
        <fig id="btz367-F7" orientation="portrait" position="float">
          <label>Fig. 7.</label>
          <caption>
            <p>1500 isoforms of MIGs are grouped into 99 clusters. The average pairwise functional similarity, sequence similarity and structural similarity are estimated for each cluster. (a) The correlation between functional similarity and structural similarity. (b) The correlation between functional similarity and sequence similarity</p>
          </caption>
          <graphic xlink:href="btz367f7"/>
        </fig>
      </sec>
      <sec>
        <label>3.2.3</label>
        <title>Consistency with well-studied UniProt sequence features</title>
        <p>A recent review (<xref rid="btz367-B43" ref-type="bibr">Sulakhe <italic>et al.</italic>, 2018</xref>) reported a set of function-related sequence features (as defined by UniProt; <xref rid="btz367-B8" ref-type="bibr">Breuza <italic>et al.</italic>, 2016</xref>) associated with a list of isoforms. The presence or absence of these functional sequence features can be used to infer potential isoform functions. Three of the functional sequence features can be mapped to GO terms, which are ‘Metal ion binding site’ (to GO: 0046872), ‘ATP binding site’ (to GO: 0005524) and ‘Nuclear localization signal’ (to GO: 0005634). We then map the list of isoforms reported in this review to our isoform dataset. For each GO term, we check the consistency between the presence or absence of the corresponding sequence feature in associated isoforms and the functional predictions concerning this GO term. To quantify the consistency for the three GO terms separately, the Jaccard indices are calculated as in the literature (<xref rid="btz367-B49" ref-type="bibr">Yang <italic>et al.</italic>, 2016</xref>). The same computational experiment is repeated for the three other methods as well to compare. The Jaccard indices of DIFFUSE are 0.674, 0.700 and 0.700 for GO: 0046872, GO: 0005524 and GO: 0005634, respectively, which are significantly higher than those of DeepIsofun (0.548, 0.595 and 0.579), WLRM (0.514, 0.578 and 0.580), mi-SVM (0.534, 0.517 and 0.569) and iMILP (0.560, 0.581 and 0.521). The detailed results concerning the three GO terms are shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Tables S2–S4</xref>.</p>
      </sec>
      <sec>
        <label>3.2.4</label>
        <title>Validation via the literature</title>
        <p>We further perform an exhaustive literature search for experimentally verified functions of the isoforms analyzed above (i.e. appearing in <xref ref-type="supplementary-material" rid="sup1">Supplementary Tables S2–S4</xref>). Functions or strong functional evidence for 14 isoforms of 6 genes have been found. Out of the 14 isoforms, our method predicted correct functions for 11 of them (<xref rid="btz367-T2" ref-type="table">Table 2</xref>), which is significantly more accurate than the other methods. It is worth mentioning that 13 of the 14 functions reported in the literature are consistent with the presence or absence of their corresponding UniProt sequence features. This suggests that the UniProt sequence features may serve as a good benchmark to validate predicted isoform functions.</p>
        <table-wrap id="btz367-T2" orientation="portrait" position="float">
          <label>Table 2.</label>
          <caption>
            <p>Literature support for 14 isoforms of 6 genes on two GO terms</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="2" colspan="1">GO term</th>
                <th rowspan="2" align="left" colspan="1">Gene</th>
                <th rowspan="2" align="left" colspan="1">Isoform</th>
                <th rowspan="2" align="left" colspan="1">Literature evidence</th>
                <th colspan="5" align="left" rowspan="1">Prediction method<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1">DIFFUSE</th>
                <th rowspan="1" colspan="1">DeepIsoFun</th>
                <th rowspan="1" colspan="1">WLRM</th>
                <th rowspan="1" colspan="1">mi-SVM</th>
                <th rowspan="1" colspan="1">iMILP</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="7" colspan="1">GO: 0046872</td>
                <td rowspan="2" colspan="1">ACE</td>
                <td rowspan="1" colspan="1">P12821-1</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">P12821-3</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
              </tr>
              <tr>
                <td rowspan="2" colspan="1">ACMSD</td>
                <td rowspan="1" colspan="1">Q8TDX5-1</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Q8TDX5-2</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
              </tr>
              <tr>
                <td rowspan="3" colspan="1">GCH1</td>
                <td rowspan="1" colspan="1">P30793-1</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">∘</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">P30793-2</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">×</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">P30793-4</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
              </tr>
              <tr>
                <td rowspan="7" colspan="1">GO: 0005634</td>
                <td rowspan="2" colspan="1">ADK</td>
                <td rowspan="1" colspan="1">P55263-1</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">×</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">P55263-2</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
              </tr>
              <tr>
                <td rowspan="3" colspan="1">AIFM1</td>
                <td rowspan="1" colspan="1">O95831-1</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">O95831-3</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">×</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">O95831-4</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">×</td>
              </tr>
              <tr>
                <td rowspan="2" colspan="1">PPP1R8</td>
                <td rowspan="1" colspan="1">Q12972-1</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">∘</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Q12972-3</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">∘</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">×</td>
                <td rowspan="1" colspan="1">∘</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Accuracy</td>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">
                  <bold>78.6%</bold>
                </td>
                <td rowspan="1" colspan="1">71.4%</td>
                <td rowspan="1" colspan="1">50.0%</td>
                <td rowspan="1" colspan="1">64.3%</td>
                <td rowspan="1" colspan="1">64.3%</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn2">
              <p><italic>Note</italic>: Positive and negative results are represented as circles and crosses in the table. Experimental evidence concerning relevant functions have been found for six genes in the literature: ACE (<xref rid="btz367-B12" ref-type="bibr">Corradi <italic>et al.</italic>, 2006</xref>), ACMSD (<xref rid="btz367-B39" ref-type="bibr">Pucci <italic>et al.</italic>, 2007</xref>), GCH1 (<xref rid="btz367-B4" ref-type="bibr">Auerbach <italic>et al.</italic>, 2000</xref>), ADK (<xref rid="btz367-B13" ref-type="bibr">Cui <italic>et al.</italic>, 2009</xref>), AIFM1 (<xref rid="btz367-B14" ref-type="bibr">Delettre <italic>et al.</italic>, 2006</xref>) and PPP1R8 (<xref rid="btz367-B10" ref-type="bibr">Chang <italic>et al.</italic>, 1999</xref>). The best performance value is highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>As discussed in recent reviews (<xref rid="btz367-B33" ref-type="bibr">Li <italic>et al.</italic>, 2016</xref>; <xref rid="btz367-B43" ref-type="bibr">Sulakhe <italic>et al.</italic>, 2018</xref>), the integration of various types of biological information is needed to improve isoform function prediction. In this paper, we proposed a deep learning-based method, called DIFFUSE, that integrates sequence, conserved domain and expression information into a unified predictive model. DIFFUSE greatly outperformed the existing methods in our comprehensive computational experiments. However, the performance of DIFFUSE could be further improved in several aspects. First, the co-expression networks derived from RNA-seq data are specific to different tissues and conditions, which may be correlated with specific GO terms. <xref rid="btz367-B32" ref-type="bibr">Li <italic>et al.</italic> (2014b)</xref> used a search algorithm to identify the best performing subset of co-expression networks for each GO term. However, the algorithm is time-consuming. We believe that an efficient algorithm that can search for a good combination of co-expression networks specific to each GO terms could be designed and integrated into our method. Moreover, in the model training procedure, we decoupled the DNN and CRF training stages, assuming that the DNN parameters were fixed when optimizing the CRF parameters. A recent work (<xref rid="btz367-B51" ref-type="bibr">Zheng <italic>et al.</italic>, 2015</xref>) demonstrated the advantage of formulating the CRF as a layer in the DNN to enable end-to-end training with the usual back-propagation algorithm. This could further improve the performance of our model.</p>
    <p>As demonstrated in our paper (also a well-known fact), isoform functions are more correlated with protein structures than anything else. Hence, it is natural to consider incorporating protein structures in isoform function prediction (<xref rid="btz367-B31" ref-type="bibr">Li <italic>et al.</italic>, 2014a</xref>). However, large-scale determination of 3D protein structures for isoforms accurately is computationally prohibitive. Nonetheless, contact maps have been used to represent protein structures approximately and they are easier to compute (<xref rid="btz367-B48" ref-type="bibr">Wang <italic>et al.</italic>, 2017</xref>). We have used them in the validation of our predictions in this work and plan to explore how to incorporate them into our model in the future.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported in part by the National Science Foundation [IIS-1646333], the National Natural Science Foundation of China [61772197, 31671369, 31770775, 61872216, 61472205 and 81630103] and the National Key Research and Development Program of China [2018YFC0910404 and 2018YFC0910405].</p>
    <p><italic>Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btz367_Supplementary_Data</label>
      <media xlink:href="btz367_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btz367-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Abadi</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>TensorFlow: a system for large-scale machine learning</article-title>. In <source>OSDI</source>, Vol. <volume>16</volume>, pp. <fpage>265</fpage>–<lpage>283</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Altschul</surname><given-names>S.F.</given-names></name></person-group><etal>et al</etal> (<year>1997</year>) 
<article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>. <source>Nucleic Acids Res</source>., <volume>25</volume>, <fpage>3389</fpage>–<lpage>3402</lpage>.<pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Andrews</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2002</year>) Multiple instance learning with generalized support vector machines. In <italic>AAAI/IAAI</italic>, pp. <fpage>943</fpage>–<lpage>944</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Auerbach</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (<year>2000</year>) 
<article-title>Zinc plays a key role in human and bacterial GTP cyclohydrolase I</article-title>. <source>Proc. Natl. Acad. Sci</source>., <volume>97</volume>, <fpage>13567</fpage>–<lpage>13572</lpage>.<pub-id pub-id-type="pmid">11087827</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bairoch</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) 
<article-title>The universal protein resource (UniProt)</article-title>. <source>Nucleic Acids Res</source>., <volume>33</volume>, <fpage>D154</fpage>–<lpage>159</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bengio</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2003</year>) 
<article-title>A neural probabilistic language model</article-title>. <source>J. Mach. Learn. Res</source>., <volume>3</volume>, <fpage>1137</fpage>–<lpage>1155</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B7">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Boutet</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) <chapter-title>UniProtKB/Swiss-Prot, the manually annotated section of the UniProt KnowledgeBase: how to use the entry view</chapter-title> In <source>Plant Bioinformatics</source>, 
<publisher-name>Springer</publisher-name>, pp. <fpage>23</fpage>–<lpage>54</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Breuza</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>The UniProtKB guide to the human proteome</article-title>. <source>Database</source>, <volume>2016</volume>, <fpage>bav120</fpage>.<pub-id pub-id-type="pmid">26896845</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Caniza</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>GOssTo: a stand-alone application and a web tool for calculating semantic similarities on the Gene Ontology</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>2235</fpage>–<lpage>2236</lpage>.<pub-id pub-id-type="pmid">24659104</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chang</surname><given-names>A.C.</given-names></name></person-group><etal>et al</etal> (<year>1999</year>) 
<article-title>Alternative splicing regulates the production of ARD-1 endoribonuclease and NIPP-1, an inhibitor of protein phosphatase-1, as isoforms encoded by the same gene</article-title>. <source>Gene</source>, <volume>240</volume>, <fpage>45</fpage>–<lpage>55</lpage>.<pub-id pub-id-type="pmid">10564811</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Consortium</surname><given-names>G.O.</given-names></name></person-group> (<year>2004</year>) 
<article-title>The Gene Ontology (GO) database and informatics resource</article-title>. <source>Nucleic Acids Res</source>., <volume>32</volume>, <fpage>D258</fpage>–<lpage>261</lpage>.<pub-id pub-id-type="pmid">14681407</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Corradi</surname><given-names>H.R.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>Crystal structure of the N domain of human somatic angiotensin I-converting enzyme provides a structural basis for domain-specific inhibitor design</article-title>. <source>J. Mol. Biol</source>., <volume>357</volume>, <fpage>964</fpage>–<lpage>974</lpage>.<pub-id pub-id-type="pmid">16476442</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cui</surname><given-names>X.A.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Subcellular localization of adenosine kinase in mammalian cells: the long isoform of AdK is localized in the nucleus</article-title>. <source>Biochem. Biophys. Res. Commun</source>., <volume>388</volume>, <fpage>46</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">19635462</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Delettre</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>Identification and characterization of AIFsh2, a mitochondrial apoptosis-inducing factor (AIF) isoform with NADH oxidase activity</article-title>. <source>J. Biol. Chem</source>., <volume>281</volume>, <fpage>18507</fpage>–<lpage>18518</lpage>.<pub-id pub-id-type="pmid">16644725</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Di Lena</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Fast overlapping of protein contact maps by alignment of eigenvectors</article-title>. <source>Bioinformatics</source>, <volume>26</volume>, <fpage>2250</fpage>–<lpage>2258</lpage>.<pub-id pub-id-type="pmid">20610612</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Eksi</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Systematically differentiating functions for alternatively spliced isoforms through integrating RNA-seq data</article-title>. <source>PLoS Comput. Biol</source>., <volume>9</volume>, <fpage>e1003314.</fpage><pub-id pub-id-type="pmid">24244129</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ellis</surname><given-names>J.D.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Tissue-specific alternative splicing remodels protein–protein interaction networks</article-title>. <source>Mol. Cell</source>, <volume>46</volume>, <fpage>884</fpage>–<lpage>892</lpage>.<pub-id pub-id-type="pmid">22749401</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B18">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>He</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) <chapter-title>Spatial pyramid pooling in deep convolutional networks for visual recognition</chapter-title> In: <source>European Conference on Computer Vision</source>, 
<publisher-name>Springer</publisher-name>, pp. <fpage>346</fpage>–<lpage>361</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huerta-Cepas</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>eggNOG 4.5: a hierarchical orthology framework with improved functional annotations for eukaryotic, prokaryotic and viral sequences</article-title>. <source>Nucleic Acids Res</source>., <volume>44</volume>, <fpage>D286</fpage>–<lpage>293</lpage>.<pub-id pub-id-type="pmid">26582926</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huntley</surname><given-names>R.P.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>The GOA database: Gene Ontology annotation updates for 2015</article-title>. <source>Nucleic Acids Res</source>., <volume>43</volume>, <fpage>D1057</fpage>–<lpage>1063</lpage>.<pub-id pub-id-type="pmid">25378336</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Illergård</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Structure is three to ten times more conserved than sequence—a study of structural response in protein cores</article-title>. <source>Proteins</source>, <volume>77</volume>, <fpage>499</fpage>–<lpage>508</lpage>.<pub-id pub-id-type="pmid">19507241</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kanehisa</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2000</year>) 
<article-title>KEGG: kyoto encyclopedia of genes and genomes</article-title>. <source>Nucleic Acids Res</source>., <volume>28</volume>, <fpage>27</fpage>–<lpage>30</lpage>.<pub-id pub-id-type="pmid">10592173</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B23">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Kingma</surname><given-names>D.P.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) Adam: A method for stochastic optimization. <italic>arXiv preprint</italic> arXiv:1412.6980.</mixed-citation>
    </ref>
    <ref id="btz367-B24">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Kotikalapudi</surname></name></person-group>,<etal>et al</etal> (<year>2017</year>) Keras-vis. <ext-link ext-link-type="uri" xlink:href="https://github.com/raghakot/keras-vis">https://github.com/raghakot/keras-vis</ext-link>. GitHub.</mixed-citation>
    </ref>
    <ref id="btz367-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Krähenbühl</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) Efficient inference in fully connected crfs with gaussian edge potentials. In <italic>Advances in Neural Information Processing Systems</italic>, pp. <fpage>109</fpage>–<lpage>117</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kulmanov</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>DeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>660</fpage>–<lpage>668</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kummerfeld</surname><given-names>S.K.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Protein domain organisation: adding order</article-title>. <source>BMC Bioinform</source>., <volume>10</volume>, <fpage>39.</fpage></mixed-citation>
    </ref>
    <ref id="btz367-B28">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Lanchantin</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) <chapter-title>Deep motif dashboard: visualizing and understanding genomic sequences using deep neural networks</chapter-title> In <source>Pacific Symposium on Biocomputing 2017</source>, 
<publisher-name>World Scientific</publisher-name>, pp. <fpage>254</fpage>–<lpage>265</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Langfelder</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>WGCNA: an R package for weighted correlation network analysis</article-title>. <source>BMC Bioinform</source>., <volume>9</volume>, <fpage>559.</fpage></mixed-citation>
    </ref>
    <ref id="btz367-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Leinonen</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>The sequence read archive</article-title>. <source>Nucleic Acids Res</source>., <volume>39</volume>, <fpage>D19</fpage>–<lpage>21</lpage>.<pub-id pub-id-type="pmid">21062823</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>H.D.</given-names></name></person-group><etal>et al</etal> (<year>2014a</year>) 
<article-title>The emerging era of genomic data integration for analyzing splice isoform function</article-title>. <source>Trends Genet</source>., <volume>30</volume>, <fpage>340</fpage>–<lpage>347</lpage>.<pub-id pub-id-type="pmid">24951248</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>W.</given-names></name></person-group><etal>et al</etal> (<year>2014b</year>) 
<article-title>High-resolution functional annotation of human transcriptome: predicting isoform functions by a novel multiple instance-based label propagation method</article-title>. <source>Nucleic Acids Res</source>., <volume>42</volume>, <fpage>e39</fpage>.<pub-id pub-id-type="pmid">24369432</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>H.D.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>A proteogenomic approach to understand splice isoform functions through sequence and expression-based computational modeling</article-title>. <source>Briefings Bioinform</source>., <volume>17</volume>, <fpage>1024</fpage>–<lpage>1031</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B34">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Luo</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) <chapter-title>Functional annotation of human protein coding isoforms via non-convex multi-instance learning</chapter-title> In <source>Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</source>, 
<publisher-name>ACM</publisher-name>, pp. <fpage>345</fpage>–<lpage>354</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Marchler-Bauer</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>CDD: NCBI’s conserved domain database</article-title>. <source>Nucleic Acids Res</source>., <volume>43</volume>, <fpage>D222</fpage>–<lpage>226</lpage>.<pub-id pub-id-type="pmid">25414356</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mostafavi</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>GeneMANIA: a real-time multiple association network integration algorithm for predicting gene function</article-title>. <source>Genome Biol</source>., <volume>9</volume>, <fpage>S4.</fpage></mixed-citation>
    </ref>
    <ref id="btz367-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Peng</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>RaptorX: exploiting structure information for protein alignment by statistical inference</article-title>. <source>Proteins</source>, <volume>79</volume>, <fpage>161</fpage>–<lpage>171</lpage>.<pub-id pub-id-type="pmid">21987485</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pruitt</surname><given-names>K.D.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>NCBI Reference Sequences (RefSeq): current status, new features and genome annotation policy</article-title>. <source>Nucleic Acids Res</source>., <volume>40</volume>, <fpage>D130</fpage>–<lpage>135</lpage>.<pub-id pub-id-type="pmid">22121212</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pucci</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Tissue expression and biochemical characterization of human 2-amino 3-carboxymuconate 6-semialdehyde decarboxylase, a key enzyme in tryptophan catabolism</article-title>. <source>FEBS J</source>., <volume>274</volume>, <fpage>827</fpage>–<lpage>840</lpage>.<pub-id pub-id-type="pmid">17288562</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B40">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Shaw</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) DeepIsoFun: a deep domain adaptation approach to predict isoform functions. <italic>Bioinformatics</italic>, bty1017.</mixed-citation>
    </ref>
    <ref id="btz367-B41">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Simonyan</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) Deep inside convolutional networks: Visualising image classification models and saliency maps. <italic>arXiv preprint</italic> arXiv:1312.6034.</mixed-citation>
    </ref>
    <ref id="btz367-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Srivastava</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>. <source>J. Mach. Learn. Res</source>., <volume>15</volume>, <fpage>1929</fpage>–<lpage>1958</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sulakhe</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Exploring the functional impact of alternative splicing on human protein isoforms using available annotation sources</article-title>. <source>Brief. Bioinform</source>., <fpage>bby047</fpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sutton</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>An introduction to conditional random fields</article-title>. <source>Found. Trends Mach. Learn</source>., <volume>4</volume>, <fpage>267</fpage>–<lpage>373</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Taneri</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) 
<article-title>Alternative splicing of mouse transcription factors affects their DNA-binding domain architecture and is tissue specific</article-title>. <source>Genome Biol</source>., <volume>5</volume>, <fpage>R75.</fpage><pub-id pub-id-type="pmid">15461794</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tatusov</surname><given-names>R.L.</given-names></name></person-group><etal>et al</etal> (<year>2000</year>) 
<article-title>The COG database: a tool for genome-scale analysis of protein functions and evolution</article-title>. <source>Nucleic Acids Res</source>., <volume>28</volume>, <fpage>33</fpage>–<lpage>36</lpage>.<pub-id pub-id-type="pmid">10592175</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>E.T.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>Alternative isoform regulation in human tissue transcriptomes</article-title>. <source>Nature</source>, <volume>456</volume>, <fpage>470.</fpage><pub-id pub-id-type="pmid">18978772</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Accurate de novo prediction of protein contact map by ultra-deep learning model</article-title>. <source>PLoS Comput. Biol</source>., <volume>13</volume>, <fpage>e1005324.</fpage><pub-id pub-id-type="pmid">28056090</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yang</surname><given-names>E.W.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>SDEAP: a splice graph based differential transcript expression analysis tool for population data</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>3593</fpage>–<lpage>3602</lpage>.<pub-id pub-id-type="pmid">27522083</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>TITER: predicting translation initiation sites by deep learning</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>i234</fpage>–<lpage>242</lpage>.<pub-id pub-id-type="pmid">28881981</pub-id></mixed-citation>
    </ref>
    <ref id="btz367-B51">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zheng</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) Conditional random fields as recurrent neural networks. In: <italic>Proceedings of the IEEE International Conference on Computer Vision</italic>, pp. <fpage>1529</fpage>–<lpage>1537</lpage>.</mixed-citation>
    </ref>
    <ref id="btz367-B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhu</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>1997</year>) 
<article-title>Algorithm 778: L-BFGS-B: Fortran subroutines for large-scale bound-constrained optimization</article-title>. <source>ACM Trans. Math. Softw</source>., <volume>23</volume>, <fpage>550</fpage>–<lpage>560</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
