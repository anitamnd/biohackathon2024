<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8097680</article-id>
    <article-id pub-id-type="pmid">32805018</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa734</article-id>
    <article-id pub-id-type="publisher-id">btaa734</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Notes</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Gene Expression</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MCPeSe: Monte Carlo penalty selection for graphical lasso</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-9074-7420</contrib-id>
        <name>
          <surname>Kuismin</surname>
          <given-names>Markku</given-names>
        </name>
        <aff><institution>Research Unit of Mathematical Sciences, University of Oulu</institution>, Oulu FI-90014, <country country="FI">Finland</country></aff>
        <aff><institution>Biocenter Oulu, University of Oulu</institution>, Oulu FI-90014, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-2808-2768</contrib-id>
        <name>
          <surname>Sillanpää</surname>
          <given-names>Mikko J</given-names>
        </name>
        <xref rid="btaa734-cor1" ref-type="corresp"/>
        <aff><institution>Research Unit of Mathematical Sciences, University of Oulu</institution>, Oulu FI-90014, <country country="FI">Finland</country></aff>
        <aff><institution>Biocenter Oulu, University of Oulu</institution>, Oulu FI-90014, <country country="FI">Finland</country></aff>
        <aff><institution>Infotech Oulu, University of Oulu</institution>, Oulu FI-90014, <country country="FI">Finland</country></aff>
        <!--mikko.sillanpaa@oulu.fi-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Luigi Martelli</surname>
          <given-names>Pier</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btaa734-cor1">To whom correspondence should be addressed. <email>mikko.sillanpaa@oulu.fi</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-08-17">
      <day>17</day>
      <month>8</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>17</day>
      <month>8</month>
      <year>2020</year>
    </pub-date>
    <volume>37</volume>
    <issue>5</issue>
    <fpage>726</fpage>
    <lpage>727</lpage>
    <history>
      <date date-type="received">
        <day>17</day>
        <month>1</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>13</day>
        <month>7</month>
        <year>2020</year>
      </date>
      <date date-type="editorial-decision">
        <day>11</day>
        <month>8</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>12</day>
        <month>8</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa734.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Graphical lasso (Glasso) is a widely used tool for identifying gene regulatory networks in systems biology. However, its computational efficiency depends on the choice of regularization parameter (tuning parameter), and selecting this parameter can be highly time consuming. Although fully Bayesian implementations of Glasso alleviate this problem somewhat by specifying <italic toggle="yes">a priori</italic> distribution for the parameter, these approaches lack the scalability of their frequentist counterparts.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Here, we present a new Monte Carlo Penalty Selection method (MCPeSe), a computationally efficient approach to regularization parameter selection for Glasso. MCPeSe combines the scalability and low computational cost of the frequentist Glasso with the ability to automatically choose the regularization by Bayesian Glasso modeling. MCPeSe provides a state-of-the-art ‘tuning-free’ model selection criterion for Glasso and allows exploration of the posterior probability distribution of the tuning parameter.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>R source code of MCPeSe, a step by step example showing how to apply MCPeSe and a collection of scripts used to prepare the material in this article are publicly available at GitHub under GPL (<ext-link xlink:href="https://github.com/markkukuismin/MCPeSe/" ext-link-type="uri">https://github.com/markkukuismin/MCPeSe/</ext-link>).</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Biocenter Oulu funding</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Technology Industries of Finland Centennial Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100006136</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Jane and Aatos Erkko Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100004012</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Academy of Finland Profi 5</institution>
          </institution-wrap>
        </funding-source>
        <award-id>326291</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="2"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>The graphical lasso (Glasso) (<xref rid="btaa734-B1" ref-type="bibr">Banerjee <italic toggle="yes">et al.</italic>, 2008</xref>; <xref rid="btaa734-B4" ref-type="bibr">Friedman <italic toggle="yes">et al.</italic>, 2008</xref>) is one of the most popular tools for Gaussian graphical model (GGM) selection: the papers of <xref rid="btaa734-B4" ref-type="bibr">Friedman <italic toggle="yes">et al.</italic> (2008)</xref> and <xref rid="btaa734-B1" ref-type="bibr">Banerjee <italic toggle="yes">et al.</italic> (2008)</xref> describing its use have been cited over 1821 and 544 times, respectively (Web of Science database, May 22, 2020). This is due to the following beneficial properties of <italic toggle="yes">L</italic><sub>1</sub> regularization: (i) the optimization of Glasso is a convex problem and thus has a reasonable computational cost, (ii) the estimates of the precision and covariance matrices obtained using Glasso are positive definite even though the corresponding maximum likelihood estimate is not and (iii) some of the off-diagonal elements in the precision matrix are suppressed exactly to zero, making it possible to use Glasso for GGM selection. Consequently, Glasso is a popular alternative to computationally intensive <italic toggle="yes">L</italic><sub>0</sub> regularization for penalized likelihood estimation.</p>
    <p>However, the estimate computed with Glasso depends on the so-called tuning parameter (regularization parameter), which controls the sparsity of the selected GGM. Choosing this parameter is a challenging task. Some model selection criteria have been developed for selecting the Glasso tuning parameter. For example, <xref rid="btaa734-B7" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2010)</xref> introduced a stability approach to regularization selection (StARS) in Glasso models. StARS is based on subsampling of the data and selects the parameter such that it maximizes the stability of the undirected graph calculated based on these subsamples. Although this stability-based approach (see also <xref rid="btaa734-B10" ref-type="bibr">Meinshausen and Bühlmann, 2010</xref>) is a general method for regularization parameter selection (cases involving continuous and discrete data), computing GGMs for each subsample is time consuming when the number of variables <italic toggle="yes">P</italic> is on the order of thousands. The extended Bayesian information criterion (eBIC) (<xref rid="btaa734-B3" ref-type="bibr">Chen and Chen, 2008</xref>) is a more time-efficient method for regularization selection but it depends on a hyperparameter that controls the sparsity of the GGM and must be set manually. The Rotation Information Criterion (RIC) (<xref rid="btaa734-B8" ref-type="bibr">Lysen, 2009</xref>; <xref rid="btaa734-B13" ref-type="bibr">Zhao <italic toggle="yes">et al.</italic>, 2012</xref>) is an efficient tuning parameter selection method that scales to large datasets. Whereas StARS and eBIC depend on an extra tuning parameter, RIC can be considered a tuning-free method. For model selection in cases involving mixed data (i.e. a combination of continuous and discrete variables), see <xref rid="btaa734-B6" ref-type="bibr">Lee and Hastie (2015)</xref> and <xref rid="btaa734-B11" ref-type="bibr">Sedgewick <italic toggle="yes">et al.</italic> (2016)</xref>.</p>
    <p>Alternative Bayesian implementations of Glasso have also been proposed (<xref rid="btaa734-B5" ref-type="bibr">Khondker <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btaa734-B9" ref-type="bibr">Marlin and Murphy, 2009</xref>; <xref rid="btaa734-B12" ref-type="bibr">Wang, 2012</xref>), but these do not scale to very high-dimensional problems (e.g. over 10k genes). Here, we focus on the Glasso model for continuous data.</p>
    <p>To enable efficient tuning-free selection, we introduce a Monte Carlo penalty selection method (MCPeSe). This method uses the whole solution path computed with the frequentist Glasso to time-efficiently simulate the posterior distribution of the Glasso tuning parameter either using rejection sampling or the Metropolis–Hastings algorithm.</p>
  </sec>
  <sec>
    <title>2 Examples</title>
    <p>We compare MCPeSe to eBIC, RIC and StARS and show that MCPeSe is a highly competitive tuning parameter selection method in terms of both computational time (<xref rid="btaa734-F1" ref-type="fig">Fig. 1</xref>) and graphical structure learning. In addition, in a binary classification test, the GGM determined with MCPeSe performed similarly to those determined with StARS and RIC in terms of sensitivity, precision and Matthews correlation coefficient. Further details can be found in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Note</xref>s.
</p>
    <fig position="float" id="btaa734-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>Computational times for MCPeSe (black solid line), Bayes Glasso (blue dotted line), RIC (purple dot-dashed line colliding with the black solid line) and StARS (red dashed line) as a function of <italic toggle="yes">P</italic>. A grid of 100 tuning parameter values was used for MCPeSe, StARS and RIC. 500k tuning parameter values were sampled with MCPeSe using rejection sampling. For Bayes Glasso, the number of burn-in iterations and length of Markov chain were both set to 100. With RIC, 20 rotations were computed. With StARS, 20 subsamples were drawn</p>
      </caption>
      <graphic xlink:href="btaa734f1" position="float"/>
    </fig>
  </sec>
  <sec>
    <title>3 Implementation</title>
    <p>The provided R implementation of MCPeSe is fully compatible with the widely used <monospace>huge</monospace> R package (<xref rid="btaa734-B13" ref-type="bibr">Zhao <italic toggle="yes">et al.</italic>, 2012</xref>) (cited over 129 times according to the Web of Science database, May 22, 2020). The output of the function <monospace>huge</monospace>() from the <monospace>huge</monospace> package can be used as an input for the function <monospace>mcpese</monospace>().</p>
    <p>The following code fragment shows how to run MCPeSe with <monospace>huge</monospace>:</p>
    <p>
      <disp-quote content-type="extract">
        <p># tuning parameter selection; data are provided as an <italic toggle="yes">n </italic>× <italic toggle="yes">p</italic> matrix</p>
        <p>L = huge(Y, nlambda = 50, method=“glasso”)</p>
        <p>MCPeSeSelect = mcpese(L, n=<bold>nrow</bold>(Y))</p>
        <p><bold>names</bold>(MCPeSeSelect)</p>
        <p>“indx”“rhos”“accept.rate”“opt.rho”“opt.index”“n”</p>
      </disp-quote>
    </p>
    <p>The function <monospace>mcpese</monospace>() returns the vector of indices of the selected tuning parameter values, simulated tuning parameter values, the accept rate, the smallest tuning parameter value greater than or equal to the mean of the estimated posterior distribution, the index of this tuning parameter and the sample size.</p>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>MCPeSe allows many different high-dimensional graphical models to be examined at little computational cost. In addition, the selected GGMs are comparable to those obtained using StARS and RIC. Combining MCPeSe with other network construction tools (see, e.g. <xref rid="btaa734-B2" ref-type="bibr">Basu <italic toggle="yes">et al.</italic>, 2017</xref>) could thus facilitate the analysis of large-scale data.</p>
    <p>For rapid dissemination and utilization of MCPeSe, an R implementation with detailed examples and descriptions of the method is available at GitHub and at <italic toggle="yes">Bioinformatics</italic> online.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btaa734_Supplementary_Data</label>
      <media xlink:href="btaa734_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors thank the Associate Editor, four anonymous referees and Andreas Hauptmann for their valuable comments, which helped us improve the presentation of this article.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by the Biocenter Oulu funding; the Technology Industries of Finland Centennial Foundation &amp; the Jane and Aatos Erkko Foundation and the Academy of Finland Profi 5 funding for mathematics and AI: data insight for high-dimensional dynamics [Project 326291].</p>
      <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa734-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Banerjee</surname>
 <given-names>O.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2008</year>) 
<article-title>Model selection through sparse maximum likelihood estimation for multivariate Gaussian or binary data</article-title>. <source>J. Mach. Learn. Res</source>., <volume>9</volume>, <fpage>485</fpage>–<lpage>516</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa734-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Basu</surname>
 <given-names>S.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2017</year>) 
<article-title>Sparse network modeling and metscape-based visualization methods for the analysis of large-scale metabolomics data</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>1545</fpage>–<lpage>1553</lpage>.<pub-id pub-id-type="pmid">28137712</pub-id></mixed-citation>
    </ref>
    <ref id="btaa734-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname>
 <given-names>J.</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Z.</given-names></string-name></person-group> (<year>2008</year>) 
<article-title>Extended Bayesian information criteria for model selection with large model spaces</article-title>. <source>Biometrika</source>, <volume>95</volume>, <fpage>759</fpage>–<lpage>771</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa734-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friedman</surname>
 <given-names>J.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2008</year>) 
<article-title>Sparse inverse covariance estimation with the graphical lasso</article-title>. <source>Biostatistics</source>, <volume>9</volume>, <fpage>432</fpage>–<lpage>441</lpage>.<pub-id pub-id-type="pmid">18079126</pub-id></mixed-citation>
    </ref>
    <ref id="btaa734-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Khondker</surname>
 <given-names>Z.S.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2013</year>) 
<article-title>The Bayesian covariance lasso</article-title>. <source>Stat. Interface</source>, <volume>6</volume>, <fpage>243</fpage>–<lpage>259</lpage>.<pub-id pub-id-type="pmid">24551316</pub-id></mixed-citation>
    </ref>
    <ref id="btaa734-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname>
 <given-names>J.D.</given-names></string-name>, <string-name><surname>Hastie</surname><given-names>T.J.</given-names></string-name></person-group> (<year>2015</year>) 
<article-title>Learning the structure of mixed graphical models</article-title>. <source>J. Comput. Graph. Stat</source>., <volume>24</volume>, <fpage>230</fpage>–<lpage>253</lpage>.<pub-id pub-id-type="pmid">26085782</pub-id></mixed-citation>
    </ref>
    <ref id="btaa734-B7">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Liu</surname>
 <given-names>H.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2010</year>) <part-title>Stability approach to regularization selection (StARS) for high dimensional graphical models</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Lafferty</surname><given-names>J.D.</given-names></string-name></person-group><etal>et al</etal> (eds.) <source>Advances in Neural Information ProcessingSystems</source> Vol. <volume>23</volume>, 
<publisher-name>Curran Associates, Inc</publisher-name>., 
<publisher-loc>USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btaa734-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lysen</surname>
 <given-names>S.</given-names></string-name></person-group> (<year>2009</year>) Permuted inclusion criterion: a variable selection technique. Publicly Accessible Penn Dissertations. 28. <ext-link xlink:href="https://repository.upenn.edu/edissertations/28" ext-link-type="uri">https://repository.upenn.edu/edissertations/28</ext-link></mixed-citation>
    </ref>
    <ref id="btaa734-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Marlin</surname>
 <given-names>B.M.</given-names></string-name>, <string-name><surname>Murphy</surname><given-names>K.P.</given-names></string-name></person-group> (<year>2009</year>) Sparse Gaussian graphical models with unknown block structure. In <italic toggle="yes">Proceedings of the 26th Annual International Conference on Machine Learning</italic>. Montreal, Quebec, Canada, pp. <fpage>705</fpage>–<lpage>712</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa734-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meinshausen</surname>
 <given-names>N.</given-names></string-name>, <string-name><surname>Bühlmann</surname><given-names>P.</given-names></string-name></person-group> (<year>2010</year>) 
<article-title>Stability selection</article-title>. <source>J. R. Stat. Soc. Ser. B (Stat. Methodol.)</source>, <volume>72</volume>, <fpage>417</fpage>–<lpage>473</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa734-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sedgewick</surname>
 <given-names>A.J.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2016</year>) 
<article-title>Learning mixed graphical models with separate sparsity parameters and stability-based model selection</article-title>. <source>BMC Bioinformatics</source>, <volume>17</volume>, <lpage>S175</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa734-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>
 <given-names>H.</given-names></string-name></person-group> (<year>2012</year>) 
<article-title>Bayesian graphical lasso models and efficient posterior computation</article-title>. <source>Bayesian Anal</source>., <volume>7</volume>, <fpage>867</fpage>–<lpage>886</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa734-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname>
 <given-names>T.</given-names></string-name></person-group>
 <etal>et al</etal> (<year>2012</year>) 
<article-title>The huge package for high-dimensional undirected graph estimation in R</article-title>. <source>J. Mach. Learn. Res</source>., <volume>13</volume>, <fpage>1059</fpage>–<lpage>1062</lpage>.<pub-id pub-id-type="pmid">26834510</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
