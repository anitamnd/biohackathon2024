<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8428609</article-id>
    <article-id pub-id-type="pmid">33508086</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btab042</article-id>
    <article-id pub-id-type="publisher-id">btab042</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Notes</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>HunFlair: an easy-to-use tool for state-of-the-art biomedical named entity recognition</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Weber</surname>
          <given-names>Leon</given-names>
        </name>
        <xref rid="btab042-cor1" ref-type="corresp"/>
        <aff><institution>Computer Science Department, Humboldt-Universität zu Berlin</institution>, Berlin 10099, <country country="DE">Germany</country></aff>
        <aff><institution>Group Mathematical Modelling of Cellular Processes, Max Delbrück Center for Molecular Medicine in the Helmholtz Association</institution>, Berlin 13125, <country country="DE">Germany</country></aff>
        <xref rid="btab042-FM1" ref-type="author-notes"/>
        <!--weberple@informatik.hu-berlin.de-->
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Sänger</surname>
          <given-names>Mario</given-names>
        </name>
        <xref rid="btab042-cor1" ref-type="corresp"/>
        <aff><institution>Computer Science Department, Humboldt-Universität zu Berlin</institution>, Berlin 10099, <country country="DE">Germany</country></aff>
        <xref rid="btab042-FM1" ref-type="author-notes"/>
        <!--saengema@informatik.hu-berlin.de-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Münchmeyer</surname>
          <given-names>Jannes</given-names>
        </name>
        <aff><institution>Computer Science Department, Humboldt-Universität zu Berlin</institution>, Berlin 10099, <country country="DE">Germany</country></aff>
        <aff><institution>Section Seismology, GFZ German Research Centre for Geosciences</institution>, Potsdam 14473, <country country="DE">Germany</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Habibi</surname>
          <given-names>Maryam</given-names>
        </name>
        <aff><institution>Computer Science Department, Humboldt-Universität zu Berlin</institution>, Berlin 10099, <country country="DE">Germany</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Leser</surname>
          <given-names>Ulf</given-names>
        </name>
        <aff><institution>Computer Science Department, Humboldt-Universität zu Berlin</institution>, Berlin 10099, <country country="DE">Germany</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Akbik</surname>
          <given-names>Alan</given-names>
        </name>
        <aff><institution>Computer Science Department, Humboldt-Universität zu Berlin</institution>, Berlin 10099, <country country="DE">Germany</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Wren</surname>
          <given-names>Jonathan</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <fn id="btab042-FM1">
        <p>The authors wish it to be known that, in their opinion, Leon Weber and Mario Sänger should be regarded as Joint First Authors.</p>
      </fn>
      <corresp id="btab042-cor1">To whom correspondence should be addressed. <email>weberple@informatik.hu-berlin.de</email> or <email>saengema@informatik.hu-berlin.de</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>9</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-01-28">
      <day>28</day>
      <month>1</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>28</day>
      <month>1</month>
      <year>2021</year>
    </pub-date>
    <volume>37</volume>
    <issue>17</issue>
    <fpage>2792</fpage>
    <lpage>2794</lpage>
    <history>
      <date date-type="received">
        <day>19</day>
        <month>8</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>13</day>
        <month>1</month>
        <year>2021</year>
      </date>
      <date date-type="editorial-decision">
        <day>18</day>
        <month>1</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>1</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btab042.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Summary</title>
        <p>Named entity recognition (NER) is an important step in biomedical information extraction pipelines. Tools for NER should be easy to use, cover multiple entity types, be highly accurate and be robust toward variations in text genre and style. We present <italic toggle="yes">HunFlair</italic>, a NER tagger fulfilling these requirements. HunFlair is integrated into the widely used NLP framework <italic toggle="yes">Flair</italic>, recognizes five biomedical entity types, reaches or overcomes state-of-the-art performance on a wide set of evaluation corpora, and is trained in a cross-corpus setting to avoid corpus-specific bias. Technically, it uses a character-level language model pretrained on roughly 24 million biomedical abstracts and three million full texts. It outperforms other off-the-shelf biomedical NER tools with an average gain of 7.26 pp over the next best tool in a cross-corpus setting and achieves on-par results with state-of-the-art research prototypes in in-corpus experiments. <italic toggle="yes">HunFlair</italic> can be installed with a single command and is applied with only four lines of code. Furthermore, it is accompanied by harmonized versions of 23 biomedical NER corpora.</p>
      </sec>
      <sec id="s2">
        <title>Availability and implementation</title>
        <p><italic toggle="yes">HunFlair</italic> ist freely available through the <italic toggle="yes">Flair</italic> NLP framework (<ext-link xlink:href="https://github.com/flairNLP/flair" ext-link-type="uri">https://github.com/flairNLP/flair</ext-link>) under an MIT license and is compatible with all major operating systems.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Helmholtz Einstein International Berlin Research School in Data Science (HEIBRiDS)</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>German Research Council</institution>
          </institution-wrap>
        </funding-source>
        <award-id>LE-1428/7-1</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="3"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Recognizing biomedical entities (NER) such as genes, chemicals or diseases in unstructured scientific text is a crucial step of all biomedical information extraction pipelines. The respective tools are typically trained and evaluated on rather small gold standard datasets. However, in any real application they are applied ‘in the wild’, i.e. to a large collection of texts often varying in focus, entity distribution, genre (e.g. patents versus scientific articles) and text type (e.g. abstract versus full text). This mismatch can lead to severely misleading evaluation results. To address this, we recently released the <italic toggle="yes">HUNER</italic> tagger (<xref rid="btab042-B16" ref-type="bibr">Weber et al., 2020</xref>) that was trained jointly on a large collection of biomedical NER datasets, leading to a much better performance on unseen corpora compared to models trained on a single corpus. However, <italic toggle="yes">HUNER</italic> relies on a Docker installation and uses a client-server architecture. These design decisions do not hinder its own installation but make its integration into any of the major NLP frameworks, which is required for the construction of comprehensive information extraction pipelines, cumbersome. Moreover, <italic toggle="yes">HUNER</italic> does not build upon a pretrained language model (LM), although such models were the basis for many recent breakthroughs in NLP research (<xref rid="btab042-B2" ref-type="bibr">Akbik <italic toggle="yes">et al.</italic>, 2019</xref>).</p>
    <p>Here, we present <italic toggle="yes">HunFlair</italic>, a redesigned and retrained version of <italic toggle="yes">HUNER</italic> integrated into the widely used <italic toggle="yes">Flair</italic> NLP framework. <italic toggle="yes">HunFlair</italic> builds upon a pretrained character-level language model. It recognizes five important biomedical entity types with high accuracy, namely <italic toggle="yes">Cell Lines</italic>, <italic toggle="yes">Chemicals</italic>, <italic toggle="yes">Diseases</italic>, <italic toggle="yes">Genes</italic> and <italic toggle="yes">Species</italic>. Through its shipping as a Flair component, it can be easily combined with other IE tools (e.g. text parsing, document classification, hedge detection) or other language models and benefits from the experiences and future developments of the large user and developer base of <italic toggle="yes">Flair</italic>. Through its simple but extensible interface, it is easily accessible also for non-experts. Technically, <italic toggle="yes">HunFlair</italic> combines the insights from <xref rid="btab042-B16" ref-type="bibr">Weber <italic toggle="yes">et al.</italic> (2020)</xref> and <xref rid="btab042-B2" ref-type="bibr">Akbik <italic toggle="yes">et al.</italic> (2019)</xref> by merging character-level LM pretraining and joint training on multiple gold standard corpora, which leads to strong gains over other state-of-the-art off-the-shelf NER tools. For <italic toggle="yes">HunFlair</italic>, we specially trained a character-level in-domain LM on a large corpus of biomedical abstracts and full-texts and make it publicly available to facilitate further research.</p>
    <p>In addition, we integrate 23 biomedical NER corpora into <italic toggle="yes">HunFlair</italic> using a consistent format, which enables researchers and practitioners to rapidly train their own models and experiment with new approaches within <italic toggle="yes">Flair</italic>. Note that these are the same corpora that were already made available through <italic toggle="yes">HUNER</italic>. However, the integration into <italic toggle="yes">Flair</italic> has the additional benefits of more convenient automated downloading and flexible preprocessing. While <italic toggle="yes">HUNER</italic>’s corpora came preprocessed with a particular method, users of <italic toggle="yes">HunFlair</italic> may process the corpora along with their own choices, for instance by using different sentence resp. word segmentation methods.</p>
  </sec>
  <sec>
    <title>2 Hunflair</title>
    <p><italic toggle="yes">HunFlair</italic> was created by implementing the approach behind <italic toggle="yes">HUNER</italic> into the <italic toggle="yes">Flair</italic> NLP framework, along with its improvement by integrating a pretrained language model. <italic toggle="yes">Flair</italic> is an NLP framework designed to allow intuitive training and distribution of sequence labeling, text classification and language models. <italic toggle="yes">Flair</italic> achieves state-of-the-art performance in several NLP research challenges (<xref rid="btab042-B1" ref-type="bibr">Akbik et al., 2018</xref>), allows researchers to ‘mix and match’ various types of character, word and document embeddings and features a base of more than 120 contributors. In addition, more than 500 open-source projects and python libraries rely on Flair (see <ext-link xlink:href="https://github.com/flairNLP/flair" ext-link-type="uri">https://github.com/flairNLP/flair</ext-link>).</p>
    <p><xref rid="btab042-F1" ref-type="fig">Figure 1</xref> shows the architecture of <italic toggle="yes">HunFlair</italic> and illustrates how little coding is required to use it. At the core, it relies on a Flair character-level language model trained on roughly 24 million abstracts of biomedical articles from PubMed and 3 million full texts originating from PMC as well as fastText word embeddings (<xref rid="btab042-B5" ref-type="bibr">Bojanowski et al., 2017</xref>). The inclusion of such pretrained character-level language models in NER models lead to strong improvements in other domains (<xref rid="btab042-B1" ref-type="bibr">Akbik <italic toggle="yes">et al.</italic>, 2018</xref>). Prediction of named entities is performed by a BiLSTM-CRF model (<xref rid="btab042-B7" ref-type="bibr">Huang et al., 2015</xref>). Following the HUNER approach, it consists of distinct models for each entity type which are trained on the union of all training sets of all integrated gold standard NER corpora with this type to achieve a more robust performance across other texts, text genres and biomedical sub-domains. See <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> S1 for details of the training process.</p>
    <fig position="float" id="btab042-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>Overview of the <italic toggle="yes">HunFlair</italic> model and it’s integration into the Flair ecosystem. The model is based on a biomedical Flair character-level language model and word embeddings from fastText. In total, the model was trained on 23 biomedical NER datasets spanning five distinct entity types. Furthermore, the simple installation and application of <italic toggle="yes">HunFlair</italic> as well as it’s integration with other Flair components is shown exemplarily</p>
      </caption>
      <graphic xlink:href="btab042f1" position="float"/>
    </fig>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>We compare the tagging accuracy of <italic toggle="yes">HunFlair</italic> to two types of competitors: Other ‘off-the-shelf’ biomedical NER tools, and other recent research prototypes. Therefore, we classify a tool as off-the-shelf when it (i) comes with pretrained prediction models (ease of use), and (ii) can be locally installed (to allow the application to potentially large and potentially propriatary text collections). In contrast, we classify a tool as research prototype when its application requires a retraining of models or when it is only usable as a web service.</p>
    <p>Our primary comparisons to off-the-shelve tools are based on cross-corpus experiments, because these give insight into the generalization properties of a model across different text types (e.g. full text versus abstract) and scientific subdomains (e.g. human oncology, psychological diseases, biology of plants, etc.). Clearly, this comes at the price of introducing a bias against methods which were designed for specific annotation guidelines that differ from those of an evaluation corpus. Therefore, our comparisons to research prototypes are based on in-corpus experiments which evaluate the architecture of <italic toggle="yes">HunFlair</italic> also in this setting.</p>
    <sec>
      <title>3.1 Comparison to off-the-shelf tools</title>
      <p>We compare the performance of <italic toggle="yes">HunFlair</italic> in a cross-corpus setting to five other state-of-the-art biomedical NER tools using three gold standard corpora: CRAFT (<xref rid="btab042-B3" ref-type="bibr">Bada et al., 2012</xref>), BioNLP13 Cancer Genetics (<xref rid="btab042-B15" ref-type="bibr">Pyysalo et al., 2013</xref>) and PDR (<xref rid="btab042-B8" ref-type="bibr">Kim et al., 2019</xref>). None of these was used in the training of neither <italic toggle="yes">HunFlair</italic> nor any competitor tools and we checked that there are no significant textual overlaps between these corpora and any of <italic toggle="yes">HunFlair’</italic>s trainings corpora. We compare (restricted to the supported entity types) against <italic toggle="yes">SciSpacy</italic> (<xref rid="btab042-B14" ref-type="bibr">Neumann et al., 2019</xref>), <italic toggle="yes">HUNER</italic> (<xref rid="btab042-B16" ref-type="bibr">Weber <italic toggle="yes">et al.</italic>, 2020</xref>), <italic toggle="yes">tmChem</italic> (<xref rid="btab042-B11" ref-type="bibr">Leaman et al., 2015</xref>), <italic toggle="yes">GNormPlus</italic> (<xref rid="btab042-B17" ref-type="bibr">Wei et al., 2015</xref>) and <italic toggle="yes">DNorm</italic> (<xref rid="btab042-B10" ref-type="bibr">Leaman et al., 2013</xref>). As <italic toggle="yes">SciSpacy</italic> comes with several models for each entity type, we report the best performance among all of those models that were not trained on the evaluation corpus. Results can be found in <xref rid="btab042-T1" ref-type="table">Table 1</xref>.</p>
      <table-wrap position="float" id="btab042-T1">
        <label>Table 1.</label>
        <caption>
          <p>F1-scores of several off-the-shelf biomedical NER tools on three unseen corpora</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th colspan="3" rowspan="1">CRAFT<hr/></th>
              <th colspan="4" rowspan="1">BioNLP CG<hr/></th>
              <th rowspan="1" colspan="1">PDR</th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Ch</th>
              <th rowspan="1" colspan="1">G</th>
              <th rowspan="1" colspan="1">S</th>
              <th rowspan="1" colspan="1">Ch</th>
              <th rowspan="1" colspan="1">D</th>
              <th rowspan="1" colspan="1">G</th>
              <th rowspan="1" colspan="1">S</th>
              <th rowspan="1" colspan="1">D</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Misc</td>
              <td rowspan="1" colspan="1">42.88</td>
              <td rowspan="1" colspan="1">64.93</td>
              <td rowspan="1" colspan="1">81.15</td>
              <td rowspan="1" colspan="1">72.15</td>
              <td rowspan="1" colspan="1">55.64</td>
              <td rowspan="1" colspan="1">68.97</td>
              <td rowspan="1" colspan="1">
                <bold>80.53</bold>
              </td>
              <td rowspan="1" colspan="1">80.63</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SciSpacy</td>
              <td rowspan="1" colspan="1">35.73</td>
              <td rowspan="1" colspan="1">47.76</td>
              <td rowspan="1" colspan="1">54.21</td>
              <td rowspan="1" colspan="1">58.43</td>
              <td rowspan="1" colspan="1">56.48</td>
              <td rowspan="1" colspan="1">66.18</td>
              <td rowspan="1" colspan="1">57.11</td>
              <td rowspan="1" colspan="1">75.90</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">HUNER</td>
              <td rowspan="1" colspan="1">42.99</td>
              <td rowspan="1" colspan="1">50.77</td>
              <td rowspan="1" colspan="1">84.45</td>
              <td rowspan="1" colspan="1">67.37</td>
              <td rowspan="1" colspan="1">55.32</td>
              <td rowspan="1" colspan="1">71.22</td>
              <td rowspan="1" colspan="1">67.84</td>
              <td rowspan="1" colspan="1">73.64</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">HunFlair</td>
              <td rowspan="1" colspan="1">
                <bold>59.69</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>72.19</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>85.05</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>81.82</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>65.07</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>87.71</bold>
              </td>
              <td rowspan="1" colspan="1">76.47</td>
              <td rowspan="1" colspan="1">
                <bold>83.44</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic toggle="yes">Note</italic>: We distinguish entity types Chemical (Ch), Disease (D), Gene (G) and Species (S). The best results are in bold. Misc displays the results of multiple taggers: <italic toggle="yes">tmChem</italic> for Chemical, <italic toggle="yes">GNormPlus</italic> for Gene and Species and <italic toggle="yes">DNorm</italic> for Disease. Note, this cross-corpus evaluation setup aims to assess the robustness of the tools regarding varying entity type definitions. However, it can introduce a bias against tools designed for a particular annotation guideline such as those listed under <italic toggle="yes">Misc</italic>.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p><italic toggle="yes">HunFlair</italic> outperforms all competitors in all but one comparison, with an average gain of 7.26 pp in F1. Note that this evaluation uses mention-level F1 scores and compares against the gold spans annotated in the original corpora, while allowing for a one-character offset which accounts for differences in the handling of special characters. Results for a slightly different evaluation protocol, which considers as match any overlap between gold standard and predicted spans, along with a more in-depth discussion of evaluation setups and results, can be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> S2. Although especially <italic toggle="yes">SciSpacy</italic> and <italic toggle="yes">HUNER</italic> profit from this more lenient evaluation (+8.04 pp/+5.55 pp), the overall ranking of methods is not changed.</p>
    </sec>
    <sec>
      <title>3.2 Comparison to research prototypes</title>
      <p>We compare <italic toggle="yes">HunFlair’s</italic> results in an in-corpus setting to those reported by four different research prototypes based on three different corpora: JNLPBA (<xref rid="btab042-B9" ref-type="bibr">Kim et al., 2004</xref>), BioCreative V CDR (<xref rid="btab042-B13" ref-type="bibr">Li et al., 2016</xref>) and NCBI Disease (<xref rid="btab042-B6" ref-type="bibr">Doğan <italic toggle="yes">et al.</italic>, 2014</xref>). These corpora were chosen because of the availability of published results on the test splits. Specifically, we compare to <italic toggle="yes">BioBERT</italic> (<xref rid="btab042-B12" ref-type="bibr">Lee et al., 2019</xref>), <italic toggle="yes">SciBERT</italic> (<xref rid="btab042-B4" ref-type="bibr">Beltagy <italic toggle="yes">et al.</italic>, 2019</xref>), <italic toggle="yes">CollaboNet</italic> (<xref rid="btab042-B18" ref-type="bibr">Yoon et al., 2019</xref>) and <italic toggle="yes">SciSpacy</italic> (<xref rid="btab042-B14" ref-type="bibr">Neumann <italic toggle="yes">et al.</italic>, 2019</xref>). To ensure a fair comparison, we proceed as follows when evaluating <italic toggle="yes">HunFlair</italic> in this setting. We first remove the three evaluation corpora from the pretraining set. We next pre-train <italic toggle="yes">HunFlair</italic> on all remaining corpora and then fine-tune it on the training and development portions of the respective corpus.</p>
      <p>The results can be found in <xref rid="btab042-T2" ref-type="table">Table 2</xref> and the detailed evaluation protocol is described in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> S3. <italic toggle="yes">HunFlair</italic> sets the new state-of-the-art on <italic toggle="yes">BioCreative V CDR</italic> consisting of chemical and disease annotations with a macro-average F1 score of 90.57. For JNLPBA (gene) and NCBI Disease, it reaches on-par results with the competitor methods. We also investigate the effect of pretraining on multiple gold standard corpora, by comparing <italic toggle="yes">HunFlair</italic> to a non-pretrained version on all 23 NER corpora. On average, finetuning improves results on all entity types with the improvements in F1 ranging from 0.8 pp for chemicals to 4.75 pp for cell lines. The full results per corpus are provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> S4.</p>
      <table-wrap position="float" id="btab042-T2">
        <label>Table 2.</label>
        <caption>
          <p>Comparison with the reported results of state-of-the-art research prototypes for BioNER</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">JNLPBA (Gene)</th>
              <th rowspan="1" colspan="1">BC5CDR</th>
              <th rowspan="1" colspan="1">NCBI</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SciBERT</td>
              <td rowspan="1" colspan="1">77.28</td>
              <td rowspan="1" colspan="1">90.01</td>
              <td rowspan="1" colspan="1">88.57</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioBERT v1.1</td>
              <td rowspan="1" colspan="1">77.49</td>
              <td rowspan="1" colspan="1">89.76</td>
              <td rowspan="1" colspan="1">
                <bold>89.71</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CollaboNET</td>
              <td rowspan="1" colspan="1">
                <bold>78.58</bold>
              </td>
              <td rowspan="1" colspan="1">87.68</td>
              <td rowspan="1" colspan="1">88.60</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SciSpacy</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">83.92</td>
              <td rowspan="1" colspan="1">81.56</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">HunFlair</td>
              <td rowspan="1" colspan="1">77.60</td>
              <td rowspan="1" colspan="1">89.65</td>
              <td rowspan="1" colspan="1">88.65</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">HunFlair (vanilla)</td>
              <td rowspan="1" colspan="1">77.78</td>
              <td rowspan="1" colspan="1">
                <bold>90.57</bold>
              </td>
              <td rowspan="1" colspan="1">87.47</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic toggle="yes">Note</italic>: Scores are macro-averaged F1 and best results are printed in bold. Note, that HunFlair has been trained on the training and development portions of the respective corpus. ’HunFlair (vanilla)’ refers to the HunFlair model without pretraining on gold standard corpora.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>We proposed <italic toggle="yes">HunFlair</italic>, a state-of-the-art biomedical NER tagger. Through its tight integration into the Flair NLP framework, it is easy to install, easy to use and easy to combine with other NLP modules. It comes comes along with 23 biomedical NER corpora in a single format while still enabling customized pre-processing. <italic toggle="yes">HunFlair</italic> is a redesign of <italic toggle="yes">HUNER</italic>, which it extends with pretrained domain-specific character-level language models. It outperforms a series of other off-the-shelf tools in a cross-corpus evaluation setting on different datasets, and achieves on-par results with current state-of-the-art research prototypes based on in-corpus experiments.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>L.W. and J.M. were funded by the Helmholtz Einstein International Berlin Research School in Data Science (HEIBRiDS). M.H. was funded by the German Research Council [LE-1428/7-1].</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btab042_Supplementary_Data</label>
      <media xlink:href="btab042_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btab042-B1">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Akbik</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <part-title>Contextual string embeddings for sequence labeling</part-title>. In <source>Proceedings of the 27th International Conference on Computational Linguistics</source>. 
<publisher-name>Association for Computational Linguistics</publisher-name>, 
<publisher-loc>Santa Fe, New Mexico, USA</publisher-loc>, pages <fpage>1638</fpage>–<lpage>1649</lpage>.</mixed-citation>
    </ref>
    <ref id="btab042-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Akbik</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) FLAIR: An easy-to-use framework for state-of-the-art NLP. In <italic toggle="yes">Proceedings of the Conference of the NAACL 2019 Conference (Demo)</italic>. Association for Computational Linguistics, Minneapolis, MN, pp. <fpage>54</fpage>–<lpage>59</lpage>.</mixed-citation>
    </ref>
    <ref id="btab042-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bada</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) 
<article-title>Concept annotation in the craft corpus</article-title>. <source>BMC Bioinformatics</source>, <volume>13</volume>, <fpage>161</fpage>.<pub-id pub-id-type="pmid">22776079</pub-id></mixed-citation>
    </ref>
    <ref id="btab042-B4">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Beltagy</surname><given-names>I.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <part-title>SciBERT: a pretrained language model for scientific text</part-title>. In <source>Empirical Methods in Natural Language Processing 2019 (EMNLP)</source>. 
<publisher-name>Association for Computational Linguistics, Hong Kong, China, pp. 3615–3620</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btab042-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bojanowski</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) 
<article-title>Enriching word vectors with subword information</article-title>. <source>Trans. ACL</source>, <volume>5</volume>, <fpage>135</fpage>–<lpage>146</lpage>.</mixed-citation>
    </ref>
    <ref id="btab042-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Doğan</surname><given-names>R.I.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) 
<article-title>NCBI disease corpus: a resource for disease name recognition and concept normalization</article-title>. <source>J. Biomed. Inform</source>., <volume>47</volume>, <fpage>1</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">24393765</pub-id></mixed-citation>
    </ref>
    <ref id="btab042-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>Z.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) 
<article-title>Bidirectional LSTM-CRF models for sequence tagging</article-title>. <bold><italic toggle="yes">arXiv preprint arXiv:1508.01991</italic></bold>.</mixed-citation>
    </ref>
    <ref id="btab042-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>A corpus of plant–disease relations in the biomedical domain</article-title>. <source>PLoS One</source>, <volume>14</volume>, <fpage>e0221582</fpage>.<pub-id pub-id-type="pmid">31461491</pub-id></mixed-citation>
    </ref>
    <ref id="btab042-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>J.-D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2004</year>) Introduction to the bio-entity recognition task at JNLPBA. In <italic toggle="yes">Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and Its Applications</italic>. Citeseer, Geneva, Switzerland, pp. <fpage>73</fpage>–<lpage>78</lpage>.</mixed-citation>
    </ref>
    <ref id="btab042-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Leaman</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) 
<article-title>DNorm: disease name normalization with pairwise learning to rank</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>2909</fpage>–<lpage>2917</lpage>.<pub-id pub-id-type="pmid">23969135</pub-id></mixed-citation>
    </ref>
    <ref id="btab042-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Leaman</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) 
<article-title>tmchem: a high performance approach for chemical named entity recognition and normalization</article-title>. <source>J. Cheminf</source>., <volume>7</volume>, <fpage>S3</fpage>.</mixed-citation>
    </ref>
    <ref id="btab042-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>1234</fpage>–<lpage>1240</lpage>.</mixed-citation>
    </ref>
    <ref id="btab042-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) 
<article-title>BioCreative V CDR task corpus: a resource for chemical disease relation extraction</article-title>. <source>Database</source>, <volume>2016</volume>, <fpage>baw068</fpage>.<pub-id pub-id-type="pmid">27161011</pub-id></mixed-citation>
    </ref>
    <ref id="btab042-B14">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Neumann</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <part-title>ScispaCy: fast and robust models for biomedical natural language processing</part-title>. In: <source>18th BioNLP Workshop and Shared Task</source>. 
<publisher-name>Association for Computational Linguistics, Florence, Italy, pp. 58–66</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btab042-B15">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Pyysalo</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <part-title>Overview of the cancer genetics (CG) task of BioNLP shared task 2013</part-title>. In: <source>BioNLP Shared Task 2013 Workshop</source>. 
<publisher-name>Association for Computational Linguistics, Sofia, Bulgaria, pp. 58–66</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btab042-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weber</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) 
<article-title>HUNER: improving biomedical NER with pretraining</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>295</fpage>–<lpage>302</lpage>.<pub-id pub-id-type="pmid">31243432</pub-id></mixed-citation>
    </ref>
    <ref id="btab042-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wei</surname><given-names>C.-H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) 
<article-title>Gnormplus: an integrative approach for tagging genes, gene families, and protein domains</article-title>. <source>BioMed. Res. Int</source>., <volume>2015</volume>, <fpage>1</fpage>–<lpage>7</lpage>.</mixed-citation>
    </ref>
    <ref id="btab042-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yoon</surname><given-names>W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>Collabonet: collaboration of deep neural networks for biomedical named entity recognition</article-title>. <source>BMC Bioinformatics</source>, <volume>20</volume>, <fpage>249</fpage>.<pub-id pub-id-type="pmid">31138109</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
