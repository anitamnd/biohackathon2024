<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Database (Oxford)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Database (Oxford)</journal-id>
    <journal-id journal-id-type="publisher-id">databa</journal-id>
    <journal-title-group>
      <journal-title>Database: The Journal of Biological Databases and Curation</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-0463</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
      <publisher-loc>UK</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9732843</article-id>
    <article-id pub-id-type="pmid">36484479</article-id>
    <article-id pub-id-type="doi">10.1093/database/baac104</article-id>
    <article-id pub-id-type="publisher-id">baac104</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Article</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI00960</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Emati: a recommender system for biomedical literature based on supervised learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6954-4928</contrib-id>
        <name>
          <surname>Kart</surname>
          <given-names>Özge</given-names>
        </name>
        <aff><institution content-type="department">Biotechnology Center (BIOTEC), Center for Molecular and Cellular Bioengineering (CMCB), Technische Universität Dresden</institution>, Tatzberg 47-49, Dresden 01307, <country country="DE">Germany</country></aff>
        <aff><institution content-type="department">Department of Computer Engineering, Dokuz Eylül University</institution>, Tinaztepe Campus, Buca 35160 Izmir, <country country="TR">Turkey</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mestiashvili</surname>
          <given-names>Alexandre</given-names>
        </name>
        <aff><institution content-type="department">Biotechnology Center (BIOTEC), Center for Molecular and Cellular Bioengineering (CMCB), Technische Universität Dresden</institution>, Tatzberg 47-49, Dresden 01307, <country country="DE">Germany</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lachmann</surname>
          <given-names>Kurt</given-names>
        </name>
        <aff><institution content-type="department">Biotechnology Center (BIOTEC), Center for Molecular and Cellular Bioengineering (CMCB), Technische Universität Dresden</institution>, Tatzberg 47-49, Dresden 01307, <country country="DE">Germany</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kwasnicki</surname>
          <given-names>Richard</given-names>
        </name>
        <aff><institution content-type="department">Biotechnology Center (BIOTEC), Center for Molecular and Cellular Bioengineering (CMCB), Technische Universität Dresden</institution>, Tatzberg 47-49, Dresden 01307, <country country="DE">Germany</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-2848-6949</contrib-id>
        <name>
          <surname>Schroeder</surname>
          <given-names>Michael</given-names>
        </name>
        <xref rid="COR0001" ref-type="corresp"/>
        <!--michael.schroeder@tu-dresden.de-->
        <aff><institution content-type="department">Biotechnology Center (BIOTEC), Center for Molecular and Cellular Bioengineering (CMCB), Technische Universität Dresden</institution>, Tatzberg 47-49, Dresden 01307, <country country="DE">Germany</country></aff>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="COR0001">*Corresponding author: Tel: +49 351 463-40062; Email: <email xlink:href="michael.schroeder@tu-dresden.de">michael.schroeder@tu-dresden.de</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-12-09">
      <day>09</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>09</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <volume>2022</volume>
    <elocation-id>baac104</elocation-id>
    <history>
      <date date-type="received">
        <day>28</day>
        <month>2</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>07</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>17</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>08</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>09</day>
        <month>12</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="baac104.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>The scientific literature continues to grow at an ever-increasing rate. Considering that thousands of new articles are published every week, it is obvious how challenging it is to keep up with newly published literature on a regular basis. Using a recommender system that improves the user experience in the online environment can be a solution to this problem. In the present study, we aimed to develop a web-based article recommender service, called Emati. Since the data are text-based by nature and we wanted our system to be independent of the number of users, a content-based approach has been adopted in this study. A supervised machine learning model has been proposed to generate article recommendations. Two different supervised learning approaches, namely the naïve Bayes model with Term Frequency-Inverse Document Frequency (TF-IDF) vectorizer and the state-of-the-art language model bidirectional encoder representations from transformers (BERT), have been implemented. In the first one, a list of documents is converted into TF-IDF–weighted features and fed into a classifier to distinguish relevant articles from irrelevant ones. Multinomial naïve Bayes algorithm is used as a classifier since, along with the class label, it also gives the probability that the input belongs to this class. The second approach is based on fine-tuning the pretrained state-of-the-art language model BERT for the text classification task. Emati provides a weekly updated list of article recommendations and presents it to the user, sorted by probability scores. New article recommendations are also sent to users’ email addresses on a weekly basis. Additionally, Emati has a personalized search feature to search online services’ (such as PubMed and arXiv) content and have the results sorted by the user’s classifier.</p>
      <p><bold>Database URL</bold>: <ext-link xlink:href="https://emati.biotec.tu-dresden.de" ext-link-type="uri">https://emati.biotec.tu-dresden.de</ext-link></p>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Bundesministerium für Bildung und Forschung</institution>
            <institution-id institution-id-type="DOI">10.13039/501100002347</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="s2">
    <title>Introduction</title>
    <p>The scientific literature is growing rapidly. Since more and more articles are published every year, it can be hard to keep track of relevant topics. In 2020 alone, PubMed (<ext-link xlink:href="https://pubmed.ncbi.nlm.nih.gov/" ext-link-type="uri">https://pubmed.ncbi.nlm.nih.gov/</ext-link>) has indexed 1.4 million new scientific papers. This equals an average of 27 000 papers every week. With such high numbers, it is impossible to find the most relevant publication without tediously browsing through long pages of search results. Considering that a person can read an average of 200–250 words per minute and assuming that an average-length research article consists of 5000 words, the reading time of an article is a minimum of 20 min. According to this calculation, a researcher can read up to 168 articles per week by reading 8 h a day. These numbers show the difficulty of following the relevant literature for researchers with busy work routines. Recommendation systems play an important role in reducing this limitation and improving the search results by considering user profiles as well as domain data.</p>
    <p>Recommender systems can be categorized into three approaches: collaborative filtering, content-based filtering and a hybrid approach. The content-based filtering approach considers the content similarity between users’ interests and the metadata of the articles (<xref rid="R1" ref-type="bibr">1</xref>, <xref rid="R2" ref-type="bibr">2</xref>). Collaborative filtering offers suggestions based on the neighbor’s selection of the same user group (<xref rid="R3" ref-type="bibr">3</xref>). Lastly, the hybrid filtering technique aims to enhance recommendation quality by combining the first two methods (<xref rid="R4" ref-type="bibr">4</xref>). Content-based filtering is preferred when an item is information-rich, such as text data.</p>
    <p>In a content-based recommendation system, a profile is created for each item based on the information it contains, and each user has a profile based on the items they have liked or disliked in the past. Thus, a user profile defines the type of content related to that user. The purpose of the system is to find items whose content best matches the data stored in this user profile.</p>
    <p>Since the approach is domain-specific, this means that it can deliver more precise results. It is easier to accurately tell a user’s interests by looking at the actual content, rather than inferring from a group of similar users. Furthermore, the major advantage of a content-based design is that it is independent of the size of the user base. Recommendations will be equally accurate whether it is just a single user or millions of users. Therefore, it can be applied even to small projects that might not have enough users to make a collaborative approach applicable. However, in this approach, it is important to properly represent information in terms of features. In previous studies, articles are represented in different ways such as paper’s metadata (<xref rid="R5" ref-type="bibr">5</xref>), bag of words (<xref rid="R6" ref-type="bibr">6</xref>), vector space (<xref rid="R7" ref-type="bibr">7</xref>), key phrase (<xref rid="R8" ref-type="bibr">8</xref>, <xref rid="R9" ref-type="bibr">9</xref>) and user’s given tag (<xref rid="R10" ref-type="bibr">10</xref>, <xref rid="R11" ref-type="bibr">11</xref>). The TF-IDF method has been used as a similarity measure between items in article recommendation system studies (<xref rid="R12" ref-type="bibr">12</xref>, <xref rid="R13" ref-type="bibr">13</xref>). There are many other studies (<xref rid="R14" ref-type="bibr">14–16</xref>) that use this method for the same purpose in different domains.</p>
    <p>Recently, various approaches have been used in content-based research article recommendation systems. Chaudhuri <italic toggle="yes">et al.</italic> proposed new features for improving the efficiency of the recommendation system, which are extracted indirectly from research articles. These features are keyword diversification, text complexity, citation analysis over time and scientific quality measurement to represent a research article. The keyword diversification indicates the uniqueness of the keywords to help variation in a recommendation. The text complexity measure helps match an article to a user based on the user’s understandability level. The citation analysis over time indicates the relevancy of a paper. The scientific quality ranks the scientific merits of articles (<xref rid="R17" ref-type="bibr">17</xref>). Bulut <italic toggle="yes">et al.</italic> used the Doc2vec method to compare user profiles with candidate articles to be recommended. User profiles and candidate articles are represented as continuous vectors in the Doc2vec method. Similar articles to a user profile are recommended to that user (<xref rid="R13" ref-type="bibr">13</xref>). Hao <italic toggle="yes">et al.</italic> integrated academic network information with content similarity information to improve the accuracy and efficiency of recommendations. The academic network consists of links between author nodes, paper notes and conference nodes (<xref rid="R18" ref-type="bibr">18</xref>).</p>
    <p>In content-based recommendation systems, the task of determining the semantic similarity of texts is challenging. The recently announced pretrained transformers for language modeling such as bidirectional encoder representations from transformers (BERT) Embeddings from Language Models and Generative Pre-trained Transformer 3 are quite successful in overcoming this challenge. These pretrained machine learning models have achieved state-of-the-art performance for many natural language processing (NLP) tasks such as question answering, sentiment analysis and named entity recognition (<xref rid="R19" ref-type="bibr">19–21</xref>). There are also some recent studies using BERT in various ways in recommendation systems. Jeong <italic toggle="yes">et al.</italic> (2020) proposed a citation recommender model by using BERT to obtain embedding vectors from textual data and by using graph convolutional network to obtain embedding vectors from citation graphs (<xref rid="R22" ref-type="bibr">22</xref>). Sun <italic toggle="yes">et al.</italic> proposed a recommender system in which BERT architecture was adapted to take a set of items instead of text as input values (<xref rid="R23" ref-type="bibr">23</xref>). In these studies, the BERT model showed a stronger performance than the other models.</p>
    <p>According to a literature survey on research-paper recommender systems conducted by Beel <italic toggle="yes">et al.</italic> (<xref rid="R24" ref-type="bibr">24</xref>), out of the reviewed approaches, only 39% of research-paper recommender systems could be used by users in practice. Of these recommender systems, 44% are still running and actively maintained. On the other hand, Beel <italic toggle="yes">et al.</italic> emphasized that most of the real-world recommender systems implement basic recommendation approaches that are not based on recent research (<xref rid="R24" ref-type="bibr">24</xref>). In order to bridge this gap, we focused our study on developing a web-based article recommendation service, which provides users with updated research results.</p>
    <p>The developed system adopts a content-based approach and uses supervised machine learning to create recommendations. The classification task is to label each article with one of the two target classes ‘interesting’ and ‘irrelevant’. Two different approaches have been implemented for this task. In the first one, we represent articles with TF-IDF vectors and train a classifier with these vectors. The multinomial naïve Bayes classifier is used in the implementation since it provides probability distribution, which determines the probability that the input belongs to each class, as well as a class label. The recommended articles are ranked based on their probability scores. The second approach is based on a state-of-the-art language model BERT. The pretrained BERT model is fine-tuned for the text classification task. The probability of class membership for each class label is obtained by the softmax function.</p>
    <p>SCI-BERT is a pretrained language model that has the same architecture as BERT but is trained on a large corpus of scientific text (<xref rid="R25" ref-type="bibr">25</xref>). The SCI-BERT paper reports a +1.92 F1 score increase on average at the fine-tuned SCI-BERT models for various tasks in the biomedical domain such as named entity recognition, PICO extraction, relation classification and dependency parsing, compared to the BERT-base. However, it does not report any result for the text classification task in the biomedical domain, which we employ in this study. It reports the results of the text classification task on two data sets from multiple domains, which yield only a +0.49 F1 score increase on average. Therefore, large improvements are not expected from the use of SCI-BERT models instead of the BERT-base.</p>
    <p>A website has been developed to display a weekly updated list of articles recommended for each user, which is available at <ext-link xlink:href="https://emati.biotec.tu-dresden.de" ext-link-type="uri">https://emati.biotec.tu-dresden.de</ext-link>. The system also sends new article recommendations to users’ email addresses on a weekly basis. Furthermore, Emati has a personalized search feature to search from online services (such as PubMed and arXiv) and have the results sorted by the user’s classifier. The first approach, which is based on TF-IDF and multinomial naïve Bayes, is used in production as a classifier due to the need for scalability. The source codes of the project are available on the GitHub repository (<ext-link xlink:href="https://github.com/bioinfcollab/emati" ext-link-type="uri">https://github.com/bioinfcollab/emati</ext-link>), where both naïve Bayes– and BERT-based approaches are available to the user as a classifier option.</p>
    <p>The advantages of Emati over similar systems such as arXivDigest (<xref rid="R26" ref-type="bibr">26</xref>) can be listed as follows: arXivDigest provides recommendations over papers published on only arXiv. Emati currently provides recommendations from both PubMed and arXiv, which means it can offer a wider range and produce more accurate recommendations, especially for biomedical researchers. Also due to the flexible design of Emati, further sources can be easily integrated. Moreover, arXivDigest requires the users to provide topics of their interests as keywords at the registration and it basically returns the keyword search results to the users as recommended articles. It enables the researchers can register their own recommender system; however, it does not itself provide any complex recommender engine based on machine learning, collaborative filtering or another state-of-the-art recommendation method. Emati recommendations are based on a machine learning classifier, and users can upload the reference list of the articles they are interested in to train the personalized classifier based on their interests.</p>
  </sec>
  <sec id="s3">
    <title>Materials and Methods</title>
    <p>Emati is a web-based recommender system that displays a weekly updated list of recommended scientific articles. <xref rid="F1" ref-type="fig">Figure 1</xref> shows a screenshot of the main page. The Emati database (DB) contains article information published in PubMed and arXiv since 2000, and it is updated every week with newly published articles. The approximate number of articles in the DB in 2022 is ∼15 million. The system allows fetching new content from any source, as long as it offers an Application Programming Interface for downloading papers with their title, abstract, journal, authors and date of publication stored in separate fields. Thus, it is possible to include multiple sources and expand the range of topics.</p>
    <fig position="float" id="F1" fig-type="figure">
      <label>Figure 1.</label>
      <caption>
        <p>Weekly article recommendations of the user are listed on the homepage.</p>
      </caption>
      <graphic xlink:href="baac104f1" position="float"/>
    </fig>
    <p>In order to get updated article recommendations, a user creates an account, logs in to the system and uploads their reference files. The file upload process is detailed in the 2.2.4 training corpus subsection. The reference files are parsed to learn about the topics this particular user is interested in. Once the initial recommender model is initialized, it can be updated with the data collected from user interaction. Users click on the articles to read and click like or dislike buttons in accordance with their interests. With this information, a personal machine learning classifier is trained. When enough new interactions are detected, the classifier is retrained to keep itself up-to-date. The trained model is used to create new weekly content for the user. A combination of percentage and absolute interactions is used as the number of new interactions required to trigger retraining. Whatever case occurs first triggers the retraining. The percentage threshold is the percentage in relation to total interactions so far. For example, a user has clicked/liked/disliked 100 articles in total. A threshold of 0.1 means that 100 * 0.1 = 10 new interactions since the last training are needed to train the classifier anew. The absolute threshold is the absolute number of new interactions required to trigger retraining. These parameters are set to 0.1 and 10 by default, respectively.</p>
    <sec id="s3-s1">
      <title>General structure of the system</title>
      <p>The system is composed of two separate servers. <xref rid="F2" ref-type="fig">Figure 2(a)</xref> shows the high-level system design of the project. The code implemented during this study resides within the Django project. The machine learning aspects of this project are also implemented in Python using the scikit-learn library.</p>
      <fig position="float" id="F2" fig-type="figure">
        <label>Figure 2.</label>
        <caption>
          <p>(<bold>a</bold>) High-level system design that shows how components of the system are connected and communicate with each other. (<bold>b</bold>) Data flow diagram for the creation of recommendations. (<bold>c</bold>) Personalized search pipeline that shows how a query term is searched from the search engine and returned results are reordered by the classifier.</p>
        </caption>
        <graphic xlink:href="baac104f2" position="float"/>
      </fig>
      <p>Elasticsearch is the search engine responsible for the full-text search feature. Django communicates with the search index by sending requests to Elasticsearch’s web interface. Elasticsearch consists of a search index managed by a server that provides an HTTP web interface. By sending requests to that server, it is possible to query the search index or add new documents. There is also an official Python client for Elasticsearch that takes care of handling requests and responses (<ext-link xlink:href="https://github.com/elastic/elasticsearch-py" ext-link-type="uri">https://github.com/elastic/elasticsearch-py</ext-link>, accessed 30 October 2021). This makes it very easy to communicate with the search index from within the Django project.</p>
    </sec>
    <sec id="s3-s2">
      <title>Recommender model</title>
      <p>The recommender model is based on a classification task that is used to label each article with one of the two target classes ‘interesting’ and ‘irrelevant’. Since our ultimate goal is to rank articles according to how interesting they are, we need not only a binary classification but also their probability of belonging to a particular target class. This requirement was met by using the multinomial naïve Bayes classifier and the BERT classifier with a softmax function in the implementation of this study. Since those classes are mutually exclusive, their scores will always add up to 1. In other words, if an article is considered interesting with a probability of 80%, then it must be irrelevant with a probability of 20%.</p>
      <p><xref rid="F2" ref-type="fig">Figure 2(b)</xref> shows the data flow during the creation of new recommendations. The Ranker will take a list of articles together with the classifier of a single user. It then calculates the scores for each article. These scores indicate the probability with which an article belongs to the class titled interesting. For the best scoring articles, the Ranker will create Recommendation objects that contain references to the user and that specific article together with the computed score. By saving only the best scoring recommendations, we also reduce the required data storage.</p>
      <sec id="s3-s2-s1">
        <title>Multinomial naïve Bayes</title>
        <p>Multinomial naïve Bayes classifier, which is still a popular model for text classification, is used in this study. A naïve Bayes classifier outputs a maximum <italic toggle="yes">a posteriori</italic> prediction where the posterior probabilities for the levels of the target feature are computed, assuming that the descriptive features are conditionally independent in an instance given a target feature level (<xref rid="R27" ref-type="bibr">27</xref>). The naïve Bayes model is defined as follows:
<disp-formula id="UM0001"><tex-math notation="LaTeX" id="UM0001-Latex">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$M(q)\; = \;ar\;gma{x_{\;l\; \in levels(t)\;}}(\left( {\prod\limits_{i = 1}^m {\;\;p(q[i]\left| {t\; = l)} \right.} } \right) * \;p(t = l))$$\end{document}</tex-math></disp-formula></p>
        <p>where <italic toggle="yes">t</italic> is the target feature with a set of levels, levels(<italic toggle="yes">t</italic>), and <italic toggle="yes">q</italic> is the query instance with a set of descriptive features, <italic toggle="yes">q</italic>[1], …, <italic toggle="yes">q</italic>[<italic toggle="yes">m</italic>].</p>
      </sec>
      <sec id="s3-s2-s2">
        <title>Feature generation and classification</title>
        <p>Our data set consists of the article’s title and abstract, the journal it was published in, the list of authors and the date of publication. These data can be used to categorize a document into ‘interesting’ and ‘irrelevant’. The text is split into words that are then weighted according to the TF-IDF weighting scheme. Each document is represented by a vector of these features. The vectors are then fed into the multinomial naïve Bayes classifier.</p>
        <p>During training, the algorithm will learn all words present in the corpus. Since each user’s field of interest is different, each training corpus will be different as well. This also means that all users will have a personalized vocabulary of words that are known to their classifier. Each user’s final model, therefore, consists of a vectorizer and a classifier. The vectorizer represents the learned vocabulary. It is responsible for converting a list of documents into vectors of TF-IDF–weighted features. During the training process, the vectorizer learns the weights based on the given corpus. The TF-IDF vectorizer uses the corpus from the training data. So while creating recommendations from new articles, it can vectorize only existing terms in that corpus. The classifier is responsible for the actual categorization task. It takes a list of feature vectors and returns a vector of probabilities for each document, which indicates the likeliness with which it belongs to one of the available classes.</p>
      </sec>
      <sec id="s3-s2-s3">
        <title>Bidirectional encoder representations from transformers</title>
        <p>BERT is one of the most popular natural language models which is mainly divided into two stages: pretraining and fine-tuning. It has been pretrained to learn deep bidirectional representation from the unlabeled text. It is designed to perform fine-tuning using labeled text for various NLP tasks after pretraining (<xref rid="R19" ref-type="bibr">19</xref>). The BERT model uses a large corpus comprising BooksCorpus (800 M words) (<xref rid="R28" ref-type="bibr">28</xref>) and English Wikipedia (2500 M words) for the pretraining. In fine-tuning, the BERT model is initialized with pretrained parameters and then trained on a downstream task, which is text classification in our case, by simply fine-tuning all pretrained parameters. The self-attention mechanism in the transformer enables the modeling of multiple downstream tasks by replacing appropriate inputs and outputs.</p>
        <p>BERT’s most superior feature is to generate contextualized word representations. However, it also brings some drawbacks. The model is huge due to the training structure and large corpus. It is slower to train compared to shallow machine learning algorithms. It is also very compute-intensive at inference time, which means that it can become costly if someone wants to use it in production at scale. A single BERT-base model checkpoint is ∼1.3 GB in size. Moreover, it is stated that the fine-tuning examples in the BERT paper (<xref rid="R19" ref-type="bibr">19</xref>), which use BERT-base, should be able to run on a graphics processing unit that has at least 12 GB of random access memory (RAM) using the hyperparameters given in <ext-link xlink:href="https://github.com/google-research/bert" ext-link-type="uri">https://github.com/google-research/bert</ext-link>. In a multiuser system where each user’s own profile is created and updated over time, such high-capacity hardware requirements increase costs significantly as the number of users increases.</p>
      </sec>
      <sec id="s3-s2-s4">
        <title>Training corpus</title>
        <p>As already stated earlier, the recommender system works on scientific articles. But naturally, the system has no data on a newly signed-up user. To overcome this problem, which is also referred to as the ‘cold-start’ or ‘new-user’ problem, the system provides users with the possibility to upload reference files from the ‘Settings’ menu, as shown in <xref rid="F3" ref-type="fig">Figure 3</xref>. Currently supported file formats are BibTeX (.bib), RIS (.ris) and Endnote XML (.xml). These files contain a list of articles the user has cited in the past. This makes it possible to infer the field they are working on. The reference files contain the same type of data that our system is working with (title, journal, author and abstract) and already store it in separate fields. Thus, they can be easily parsed and fed into the algorithm. If the abstract of an article is not already provided in the reference file, the system queries the article title from the sources and includes the abstract if available. Users can also upload a PubMed ID (PMID) list of articles as a text (.txt) file or save the PMIDs in a text area provided in the ‘Settings’ menu. The system queries PubMed by the provided PMIDs and fetches the article information such as title, journal, author and abstract. According to a current study (<xref rid="R29" ref-type="bibr">29</xref>), the increase of the Area Under the Curve value when full texts were used instead of abstracts ranges from 0% to 9% across six different text mining tasks, and the median was 3.5%. Since the improvement expected in the performance is not so large compared to the reduced scalability and increase in resources needed, we decided to use abstracts in this study.</p>
        <fig position="float" id="F3" fig-type="figure">
          <label>Figure 3.</label>
          <caption>
            <p>Reference files are uploaded from the Settings menu.</p>
          </caption>
          <graphic xlink:href="baac104f3" position="float"/>
        </fig>
        <p>The data points collected this way serve as positive training samples—they define the ‘interesting’ class. A set of randomly picked articles are used as negative samples. The training corpus is filled with random articles until there is an equal amount of positive and negative samples. Once the initial recommender model is initialized, it can be updated with the data collected from user interaction. Every user interaction is logged so that a classifier can be retrained regularly with an ever-increasing corpus. Implicitly, this is done by incorporating the articles that the user clicked on to view their details since it might be an indication of their interest. More explicit feedback is provided by the website in the form of like and dislike buttons. The collected feedback is weighted higher than the logged click since the user explicitly tells the system their opinion. In other words, clicked articles have less (50% by default) weight than liked articles while training a classifier since ‘like’ is stronger evidence rather than ‘click’. Also with disliked articles, a better negative training set is obtained. During the first training, the negative samples consisted only of randomly picked articles, meaning that the system tried to discern ‘interesting’ articles from the ‘average’ article. But it cannot make a clear distinction since it does not know the true bounds of the ‘interesting’ class—the borders are fuzzy. By using articles that were considered ‘interesting’ by the engine but labeled ‘irrelevant’ by the user, the true edge of the ‘interesting’ class can be discovered and the border becomes sharper.</p>
      </sec>
    </sec>
    <sec id="s3-s3">
      <title>Results and Discussion</title>
      <p>In order to evaluate the proposed recommendation system, we conducted some necessary experiments on several data sets for different use-case scenarios. All the experiments were implemented using Python on a Debian GNU/Linux 10 (buster) and run on an Intel(R) Xeon(R) E5-2650 v2 @ 2.60 GHz central processing unit and 256 GB RAM. Both the naïve Bayes with TF-IDF vectorizer and BERT-based approaches have been implemented. The multinomial naïve Bayes algorithm was implemented using scikit-learn. The pretrained ‘BERT-base-uncased’ model has been downloaded and fine-tuned for the text classification task using the HuggingFace Transformers library on the data sets detailed later. The text data are tokenized by using the BERT tokenizer and fed to the BERT model. The input token length is 300, which is the approximate length of an abstract. The parameters set for fine-tuning are as follows: the number of training epochs is 3. Batch sizes for training and evaluation are set to 32 and 64, respectively. The best model is loaded to be used for inference at the end of training.</p>
      <p>A 10-fold cross-validation scheme has been implemented to evaluate the naïve Bayes models. <italic toggle="yes">n</italic>-fold cross-validation splits the training data into <italic toggle="yes">n</italic> equal parts. A model is trained by <italic toggle="yes">n</italic> − 1 parts and tested by one part. This process iterates <italic toggle="yes">n</italic> times until all parts are used in the training and test process. To be more specific, the split ratio is 90:10 per iteration in our case. The hold-out validation method has been used to evaluate the BERT models. The split ratio is 80:20.</p>
      <sec id="s3-s3-s1">
        <title>A researcher use case with a particular research focus</title>
        <p>A new-user account has been created, and a BibTeX file containing positive training examples has been generated and uploaded to Emati. In order to create a user profile for a researcher who is interested in biology with a specific focus on liquid–liquid phase separation (LLPS), 52 protein names that are common in four LLPS DBs (<xref rid="R30" ref-type="bibr">30–33</xref>) have been queried in PubMed along with related keywords such as phase separation, phase transition, condensate and membraneless organelle. The articles published in journals with an impact factor have been filtered out in the results to create a positive data set. As a result, the reference file contained data of 300 articles. The same number of negative samples has been randomly selected among the downloaded PubMed articles published between 1 May 2021 and 10 July 2021. Two more example user profiles have been created separately for the researchers who are interested in the topics of ‘neurodegenerative diseases’ and ‘antibiotics resistance’. These two terms have been queried in PubMed. The articles published in journals with an impact factor have been filtered out in the results to create positive data sets from indexed journals. As a result, the data of 7048 and 6852 articles have been uploaded to the system as positive samples for example user profiles who are interested in the topics of neurodegenerative diseases and antibiotics resistance, respectively. The same number of negative samples has been randomly selected among the downloaded PubMed articles published in 2021.</p>
        <p>The performance values obtained by the experiments using both the naïve Bayes and BERT models are given in <xref rid="T1" ref-type="table">Tables 1</xref> and <xref rid="T2" ref-type="table">2</xref>. BERT models provided more accurate results compared to naïve Bayes models for all researcher profiles. We also have subsampled 15 random samples from each constructed positive data set and trained models using them to observe the training performance of the models when users provide a small set of positive examples. When using smaller training sets, the performance drop of BERT models was quite greater than that of naïve Bayes. The naïve Bayes performed better on small data sets.</p>
        <table-wrap position="float" id="T1">
          <label>Table 1.</label>
          <caption>
            <p>Training performance values obtained by the validation of naïve Bayes models trained with three different researcher profiles</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th valign="bottom" colspan="1" align="left" rowspan="1">Researcher profile</th>
                <th valign="bottom" colspan="2" align="center" rowspan="1">LLPS proteins</th>
                <th valign="bottom" colspan="2" align="center" rowspan="1">Neurodegenerative diseases</th>
                <th valign="bottom" colspan="2" align="center" rowspan="1">Antibiotics resistance</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">Data set size</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Large (300 * 2)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Small (15 * 2)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Large (7048 * 2)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Small (15 * 2)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Large (6852 * 2)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Small (15 * 2)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Precision</td>
                <td align="left" rowspan="1" colspan="1">0.95</td>
                <td align="left" rowspan="1" colspan="1">0.95</td>
                <td align="left" rowspan="1" colspan="1">0.83</td>
                <td align="left" rowspan="1" colspan="1">0.7</td>
                <td align="left" rowspan="1" colspan="1">0.88</td>
                <td align="left" rowspan="1" colspan="1">0.65</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Recall</td>
                <td align="left" rowspan="1" colspan="1">1</td>
                <td align="left" rowspan="1" colspan="1">0.9</td>
                <td align="left" rowspan="1" colspan="1">0.96</td>
                <td align="left" rowspan="1" colspan="1">1</td>
                <td align="left" rowspan="1" colspan="1">0.99</td>
                <td align="left" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"><italic toggle="yes">F</italic>-measure</td>
                <td align="left" rowspan="1" colspan="1">0.98</td>
                <td align="left" rowspan="1" colspan="1">0.95</td>
                <td align="left" rowspan="1" colspan="1">0.89</td>
                <td align="left" rowspan="1" colspan="1">0.82</td>
                <td align="left" rowspan="1" colspan="1">0.93</td>
                <td align="left" rowspan="1" colspan="1">0.79</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T2">
          <label>Table 2.</label>
          <caption>
            <p>Training performance values obtained by the validation of BERT models trained with three different researcher profiles</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th valign="bottom" colspan="1" align="left" rowspan="1">Researcher profile</th>
                <th valign="bottom" colspan="2" align="center" rowspan="1">LLPS proteins</th>
                <th valign="bottom" colspan="2" align="center" rowspan="1">Neurodegenerative diseases</th>
                <th valign="bottom" colspan="2" align="center" rowspan="1">Antibiotics resistance</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">Data set size</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Large (300 * 2)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Small (15 * 2)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Large (7048 * 2)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Small (15 * 2)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Large (6852 * 2)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Small (15 * 2)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Precision</td>
                <td align="left" rowspan="1" colspan="1">1</td>
                <td align="left" rowspan="1" colspan="1">0.5</td>
                <td align="left" rowspan="1" colspan="1">0.97</td>
                <td align="left" rowspan="1" colspan="1">0.33</td>
                <td align="left" rowspan="1" colspan="1">0.98</td>
                <td align="left" rowspan="1" colspan="1">0.66</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Recall</td>
                <td align="left" rowspan="1" colspan="1">0.98</td>
                <td align="left" rowspan="1" colspan="1">1</td>
                <td align="left" rowspan="1" colspan="1">0.97</td>
                <td align="left" rowspan="1" colspan="1">1</td>
                <td align="left" rowspan="1" colspan="1">0.98</td>
                <td align="left" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"><italic toggle="yes">F</italic>-measure</td>
                <td align="left" rowspan="1" colspan="1">0.99</td>
                <td align="left" rowspan="1" colspan="1">0.67</td>
                <td align="left" rowspan="1" colspan="1">0.99</td>
                <td align="left" rowspan="1" colspan="1">0.5</td>
                <td align="left" rowspan="1" colspan="1">0.98</td>
                <td align="left" rowspan="1" colspan="1">0.8</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec id="s3-s3-s2">
        <title>A curator use case with a focus on a model organism DB</title>
        <p>Model organism DBs are biological DBs that holistically produce, source and blend species-specific information by putting expert knowledge together with bioinformatics and literature curation. DB curators are hired experts who read articles, extract useful information and place that information into searchable DBs.</p>
        <p>Considering that the curators may be potential users of the proposed system, some retrospective experiments have been carried out on FlyBase (<ext-link xlink:href="http://flybase.org/" ext-link-type="uri">http://flybase.org/</ext-link>), The Zebrafish Information Network (ZFIN) (<ext-link xlink:href="http://zfin.org/" ext-link-type="uri">http://zfin.org/</ext-link>) and Mouse Genome Informatics (MGI) (<ext-link xlink:href="http://www.informatics.jax.org/" ext-link-type="uri">http://www.informatics.jax.org/</ext-link>), which are model organism DBs for fruit fly, zebrafish and mouse, respectively. The DBs provide the information of the articles they use as evidence for their annotations. In our experiments, we have extracted those articles published in 2019 to be used as a positive training set while training recommender models. The number of articles extracted from each DB is given in <xref rid="T3" ref-type="table">Table 3</xref>. The same number of random articles published in 2019 has been collected from PubMed as negative examples. <xref rid="T4" ref-type="table">Table 4</xref> shows the precision, recall and <italic toggle="yes">F</italic>-measure values of the trained models for each DB based on the implemented validation scheme.</p>
        <table-wrap position="float" id="T3">
          <label>Table 3.</label>
          <caption>
            <p>The number of positive examples in the FlyBase, ZFIN and MGI data sets</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th valign="bottom" align="left" rowspan="1" colspan="1">DB name</th>
                <th valign="bottom" align="left" rowspan="1" colspan="1">FlyBase</th>
                <th valign="bottom" align="left" rowspan="1" colspan="1">ZFIN</th>
                <th valign="bottom" align="left" rowspan="1" colspan="1">MGI</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">No. of articles in 2019 cited in the DB</td>
                <td align="left" rowspan="1" colspan="1">2825</td>
                <td align="left" rowspan="1" colspan="1">3330</td>
                <td valign="top" align="left" rowspan="1" colspan="1">12 744</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T4">
          <label>Table 4.</label>
          <caption>
            <p>Training performance values obtained by the validation of naïve Bayes and BERT classifiers trained with the FlyBase, ZFIN and MGI data sets</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th valign="bottom" align="left" rowspan="1" colspan="1"/>
                <th valign="bottom" colspan="3" align="center" rowspan="1">Naïve Bayes (10-fold cv)</th>
                <th valign="bottom" colspan="3" align="center" rowspan="1">BERT (train/test split 80:20)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">DB name</td>
                <td valign="top" align="left" rowspan="1" colspan="1">FlyBase</td>
                <td valign="top" align="left" rowspan="1" colspan="1">ZFIN</td>
                <td valign="top" align="left" rowspan="1" colspan="1">MGI</td>
                <td valign="top" align="left" rowspan="1" colspan="1">FlyBase</td>
                <td valign="top" align="left" rowspan="1" colspan="1">ZFIN</td>
                <td valign="top" align="left" rowspan="1" colspan="1">MGI</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Precision</td>
                <td align="left" rowspan="1" colspan="1">0.97</td>
                <td align="left" rowspan="1" colspan="1">0.97</td>
                <td align="left" rowspan="1" colspan="1">0.98</td>
                <td align="left" rowspan="1" colspan="1">0.98</td>
                <td align="left" rowspan="1" colspan="1">0.97</td>
                <td align="left" rowspan="1" colspan="1">0.94</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Recall</td>
                <td align="left" rowspan="1" colspan="1">0.82</td>
                <td align="left" rowspan="1" colspan="1">0.75</td>
                <td align="left" rowspan="1" colspan="1">0.85</td>
                <td align="left" rowspan="1" colspan="1">0.97</td>
                <td align="left" rowspan="1" colspan="1">0.94</td>
                <td align="left" rowspan="1" colspan="1">0.98</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"><italic toggle="yes">F</italic>-measure</td>
                <td align="left" rowspan="1" colspan="1">0.89</td>
                <td align="left" rowspan="1" colspan="1">0.84</td>
                <td align="left" rowspan="1" colspan="1">0.91</td>
                <td align="left" rowspan="1" colspan="1">0.97</td>
                <td align="left" rowspan="1" colspan="1">0.95</td>
                <td align="left" rowspan="1" colspan="1">0.96</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>The models trained on the full 2019 training data have been used to create recommendations for the first, second and third weeks of 2020. The system recommendations have been compared with the articles published in corresponding weeks which were already cited by the DBs. Precision@50 (precision at top 50 Emati recommendations) and Recall@<italic toggle="yes">n</italic> for different <italic toggle="yes">n</italic> values have been computed for each DB (<xref rid="T5 T6 T7" ref-type="table">Tables 5–7</xref>).</p>
        <table-wrap position="float" id="T5">
          <label>Table 5.</label>
          <caption>
            <p>Recommendation performance values of the classifiers trained with the FlyBase data set, based on the first 3 weeks of 2020</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th valign="bottom" align="left" rowspan="1" colspan="1"/>
                <th valign="bottom" align="left" rowspan="1" colspan="1"/>
                <th valign="bottom" colspan="2" align="center" rowspan="1">Naïve Bayes classifier</th>
                <th valign="bottom" colspan="2" align="center" rowspan="1">BERT classifier</th>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td valign="bottom" colspan="1" align="left" rowspan="1">
                  <bold><italic toggle="yes">n</italic> (no. of weekly articles in FlyBase)</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Recall@<italic toggle="yes">n</italic></bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Precision@50</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Recall@<italic toggle="yes">n</italic></bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Precision@50</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">First week of 2020</td>
                <td align="left" rowspan="1" colspan="1">58</td>
                <td align="left" rowspan="1" colspan="1">11/58 = 0.19</td>
                <td align="left" rowspan="1" colspan="1">11/50 = 0.22</td>
                <td align="left" rowspan="1" colspan="1">33/58 = 0.57</td>
                <td align="left" rowspan="1" colspan="1">29/50 = 0.58</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Second week of 2020</td>
                <td align="left" rowspan="1" colspan="1">66</td>
                <td align="left" rowspan="1" colspan="1">23/66 = 0.35</td>
                <td align="left" rowspan="1" colspan="1">17/50 = 0.34</td>
                <td align="left" rowspan="1" colspan="1">48/66 = 0.73</td>
                <td align="left" rowspan="1" colspan="1">39/50 = 0.78</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Third week of 2020</td>
                <td align="left" rowspan="1" colspan="1">46</td>
                <td align="left" rowspan="1" colspan="1">15/46 = 0.33</td>
                <td align="left" rowspan="1" colspan="1">17/50 = 0.34</td>
                <td align="left" rowspan="1" colspan="1">26/46 = 0.57</td>
                <td align="left" rowspan="1" colspan="1">27/50 = 0.54</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T6">
          <label>Table 6.</label>
          <caption>
            <p>Recommendation performance values of the classifiers trained with the ZFIN data set, based on the first 3 weeks of 2020</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th valign="bottom" align="left" rowspan="1" colspan="1"/>
                <th valign="bottom" align="left" rowspan="1" colspan="1"/>
                <th valign="bottom" colspan="2" align="center" rowspan="1">Naïve Bayes classifier</th>
                <th valign="bottom" colspan="2" align="center" rowspan="1">BERT classifier</th>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td valign="bottom" colspan="1" align="left" rowspan="1">
                  <bold><italic toggle="yes">n</italic> (no. of weekly articles in ZFIN)</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Recall@<italic toggle="yes">n</italic></bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Precision@50</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Recall@<italic toggle="yes">n</italic></bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Precision@50</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">First week of 2020</td>
                <td align="left" rowspan="1" colspan="1">178</td>
                <td align="left" rowspan="1" colspan="1">63/178 = 0.35</td>
                <td align="left" rowspan="1" colspan="1">33/50 = 0.66</td>
                <td align="left" rowspan="1" colspan="1">108/178 = 0.61</td>
                <td align="left" rowspan="1" colspan="1">48/50 = 0.96</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Second week of 2020</td>
                <td align="left" rowspan="1" colspan="1">38</td>
                <td align="left" rowspan="1" colspan="1">5/38 = 0.13</td>
                <td align="left" rowspan="1" colspan="1">9/50 = 0.18</td>
                <td align="left" rowspan="1" colspan="1">28/38 = 0.74</td>
                <td align="left" rowspan="1" colspan="1">31/50 = 0.62</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Third week of 2020</td>
                <td align="left" rowspan="1" colspan="1">58</td>
                <td align="left" rowspan="1" colspan="1">12/58 = 0.21</td>
                <td align="left" rowspan="1" colspan="1">11/50 = 0.22</td>
                <td align="left" rowspan="1" colspan="1">42/58 = 0.72</td>
                <td align="left" rowspan="1" colspan="1">42/50 = 0.84</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T7">
          <label>Table 7.</label>
          <caption>
            <p>Recommendation performance values of the classifiers trained with the MGI data set, based on the first 3 weeks of 2020</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th valign="bottom" align="left" rowspan="1" colspan="1"/>
                <th valign="bottom" align="left" rowspan="1" colspan="1"/>
                <th valign="bottom" colspan="2" align="center" rowspan="1">Naïve Bayes classifier</th>
                <th valign="bottom" colspan="2" align="center" rowspan="1">BERT classifier</th>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td valign="bottom" colspan="1" align="left" rowspan="1">
                  <bold><italic toggle="yes">n</italic> (no. of weekly articles in MGI)</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Recall@<italic toggle="yes">n</italic></bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Precision@50</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Recall@<italic toggle="yes">n</italic></bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Precision@50</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">First week of 2020</td>
                <td align="left" rowspan="1" colspan="1">505</td>
                <td align="left" rowspan="1" colspan="1">102/505<xref rid="T0007-fn1" ref-type="table-fn"><sup>a</sup></xref> = 0.20</td>
                <td align="left" rowspan="1" colspan="1">27/50 = 0.54</td>
                <td align="left" rowspan="1" colspan="1">170/505 = 0.34</td>
                <td align="left" rowspan="1" colspan="1">37/50 = 0.74</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Second week of 2020</td>
                <td align="left" rowspan="1" colspan="1">151</td>
                <td align="left" rowspan="1" colspan="1">52/151 = 0.34</td>
                <td align="left" rowspan="1" colspan="1">20/50 = 0.40</td>
                <td align="left" rowspan="1" colspan="1">49/151 = 0.32</td>
                <td align="left" rowspan="1" colspan="1">30/50 = 0.60</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Third week of 2020</td>
                <td align="left" rowspan="1" colspan="1">184</td>
                <td align="left" rowspan="1" colspan="1">28/184 = 0.15</td>
                <td align="left" rowspan="1" colspan="1">19/50 = 0.38</td>
                <td align="left" rowspan="1" colspan="1">63/184 = 0.34</td>
                <td align="left" rowspan="1" colspan="1">31/50 = 0.62</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="T0007-fn1">
              <label>a</label>
              <p>The number of weekly Emati recommendations &lt; <italic toggle="yes">n</italic>.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>The training performance of the naïve Bayes classifiers trained using the same number of positive and negative examples is quite high with <italic toggle="yes">F</italic>-measures ranging from 0.84 to 0.91. However, since thousands of new papers are published in a week, the task of recommending weekly articles is much harder than distinguishing positive and negative examples in a balanced data set. Therefore, it is reasonable that the precision and recall values given in <xref rid="T5 T6 T7" ref-type="table">Tables 5–7</xref> are relatively lower. On the other hand, the BERT models obtained outstanding results for the recommendation task. The recommendation performance values of fine-tuned BERT models are significantly higher than naïve Bayes models. <xref rid="F4" ref-type="fig">Figure 4</xref> illustrates the 3-week average recommendation performance of classifiers trained with the FlyBase, ZFIN and MGI data sets, whose sizes are given next to their names.</p>
        <fig position="float" id="F4" fig-type="figure">
          <label>Figure 4.</label>
          <caption>
            <p>Average recommendation performances of the classifiers trained with the FlyBase, ZFIN and MGI data sets in terms of (<bold>a</bold>) Recall@<italic toggle="yes">n</italic> and (<bold>b</bold>) Precision@50.</p>
          </caption>
          <graphic xlink:href="baac104f4" position="float"/>
        </fig>
      </sec>
      <sec id="s3-s3-s3">
        <title>Model training time and size evaluation</title>
        <p>The training time of each model trained on the smallest (LLPS) and largest (MGI) data sets used in the experiments is given in <xref rid="T8" ref-type="table">Table 8</xref>. The size of the data set and the complexity of the model are highly related to the training time. The sizes of BERT models are huge due to the training structure and large corpus compared to the naïve Bayes models, as shown in <xref rid="T8" ref-type="table">Table 8</xref>. The naïve Bayes model sizes include both vectorizer and classifier.</p>
        <table-wrap position="float" id="T8">
          <label>Table 8.</label>
          <caption>
            <p>Training time and size of the naïve Bayes and BERT models trained on the LLPS and MGI data sets</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th valign="bottom" align="left" rowspan="1" colspan="1"/>
                <th valign="bottom" align="left" rowspan="1" colspan="1"/>
                <th valign="bottom" colspan="4" align="center" rowspan="1">Model name</th>
              </tr>
              <tr>
                <th valign="bottom" align="left" rowspan="1" colspan="1"/>
                <th valign="bottom" align="left" rowspan="1" colspan="1"/>
                <th valign="bottom" colspan="2" align="center" rowspan="1">Naïve Bayes</th>
                <th valign="bottom" colspan="2" align="center" rowspan="1">BERT</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">Data set name</td>
                <td align="left" rowspan="1" colspan="1">Data set size</td>
                <td align="left" rowspan="1" colspan="1">Training time</td>
                <td align="left" rowspan="1" colspan="1">Model size</td>
                <td align="left" rowspan="1" colspan="1">Training time</td>
                <td align="left" rowspan="1" colspan="1">Model size</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">LLPS</td>
                <td align="left" rowspan="1" colspan="1">300 * 2</td>
                <td align="left" rowspan="1" colspan="1">0.32 s</td>
                <td align="left" rowspan="1" colspan="1">1.1 MB</td>
                <td align="left" rowspan="1" colspan="1">18 min 45 s</td>
                <td align="left" rowspan="1" colspan="1">1.3 GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">MGI</td>
                <td align="left" rowspan="1" colspan="1">12 744 * 2</td>
                <td align="left" rowspan="1" colspan="1">9.34 s</td>
                <td align="left" rowspan="1" colspan="1">13 MB</td>
                <td align="left" rowspan="1" colspan="1">12 h 56 min 12 s</td>
                <td align="left" rowspan="1" colspan="1">1.3 GB</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
    </sec>
    <sec id="s3-s4">
      <title>Personalized search</title>
      <p>The system provides a personalized search feature. Users can search articles’ content and have the results sorted according to their classifier. This allows for better search results because the system already knows which topics are relevant to the user without having to explicitly narrow down the search query. The search pipeline is illustrated in <xref rid="F2" ref-type="fig">Figure 2(c)</xref>. Instead of querying an online service (such as PubMed) for every search request, which slows down the search, the design is centered on a DB storing all fetched articles. Searching is done on a local search index. The index is updated regularly with new publications.</p>
    </sec>
  </sec>
  <sec id="s4">
    <title>Conclusion and future work</title>
    <p>We have developed a web-based article recommender service which can be accessed at <ext-link xlink:href="https://emati.biotec.tu-dresden.de" ext-link-type="uri">https://emati.biotec.tu-dresden.de</ext-link>. It displays a weekly updated list of articles based on the users’ profile and sends it to users’ emails on a weekly basis. It has also a personalized search feature to search online services’ (such as PubMed and arXiv) content and have the results sorted by the user’s classifier. The potential users of the recommender system are scientific researchers who want to keep up-to-date with the scientific literature. For example, model organism DB curators who read the currently published relevant articles, extract useful information and place that information into searchable DBs are potential users to highly benefit from the system. In addition, the system also might be useful for PhD students, postdoctoral researchers or principal investigators who want to follow current literature related to their research interests, as well as research group members who want to present current articles in the journal club.</p>
    <p>The system contains a content-based recommender using supervised machine learning to classify articles as ‘relevant’ and ‘irrelevant’ to the user. Two different supervised learning approaches, namely the naïve Bayes model with TF-IDF vectorizer and the state-of-the-art language model BERT, have been implemented. The training performance of naïve Bayes models trained on small data sets was higher than that of fine-tuned BERT models. On the other hand, BERT models showed outstanding recommendation performance in the experiments using test data sets from model organism DBs. Due to the need for scalability, the currently deployed version of Emati is based on the TF-IDF vectorizer and the naïve Bayes classifier approach. The BERT fine-tuning implementation is also available as an option in the source code which is provided at <ext-link xlink:href="https://github.com/bioinfcollab/emati" ext-link-type="uri">https://github.com/bioinfcollab/emati</ext-link>.</p>
    <p>Currently, the system sources new content from PubMed and arXiv. In the future, it could still be extended by incorporating even more additional services as sources.</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We are very grateful to Steven Marygold from FlyBase, Douglas G. Howe and Leyla Ruzicka from ZFIN and Martin Ringwald and Cynthia Smith from MGI for their valuable feedback on this study.</p>
  </ack>
  <sec id="s5">
    <title>Funding</title>
    <p>Federal Ministry of Education and Research project Center for Scalable Data Analytics and Artificial Intelligence.</p>
  </sec>
  <sec id="s6">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="R1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sugiyama</surname><given-names>K.</given-names></string-name> and <string-name><surname>Kan</surname><given-names>M.Y.</given-names></string-name></person-group> (<year>2015</year>) <article-title>A comprehensive evaluation of scholarly paper recommendation using potential citation papers</article-title>. <source><italic toggle="yes">Int. J. Digit. Libr.</italic></source>, <volume>16</volume>, <fpage>91</fpage>–<lpage>109</lpage>.</mixed-citation>
    </ref>
    <ref id="R2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lops</surname><given-names>P.</given-names></string-name>, <string-name><surname>Jannach</surname><given-names>D.</given-names></string-name>, <string-name><surname>Musto</surname><given-names>C.</given-names></string-name></person-group><etal>et al.</etal> (<year>2019</year>) <article-title>Trends in content-based recommendation</article-title>. <source><italic toggle="yes">User Model. User-Adapt. Interact.</italic></source>, <volume>29</volume>, <fpage>239</fpage>–<lpage>249</lpage>.</mixed-citation>
    </ref>
    <ref id="R3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haruna</surname><given-names>K.</given-names></string-name>, <string-name><surname>Ismail</surname><given-names>M.A.</given-names></string-name>, <string-name><surname>Damiasih</surname><given-names>D.</given-names></string-name></person-group><etal>et al.</etal> (<year>2017</year>). <article-title>A collaborative approach for research paper recommender system</article-title>. <source><italic toggle="yes">PLoS ONE</italic></source>, <volume>12</volume>, <page-range>e0184516</page-range>.</mixed-citation>
    </ref>
    <ref id="R4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Z.P.</given-names></string-name>, <string-name><surname>Li</surname><given-names>L.N.</given-names></string-name> and <string-name><surname>Yu</surname><given-names>H.Y.</given-names></string-name></person-group> (<year>2013</year>) <article-title>A hybrid document recommender algorithm based on random walk</article-title>. <source><italic toggle="yes">Appl. Mech. Mater.</italic></source>, <volume>336</volume>, <fpage>2270</fpage>–<lpage>2276</lpage>.</mixed-citation>
    </ref>
    <ref id="R5">
      <label>5.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Kanakia</surname><given-names>A.</given-names></string-name>, <string-name><surname>Eide</surname><given-names>D.</given-names></string-name>, <string-name><surname>Shen</surname><given-names>Z.</given-names></string-name></person-group><etal>et al.</etal> (<year>2019</year>) <article-title>A scalable hybrid research paper recommender system for Microsoft academic</article-title>. In: <conf-name>The Web Conference 2019—Proceedings of the World Wide Web Conference, WWW 2019. San Francisco, CA, USA</conf-name>.</mixed-citation>
    </ref>
    <ref id="R6">
      <label>6.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Sugiyama</surname><given-names>K.</given-names></string-name>, <string-name><surname>Hatano</surname><given-names>K.</given-names></string-name> and <string-name><surname>Yoshikawa</surname><given-names>M.</given-names></string-name></person-group> (<year>2004</year>) <article-title>Adaptive Web search based on user profile constructed without any effort from users</article-title>. In: <conf-name>Thirteenth International World Wide Web Conference Proceedings, WWW 2004. New York, NY, USA</conf-name>.</mixed-citation>
    </ref>
    <ref id="R7">
      <label>7.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Musto</surname><given-names>C.</given-names></string-name></person-group> (<year>2010</year>) <article-title>Enhanced vector space models for content-based recommender systems</article-title>. In: <conf-name>RecSys’10 - Proceedings of the 4th ACM Conference on Recommender Systems</conf-name>, <conf-loc>Barcelona, Spain</conf-loc>.</mixed-citation>
    </ref>
    <ref id="R8">
      <label>8.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Ferrara</surname><given-names>F.</given-names></string-name>, <string-name><surname>Pudota</surname><given-names>N.</given-names></string-name> and <string-name><surname>Tasso</surname><given-names>C.</given-names></string-name></person-group> (<year>2011</year>) <article-title>A keyphrase-based paper recommender system</article-title>. In: <conf-name>Italian Research Conference on Digital Libraries</conf-name>, <conf-loc>Pisa, Italy</conf-loc>, pp. <fpage>14</fpage>–<lpage>25</lpage>.</mixed-citation>
    </ref>
    <ref id="R9">
      <label>9.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Beel</surname><given-names>J.</given-names></string-name>, <string-name><surname>Langer</surname><given-names>S.</given-names></string-name>, <string-name><surname>Gipp</surname><given-names>B.</given-names></string-name></person-group><etal>et al.</etal> (<year>2014</year>) <article-title>The architecture and datasets of Docear’s research paper recommender system</article-title>. <italic toggle="yes">D-Lib Magazine</italic>, vol. 20.</mixed-citation>
    </ref>
    <ref id="R10">
      <label>10.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Jomsri</surname><given-names>P.</given-names></string-name>, <string-name><surname>Sanguansintukul</surname><given-names>S.</given-names></string-name> and <string-name><surname>Choochaiwattana</surname><given-names>W.</given-names></string-name></person-group> (<year>2010</year>) <article-title>A framework for tag-based research paper recommender system: an IR approach</article-title>. In: <conf-name>24th IEEE International Conference on Advanced Information Networking and Applications Workshops, WAINA 2010</conf-name>. <conf-loc>Perth, WA, Australia</conf-loc>.</mixed-citation>
    </ref>
    <ref id="R11">
      <label>11.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Gautam</surname><given-names>J.</given-names></string-name> and <string-name><surname>Kumar</surname><given-names>E.</given-names></string-name></person-group> (<year>2012</year>) <article-title>An improved framework for tag-based academic information sharing and recommendation system</article-title>. <source><italic toggle="yes">World Congress on Engineering</italic></source><conf-loc>London, U.K.</conf-loc><conf-date>July 4 - 6, 2012</conf-date>.</mixed-citation>
    </ref>
    <ref id="R12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>White</surname><given-names>H.D.</given-names></string-name></person-group> (<year>2018</year>) <article-title>Bag of works retrieval: TF*IDF weighting of works co-cited with a seed</article-title>. <source><italic toggle="yes">Int. J. Digit. Libr.</italic></source>, <volume>19</volume>, <fpage>139</fpage>–<lpage>49</lpage>.</mixed-citation>
    </ref>
    <ref id="R13">
      <label>13.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bulut</surname><given-names>B.</given-names></string-name><string-name><surname>Gündoğan</surname><given-names>E.</given-names></string-name><string-name><surname>Kaya</surname><given-names>B.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <part-title>User’s Research Interests Based Paper Recommendation System: A Deep Learning Approach</part-title> In: <person-group person-group-type="editor"><string-name><surname>Kaya</surname><given-names>M</given-names></string-name>, <string-name><surname>Birinci</surname><given-names>Ş</given-names></string-name>, <string-name><surname>Kawash,</surname><given-names>J</given-names></string-name> and <string-name><surname>Alhajj</surname><given-names>Reda</given-names></string-name></person-group> (eds.) <source><italic toggle="yes">Putting Social Media and Networking Data in Practice for Education, Planning, Prediction and Recommendation</italic></source>. <publisher-name>Springer, Cham</publisher-name>, pp. <fpage>117</fpage>–<lpage>130</lpage>.</mixed-citation>
    </ref>
    <ref id="R14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>W.</given-names></string-name>, <string-name><surname>Yoshida</surname><given-names>T.</given-names></string-name> and <string-name><surname>Tang</surname><given-names>X.</given-names></string-name></person-group> (<year>2011</year>) <article-title>A comparative study of TF*IDF, LSI and multi-words for text classification</article-title>. <source><italic toggle="yes">Expert Syst. Appl.</italic></source>, <volume>38</volume>, <fpage>2758</fpage>–<lpage>65</lpage>.</mixed-citation>
    </ref>
    <ref id="R15">
      <label>15.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Kenter</surname><given-names>T.</given-names></string-name> and <string-name><surname>Rijke</surname><given-names>M.D.</given-names></string-name></person-group> (<year>2015</year>) <article-title>Short text similarity with word embeddings categories and subject descriptors</article-title>. In: <conf-name>Proceedings of the 24th ACM International on Conference on Information and Knowledge Management (CIKM 2015)</conf-name>. <conf-loc>Melbourne, Australia</conf-loc>.</mixed-citation>
    </ref>
    <ref id="R16">
      <label>16.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Albitar</surname><given-names>S.</given-names></string-name>, <string-name><surname>Fournier</surname><given-names>S.</given-names></string-name> and <string-name><surname>Espinasse</surname><given-names>B.</given-names></string-name></person-group> (<year>2014</year>) <article-title>An effective TF/IDF-based text-to-text semantic similarity measure for text classification</article-title><source><italic toggle="yes">Web Information System Engineering</italic></source><conf-loc>Thessaloniki, Greece</conf-loc><conf-date>12-14 October 2014</conf-date>.</mixed-citation>
    </ref>
    <ref id="R17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chaudhuri</surname><given-names>A.</given-names></string-name>, <string-name><surname>Sinhababu</surname><given-names>N.</given-names></string-name>, <string-name><surname>Sarma</surname><given-names>M.</given-names></string-name></person-group><etal>et al.</etal> (<year>2021</year>) <article-title>Hidden features identification for designing an efficient research article recommendation system</article-title>. <source><italic toggle="yes">Int. J. Digit. Libr.</italic></source>, <volume>22</volume>, <fpage>233</fpage>–<lpage>4</lpage>.</mixed-citation>
    </ref>
    <ref id="R18">
      <label>18.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Hao</surname><given-names>L.</given-names></string-name>, <string-name><surname>Liu</surname><given-names>S.</given-names></string-name> and <string-name><surname>Pan</surname><given-names>L.</given-names></string-name></person-group> (<year>2021</year>) <article-title>Paper recommendation based on author-paper interest and graph structure</article-title>. In: <conf-name>Proceedings of the 2021 IEEE 24th International Conference on Computer Supported Cooperative Work in Design, CSCWD, 2021. Dalian, China</conf-name>.</mixed-citation>
    </ref>
    <ref id="R19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Devlin</surname><given-names>J.</given-names></string-name>, <string-name><surname>Chang</surname><given-names>M.W.</given-names></string-name>, <string-name><surname>Lee</surname><given-names>K.</given-names></string-name></person-group><etal>et al.</etal> (<year>2018</year>) <article-title>BERT: pre-training of deep bidirectional transformers for language understanding</article-title>. arXiv preprint arXiv:1810.04805.</mixed-citation>
    </ref>
    <ref id="R20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peters</surname><given-names>M.E.</given-names></string-name>, <string-name><surname>Neumann</surname><given-names>M.</given-names></string-name>, <string-name><surname>Iyyer</surname><given-names>M.</given-names></string-name></person-group><etal>et al.</etal> (<year>2018</year>) <article-title>Deep contextualized word representations</article-title>. arXiv preprint arXiv:1802.05365, <page-range>12</page-range>.</mixed-citation>
    </ref>
    <ref id="R21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brown</surname><given-names>T.</given-names></string-name>, <string-name><surname>Mann</surname><given-names>B.</given-names></string-name>, <string-name><surname>Ryder</surname><given-names>N.</given-names></string-name></person-group><etal>et al.</etal> (<year>2020</year>) <article-title>Language models are few-shot learners</article-title>. <source><italic toggle="yes">Adv. Neural Inf. Process. Syst.</italic></source>, <volume>33</volume>, <fpage>1877</fpage>–<lpage>1901</lpage>.</mixed-citation>
    </ref>
    <ref id="R22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jeong</surname><given-names>C.</given-names></string-name>, <string-name><surname>Jang</surname><given-names>S.</given-names></string-name>, <string-name><surname>Park</surname><given-names>E.</given-names></string-name></person-group><etal>et al.</etal> (<year>2020</year>) <article-title>A context-aware citation recommendation model with BERT and graph convolutional networks</article-title>. <source><italic toggle="yes">Scientometrics</italic></source>, <volume>124</volume>, <fpage>1907</fpage>–<lpage>1922</lpage>.</mixed-citation>
    </ref>
    <ref id="R23">
      <label>23.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>F.</given-names></string-name>, <string-name><surname>Liu</surname><given-names>J.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>J.</given-names></string-name></person-group><etal>et al.</etal> (<year>2019</year>) <article-title>BERT4Rec: sequential recommendation with bidirectional encoder representations from transformer</article-title> In: <conf-name>Proceedings of the 28th ACM International Conference on Information and Knowledge Management</conf-name>. <conf-loc>Beijing, China</conf-loc>.</mixed-citation>
    </ref>
    <ref id="R24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Beel</surname><given-names>J.</given-names></string-name>, <string-name><surname>Gipp</surname><given-names>B.</given-names></string-name>, <string-name><surname>Langer</surname><given-names>S.</given-names></string-name></person-group><etal>et al.</etal> (<year>2016</year>) <article-title>Research-paper recommender systems: a literature survey</article-title>. <source><italic toggle="yes">Int. J. Digit. Libr.</italic></source>, <volume>17</volume>, <fpage>305</fpage>–<lpage>338</lpage>.</mixed-citation>
    </ref>
    <ref id="R25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Beltagy</surname><given-names>I.</given-names></string-name>, <string-name><surname>Lo</surname><given-names>K.</given-names></string-name> and <string-name><surname>Cohan</surname><given-names>A.</given-names></string-name></person-group> (<year>2019</year>) <article-title>SciBERT: a pretrained language model for scientific text</article-title>. arXiv preprint arXiv:1903.10676.</mixed-citation>
    </ref>
    <ref id="R26">
      <label>26.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Gingstad</surname><given-names>K.</given-names></string-name>, <string-name><surname>Jekteberg</surname><given-names>Ø.</given-names></string-name> and <string-name><surname>Balog</surname><given-names>K.</given-names></string-name></person-group> (<year>2020</year>) <article-title>ArXivDigest: a living lab for personalized scientific literature recommendation</article-title>. In: <conf-name>Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</conf-name>. <conf-loc>Virtual Event Ireland</conf-loc>.</mixed-citation>
    </ref>
    <ref id="R27">
      <label>27.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Kelleher</surname><given-names>J.D.</given-names></string-name>, <string-name><surname>Namee</surname><given-names>B.M.</given-names></string-name> and <string-name><surname>D’Arcy</surname><given-names>A.</given-names></string-name></person-group> (<year>2015</year>) <source><italic toggle="yes">Fundamentals of machine learning for predictive data analytics</italic></source> (<publisher-name>MIT press</publisher-name>) <page-range>624</page-range>.</mixed-citation>
    </ref>
    <ref id="R28">
      <label>28.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Zhu</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Kiros</surname><given-names>R.</given-names></string-name>, <string-name><surname>Zemel</surname><given-names>R.</given-names></string-name></person-group><etal>et al.</etal> (<year>2015</year>) <article-title>Aligning books and movies: towards story-like visual explanations by watching movies and reading books</article-title>. In: <conf-name>Proceedings of the IEEE International Conference on Computer Vision</conf-name>. <conf-loc>Santiago, Chile</conf-loc>, pp. <fpage>19</fpage>–<lpage>27</lpage>.</mixed-citation>
    </ref>
    <ref id="R29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Westergaard</surname><given-names>D.</given-names></string-name>, <string-name><surname>Stærfeldt</surname><given-names>H.H.</given-names></string-name>, <string-name><surname>Tønsberg</surname><given-names>C.</given-names></string-name></person-group><etal>et al.</etal> (<year>2018</year>) <article-title>A comprehensive and quantitative comparison of text-mining in 15 million full-text articles versus their corresponding abstracts</article-title>. <source><italic toggle="yes">PLoS Comput. Biol.</italic></source>, <volume>14</volume>, <page-range>e1005962</page-range>.</mixed-citation>
    </ref>
    <ref id="R30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Q.</given-names></string-name>, <string-name><surname>Peng</surname><given-names>X.</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y.</given-names></string-name></person-group><etal>et al.</etal> (<year>2020</year>) <article-title>LLPSDB: a database of proteins undergoing liquid-liquid phase separation in vitro</article-title>. <source><italic toggle="yes">Nucleic Acids Res.</italic></source>, <volume>48</volume>, <fpage>D320</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">31906602</pub-id></mixed-citation>
    </ref>
    <ref id="R31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>You</surname><given-names>K.</given-names></string-name>, <string-name><surname>Huang</surname><given-names>Q.</given-names></string-name>, <string-name><surname>Yu</surname><given-names>C.</given-names></string-name></person-group><etal>et al.</etal> (<year>2020</year>) <article-title>PhaSepDB: A database of liquid-liquid phase separation related proteins</article-title>. <source><italic toggle="yes">Nucleic Acids Res.</italic></source>, <volume>48</volume>, <fpage>D354</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">31584089</pub-id></mixed-citation>
    </ref>
    <ref id="R32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mészáros</surname><given-names>B.</given-names></string-name>, <string-name><surname>Erdos</surname><given-names>G.</given-names></string-name>, <string-name><surname>Szabó</surname><given-names>B.</given-names></string-name></person-group><etal>et al.</etal> (<year>2020</year>) <article-title>PhaSePro: the database of proteins driving liquid-liquid phase separation</article-title>. <source><italic toggle="yes">Nucleic Acids Res.</italic></source>, <volume>48</volume>, <fpage>D360</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">31612960</pub-id></mixed-citation>
    </ref>
    <ref id="R33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ning</surname><given-names>W.</given-names></string-name>, <string-name><surname>Guo</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Lin</surname><given-names>S.</given-names></string-name></person-group><etal>et al.</etal> (<year>2020</year>) <article-title>DrLLPS: a data resource of liquid-liquid phase separation in eukaryotes</article-title>. <source><italic toggle="yes">Nucleic Acids Res.</italic></source>, <volume>48</volume>, <fpage>D288</fpage>–<lpage>95</lpage>.<pub-id pub-id-type="pmid">31691822</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
