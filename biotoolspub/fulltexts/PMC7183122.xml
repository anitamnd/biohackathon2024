<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Genomics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Genomics</journal-id>
    <journal-title-group>
      <journal-title>BMC Genomics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2164</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7183122</article-id>
    <article-id pub-id-type="publisher-id">6693</article-id>
    <article-id pub-id-type="doi">10.1186/s12864-020-6693-y</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Methodology Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A cost-sensitive online learning method for peptide identification</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6991-7162</contrib-id>
        <name>
          <surname>Liang</surname>
          <given-names>Xijun</given-names>
        </name>
        <address>
          <email>liangxijunsd@163.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xia</surname>
          <given-names>Zhonghang</given-names>
        </name>
        <address>
          <email>zhonghang.xia@wku.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jian</surname>
          <given-names>Ling</given-names>
        </name>
        <address>
          <email>bebetter@upc.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Yongxiang</given-names>
        </name>
        <address>
          <email>wangyongxiang2018@163.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Niu</surname>
          <given-names>Xinnan</given-names>
        </name>
        <address>
          <email>xinnan.niu@vumc.org</email>
        </address>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Link</surname>
          <given-names>Andrew J.</given-names>
        </name>
        <address>
          <email>andrew.link@vanderbilt.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1798 1132</institution-id><institution-id institution-id-type="GRID">grid.497420.c</institution-id><institution>College of Science, China University of Petroleum, </institution></institution-wrap>Changjiang West Road, Qingdao, 266580 China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2286 2224</institution-id><institution-id institution-id-type="GRID">grid.268184.1</institution-id><institution>School of Engineering and Applied Science, Western Kentucky University, </institution></institution-wrap>Bowling Green, 42101 KY USA </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1798 1132</institution-id><institution-id institution-id-type="GRID">grid.497420.c</institution-id><institution>School of Economics and Management, China University of Petroleum, </institution></institution-wrap>Changjiang West Road, Qingdao, 266580 China </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2264 7217</institution-id><institution-id institution-id-type="GRID">grid.152326.1</institution-id><institution>Dept. of Pathology, Microbiology and Immunology, Vanderbilt University School of Medicine, </institution></institution-wrap>Nashville, 37232 TN USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>25</day>
      <month>4</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>25</day>
      <month>4</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>21</volume>
    <elocation-id>324</elocation-id>
    <history>
      <date date-type="received">
        <day>27</day>
        <month>7</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>24</day>
        <month>3</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Post-database search is a key procedure in peptide identification with tandem mass spectrometry (MS/MS) strategies for refining peptide-spectrum matches (PSMs) generated by database search engines. Although many statistical and machine learning-based methods have been developed to improve the accuracy of peptide identification, the challenge remains on large-scale datasets and datasets with a distribution of unbalanced PSMs. A more efficient learning strategy is required for improving the accuracy of peptide identification on challenging datasets. While complex learning models have larger power of classification, they may cause overfitting problems and introduce computational complexity on large-scale datasets. Kernel methods map data from the sample space to high dimensional spaces where data relationships can be simplified for modeling.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">In order to tackle the computational challenge of using the kernel-based learning model for practical peptide identification problems, we present an online learning algorithm, OLCS-Ranker, which iteratively feeds only one training sample into the learning model at each round, and, as a result, the memory requirement for computation is significantly reduced. Meanwhile, we propose a cost-sensitive learning model for OLCS-Ranker by using a larger loss of decoy PSMs than that of target PSMs in the loss function.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">The new model can reduce its false discovery rate on datasets with a distribution of unbalanced PSMs. Experimental studies show that OLCS-Ranker outperforms other methods in terms of accuracy and stability, especially on datasets with a distribution of unbalanced PSMs. Furthermore, OLCS-Ranker is 15–85 times faster than CRanker.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Peptide identification</kwd>
      <kwd>Mass spectrometry</kwd>
      <kwd>Classification</kwd>
      <kwd>Support vector machines</kwd>
      <kwd>Online learning</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution> National Natural Science Foundation of China</institution>
        </funding-source>
        <award-id>61503412</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>61873279</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Key Technology Research and Development Program of Shandong (CN)</institution>
        </funding-source>
        <award-id>2018GSF120020</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>National Science and Technology Major Project of China</institution>
        </funding-source>
        <award-id>2016ZX05011-001-003</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
            <institution>National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>GM64779, HL68744, ES11993, and CA098131</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>National Institutes of Health (US)</institution>
        </funding-source>
        <award-id>GM64779, HL68744, ES11993, and CA098131</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution> WKU RCAP Grant </institution>
        </funding-source>
        <award-id>No. 20-8032</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Natural Science Foundation of Shandong Province (CN)</institution>
        </funding-source>
        <award-id>ZR2019MA016</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100012226</institution-id>
            <institution>Fundamental Research Funds for the Central Universities</institution>
          </institution-wrap>
        </funding-source>
        <award-id>19CX05027B</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2020</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p>Tandem mass spectrometry (MS/MS)-based strategies are presently the method of choice for large-scale protein identification due to its high-throughput analysis of biological samples. With database sequence searching method, a huge number of peptide spectra generated from MS/MS experiments are routinely searched by using a search engine, such as SEQUEST, MASCOT or X!TANDEM, against theoretical fragmentation spectra derived from target databases or experimentally observed spectra for peptide-spectrum match (PSM). However, most of these PSMs are not correct [<xref ref-type="bibr" rid="CR1">1</xref>]. A number of computational methods and error rate estimation procedures after database search have been proposed to improve the identification accuracy of target PSMs[<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>].</p>
    <p>Recently, advanced statistical and machine learning approaches have been studied for better identification accuracy in the post-database search. PeptideProphet [<xref ref-type="bibr" rid="CR4">4</xref>] and Percolator [<xref ref-type="bibr" rid="CR5">5</xref>] are two popular ones among those machine learning-based tools. PeptideProphet employs the expectation maximization method to compute the probabilities of correct and incorrect PSM, based on the assumption that the PSM data are drawn from a mixture of the Gaussian distribution and the Gamma distribution which generate samples of the correct and incorrect PSMs. Several works have extended the PeptideProphet method to improve its performance. Particularly, decoy PSMs were incorporated into a mixture probabilistic model in [<xref ref-type="bibr" rid="CR6">6</xref>] at the estimation step of the expectation maximization. An adaptive method described in [<xref ref-type="bibr" rid="CR7">7</xref>] iteratively learned a new discriminant function from the training set. Moreover, a Bayesian nonparametric (BNP) model was presented in [<xref ref-type="bibr" rid="CR8">8</xref>] to replace the probabilistic distribution used in PeptideProphet for calculating the posterior probability. A similar BNP model [<xref ref-type="bibr" rid="CR9">9</xref>] was also applied to MASCOT search results. Percolator starts the learning process with a small set of trusted correct PSMs and decoy PSMs, and it iteratively adjusts its learning model to fit the dataset. Percolator ranks the PSMs according to its confidence on them. Some works [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR11">11</xref>] have also extended Percolator to deal with large-scale datasets.</p>
    <p>In fact, Percolator is a typical method of supervised learning. With given knowledge (labeled data), supervised learning can train a model with labeled data and uses it to get an accurate prediction on unlabeled data. In [<xref ref-type="bibr" rid="CR12">12</xref>], a fully supervised method is proposed to improve the performance of Percolator. Two types of discriminant functions, linear functions and two-layer neural networks, are compared. The two-layer neural networks is a nonlinear discriminant function which adds lots of parameters of hidden units. As expected, it achieves better identification performance than the model with linear discriminant function [<xref ref-type="bibr" rid="CR12">12</xref>]. Besides, the work in [<xref ref-type="bibr" rid="CR13">13</xref>] used a generative model, Deep Belief Networks, to improve the identification.</p>
    <p>In supervised learning, kernel functions have been widely used to map data from the sample space to high dimensional spaces where data with non-linear relationships can be classified by linear models. With the kernel-based support vector machine (SVM), CRanker [<xref ref-type="bibr" rid="CR14">14</xref>] has shown significantly better performance than linear models. Although kernel-based post-database searching approaches have improved the accuracy of peptide identification, two big challenges remain in practical implementation of kernel-based methods: (1) The performance of the algorithms degrades on the datasets with a distribution of unbalanced PSMs, in which case some datasets contain an extremely large proportion of false positives. We call them <italic>“hard dataset”</italic> as most post-database search methods degrade their performances on these datasets; (2) Scalability problems in both memory use and computational time are still barriers for kernel-based algorithms on large-scale datasets. Kernel-based batch learning algorithms need to load the entire kernel matrix into memory, and thus the memory requirement can be very intense during the training process.</p>
    <p>In some extent, the above challenges also exists in other post-database searching methods. A number of recent works are related to the two challenges. The methods of data fusion [<xref ref-type="bibr" rid="CR15">15</xref>–<xref ref-type="bibr" rid="CR18">18</xref>] integrate different sources of auxiliary information, alleviated the challenge of “hard datasets”. Moreover, cloud computing platform is used in [<xref ref-type="bibr" rid="CR19">19</xref>] to tackle the intense memory and computation requirement for mass spectrometry-based proteomics analysis using the Trans-Proteomic Pipeline (TPP). Existing researches either integrated extensive biological information or leveraged hardware support to overcome the challenges.</p>
    <p>In this work, we develop an online classification algorithm to tackle the two challenges in kernel-based methods. For the challenge of “hard dataset”, we extend CRanker [<xref ref-type="bibr" rid="CR14">14</xref>] model to a cost-sensitive Ranker (CS-Ranker) by using different loss functions for decoy and target PSMs respectively. The CS-Ranker model gives a larger penalty for wrongly selecting decoy PSMs than that for target PSMs, which reduces the model’s false discovery rate while increases its true positive rate. For the challenge of scalability problems, we design an online algorithm for CS-Ranker (OLCS-Ranker) which trains PSM data samples one by one and uses an active set to keep only those PSMs effective to the discriminant function. As a result, memory requirement and total training time can be dramatically reduced. Moreover, the training model is less prone to converging to poor local minima, avoiding extremely bad identification results.</p>
    <p>In addition, we calibrate the quality of OLCS-Ranker outputs by using the entrapment sequences obtained from “Pfu” dataset published in [<xref ref-type="bibr" rid="CR20">20</xref>]. Although the target-decoy strategy has become a mainstream method for the quality control in peptide identification, it cannot directly evaluate the false positive matches in identified PSMs. We aim to use the entrapment sequence method as an alternative of target-decoy strategy in the assessment of OLCS-Ranker [<xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR22">22</xref>].</p>
    <p>Experimental studies have shown that OLCS-Ranker not only outperformed Percolator and CRanker in terms of accuracy and stability, especially on hard datasets, but also reported evidently more target PSMs than those reported by Percolator on about half of datasets. Also, OLCS-Ranker is 15∼85 times faster on large datasets than the kernel-based baseline method, CRanker.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <sec id="Sec3">
      <title>Experimental setup</title>
      <p>To evaluate the OLCS-Ranker algorithm, we used six LC/MS/MS datasets generated from a variety of biological and control protein samples and different mass spectrometers to minimize the bias caused by the sample, type of mass spectrometer, or mass spectrometry method. Specifically, the datasets include universal proteomics standard set (Ups1), the <italic>S.cerevisiae</italic> Gcn4 affinity-purified complex (Yeast), <italic>S.cerevisiae</italic> transcription complexes using the Tal08 minichromosome (Tal08 and Tal08-large) and Human Peripheral Blood Mononuclear Cells (PBMC datasets). There are two PBMC sample datasets which were analyzed with the LTQ-Orbitrap Velos with MiPS (Velos-mips) and MiPS-off (Velos-nomips) respectively. All PSMs were assigned by the SEQUEST search engine. Refer to [<xref ref-type="bibr" rid="CR23">23</xref>] for the details of the sample preparation and LC/MS/MS analysis.</p>
      <p>We converted the SEQUEST outputs from *.out format to Microsoft Excel format for OLCS-Ranker and removed all blank PSMs records if any. Statistics of the SEQUEST search results of the datasets are summarized in Table <xref rid="Tab1" ref-type="table">1</xref>.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Statistics of datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Total</th><th align="left">Target PSM</th><th align="left">Decoy PSM</th></tr></thead><tbody><tr><td align="left">Yeast</td><td align="left">14892</td><td align="left">6703</td><td align="left">8189</td></tr><tr><td align="left">Ups1</td><td align="left">17335</td><td align="left">8974</td><td align="left">8361</td></tr><tr><td align="left">Tal08</td><td align="left">18653</td><td align="left">9907</td><td align="left">8746</td></tr><tr><td align="left">Tal08-large</td><td align="left">69560</td><td align="left">42222</td><td align="left">27338</td></tr><tr><td align="left">Velos-mips</td><td align="left">301879</td><td align="left">208765</td><td align="left">93114</td></tr><tr><td align="left">Velos-nomips</td><td align="left">447350</td><td align="left">307549</td><td align="left">139801</td></tr></tbody></table></table-wrap>
</p>
      <p>A PSM record is represented by a vector of nine attributes: xcorr, deltacn, sprank, ions, hit mass, enzN, enzC, numProt, deltacnR. The first five attributes inherit from the SEQUEST algorithm and the last four attributes are defined as
<list list-type="bullet"><list-item><p>enzN: A boolean variable indicating whether the peptide is preceded by a tryptic site;</p></list-item><list-item><p>enzC: A boolean variable indicating whether the peptide has a tryptic C-terminus;</p></list-item><list-item><p>numProt: The number that the corresponding protein matches other PSMs;</p></list-item><list-item><p>deltacnR: deltacn/xcorr.</p></list-item></list></p>
      <p>Based on our observation, “xcorr” and “deltacn” played more important roles in identification of PSMs, and hence, we used 1.0 for the weights of the two features, and 0.5 for all others. Also, Gaussian kernel <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$k(x_{i},x_{j}) = \exp {(\frac {\|x_{i}-x_{j}\|^{2}}{2\sigma ^{2}})} $\end{document}</tex-math><mml:math id="M2"><mml:mi>k</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>exp</mml:mo><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq1.gif"/></alternatives></inline-formula> was chosen in this experimental study.</p>
      <p>The choice of parameters, <italic>C</italic><sub>1</sub>,<italic>C</italic><sub>2</sub>,<italic>σ</italic>, is a critical step in the use of OLCS-Ranker. We performed a 3-fold cross-validation and the values of parameters were chosen by maximizing the number of identified PSMs. Detailed cross-validation results could be found in Additional file <xref rid="MOESM2" ref-type="media">2</xref>. The PSMs were selected according to the calculated scores under FDR level 0.02 and 0.04, respectively, and FDR was computed using the following equation
<disp-formula id="Equa"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\text{FDR}= 2D/ (D+T), $$ \end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mtext>FDR</mml:mtext><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>D</mml:mi><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12864_2020_6693_Article_Equa.gif" position="anchor"/></alternatives></disp-formula> where <italic>D</italic> is the number of the spectra matched to decoy peptide sequences and <italic>T</italic> is the number of the PSMs matched to target peptide sequence. As the performance of OLCS-Ranker is not sensitive to the algorithm parameters, we constantly set <italic>M</italic>=1000, <italic>m</italic>=0.35|<italic>S</italic>|, where <italic>S</italic> is the active index set and |<italic>S</italic>| denotes its size, in this experimental study.</p>
      <p>OLCS-Ranker was implemented with Matlab R2015b. The source code can be download from https://github.com/Isaac-QiXing/CRanker. All experiments were implemented on a PC with Intel Core E5-2640 CPU 2.40GHz and 24Gb RAM.</p>
      <p>For comparison with PeptideProphet and Percolator, we followed the steps described in Trans Proteomic Pipeline (TPP) suite[<xref ref-type="bibr" rid="CR24">24</xref>] and [<xref ref-type="bibr" rid="CR10">10</xref>]. In PeptideProphet, we used the program MzXML2Search to extract the MS/MS spectra from the mzXML file, and the search outputs were converted to pep.XML format files with the TPP suite. In Percolator, we converted the SEQUEST outputs to a merged file in SQT format [<xref ref-type="bibr" rid="CR25">25</xref>, <xref ref-type="bibr" rid="CR26">26</xref>], and then transformed it to PIN format by sqt2pin integrated in Percolator suite[<xref ref-type="bibr" rid="CR10">10</xref>]. We used ’-N’ option of the “percolator” command to specify the number of training PSMs.</p>
    </sec>
    <sec id="Sec4">
      <title>Comparison with benchmark methods</title>
      <p>We compared OLCS-Ranker, PeptideProphet and Percolator on the six datasets in term of the numbers of validated PSMs at FDR =0.02 and FDR =0.04. The performance of a validation approach is better if it can validate more target PSMs than the other approach under the same FDR. Table <xref rid="Tab2" ref-type="table">2</xref> shows the number of validated PSMs and the ratio of this number to the total of each dataset. As we can see, OLCS-Ranker identified more PSMs on three datasets, similar numbers of PSMs on the other three datasets, compared with PeptideProphet or Percolator.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Number of PSMs output by PeptideProphet, Percolator, and OLCS-Ranker</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">Method</th><th align="left" colspan="3">FDR = 0.02</th><th align="left" colspan="3">FDR = 0.04</th></tr><tr><th align="left"/><th align="left"/><th align="left">Targets</th><th align="left">Decoys</th><th align="left">Ratio</th><th align="left">Targets</th><th align="left">Decoys</th><th align="left">Ratio</th></tr></thead><tbody><tr><td align="left">Yeast</td><td align="left">PepProphet</td><td align="left">1379</td><td align="left">13</td><td align="left">0.206</td><td align="left">1436</td><td align="left">29</td><td align="left">0.214</td></tr><tr><td align="left"/><td align="left">Percolator</td><td align="left">1225</td><td align="left">12</td><td align="left">0.183</td><td align="left">1366</td><td align="left">27</td><td align="left">0.204</td></tr><tr><td align="left"/><td align="left">OLCS-Ranker</td><td align="left">1374</td><td align="left">13</td><td align="left">0.205</td><td align="left">1467</td><td align="left">29</td><td align="left">0.219</td></tr><tr><td align="left">Ups1</td><td align="left">PepProphet</td><td align="left">506</td><td align="left">5</td><td align="left">0.056</td><td align="left">545</td><td align="left">11</td><td align="left">0.061</td></tr><tr><td align="left"/><td align="left">Percolator</td><td align="left">471</td><td align="left">4</td><td align="left">0.052</td><td align="left">554</td><td align="left">11</td><td align="left">0.062</td></tr><tr><td align="left"/><td align="left">OLCS-Ranker</td><td align="left">473</td><td align="left">4</td><td align="left">0.053</td><td align="left">528</td><td align="left">10</td><td align="left">0.059</td></tr><tr><td align="left">Tal08</td><td align="left">PepProphet</td><td align="left">911</td><td align="left">9</td><td align="left">0.092</td><td align="left">948</td><td align="left">20</td><td align="left">0.096</td></tr><tr><td align="left"/><td align="left">Percolator</td><td align="left">1036</td><td align="left">10</td><td align="left">0.105</td><td align="left">1059</td><td align="left">21</td><td align="left">0.107</td></tr><tr><td align="left"/><td align="left">OLCS-Ranker</td><td align="left">1140</td><td align="left">10</td><td align="left">0.115</td><td align="left">1156</td><td align="left">22</td><td align="left">0.117</td></tr><tr><td align="left">Tal08-large</td><td align="left">PepProphet</td><td align="left">14966</td><td align="left">152</td><td align="left">0.354</td><td align="left">15516</td><td align="left">317</td><td align="left">0.367</td></tr><tr><td align="left"/><td align="left">Percolator</td><td align="left">15793</td><td align="left">159</td><td align="left">0.374</td><td align="left">16164</td><td align="left">329</td><td align="left">0.383</td></tr><tr><td align="left"/><td align="left">OLCS-Ranker</td><td align="left">15706</td><td align="left">157</td><td align="left">0.372</td><td align="left">16078</td><td align="left">327</td><td align="left">0.381</td></tr><tr><td align="left">Velos-mips</td><td align="left">PepProphet</td><td align="left">116533</td><td align="left">1177</td><td align="left">0.558</td><td align="left">120080</td><td align="left">2450</td><td align="left">0.575</td></tr><tr><td align="left"/><td align="left">Percolator</td><td align="left">116046</td><td align="left">1172</td><td align="left">0.556</td><td align="left">120952</td><td align="left">2468</td><td align="left">0.579</td></tr><tr><td align="left"/><td align="left">OLCS-Ranker</td><td align="left">117084</td><td align="left">1182</td><td align="left">0.561</td><td align="left">120033</td><td align="left">2448</td><td align="left">0.575</td></tr><tr><td align="left">Velos-nomips</td><td align="left">PepProphet</td><td align="left">166790</td><td align="left">1684</td><td align="left">0.542</td><td align="left">173935</td><td align="left">3549</td><td align="left">0.566</td></tr><tr><td align="left"/><td align="left">Percolator</td><td align="left">165174</td><td align="left">1668</td><td align="left">0.537</td><td align="left">174361</td><td align="left">3558</td><td align="left">0.567</td></tr><tr><td align="left"/><td align="left">OLCS-Ranker</td><td align="left">170722</td><td align="left">1723</td><td align="left">0.555</td><td align="left">177007</td><td align="left">3611</td><td align="left">0.576</td></tr></tbody></table><table-wrap-foot><p>“Targets”: number of selected target PSMs; “Decoys”: number of selected decoy PSMs; “ratio”: the ratio of the number of selected target PSMs under FDR = 0.04 to the total number of target PSMs in the dataset; “PepProphet”: PeptideProphet</p></table-wrap-foot></table-wrap>
</p>
      <p>Compared with PeptideProphet, 25.1%, 4.9% and 2.4% more PSMs were identified by OLCS-Ranker at FDR =0.02 on Tal08, Tal08-large and Velos-nomips, respectively. Compared with Percolator, 12.2%, 10.0% and 3.4% more PSMs were identified by OLCS-Ranker at FDR =0.01 on Yeast, Tal08 and Velos-nomips, respectively. On Ups1 and Tal08-large OLCS-Ranker identified a similar number of PSMs to that of Percolator. The numbers of PSMs identified by the three methods on each dataset under FDR =0.04 are similar to those under FDR =0.02.</p>
      <p>We have also compared the overlapping of target PSMs identified by the three approaches as a PSM reported by multiple methods is more likely to be correct. Figure <xref rid="Fig1" ref-type="fig">1</xref> shows that the majority of validated PSMs by the three approaches overlaps, indicating high conference on the identified PSMs output by OLCS-Ranker. Particularly, on Yeast, the three approaches have 1197 PSMs in common, covers more than 86% of the total target PSMs identified by each of the algorithms. This ratio of common PSMs is 86% and 75% on Ups1 and Tal08, respectively, and more than 90% on Tal08-large, Velos-mips and Velos-nomips.
<fig id="Fig1"><label>Fig. 1</label><caption><p>Overlap of identified target PSMs by PeptideProphet, Percolator and OLCS-Ranker. PepProphet: PeptideProphet</p></caption><graphic xlink:href="12864_2020_6693_Fig1_HTML" id="MO1"/></fig>
</p>
      <p>Furthermore, the overlapping PSMs identified from OLCS-Ranker and each of PeptideProphet and Percolator is more than those overlapping PSMs identified from PeptideProphet and Percolator. On Yeast, besides the overlapping among three methods, OLCS-Ranker and PeptideProphet identified 128 PSMs in common and OLCS-Ranker and Percolator identified 25 PSMs in common. In contrast, PeptideProphet and Percolator have only 3 PSMs in common. Similar patterns occurred on other datasets.</p>
      <p>Not surprisingly, OLCS-Ranker validated more PSMs than other methods in most cases. For a closer look, we compared the outputs by OLCS-Ranker and Percolator on Velos-nomips in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. For visualization, we project PSMs in nine-dimensional sample space to a plane which can be seen, as shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. As we can see, the red dots are mainly distributed in the margin region, and they are mixed with decoy and other target PSMs. Percolator misclassified these red dots, OLCS-Ranker, however, has correctly identified them using nonlinear kernel. Similarly, we have observed this advantage of OLCS-Ranker on Yeast, Tal08 and Velos-mips datasets as well. These figures could be found in Additional file <xref rid="MOESM1" ref-type="media">1</xref>.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Distribution of identified PSMs by Percolator and OLCS-Ranker. The blue and yellow dots represent target and decoy PSMs, respectively, the cyan dots represent the target PSMs identified by Percolator (98.8% of them have also been identified by OLCS-Ranker), and the red dots represent the target PSMs identified by OLCS-Ranker only. The dotted line represents the linear classifier given by Percolator, and its margin region is defined by the region bounded by the two solid lines. The two-step projection is given as follows. Step 1. Rotate the sample space. Let 〈<italic>b</italic>,<italic>u</italic>〉+<italic>b</italic><sub>0</sub>=0 be the discriminant hyperplane trained by Percolator, with feature coefficients <italic>b</italic>=[<italic>b</italic><sub>1</sub>,⋯,<italic>b</italic><sub><italic>q</italic></sub>], intercept <italic>b</italic><sub>0</sub>, and number of features <italic>q</italic>. Let <italic>P</italic>∈<italic>R</italic><sup><italic>q</italic>×<italic>q</italic></sup> be orthogonal rotation matrix with <italic>w</italic>=[1,1,0,⋯,0]∈<italic>R</italic><sup><italic>q</italic></sup> such that <italic>P</italic><italic>w</italic>=<italic>b</italic>. Then the hyperplane after rotation is <inline-formula id="IEq2"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\langle P w,u \rangle + b_{0} = 0 \quad \Leftrightarrow \quad \langle w,P_{}^{T} u \rangle + b_{0} = 0 \quad \Leftrightarrow \quad \langle [1,\ 1], [x_{1},x_{2}] \rangle + b_{0} = 0 $\end{document}</tex-math><mml:math id="M6"><mml:mo>〈</mml:mo><mml:mtext mathvariant="italic">Pw</mml:mtext><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo>〉</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="1em"/><mml:mo>⇔</mml:mo><mml:mspace width="1em"/><mml:mo>〈</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mi>u</mml:mi><mml:mo>〉</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="1em"/><mml:mo>⇔</mml:mo><mml:mspace width="1em"/><mml:mo>〈</mml:mo><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mn>1</mml:mn><mml:mo>]</mml:mo><mml:mo>,</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>]</mml:mo><mml:mo>〉</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq2.gif"/></alternatives></inline-formula>, with <inline-formula id="IEq3"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$ P_{}^{T} u = [x_{1},\cdots, x_{q}]$\end{document}</tex-math><mml:math id="M8"><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3em"/><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq3.gif"/></alternatives></inline-formula>. PSM <italic>u</italic> in sample space <italic>R</italic><sup><italic>q</italic></sup> is rotated as <inline-formula id="IEq4"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$ P_{}^{T} u = [x_{1},\cdots, x_{q}]$\end{document}</tex-math><mml:math id="M10"><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3em"/><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq4.gif"/></alternatives></inline-formula>. Step 2. Project the rotated PSMs to a plane with the first two rotated coordinates <italic>x</italic><sub>1</sub> and <italic>x</italic><sub>2</sub> (two axes in the figure). The dotted line 〈[1, 1],[<italic>x</italic><sub>1</sub>,<italic>x</italic><sub>2</sub>]〉+<italic>b</italic><sub>0</sub>=0 is the linear classifier. 〈[1, 1],[<italic>x</italic><sub>1</sub>,<italic>x</italic><sub>2</sub>]〉+<italic>b</italic><sub>0</sub>=+1 and 〈[1, 1],[<italic>x</italic><sub>1</sub>,<italic>x</italic><sub>2</sub>]〉+<italic>b</italic><sub>0</sub>=−1 are the boundaries of the margin of the linear classifier</p></caption><graphic xlink:href="12864_2020_6693_Fig2_HTML" id="MO2"/></fig>
</p>
      <p>
        <bold>Hard datasets and normal datasets</bold>
      </p>
      <p>Note that in Table <xref rid="Tab2" ref-type="table">2</xref>, all the three approaches reported relatively low ratios of validated PSMs on Yeast, Ups1 and Tal08 dataset. As aforementioned, we call them “hard datasets”, in which a large proportion of incorrect PSMs usually increases the complexity of identification for any approach. Particularly, the ratios on Yeast, Ups1 and Tal08 are 0.204 ∼0.219, 0.05 ∼0.062, and 0.096 ∼0.117, respectively, while the ratios on the other datasets (“normal datasets”) are larger than 0.35.</p>
    </sec>
    <sec id="Sec5">
      <title>Model evaluation</title>
      <p>We used receiver operating characteristic (ROC) to compare the performances of OLCS-Ranker, PeptideProphet and Percolator. As shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, OLCS-Ranker reached highest TPRs among the three methods at most values of FPRs on all datasets. Compared with PeptideProphet, OLCS-CRanker reached significantly higher TPR levels on Tal08 and Tal08-large dataset. Compared with Percolator, OLCS-CRanker reached significantly higher TPR levels on Yeast, Tal08 and Velos-nomips dataset. On Velos-nomips, the TPR values of OLCS-Ranker were about 0.04 higher (i.e., about 8% more identified target PSMs) than that of Percolator with FPR levels from 0 to 0.02 (corresponding FDR levels from 0 to 0.07). In general, OLCS-Ranker outperformed PeptideProphet and Percolator in terms of the ROC curve.
<fig id="Fig3"><label>Fig. 3</label><caption><p>ROC curves. Relationship of TPR and FPR of the identified PSMs by PeptideProphet, Percolator and OLCS-Ranker. <bold>a</bold>. On Ups1; <bold>b</bold>. On Yeast; <bold>c</bold>. On Tal08; <bold>d</bold>. On Tal08-large; <bold>e</bold>. On Velos-mips; <bold>f</bold>. On Velos-nomips</p></caption><graphic xlink:href="12864_2020_6693_Fig3_HTML" id="MO3"/></fig>
</p>
      <p>We have also examined model overfitting by the ratio of identified PSMs in the test set to the number of the total identified PSMs (identified_test/identified_total) versus the ratio of the size of training set to the size of total dataset (|train set | / |total set |). As PeptideProphet does not use the supervised learning framework, we only compared OLCS-Ranker with Percolator and CRanker in this experiment. Assume that correct PSMs are identically distributed over the whole dataset. If neither underfitting nor overfitting occurs, then the ratio of identified_test/identified_total should be close to 1 - |train set |/ |total set |. For example, at |train set |/ |total set | =0.2, the expected ratio of identified_test/identified_total is 0.8. Particularly, the training sets and test sets were formed by randomly selecting PSMs from the original datasets according to the values of =0.1,0.2,⋯,0.8. For each value of train/total, we computed the mean value and the standard deviation of the ratios of identified_test/identified_total based on 30 times of running Percolator and OLCS-Ranker, and results were shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. As we can see, the identified_test/identified_total ratios reported by OLCS-Ranker are closer to the expected ratios than those of Percolator does on Yeast on Ups1. Take |train set |/ |total set | = 0.2 in Fig. <xref rid="Fig4" ref-type="fig">4</xref>a, as an example, in which 20%/80% of PSMs were used for training/testing, and the corresponding expected identified_test/identified_total ratio is 0.8. The actual identified_test/identified_total ratio of OLCS-Ranker is 0.773 with standard error 0.018, and 0.861 with standard error 0.043 by Percolator.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Identified_test/Identified_total versus |train set |/ |total set |. <italic>x</italic>-axis: train/total ratio, the ratio of the number of selected training PSMs to the total number of PSMs in the dataset; <italic>y</italic>-axis: test/total ratio, the ratio of the number of PSMs identified on the test set to the number of PSMs identified in the total dataset. The dotted line segment between (0,1) and (1,0) indicates the expected test/total ratios. <bold>a</bold>. On Yeast; <bold>b</bold>. On Ups1; <bold>c</bold>. On Tal08; <bold>d</bold>. On Tal08-large; <bold>e</bold>. On Velos-mips; <bold>f</bold>. On Velos-nomips</p></caption><graphic xlink:href="12864_2020_6693_Fig4_HTML" id="MO4"/></fig>
</p>
      <p>Due to the extraordinary running time of CRanker, we only compared OLCS-Ranker and CRanker at |train set |/ |total set | =2/3, and listed the results in Table <xref rid="Tab3" ref-type="table">3</xref>. Although CRanker showed the same ratios of identified_test/identified_total on normal datasets as OLCS-Ranker did, its ratios on hard dataset are less than the expected ratio, 1/3. While the identified_test/identified_total ratio of CRanker is 0.272 and 0.306 on Ups1 and Tal08 respectively, the ratio of OLCS-Ranker is 0.334 and 0.342, respectively. The results indicate that compared with CRanker, OLCS-Ranker overcomes the overfitting problem on hard datasets.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Comparing OLCS-Ranker with CRanker algorithm</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">Method</th><th align="left">#PSMs</th><th align="left"><inline-formula id="IEq5"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\frac {test}{total} $\end{document}</tex-math><mml:math id="M12"><mml:mfrac><mml:mrow><mml:mtext mathvariant="italic">test</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">total</mml:mtext></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq5.gif"/></alternatives></inline-formula></th><th align="left">RAM (Mb)</th><th align="left">time (s)</th></tr></thead><tbody><tr><td align="left">Yeast</td><td align="left">CRanker</td><td align="left">1386</td><td align="left">0.339</td><td align="left">1503.6</td><td align="left">667.8</td></tr><tr><td align="left"/><td align="left">OLCS-Ranker</td><td align="left">1387</td><td align="left">0.320</td><td align="left">87.2</td><td align="left">16.9</td></tr><tr><td align="left">Ups1</td><td align="left">CRanker</td><td align="left">510</td><td align="left">0.272</td><td align="left">2034.0</td><td align="left">1507.0</td></tr><tr><td align="left"/><td align="left">OLCS-Ranker</td><td align="left">477</td><td align="left">0.334</td><td align="left">160.2</td><td align="left">19.3</td></tr><tr><td align="left">Tal08</td><td align="left">CRanker</td><td align="left">1030</td><td align="left">0.306</td><td align="left">2347.9</td><td align="left">1579.6</td></tr><tr><td align="left"/><td align="left">OLCS-Ranker</td><td align="left">1150</td><td align="left">0.342</td><td align="left">28.9</td><td align="left">26.0</td></tr><tr><td align="left">Tal08-large</td><td align="left">CRanker</td><td align="left">15531</td><td align="left">0.334</td><td align="left">6107.9</td><td align="left">10090.1</td></tr><tr><td align="left"/><td align="left">OLCS-Ranker</td><td align="left">15863</td><td align="left">0.331</td><td align="left">601.0</td><td align="left">116.7</td></tr><tr><td align="left">Velos-mips</td><td align="left">CRanker</td><td align="left">117301</td><td align="left">0.334</td><td align="left">6123.1</td><td align="left">9052.9</td></tr><tr><td align="left"/><td align="left">OLCS-Ranker</td><td align="left">118266</td><td align="left">0.333</td><td align="left">699.3</td><td align="left">495.5</td></tr><tr><td align="left">Velos-nomips</td><td align="left">CRanker</td><td align="left">170092</td><td align="left">0.332</td><td align="left">6128.9</td><td align="left">11478.5</td></tr><tr><td align="left"/><td align="left">OLCS-Ranker</td><td align="left">172445</td><td align="left">0.333</td><td align="left">395.7</td><td align="left">754.3</td></tr></tbody></table></table-wrap>
</p>
      <p>Furthermore, we have compared the outputs of Percolator and OLCS-Ranker with different training sets to examine the stability of OLCS-Ranker. Usually, the output of a stable algorithm does not change dramatically along with input training data samples. We have run Percolator and OLCS-Ranker 30 times at each value of |train set |/ |total set | ratio =0.1,0.2,0.3,⋯,0.8.</p>
      <p>The average numbers of identified PSMs and its standard deviations were plotted in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. As we can see, both algorithms are stable on normal datasets. However, on Yeast and Ups1, deviations of outputs by OLCS-Ranker are smaller, especially when |train set |/ |total set | ratio is small.
<fig id="Fig5"><label>Fig. 5</label><caption><p>The number of identified target PSMs with various number of training PSMs. <italic>x</italic>-axis: train/total ratio, the ratio of the number of training PSMs to the total number of PSMs the total dataset; <italic>y</italic>-axis: identified targets, the number of identified target PSMs. <bold>a</bold>. On Yeast; <bold>b</bold>. On Ups1; <bold>c</bold>. On Tal08; <bold>d</bold>. On Tal08-large; <bold>e</bold>. On Velos-mips; <bold>f</bold>. On Velos-nomips</p></caption><graphic xlink:href="12864_2020_6693_Fig5_HTML" id="MO5"/></fig>
</p>
    </sec>
    <sec id="Sec6">
      <title>The algorithm efficiency</title>
      <p>In order to evaluate the computational resources consumed by OLCS-Ranker, we compared its running time and used memory with that used by the kernel-based baseline method, CRanker. As the whole training data is needed for CRanker to construct its kernel matrix, it is very time-consuming on large datasets. Instead, CRanker divided the training set into five subsets by randomly selecting 16000 PSMs for each subset. The final score of a PSM is the average of the scores on the five subsets.</p>
      <p>Table <xref rid="Tab3" ref-type="table">3</xref> summarized the comparison of OLCS-Ranker and CRanker in terms of the total number of identified PSMs, the ratio of identified PSMs in the test set to the number of total identified PSMs, used RAM and elapsed time. As we can see, it took CRanker from about 10 min to half an hour on three small datasets, Ups1, Yeast and Tal08, and about 3 h on comparatively large datasets, Tal08-large, Velos-mips and Velos-nomips. In contrast, it took OLCS-Ranker only 13 min on the largest dataset Velos-nomips, about 15∼85 times faster than CRanker. Moreover, OLCS-Ranker consumed only about 1/10 of RAM that used by CRanker on small datasets. On large datasets, OLCS-Ranker has low memory cost. It uses about 400Mb RAM on the tested largest dataset, Velos-nomips. By contrast, CRanker could not efficiently deal with large-scale datasets since large kernel matrix could not load into to memory. The memory of CRanker list in the table is used for training its five small-sized sub-models.</p>
      <p>In summary, OLCS-Ranker requires less computational time and memory than C-Ranker does. The analysis is given as follows. CRanker uses a batch learning method in training process and has to maintain a <italic>n</italic>-by-<italic>n</italic> dense kernel matrix, where <italic>n</italic> is the number of PSMs. In contrast, OLCS-Ranker uses an online learning algorithm, which iteratively trains the model by taking only one data sample at each round. Moreover, OLCS-Ranker only needs to keep data samples in the active set in the memory. Hence, the requirement of computational resources during the model-training process is significantly reduced.</p>
      <p>Particularly, the memory required by CRanker is <italic>O</italic>(<italic>n</italic><sup>2</sup>), with <italic>n</italic> the number of training PSMs, while it is <italic>O</italic>(|<italic>S</italic>|<sup>2</sup>) required by OLCS-Ranker, where |<italic>S</italic>| is the number of PSMs in the active set <italic>S</italic>. As the value of <italic>n</italic> is usually very large, CRanker can hardly run a dataset with more than 20,000 PSMs on a normal PC. However, the maximum size of the active set |<italic>S</italic>| in OLCS-Ranker is pre-selected and far less than the value of <italic>n</italic> for large datasets.</p>
      <p>From the perspective of computational complexity, CRanker needs to solve a series of convex sub-problem. Each subproblem is essentially an SVM classification problem, and the computational complexity is between <italic>O</italic>(<italic>n</italic><sup>2</sup>) and <italic>O</italic>(<italic>n</italic><sup>3</sup>). Thus, the computational complexity of CRanker is at least <italic>O</italic>(<italic>n</italic><sup>2</sup>). However, OLCS-Ranker deals with one PSM sample, at the computational cost of <italic>O</italic>(|<italic>S</italic>|<sup>2</sup>), at each round. Thus, the computational complexity of OLCS-Ranker is bounded by <italic>O</italic>(<italic>n</italic>|<italic>S</italic>|<sup>2</sup>), which is usually far less than that of CRanker when |<italic>S</italic>|≪<italic>n</italic>.</p>
    </sec>
    <sec id="Sec7">
      <title>Evaluation by the entrapment sequence method</title>
      <p>The entrapment sequence method was introduced as an alternative of target-decoy strategy to validate true PSMs in mass spectrometry data analysis. We have evaluated the performance of OLCS-ranker with the entrapment sequences obtained from “Pfu” dataset published in reference [<xref ref-type="bibr" rid="CR20">20</xref>].</p>
      <p>We use the entrapment hits to calculate the false match rate (FMR) to assess the quality of the identification results. Fig. <xref rid="Fig6" ref-type="fig">6</xref> depicts corresponding FMRs under a series of FDR levels of OLCS-Ranker. It is shown that with both Tide (Fig. <xref rid="Fig6" ref-type="fig">6</xref>a) and Comet (Fig. <xref rid="Fig6" ref-type="fig">6</xref>b) search engines, OLCS-Ranker has approximately lower FMR levels than those of FDRs in identified sample PSMs and peptides, which indicates the identification results are reasonable according to the definition of FMR.
<fig id="Fig6"><label>Fig. 6</label><caption><p>False match rate under various FDR level on Pfu dataset of OLCS-Ranker, FMR =<inline-formula id="IEq6"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$N_{\text {entrapment}} / N_{\text {target}}^{}$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>entrapment</mml:mtext></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>target</mml:mtext></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq6.gif"/></alternatives></inline-formula>. <bold>a</bold>. Tide + OLCS-Ranker; <bold>b</bold>. Comet + OLCS-Ranker</p></caption><graphic xlink:href="12864_2020_6693_Fig6_HTML" id="MO6"/></fig>
</p>
      <p>We also compared the identification results of OLCS-Ranker using different search engines with those in [<xref ref-type="bibr" rid="CR20">20</xref>] under 0.01 FDR for PSM and peptide, respectively, and results are listed in Table <xref rid="Tab4" ref-type="table">4</xref>. It is shown that in most cases the FMRs estimated by entrapment hits are roughly equal to 0.01. Particularly, with the Comet search engine at FMR =0.009, OLCS-Ranker identified 10603 PSMs, 6% more than those identified by Crux Percolator. Similarly for identified peptides, the number given by OLCS-Ranker is about 6% (5667−5343)/5343=6.06<italic>%</italic>) more than that of Crux Percolator. With the Tide search engine, OLCS-Ranker identifies approximately the same number of PSMs and peptides as those of Crux Percolator, but has lower FMR levels. Thus, in terms of identification number and FMRs given by this entrapment sequence test, OLCS-Ranker has shown the quality of its identified results is at least as high as that of Crux Percolator.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>The identification numbers and FMRs under FDR =0.01 on Pfu dataset of various searching methods</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Method</th><th align="left">Identification number</th><th align="left">FMR</th></tr></thead><tbody><tr><td align="left">Sample PSM</td><td align="left">Tide + Crux percolator</td><td align="left">6799</td><td align="left">0.013</td></tr><tr><td align="left"/><td align="left">X!Tandem + percolator</td><td align="left">9889</td><td align="left">0.011</td></tr><tr><td align="left"/><td align="left">Mascot + PepDistiller</td><td align="left">9864</td><td align="left">0.013</td></tr><tr><td align="left"/><td align="left">Comet + Crux Percolator</td><td align="left">9922</td><td align="left">0.009</td></tr><tr><td align="left"/><td align="left">Tide + OLCS-Ranker</td><td align="left">6897</td><td align="left">0.008</td></tr><tr><td align="left"/><td align="left">Comet + OLCS-Ranker</td><td align="left">10603</td><td align="left">0.009</td></tr><tr><td align="left">Sample peptide</td><td align="left">Tide + crux percolator</td><td align="left">3878</td><td align="left">0.016</td></tr><tr><td align="left"/><td align="left">X!Tandem + percolator</td><td align="left">5320</td><td align="left">0.012</td></tr><tr><td align="left"/><td align="left">Mascot + PepDistiller</td><td align="left">5360</td><td align="left">0.015</td></tr><tr><td align="left"/><td align="left">Comet + crux percolator</td><td align="left">5343</td><td align="left">0.010</td></tr><tr><td align="left"/><td align="left">Tide + OLCS-ranker</td><td align="left">3806</td><td align="left">0.008</td></tr><tr><td align="left"/><td align="left">Comet + OLCS-ranker</td><td align="left">5667</td><td align="left">0.011</td></tr></tbody></table></table-wrap>
</p>
    </sec>
  </sec>
  <sec id="Sec8" sec-type="conclusion">
    <title>Conclusions</title>
    <p>We have presented a cost-sensitive post-database search approach, OLCS-Ranker, for peptide identification to overcome the challenges of “hard datasets” and scalability problem with the kernel-based learning model. We designed an online cost-sensitive model to tackle a large portion of decoy PSMs in hard datasets by assigning them larger penalties. Moreover, OLCS-Ranker has shown better scalability than CRanker due to significantly reduced memory requirement and total training time. Experimental studies have shown that OLCS-Ranker outperformed benchmark methods in terms of accuracy and stability. Also, compared with CRanker, OLCS-Ranker is about 15 ∼85 times faster over tested datasets and has overcome the overfitting problem on hard datasets.</p>
  </sec>
  <sec id="Sec9">
    <title>Materials and methods</title>
    <sec id="Sec10">
      <title>Basic CRanker model</title>
      <p>CRanker [<xref ref-type="bibr" rid="CR14">14</xref>] cast identification of target PSM as a classification problem. Let <inline-formula id="IEq7"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\Omega =\{x_{i}^{},y_{i}^{}\}_{i=1}^{n} \subseteq R_{}^{q} \times \{-1,1\}$\end{document}</tex-math><mml:math id="M16"><mml:mi>Ω</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mo>⊆</mml:mo><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msubsup><mml:mo>×</mml:mo><mml:mo>{</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq7.gif"/></alternatives></inline-formula> be a set of <italic>n</italic> PSMs, where <inline-formula id="IEq8"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$x_{i}^{} \in R_{}^{q}$\end{document}</tex-math><mml:math id="M18"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq8.gif"/></alternatives></inline-formula> represents its <italic>i</italic>-th PSM record with <italic>q</italic> attributes, and <inline-formula id="IEq9"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$y_{i}^{} \in \{ 1, -1\}$\end{document}</tex-math><mml:math id="M20"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq9.gif"/></alternatives></inline-formula> is the corresponding label indicating a target or decoy PSM. Define <inline-formula id="IEq10"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$ \Omega _{+}^{} = \{j \,|\, y_{j}^{} = 1 \}, \quad \Omega _{-}^{} = \{j \,|\, y_{j}^{} = -1 \}. $\end{document}</tex-math><mml:math id="M22"><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>j</mml:mi><mml:mspace width="0.3em"/><mml:mo>|</mml:mo><mml:mspace width="0.3em"/><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>j</mml:mi><mml:mspace width="0.3em"/><mml:mo>|</mml:mo><mml:mspace width="0.3em"/><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo><mml:mi>.</mml:mi></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq10.gif"/></alternatives></inline-formula> The identification task is to train a discriminant function for filtering out the correct PSMs from the target PSMs (ones with labels “ +1”).</p>
      <p>While class labels in a standard classification problem are all trustworthy, a large number of “ +1” labels in PSM identification are not correct. CRanker [<xref ref-type="bibr" rid="CR14">14</xref>] introduced weight <italic>θ</italic><sub><italic>i</italic></sub>∈[0,1] for each PSM sample (<italic>x</italic><sub><italic>i</italic></sub>,<italic>y</italic><sub><italic>i</italic></sub>) to indicate the degree of the reliability of the label <italic>y</italic><sub><italic>i</italic></sub>. Particularly, <italic>θ</italic><sub><italic>i</italic></sub>=1 indicates that label <italic>y</italic><sub><italic>i</italic></sub> is definitely correct, <italic>θ</italic><sub><italic>i</italic></sub>=0 indicates that it is definitely incorrect, and <italic>θ</italic><sub><italic>i</italic></sub>∈(0,1) indicates that label <italic>y</italic><sub><italic>i</italic></sub> is probably correct. In fact, all “ −1” labels (decoy PSMs) are correct, and thus <italic>θ</italic><sub><italic>i</italic></sub>=1 for all <inline-formula id="IEq11"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$i\in \Omega _{-}^{}$\end{document}</tex-math><mml:math id="M24"><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq11.gif"/></alternatives></inline-formula>. Based on Support Vector Machine (SVM) [<xref ref-type="bibr" rid="CR27">27</xref>], CRanker can be solved by the following optimization problem
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \begin{array}{cl} \min_{w,\theta}^{} &amp; \frac{1}{2}\|w\|^{2} + C \sum_{i=1}^{n} \theta_{i}^{} h(y_{i}^{}f(x_{i})) - \lambda \sum_{i=1}^{n} \theta_{i}^{} \\ \text{s.\,t.} &amp; \theta_{i}^{} = 1, \ i \in \Omega_{-}^{}, \\ &amp; 0\leq \theta_{i}^{} \leq 1,\ i \in \Omega_{+}^{}, \\ \end{array}  $$ \end{document}</tex-math><mml:math id="M26"><mml:mtable class="array" columnalign="left"><mml:mtr><mml:mtd><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>min</mml:mo></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mrow/></mml:munderover></mml:mtd><mml:mtd><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>∥</mml:mo><mml:mi>w</mml:mi><mml:msup><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>s. t.</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr/></mml:mtable></mml:math><graphic xlink:href="12864_2020_6693_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <italic>C</italic>&gt;0 is the regularization parameter, <italic>λ</italic>&gt;0 is the parameter controlling the number of identified PSMs, <italic>h</italic>(<italic>t</italic>)= max(0,1−<italic>t</italic>) is the hinge loss function, and <italic>f</italic>(<italic>x</italic><sub><italic>i</italic></sub>)=〈<italic>w</italic>,<italic>ϕ</italic>(<italic>x</italic><sub><italic>i</italic></sub>)〉 is the value of discriminant function at <italic>x</italic><sub><italic>i</italic></sub> with feature mapping <italic>ϕ</italic>(·). As shown in [<xref ref-type="bibr" rid="CR28">28</xref>, <xref ref-type="bibr" rid="CR29">29</xref>], a larger value of parameter <italic>λ</italic> selects more PSMs into the training process.</p>
    </sec>
    <sec id="Sec11">
      <title>Cost-sensitive ranker model</title>
      <p>In this section, we present a cost-sensitive (CS) classification model to partially tackle the stability problem of CRanker over datasets with a distribution of unbalanced PSMs. Unlike the CRanker model, the CS model uses different loss functions for decoy and target PSMs. In fact, learning errors should be treated with different penalties in peptide identification. If the discriminant function assigns “ +1” label to a decoy PSM, then we know for sure that the label assignment is wrong. In this case, the learning error is more likely caused by the model itself rather than the quality of the data sample, and hence we should give the loss function a large penalty. On the other hand, if a target is classified as negative and assigned label “ −1”, we are not even sure whether the label assignment is correct, and thus we consider a small penalty for the loss function. Based on these observations, we incorporate the new penalty policy into model (<xref rid="Equ1" ref-type="">1</xref>) and the new model is described as follows:
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \begin{array}{cl} \min_{w,\theta}^{} &amp; \frac{1}{2}\|w\|^{2} + C_{1} \sum_{i\in\Omega_{-}^{}}^{} \theta_{i}^{} h(y_{i}^{}f(x_{i}))\\ &amp; \quad + C_{2} \sum_{i\in\Omega_{+}^{}}^{} \theta_{i}^{} h(y_{i}^{}f(x_{i})) - \lambda \sum_{i=1}^{n} \theta_{i}^{} \\ \text{s.\,t.} &amp; \theta_{i}^{} = 1, \ i \in \Omega_{-}^{}, \\ &amp; 0\leq \theta_{i}^{} \leq 1,\ i \in \Omega_{+}^{}, \\ \end{array}  $$ \end{document}</tex-math><mml:math id="M28"><mml:mtable class="array" columnalign="left"><mml:mtr><mml:mtd><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>min</mml:mo></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mrow/></mml:munderover></mml:mtd><mml:mtd><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>∥</mml:mo><mml:mi>w</mml:mi><mml:msup><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow><mml:mrow/></mml:munderover><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="1em"/><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow><mml:mrow/></mml:munderover><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>s. t.</mml:mtext></mml:mtd><mml:mtd><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr/></mml:mtable></mml:math><graphic xlink:href="12864_2020_6693_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <italic>C</italic><sub>1</sub>&gt;0, <italic>C</italic><sub>2</sub>&gt;0 are weights for the losses of the decoys and targets, respectively. Model (<xref rid="Equ2" ref-type="">2</xref>) is named <bold>cost-sensitive ranker</bold> model and denoted by <bold>CS-Ranker</bold>. As we choose a larger penalty for decoy losses, <inline-formula id="IEq12"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$C_{1}^{} \geq C_{2}^{}$\end{document}</tex-math><mml:math id="M30"><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>≥</mml:mo><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq12.gif"/></alternatives></inline-formula> always holds.</p>
    </sec>
    <sec id="Sec12">
      <title>The convex-concave procedure for solving CS-Ranker</title>
      <p>In order to solve the CS-Ranker model, we transform (<xref rid="Equ2" ref-type="">2</xref>) to its DC (<bold>d</bold>ifference of two <bold>c</bold>onvex functions) form. According to the method in [<xref ref-type="bibr" rid="CR29">29</xref>], if a pair of <italic>w</italic><sup>∗</sup>∈<italic>R</italic><sup><italic>n</italic></sup> and <italic>θ</italic><sup>∗</sup>∈<italic>R</italic><sup><italic>n</italic></sup> is an optimal solution to CS-Ranker model (<xref rid="Equ2" ref-type="">2</xref>), then <italic>w</italic><sup>∗</sup> is also an optimal solution of the following problem
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \min_{w}^{} \, \frac{1}{2}\|w\|^{2} + C_{1} \sum_{i\in\Omega_{-}^{}}^{} h(y_{i}^{}f(x_{i})) + C_{2} \sum_{i\in\Omega_{+}^{}}^{} R_{s}^{}(y_{i}^{}f(x_{i}))  $$ \end{document}</tex-math><mml:math id="M32"><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>min</mml:mo></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow/></mml:munderover><mml:mspace width="0.3em"/><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>∥</mml:mo><mml:mi>w</mml:mi><mml:msup><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow><mml:mrow/></mml:munderover><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow><mml:mrow/></mml:munderover><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:math><graphic xlink:href="12864_2020_6693_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <italic>R</italic><sub><italic>s</italic></sub>(<italic>t</italic>)= min(1−<italic>s</italic>, max(0,1−<italic>t</italic>)), <inline-formula id="IEq13"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$s = 1- \frac {\lambda }{C_{2}^{}}$\end{document}</tex-math><mml:math id="M34"><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq13.gif"/></alternatives></inline-formula>.</p>
      <p>Since <italic>R</italic><sub><italic>s</italic></sub>(<italic>t</italic>)=<italic>H</italic><sub>1</sub>(<italic>t</italic>)−<italic>H</italic><sub><italic>s</italic></sub>(<italic>t</italic>), with <italic>H</italic><sub><italic>s</italic></sub>(<italic>t</italic>)= max(0,<italic>s</italic>−<italic>t</italic>) and <italic>H</italic><sub>1</sub>(<italic>t</italic>)= max(0,1−<italic>t</italic>), then model (<xref rid="Equ3" ref-type="">3</xref>) can be recast as
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \min \quad J(w) = J_{\text{vex}}^{}(w) + J_{\text{cav}}^{}(w),  $$ \end{document}</tex-math><mml:math id="M36"><mml:mo>min</mml:mo><mml:mspace width="1em"/><mml:mi>J</mml:mi><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mtext>vex</mml:mtext></mml:mrow><mml:mrow/></mml:munderover><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mtext>cav</mml:mtext></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12864_2020_6693_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where
<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \begin{array}{l} J_{\text{vex}}^{}(w)= \frac{1}{2}\|w\|^{2} + C_{1}^{} \sum_{i\in\Omega_{-}^{}}^{} H_{1}(y_{i}^{}f(x_{i})) \\ \qquad + C_{2}^{} \sum_{i\in\Omega_{+}^{}}^{} H_{1}(y_{i}^{}f(x_{i})), \\ J_{\text{cav}}^{}(w) = - C_{2}^{} \sum_{i\in\Omega_{+}^{}}^{} H_{s}^{}(y_{i}^{}f(x_{i})). \end{array}  $$ \end{document}</tex-math><mml:math id="M38"><mml:mtable class="array" columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mtext>vex</mml:mtext></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>∥</mml:mo><mml:mi>w</mml:mi><mml:msup><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow><mml:mrow/></mml:munderover><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="2em"/><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow/></mml:msubsup><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow><mml:mrow/></mml:munderover><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mtext>cav</mml:mtext></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow/></mml:msubsup><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow><mml:mrow/></mml:munderover><mml:msubsup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mi>.</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12864_2020_6693_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
      <p><inline-formula id="IEq14"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$J_{\text {vex}}^{}(\cdot)$\end{document}</tex-math><mml:math id="M40"><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mtext>vex</mml:mtext></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>(</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq14.gif"/></alternatives></inline-formula> and <inline-formula id="IEq15"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$J_{\text {cav}}^{}(\cdot)$\end{document}</tex-math><mml:math id="M42"><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mtext>cav</mml:mtext></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>(</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq15.gif"/></alternatives></inline-formula> are convex and concave functions respectively. Hence, Problem (<xref rid="Equ4" ref-type="">4</xref>) can be solved by a standard Concave-Convex Procedure (CCCP) [<xref ref-type="bibr" rid="CR30">30</xref>], which iteratively solves subproblems
<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ w_{}^{k+1} = \text{argmin}_{w}^{} \quad J_{\text{vex}}^{}(w) + J_{\text{cav}}^{\prime}(w^{k})\cdot w  $$ \end{document}</tex-math><mml:math id="M44"><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mtext>argmin</mml:mtext></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mspace width="1em"/><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mtext>vex</mml:mtext></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mtext>cav</mml:mtext></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>)</mml:mo><mml:mo>·</mml:mo><mml:mi>w</mml:mi></mml:math><graphic xlink:href="12864_2020_6693_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>with initial <italic>w</italic><sup>0</sup>. The subproblem (<xref rid="Equ6" ref-type="">6</xref>) can be solved by its Lagrange dual [<xref ref-type="bibr" rid="CR31">31</xref>]:
<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ {{}\begin{aligned} \begin{array}{cl} \max_{\alpha}^{} &amp; G(\alpha) \,=\, -\frac{1}{2}\sum_{i,j}^{}\alpha_{i}^{} \alpha_{j}^{} k(x_{i},x_{j}) + \langle \alpha,y \rangle + \sum_{i\in \Omega_{+}}^{} C_{2} \eta_{i}^{k} \\ \text{s.\,t.} &amp; A_{i} \leq \alpha_{i} \leq B_{i}, \quad, i=1,\ldots, n \\ &amp; A_{i} = \min(0,C_{1}^{} y_{i}),\ i\in \Omega_{-}^{} \\ &amp; B_{i} = \max(0,C_{1}^{} y_{i}),\ i\in \Omega_{-}^{} \\ &amp; A_{i} = \min(0,C_{2}^{}y_{i})-C_{2}^{}\eta_{i}^{}y_{i},\ i\in \Omega_{+}^{} \\ &amp; B_{i} = \max(0,C_{2}^{}y_{i})-C_{2}^{}\eta_{i}^{}y_{i},\ i\in \Omega_{+}^{} \\ \end{array} \end{aligned}}  $$ \end{document}</tex-math><mml:math id="M46"><mml:mtable><mml:mtr><mml:mtd><mml:mtable class="array" columnalign="left"><mml:mtr><mml:mtd><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>max</mml:mo></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow/></mml:munderover></mml:mtd><mml:mtd><mml:mi>G</mml:mi><mml:mo>(</mml:mo><mml:mi>α</mml:mi><mml:mo>)</mml:mo><mml:mspace width="0.3em"/><mml:mo>=</mml:mo><mml:mspace width="0.3em"/><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow/></mml:munderover><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>k</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mo>〈</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>〉</mml:mo><mml:mo>+</mml:mo><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mrow/></mml:munderover><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>s. t.</mml:mtext></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>min</mml:mo><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:munderover><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>max</mml:mo><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:munderover><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>min</mml:mo><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow/></mml:munderover><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow/></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>max</mml:mo><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow/></mml:munderover><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow/></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mtd></mml:mtr><mml:mtr/></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12864_2020_6693_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <inline-formula id="IEq16"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\eta _{i} = \left \{ \begin {array}{cl} 1, &amp; \text { if}\ y_{i} f^{}(x_{i}) &lt; s,\\ 0, &amp; \text { otherwise }. \end {array} \right.$\end{document}</tex-math><mml:math id="M48"><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable class="array" columnalign="left"><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow/></mml:msup><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>otherwise</mml:mtext><mml:mi>.</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq16.gif"/></alternatives></inline-formula></p>
      <p>Model (<xref rid="Equ7" ref-type="">7</xref>) is a kernel-based learning model with <italic>k</italic>(·,·) the kernel function. Then <italic>k</italic>(<italic>x</italic><sub><italic>i</italic></sub>,<italic>x</italic><sub><italic>j</italic></sub>) calculates, in feature space, the pairwise inner product of PSM records of <italic>x</italic><sub><italic>i</italic></sub> and <italic>x</italic><sub><italic>j</italic></sub>, which are represented in vector format. Hence, OLCS-Ranker can handle PSM records generated by any search engine as long as the output PSMs are represented in vector format.</p>
    </sec>
    <sec id="Sec13">
      <title>The online learning algorithm for CS-Ranker model</title>
      <p>Inspired by the work in [<xref ref-type="bibr" rid="CR32">32</xref>, <xref ref-type="bibr" rid="CR33">33</xref>], we obtain the discriminant function for CS-Ranker by solving its DC form (<xref rid="Equ3" ref-type="">3</xref>).</p>
      <p>Different from classical classifiers which take all PSM samples at once, the <bold>online CS-Ranker algorithm</bold> (<bold>OLCS-Ranker</bold>) iteratively trains the discrimination function and adds only one PSM sample into the training process at each iteration. The PSM sample is randomly selected to prevent the solution of (<xref rid="Equ3" ref-type="">3</xref>) from trapping at a local minimum and its effectiveness has been observed in approaches such as stochastic gradient descent [<xref ref-type="bibr" rid="CR34">34</xref>]. In order to reduce the cost of memory and computation, OLCS-Ranker maintains an active set which keeps only indices of PSMs that determine the discriminant function in model training, and the PSMs that do not affect the discriminant function are discarded.</p>
      <sec id="Sec14">
        <title>Online algorithm for solving CS-Ranker</title>
        <p>The implementation of OLCS-Ranker is depicted in Algorithm 1. Particularly, given a chosen PSM sample (Line 3), OLCS-Ranker updates bounds <italic>A</italic><sub><italic>j</italic></sub>, <italic>B</italic><sub><italic>j</italic></sub>, for all <inline-formula id="IEq17"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$j \in \Omega _{+}^{}\cap S$\end{document}</tex-math><mml:math id="M50"><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>∩</mml:mo><mml:mi>S</mml:mi></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq17.gif"/></alternatives></inline-formula> (Line 4 – Line 7), and calls subroutines PROCESS and REPROCESS to solve dual programming (<xref rid="Equ7" ref-type="">7</xref>) with training samples in active set <italic>S</italic> (Line 8–Line 12). Iteratively, the algorithm calls subroutine CLEAN to remove part of redundant PSMs from the active set (Line 13). The iteration terminates when all the training PSMs have been chosen for training.</p>
        <p>
          <graphic position="anchor" xlink:href="12864_2020_6693_Figa_HTML" id="MO7"/>
        </p>
      </sec>
      <sec id="Sec15">
        <title>Subroutines</title>
        <p>Subroutine PROCESS ensures that all the coordinates of <italic>α</italic><sub><italic>j</italic></sub> satisfy the bound constraint conditions in CS-Ranker model (<xref rid="Equ7" ref-type="">7</xref>). It initializes <inline-formula id="IEq18"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\alpha _{i_{0}}$\end{document}</tex-math><mml:math id="M52"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq18.gif"/></alternatives></inline-formula> with 0, where <italic>i</italic><sub>0</sub> is the index of the chosen PSM, and updates the coordinates <italic>α</italic><sub><italic>j</italic></sub> if bound <italic>A</italic><sub><italic>j</italic></sub> or <italic>B</italic><sub><italic>j</italic></sub> has changed (Line 1-2). Then, it updates gradient vector <italic>g</italic><sub><italic>j</italic></sub>, <italic>j</italic>∈<italic>S</italic> (Line 3), where <italic>g</italic> is defined by
<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ g_{i} \stackrel{\triangle}{=} \frac{\partial G(\alpha)}{\partial \alpha_{i}} = y_{i} - \sum_{j\in S}^{} \alpha_{j}^{}k(x_{i},x_{j}).  $$ \end{document}</tex-math><mml:math id="M54"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mover><mml:mrow><mml:mo>=</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo>△</mml:mo></mml:mrow></mml:mrow></mml:mover><mml:mfrac><mml:mrow><mml:mi>∂G</mml:mi><mml:mo>(</mml:mo><mml:mi>α</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow/></mml:munderover><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mi>k</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mi>.</mml:mi></mml:math><graphic xlink:href="12864_2020_6693_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula></p>
        <p>
          <graphic position="anchor" xlink:href="12864_2020_6693_Figb_HTML" id="MO8"/>
        </p>
        <p>Subroutine REPROCESS aims to find a better solution of model (<xref rid="Equ7" ref-type="">7</xref>). It selects the instances with the maximal gradient in active set <italic>S</italic> (Line 1 – Line 12). Once an instance is selected, it computes a stepsize (Line 13 – Line 17) and performs a direction search (Line 18 – Line 19). The derivation of these iteration formulae could be found in Additional file <xref rid="MOESM1" ref-type="media">1</xref>.</p>
        <p>
          <graphic position="anchor" xlink:href="12864_2020_6693_Figc_HTML" id="MO9"/>
        </p>
        <p>Subroutine CLEAN removes PSMs that are not effective to the discriminant function from the active set <italic>S</italic> to minimize the requirement of memory and computation. The subroutine selects non-support vectors and keeps them in set <italic>V</italic> (Line 1 – Line 4), then selects at most <italic>m</italic> PSMs of <italic>V</italic> with the largest gradients, and finally removes them from <italic>S</italic> (Line 5 – Line 9).</p>
        <p>
          <graphic position="anchor" xlink:href="12864_2020_6693_Figd_HTML" id="MO10"/>
        </p>
      </sec>
      <sec id="Sec16">
        <title>Calculate PSM scores</title>
        <p>After discriminant function <inline-formula id="IEq19"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {f}$\end{document}</tex-math><mml:math id="M56"><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq19.gif"/></alternatives></inline-formula>: <inline-formula id="IEq20"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$ \hat {f}(x) = \sum _{j\in S}^{} \alpha _{j} k(x_{j},x),$\end{document}</tex-math><mml:math id="M58"><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow/></mml:munderover><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>k</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math><inline-graphic xlink:href="12864_2020_6693_Article_IEq20.gif"/></alternatives></inline-formula> where <italic>k</italic>(·) is the selected kernel function, is trained, we calculate the scores of all PSMs on both training and test sets. The score of PSM (<italic>x</italic><sub><italic>i</italic></sub>,<italic>y</italic><sub><italic>i</italic></sub>) is defined in [<xref ref-type="bibr" rid="CR14">14</xref>]:
<disp-formula id="Equb"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$score(i) = \frac{2}{\pi}\arctan(\hat{f}(x_{i})). $$ \end{document}</tex-math><mml:math id="M60"><mml:mrow><mml:mtext mathvariant="italic">score</mml:mtext><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:mfrac><mml:mo>arctan</mml:mo><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mi>.</mml:mi></mml:mrow></mml:math><graphic xlink:href="12864_2020_6693_Article_Equb.gif" position="anchor"/></alternatives></disp-formula></p>
        <p>The larger the score value is, the more likely a PSM is correct. The PSMs are ordered according to their scores, and a certain number of PSMs are reported according to a pre-selected FDR.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec17">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12864_2020_6693_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1</bold> Additional results. The derivation of iteration formulae of OLCS-Ranker and some additional results.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="12864_2020_6693_MOESM2_ESM.xlsx">
            <caption>
              <p><bold>Additional file 2</bold> Cross validation results. Details of the Cross validation results (Excel file).</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>MS/MS</term>
        <def>
          <p>Tandem mass spectrometry</p>
        </def>
      </def-item>
      <def-item>
        <term>PSM</term>
        <def>
          <p>Peptide-spectrum match</p>
        </def>
      </def-item>
      <def-item>
        <term>BNP</term>
        <def>
          <p>Bayesian nonparametric model</p>
        </def>
      </def-item>
      <def-item>
        <term>SVM</term>
        <def>
          <p>Support vector machine</p>
        </def>
      </def-item>
      <def-item>
        <term>TPP</term>
        <def>
          <p>Trans-Proteomic Pipeline</p>
        </def>
      </def-item>
      <def-item>
        <term>CS-Ranker</term>
        <def>
          <p>Cost-sensitive Ranker</p>
        </def>
      </def-item>
      <def-item>
        <term>OLCS-Ranker</term>
        <def>
          <p>Online algorithm for CS-Ranker</p>
        </def>
      </def-item>
      <def-item>
        <term>Ups1</term>
        <def>
          <p>Universal proteomics standard set</p>
        </def>
      </def-item>
      <def-item>
        <term>Yeast</term>
        <def>
          <p>S.cerevisiae Gcn4 affinity-purified complex</p>
        </def>
      </def-item>
      <def-item>
        <term>PBMC</term>
        <def>
          <p>Human Peripheral Blood Mononuclear Cells</p>
        </def>
      </def-item>
      <def-item>
        <term>Velos-mips</term>
        <def>
          <p>LTQ-Orbitrap Velos with MiPS</p>
        </def>
      </def-item>
      <def-item>
        <term>Velos-nomips</term>
        <def>
          <p>LTQ-Orbitrap Velos with MiPS-off</p>
        </def>
      </def-item>
      <def-item>
        <term>ROC</term>
        <def>
          <p>Receiver operating characteristic</p>
        </def>
      </def-item>
      <def-item>
        <term>DC</term>
        <def>
          <p>Difference of two convex functions</p>
        </def>
      </def-item>
      <def-item>
        <term>CCCP</term>
        <def>
          <p>Concave-Convex Procedure</p>
        </def>
      </def-item>
      <def-item>
        <term>FMR</term>
        <def>
          <p>False match rate</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p><bold>Supplementary information</bold> accompanies this paper at 10.1186/s12864-020-6693-y.</p>
  </sec>
  <ack>
    <p>We wish to thank Prof. Xiaolin Chen (Qufu Normal University, China) for his work on the analysis of the OLCS-Ranker algorithm.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>XL and ZX designed the classification model and wrote the manuscript. LJ, YW and XL designed the parameter selection and experiments. XN and AL provided the proteomics data and verified the experimental results. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Xijun Liang and Ling Jian were partially supported by the National Natural Science Foundation of China under Grant No. 61503412, 61873279, the Key Research and Development Program of Shandong Province under Grant No. 2018GSF120020, National Natural Science Foundation of Shandong Province under Grant No. ZR2019MA016, Fundamental Research Funds for the Central Universities under Grant No. 19CX05027B, and National Science and Technology Major Project of China under Grant No. 2016ZX05011-001-003. Andrew J. Link was supported in part by NIH grant GM64779. Xinnan Niu and Andrew J. Link were supported by NIH Grants GM64779, HL68744, ES11993, and CA098131. Zhonghang Xia were supported by WKU RCAP Grant No. 20-8032.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The datasets supporting the conclusions of this article are available in the Figshare repository, 10.6084/m9.figshare.5739705.v1.</p>
    <p>The software of OLCS-Ranker can be download from <ext-link ext-link-type="uri" xlink:href="https://github.com/Isaac-QiXing/CRanker">https://github.com/Isaac-QiXing/CRanker</ext-link>. A web-based GUI for users of OLCS-Ranker is provided at <ext-link ext-link-type="uri" xlink:href="http://161.6.5.181:8000/olcs-ranker/">http://161.6.5.181:8000/olcs-ranker/</ext-link>.</p>
  </notes>
  <notes>
    <title>Ethics approval and consent to participate</title>
    <p>Not applicable.</p>
  </notes>
  <notes>
    <title>Consent for publication</title>
    <p>Not applicable.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p>The authors declare that they have no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Elias</surname>
            <given-names>JE</given-names>
          </name>
          <name>
            <surname>Haas</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Faherty</surname>
            <given-names>BK</given-names>
          </name>
          <name>
            <surname>Gygi</surname>
            <given-names>SP</given-names>
          </name>
        </person-group>
        <article-title>Comparative evaluation of mass spectrometry platforms used in large-scale proteomics investigations</article-title>
        <source>Nat Methods</source>
        <year>2005</year>
        <volume>2</volume>
        <issue>9</issue>
        <fpage>667</fpage>
        <lpage>75</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth785</pub-id>
        <pub-id pub-id-type="pmid">16118637</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2</label>
      <mixed-citation publication-type="other">Link AJ, Eng J, Schieltz1 DM, Carmack E. Direct analysis of protein complexes using mass spectrometry. Nat Biotechnol. 1999; 17(7):676–82.</mixed-citation>
    </ref>
    <ref id="CR3">
      <label>3</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nesvizhskii</surname>
            <given-names>AI</given-names>
          </name>
        </person-group>
        <article-title>A survey of computational methods and error rate estimation procedures for peptide and protein identification in shotgun proteomics</article-title>
        <source>J Proteomics</source>
        <year>2010</year>
        <volume>73</volume>
        <issue>11</issue>
        <fpage>2092</fpage>
        <lpage>123</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jprot.2010.08.009</pub-id>
        <pub-id pub-id-type="pmid">20816881</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Keller</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Nesvizhskii</surname>
            <given-names>AI</given-names>
          </name>
          <name>
            <surname>Kolker</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Aebersold</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Empirical statistical model to estimate the accuracy of peptide identifications made by ms/ms and database search</article-title>
        <source>Anal Chem</source>
        <year>2002</year>
        <volume>74</volume>
        <issue>20</issue>
        <fpage>5383</fpage>
        <lpage>92</lpage>
        <pub-id pub-id-type="doi">10.1021/ac025747h</pub-id>
        <pub-id pub-id-type="pmid">12403597</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Käll</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Canterbury</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>Weston</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Semi-supervised learning for peptide identification from shotgun proteomics datasets</article-title>
        <source>Nat Methods</source>
        <year>2007</year>
        <volume>4</volume>
        <issue>11</issue>
        <fpage>923</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth1113</pub-id>
        <pub-id pub-id-type="pmid">17952086</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Choi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Nesvizhskii</surname>
            <given-names>AI</given-names>
          </name>
        </person-group>
        <article-title>Semisupervised model-based validation of peptide identifications in mass spectrometry-based proteomics</article-title>
        <source>J proteome Res</source>
        <year>2007</year>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>254</fpage>
        <lpage>65</lpage>
        <pub-id pub-id-type="doi">10.1021/pr070542g</pub-id>
        <pub-id pub-id-type="pmid">18159924</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Choi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Nesvizhskii</surname>
            <given-names>AI</given-names>
          </name>
        </person-group>
        <article-title>Adaptive discriminant function analysis and reranking of ms/ms database search results for improved peptide identification in shotgun proteomics</article-title>
        <source>J Proteome Res</source>
        <year>2008</year>
        <volume>7</volume>
        <issue>11</issue>
        <fpage>4878</fpage>
        <lpage>89</lpage>
        <pub-id pub-id-type="doi">10.1021/pr800484x</pub-id>
        <pub-id pub-id-type="pmid">18788775</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Dou</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Qian</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xie</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Bayesian nonparametric model for the validation of peptide identification in shotgun proteomics</article-title>
        <source>Mol Cell Proteomics</source>
        <year>2009</year>
        <volume>8</volume>
        <issue>3</issue>
        <fpage>547</fpage>
        <pub-id pub-id-type="doi">10.1074/mcp.M700558-MCP200</pub-id>
        <pub-id pub-id-type="pmid">19005226</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jie</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Jiyang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Songfeng</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Dong</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Yunping</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Fuchu</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Improving the sensitivity of mascot search results validation by combining new features with bayesian nonparametric model</article-title>
        <source>Proteomics</source>
        <year>2010</year>
        <volume>10</volume>
        <issue>23</issue>
        <fpage>4293</fpage>
        <lpage>300</lpage>
        <pub-id pub-id-type="doi">10.1002/pmic.200900668</pub-id>
        <pub-id pub-id-type="pmid">21086516</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>The</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>MacCoss</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Noble</surname>
            <given-names>WS</given-names>
          </name>
          <name>
            <surname>Käll</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Fast and accurate protein false discovery rates on large-scale proteomics data sets with percolator 3.0</article-title>
        <source>J Am Soc Mass Spectrom</source>
        <year>2016</year>
        <volume>27</volume>
        <issue>11</issue>
        <fpage>1719</fpage>
        <lpage>27</lpage>
        <pub-id pub-id-type="doi">10.1007/s13361-016-1460-7</pub-id>
        <pub-id pub-id-type="pmid">27572102</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Halloran</surname>
            <given-names>JT</given-names>
          </name>
          <name>
            <surname>Rocke</surname>
            <given-names>DM</given-names>
          </name>
        </person-group>
        <article-title>A matter of time: faster percolator analysis via efficient svm learning for large-scale proteomics</article-title>
        <source>J Proteome Res</source>
        <year>2018</year>
        <volume>17</volume>
        <issue>5</issue>
        <fpage>1978</fpage>
        <lpage>82</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jproteome.7b00767</pub-id>
        <pub-id pub-id-type="pmid">29607643</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Spivak</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Weston</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bottou</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Käll</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Noble</surname>
            <given-names>WS</given-names>
          </name>
        </person-group>
        <article-title>Improvements to the percolator algorithm for peptide identification from shotgun proteomics data sets</article-title>
        <source>J Proteome Res</source>
        <year>2009</year>
        <volume>8</volume>
        <issue>7</issue>
        <fpage>3737</fpage>
        <lpage>345</lpage>
        <pub-id pub-id-type="doi">10.1021/pr801109k</pub-id>
        <pub-id pub-id-type="pmid">19385687</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Halloran</surname>
            <given-names>JT</given-names>
          </name>
          <name>
            <surname>Rocke</surname>
            <given-names>DM</given-names>
          </name>
        </person-group>
        <article-title>Gradients of generative models for improved discriminative analysis of tandem mass spectra</article-title>
        <source>Adv Neural Inf Proc Syst</source>
        <year>2017</year>
        <volume>30</volume>
        <fpage>5724</fpage>
        <lpage>33</lpage>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xia</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Jian</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Niu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Link</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>An adaptive classification model for peptide identification</article-title>
        <source>BMC Genom</source>
        <year>2015</year>
        <volume>16</volume>
        <issue>11</issue>
        <fpage>1</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1186/1471-2164-16-S11-S1</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ivanov</surname>
            <given-names>MV</given-names>
          </name>
          <name>
            <surname>Levitsky</surname>
            <given-names>LI</given-names>
          </name>
          <name>
            <surname>Lobas</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Panic</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Laskay</surname>
            <given-names>UA</given-names>
          </name>
          <name>
            <surname>Mitulovic</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Schmid</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Pridatchenko</surname>
            <given-names>ML</given-names>
          </name>
          <name>
            <surname>Tsybin</surname>
            <given-names>YO</given-names>
          </name>
          <name>
            <surname>Gorshkov</surname>
            <given-names>MV</given-names>
          </name>
        </person-group>
        <article-title>Empirical multidimensional space for scoring peptide spectrum matches in shotgun proteomics</article-title>
        <source>J Proteome Res</source>
        <year>2014</year>
        <volume>13</volume>
        <issue>4</issue>
        <fpage>1911</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="doi">10.1021/pr401026y</pub-id>
        <pub-id pub-id-type="pmid">24571493</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Spivak</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bereman</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Maccoss</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Noble</surname>
            <given-names>WS</given-names>
          </name>
        </person-group>
        <article-title>Learning score function parameters for improved spectrum identification in tandem mass spectrometry experiments</article-title>
        <source>J Proteome Res</source>
        <year>2012</year>
        <volume>11</volume>
        <issue>9</issue>
        <fpage>4499</fpage>
        <lpage>508</lpage>
        <pub-id pub-id-type="doi">10.1021/pr300234m</pub-id>
        <pub-id pub-id-type="pmid">22866926</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Integrating genomic, transcriptomic, and interactome data to improve peptide and protein identification in shotgun proteomics</article-title>
        <source>J Proteome Res</source>
        <year>2014</year>
        <volume>13</volume>
        <issue>6</issue>
        <fpage>2715</fpage>
        <lpage>23</lpage>
        <pub-id pub-id-type="doi">10.1021/pr500194t</pub-id>
        <pub-id pub-id-type="pmid">24792918</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jian</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Xia</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Niu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Samir</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Link</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>L2 multiple kernel fuzzy svm-based data fusion for improving peptide identification</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinforma</source>
        <year>2016</year>
        <volume>13</volume>
        <issue>4</issue>
        <fpage>804</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2015.2480084</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Slagel</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Mendoza</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Shteynberg</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Deutsch</surname>
            <given-names>EW</given-names>
          </name>
          <name>
            <surname>Moritz</surname>
            <given-names>RL</given-names>
          </name>
        </person-group>
        <article-title>Processing shotgun proteomics data on the amazon cloud with the trans-proteomic pipeline</article-title>
        <source>Mol Cell Proteomics</source>
        <year>2015</year>
        <volume>14</volume>
        <issue>2</issue>
        <fpage>399</fpage>
        <lpage>404</lpage>
        <pub-id pub-id-type="doi">10.1074/mcp.O114.043380</pub-id>
        <pub-id pub-id-type="pmid">25418363</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20</label>
      <mixed-citation publication-type="other">Feng XD, Li LW, Zhang JH, Zhu YP, Chang C, Shu K. -x., Ma J. Using the entrapment sequence method as a standard to evaluate key steps of proteomics data analysis process. BMC Genomics. 2017; 18(Suppl 2). 10.1186/s12864-017-3491-2.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vaudel</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Burkhart</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Breiter</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Zahedi</surname>
            <given-names>RP</given-names>
          </name>
          <name>
            <surname>Sickmann</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Martens</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>A complex standard for protein identification, designed by evolution</article-title>
        <source>J Proteome Res</source>
        <year>2012</year>
        <volume>11</volume>
        <issue>10</issue>
        <fpage>5065</fpage>
        <lpage>71</lpage>
        <pub-id pub-id-type="doi">10.1021/pr300055q</pub-id>
        <pub-id pub-id-type="pmid">22489649</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Granholm</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Noble</surname>
            <given-names>WS</given-names>
          </name>
          <name>
            <surname>Käll</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>On using samples of known protein content to assess the statistical calibration of scores assigned to peptide-spectrum matches in shotgun proteomics</article-title>
        <source>J Proteome Res</source>
        <year>2011</year>
        <volume>10</volume>
        <issue>5</issue>
        <fpage>2671</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1021/pr1012619</pub-id>
        <pub-id pub-id-type="pmid">21391616</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jian</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Niu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xia</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Samir</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Sumanasekera</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Mu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Jennings</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Hoek</surname>
            <given-names>KL</given-names>
          </name>
          <name>
            <surname>Allos</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Howard</surname>
            <given-names>LM</given-names>
          </name>
          <name>
            <surname>Edwards</surname>
            <given-names>KM</given-names>
          </name>
          <name>
            <surname>Weil</surname>
            <given-names>PA</given-names>
          </name>
          <name>
            <surname>Link</surname>
            <given-names>AJ</given-names>
          </name>
        </person-group>
        <article-title>A novel algorithm for validating peptide identification from a shotgun proteomics search engine</article-title>
        <source>J Proteome Res</source>
        <year>2013</year>
        <volume>12</volume>
        <issue>3</issue>
        <fpage>1108</fpage>
        <lpage>19</lpage>
        <pub-id pub-id-type="doi">10.1021/pr300631t</pub-id>
        <pub-id pub-id-type="pmid">23402659</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24</label>
      <mixed-citation publication-type="other">Shteynberg D, Mendoza L, Hoopmann M, Eng J, Lam H. Trans-Proteomic Pipeline. 2018. <ext-link ext-link-type="uri" xlink:href="http://tools.proteomecenter.org/wiki/index.php?title=Software:TPP">http://tools.proteomecenter.org/wiki/index.php?title=Software:TPP</ext-link>. Accessed 4 Nov 2019.</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25</label>
      <mixed-citation publication-type="other">Mcdonald H, Tabb D, Sadygov R, Maccoss M, Venable J, Graumann J, R Johnson J, Cociorva D, Yates J. Ms1, ms2, and sqt - three unified, compact, and easily parsed file formats for the storage of shotgun proteomic spectra and identifications. 2004; 18:2162–8. 10.1002/rcm.1603.</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26</label>
      <mixed-citation publication-type="other">Bill N. SQT file format. 2004. <ext-link ext-link-type="uri" xlink:href="http://crux.ms/file-formats/sqt-format.html">http://crux.ms/file-formats/sqt-format.html</ext-link>. Accessed 15 Dec 2019.</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Burges</surname>
            <given-names>CJC</given-names>
          </name>
        </person-group>
        <article-title>A tutorial on support vector machines for pattern recognition</article-title>
        <source>Data Min Knowl Discov</source>
        <year>1998</year>
        <volume>2</volume>
        <fpage>121</fpage>
        <lpage>67</lpage>
        <pub-id pub-id-type="doi">10.1023/A:1009715923555</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28</label>
      <mixed-citation publication-type="other">Wang Y, Liang X, Xia ZX, Niu X, Link AJ. Improved classification model for peptide identification based on self-paced learning. In: IEEE International Conference on Bioinformatics and Biomedicine (BIBM): 2017. p. 258–61. 10.1109/bibm.2017.8217659.</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29</label>
      <mixed-citation publication-type="other">Meng D, Zhao Q, Jiang L. What objective does self-paced learning indeed optimize? 2015. arXiv:1511.06049.</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yuille</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Rangarajan</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>The concave-convex procedure</article-title>
        <source>Neural Comput</source>
        <year>2003</year>
        <volume>15</volume>
        <issue>4</issue>
        <fpage>915</fpage>
        <lpage>36</lpage>
        <pub-id pub-id-type="doi">10.1162/08997660360581958</pub-id>
        <pub-id pub-id-type="pmid">12689392</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Boyd</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Vandenberghe</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <source>Convex Optimization</source>
        <year>2004</year>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>Cambridge university press</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bordes</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ertekin</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Weston</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bottou</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Fast kernel classifiers with online and active learning</article-title>
        <source>J Mach Learn Res</source>
        <year>2005</year>
        <volume>6</volume>
        <issue>6</issue>
        <fpage>1579</fpage>
        <lpage>619</lpage>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ertekin</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Bottou</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Giles</surname>
            <given-names>CL</given-names>
          </name>
        </person-group>
        <article-title>Nonconvex online support vector machines</article-title>
        <source>IEEE Trans Pattern Anal Mach Intell</source>
        <year>2011</year>
        <volume>33</volume>
        <issue>2</issue>
        <fpage>368</fpage>
        <lpage>81</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2010.109</pub-id>
        <pub-id pub-id-type="pmid">20513924</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Bottou</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Stochastic gradient learning in neural networks</article-title>
        <source>Proceedings of Neuro-Nîmes, vol. 91</source>
        <year>1991</year>
        <publisher-loc>France</publisher-loc>
        <publisher-name>The International Neural Society (INNS), Nimes</publisher-name>
      </element-citation>
    </ref>
  </ref-list>
</back>
