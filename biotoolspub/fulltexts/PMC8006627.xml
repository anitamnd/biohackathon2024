<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Biomed Semantics</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Biomed Semantics</journal-id>
    <journal-title-group>
      <journal-title>Journal of Biomedical Semantics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2041-1480</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8006627</article-id>
    <article-id pub-id-type="publisher-id">236</article-id>
    <article-id pub-id-type="doi">10.1186/s13326-021-00236-2</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>De-identifying Spanish medical texts - named entity recognition applied to radiology reports</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Pérez-Díez</surname>
          <given-names>Irene</given-names>
        </name>
        <address>
          <email>ipediez93@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Pérez-Moraga</surname>
          <given-names>Raúl</given-names>
        </name>
        <address>
          <email>rperez@cipf.es</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>López-Cerdán</surname>
          <given-names>Adolfo</given-names>
        </name>
        <address>
          <email>adlpecer@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Salinas-Serrano</surname>
          <given-names>Jose-Maria</given-names>
        </name>
        <address>
          <email>salinas_josser@gva.es</email>
        </address>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4505-8399</contrib-id>
        <name>
          <surname>la Iglesia-Vayá</surname>
          <given-names>María de</given-names>
        </name>
        <address>
          <email>miglesia@cipf.es</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.428862.2</institution-id><institution>FISABIO-CIPF Joint Research Unit in Biomedical Imaging. Fundació per al Foment de la Investigació Sanitària i Biomèdica (FISABIO), </institution></institution-wrap>Av. de Catalunya 21, València, 46020 Spain </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.418274.c</institution-id><institution-id institution-id-type="ISNI">0000 0004 0399 600X</institution-id><institution>Bioinformatics and Biostatistics Unit. Centro de Investigación Príncipe Felipe (CIPF), </institution></institution-wrap>Carrer d’Eduardo Primo Yúfera 3, València, 46012 Spain </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.412878.0</institution-id><institution-id institution-id-type="ISNI">0000 0004 1769 4352</institution-id><institution>ESI International Chair@CEU-UCH, Departamento de Matemáticas, Física y Ciencias Tecnológicas, Universidad Cardenal Herrera-CEU, CEU Universities, </institution></institution-wrap>Calle San Bartolomé 55, Alfafara del Patriarca, 46115 Spain </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.411263.3</institution-id><institution>Health Informatics Department, </institution><institution>Hospital San Juan de Alicante, </institution></institution-wrap>Sant Joan d’Alacant, 03550 Spain </aff>
      <aff id="Aff5"><label>5</label>Regional ministry of Universal Health and Public Health in Valencia, Carrer de Misser Mascó 31, València, 46010 Spain </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="GRID">grid.413448.e</institution-id><institution-id institution-id-type="ISNI">0000 0000 9314 1427</institution-id><institution>CIBERSAM, ISCIII, </institution></institution-wrap>Av. Blasco Ibáñez 15, València, 46010 Spain </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>29</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>29</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>12</volume>
    <elocation-id>6</elocation-id>
    <history>
      <date date-type="received">
        <day>28</day>
        <month>4</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>2</day>
        <month>3</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Medical texts such as radiology reports or electronic health records are a powerful source of data for researchers. Anonymization methods must be developed to de-identify documents containing personal information from both patients and medical staff. Although currently there are several anonymization strategies for the English language, they are also language-dependent. Here, we introduce a named entity recognition strategy for Spanish medical texts, translatable to other languages.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">We tested 4 neural networks on our radiology reports dataset, achieving a recall of 97.18% of the identifying entities. Alongside, we developed a randomization algorithm to substitute the detected entities with new ones from the same category, making it virtually impossible to differentiate real data from synthetic data. The three best architectures were tested with the MEDDOCAN challenge dataset of electronic health records as an external test, achieving a recall of 69.18%.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">The strategy proposed, combining named entity recognition tasks with randomization of entities, is suitable for Spanish radiology reports. It does not require a big training corpus, thus it could be easily extended to other languages and medical texts, such as electronic health records.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Natural language processing</kwd>
      <kwd>Named entity recognition</kwd>
      <kwd>Radiology reports</kwd>
      <kwd>Medical texts</kwd>
      <kwd>Spanish</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010661</institution-id>
            <institution>Horizon 2020 Framework Programme</institution>
          </institution-wrap>
        </funding-source>
        <award-id>825111</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2021</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p>Medical imaging is widely used in clinical practice for the diagnosis and treatment of several diseases, such as Alzheimer, cancer or pneumothorax. Data from radiology reports, electronic health records and other medical texts such as clinical trial protocols are being used for research purposes [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Health care institutions, researchers and patients can greatly benefit from these datasets. However, these records and reports contain patient notes known as personal data that can challenge patient confidentiality and privacy, as provided for in the European Regulation on the protection of personal data [<xref ref-type="bibr" rid="CR3">3</xref>]. All words that could identify a patient must be removed or de-identified before data analysts start their research or even more before the dataset is published.</p>
    <p>From a legal point of view, Regulation (EU) 2016/67 on the protection of natural persons and with regard to the processing of personal data and on the free movement of such data [<xref ref-type="bibr" rid="CR3">3</xref>] provides the regulatory framework in the European Union. Although its application is mandatory to all its member states, its concrete implementation varies depending on each of them. In Spain, the Organic Law 3/2018 [<xref ref-type="bibr" rid="CR4">4</xref>] establishes the legal framework for data protection in biomedical research. Reuse of personal data for medical research needs to be approved by an ethics committee, and data must be at least pseudonymized before the researchers get access to it.</p>
    <p>Legal issues regarding data privacy are not the only source of concern. Direct consequences for patients are also a very important factor to be carefully considered. It is crucial to protect the private health details of a patient from any third party’s access, and avoid exposing identifiable personal data such as identifier numbers or addresses. De-identification is therefore essential to ensure patient privacy and comply with legal requirements.</p>
    <p>From a data management point of view, the de-identification methodology needs to be precise and recallable. Precision is needed to minimize the data loss of the de-identification process and to preserve the semantic meaning of the radiology report; recall allows getting the best de-identification possible and avoid leaving any identifiable information in the text [<xref ref-type="bibr" rid="CR5">5</xref>].</p>
    <p>Even though several de-identification or anonymization methodologies have been proposed in English, legislation differs on a national level worldwide and language-specific problems can arise, hence a different method for each language must be developed. These difficulties extend to any Natural Language Processing (NLP) implementation. In the biomedical field, NLP has been applied successfully in English, including for de-identification purposes [<xref ref-type="bibr" rid="CR6">6</xref>], but many of these strategies rely on language-specific resources and are not extensible to other languages [<xref ref-type="bibr" rid="CR7">7</xref>]. Apart from the English language, this problem has been assessed in French, where different strategies from machine learning to the use of dictionaries and lists have been proposed, along with protocols for corpus development [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR9">9</xref>]. In other languages such as German, Swedish, Dutch or Chinese some strategies and methodologies have also been proposed [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR10">10</xref>–<xref ref-type="bibr" rid="CR13">13</xref>], but there have been so far rather limited attempts in automatic de-identification for Spanish medical texts [<xref ref-type="bibr" rid="CR14">14</xref>–<xref ref-type="bibr" rid="CR16">16</xref>], such as the MEDDOCAN task [<xref ref-type="bibr" rid="CR16">16</xref>]. For the sake of giving an insight on the different approaches proposed by these authors, the datasets used and the performance of each work, we have summarized this information in Table <xref rid="Tab1" ref-type="table">1</xref>.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>State of the art summary for de-identification studies in non-English languages</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Study</th><th align="left">Methodology</th><th align="left">Recall</th><th align="left">F1-score</th><th align="left">Corpus size</th><th align="left">Identifying tokens</th></tr></thead><tbody><tr><td align="left">Dalianis et al. [<xref ref-type="bibr" rid="CR5">5</xref>]</td><td align="left">CRF</td><td align="left">0.715</td><td align="left">0.810</td><td align="left">100 clinical records, train set</td><td align="left">6170</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left">4-fold cross-validation</td><td align="left"/></tr><tr><td align="left">Menger et al. [<xref ref-type="bibr" rid="CR12">12</xref>]</td><td align="left">Regular expression rules</td><td align="left">0.916</td><td align="left">0.862</td><td align="left">2000 medical texts, development</td><td align="left">542, test set</td></tr><tr><td align="left"/><td align="left">and tree-based hashing</td><td align="left"/><td align="left"/><td align="left">400 medical texts, test set</td><td align="left"/></tr><tr><td align="left">Jian et al. [<xref ref-type="bibr" rid="CR13">13</xref>]</td><td align="left">Rule-based and CRF</td><td align="left">0.851</td><td align="left">0.848</td><td align="left">201 sentences, train set</td><td align="left">1259, train set</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left">1000 clinical records, test set</td><td align="left"/></tr><tr><td align="left">Lange et al. [<xref ref-type="bibr" rid="CR28">28</xref>]</td><td align="left">BiLSTM with CRF</td><td align="left">0.974</td><td align="left">0.974</td><td align="left">500 clinical records, train set</td><td align="left">11333, train set</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left">250 clinical records, development</td><td align="left">5801, development</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left">250 clinical records, test set</td><td align="left">5661, test set</td></tr><tr><td align="left">Jiang et al. [<xref ref-type="bibr" rid="CR29">29</xref>]</td><td align="left">BERT and flair system</td><td align="left">0.968</td><td align="left">0.962</td><td align="left">500 clinical records, train set</td><td align="left">11333, train set</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left">250 clinical records, development</td><td align="left">5801, development</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left">250 clinical records, test set</td><td align="left">5661, test set</td></tr><tr><td align="left">Pérez et al. [<xref ref-type="bibr" rid="CR30">30</xref>]</td><td align="left">spaCy</td><td align="left">0.953</td><td align="left">0.960</td><td align="left">500 clinical records, train set</td><td align="left">11333, train set</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left">250 clinical records, development</td><td align="left">5801, development</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left">250 clinical records, test set</td><td align="left">5661, test set</td></tr></tbody></table><table-wrap-foot><p>The table describes the methodology used by the authors, the performance of the approach and the corpus size in number of documents and number of identifying tokens. From MEDDOCAN, the top 3 best-performing models were included</p></table-wrap-foot></table-wrap></p>
    <p>Most of the works around text de-identification are based on pattern matching or machine learning, or even a combination of both. Whereas pattern matching does not account for the context of a word and is unaware of typographical errors, machine learning techniques require a large corpus of annotated text [<xref ref-type="bibr" rid="CR17">17</xref>]. Since our radiology reports were mostly free text with sensitive data outside headers, we opted for annotating our own corpus and developing a Named Entity Recognition (NER) based de-identification method.</p>
    <p>NER is a sequence tagging task comprised inside the field of NLP, which focuses on assigning different tokens or words into specific predefined classes, such as persons, dates or organizations. NLP tasks are usually based on recurrent neural networks (RNNs), and NER approaches tend to employ long short-term memory units (LSTM) [<xref ref-type="bibr" rid="CR18">18</xref>] combined with conditional random fields (CRF) [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR20">20</xref>]. LSTMs are variants of RNNs that can cope with long distance dependencies in the text, and for many applications it is beneficial to access to left and right context in the sentence through bi-directional LSTMs [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR21">21</xref>]. Moreover, the reference model for several state-of-the-art NER implementations in English language is the bidirectional LSTM (BiLSTM)-CRF model by Lample et al. [<xref ref-type="bibr" rid="CR22">22</xref>–<xref ref-type="bibr" rid="CR24">24</xref>]. Some implementations combine LSTM units with convolutional layers [<xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR25">25</xref>], and other architectures such as Bidirectional Encoder Representations for Transformers (BERT) [<xref ref-type="bibr" rid="CR26">26</xref>] have been proposed for several NLP tasks, including NER.</p>
    <p>Although some contests and projects have been organized to exploit the content of unstructured clinical records in Spanish language using NLP tools, they are not focused on de-identification. For example, Cantemist (Cancer Text Mining SharedTask) is a project held to gather a community effort to create tools and models to perform text mining using NLP in oncological records [<xref ref-type="bibr" rid="CR27">27</xref>]. The best performing models in this contest were based on BiLSTM with CRF. Nevertheless, regarding the de-identification of clinical text for secondary use, in 2019 the MEDDOCAN (Medical Document Anonymization) task was organized. The most successful models in this task employ deep learning-based methodologies to perform a NER detection task, for instance, the winner model presented by Lange et al. [<xref ref-type="bibr" rid="CR28">28</xref>] used a network based on BiLSTM-CRF and achieved a recall and F1 score of 0.974. The second-best model for the de-identification task was designed by Jiang et al. [<xref ref-type="bibr" rid="CR29">29</xref>] with a model based on BERT and Flair embeddings, and achieved a recall of 0.962 and a F1 score of 0.968. The third proposed model used a spaCy NER model achieving a recall of 0.953 and F1 score of 0.960 [<xref ref-type="bibr" rid="CR30">30</xref>].</p>
    <p>Having in mind that the best NER approaches in Spanish language and in the general literature are based on RNNs with LSTM units and CRF, we decided to focus our work on these architectures. Nevertheless, automatic de-identification approaches do not achieve a perfect recall score, meaning that sensitive information could be leaked. To address this issue, we have proposed and developed a methodology to combine both NER and the replacement of the named entities recognized with synthetic data.</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <p>The proposed methodology is based on a combination of NER and the substitution of the detected sensitive words with others randomly sampled from databases. The approach started with the definition of the named entities that contain sensitive information and the annotation of the corpus (Fig. <xref rid="Fig1" ref-type="fig">1</xref>a). Then, a randomizer script was created based on publicly available databases to create a synthetic corpus by substituting the manually annotated words by new ones extracted from the databases (Fig. <xref rid="Fig1" ref-type="fig">1</xref>b). This corpus was then fed to different NER neural networks to assess their performance and select the most suitable model for the desired application (Fig. <xref rid="Fig1" ref-type="fig">1</xref>c). Lastly, when a new radiology record needs to be de-identified, the trained model detects the named entities and the randomizer script substitutes them with random words of the same category (Fig. <xref rid="Fig1" ref-type="fig">1</xref>d).
<fig id="Fig1"><label>Fig. 1</label><caption><p>Summary of the proposed de-identification approach. <bold>a</bold> Corpus creation, annotation and manual revision, further detailed in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. <bold>b</bold> Selection of databases to develop a randomizer script. The script is used to create the synthetic corpus. <bold>c</bold> Training and testing of different neural networks to select the best performing model. <bold>d</bold> When a new report needs to be de-identified, the selected model labels the words that belong to one of the defined named entities. Finally, the randomizer script creates a de-identified report with synthetic information</p></caption><graphic xlink:href="13326_2021_236_Fig1_HTML" id="MO1"/></fig></p>
    <sec id="Sec3">
      <title>Named entities</title>
      <p>Given that there is no specific guidance in the Spanish legal system on what information has to be removed to de-identify medical texts, we decided to assess the presence in our corpus of the Protected Health Information (PHI) categories defined by the Health Insurance Portability and Accountability Act (HIPAA) in the United States of America [<xref ref-type="bibr" rid="CR31">31</xref>]. After manual inspection of the data and considering the scope of this work, we performed a sub-selection of PHI categories and finally grouped them in 6 Named Entities (NEs) as shown in Table <xref rid="Tab2" ref-type="table">2</xref>. Some NEs included other information that should be protected to preserve the privacy of patients or doctors but was not included in PHI categories, such as digital signatures or healthcare centres. The named entities selected were: 
<list list-type="bullet"><list-item><p>NAME (name): This NE includes names and surnames of any person mentioned in the radiology record, typically patients or medical staff.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Named entities selected for this task and their associated Protected Health Information categories</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">NEs</th><th align="left">Description</th><th align="left">PHIs</th></tr></thead><tbody><tr><td align="left">CAB</td><td align="justify">Section headers</td><td align="justify">-</td></tr><tr><td align="left">NAME</td><td align="justify">Names and surnames (patient and others)</td><td align="justify">Names</td></tr><tr><td align="left">DIR</td><td align="justify">Full addresses, including streets, numbers and zip codes</td><td align="justify">Geographic data</td></tr><tr><td align="left">LOC</td><td align="justify">Cities, inside and outside addresses</td><td align="justify">Geographic data</td></tr><tr><td align="left">NUM</td><td align="justify">Numbers or alphanumeric strings that might identify someone, including digital signatures, patient numbers, medical numbers, medical license numbers and others</td><td align="justify">medical record numbers, social security numbers, account numbers, any unique identifying number or code</td></tr><tr><td align="left">FECHA</td><td align="justify">Dates</td><td align="justify">Dates</td></tr><tr><td align="left">INST</td><td align="justify">Hospitals, healthcare centres or other institutions that might point to someone’s location</td><td align="justify">-</td></tr></tbody></table></table-wrap></p></list-item><list-item><p>DIR (address): Includes geographic data in form of full addresses, including streets and zip codes.</p></list-item><list-item><p>LOC (locations): Considers geographic data referring only to cities, villages and other populated areas. This is differentiated from the DIR named entity due to the possibility of a city to be mentioned out of the context of a full address, for example, next to a data as in “14 de Abril, Valencia”.</p></list-item><list-item><p>NUM (numbers): Includes any number or alphanumeric string that might identify a person, such as patient record identification numbers, medical license numbers, digital signatures, fiscal identification numbers and others.</p></list-item><list-item><p>FECHA (dates): Any date available in the report, either numeric or written.</p></list-item><list-item><p>INST (institutions): Any healthcare facility or institution mentioned in the radiology record that could be used to narrow the location of a patient or medical staff.</p></list-item></list></p>
      <p>Header sections (CAB) were included as a seventh NE to ensure that they were not removed from the final text. These headers are necessary for further analysis, being key to extract the most relevant information of a radiology report.</p>
    </sec>
    <sec id="Sec4">
      <title>Corpus construction</title>
      <p>The de-identification corpus consists of brain imaging radiology reports randomly extracted from the Medical Imaging Databank of the Valencian Region (BIMCV) database [<xref ref-type="bibr" rid="CR32">32</xref>, <xref ref-type="bibr" rid="CR33">33</xref>], distributed among 17 health departments of the Valencian Region (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). A total of 7848 records were initially retrieved and automatically pre-annotated using the Spanish National Statistics Institute name and surname database [<xref ref-type="bibr" rid="CR34">34</xref>], which includes those names with a frequency higher or equal to 20 in Spain, and a list of the hospital names in the Valencian Region. To ensure the presence of personal information in our corpus, a subset of reports with at least two “NAME” tags was extracted. This filter left out of the selected reports those including words like “cabeza”, included in the text as an anatomical part although it can be also a surname, but containing no sensitive information. One-third of those reports were randomly selected to be manually corrected and annotated, with a final corpus of 692 records. The annotations were manually reviewed by three annotators, including finally all the NE tags.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Data curation process and corpus preparation workflow. <bold>a</bold> 7848 radiology reports in total were retrieved from BIMCV database. <bold>b</bold> We used a custom Python script to automatically annotate the names, surnames and hospital names from radiology reports. <bold>c</bold> A subset of records was made meeting the condition that more than one ‘name’ tag was present, remaining 2214 reports. <bold>d</bold> Another subsetting was performed to randomly select one-third of reports to be manually annotated and corrected by three annotators. After the manual revision, 692 reports remain. <bold>e</bold> Ground Truth dataset was divided into 3 subsets: the training set included 447 reports, validation 213, and test 32 reports from healthcare department number 7</p></caption><graphic xlink:href="13326_2021_236_Fig2_HTML" id="MO2"/></fig></p>
      <p>Radiology reports were not pre-processed so that they remain unchanged after the de-identification, apart from the identifying information. Although our radiology reports were mostly free-text sections preceded by headers, the 7th health department lacked headers and had an increased number of entities entirely out of context: this is, a name or a surname with no more text in an independent line, as shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. With this in mind, we divided our dataset into three sets: 
<list list-type="bullet"><list-item><p>Training set, including 447 randomly selected records from all the departments, including 65 reports from the 7th health department.
<fig id="Fig3"><label>Fig. 3</label><caption><p>Partial examples of radiology reports from validation and test. Validation set (<bold>a</bold>) has metadata headers clearly defined. In turn, test set (<bold>b</bold>) has metadata headers in Valencian language and metadata information detached from these headers by a line break. Both structures include identifiable information in new lines without metadata headers. Any name, surname, address, identification number or date presented in the figure are fictitious</p></caption><graphic xlink:href="13326_2021_236_Fig3_HTML" id="MO3"/></fig></p></list-item><list-item><p>Validation set, including 213 randomly selected records from all the departments except 7th department.</p></list-item><list-item><p>Test set, including 32 randomly selected records from the 7th department.</p></list-item></list></p>
      <p>To assess the performance of our final model with external data, we decided to incorporate 100 randomly selected clinical records from the MEDDOCAN task [<xref ref-type="bibr" rid="CR16">16</xref>]. These records have a different structure (Fig. <xref rid="Fig4" ref-type="fig">4</xref>) and are not related to radiology.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Structure differences between the radiology records used for training/testing and the clinical records from MEDDOCAN. <bold>a</bold> Radiology record from the Valencian Region, where names, surnames and other sensitive information from patients and medical staff are not always in the same line that the metadata information. <bold>b</bold> Clinical record from MEDDOCAN, where sensitive data is preceded by their correspondent metadata descriptors. Any name, surname, address, identification number or date present in the figure are fictitious</p></caption><graphic xlink:href="13326_2021_236_Fig4_HTML" id="MO4"/></fig></p>
      <p>Whereas both training and validation sets present a similar distribution of NEs (Table <xref rid="Tab3" ref-type="table">3</xref>), the test set shows an increase of addresses, locations and institutions. Having a separate test for department 7 allows us to check the performance of our method with highly unstructured data, with a distribution of NEs different from the training. As shown in Table <xref rid="Tab3" ref-type="table">3</xref>, addresses and locations are the NEs with the lowest sample size.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Number and percentage of annotations per corpus subset: Training, validation and test</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Training (words / %)</th><th align="left">Validation (words / %)</th><th align="left">Test (words / %)</th></tr></thead><tbody><tr><td align="left">CAB</td><td align="justify">1987 / 21.37%</td><td align="left">993 / 20.87%</td><td align="left">120 / 9.4%</td></tr><tr><td align="left">NAME</td><td align="justify">3286 / 35.34%</td><td align="left">1591 / 33.45%</td><td align="left">386 / 30.25%</td></tr><tr><td align="left">DIR</td><td align="justify">128 / 1.38%</td><td align="left">106 / 2.23%</td><td align="left">72 / 5.64%</td></tr><tr><td align="left">LOC</td><td align="justify">79 / 0.85%</td><td align="left">46 / 0.97%</td><td align="left">26 / 2.04%</td></tr><tr><td align="left">NUM</td><td align="justify">1159 / 12.47%</td><td align="left">585 / 12.29%</td><td align="left">143 / 11.21%</td></tr><tr><td align="left">FECHA</td><td align="justify">1655 / 17.79%</td><td align="left">897 / 18.86%</td><td align="left">300 / 23.51%</td></tr><tr><td align="left">INST</td><td align="justify">1004 / 10.80%</td><td align="left">539 / 11.33%</td><td align="left">229 / 17.95%</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec5">
      <title>NE randomization</title>
      <p>We developed a methodology to randomize the PHIs found in a text, and applied it to the manually labelled dataset, obtaining a synthetic corpus. This methodology applies a set of rules depending on the NE associated with each tagged word. It is based on the substitution of tagged entities with new words randomly extracted from different databases available online: 
<list list-type="bullet"><list-item><p>Spanish National Statistics Institute name and surname database [<xref ref-type="bibr" rid="CR34">34</xref>], weighted by frequency. This database includes foreign names and surnames, such as Xiaojing, Steven, Abdul or Harrison.</p></list-item><list-item><p>Spanish National Statistics Institute municipal register database [<xref ref-type="bibr" rid="CR35">35</xref>], weighted by population in 2019.</p></list-item><list-item><p>National Hospital Index [<xref ref-type="bibr" rid="CR36">36</xref>].</p></list-item><list-item><p>National Outpatients Clinic Index [<xref ref-type="bibr" rid="CR37">37</xref>].</p></list-item><list-item><p>Municipality addresses [<xref ref-type="bibr" rid="CR38">38</xref>].</p></list-item></list></p>
      <p>With the aim of avoiding the leakage of sensitive personal data, this methodology also checks that the randomly chosen word or number is not the same as the original one.</p>
    </sec>
    <sec id="Sec6">
      <title>Networks</title>
      <p>A variety of neural networks were tested and evaluated, all of them designed for NER tasks. Three network architectures were based on Bidirectional Long Short-Term Memory (BiLSTM) layers, obtained from Guillaume Genthial’s GitHub repository [<xref ref-type="bibr" rid="CR39">39</xref>]: 
<list list-type="bullet"><list-item><p>LSTM-CRF: GloVe vectors, BiLSTM and Conditional Random Fields (CRF) based on the work of Huang <italic>et al</italic> [<xref ref-type="bibr" rid="CR20">20</xref>].</p></list-item><list-item><p>LSTM-LSTM-CRF: GloVe vectors, character embeddings, BiLSTM for character embeddings, BiLSTM and CRF, based on the work of Lample <italic>et al</italic> [<xref ref-type="bibr" rid="CR22">22</xref>].</p></list-item><list-item><p>Conv-LSTM-CRF: GloVe vectors, character embeddings with 1D convolution and max pooling, BiLSTM and CRF, based on the work of Ma and Hovy [<xref ref-type="bibr" rid="CR40">40</xref>].</p></list-item></list></p>
      <p>These networks were trained with and without Exponential Moving Average (EMA) of the weights. We also trained a spaCy [<xref ref-type="bibr" rid="CR24">24</xref>] NER model, based partly on the work of Lample <italic>et al</italic> [<xref ref-type="bibr" rid="CR22">22</xref>] with Bloom embeddings along with Convolutional Neural Networks (CNNs) with an attention mechanism.</p>
    </sec>
    <sec id="Sec7">
      <title>Evaluation metrics</title>
      <p>To assess the performance of the different models trained we computed precision, recall and F1-score metrics. These metrics can be defined as: 
<disp-formula id="Equa"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$precision = \frac{TP}{TP + FP} $$ \end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mtext mathvariant="italic">precision</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext mathvariant="italic">TP</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext mathvariant="italic">FP</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="13326_2021_236_Article_Equa.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equb"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$recall = \frac{TP}{TP + FN} $$ \end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mtext mathvariant="italic">recall</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext mathvariant="italic">TP</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext mathvariant="italic">FN</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="13326_2021_236_Article_Equb.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equc"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$F1 score = \frac{2 \cdot precision \cdot recall}{precision + recall} $$ \end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mtext mathvariant="italic">score</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>·</mml:mo><mml:mtext mathvariant="italic">precision</mml:mtext><mml:mo>·</mml:mo><mml:mtext mathvariant="italic">recall</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">precision</mml:mtext><mml:mo>+</mml:mo><mml:mtext mathvariant="italic">recall</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="13326_2021_236_Article_Equc.gif" position="anchor"/></alternatives></disp-formula> being TP the number of true positives, FP the number of false positives, and FN the number of false negatives.</p>
      <p>To compute the amount of de-identification achieved by the model, we did not only apply these metrics to each NE, but to the set of words that should have been labelled as an identifying NE. With this approach, we obtained quantitative indicators of global de-identification.</p>
    </sec>
  </sec>
  <sec id="Sec8" sec-type="results">
    <title>Results</title>
    <p>First, models for each neural network were trained and then evaluated. Table <xref rid="Tab4" ref-type="table">4</xref> shows the mean global results of the different networks, given three replicates for each one.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Evaluation metrics for each of the different neural networks tested</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="3">Training set</th><th align="left" colspan="3">Validation set</th><th align="left" colspan="3">Test set</th></tr><tr><th align="left">Model</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th></tr></thead><tbody><tr><td align="left">LSTM-CRF</td><td align="left">90.39</td><td align="left">81.93</td><td align="left">85.95</td><td align="left">87.09</td><td align="left">77.11</td><td align="left">81.79</td><td align="left">81.35</td><td align="left">61.37</td><td align="left">69.96</td></tr><tr><td align="left">LSTM-CRF with EMA</td><td align="left">91.19</td><td align="left">84.15</td><td align="left">87.53</td><td align="left">87.05</td><td align="left">78.49</td><td align="left">82.55</td><td align="left">71.48</td><td align="left">59.65</td><td align="left">64.96</td></tr><tr><td align="left">LSTM-LSTM-CRF</td><td align="left">99.20</td><td align="left">98.79</td><td align="left">98.99</td><td align="left"><bold>98.13</bold></td><td align="left">97.18</td><td align="left">97.66</td><td align="left">93.01</td><td align="left">90.94</td><td align="left">91.96</td></tr><tr><td align="left">LSTM-LSTM-CRF with EMA</td><td align="left">99.06</td><td align="left">98.96</td><td align="left">99.01</td><td align="left">98.00</td><td align="left">97.34</td><td align="left">97.67</td><td align="left">94.20</td><td align="left"><bold>91.10</bold></td><td align="left"><bold>92.63</bold></td></tr><tr><td align="left">Conv-LSTM-CRF</td><td align="left">99.31</td><td align="left">99.05</td><td align="left">99.18</td><td align="left">98.11</td><td align="left">97.29</td><td align="left">97.70</td><td align="left"><bold>94.49</bold></td><td align="left">90.43</td><td align="left">92.41</td></tr><tr><td align="left">Conv-LSTM-CRF with EMA</td><td align="left">99.17</td><td align="left">99.05</td><td align="left">99.11</td><td align="left">98.08</td><td align="left"><bold>97.36</bold></td><td align="left"><bold>97.72</bold></td><td align="left">93.72</td><td align="left">90.64</td><td align="left">92.15</td></tr><tr><td align="left">Spacy</td><td align="left"><bold>99.87</bold></td><td align="left"><bold>99.28</bold></td><td align="left"><bold>99.58</bold></td><td align="left">98.06</td><td align="left">96.10</td><td align="left">97.07</td><td align="left">93.23</td><td align="left">89.39</td><td align="left">91.31</td></tr></tbody></table><table-wrap-foot><p>Bold font highlights the best metric in each data subset</p></table-wrap-foot></table-wrap></p>
    <p>The recall is one of the most relevant evaluation metrics in any de-identification process [<xref ref-type="bibr" rid="CR5">5</xref>], to avoid the leakage of sensitive information. Taking this into account, LSTM-LSTM-CRF with EMA shows the highest recall in test, and Conv-LSTM-CRF with EMA in validation. Although these are the two best-performing networks in both sets, we decided to include also spaCy for further analysis and leave outside the worst-performing architecture: LSTM-CRF.</p>
    <p>The performance stats of each NE for LSTM-LSTM-CRF with EMA, Conv-LSTM-CRF with EMA and spaCy are displayed in Tables <xref rid="Tab5" ref-type="table">5</xref>, <xref rid="Tab6" ref-type="table">6</xref> and <xref rid="Tab7" ref-type="table">7</xref>. Whereas in training set spaCy outperforms the other networks in every NE except for CAB, in validation and test sets the results are more contested. Evaluating F1-score in validation, LSTM-LSTM-CRF classifies better dates, locations, names and numbers, while spaCy stands out with institutions. On the other hand, Conv-LSTM-CRF performs better with addresses and shows higher recall in names than LSTM-LSTM-CRF. When analysing the results for the test set, the spaCy model shows better metrics in dates and better recall in institutions whereas LSTM-LSTM-CRF has a higher F1-score in institutions, locations and names. Conv-LSTM-CRF again performs better with addresses, but also with numbers and shows the highest recall in locations and names. When applying the models to MEDDOCAN dataset there’s a decay of the performance, although spaCy has higher recall rates in addresses, dates, institutions and name, whilst Conv-LSTM-CRF outperforms in locations and numbers.
<table-wrap id="Tab5"><label>Table 5</label><caption><p>Evaluation metrics obtained with LSTM-LSTM-CRF with EMA model for each named entity</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="3">Training set</th><th align="left" colspan="3">Validation set</th><th align="left" colspan="3">Test set</th><th align="left" colspan="3">MEDDOCAN</th></tr><tr><th align="left"/><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th></tr></thead><tbody><tr><td align="left">CAB</td><td align="left">98.29</td><td align="left">97.94</td><td align="left">98.11</td><td align="left">96.03</td><td align="left">94.92</td><td align="left">95.47</td><td align="left">83.69</td><td align="left">75.76</td><td align="left">79.53</td><td align="left">13.33</td><td align="left">33.33</td><td align="left">19.05</td></tr><tr><td align="left">DIR</td><td align="left">100</td><td align="left">100</td><td align="left">100</td><td align="left">93.49</td><td align="left">95.00</td><td align="left">94.22</td><td align="left">90.91</td><td align="left">90.91</td><td align="left">90.91</td><td align="left">0.00</td><td align="left">0.00</td><td align="left">0.00</td></tr><tr><td align="left">FECHA</td><td align="left">99.74</td><td align="left">99.64</td><td align="left">99.69</td><td align="left">98.93</td><td align="left">99.20</td><td align="left">99.07</td><td align="left">96.65</td><td align="left">94.83</td><td align="left">95.74</td><td align="left">74.95</td><td align="left">86.34</td><td align="left">80.20</td></tr><tr><td align="left">INST</td><td align="left">98.96</td><td align="left">98.96</td><td align="left">98.96</td><td align="left">95.73</td><td align="left">95.72</td><td align="left">95.73</td><td align="left">96.08</td><td align="left">96.08</td><td align="left">96.08</td><td align="left">11.11</td><td align="left">0.67</td><td align="left">1.26</td></tr><tr><td align="left">LOC</td><td align="left">100</td><td align="left">89.45</td><td align="left">94.42</td><td align="left">94.35</td><td align="left">87.88</td><td align="left">90.99</td><td align="left">92.58</td><td align="left">55.55</td><td align="left">69.41</td><td align="left">0.00</td><td align="left">0.00</td><td align="left">0.00</td></tr><tr><td align="left">NAME</td><td align="left">98.99</td><td align="left">99.15</td><td align="left">99.07</td><td align="left">98.97</td><td align="left">98.24</td><td align="left">98.60</td><td align="left">94.78</td><td align="left">95.13</td><td align="left">94.95</td><td align="left">61.62</td><td align="left">77.39</td><td align="left">68.59</td></tr><tr><td align="left">NUM</td><td align="left">99.39</td><td align="left">99.91</td><td align="left">99.65</td><td align="left">99.34</td><td align="left">98.69</td><td align="left">99.01</td><td align="left">96.65</td><td align="left">97.66</td><td align="left">97.15</td><td align="left">56.93</td><td align="left">68.28</td><td align="left">62.05</td></tr><tr><td align="left"/><td align="left">99.05</td><td align="left">98.96</td><td align="left">99.01</td><td align="left">98.00</td><td align="left">97.34</td><td align="left">97.67</td><td align="left">94.20</td><td align="left">91.10</td><td align="left">92.62</td><td align="left">62.35</td><td align="left">56.11</td><td align="left">59.07</td></tr></tbody></table></table-wrap><table-wrap id="Tab6"><label>Table 6</label><caption><p>Evaluation metrics obtained with Conv-LSTM-CRF with EMA model for each named entity</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="3">Training set</th><th align="left" colspan="3">Validation set</th><th align="left" colspan="3">Test set</th><th align="left" colspan="3">MEDDOCAN</th></tr><tr><th align="left"/><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th></tr></thead><tbody><tr><td align="left">CAB</td><td align="left">98.57</td><td align="left">97.99</td><td align="left">98.28</td><td align="left">96.82</td><td align="left">94.97</td><td align="left">95.89</td><td align="left">91.45</td><td align="left">76.89</td><td align="left">83.54</td><td align="left">0.78</td><td align="left">16.67</td><td align="left">1.48</td></tr><tr><td align="left">DIR</td><td align="left">100</td><td align="left">100</td><td align="left">100</td><td align="left">98.33</td><td align="left">95.00</td><td align="left">96.63</td><td align="left">93.94</td><td align="left">93.94</td><td align="left">93.94</td><td align="left">10.71</td><td align="left">1.18</td><td align="left">2.11</td></tr><tr><td align="left">FECHA</td><td align="left">99.71</td><td align="left">99.78</td><td align="left">99.74</td><td align="left">98.79</td><td align="left">99.13</td><td align="left">98.96</td><td align="left">95.77</td><td align="left">93.21</td><td align="left">94.47</td><td align="left">82.28</td><td align="left">86.21</td><td align="left">84.18</td></tr><tr><td align="left">INST</td><td align="left">98.96</td><td align="left">98.96</td><td align="left">98.96</td><td align="left">96.35</td><td align="left">95.94</td><td align="left">96.14</td><td align="left">92.91</td><td align="left">94.12</td><td align="left">93.51</td><td align="left">0.00</td><td align="left">0.00</td><td align="left">0.00</td></tr><tr><td align="left">LOC</td><td align="left">100</td><td align="left">91.56</td><td align="left">95.59</td><td align="left">92.89</td><td align="left">87.88</td><td align="left">90.29</td><td align="left">89.44</td><td align="left">55.56</td><td align="left">68.50</td><td align="left">20.83</td><td align="left">0.58</td><td align="left">1.12</td></tr><tr><td align="left">NAME</td><td align="left">99.17</td><td align="left">99.28</td><td align="left">99.23</td><td align="left">98.69</td><td align="left">98.28</td><td align="left">98.49</td><td align="left">92.31</td><td align="left">96.26</td><td align="left">94.23</td><td align="left">70.17</td><td align="left">77.39</td><td align="left">73.56</td></tr><tr><td align="left">NUM</td><td align="left">99.35</td><td align="left">99.88</td><td align="left">99.62</td><td align="left">98.98</td><td align="left">98.63</td><td align="left">98.80</td><td align="left">95.59</td><td align="left">95.57</td><td align="left">95.58</td><td align="left">64.53</td><td align="left">78.29</td><td align="left">70.69</td></tr><tr><td align="left"/><td align="left">99.17</td><td align="left">99.06</td><td align="left">99.11</td><td align="left">98.08</td><td align="left">97.36</td><td align="left">97.72</td><td align="left">93.72</td><td align="left">90.64</td><td align="left">92.16</td><td align="left">67.07</td><td align="left">58.90</td><td align="left">62.71</td></tr></tbody></table></table-wrap><table-wrap id="Tab7"><label>Table 7</label><caption><p>Evaluation metrics obtained with spaCy model for each named entity</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="3">Training set</th><th align="left" colspan="3">Validation set</th><th align="left" colspan="3">Test set</th><th align="left" colspan="3">MEDDOCAN</th></tr><tr><th align="left"/><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th></tr></thead><tbody><tr><td align="left">CAB</td><td align="left">99.43</td><td align="left">96.54</td><td align="left">97.96</td><td align="left">98.28</td><td align="left">93.98</td><td align="left">96.08</td><td align="left">92.54</td><td align="left">74.49</td><td align="left">82.52</td><td align="left">4.76</td><td align="left">33.33</td><td align="left">8.33</td></tr><tr><td align="left">DIR</td><td align="left">100</td><td align="left">100</td><td align="left">100</td><td align="left">94.28</td><td align="left">63.96</td><td align="left">76.01</td><td align="left">87.79</td><td align="left">74.77</td><td align="left">61.46</td><td align="left">43.15</td><td align="left">4.47</td><td align="left">8.01</td></tr><tr><td align="left">FECHA</td><td align="left">100</td><td align="left">100</td><td align="left">100</td><td align="left">98.54</td><td align="left">99.04</td><td align="left">98.78</td><td align="left">98.20</td><td align="left">97.53</td><td align="left">97.86</td><td align="left">51.39</td><td align="left">89.41</td><td align="left">65.13</td></tr><tr><td align="left">INST</td><td align="left">99.97</td><td align="left">99.96</td><td align="left">99.98</td><td align="left">98.19</td><td align="left">97.24</td><td align="left">97.71</td><td align="left">93.50</td><td align="left">98.00</td><td align="left">95.69</td><td align="left">45.72</td><td align="left">12.28</td><td align="left">19.27</td></tr><tr><td align="left">LOC</td><td align="left">100</td><td align="left">100</td><td align="left">100</td><td align="left">76.64</td><td align="left">54.66</td><td align="left">63.80</td><td align="left">61.04</td><td align="left">26.85</td><td align="left">36.79</td><td align="left">7.19</td><td align="left">0.32</td><td align="left">0.59</td></tr><tr><td align="left">NAME</td><td align="left">100</td><td align="left">99.99</td><td align="left">99.99</td><td align="left">98.34</td><td align="left">98.28</td><td align="left">98.31</td><td align="left">88.78</td><td align="left">94.29</td><td align="left">93.19</td><td align="left">75.62</td><td align="left">83.91</td><td align="left">79.23</td></tr><tr><td align="left">NUM</td><td align="left">100</td><td align="left">100</td><td align="left">100</td><td align="left">97.81</td><td align="left">95.65</td><td align="left">96.72</td><td align="left">95.11</td><td align="left">87.56</td><td align="left">91.18</td><td align="left">68.50</td><td align="left">60.32</td><td align="left">63.99</td></tr><tr><td align="left"/><td align="left">99.87</td><td align="left">99.28</td><td align="left">99.58</td><td align="left">98.06</td><td align="left">96.10</td><td align="left">97.08</td><td align="left">93.23</td><td align="left">89.39</td><td align="left">91.31</td><td align="left">65.63</td><td align="left">55.37</td><td align="left">59.98</td></tr></tbody></table></table-wrap></p>
    <p>Given that our aim was not to correctly classify NE, but to completely remove sensitive information from the text, global de-identification metrics were computed (Table <xref rid="Tab8" ref-type="table">8</xref>). Conv-LSTM-CRF with EMA shows better recall in validation and test sets (Fig. <xref rid="Fig5" ref-type="fig">5</xref>), whilst LSTM-LSTM-CRF has higher F1-score on test. On MEDDOCAN data, the model that better maintains recall and F1-score is LSTM-LSTM-CRF (Fig. <xref rid="Fig5" ref-type="fig">5</xref>, Table <xref rid="Tab8" ref-type="table">8</xref>). To assess the performance of our models with external data, we wanted to apply the models generated at MEDDOCAN to our data. Only one of the participants made their models available [<xref ref-type="bibr" rid="CR30">30</xref>], being one of the implemented networks spaCy. Their spaCy model achieved a precision of 87.89% and 80.31%, a recall of 42.66% and 26.54%, and an F1-score of 57.44% and 39.89% in our validation and our test, respectively (Table <xref rid="Tab8" ref-type="table">8</xref>).
<fig id="Fig5"><label>Fig. 5</label><caption><p>Global de-identification metrics for the three best performing architectures. Precision (<bold>a</bold>), recall (<bold>b</bold>) and F1-score (<bold>c</bold>) for the three best performing architectures, LSTM-LSTM-CRF with EMA (blue), Conv-LSTM-CRF with EMA (yellow) and spaCy (grey) by data subset</p></caption><graphic xlink:href="13326_2021_236_Fig5_HTML" id="MO5"/></fig><table-wrap id="Tab8"><label>Table 8</label><caption><p>Global de-identification metrics for LSTM-LSTM-CRF, Conv-LSTM-CRF, spaCy and the model retrieved from MEDDOCAN</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="3">Validation set</th><th align="left" colspan="3">Test set</th><th align="left" colspan="3">MEDDOCAN</th></tr><tr><th align="left"/><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1</th></tr></thead><tbody><tr><td align="left">LSTM-LSTM with EMA</td><td align="left">99.66</td><td align="left">99.29</td><td align="left">99.48</td><td align="left">99.08</td><td align="left">97.18</td><td align="left">98.10</td><td align="left">98.09</td><td align="left">69.18</td><td align="left">81.13</td></tr><tr><td align="left">Conv-LSTM-CRF with EMA</td><td align="left">99.58</td><td align="left">99.42</td><td align="left">99.50</td><td align="left">98.18</td><td align="left">97.43</td><td align="left">97.80</td><td align="left">97.11</td><td align="left">67.10</td><td align="left">79.36</td></tr><tr><td align="left">spaCy</td><td align="left">99.28</td><td align="left">94.15</td><td align="left">96.64</td><td align="left">95.69</td><td align="left">91.18</td><td align="left">93.38</td><td align="left">84.96</td><td align="left">61.69</td><td align="left">71.48</td></tr><tr><td align="left">MEDDOCAN model</td><td align="left">87.89</td><td align="left">42.66</td><td align="left">57.44</td><td align="left">80.31</td><td align="left">26.54</td><td align="left">38.89</td><td align="left">96.70*</td><td align="left">95.30*</td><td align="left">96.60*</td></tr></tbody></table><table-wrap-foot><p><sup>(*)</sup>Results extracted from the original publication [<xref ref-type="bibr" rid="CR30">30</xref>]</p></table-wrap-foot></table-wrap></p>
  </sec>
  <sec id="Sec9" sec-type="discussion">
    <title>Discussion</title>
    <p>This work has defined and evaluated a methodology based on NER to de-identify radiology reports in Spanish language. In comparison with traditional approaches based on regular expressions, NLP and neural networks do not underperform due to human misspellings or the absence of a clear and repeated structure. Neural networks are also context-dependent, and words like Cabeza (head), a common surname in Spanish that also refers to an anatomical part, will be detected as a “NAME” entity when used as a surname but left unchanged when used as a medical word, avoiding the loss of meaningful information.</p>
    <p>The main drawback of this methodology is the requi- rement of a learning corpus of de-identified reports, which is not necessary for regular expression-based strategies. Although the curation of a corpus is a tedious and methodical task, there is no need for a big dataset: with a training set of 447 texts, we achieved a suitable performance.</p>
    <p>Neural networks should be trained with a corpus diverse in structure to avoid overfitting. Machine learning models tend to learn the structure or format of the text, finding the position of words containing sensitive data when performing de-identification. If a model was trained with a corpus with a determined structure, it will only be able to de-identify similarly-formatted texts. By comparing our spaCy model with the spaCy model retrieved from MEDDOCAN [<xref ref-type="bibr" rid="CR30">30</xref>], we show the high impact that text structure has in the outcome. The MEDDOCAN training set was similar in size to ours (500 and 447 texts with a median of 20 and 22 lines per text, respectively), but their text structure was highly defined and invariant (texts from both datasets are compared at Fig. <xref rid="Fig4" ref-type="fig">4</xref>). With a training set diverse in its structure we can obtain higher recall and precision in external data, generating a de-identification model better prepared to deal with new data. Figure <xref rid="Fig3" ref-type="fig">3</xref> illustrates the structure and format diversity of radiological reports between health departments included in our dataset.</p>
    <p>Considering that the recall metric assesses the capability to avoid the leakage of sensitive information of a model, we propose LSTM-LSTM-CRF with EMA as the best neural network to address a de-identification task based on NER. This neural network showed higher F1-score in the test and MEDDOCAN, and its recall in validation and test sets are comparable to those obtained with Conv-LSTM-CRF with EMA. Furthermore, its recall on MEDDOCAN outperforms the one obtained by other networks. Thus, we expect LSTM-LSTM-CRF with EMA to behave optimally when presenting new data to it. Although its recall is 99.29 and 97.18 for validation and test sets respectively, it is not perfect. If we compare the results obtained by our models with those presented in MEDDOCAN, our LSTM-LSTM-CRF trained model outperforms the winner of MEDDOCAN contest at F1-score, 98.1 vs 97.4, but not at recall level, 97.1 vs 97.4, respectively. Thus, our presented models are close in terms of performance with those models presented on MEDDOCAN.</p>
    <p>When new radiology reports from the Valencian Region are included in BIMCV database, 97.18% of recall in test set means that almost 3% of identifying words will remain in the text. It might not be enough to re-identify the patient: could be left only a surname, a city name, or a part of an address. In fact, the de-identification methodology proposed in this work was applied to the COVID-19 image dataset described by de la Iglesia Vayá et al. [<xref ref-type="bibr" rid="CR41">41</xref>], that needed to be reused for research due to the medical emergency situation in 2020. The radiology records in this dataset were revised by radiologists, finding in 28 out of 11558 (0.24%) reports enough sensitive information to identify patients or medical staff. This included names, patient record identification numbers, birthdates or healthcare centre names. To ensure that the identity of a patient is not recoverable, a final check of the texts by an authorized person remains necessary. Nevertheless, we propose a randomization strategy to change the identified NEs for synthetic ones of the same category. This strategy masks the identifying words left by the neural network with synthetic information, making it more difficult to discern between real and synthetic identifying words than by simply erasing words (Fig. <xref rid="Fig6" ref-type="fig">6</xref>). Further efforts need to be done to validate whether this strategy makes original information irretrievable or not.
<fig id="Fig6"><label>Fig. 6</label><caption><p>Anonymization strategies. When applying word elimination (<bold>a</bold>) errors are easily detectable whereas with synthetic substitution (<bold>b</bold>) any mistake is hidden with randomized synthetic information. Any name, surname, address, identification number or date presented in the figure are fictitious</p></caption><graphic xlink:href="13326_2021_236_Fig6_HTML" id="MO6"/></fig></p>
  </sec>
  <sec id="Sec10" sec-type="conclusion">
    <title>Conclusions</title>
    <p>Medical texts hold great potential for research, but legal and privacy concerns arise with its use, even more, when institutions external to the hospital are involved. Real-world medical texts tend to be semi-structured with free text that includes sensitive information, thus classical de-identification approaches based on regular expressions are not good enough. We propose a robust and flexible framework based on NER for Spanish medical texts, tested on radiology reports from the Valencian Region. This framework is generic and relatively simple and can be easily generalizable to other Spanish medical texts by re-training the network with additional data. However, the applicability of the de-identification methodology to other languages needs to be evaluated. We consider that our approach can be replicated in other Romance derived languages, following the training of a BiLSTM-CRF network with suitable data and the application of the randomization strategy. The easiest network to implement for deep learning non-specialized teams would be spaCy, although it is not the best performing. The proposed de-identification methodology still missed identifiers after training, thus a final check of the texts by an authorized person remains necessary. Nevertheless, we believe a combination of NER with the generation of synthetic data will make it virtually impossible to extract real identifying words from the text. Further efforts need to be done to assess and test this hypothesis.</p>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>NLP</term>
        <def>
          <p>Natural language processing</p>
        </def>
      </def-item>
      <def-item>
        <term>NER</term>
        <def>
          <p>Named entity recognition</p>
        </def>
      </def-item>
      <def-item>
        <term>PHI</term>
        <def>
          <p>Protected health information</p>
        </def>
      </def-item>
      <def-item>
        <term>HIPAA</term>
        <def>
          <p>Health insurance portability and accountability act</p>
        </def>
      </def-item>
      <def-item>
        <term>NE</term>
        <def>
          <p>Named entity</p>
        </def>
      </def-item>
      <def-item>
        <term>BIMCV</term>
        <def>
          <p>Medical imaging databank of the Valencian Region</p>
        </def>
      </def-item>
      <def-item>
        <term>BiLSTM</term>
        <def>
          <p>Bidirectional long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>CRF</term>
        <def>
          <p>Conditional random fields</p>
        </def>
      </def-item>
      <def-item>
        <term>EMA</term>
        <def>
          <p>Exponential moving average</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p>Convolutional neural network</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>Irene P\'{e}rez-D\'{\i}ez and Ra\'{u}l P\'{e}rez-Moraga contributed equally to this work.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to thank the Medical Image Bank of the Valencian Community, from which the data used in this publication come from. We would also like to thank the support from the Regional Ministry of Innovation, Universities, Science and Digital Society, the Valencian Innovation Agency (Spain) and Regional Ministry of Health in Valencia Region, for applying this methodology in the COVID-19 dataset cited in this publication.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author’s contributions</title>
    <p>IPD.: conceptualization; data curation; formal analysis; investigation; methodology; software; validation, visualization; writing - original draft, review &amp; editing. RPM: conceptualization; data curation; formal analysis; investigation; methodology; software; validation, visualization; writing - original draft, review &amp; editing. ALC: conceptualization; data curation; writing - review &amp; editing. JMSS: project administration; resources; writing - review &amp; editing. MIV: conceptualization; funding acquisition; project administration; resources; supervision; writing - review &amp; editing.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This article describes work undertaken in the context of the DeepHealth project, “Deep-Learning and HPC to Boost Biomedical Applications for Health” (https://deephealth-project.eu/) which has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 825111”. The contents of this publication reflect only the author’s view, can in no way be taken to reflect the views of the European Union and the Community is not liable for any use that may be made of the information contained therein.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The data that support the findings of this study are available from BIMCV but restrictions apply to the availability of these data under a research use agreement. Data access can be requested at <ext-link ext-link-type="uri" xlink:href="http://bimcv.cipf.es/bimcv-projects/dismed">http://bimcv.cipf.es/bimcv-projects/dismed</ext-link></p>
    <p>Supplementary information and code are available online in GitHub.</p>
    <p>• Project name: DiSMed - De-identifying Spanish medical texts</p>
    <p>• Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/BIMCV-CSUSP/DiSMed">https://github.com/BIMCV-CSUSP/DiSMed</ext-link></p>
    <p>• Operating system(s): Platform independent</p>
    <p>• Programming language: Python</p>
    <p>• Other requirements: Python (version ≥3.5). DiSMed imports the following Python non-built-in libraries: pandas, numpy, codecs, spacy, tensorflow (version &lt;2)</p>
    <p>• License: MIT</p>
  </notes>
  <notes id="FPar1">
    <title>Ethics approval and consent to participate</title>
    <p>The study was approved by the local institutional ethics committee DGSP-CSISP NÚM. 20190503/12.</p>
  </notes>
  <notes id="FPar2" notes-type="COI-statement">
    <title>Competing interests</title>
    <p>The authors declare that they have no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hemingway</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Asselbergs</surname>
            <given-names>FW</given-names>
          </name>
          <name>
            <surname>Danesh</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Dobson</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Maniadakis</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Maggioni</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>van Thiel</surname>
            <given-names>GJM</given-names>
          </name>
          <name>
            <surname>Cronin</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Brobert</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Vardas</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Anker</surname>
            <given-names>SD</given-names>
          </name>
          <name>
            <surname>Grobbee</surname>
            <given-names>DE</given-names>
          </name>
          <name>
            <surname>and</surname>
            <given-names>SD</given-names>
          </name>
        </person-group>
        <article-title>Big data from electronic health records for early and late translational cardiovascular research: challenges and potential</article-title>
        <source>Eur Heart J</source>
        <year>2017</year>
        <volume>39</volume>
        <issue>16</issue>
        <fpage>1481</fpage>
        <lpage>95</lpage>
        <pub-id pub-id-type="doi">10.1093/eurheartj/ehx487</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bustos</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Pertusa</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Salinas</surname>
            <given-names>J-M</given-names>
          </name>
          <name>
            <surname>de la Iglesia-Vayá</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Padchest: A large chest x-ray image dataset with multi-label annotated reports</article-title>
        <source>Med Image Anal</source>
        <year>2020</year>
        <volume>66</volume>
        <fpage>101797</fpage>
        <pub-id pub-id-type="doi">10.1016/j.media.2020.101797</pub-id>
        <pub-id pub-id-type="pmid">32877839</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <collab>Council of the European Union</collab>
        </person-group>
        <article-title>Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and of the free movement of such data</article-title>
        <source>Off J</source>
        <year>2016</year>
        <volume>L119</volume>
        <fpage>1</fpage>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4</label>
      <mixed-citation publication-type="other">Cortes Generales de España. Ley Orgánica 3/2015, de 5 de diciembre, de protección de datos personales y garantía de los derechos digitales. Boletín Oficial del Estado. 2018:A-2018-16673.</mixed-citation>
    </ref>
    <ref id="CR5">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dalianis</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Velupillai</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>De-identifying Swedish clinical text-refinement of a gold standard and experiments with Conditional random fields</article-title>
        <source>J Biomed Semant</source>
        <year>2010</year>
        <volume>1</volume>
        <issue>1</issue>
        <fpage>6</fpage>
        <pub-id pub-id-type="doi">10.1186/2041-1480-1-6</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cardinal</surname>
            <given-names>RN</given-names>
          </name>
        </person-group>
        <article-title>Clinical records anonymisation and text extraction (CRATE): an open-source software system</article-title>
        <source>BMC Med Inf Decis Mak</source>
        <year>2017</year>
        <volume>17</volume>
        <issue>1</issue>
        <fpage>50</fpage>
        <pub-id pub-id-type="doi">10.1186/s12911-017-0437-1</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Névéol</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Dalianis</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Velupillai</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Savova</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Zweigenbaum</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Clinical natural language processing in languages other than english: opportunities and challenges</article-title>
        <source>J Biomed Semant</source>
        <year>2018</year>
        <volume>9</volume>
        <issue>1</issue>
        <fpage>12</fpage>
        <pub-id pub-id-type="doi">10.1186/s13326-018-0179-8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chazard</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Mouret</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ficheur</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Schaffar</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Beuscart</surname>
            <given-names>J-B</given-names>
          </name>
          <name>
            <surname>Beuscart</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Proposal and evaluation of FASDIM, a Fast And Simple De-Identification Method for unstructured free-text clinical records</article-title>
        <source>Int J Med Inform</source>
        <year>2014</year>
        <volume>83</volume>
        <issue>4</issue>
        <fpage>303</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ijmedinf.2013.11.005</pub-id>
        <pub-id pub-id-type="pmid">24370391</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grouin</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Névéol</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>De-identification of clinical notes in French: towards a protocol for reference corpus development</article-title>
        <source>J Biomed Inform</source>
        <year>2014</year>
        <volume>50</volume>
        <fpage>151</fpage>
        <lpage>61</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jbi.2013.12.014</pub-id>
        <pub-id pub-id-type="pmid">24380818</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10</label>
      <mixed-citation publication-type="other">Seuss H, Dankerl P, Ihle M, Grandjean A, Hammon R, Kaestle N, Fasching P, Maier C, Christoph J, Sedlmayr M, Uder M, Cavallaro A, Hammon M. Semi-automated De-identification of German Content Sensitive Reports for Big Data Analytics. In: RöFo - Fortschritte auf dem Gebiet der Röntgenstrahlen und der bildgebenden Verfahren: 2017. p. 661–71. 10.1055/s-0043-102939.</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Richter-Pechanski</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Amr</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Katus</surname>
            <given-names>HA</given-names>
          </name>
          <name>
            <surname>Dieterich</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Deep learning approaches outperform conventional strategies in de-identification of German medical reports</article-title>
        <source>Stud Health Technol Informat</source>
        <year>2019</year>
        <volume>267</volume>
        <fpage>101</fpage>
        <lpage>9</lpage>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Menger</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Scheepers</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>van Wijk</surname>
            <given-names>LM</given-names>
          </name>
          <name>
            <surname>Spruit</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>DEDUCE: A pattern matching method for automatic de-identification of Dutch medical text</article-title>
        <source>Telematics Inform</source>
        <year>2018</year>
        <volume>35</volume>
        <issue>4</issue>
        <fpage>727</fpage>
        <lpage>36</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tele.2017.08.002</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jian</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Lei</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>A cascaded approach for Chinese clinical text de-identification with less annotation effort</article-title>
        <source>J Biomed Inf</source>
        <year>2017</year>
        <volume>73</volume>
        <fpage>76</fpage>
        <lpage>83</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jbi.2017.07.017</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14</label>
      <mixed-citation publication-type="other">Medina S, Turmo J. Building a Spanish/Catalan health records corpus with very sparse protected information labelled. In: LREC 2018: Workshop MultilingualBIO: Multilingual Biomedical Text Processing: Proceedings: 2018. p. 1–7. <ext-link ext-link-type="uri" xlink:href="http://hdl.handle.net/2117/124710">http://hdl.handle.net/2117/124710</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Perez-Lainez</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Iglesias</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>de Pablo-Sanchez</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Anonymitext: anonimization of unstructured documents</article-title>
        <source>Proceedings of the International Conference on Knowledge Discovery and Information Retrieval</source>
        <year>2009</year>
        <publisher-loc>Funchal</publisher-loc>
        <publisher-name>INSTICC</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16</label>
      <mixed-citation publication-type="other">Marimon M, Gonzalez-Aguirre A, Intxaurrondo A, Rodríguez H, Martin J, Villegas M, Krallinger M. Automatic de-identification of medical texts in Spanish: the MEDDOCAN track, corpus, guidelines, methods and evaluation of results. In: Proceedings of the Iberian Language Evaluation Forum (IberLEF 2019): 2019. p. 618–38.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meystre</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Ferrández</surname>
            <given-names>Ó</given-names>
          </name>
          <name>
            <surname>Friedlin</surname>
            <given-names>FJ</given-names>
          </name>
          <name>
            <surname>South</surname>
            <given-names>BR</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Samore</surname>
            <given-names>MH</given-names>
          </name>
        </person-group>
        <article-title>Text de-identification for privacy protection: A study of its impact on clinical text information content</article-title>
        <source>J Biomed Inf</source>
        <year>2014</year>
        <volume>50</volume>
        <fpage>142</fpage>
        <lpage>50</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jbi.2014.01.011</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hochreiter</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Long short-term memory</article-title>
        <source>Neural Comput</source>
        <year>1997</year>
        <volume>9</volume>
        <issue>8</issue>
        <fpage>1735</fpage>
        <lpage>80</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
        <pub-id pub-id-type="pmid">9377276</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Lafferty</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>McCallum</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Pereira</surname>
            <given-names>FCN</given-names>
          </name>
        </person-group>
        <article-title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data</article-title>
        <source>Proceedings of the Eighteenth International Conference on Machine Learning ICML ’01</source>
        <year>2001</year>
        <publisher-loc>San Francisco, CA, USA</publisher-loc>
        <publisher-name>Morgan Kaufmann Publishers Inc.</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20</label>
      <mixed-citation publication-type="other">Huang Z, Xu W, Yu K. Bidirectional LSTM-CRF Models for Sequence Tagging. arXiv:1508.01991 [Preprint]. 2015. <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1508.01991">https://arxiv.org/abs/1508.01991</ext-link>. Accessed 19 Dec 2019.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Dyer</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ballesteros</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ling</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Matthews</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>NA</given-names>
          </name>
        </person-group>
        <article-title>Transition-based dependency parsing with stack long short-term memory</article-title>
        <source>Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</source>
        <year>2015</year>
        <publisher-loc>Beijing, China</publisher-loc>
        <publisher-name>Association for Computational Linguistics</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Lample</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Ballesteros</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Subramanian</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kawakami</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Dyer</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Neural architectures for named entity recognition</article-title>
        <source>Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</source>
        <year>2016</year>
        <publisher-loc>San Diego, California</publisher-loc>
        <publisher-name>Association for Computational Linguistics</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Vaswani</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Knight</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Marcu</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Name tagging for low-resource incident languages based on expectation-driven learning</article-title>
        <source>Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</source>
        <year>2016</year>
        <publisher-loc>San Diego, California</publisher-loc>
        <publisher-name>Association for Computational Linguistics</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24</label>
      <mixed-citation publication-type="other">Explosion: spaCy 2.0. 2018. <ext-link ext-link-type="uri" xlink:href="https://spacy.io/">https://spacy.io/</ext-link>. Accessed 16 Dec 2019.</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>dos Santos</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Guimarães</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Boosting named entity recognition with neural character embeddings</article-title>
        <source>Proceedings of the Fifth Named Entity Workshop</source>
        <year>2015</year>
        <publisher-loc>Beijing, China</publisher-loc>
        <publisher-name>Association for Computational Linguistics</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Devlin</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>M-W</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Toutanova</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>BERT: Pre-training of deep bidirectional transformers for language understanding</article-title>
        <source>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</source>
        <year>2019</year>
        <publisher-loc>Minneapolis, Minnesota</publisher-loc>
        <publisher-name>Association for Computational Linguistics</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27</label>
      <mixed-citation publication-type="other">Miranda-Escalada A, Farré-Maduell E, Krallinger M. Named entity recognition, concept normalization and clinical coding: Overview of the cantemist track for cancer text mining in spanish, corpus, guidelines, methods and results. In: Proceedings of the Iberian Language Evaluation Forum (IberLEF 2020), CEUR Workshop Proceedings: 2020. p. 303–23.</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28</label>
      <mixed-citation publication-type="other">Lange L, Adel H, Strötgen J. Neither-language-nor-domain-experts’ way of Spanish medical document de-identification. In: Proceedings of the Iberian Language Evaluation Forum (IberLEF 2019): 2019. p. 671–8.</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29</label>
      <mixed-citation publication-type="other">Jiang D, Shen Y, Chen S, Tang B, Wang X, Chen Q, Xu R, Yan J, Zhou Y. A deep learning-based system for the MEDDOCAN task. In: Proceedings of the Iberian Language Evaluation Forum (IberLEF 2019): 2019. p. 761–7.</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30</label>
      <mixed-citation publication-type="other">Perez N, García-Sardiña L, Serras M, Del Pozo A. Vimcotech at MEDDOCAN: Medical document anonymization. In: Proceedings of the Iberian Language Evaluation Forum (IberLEF 2019): 2019. p. 696–703.</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31</label>
      <mixed-citation publication-type="other">United States Congress. The Health Insurance Portability and Accountability Act (HIPAA). 1996. 104th Congress L.104-191.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32</label>
      <mixed-citation publication-type="other">BIMCV: Medical Imaging Databank of the Valencia Region. 2014. <ext-link ext-link-type="uri" xlink:href="https://bimcv.cipf.es/">https://bimcv.cipf.es/</ext-link>. Accessed 10 Dec 2019.</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Salinas</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>de la Iglesia-Vaya</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bonmati</surname>
            <given-names>LM</given-names>
          </name>
          <name>
            <surname>Valenzuela</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Cazorla</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>R &amp; D cloud CEIB: Management system and knowledge extraction for bioimaging in the cloud</article-title>
        <source>Distributed Computing and Artificial Intelligence</source>
        <year>2012</year>
        <publisher-loc>Berlin, Heidelberg</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34</label>
      <mixed-citation publication-type="other">Instituto Nacional de Estadística: Nombres y apellidos más frecuentes. 2019. https://www.ine.es/dyngs/INEbase/es/operacion.htm?c=Estadistica_{C}&amp;cid=1254736177009&amp;menu=ultiDatos&amp;idp= 1254734710990. Accessed 3 Jan 2020.</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35</label>
      <mixed-citation publication-type="other">Instituto Nacional de Estadística: Cifras oficiales de población resultantes de la revisión del Padrón municipal. 2019. https://www.ine.es/dynt3/inebase/es/index.htm?padre=517&amp;capsel=525. Accessed 3 Jan 2020.</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36</label>
      <mixed-citation publication-type="other">Ministerio de Sanidad, Consumo y Bienestar Social: Catálogo Nacional de Hospitales. 2019. <ext-link ext-link-type="uri" xlink:href="https://www.mscbs.gob.es/ciudadanos/prestaciones/centrosServiciosSNS/hospitales/home.htm">https://www.mscbs.gob.es/ciudadanos/prestaciones/centrosServiciosSNS/hospitales/home.htm</ext-link>. Accessed 3 Jan 2020.</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37</label>
      <mixed-citation publication-type="other">Ministerio de Sanidad, Consumo y Bienestar Social: Catálogo de Centros de Atención Primaria del SNS. 2019. <ext-link ext-link-type="uri" xlink:href="https://www.mscbs.gob.es/ciudadanos/prestaciones/centrosServiciosSNS/centrosSalud/home.htm">https://www.mscbs.gob.es/ciudadanos/prestaciones/centrosServiciosSNS/centrosSalud/home.htm</ext-link>. Accessed 3 Jan 2020.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38</label>
      <mixed-citation publication-type="other">Gobierno de España: Direcciones, tel. y CIF de todos los ayuntamientos de España. 2016. <ext-link ext-link-type="uri" xlink:href="https://datos.gob.es/en/peticiones-datos/direcciones-tel-y-cif-de-todos-los-ayuntamientosde-espana">https://datos.gob.es/en/peticiones-datos/direcciones-tel-y-cif-de-todos-los-ayuntamientosde-espana</ext-link>. Accessed 3 Jan 2020.</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39</label>
      <mixed-citation publication-type="other">Genthial G. Tensorflow – Named Entity Recognition. 2018. <ext-link ext-link-type="uri" xlink:href="https://github.com/guillaumegenthial/tf_ner">https://github.com/guillaumegenthial/tf_ner</ext-link>. Accessed 16 Dec 2019.</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Ma</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Hovy</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF</article-title>
        <source>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</source>
        <year>2016</year>
        <publisher-loc>Berlin, Germany</publisher-loc>
        <publisher-name>Association for Computational Linguistics</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41</label>
      <mixed-citation publication-type="other">de la Iglesia Vayà M, Saborit JM, Montell JA, Pertusa A, Bustos A, Cazorla M, Galant J, Barber X, Orozco-Beltrán D, García-García F, Caparrós M, González G, Salinas JM. BIMCV COVID-19+: a large annotated dataset of RX and CT images from COVID-19 patients. arXiv:2006.01174 [Preprint]. 2020. <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2006.01174">https://arxiv.org/abs/2006.01174</ext-link>. Accessed 15 Nov 2020.</mixed-citation>
    </ref>
  </ref-list>
</back>
