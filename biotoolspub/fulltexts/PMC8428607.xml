<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8428607</article-id>
    <article-id pub-id-type="pmid">34042953</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btab137</article-id>
    <article-id pub-id-type="publisher-id">btab137</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Systems Biology</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Using interpretable deep learning to model cancer dependencies</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-4034-8960</contrib-id>
        <name>
          <surname>Lin</surname>
          <given-names>Chih-Hsu</given-names>
        </name>
        <aff>
          <institution>Department of Molecular and Human Genetics</institution>
        </aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Lichtarge</surname>
          <given-names>Olivier</given-names>
        </name>
        <xref rid="btab137-cor1" ref-type="corresp"/>
        <aff>
          <institution>Department of Molecular and Human Genetics</institution>
        </aff>
        <aff>
          <institution>Department of Biochemistry and Molecular Biology</institution>
        </aff>
        <aff>
          <institution>Department of Pharmacology</institution>
        </aff>
        <aff><institution>Computational and Integrative Biomedical Research Center, Baylor College of Medicine, One Baylor Plaza</institution>, Houston, <addr-line>TX 77030</addr-line>, <country country="US">USA</country></aff>
        <!--lichtarge@bcm.edu-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Xu</surname>
          <given-names>Jinbo</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btab137-cor1">To whom correspondence should be addressed. <email>lichtarge@bcm.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>9</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-05-27">
      <day>27</day>
      <month>5</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>27</day>
      <month>5</month>
      <year>2021</year>
    </pub-date>
    <volume>37</volume>
    <issue>17</issue>
    <fpage>2675</fpage>
    <lpage>2681</lpage>
    <history>
      <date date-type="received">
        <day>09</day>
        <month>10</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>03</day>
        <month>2</month>
        <year>2021</year>
      </date>
      <date date-type="editorial-decision">
        <day>22</day>
        <month>2</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Â© The Author(s) 2021. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btab137.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Cancer dependencies provide potential drug targets. Unfortunately, dependencies differ among cancers and even individuals. To this end, visible neural networks (VNNs) are promising due to robust performance and the interpretability required for the biomedical field.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We design Biological visible neural network (BioVNN) using pathway knowledge to predict cancer dependencies. Despite having fewer parameters, BioVNN marginally outperforms traditional neural networks (NNs) and converges faster. BioVNN also outperforms an NN based on randomized pathways. More importantly, dependency predictions can be explained by correlating with the neuron output states of relevant pathways, which suggest dependency mechanisms. In feature importance analysis, BioVNN recapitulates known reaction partners and proposes new ones. Such robust and interpretable VNNs may facilitate the understanding of cancer dependency and the development of targeted therapies.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>Code and data are available at <ext-link xlink:href="https://github.com/LichtargeLab/BioVNN" ext-link-type="uri">https://github.com/LichtargeLab/BioVNN</ext-link></p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>NIH-GM079656</award-id>
        <award-id>NIH-GM066099</award-id>
        <award-id>AG061105</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Oskar Fischer Foundation</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Precision medicine aims to improve therapy based on individual patient and disease variations. In cancer, a promising approach is to target treatment on specific genetic vulnerabilities, which encode mechanisms essential to the survival and proliferation of cancer cells. Genetic dependencies differ among cancers and individuals, unfortunately, requiring resource-intensive experimental approaches [e.g. CRISPR screening (<xref rid="btab137-B7" ref-type="bibr">Dempster <italic toggle="yes">et al.</italic>, 2019b</xref>; <xref rid="btab137-B24" ref-type="bibr">Meyers <italic toggle="yes">et al.</italic>, 2017</xref>)] to map them. As these experiments are impractical to conduct on every patient, algorithmic methods to pinpoint dependencies may accelerate a general approach to discover cancer essential genes for personalized therapeutic targeting.</p>
    <p>One possible approach is deep learning (i.e. neural networks; NNs). It has been useful in biological applications, such as to predict sequence specificities of DNA- and RNA-binding proteins (<xref rid="btab137-B1" ref-type="bibr">Alipanahi <italic toggle="yes">et al.</italic>, 2015</xref>) and to classify clinical images (<xref rid="btab137-B10" ref-type="bibr">Esteva <italic toggle="yes">et al.</italic>, 2017</xref>). Despite robust performance, however, these models are like black boxes. Their parameters are difficult to interpret due to their complex and nonlinear relationship with the output (<xref rid="btab137-B9" ref-type="bibr">Eraslan <italic toggle="yes">et al.</italic>, 2019</xref>). While model interpretability is not uniformly crucial, it is highly desired in biomedical applications, to guide both clinicians and patients to make well-reasoned medical decisions.</p>
    <p>To improve interpretability, recent studies sought to encode biological knowledge directly into the architecture of the NN. This led to parameters and output states that represent biological entities or subsystems (<xref rid="btab137-B9" ref-type="bibr">Eraslan <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab137-B36" ref-type="bibr">Yu <italic toggle="yes">et al.</italic>, 2018</xref>). These models were named visible neural networks (VNNs; <xref rid="btab137-B23" ref-type="bibr">Ma <italic toggle="yes">et al.</italic>, 2018</xref>) as opposed to the traditional, black box NN whose parameters are not interpretable. For example, <xref rid="btab137-B23" ref-type="bibr">Ma <italic toggle="yes">et al.</italic> (2018)</xref> used Gene Ontology (<xref rid="btab137-B33" ref-type="bibr">The Gene Ontology Consortium, 2017</xref>) and Clique-eXtracted Ontology (<xref rid="btab137-B16" ref-type="bibr">Kramer <italic toggle="yes">et al.</italic>, 2014</xref>) to design the architecture of an NN model, DCell, for predicting yeast cell growth given gene deletion genotypes. The same group further extended the model to predict drug responses and synergy (<xref rid="btab137-B17" ref-type="bibr">Kuenzi <italic toggle="yes">et al.</italic>, 2020</xref>). <xref rid="btab137-B20" ref-type="bibr">Lin <italic toggle="yes">et al.</italic> (2017)</xref> and <xref rid="btab137-B28" ref-type="bibr">Peng <italic toggle="yes">et al.</italic> (2019)</xref> embedded proteinâprotein interactions, proteinâDNA interactions and Gene Ontology into VNNs that reduce the dimensions of single-cell RNA-seq data. <xref rid="btab137-B8" ref-type="bibr">Eetemadi and Tagkopoulos (2019)</xref> used the transcriptional regulatory network to build the architecture of the genetic NN to predict gene expression. These examples suggest that VNNs perform as well or better than traditional NNs and other non-NN methods while providing interpretable models/predictions. However, signaling pathway information has not yet been used to design VNN.</p>
    <p>Pathways [e.g. Reactome (<xref rid="btab137-B11" ref-type="bibr">Fabregat <italic toggle="yes">et al.</italic>, 2018</xref>)] summarize how some biological components work together to relay upstream signals downstream and biochemically transform molecules through orchestrated series of reactions. Such pathways (<xref rid="btab137-F1" ref-type="fig">Fig.Â 1A</xref>) can be viewed as a hierarchy of interconnected modules that integrate signals and process responses, not unlike an NN architecture (<xref rid="btab137-F1" ref-type="fig">Fig.Â 1B</xref>). Therefore, such pathway information may naturally fit well to build VNNs models that better reflect biological and cellular systems.</p>
    <fig position="float" id="btab137-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>An illustration of the BioVNN for predicting gene dependency. (<bold>A</bold>) A toy example of signaling pathway hierarchy. G, gene; P, pathway. P1 contains G1, G2, G3 and G7; P2 contains G4 and G5; P3 contains G3 and G6; P4 contains G3 and G7; P7 is the parent pathway of P1 and P2; P6 is the parent pathway of P3 and P4. (<bold>B</bold>) A BioVNN designed based on pathway information in (A). The information from nodes in previous layers is integrated in a node of the next layer only if two nodes are connected. The input layer nodes (genes) are connected to the hidden layer nodes (pathways) only when the gene is in that pathway. The input consists of RNA features and deletion status (see Section 2). Lower-level pathways are further connected to higher-level pathways for integrating information toward the prediction of gene dependency. BioVNN is sparsely connected opposed to (<bold>C</bold>) traditional fully connected feedforward network</p>
      </caption>
      <graphic xlink:href="btab137f1" position="float"/>
    </fig>
    <fig position="float" id="btab137-F2">
      <label>Fig. 2.</label>
      <caption>
        <p>BioVNN predicts the dependency for genes with potential druggability. (<bold>A</bold>) The receiver operating characteristic (ROC) curve and (<bold>B</bold>) precisionârecall (PR) curve of BioVNN based on Reactome pathways, the FCN and the matched randomized NN which matches the architecture but with shuffled geneâpathway relationship (random gene groups). The AUROC and the AUPRC were used as the performance metrics (see Section 2). (<bold>C</bold>) The number of training cycles (i.e. epochs) required for the three networks to converge. (<bold>D</bold>) The relative number of trainable parameters of three networks</p>
      </caption>
      <graphic xlink:href="btab137f2" position="float"/>
    </fig>
    <p>As a test, VNNs might help deconvolute cancer dependencies where, besides their performance, they could advance the understanding of the internal states of biological systems by linking predictions to underlying mechanisms represented by pathways (<xref rid="btab137-B36" ref-type="bibr">Yu <italic toggle="yes">et al.</italic>, 2018</xref>). However, to our knowledge, VNNs have not been utilized to predict cancer dependencies to improve the model interpretability and accelerate precision medicine.</p>
    <p>To that end, we develop here <underline>Bio</underline>logical <underline>V</underline>isible <underline>N</underline>eural <underline>N</underline>etwork (BioVNN), an interpretable model, to predict the dependencies of potentially druggable genes for cancer cells with RNA expression features. Crucially, the architecture design of BioVNN reflects domain expert-curated signaling pathways, Reactome (<xref rid="btab137-B11" ref-type="bibr">Fabregat <italic toggle="yes">et al.</italic>, 2018</xref>). Just as convolutional layers combine pixel information of spatial relationships, BioVNN integrates modular information on gene pathways; the neuron units are sparsely connected by following the pathway knowledge (<xref rid="btab137-F1" ref-type="fig">Fig.Â 1B</xref>). We compare BioVNN to a matched random gene group model and to a fully connected network (FCN), and find that even with fewer training cycles, it significantly outperforms the former and slightly outperforms the latter, which has 193 times more parameters in five-fold cross-validation. In a time-stamp experiment, BioVNN outperforms random group model when predicting future observations from prior data. Besides this robust performance, BioVNN predictions can also be explained by the neuron states of specific pathways. The pathway states are different between dependent and nondependent cells and such difference specifically exists only when the gene of target variable is in the pathways. On closer examination, strikingly, BioVNN learns to overweight the feature genes in the same reactions as the genes of target variable, even though such reaction information is never explicitly provided in training data or model. In addition, greater feature weights may suggest novel reaction components. In summary, BioVNN embeds Reactome pathways to predict gene dependency in cancer cells and also provide interpretable neuron states that suggest a rationale for the predictions. By improve our understanding of cancer dependency, this robust and interpretable model is a step toward faster development of precision medicine.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Data collection and preprocessing</title>
      <sec>
        <title>2.1.1 Pathway data</title>
        <p>To design BioVNN from pathway information, the pathways gene set file (*.gmt), pathway hierarchy relationship file, and reaction file were downloaded from Reactome (<xref rid="btab137-B11" ref-type="bibr">Fabregat <italic toggle="yes">et al.</italic>, 2018</xref>) (<ext-link xlink:href="https://reactome.org" ext-link-type="uri">https://reactome.org</ext-link>) on May 29, 2019. To ensure that the pathway information was useful, we selected just those 1,425 pathways (including the root) with at least five genes which are feature genes (which expression profiles are used as the model input) and/or genes in the target variable (which dependency predicted in the model output). They consist of total 9,501 genes. The reaction file provides more detailed geneâgene relationship information within a pathway, e.g. binding, activation, translocation, degradation and biochemical events. We test whether the trained models could recapitulate these reaction relationships as validation.</p>
      </sec>
      <sec>
        <title>2.1.2 RNA expression features and dependency target variables</title>
        <p>We downloaded CCLE RNA expression data of cancer cell lines (<xref rid="btab137-B12" ref-type="bibr">Ghandi <italic toggle="yes">et al.</italic>, 2019</xref>) and CRISPR data of cancer cell lines (<xref rid="btab137-B7" ref-type="bibr">Dempster <italic toggle="yes">et al.</italic>, 2019b</xref>; <xref rid="btab137-B24" ref-type="bibr">Meyers <italic toggle="yes">et al.</italic>, 2017</xref>) of 19Q3 and 20Q2 versions from DepMap (<ext-link xlink:href="https://depmap.org" ext-link-type="uri">https://depmap.org</ext-link>). In total, 609 cell lines in 19Q3 and 142 different cell lines newly added in 20Q2, which have both expression and CRISPR data, were used.</p>
        <p>The expression data are RNA sequencing (RNA-seq) log2-transformed TPM (transcripts per million) values, using a pseudo-count of 1. To select feature genes, we first only considered those with values greater than 1 in at least 1% of the cell lines (i.e. 7 cell lines). Then, we further narrowed our choice to genes present in Reactome. This yielded 9488 genes as RNA expression features.</p>
        <p>The CRISPR screening measures the knockout effects of around 18,000 genes on cancer cell growth and the more significant effects represent higher dependencies. The dependency probabilities (between 0 and 1) were used to set up a classification problem of interests, i.e. a gene has a significant effect on a cell line, as suggested on the DepMap webpage: samples with dependency â¥0.5 were defined as the positive class (target variableâ=â1) and the samples with dependency &lt;0.5 were defined as the negative class (target variableâ=â0).</p>
        <p>To choose genes as target variables (which dependencies were predicted in the model output) we first selected genes that exist in both Reactome and CRISPR data. Then, to focus on genes with sufficient data for training and potential druggabilities, we further restricted our choice to a final set of 683 genes with (i) at least six positive samples; (ii) at least six negative samples; (iii) at least one druggable gene category and at least one chemical interaction in DGIdb (which records drugâgene interactions and potentially druggable genes) (<xref rid="btab137-B5" ref-type="bibr">Cotto <italic toggle="yes">et al.</italic>, 2018</xref>) (v3.0.2). Note also that we excluded genes which were either nearly all dependent or nearly all nondependent across cell lines as they could lead to overestimates and inaccurate performance evaluation.</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 BioVNN design</title>
      <p>Like the convolutional layers combining pixel information based on spatial relationship and forming higher-level abstraction in deeper layers, BioVNN layers integrate information based on geneâpathway and pathwayâpathway relationships and simulate the representations of higher-level pathways in deeper layers. We hypothesize that NNs only need to integrate the information of the genes/pathways which are functionally related to predict dependency. In other words, we specifically look for the correlation among RNA expression and deletion status of all genes in the same pathway and the correlation among pathways having the same parents. Hence, the first hidden layer of lowest-level pathways selectively connects those input genes in the same pathways to the same neuron units, which look for the combinatory effects of expressed and knocked-out genes on cell growth/death. Then, it sends the integrated information to the neurons of corresponding parent pathways until reaching the root. These are important distinctions between BioVNN and FCNs. BioVNN selectively integrates the input based on pathway knowledge, whereas FCNs integrate all information from the previous layer (<xref rid="btab137-F1" ref-type="fig">Fig.Â 1</xref>). Code and data are available at <ext-link xlink:href="https://github.com/LichtargeLab/BioVNN" ext-link-type="uri">https://github.com/LichtargeLab/BioVNN</ext-link>.</p>
      <p>The input of BioVNN consists of two parts (<xref rid="btab137-F1" ref-type="fig">Fig.Â 1B</xref>). The first part is the RNA gene expression profile of the cell line. The second part is the deletion status that specifies which gene is âknocked-outâ to simulate its effect on the cell line, inspired by DCell (<xref rid="btab137-B23" ref-type="bibr">Ma <italic toggle="yes">et al.</italic>, 2018</xref>). With the architecture mimicking the 13-level hierarchy of 1,425 Reactome pathways, BioVNN predicts the dependency of the gene in the cell line specified in the input. Conceptually, BioVNN could be viewed as a sparsely connected feedforward network of 13 hidden layers (<xref rid="btab137-F1" ref-type="fig">Fig.Â 1B</xref>).</p>
      <p>Mathematically, we denote the dataset as <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mn>0,1</mml:mn></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>â</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>â</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math></inline-formula>, where <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula> is the number of RNA expression genes, <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mi>m</mml:mi></mml:math></inline-formula> is the number of cell lines and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mi>n</mml:mi></mml:math></inline-formula> is the number of genes in the deletion status. The data used to compare the output prediction of the model, <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the dependency of the gene <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mi>j</mml:mi></mml:math></inline-formula> in cell line <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula>. Input <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a concatenated vector of <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mo>â¼</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>. To reduce the curse of dimensionality and to focus on biologically relevant genes based on pathway knowledge, while predicting dependency of gene <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mi>j</mml:mi></mml:math></inline-formula>, we mask the RNA expression vector <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> of cell line<inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mo>Â </mml:mo><mml:mi>i</mml:mi></mml:math></inline-formula> as <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mo>â¼</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>; <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mo>â¼</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, where <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is a binary vector like a filter to keep genes in the same pathways as gene <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mi>j</mml:mi></mml:math></inline-formula> (1â=âsame pathway; 0 otherwise). The genes in <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are selected from the smallest pathways to largest pathways until reaching 100 genes because smaller pathways represent stronger relationship than larger pathways.</p>
      <p>We denote the deletion status as <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, a one-hot encoding vector of <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mi>n</mml:mi></mml:math></inline-formula> genes (1â=âknocked-out; 0 otherwise). <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> assigns the gene for predicting dependency and directs modelâs attention to that gene. In this way, we formulate the problem as a single-label binary classification (i.e. agnostic to which genes) instead of a multilabel classification (i.e. treating different genes as separate labels and adding more neurons in the output layers). The model could benefit from more samples (i.e. <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mi>m</mml:mi><mml:mo>Ã</mml:mo><mml:mi>n</mml:mi></mml:math></inline-formula> samples instead of <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mi>m</mml:mi></mml:math></inline-formula> samples), and the dependency prediction for different genes uses the same set of weights, which assumes the signal integration process through pathway hierarchy is the same for predicting dependency of different genes.</p>
      <p>We denote the output neuron state <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> of pathway <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mi>t</mml:mi></mml:math></inline-formula> with input <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> as 
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant="italic">Dropout</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="italic">BatchNorm</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="italic">Mish</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="italic">Linear</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math></disp-formula></p>
      <p>More concretely, when the lowest pathway <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mi>t</mml:mi></mml:math></inline-formula> is at the beginning of hierarchy, input <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> is the concatenated vector of its gene member input selected from <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>; when pathway <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mi>t</mml:mi></mml:math></inline-formula> has children pathways, <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> is the concatenated vector of the output neuron states of its children pathways.</p>
      <p>The <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mi mathvariant="italic">Linear</mml:mi></mml:math></inline-formula> transformation in <xref rid="E1" ref-type="disp-formula">Equation (1)</xref> is defined as: <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mi mathvariant="italic">Linear</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula>. The weight matrix <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> with dimension of <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>Ã</mml:mo><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> and bias vector <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> with length of <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> are the parameters to learn the representation of pathway <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mi>t</mml:mi></mml:math></inline-formula>. The length of <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> vector, <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant="italic">max</mml:mi><mml:mo>â¡</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mfenced open="â" close="â" separators="|"><mml:mrow><mml:mn>0.3</mml:mn><mml:mi mathvariant="normal">*</mml:mi><mml:mi mathvariant="normal">number</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">of</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">genes</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">in</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">pathway</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math></inline-formula> and the length of <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> vector is <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula>. Because the representation of pathways with more gene members may be harder to learn, we set <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> proportionally to the size of pathway <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mi>t</mml:mi></mml:math></inline-formula>, and 10 is the minimum of <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> for pathways with less than 34 genes.</p>
      <p><inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mi mathvariant="italic">Mish</mml:mi></mml:math></inline-formula> is the smooth, nonmonotonic and nonlinear activation function, which has been shown to outperform ReLU, Swish and others (<xref rid="btab137-B26" ref-type="bibr">Misra, 2019</xref>). <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mi mathvariant="italic">Mish</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>Â·</mml:mo><mml:mrow><mml:mrow><mml:mi>tanh</mml:mi></mml:mrow><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="italic">softplus</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p>
      <p><inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mi mathvariant="italic">BatchNorm</mml:mi></mml:math></inline-formula> is the normalization of mini-batch during training to reduce the internal covariate shift, which has been shown to achieve higher training rate and reduce overfitting (<xref rid="btab137-B14" ref-type="bibr">Ioffe and Szegedy, 2015</xref>).</p>
      <p><inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mi mathvariant="italic">Dropout</mml:mi></mml:math></inline-formula> is a technique to randomly drop neuron units during training, which has shown to reduce overfitting (<xref rid="btab137-B31" ref-type="bibr">Srivastava <italic toggle="yes">et al.</italic>, 2014</xref>). The Dropout probability is set as 0.5 (<xref rid="btab137-B31" ref-type="bibr">Srivastava <italic toggle="yes">et al.</italic>, 2014</xref>).</p>
      <p>The objective function consists of three parts: (i) the loss of the final output from the root of hierarchy, (ii) the loss of the outputs from other individual pathways and (iii) regularization. The function to be optimized is 
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo stretchy="false">â</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">â</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi mathvariant="italic">Loss</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="italic">Sigmoid</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="italic">Linear</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mo>Î±</mml:mo><mml:mrow><mml:msubsup><mml:mo stretchy="false">â</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>â </mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mrow><mml:mi mathvariant="italic">Loss</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="italic">Sigmoid</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="italic">Linear</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mo>Î»</mml:mo><mml:msub><mml:mrow><mml:mfenced open="â" close="â" separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">Â </mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math></disp-formula></p>
      <p>Here, <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mi>r</mml:mi></mml:math></inline-formula> is the root, the highest level of pathway hierarchy after integrating information over other pathway <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mi>t</mml:mi></mml:math></inline-formula>. <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mi mathvariant="italic">Loss</mml:mi></mml:math></inline-formula> is the binary entropy loss function and the negative class was weighted as the ratio of positive sample number to negative sample number in training set. The output prediction is <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:mi mathvariant="italic">Sigmoid</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="italic">Linear</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>â</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mn>0,1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>. The <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mi mathvariant="italic">Linear</mml:mi></mml:math></inline-formula> function in <xref rid="E2" ref-type="disp-formula">Equation (2)</xref> transforms the vector <inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow/></mml:msubsup></mml:math></inline-formula> to a scalar. <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mi mathvariant="italic">Sigmoid</mml:mi></mml:math></inline-formula> is an exponential function to convert the output scalar to probability.</p>
      <p>We include the loss term to compare the output scalar value of each pathway against the <inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, so that every pathway could be auxiliary classifiers to predict dependency on its own and could be optimized as features for parent pathways; <inline-formula id="IE58"><mml:math id="IM58" display="inline" overflow="scroll"><mml:mo>Î±</mml:mo></mml:math></inline-formula> is set as 0.3 to adjust the contribution of the term as previously in GoogLeNet (<xref rid="btab137-B32" ref-type="bibr">Szegedy <italic toggle="yes">et al.</italic>, 2014</xref>) and DCell (<xref rid="btab137-B23" ref-type="bibr">Ma <italic toggle="yes">et al.</italic>, 2018</xref>). <inline-formula id="IE59"><mml:math id="IM59" display="inline" overflow="scroll"><mml:mo>Î»</mml:mo></mml:math></inline-formula> is the L2 regularization factor and set as 1.</p>
    </sec>
    <sec>
      <title>2.3 Training procedure</title>
      <p>We initialize the weights by Kaiming initialization (<xref rid="btab137-B13" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2015</xref>). The model is trained with mini-batch (<italic toggle="yes">n</italic>â=â2000) by an optimizer combining Rectified Adam (<xref rid="btab137-B22" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2019</xref>) and Lookahead (<xref rid="btab137-B37" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2019</xref>) with learning rate 1Eâ03, implemented in <ext-link xlink:href="https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer" ext-link-type="uri">https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer</ext-link>.</p>
      <p>The data [<inline-formula id="IE60"><mml:math id="IM60" display="inline" overflow="scroll"><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math></inline-formula>, where <inline-formula id="IE61"><mml:math id="IM61" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a concatenated vector of RNA expression vector and deletion status; <inline-formula id="IE62"><mml:math id="IM62" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the dependency of the gene specified in deletion status in the cell line] is split into five folds with balanced classes and tissue types by cell lines. In each fold of the experiment, data are split into training, validation and test sets by the ratio, 3.2:0.8:1, so that the ratio of training set to validation set and the ratio of training set and validation set to test set are the equal at 4:1. The training set was used for training. The validation set was used to determine the early stopping criterion, which was if the loss did not improve for two epochs. The test set is used to assess model performance. The RNA expression values of all three sets are converted to <italic toggle="yes">z</italic>-scores for each gene by using the mean and standard deviation of the training set.</p>
      <p>We focus on testing the NN architecture based on biological signaling pathways to increase model interpretability so the space of hyperparameters is not fully searched. We implemented BioVNN using the PyTorch 1.2 on GTX1080 and RTX2080Ti GPUs.</p>
    </sec>
    <sec>
      <title>2.4 Time-stamped experiment</title>
      <p>To test performance in the most realistic context, we ran time-stamped experiments. We used the models trained on data from DepMap 19Q3. Then we applied these models to predict the dependency for 142 cell lines that were added in 20Q2. To be noted, some cell lines have data in both releases. Even if using 20Q2 data for both training and testing could potentially reduce batch effects affecting the performance, we used the data solely from 19Q3 for training and the data solely from 20Q2 for testing. In this case, it tests the robustness of the model to handle variations from different data versions. One gene, FCGR1A, only exists in 19Q3 but not in 20Q2 dependency data. So only 682 target variable genes were tested in this experiment. The Pearsonâs correlation of dependency between 19Q3 and 20Q2 is 0.996 in 609 overlapping cell lines and 682 overlapping genes. The Pearsonâs correlation of RNA expression between 19Q3 and 20Q2 is 1.0 in 609 overlapping cell lines and 9488 overlapping genes. It shows slight variations between two data versions.</p>
    </sec>
    <sec>
      <title>2.5 Performance evaluation</title>
      <p>We used area under the receiver operating characteristic curve (AUROC) and area under the precision-recall curve (AUPRC) as metrics. In five-fold cross-validation, the test set predictions from each fold of the five-fold cross-validation were combined to calculate the overall AUROC and AUPRC.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 BioVNN predicts cancer dependencies in potentially druggable genes</title>
      <p>Because we aimed to predict drug targets, we trained the model to predict cancer dependencies for potentially druggable genes in five-fold cross-validation (see Methods). As a baseline, we first calculated the performance while making prediction based on the expression values because the expression levels have been shown to be correlated with the dependency (<xref rid="btab137-B6" ref-type="bibr">Dempster <italic toggle="yes">et al.</italic>, 2019a</xref>). However, our results showed that at least for these druggable genes we selected, the correlation is low (Pearson correlation coefficient = 0.32; Supplementary Fig. 1) and the performance is almost random (AUROC = 0.527; AUPRC = 0.256). For model comparison, we used the matched fully connected network (Fig. 1C) which has the same number of neurons in each hidden layer and the same depth as BioVNN. To examine whether the Reactome-based architecture is useful for predicting gene dependency, we generated the matched random gene group model by shuffling the gene-pathway and pathway-pathway relationship as a control (see Supplementary Methods). In the five-fold cross-validation, Figure 2A and 2B showed that overall BioVNN (AUROC = 0.883; AUPRC = 0.754) marginally outperforms the FCN (AUROC = 0.879; AUPRC = 0.740) but, significantly, converges with one third fewer training cycles (i.e., epochs; Fig. 2C; MannâWhitneyâWilcoxon (MWW) test two-sided <italic toggle="yes">P</italic> &lt; 5.9Eâ03) and 193 times fewer trainable parameters (Fig. 2D). In addition, BioVNN also outperforms the random gene group model (AUROC = 0.845; AUPRC = 0.688) with 21% fewer epochs (Fig. 2C; MWW test two-sided <italic toggle="yes">P</italic> &lt; 5.9Eâ03). Interestingly, in the experiments of gradually increasing randomized network connections, we found that AUPRC decays faster than AUROC (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 2</xref>). Thus, random sparsity may lead to worse performance. Overall, these data suggest that Reactome pathways provide non-random gene group information which facilitates the training of neural networks and the prediction of cancer dependencies.</p>
      <p>Because the FCN has similar performance despite much more parameters, we suspected whether those additional model weights converged to zeroes after training. First, we compared the model weights of first layer to BioVNN and found that FCN has a distribution significantly more enriched at zeroes comparing to BioVNN (KolmogorovâSmirnov test <italic toggle="yes">P</italic>â&lt;â1Eâ16; <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 2</xref>), which suggests that BioVNN uses much fewer parameters but with higher averaged absolute values of weights (â¼0.03) to retain similar amount of information in the data. Next, we asked whether those parameters in FCN connect the feature genes of the same pathway to the same computing neuron, which may rediscover the pathways. Because those neurons in FCN cannot be mapped to pathways directly, we formulated gene groups by applying <italic toggle="yes">k</italic>-means clustering (<italic toggle="yes">k</italic>â=â826, the number of the pathways in the first layer of BioVNN) to the PCA-compressed model weights. We found that, surprisingly, 353 out of 826 (42.7%) of gene groups overlapped significantly [hypergeometric test adjusted <italic toggle="yes">P</italic>â&lt;â0.1 using BH method (<xref rid="btab137-B2" ref-type="bibr">Benjamini and Hochberg, 1995</xref>)] with at least one Reactome pathways. We further generated random gene groups matching the sizes of gene group generated based on FCN in 1,600 simulations and found the probability to reach 353 overlapping groups is less than 1Eâ200 given the simulated exponential distribution (<xref rid="sup1" ref-type="supplementary-material">Supplement Fig.Â 3</xref>). The results suggest that the parameters of FCN integrate the gene group information that is similar to Reactome pathways used by BioVNN. In addition, FCN also used other ways of integrating gene information, which may imply new gene groups that are also important for predicting cancer dependency.</p>
      <fig position="float" id="btab137-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>BioVNN predicts the cancer dependency in unseen cell lines of newer data release. Models trained by 19Q3 data were used to predict dependency of cell lines in 20Q2 data. (<bold>A</bold>) AUROC and (<bold>B</bold>) AUPRC showed higher performance in BioVNN and the FCN than the random group model. Each dot is a model trained in one of the five-fold cross-validation</p>
        </caption>
        <graphic xlink:href="btab137f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.2 BioVNN predicts dependencies in newer data release</title>
      <p>To test predictions prospectively, we setup time-stamped experiments using the training/test dataset from different data releases. We trained the BioVNN on data from DepMap as of 19Q3 (August 2019) and then evaluated its performance over 142 new cell lines that were added later, in the 20Q2 version (May 2020). To be clear, no data from 20Q2 were used for training and 20Q2 data were used for testing. This tests whether the model is robust across data versions given potential batch effects and variations.</p>
      <p><xref rid="btab137-F3" ref-type="fig">FigureÂ 3</xref> shows that, as before, BioVNN marginally gains on the FCN (MWW test two-sided <italic toggle="yes">Pâ&gt;â</italic>0.09) and outperforms the random gene group model for both AUROC and AUPRC (MWW test two-sided <italic toggle="yes">P</italic>â&lt;â8.0Eâ03). Again, the results suggest that the pathway knowledge embedded in the BioVNN is helpful to predict cancer dependency. More importantly, by validating the ability of BioVNN to predict dependency prospectively, these data show that BioVNN is generalizable to future data releases.</p>
    </sec>
    <sec>
      <title>3.3 The neuron states of BioVNN simulate pathway states</title>
      <p>Besides performance, interpretability is an essential characteristic of BioVNN. By encoding the Reactome hierarchy, the hidden layers of BioVNN can represent actual signaling pathways whereas traditional NNs or random group models cannot. To determine whether BioVNNâs hidden layers, representing pathways, make predictions more interpretable, we aimed to study why the model made a prediction. More specifically, we investigated three hypotheses. (1) Because the gene dependency is supposed to be affected by its pathway, we hypothesize that when one group of cell lines is dependent and another one is not dependent on the same gene, the output neuron states (<inline-formula id="IE63"><mml:math id="IM63" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula>) of the pathways including the same gene from two groups are different. (2) Because other pathways do not include the gene to predict dependency, we hypothesize that we can only find such state difference in only the specific pathways. (3) When one cell line is predicted to be dependent and another one is predicted to be not dependent on the same gene, we hypothesize that the pathway states can suggest key pathways leading to the dependency difference.</p>
      <p>To test the first hypothesis, we took the gene, ITGAV, which is a potential drug target for cancers (<xref rid="btab137-B4" ref-type="bibr">Cheuk <italic toggle="yes">et al.</italic>, 2020</xref>; van der Horst <xref rid="btab137-B34" ref-type="bibr"><italic toggle="yes">et al.</italic>, 2014</xref>), as an example. We compared the ITGAV-involved pathway states of ITGAV-dependent cell lines (which have dependency of ITGAVââ¥â0.5) and nondependent cell lines (which have dependency of ITGAVâ&lt;â0.5). For visualization, we compressed the neuron states of ITGAV-involved pathways by principal component analysis and plotted the first two components with kernel density estimation (<xref rid="btab137-F4" ref-type="fig">Fig.Â 4A</xref>). As an example, the states of the pathway, âNeutrophil degranulationâ (R-HSA-6798695), showed significantly different distributions between two classes (i.e. ITGAV-dependent and non-ITGAV-dependent cell lines) (<xref rid="btab137-F4" ref-type="fig">Fig.Â 4A;</xref> combined MWW test two-sided <italic toggle="yes">P</italic>â&lt;â4.7Eâ17; see <xref rid="sup1" ref-type="supplementary-material">Supplementary Methods</xref>). We found that 26 out of 27 ITGAV-involved pathways show significantly different neuron states between the two classes [combined MWW test two-sided adjusted <italic toggle="yes">P</italic>â&lt;â0.1 using BenjaminiâHochberg (BH) method (<xref rid="btab137-B2" ref-type="bibr">Benjamini and Hochberg, 1995</xref>)]. As a result, the difference of ITGAV dependency could be explained by the state difference of ITGAV-involved pathways.</p>
      <fig position="float" id="btab137-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Dependent and nondependent cells have distinct neuron states in related pathways. (<bold>A</bold>) The neuron states of one ITGAV-involved pathway, âNeutrophil degranulationâ, compressed by principal component analysis to two dimensions and plotted as Gaussian kernel density estimation. PC1 and PC2 are the first and the second principal components. Red and black lines represent significantly different distributions between ITGAV-dependent and non-ITGAV-dependent cell lines (MWW test two-sided <italic toggle="yes">P</italic>â&lt;â4.7Eâ17). (<bold>B</bold>) The class separation of neuron states grouped by whether they consist ITGAV or not. The class separation was measured by how different the PC1 and PC2 of pathway neuron states are between ITGAV-dependent and non-ITGAV-dependent cell lines (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Methods</xref>). Twenty-seven ITGAV-involved pathways have significantly higher class separation than 1398 other pathways. ***, MWW test one-sided <italic toggle="yes">P</italic>â&lt;â6.6Eâ06</p>
        </caption>
        <graphic xlink:href="btab137f4" position="float"/>
      </fig>
      <p>To test the second hypothesis, we examined whether such class differences are observable in all pathways, i.e. nonspecific, or only in related pathways, which contain the target variable gene (ITGAV). We found that such class separation [as measured by the âlog<sub>10</sub>(<italic toggle="yes">P</italic>) value] is significantly larger in related pathways than unrelated pathways (i.e. which do not contain the target variable gene) (<xref rid="btab137-F4" ref-type="fig">Fig.Â 4C;</xref> MWW test one-sided <italic toggle="yes">P</italic>â&lt;â6.6Eâ06). We further expanded the analysis to other genes, and found that in total 74.3% (396 out of 533 target variable genes involved in at least six pathways) have such significant class separation in related pathways [MWW test one-sided adjusted <italic toggle="yes">P</italic>â&lt;â0.1 using BH method (<xref rid="btab137-B2" ref-type="bibr">Benjamini and Hochberg, 1995</xref>)]. That is to say, the dependency differences of the target variable gene between cell lines may be explained by the differences of the neuron states of pathways that contain that target variable gene but not others. Hence, these results suggest that these neuron states could specifically simulate the internal states of pathways in cells and provide explanations for dependency predictions.</p>
      <p>To test the third hypothesis and further explain the dependency prediction, we examined the neuron states from lower-level to higher-level pathways (<xref rid="btab137-F5" ref-type="fig">Fig.Â 5A and B</xref>). Taking two cell lines, e.g. DKMG (glioma) was predicted to be ITGAV-dependent (<xref rid="btab137-F5" ref-type="fig">Fig.Â 5A</xref>); BL70 (Burkitt lymphoma) was predicted not to be ITGAV-dependent (<xref rid="btab137-F5" ref-type="fig">Fig.Â 5B</xref>). Given their RNA profiles and the ITGAV deletion vectors as input, the neuron states of their ITGAV-involved pathways look distinct (<xref rid="btab137-F5" ref-type="fig">Fig.Â 5A and B</xref>), which explains their opposite predictions. In addition, we further clustered them with other cell lines by the PC1 of their neuron states. We found that predicted ITGAV dependency could be explained by the low neuron states of pathways, which include mostly those under Immune System in the Reactome hierarchy, e.g. Neutrophil degranulation, Innate Immune System and Adaptive Immune System, while non-ITGAV dependency could be explained by high neuron states in these pathways. Hence, these data showed that to predict ITGAV dependency, BioVNN simulated ITGAV deletion and pathway states in the model. The different predictions could be interpreted and explained by the differences in Immune System pathways. It also implies that Immune System pathways may play key roles in ITGAV dependency in cancer cells. These results demonstrate that BioVNNâs predictions are interpretable by inspecting the simulated pathway neuron states.</p>
      <fig position="float" id="btab137-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>BioVNN explains the dependency by simulated pathway states. (<bold>A</bold>) ITGAV-dependent cell line, DKMG, and (<bold>B</bold>) non-ITGAV-dependent cell line, BL70, showed distinct neuron states of 27 ITGAV-involved pathways in the hierarchy, which explains their reversed predictions. (<bold>C</bold>) The clustered heatmap of neuron states of ITGAV-involved pathways and cell lines. The neuron state colors represent the PC1 of neuron states converted to a <italic toggle="yes">z</italic>-score across cell lines</p>
        </caption>
        <graphic xlink:href="btab137f5" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.4 BioVNN recovers reaction knowledge and suggests new reaction components</title>
      <p>Finally, we investigated which features are important for the dependency prediction in BioVNN. We utilized the reaction information from Reactome, which was not used in designing models nor training, to validate whether BioVNN found important features that fit biological knowledge. Reaction information groups genes that are involved in a common process, e.g. binding, activation, translocation, degradation and biochemical events. One gene can be involved in multiple reactions, which are typically smaller gene groups than pathways. A pathway thus often consists of multiple reactions to achieve its function. Two genes involved in the same reaction are in the same pathway but not necessarily vice versa. Such reaction relationships between two genes are stronger than pathway relationships. Should one gene be deleted, its reaction partners are more likely to be affected than pathway partners. Therefore, we hypothesized that even in the same pathway, genes involved in the same reaction as the target variable gene would have higher importance than others.</p>
      <p>Taking NFKB1 as an example, we hypothesized that those genes in the same reactions as NFKB1 have higher feature importance in predicting NFKB1 dependency than other genes in the same pathway. NFKB1 is involved in a total of 53 Reactome reactions, which consist of 333 genes that are NFKB1 reaction partners. One NFKB1-involved pathway at the bottom of the hierarchy is a 78-component pathway, âSenescence-Associated Secretory Phenotype (SASP)â (R-HSA-2559582), consisting of 28 NFKB1 reaction partners. We found that surprisingly, those 28 genes and NFKB1 have significantly higher importance (as measured by feature weights; see <xref rid="sup1" ref-type="supplementary-material">Supplementary Methods</xref>) than the 49 other genes in the same pathway (MWW test one-sided <italic toggle="yes">P</italic>â&lt;â2.9Eâ06; <xref rid="btab137-F6" ref-type="fig">Fig.Â 6A</xref>). Taking EP300 as another example, EP300 and the 52 genes that are reaction partners with EP300 also have significantly higher feature importance than the other genes in the 88-gene pathway, âActivation of anterior HOX genes in hindbrain development during early embryogenesisâ (R-HSA-5617472) (MWW test one-sided <italic toggle="yes">P</italic>â&lt;â5.0Eâ04; <xref rid="btab137-F6" ref-type="fig">Fig.Â 6B</xref>). Furthermore, we expanded the analysis to other target variable genes, and found that 132 out of 1618 geneâpathway pairs (corresponding to 95 of 426 unique genes; see <xref rid="sup1" ref-type="supplementary-material">Supplementary Methods</xref>) had significantly higher features importance for those genes involved in the same reactions as the target variable gene [MWW test one-sided adjusted <italic toggle="yes">P</italic>â&lt;â0.1 using BH method (<xref rid="btab137-B2" ref-type="bibr">Benjamini and Hochberg, 1995</xref>)]. These results demonstrated that the high-importance features in BioVNN are not random and are in agreement with the biological knowledge of reactions. Of note, only pathway information but not reaction information was used to build the BioVNN architecture. These data suggest that BioVNN recovers the reaction knowledge from the training data on its own even if such knowledge is not provided during model construction or training.</p>
      <fig position="float" id="btab137-F6">
        <label>Fig. 6.</label>
        <caption>
          <p>The feature importance of BioVNN recovers the reaction knowledge. (<bold>A</bold>) The feature importance for predicting NFKB1 dependency in the pathway, âSASPâ (R-HSA-2559582). (<bold>B</bold>) The feature importance for predicting EP300 dependency in the pathway, âActivation of anterior HOX genes in hindbrain development during early embryogenesisâ (R-HSA-5617472). ***, MWW test one-sided <italic toggle="yes">P</italic>â&lt;â2.9Eâ06; **, <italic toggle="yes">P</italic>â&lt;â5.0Eâ04.</p>
        </caption>
        <graphic xlink:href="btab137f6" position="float"/>
      </fig>
      <p>During the analysis above, we found outliers in groups of âOther genesâ, that were not involved in the same reactions as the target variable gene, that also have high feature importance. In other words, BioVNN regards those genes to be as useful in predicting dependency for the target variable genes as the reaction partner genes. Taking the NFKB1 and SASP pathway as an example (<xref rid="btab137-F6" ref-type="fig">Fig.Â 6A</xref>), the gene of second highest weight in âOther genesâ is CDK2, which could suggest a new reaction component with NFKB1. Indeed, a previous study showed that NF-ÎºB bound to the promoter of CDK2, turned on its transcription and upregulated the protein level of CDK2 (<xref rid="btab137-B21" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2011</xref>). In the example of EP300 (<xref rid="btab137-F6" ref-type="fig">Fig.Â 6B</xref>), the gene of highest weight in âOther genesâ is HOXD4, which we propose as a reaction component with EP300. In fact, the protein interaction between HOXD4 and p300 has already been reported (<xref rid="btab137-B30" ref-type="bibr">Shen <italic toggle="yes">et al.</italic>, 2001</xref>) but is not yet documented in the Reactome database. These findings suggest that genes with high feature importance, that are not reaction partners with the target variable gene, could be candidate reaction components, which have either not been discovered nor added in Reactome database.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>Robust and interpretable models are crucial for biomedicine, so we aimed to investigate how pathway knowledge can design VNNs for predicting and interpreting cancer dependency. We have demonstrated the ability of BioVNN to successfully predict cancer gene dependencies and provide interpretable predictions. While converging faster, BioVNN not only significantly outperforms matched random group model but also marginally outperforms the FCN that has 193 times more parameters. BioVNN is also generalizable to predict dependency for cell lines in future releases of the DepMap dataset. By examining the case of ITGAV and overall analysis, we showed that only related pathways have distinct neuron states between dependent and nondependent cell lines whereas most other pathways do not. Specifically, ITGAV dependency could be explained by the low states of pathways related to immune system.</p>
    <p>This work illustrates how biological knowledge of signaling pathways can be integrated into an NN architecture. Not only does it solve the issues of designing NN architectures, but also it provides a mechanistic explanation of predictions. For future applications of this work to precision medicine, the RNA-seq expression data of patients could be used to predict personalized cancer dependent genes.</p>
    <p>The novel application of signaling pathways to design VNNs was proven to be useful for the first time. In addition, BioVNN uniquely utilizes the pathway-guided feature masks and deletion status vectors to achieve two innovations: (1) training based on bulk RNA-seq data from only hundreds of human cell lines and (2) dependency prediction of hundreds of genes in single model. Given these innovations, a future direction would be to apply VNNs to other cell line data to predict and explain important questions like synthetic lethality and drug responses. The <italic toggle="yes">in silico</italic> states of VNNs could further explain the <italic toggle="yes">in vitro</italic> observations of cell line screenings to synergistically accelerate the development of precision medicine. With more development and validation in the future, these VNNs could be used to predict personalized drug targets and drugs <italic toggle="yes">in vivo</italic> for each patient with interpretable models to explain the predictions and guide their therapies providing better understanding of treatment mechanism.</p>
    <p>This study could be expanded in a few ways. First, other biological knowledge could also be embedded in the VNNs, due to the fact that Reactome contains around 10â000 genes, which is only about half of the human protein-coding genes and might limit performance. Many other pathway databases [e.g. Pathway Commons (<xref rid="btab137-B29" ref-type="bibr">Rodchenkov <italic toggle="yes">et al.</italic>, 2020</xref>), KEGG (<xref rid="btab137-B15" ref-type="bibr">Kanehisa and Goto, 2000</xref>), MSigDB (<xref rid="btab137-B19" ref-type="bibr">Liberzon <italic toggle="yes">et al.</italic>, 2015</xref>) and PANTHER (<xref rid="btab137-B25" ref-type="bibr">Mi <italic toggle="yes">et al.</italic>, 2019</xref>)] could be added to increase the coverage of genes as well as pathway knowledge. In addition, the gene group information can also be nonhuman-curated, such as the gene groups detected from biological networks by computational algorithms (<xref rid="btab137-B3" ref-type="bibr">Cantini <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="btab137-B35" ref-type="bibr">Wilson <italic toggle="yes">et al.</italic>, 2017</xref>). Since those gene groups are not curated by human, they can be less biased and provide novel functional gene groups.</p>
    <p>Second, the model could incorporate more features of cell lines. One possibility is to integrate other types of genomics data besides RNA expression, such as DNA mutation (<xref rid="btab137-B12" ref-type="bibr">Ghandi <italic toggle="yes">et al.</italic>, 2019</xref>), DNA methylation (<xref rid="btab137-B12" ref-type="bibr">Ghandi <italic toggle="yes">et al.</italic>, 2019</xref>), copy number variation (<xref rid="btab137-B12" ref-type="bibr">Ghandi <italic toggle="yes">et al.</italic>, 2019</xref>) and protein expression (<xref rid="btab137-B27" ref-type="bibr">Nusinow <italic toggle="yes">et al.</italic>, 2020</xref>). These multiple biological observations of the same gene from different angles could be modeled as one state and then be used as features for predicting phenotypes. Another possibility is to incorporate other biological entities [e.g. noncoding RNAs (<xref rid="btab137-B12" ref-type="bibr">Ghandi <italic toggle="yes">et al.</italic>, 2019</xref>) and metabolites (<xref rid="btab137-B18" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2019</xref>)]. In both ways, the states of the cells could be simulated more precisely and completely.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btab137_Supplementary_Data</label>
      <media xlink:href="btab137_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors would like to acknowledge the kind support of Daniel Konecki, Yashwanth Lagisetty and Tse-Ju Lin for helpful discussions.</p>
    <sec>
      <title>Funding</title>
      <p>The authors would like to acknowledge funding by the National Institutes of Health (NIH-GM079656, NIH-GM066099 and AG061105) and the Oskar Fischer Foundation. </p>
      <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btab137-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alipanahi</surname><given-names>B.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2015</year>) 
<article-title>Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning</article-title>. <source>Nat. Biotechnol</source>., <volume>33</volume>, <fpage>831</fpage>â<lpage>838</lpage>.<pub-id pub-id-type="pmid">26213851</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Benjamini</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Hochberg</surname><given-names>Y.</given-names></string-name></person-group> (<year>1995</year>) 
<article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title>. <source>J. R. Stat. Soc. Ser. B Methodol</source>., <volume>57</volume>, <fpage>289</fpage>â<lpage>300</lpage>.</mixed-citation>
    </ref>
    <ref id="btab137-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cantini</surname><given-names>L.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2015</year>) 
<article-title>Detection of gene communities in multi-networks reveals cancer drivers</article-title>. <source>Sci. Rep</source>., <volume>5</volume>, <fpage>17386</fpage>.<pub-id pub-id-type="pmid">26639632</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheuk</surname><given-names>I.W.-Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>ITGAV targeting as a therapeutic approach for treatment of metastatic breast cancer</article-title>. <source>Am. J. Cancer Res</source>., <volume>10</volume>, <fpage>211</fpage>â<lpage>223</lpage>.<pub-id pub-id-type="pmid">32064162</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cotto</surname><given-names>K.C.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2018</year>) 
<article-title>DGIdb 3.0: a redesign and expansion of the drug-gene interaction database</article-title>. <source>Nucleic Acids Res</source>., <volume>46</volume>, <fpage>D1068</fpage>â<lpage>D1073</lpage>.<pub-id pub-id-type="pmid">29156001</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dempster</surname><given-names>J.M.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019a</year>) 
<article-title>Agreement between two large pan-cancer CRISPR-Cas9 gene dependency data sets</article-title>. <source>Nat. Commun</source>., <volume>10</volume>, <fpage>5817</fpage>.<pub-id pub-id-type="pmid">31862961</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dempster</surname><given-names>J.M.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019b</year>) 
<article-title>Extracting biological insights from the project achilles genome-scale CRISPR screens in cancer cell lines</article-title><source>. bioRxiv</source>, <volume>720243</volume>.</mixed-citation>
    </ref>
    <ref id="btab137-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eetemadi</surname><given-names>A.</given-names></string-name>, <string-name><surname>Tagkopoulos</surname><given-names>I.</given-names></string-name></person-group> (<year>2019</year>) 
<article-title>Genetic neural networks: an artificial neural network architecture for capturing gene expression relationships</article-title>. <source>Bioinform. Oxf. Engl</source>., <volume>35</volume>, <fpage>2226</fpage>â<lpage>2234</lpage>.</mixed-citation>
    </ref>
    <ref id="btab137-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eraslan</surname><given-names>G.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>Deep learning: new computational modelling techniques for genomics</article-title>. <source>Nat. Rev. Genet</source>., <volume>20</volume>, <fpage>389</fpage>â<lpage>403</lpage>.<pub-id pub-id-type="pmid">30971806</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Esteva</surname><given-names>A.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) 
<article-title>Dermatologist-level classification of skin cancer with deep neural networks</article-title>. <source>Nature</source>, <volume>542</volume>, <fpage>115</fpage>â<lpage>118</lpage>.<pub-id pub-id-type="pmid">28117445</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fabregat</surname><given-names>A.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2018</year>) 
<article-title>The Reactome pathway knowledgebase</article-title>. <source>Nucleic Acids Res</source>., <volume>46</volume>, <fpage>D649</fpage>â<lpage>D655</lpage>.<pub-id pub-id-type="pmid">29145629</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ghandi</surname><given-names>M.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>Next-generation characterization of the cancer cell line encyclopedia</article-title>. <source>Nature</source>, <volume>569</volume>, <fpage>503</fpage>â<lpage>508</lpage>.<pub-id pub-id-type="pmid">31068700</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>K.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2015</year>) Delving deep into rectifiers: surpassing human-level performance on ImageNet classification. arXiv:150201852 Cs.</mixed-citation>
    </ref>
    <ref id="btab137-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ioffe</surname><given-names>S.</given-names></string-name>, <string-name><surname>Szegedy</surname><given-names>C.</given-names></string-name></person-group> (<year>2015</year>) 
<article-title>Batch normalization: accelerating deep network training by reducing internal covariate shift</article-title>. arXiv:150203167 Cs.</mixed-citation>
    </ref>
    <ref id="btab137-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kanehisa</surname><given-names>M.</given-names></string-name>, <string-name><surname>Goto</surname><given-names>S.</given-names></string-name></person-group> (<year>2000</year>) 
<article-title>KEGG: kyoto encyclopedia of genes and genomes</article-title>. <source>Nucleic Acids Res</source>., <volume>28</volume>, <fpage>27</fpage>â<lpage>30</lpage>.<pub-id pub-id-type="pmid">10592173</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kramer</surname><given-names>M.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2014</year>) 
<article-title>Inferring gene ontologies from pairwise similarity data</article-title>. <source>Bioinform. Oxf. Engl</source>., <volume>30</volume>, <fpage>i34</fpage>â<lpage>i42</lpage>.</mixed-citation>
    </ref>
    <ref id="btab137-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kuenzi</surname><given-names>B.M.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>Predicting drug response and synergy using a deep learning model of human cancer cells</article-title>. <source>Cancer Cell</source>, <volume>38</volume>, <fpage>672</fpage>â<lpage>684.e6</lpage>.<pub-id pub-id-type="pmid">33096023</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>H.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>The landscape of cancer cell line metabolism</article-title>. <source>Nat. Med</source>., <volume>25</volume>, <fpage>850</fpage>â<lpage>860</lpage>.<pub-id pub-id-type="pmid">31068703</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liberzon</surname><given-names>A.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2015</year>) 
<article-title>The Molecular Signatures Database (MSigDB) hallmark gene set collection</article-title>. <source>Cell Syst</source>., <volume>1</volume>, <fpage>417</fpage>â<lpage>425</lpage>.<pub-id pub-id-type="pmid">26771021</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>C.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) 
<article-title>Using neural networks for reducing the dimensions of single-cell RNA-Seq data</article-title>. <source>Nucleic Acids Res</source>., <volume>45</volume>, <fpage>e156</fpage>.<pub-id pub-id-type="pmid">28973464</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>J.-L.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2011</year>) 
<article-title>NF-ÎºB induces abnormal centrosome amplification by upregulation of CDK2 in laryngeal squamous cell cancer</article-title>. <source>Int. J. Oncol</source>., <volume>39</volume>, <fpage>915</fpage>â<lpage>924</lpage>.<pub-id pub-id-type="pmid">21769424</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B22">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>L.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) On the variance of the adaptive learning rate and beyond. arXiv:190803265 Cs Stat.</mixed-citation>
    </ref>
    <ref id="btab137-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ma</surname><given-names>J.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2018</year>) 
<article-title>Using deep learning to model the hierarchical structure and function of a cell</article-title>. <source>Nat. Methods</source>, <volume>15</volume>, <fpage>290</fpage>â<lpage>298</lpage>.<pub-id pub-id-type="pmid">29505029</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meyers</surname><given-names>R.M.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) 
<article-title>Computational correction of copy number effect improves specificity of CRISPR-Cas9 essentiality screens in cancer cells</article-title>. <source>Nat. Genet</source>., <volume>49</volume>, <fpage>1779</fpage>â<lpage>1784</lpage>.<pub-id pub-id-type="pmid">29083409</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mi</surname><given-names>H.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>PANTHER version 14: more genomes, a new PANTHER GO-slim and improvements in enrichment analysis tools</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>D419</fpage>â<lpage>D426</lpage>.<pub-id pub-id-type="pmid">30407594</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B26">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Misra</surname><given-names>D.</given-names></string-name></person-group> (<year>2019</year>) Mish: a self regularized non-monotonic neural activation function. arXiv:190808681 Cs Stat.</mixed-citation>
    </ref>
    <ref id="btab137-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nusinow</surname><given-names>D.P.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>Quantitative proteomics of the cancer cell line encyclopedia</article-title>. <source>Cell</source>, <volume>180</volume>, <fpage>387</fpage>â<lpage>402.e16</lpage>.<pub-id pub-id-type="pmid">31978347</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peng</surname><given-names>J.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>Combining gene ontology with deep neural networks to enhance the clustering of single cell RNA-Seq data</article-title>. <source>BMC Bioinform</source>., <volume>20</volume>, <fpage>284</fpage>.</mixed-citation>
    </ref>
    <ref id="btab137-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rodchenkov</surname><given-names>I.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>Pathway commons 2019 update: integration, analysis and exploration of pathway data</article-title>. <source>Nucleic Acids Res</source>., <volume>48</volume>, <fpage>D489</fpage>â<lpage>D497</lpage>.<pub-id pub-id-type="pmid">31647099</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shen</surname><given-names>W.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2001</year>) 
<article-title>The HOX homeodomain proteins block CBP histone acetyltransferase activity</article-title>. <source>Mol. Cell. Biol</source>., <volume>21</volume>, <fpage>7509</fpage>â<lpage>7522</lpage>.<pub-id pub-id-type="pmid">11585930</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Srivastava</surname><given-names>N.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2014</year>) 
<article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>. <source>J. Mach. Learn. Res</source>., <volume>15</volume>, <fpage>1929</fpage>â<lpage>1958</lpage>.</mixed-citation>
    </ref>
    <ref id="btab137-B32">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Szegedy</surname><given-names>C.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2014</year>) Going deeper with convolutions. arXiv:14094842 Cs.</mixed-citation>
    </ref>
    <ref id="btab137-B33">
      <mixed-citation publication-type="journal">The Gene Ontology Consortium (<year>2017</year>) 
<article-title>Expansion of the Gene Ontology knowledgebase and resources</article-title>. <source>Nucleic Acids Res</source>., <volume>45</volume>, <fpage>D331</fpage>â<lpage>D338</lpage>.<pub-id pub-id-type="pmid">27899567</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van der Horst</surname><given-names>G.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2014</year>) 
<article-title>Targeting of alpha-v integrins reduces malignancy of bladder carcinoma</article-title>. <source>PLoS One</source>, <volume>9</volume>, <fpage>e108464</fpage>.<pub-id pub-id-type="pmid">25247809</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname><given-names>S.J.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) 
<article-title>Discovery of functional and disease pathway by community detection in protein-protein interaction networks</article-title>. <source>Pac. Symp. Biocomput</source>., <volume>22</volume>, <fpage>336</fpage>â<lpage>347</lpage>.<pub-id pub-id-type="pmid">27896987</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname><given-names>M.K.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2018</year>) 
<article-title>Visible machine learning for biomedicine</article-title>. <source>Cell</source>, <volume>173</volume>, <fpage>1562</fpage>â<lpage>1565</lpage>.<pub-id pub-id-type="pmid">29906441</pub-id></mixed-citation>
    </ref>
    <ref id="btab137-B37">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>M.R.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) Lookahead optimizer: k steps forward, 1 step back. arXiv:190708610 Cs Stat.</mixed-citation>
    </ref>
  </ref-list>
</back>
