<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Genet</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Genet</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Genet.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Genetics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1664-8021</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8120292</article-id>
    <article-id pub-id-type="doi">10.3389/fgene.2021.651812</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Genetics</subject>
        <subj-group>
          <subject>Technology and Code</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MRPC: An R Package for Inference of Causal Graphs</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Badsha</surname>
          <given-names>Md. Bahadur</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">
          <sup>*</sup>
        </xref>
        <xref ref-type="author-notes" rid="fn002">
          <sup>†</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/402081/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Martin</surname>
          <given-names>Evan A.</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/1310482/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fu</surname>
          <given-names>Audrey Qiuyan</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="corresp" rid="c002">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/599236/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>Institute for Modeling Collaboration and Innovation, University of Idaho</institution>, <addr-line>Moscow, ID</addr-line>, <country>United States</country></aff>
    <aff id="aff2"><sup>2</sup><institution>The Graduate Program in Bioinformatics and Computational Biology, University of Idaho</institution>, <addr-line>Moscow, ID</addr-line>, <country>United States</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Department of Mathematics and Statistical Science, Institute for Bioinformatics and Evolutionary Studies, University of Idaho, Moscow</institution>, <addr-line>ID</addr-line>, <country>United States</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Mogens Fenger, Capital Region of Denmark, Denmark</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Alexandre Bureau, Laval University, Canada; Cen Wu, Kansas State University, United States</p>
      </fn>
      <corresp id="c001">*Correspondence: Md. Bahadur Badsha, <email>mbbadshar@gmail.com</email></corresp>
      <corresp id="c002">Audrey Qiuyan Fu, <email>audreyf@uidaho.edu</email></corresp>
      <fn fn-type="other" id="fn002">
        <p><sup>†</sup>Present address: Md. Bahadur Badsha, Sera Prognostics, Inc., Salt Lake City, UT, United States</p>
      </fn>
      <fn fn-type="other" id="fn004">
        <p>This article was submitted to Statistical Genetics and Methodology, a section of the journal Frontiers in Genetics</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>30</day>
      <month>4</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>12</volume>
    <elocation-id>651812</elocation-id>
    <history>
      <date date-type="received">
        <day>11</day>
        <month>1</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>06</day>
        <month>4</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2021 Badsha, Martin and Fu.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Badsha, Martin and Fu</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Understanding the causal relationships between variables is a central goal of many scientific inquiries. Causal relationships may be represented by directed edges in a graph (or equivalently, a network). In biology, for example, gene regulatory networks may be viewed as a type of causal networks, where X→Y represents gene X regulating (i.e., being causal to) gene Y. However, existing general-purpose graph inference methods often result in a high number of false edges, whereas current causal inference methods developed for observational data in genomics can handle only limited types of causal relationships. We present MRPC (a PC algorithm with the principle of Mendelian Randomization), an R package that learns causal graphs with improved accuracy over existing methods. Our algorithm builds on the powerful PC algorithm (named after its developers Peter Spirtes and Clark Glymour), a canonical algorithm in computer science for learning directed acyclic graphs. The improvements in MRPC result in increased accuracy in identifying v-structures (i.e., X→Y←Z), and robustness to how the nodes are arranged in the input data. In the special case of genomic data that contain genotypes and phenotypes (e.g., gene expression) at the individual level, MRPC incorporates the principle of Mendelian randomization as constraints on edge direction to help orient the edges. MRPC allows for inference of causal graphs not only for general purposes, but also for biomedical data where multiple types of data may be input to provide evidence for causality. The R package is available on CRAN and is a free open-source software package under a GPL (≥2) license.</p>
    </abstract>
    <kwd-group>
      <kwd>causal inference</kwd>
      <kwd>graphical models</kwd>
      <kwd>networks</kwd>
      <kwd>principle of Mendelian randomization</kwd>
      <kwd>gene regulatory networks</kwd>
      <kwd>R package</kwd>
    </kwd-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="4"/>
      <equation-count count="5"/>
      <ref-count count="37"/>
      <page-count count="11"/>
      <word-count count="0"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="S1">
    <title>Introduction</title>
    <p>Graphical models provide a powerful mathematical framework to represent dependence among variables. Directed edges in a graphical model further represent marginal and conditional dependencies that may be interpreted as causality (<xref rid="B14" ref-type="bibr">Lauritzen, 1996</xref>; <xref rid="B28" ref-type="bibr">Spirtes et al., 2000</xref>; <xref rid="B12" ref-type="bibr">Koller and Friedman, 2009</xref>; <xref rid="B20" ref-type="bibr">Pearl, 2009</xref>; <xref rid="B4" ref-type="bibr">Dawid, 2010</xref>; <xref rid="B6" ref-type="bibr">Guyon et al., 2010</xref>; <xref rid="B22" ref-type="bibr">Peters et al., 2017</xref>). Directed Acyclic Graphs (DAGs), also known as Bayesian networks, are a class of graphical models with only directed edges and no directed cycles.</p>
    <p>Multiple DAGs may represent the same conditional independencies, and therefore are Markov equivalent and belong to the same Markov equivalence class (<xref rid="B24" ref-type="bibr">Richardson, 1997</xref>). Without additional information, inference methods can infer only these Markov equivalence classes. For example, for a simple graph of three nodes, namely X, Y, and Z, if X and Z are conditionally independent given Y (i.e., X⊥Z | Y), three Markov equivalent graphs exist:</p>
    <disp-formula id="S1.E1">
      <label>(1)</label>
      <mml:math id="M1">
        <mml:mrow>
          <mml:mi mathvariant="normal">X</mml:mi>
          <mml:mo>⊥</mml:mo>
          <mml:mi mathvariant="normal">Z</mml:mi>
          <mml:mo stretchy="false">|</mml:mo>
          <mml:mi mathvariant="normal">Y</mml:mi>
          <mml:mo>:</mml:mo>
          <mml:mi mathvariant="normal">X</mml:mi>
          <mml:mo>→</mml:mo>
          <mml:mi mathvariant="normal">Y</mml:mi>
          <mml:mo>→</mml:mo>
          <mml:mi mathvariant="normal">Z</mml:mi>
          <mml:mo>;</mml:mo>
          <mml:mi mathvariant="normal">X</mml:mi>
          <mml:mo>←</mml:mo>
          <mml:mi mathvariant="normal">Y</mml:mi>
          <mml:mo>←</mml:mo>
          <mml:mi mathvariant="normal">Z</mml:mi>
          <mml:mo>;</mml:mo>
          <mml:mi mathvariant="normal">X</mml:mi>
          <mml:mo>←</mml:mo>
          <mml:mi mathvariant="normal">Y</mml:mi>
          <mml:mo>→</mml:mo>
          <mml:mi mathvariant="normal">Z</mml:mi>
          <mml:mo>.</mml:mo>
        </mml:mrow>
      </mml:math>
    </disp-formula>
    <p>Without additional information, it is not possible to determine which graph is the truth, and the inferred graph, which represents the equivalent class, is X−Y−Z.</p>
    <p>Existing methods for inference of DAGs or the equivalent classes fall into three broad classes (<xref rid="B25" ref-type="bibr">Scutari, 2010</xref>) (i) constraint-based methods (<xref rid="B32" ref-type="bibr">Tsamardinos et al., 2003</xref>; <xref rid="B10" ref-type="bibr">Kalisch and Bühlmann, 2007</xref>; <xref rid="B3" ref-type="bibr">Colombo and Maathuis, 2014</xref>), which perform statistical tests of marginal and conditional independence for pairs of nodes; (ii) scored-based methods (<xref rid="B21" ref-type="bibr">Peters et al., 2011</xref>; <xref rid="B18" ref-type="bibr">Mooij et al., 2016</xref>; <xref rid="B19" ref-type="bibr">Nowzohour and Bühlmann, 2016</xref>), which optimize the search according to a score function; and (iii) hybrid methods (<xref rid="B33" ref-type="bibr">Tsamardinos et al., 2006</xref>) that combine the former two approaches.</p>
    <p>The PC algorithm (named after its developers Peter Spirtes and Clark Glymour) is one of the first constraint-based algorithms (<xref rid="B28" ref-type="bibr">Spirtes et al., 2000</xref>). This algorithm makes it computationally feasible to infer graphs of high dimensions, and has been implemented in open-source software, such as the R package pcalg (<xref rid="B11" ref-type="bibr">Kalisch et al., 2012</xref>). The R package bnlearn (Bayesian Network learn) (<xref rid="B25" ref-type="bibr">Scutari, 2010</xref>) implements a collection of graph learning methods from the three classes described above.Other implementations of these algorithms also exist; for example, TETRAD (A TOOLBOX FOR CAUSAL DISCOVERY), a desktop Java application (<xref rid="B23" ref-type="bibr">Ramsey et al., 2018</xref>).</p>
    <p>The methods described above are designed for generic scenarios. In genomics there is growing interest in learning causal graphs among genes or other biological entities, with biological constraints, such as the Principle of Mendelian randomization [PMR (<xref rid="B26" ref-type="bibr">Smith and Ebrahim, 2003</xref>; <xref rid="B27" ref-type="bibr">Smith and Hemani, 2014</xref>)]. The PMR is a randomization principle that assumes the alleles of a genetic variant having been randomly assigned to individuals in a population, analogous to a natural perturbation experiment and therefore achieving the goal of randomization (<xref rid="B27" ref-type="bibr">Smith and Hemani, 2014</xref>). The genetic variant is then an instrumental variable that allows us to establish the causal relationship between phenotypes (e.g., gene expression). The canonical causal model (see M<sub>1</sub> in <xref ref-type="fig" rid="F1">Figure 1</xref>), X→Y→Z, where X is the instrumental variable, Y the exposure and Z the outcome, underlies most of the existing causal inference methods for genomic data based on the PMR (e.g., <xref rid="B5" ref-type="bibr">Didelez and Sheehan, 2007</xref>; <xref rid="B15" ref-type="bibr">Lawlor et al., 2008</xref>; <xref rid="B17" ref-type="bibr">Millstein et al., 2009</xref>; <xref rid="B27" ref-type="bibr">Smith and Hemani, 2014</xref>; <xref rid="B16" ref-type="bibr">Millstein et al., 2016</xref>; <xref rid="B35" ref-type="bibr">Wang and Michoel, 2017</xref>; <xref rid="B36" ref-type="bibr">Yang et al., 2017</xref>; <xref rid="B7" ref-type="bibr">Hemani et al., 2018</xref>; <xref rid="B34" ref-type="bibr">Verbanck et al., 2018</xref>; <xref rid="B8" ref-type="bibr">Howey et al., 2020</xref>; <xref rid="B37" ref-type="bibr">Zhao et al., 2020</xref>).</p>
    <fig id="F1" position="float">
      <label>FIGURE 1</label>
      <caption>
        <p>Basic causal graphs under the principle of Mendelian randomization. <bold>(A)</bold> The five basic (inferred) causal graphs. Each includes a genotype node (also an instrumental variable), V<sub>1</sub>, and two phenotype nodes, T<sub>1</sub> and T<sub>2</sub>. <bold>(B)</bold> Two DAGs M<sub>5</sub> and M<sub>6</sub> are Markov equivalent, and can both be represented by M<sub>4</sub>.</p>
      </caption>
      <graphic xlink:href="fgene-12-651812-g001"/>
    </fig>
    <p>Whereas these methods use the genetic variant as the instrumental variable to account for <italic>unobserved</italic> confounding, we assume causal sufficiency, i.e., confounding variables are fully observed and may be incorporated into the network inference (<xref rid="B28" ref-type="bibr">Spirtes et al., 2000</xref>). We take a graphical model approach to learning causal graphs from individual-level data under causal sufficiency. For the basic models, we consider five (inferred) causal graphs involving a genetic variant node and two phenotype nodes, with the canonical model being one of them (<xref ref-type="fig" rid="F1">Figure 1A</xref> and also see Figure 1 in <xref rid="B1" ref-type="bibr">Badsha and Fu, 2019</xref>). The PMR here means that the edges connecting a genetic variant and a phenotype always points <italic>to</italic> the phenotype and not the other way around. This constraint induced by the PMR provides background knowledge to the graph inference and helps limit the number of possible graphs.</p>
    <p>Our algorithm, namely MRPC, is essentially a variant of the PC algorithm that incorporates the PMR (<xref rid="B1" ref-type="bibr">Badsha and Fu, 2019</xref>). MRPC implements several improvements over existing general-purpose graph inference methods, and these improvements enable us to obtain more accurate and stable inference for generic data sets compared to several methods implemented in the bnlearn and pcalg packages, both of which have been widely used for network inference. Our package further provides alternative approaches to graph visualization and graph comparison that are unavailable in the bnlearn and pcalg packages.</p>
  </sec>
  <sec id="S2">
    <title>Method</title>
    <p>The MRPC package contains four modules: inference, simulation, visualization, and assessment (<xref ref-type="fig" rid="F2">Figure 2</xref>; two sample analysis pipelines of using these modules are provided in the <xref ref-type="supplementary-material" rid="DS1">Supplementary Material</xref>).</p>
    <fig id="F2" position="float">
      <label>FIGURE 2</label>
      <caption>
        <p>The four modules in the MRPC package. Inputs are listed on the left and outputs on the right. The inference module is at the center of the package, which may take the correlation matrix from real or simulated data as input, and outputs a graph object, the core of which is the (asymmetric) adjacency matrix. For genomic data, we require that the genotype (instrumental variable) nodes are placed in the data matrix before the phenotype nodes. Thus, the rows and columns of the correlation matrix and the adjacency matrix also start with genotypes, followed by phenotypes. The simulation module can generate a data matrix from which the correlation matrix may be derived and used as input to the inference module. A graph object, constructed directly or provided by the inference module, can be passed through the visualization module for displaying the graph topology and for clustering nodes into modules. The difference between two graph objects (e.g., true and inferred graphs, graphs inferred by two different methods) may be evaluated by multiple metrics in the assessment module.</p>
      </caption>
      <graphic xlink:href="fgene-12-651812-g002"/>
    </fig>
    <sec id="S2.SS1">
      <title>The Inference Module</title>
      <p>Since PC-based algorithms have demonstrated computational efficiency in learning causal graphs, we built the inference module of our MRPC algorithm on the pc function implemented in the R package pcalg. The inference module takes the data matrix or correlation matrix as input, and outputs a graph object that contains the adjacency matrix and may be visualized or compared with other graphs. The adjacency matrix of a causal graph is denoted by <italic>A</italic> = {<italic>a</italic><sub><italic>ij</italic></sub>}, where <italic>a</italic><sub><italic>ij</italic></sub>takes the value 1 if there is a directed edge from node <italic>i</italic> to node <italic>j</italic>, and 0 otherwise. In our package, we consider the rows to be parent nodes and the columns child nodes. If <italic>a<sub><italic>ij</italic></sub></italic> = <italic>a</italic><sub><italic>ji</italic></sub> = 1, then the edge between nodes <italic>i</italic> and <italic>j</italic> is bidirected (which is equivalent to being undirected in our representation).</p>
      <p>Below we describe our MRPC algorithm [first introduced in <xref rid="B1" ref-type="bibr">Badsha and Fu (2019)</xref>], which is at the center of the inference module. Similar to other PC-like algorithms, MRPC consists of two steps: learning the graph skeleton, and orienting edges in the skeleton:</p>
      <p>
        <bold>Step I: Learning the graph skeleton</bold>
      </p>
      <p>The procedure in this step is standard in all the PC-based algorithms: it starts with a fully connected graph, and then conducts a series of statistical tests for pairs of nodes, testing for marginal independence between two nodes, and then testing for conditional independence between two nodes, given one other node, two other nodes, and so on. An insignificant <italic>p</italic>-value leads to the corresponding edge being removed and never tested again in this step. The tests are similar to those in pcalg and include the Fisher’s z transformation test for Pearson correlation and partial correlation for continuous data, and the G<sup>2</sup> test for discrete data (<xref rid="B11" ref-type="bibr">Kalisch et al., 2012</xref>).</p>
      <p>However, pcalg and bnlearn do not control the overall error rate but only the type I error rate for each individual test. The number of total tests is also unknown beforehand: an edge removed after a test eliminates the need for additional tests for this edge. We implemented the LOND (determining the significance Levels based On the Number of Discoveries) method (<xref rid="B9" ref-type="bibr">Javanmard and Montanari, 2018</xref>) in order to control the overall false discovery rate (FDR) in an online manner: for each test, we use this method to calculate a <italic>p</italic>-value threshold. Depending on how many tests have been performed and how many rejections have been made, the <italic>p</italic>-value thresholds tend to be large at the beginning and decrease as more tests are performed (<xref rid="B1" ref-type="bibr">Badsha and Fu, 2019</xref>).</p>
      <p>When outliers are present, MRPC further allows for the estimate of robust correlation for continuous variables (<xref rid="B2" ref-type="bibr">Badsha et al., 2013</xref>), which may substitute Pearson correlation.</p>
      <p>
        <bold>Step II: Edge orientation</bold>
      </p>
      <p>We design the following steps for edge orientation, which are fundamentally different from existing methods implemented in bnlearn and pcalg:</p>
      <list list-type="simple">
        <list-item>
          <label>(1)</label>
          <p>If the data contain genotype information and there are edges connecting a genotype node to a non-genotype node, then the edge will always point to the non-genotype node, reflecting the assumption in the PMR that genotypes influence phenotypes, but not the other way around. An edge connecting two genotype nodes is always undirected, since it is meaningless to talk about causality between two genetic variants.</p>
        </list-item>
        <list-item>
          <label>(2)</label>
          <p>Next, we search for possible triplets (X−Y−Z) that may form a v-structure (X→Y←Z), which does not have Markov equivalent graphs and can therefore be uniquely determined. We check the test results from Step I to see whether X and Z are conditionally dependent given Y. If so, then both edges are set to point to Y. Otherwise, we leave the edges undirected.</p>
        </list-item>
      </list>
      <p>If this conditional test has not been performed in Step I (e.g., the marginal test between X and Z may result in the removal of the edge X-Z and eliminate the need for any conditional test for X and Z), we conduct it now.</p>
      <p>If the input does not contain genotype nodes or similar instrumental variables, edge orientation will start from this step.</p>
      <p>For undirected edges after steps (1) and (2), we look iteratively for triplets of nodes with at least one directed edge and no more than one undirected edge. We check which of the basic models in <xref ref-type="fig" rid="F1">Figure 1A</xref> is consistent with the test results from Step I, and if one is found, we orient the undirected edge accordingly. It is plausible that some undirected edges cannot be oriented, and we leave them as undirected. Thus, the resulting graph may have both directed and undirected edges.</p>
    </sec>
    <sec id="S2.SS2">
      <title>Simulating Continuous and Discrete Data</title>
      <p>With a known graph, we generate data first for the nodes without parents from marginal distributions, for example, a normal distribution:</p>
      <disp-formula id="S2.E2">
        <label>(2)</label>
        <mml:math id="M2">
          <mml:mrow>
            <mml:mrow>
              <mml:msub>
                <mml:mi>X</mml:mi>
                <mml:mi>i</mml:mi>
              </mml:msub>
              <mml:mo>∼</mml:mo>
              <mml:mrow>
                <mml:mi>N</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:msub>
                    <mml:mi>m</mml:mi>
                    <mml:mi>i</mml:mi>
                  </mml:msub>
                  <mml:mo>,</mml:mo>
                  <mml:msubsup>
                    <mml:mi mathvariant="normal">σ</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mn>2</mml:mn>
                  </mml:msubsup>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
            <mml:mo>,</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>where <italic>X</italic><sub><italic>i</italic></sub> represents the data observed at node <italic>i</italic>, <italic>m</italic><sub><italic>i</italic></sub> is the mean and <inline-formula><mml:math id="INEQ3"><mml:msubsup><mml:mi mathvariant="normal">σ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> the variance. If a node has one or more parents, we generate data from a conditional distribution; for example,</p>
      <disp-formula id="S2.E3">
        <label>(3)</label>
        <mml:math id="M3">
          <mml:mrow>
            <mml:mrow>
              <mml:mrow>
                <mml:msub>
                  <mml:mi>X</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:msub>
                <mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo>
                <mml:mrow>
                  <mml:mo>{</mml:mo>
                  <mml:msub>
                    <mml:mi>X</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msub>
                  <mml:mo>:</mml:mo>
                  <mml:mrow>
                    <mml:mpadded width="+1.7pt">
                      <mml:mi>l</mml:mi>
                    </mml:mpadded>
                    <mml:mo rspace="4.2pt">∈</mml:mo>
                    <mml:mtext>P</mml:mtext>
                  </mml:mrow>
                  <mml:mo>}</mml:mo>
                </mml:mrow>
              </mml:mrow>
              <mml:mo>∼</mml:mo>
              <mml:mrow>
                <mml:mi>N</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mi mathvariant="normal">γ</mml:mi>
                      <mml:mn>0</mml:mn>
                    </mml:msub>
                    <mml:mo>+</mml:mo>
                    <mml:mrow>
                      <mml:munder>
                        <mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo>
                        <mml:mrow>
                          <mml:mpadded width="+1.7pt">
                            <mml:mi>l</mml:mi>
                          </mml:mpadded>
                          <mml:mo rspace="4.2pt">∈</mml:mo>
                          <mml:mrow>
                            <mml:mtext>P</mml:mtext>
                          </mml:mrow>
                        </mml:mrow>
                      </mml:munder>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi mathvariant="normal">γ</mml:mi>
                          <mml:mi>l</mml:mi>
                        </mml:msub>
                        <mml:mo>⁢</mml:mo>
                        <mml:msub>
                          <mml:mi>X</mml:mi>
                          <mml:mi>l</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mo>,</mml:mo>
                  <mml:msubsup>
                    <mml:mi mathvariant="normal">σ</mml:mi>
                    <mml:mi>j</mml:mi>
                    <mml:mn>2</mml:mn>
                  </mml:msubsup>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
            <mml:mo>,</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>where γ<sub>0</sub> + ∑<sub><italic>l</italic>∈P</sub>γ<sub><italic>l</italic></sub><italic>X</italic><sub><italic>l</italic></sub> is the linear model that describes the dependence of <italic>X</italic><sub><italic>j</italic></sub> on data at its parent nodes in the set <italic>P</italic>.</p>
      <p>There are different ways to simulate data of genotypes. Here we assume that each genetic variant is a biallelic single nucleotide polymorphism (SNP); this means that the variant has two alleles (denoted by 0 for the reference allele and 1 for the alternative allele) in the population. The genotype at this variant may be 0 (or 00, which means homozygous for the reference allele), 1 (or 01, heterozygous), or 2 (or 11; homozygous for the alternative allele). Let <italic>q</italic> be the probability of allele 1 in the population. Assume that the probability of one allele is not affected by that of the other allele in the same individual (i.e., the genotypes are in Hardy-Weinberg equilibrium). Then the genotype of the node V follows a multinomial distribution:</p>
      <p>Pr(<italic>V</italic> = 0) = (1−<italic>q</italic>)<sup>2</sup>; Pr(<italic>V</italic> = 1) = 2<italic>q</italic> (1−<italic>q</italic>); Pr(<italic>V</italic> = 2) = <italic>q</italic><sup>2</sup>.</p>
      <p>Other types of nodes in the graph can then be simulated using the marginal and conditional normal distributions as in Expressions (2) and (3).</p>
      <p>Different approaches may be used to generate data for graphs with an undirected edge. For M<sub>4</sub> in <xref ref-type="fig" rid="F1">Figure 1A</xref>, we consider that the undirected edge is a mixture of the two possible directions (<xref ref-type="fig" rid="F1">Figure 1B</xref>). The nrefore, we generate data for T<sub>1</sub>→T<sub>2</sub>:</p>
      <disp-formula id="S2.Ex1">
        <mml:math id="M4">
          <mml:mrow>
            <mml:mrow>
              <mml:mrow>
                <mml:msub>
                  <mml:mi>T</mml:mi>
                  <mml:mn>1</mml:mn>
                </mml:msub>
                <mml:mo>∼</mml:mo>
                <mml:mrow>
                  <mml:mi>N</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi mathvariant="normal">γ</mml:mi>
                        <mml:mn>0</mml:mn>
                      </mml:msub>
                      <mml:mo>+</mml:mo>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi mathvariant="normal">γ</mml:mi>
                          <mml:mn>1</mml:mn>
                        </mml:msub>
                        <mml:mo>⁢</mml:mo>
                        <mml:msub>
                          <mml:mi>V</mml:mi>
                          <mml:mn>1</mml:mn>
                        </mml:msub>
                      </mml:mrow>
                    </mml:mrow>
                    <mml:mo>,</mml:mo>
                    <mml:msubsup>
                      <mml:mi mathvariant="normal">σ</mml:mi>
                      <mml:mn>1</mml:mn>
                      <mml:mn>2</mml:mn>
                    </mml:msubsup>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
              <mml:mo rspace="5.8pt">;</mml:mo>
              <mml:mrow>
                <mml:msub>
                  <mml:mi>T</mml:mi>
                  <mml:mn>2</mml:mn>
                </mml:msub>
                <mml:mo>∼</mml:mo>
                <mml:mrow>
                  <mml:mi>N</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi mathvariant="normal">γ</mml:mi>
                        <mml:mn>0</mml:mn>
                      </mml:msub>
                      <mml:mo>+</mml:mo>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi mathvariant="normal">γ</mml:mi>
                          <mml:mn>1</mml:mn>
                        </mml:msub>
                        <mml:mo>⁢</mml:mo>
                        <mml:msub>
                          <mml:mi>V</mml:mi>
                          <mml:mn>1</mml:mn>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mo>+</mml:mo>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi mathvariant="normal">γ</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msub>
                        <mml:mo>⁢</mml:mo>
                        <mml:msub>
                          <mml:mi>T</mml:mi>
                          <mml:mn>1</mml:mn>
                        </mml:msub>
                      </mml:mrow>
                    </mml:mrow>
                    <mml:mo>,</mml:mo>
                    <mml:msubsup>
                      <mml:mi mathvariant="normal">σ</mml:mi>
                      <mml:mn>2</mml:mn>
                      <mml:mn>2</mml:mn>
                    </mml:msubsup>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
            <mml:mo>,</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>and separately for T<sub>1</sub>←T<sub>2</sub>:</p>
      <disp-formula id="S2.Ex2">
        <mml:math id="M5">
          <mml:mrow>
            <mml:mrow>
              <mml:mrow>
                <mml:msub>
                  <mml:mi>T</mml:mi>
                  <mml:mn>1</mml:mn>
                </mml:msub>
                <mml:mo>∼</mml:mo>
                <mml:mrow>
                  <mml:mi>N</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi mathvariant="normal">γ</mml:mi>
                        <mml:mn>0</mml:mn>
                      </mml:msub>
                      <mml:mo>+</mml:mo>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi mathvariant="normal">γ</mml:mi>
                          <mml:mn>1</mml:mn>
                        </mml:msub>
                        <mml:mo>⁢</mml:mo>
                        <mml:msub>
                          <mml:mi>V</mml:mi>
                          <mml:mn>1</mml:mn>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mo>+</mml:mo>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi mathvariant="normal">γ</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msub>
                        <mml:mo>⁢</mml:mo>
                        <mml:msub>
                          <mml:mi>T</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msub>
                      </mml:mrow>
                    </mml:mrow>
                    <mml:mo>,</mml:mo>
                    <mml:msubsup>
                      <mml:mi mathvariant="normal">σ</mml:mi>
                      <mml:mn>1</mml:mn>
                      <mml:mn>2</mml:mn>
                    </mml:msubsup>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
              <mml:mo rspace="5.8pt">;</mml:mo>
              <mml:mrow>
                <mml:msub>
                  <mml:mi>T</mml:mi>
                  <mml:mn>2</mml:mn>
                </mml:msub>
                <mml:mo>∼</mml:mo>
                <mml:mrow>
                  <mml:mi>N</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi mathvariant="normal">γ</mml:mi>
                        <mml:mn>0</mml:mn>
                      </mml:msub>
                      <mml:mo>+</mml:mo>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi mathvariant="normal">γ</mml:mi>
                          <mml:mn>1</mml:mn>
                        </mml:msub>
                        <mml:mo>⁢</mml:mo>
                        <mml:msub>
                          <mml:mi>V</mml:mi>
                          <mml:mn>1</mml:mn>
                        </mml:msub>
                      </mml:mrow>
                    </mml:mrow>
                    <mml:mo>,</mml:mo>
                    <mml:msubsup>
                      <mml:mi mathvariant="normal">σ</mml:mi>
                      <mml:mn>2</mml:mn>
                      <mml:mn>2</mml:mn>
                    </mml:msubsup>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
            <mml:mo>.</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>We then randomly choose a pair of values with 50:50 probability for each sample. In a larger graph (e.g., <xref ref-type="fig" rid="F3">Figure 3A</xref>), where many genotype nodes, denoted by V<sub><italic>j</italic></sub>, have undirected edges between them), we randomly pick a direction for each undirected edge in simulation.</p>
      <fig id="F3" position="float">
        <label>FIGURE 3</label>
        <caption>
          <p>Visualization of a complex graph in MRPC. <bold>(A)</bold> The true graph includes 14 genetic variants and 8 phenotype nodes. <bold>(B)</bold> The inferred graph. <bold>(C)</bold> The dendrogram of the inferred graph with four modules identified when the minimum module size is set to 5. <bold>(D)</bold> Redrawing the inferred graph based on the dendrogram. Nodes of the same color belong to the same module.</p>
        </caption>
        <graphic xlink:href="fgene-12-651812-g003"/>
      </fig>
      <p>For discrete data, there may exist several approaches for simulation. For the sample data in our R package, we first generate continuous values and then discretize them into multiple categories, as these sample data sets lack context and are mainly for demonstrating the usage of other functions. More appropriate methods for generating discrete data can be designed when there is more knowledge of the data generative process.</p>
    </sec>
    <sec id="S2.SS3">
      <title>Visualization</title>
      <p>This module includes functions for generating three types of plots:</p>
      <list list-type="simple">
        <list-item>
          <label>(a)</label>
          <p>A graph with variables represented by nodes and causal relationships by directed edges. In cases where a causal relationship is not possible to determine (e.g., see M<sub>4</sub> in <xref ref-type="fig" rid="F1">Figure 1A</xref>), the graph will display a bidirected edge, which is equivalent to an undirected edge.</p>
        </list-item>
        <list-item>
          <label>(b)</label>
          <p>A dendrogram of all the nodes in the causal graph based on the distance (i.e., the number of edges) between two nodes. The nodes may be clustered into modules according to the dendrogram and the minimum module size, which is the number of nodes in a module.</p>
        </list-item>
        <list-item>
          <label>(c)</label>
          <p>A graph with nodes in modules of different colors. Generation of this graph uses the clustering results in the dendrogram. For genomic data, the graph further displays the genotype nodes in filled triangles and phenotype nodes in filled circles.</p>
        </list-item>
      </list>
    </sec>
    <sec id="S2.SS4">
      <title>Assessment of Inferred Graphs</title>
      <p>We provide three metrics to compare an inferred graph with the true one:</p>
      <list list-type="simple">
        <list-item>
          <label>(a)</label>
          <p>Recall and precision: Recall (i.e., power or sensitivity) measures how many edges from the true graph a method can recover, whereas precision (i.e., 1-FDR) measures how many correct edges are recovered in the inferred graph. If an edge is recovered but its direction is wrongly inferred or not inferred, we down weigh the corresponding edge with a default value of 0.5.</p>
        </list-item>
        <list-item>
          <label>(b)</label>
          <p>Adjusted Structural Hamming Distance (aSHD): The SHD, as implemented in pcalg and bnlearn, counts how many differences exist between two directed graphs. This distance is 1.0 if an edge exists in one graph but missing in the other, or if the direction of an edge is different in the two graphs. The larger this distance, the more different the two graphs are. We adjust the SHD, reducing the penalty on the wrong direction to 0.5.</p>
        </list-item>
      </list>
    </sec>
    <sec id="S2.SS5">
      <title>Relationship to Existing Methods and Implementations in R</title>
      <p>We compare MRPC to the pc function from the pcalg package (<xref rid="B11" ref-type="bibr">Kalisch et al., 2012</xref>) and several methods implemented in the bnlearn package. Among those methods from bnlearn (<xref rid="B25" ref-type="bibr">Scutari, 2010</xref>), we focus on four functions: pc.stable, which also implements the same method as the function pc in pcalg; mmpc, another constraint-based method; hc (Hill Climbing), a score-based method; and mmhc, which is the hybrid version of mmpc and hc.mmhc also consists of two steps: learning the neighbors (parent and child nodes) of a node, and finding the graph that is consistent with the data and the neighbors identified from the first step (<xref rid="B33" ref-type="bibr">Tsamardinos et al., 2006</xref>).</p>
      <p>There are several differences among these methods. First, although pc, pc.stable, and mmpc conduct statistical tests, they do not adjust for multiple testing and instead control the type I error rate only for each individual test. On the other hand, the default method in MRPC is the LOND method that controls the overall FDR. Second, whereas mmhc estimates a DAG with all edges being directed, the other methods considered here (including our MRPC method) estimate the Markov equivalence class of the DAG. Third, functions in bnlearn can restrict the direction of the edges involving genetic variants (with the “blacklist” argument), similar to our method under the PMR. The pc function in pcalg, however, cannot restrict only the direction of an edge but instead can include or exclude the entire edge (with the “fixedEdges” argument to include certain edges and “fixedGaps” to exclude edges).Fourth, pc and MRPC can take the correlation matrix, which is derived from the data matrix, as the input, whereas bnlearn requires the entire data matrix as the input.</p>
    </sec>
  </sec>
  <sec id="S3">
    <title>Results</title>
    <sec id="S3.SS1">
      <title>An Example</title>
      <p>We use a graph of 22 nodes to demonstrate the functionalities of our package. Among the 22 nodes, 14 are genetic variants and 8 are phenotype nodes. <xref ref-type="fig" rid="F3">Figure 3</xref> shows the true graph, the graph inferred by MRPC, the dendrogram of the nodes, and the graph with color-coded modules identified from clustering the branches in the dendrogram. The R code for producing this figure is below:</p>
      <p>
        <inline-graphic xlink:href="fgene-12-651812-i000.jpg"/>
      </p>
      <p>
        <inline-graphic xlink:href="fgene-12-651812-i001.jpg"/>
      </p>
      <p>The <xref ref-type="supplementary-material" rid="DS1">Supplementary Material</xref> contains the R code above as well as the code for reproducing all the other analyses in Results.</p>
    </sec>
    <sec id="S3.SS2">
      <title>V-Structure Identification</title>
      <p>In this and the next section, we compare our package with five implementations: the pc function from the pcalg package, and several methods (pc.stable, mmpc, hc, and mmhc) implemented in the bnlearn package. Additional simulations and method comparison may be found in our earlier work (<xref rid="B1" ref-type="bibr">Badsha and Fu, 2019</xref>).</p>
      <p>Since a v-structure can be uniquely determined, it is critical to correctly identify them in the data. However, pc, hc, and mmhc may wrongly identify v-structures when there is not one. With pc, the false v-structure is due to incorrect interpretation of the lack of the edge X−Z. Specifically, with a candidate v-structure that has the graph skeleton X−Y−Z, pc examines the separation set for X and Z, denoted S(X,Z). If S(X,Z) contains Y, it means that X⊥Z | Y and X−Y−Z will not form a v-structure. When S does not contain Y, however, there may be two explanations: (i) a conditional test has been conducted for X and Z given Y, and the null hypothesis is rejected, which implies a v-structure; and (ii) the edge X−Z may have been removed due to earlier tests. As a result, the conditional test is never performed, and there is no evidence for or against a v-structure. However, pc always uses the first interpretation and claims a v-structure even when there is not one. It is unclear why hc and mmhc also falsely identify v-structures, though. To resolve the problem with pc, we have made the following improvement in MRPC in Step II (2): when determining whether a candidate triplet is a v-structure, we test conditional independence between X and Z given Y, if this test has not been performed in Step I.</p>
      <p>To assess inference accuracy, we simulated data under Models M<sub>1</sub> (not a v-structure) and M<sub>2</sub> (a v-structure) from <xref ref-type="fig" rid="F1">Figure 1A</xref>, and summarized the mean and standard deviation of recall and precision in <xref rid="T1" ref-type="table">Table 1</xref>. MRPC and mmpc perform similarly and do well under both models in general, although they have some problems recovering a v-structure when the signal strength is low (γ = 0.2). When the signal strength is low in the v-structure (V<sub>1</sub>→ T<sub>1</sub>←T<sub>2</sub>), the partial correlation between V<sub>1</sub> and T<sub>2</sub> conditioned on T<sub>1</sub> tends to be weak and statistically insignificant. MRPC therefore tends to conclude conditional independence between V<sub>1</sub> and T<sub>2</sub> given T<sub>1</sub>, and infers an M<sub>1</sub> model instead of a v-structure. hc and mmhc have lower recall than MRPC and mmpc at a weak signal strength under M<sub>1</sub>. pc recovers M<sub>2</sub> well, and correctly infers M<sub>1</sub> as V<sub>1</sub>–T<sub>1</sub>–T<sub>2</sub> at moderate or strong signal. However, at weak signal, pc tends to infer a v-structure, due to the reason explained above, which results in higher recall and precision than at stronger signal, as the edge V<sub>1</sub>→T<sub>1</sub> is now correctly inferred. Also as expected, even when we use only the edge T<sub>1</sub>–T<sub>2</sub> to evaluate recall and precision, the metrics do not change much (see pc<sup>∗</sup> in <xref rid="T1" ref-type="table">Table 1</xref>). pc.stable from bnlearn does not appear to have the same problem as pc from pcalg: pc.stable performs well under both models, with reduced accuracy only at weak signal under M<sub>1</sub>.</p>
      <table-wrap id="T1" position="float">
        <label>TABLE 1</label>
        <caption>
          <p>Comparison of inference accuracy without and with a v-structure.</p>
        </caption>
        <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
          <thead>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="6" rowspan="1">Model M<sub>1</sub> in <xref ref-type="fig" rid="F1">Figure 1A</xref> (V<sub>1</sub>→T<sub>1</sub>→T<sub>2</sub>)</td>
            </tr>
            <tr>
              <td valign="top" align="center" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="6" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="2" rowspan="1">γ = 1.0 (strong signal)</td>
              <td valign="top" align="center" colspan="2" rowspan="1">γ = 0.5 (moderate signal)</td>
              <td valign="top" align="center" colspan="2" rowspan="1">γ = 0.2 (weak signal)</td>
            </tr>
            <tr>
              <td valign="top" align="center" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="2" rowspan="1">
                <hr/>
              </td>
              <td valign="top" align="center" colspan="2" rowspan="1">
                <hr/>
              </td>
              <td valign="top" align="center" colspan="2" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="center" rowspan="1" colspan="1">Recall</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Precision</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Recall</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Precision</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Recall</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Precision</td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">MRPC</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>1.00 (0.02)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>1.00 (0.05)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>1.00 (0.01)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>1.00 (0.02)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.96 (0.18)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.97 (0.12)</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.50 (0.00)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.49 (0.03)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.50 (0.00)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.49 (0.04)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.71 (0.09)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.71 (0.10)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc*</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.50 (0.00)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.50 (0.00)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.50 (0.00)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.50(0.00)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.50 (0.02)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.50 (0.02)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc.stable</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.99 (0.06)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.11)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>1.00 (0.05)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.98 (0.09)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.77 (0.09)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.76 (0.09)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mmpc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.99 (0.06)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.11)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>1.00 (0.05)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.98 (0.09)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.97 (0.10)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.97 (0.11)</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">hc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.89 (0.12)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.78 (0.24)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.99 (0.02)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.99 (0.04)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.89 (0.16)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.90 (0.14)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mmhc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.99 (0.03)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.98 (0.06)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>1.00 (0.02)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>1.00 (0.02)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.89 (0.16)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.89 (0.14)</td>
            </tr>
            <tr>
              <td valign="top" align="center" colspan="7" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="6" rowspan="1">
                <bold>Model M<sub>2</sub> in <xref ref-type="fig" rid="F1">Figure 1A</xref> (V<sub>1</sub>→T<sub>1</sub>←T<sub>2</sub>)</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="center" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="6" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="2" rowspan="1">
                <bold>γ = 1.0</bold>
              </td>
              <td valign="top" align="center" colspan="2" rowspan="1">
                <bold>γ = 0.5</bold>
              </td>
              <td valign="top" align="center" colspan="2" rowspan="1">
                <bold>γ = 0.2</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="center" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="2" rowspan="1">
                <hr/>
              </td>
              <td valign="top" align="center" colspan="2" rowspan="1">
                <hr/>
              </td>
              <td valign="top" align="center" colspan="2" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>Recall</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>Precision</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>Recall</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>Precision</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>Recall</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>Precision</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="center" colspan="7" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">MRPC</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.99 (0.08)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.99 (0.08)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.99 (0.06)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.99 (0.07)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.73 (0.11)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.74 (0.06)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.12)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.96 (0.16)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.11)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.96 (0.15)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.13)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.14)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc*</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.10)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.10)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.11)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.11)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.11)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.11)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc.stable</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.98 (0.06)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.12)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.98 (0.06)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.11)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.98 (0.10)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.98 (0.10)</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mmpc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.98 (0.06)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.12)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.98 (0.06)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.11)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.78 (0.10)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.77 (0.10)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">hc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.98 (0.06)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.96 (0.13)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.99 (0.02)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.99 (0.03)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.89 (0.16)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.91 (0.13)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mmhc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.99 (0.06)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.99 (0.07)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.99 (0.02)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.99 (0.04)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.90 (0.16)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.91 (0.10)</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <attrib>
            <italic>Mean (with standard deviation in parentheses) of recall and precision of MPRC, pc (v2.6-2), pc.stable, mmpc, hc, and mmhc (the last four are from the bnlearn package v4.4.1) across 1,000 data sets with a sample size of 1,000 are reported. Regression coefficient γ (see Equation 3) indicates the signal strength. For the functions from bnlearn, we restricted the direction of possible edges involving the genetic variant V<sub>1</sub> using the “blacklist” argument. Calculation of recall and precision uses all the edges in an inferred graph, except for the results for pc*, where edges involving the genetic variant V<sub>1</sub> are excluded. Highest mean values in each column are in bold.</italic>
          </attrib>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="S3.SS3">
      <title>Inference Accuracy of Different Methods on a Graph of 22 Nodes</title>
      <p>We are interested in how our and other methods perform on larger graphs such as the one in <xref ref-type="fig" rid="F3">Figure 3A</xref>, which contains 22 nodes and several M<sub>1</sub> and M<sub>2</sub> subgraphs. Similar to the previous section, we simulated 1,000 independent data sets for this graph at different signal strengths, and calculated the mean and standard deviation of recall and precision (<xref rid="T2" ref-type="table">Table 2</xref>). Since 14 of the nodes are genetic variants, we applied the blacklist argument again when running the functions from bnlearn. Recall that MRPC always infers an edge between two genetic variants to be bidirected (or undirected). Other methods, however, do not make this assumption. When calculating recall and precision for other methods, we adjusted the inferred graphs such that the direction of any edge between two genetic variants is ignored. With moderate and strong signal, MRPC and mmhc perform similarly, in mean recall and precision, both being better than other methods. MRPC further has smaller variance in recall and precision than all the other methods. When the signal is weak, mmhc and hc still perform well on both metrics. MRPC retains a high precision (higher than other methods, except for mmhc and hc), but its ability to recover the true edges is significantly reduced (i.e., lower recall). By contrast, all the other methods have higher recall but lower precision.</p>
      <table-wrap id="T2" position="float">
        <label>TABLE 2</label>
        <caption>
          <p>Comparison of inference accuracy on the complex graph in <xref ref-type="fig" rid="F3">Figure 3A</xref>.</p>
        </caption>
        <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
          <thead>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="2" rowspan="1">γ = 1.0 (strong signal)</td>
              <td valign="top" align="center" colspan="2" rowspan="1">γ = 0.5 (moderate signal)</td>
              <td valign="top" align="center" colspan="2" rowspan="1">γ = 0.2 (weak signal)</td>
            </tr>
            <tr>
              <td valign="top" align="center" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="2" rowspan="1">
                <hr/>
              </td>
              <td valign="top" align="center" colspan="2" rowspan="1">
                <hr/>
              </td>
              <td valign="top" align="center" colspan="2" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="center" rowspan="1" colspan="1">Recall</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Precision</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Recall</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Precision</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Recall</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Precision</td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">MRPC</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.98 (0.00)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.98 (0.00)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.01)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.98 (0.00)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.66 (0.06)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.85 (0.03)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.95 (0.01)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.93 (0.03)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.95 (0.02)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.89 (0.05)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.90 (0.04)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.76 (0.06)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc*</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.91 (0.04)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.90 (0.05)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.91 (0.04)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.89 (0.06)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.77 (0.11)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.74 (0.11)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc.stable</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.06)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.95 (0.04)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.01)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.91 (0.05)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.92 (0.04)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.78 (0.06)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mmpc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.01)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.95 (0.03)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.98 (0.01)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.91 (0.05)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.87 (0.04)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.74 (0.06)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">hc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.99 (0.01)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.92 (0.05)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.99 (0.01)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.91 (0.05)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.95 (0.03)</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.89 (0.05)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mmhc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.98 (0.01)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.97 (0.03)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.98 (0.01)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.95 (0.04)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.94 (0.04)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.90 (0.05)</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <attrib>
            <italic>See the legend for <xref rid="T1" ref-type="table">Table 1</xref>. Calculation of recall and precision uses all the edges in an inferred graph, except for the results for pc*, where edges involving the genetic variants are excluded. Highest mean values in each column are in bold.</italic>
          </attrib>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="S3.SS4">
      <title>Node-Ordering Independence</title>
      <p>Network inference algorithms are often sensitive to how the nodes are ordered in the input and may infer the graph differently simply because the node ordering is different. In this simulation, we generated 200 data sets for each graph with a strong signal (γ = 1.0) and a sample size of 1,000. For each data set, we permuted the order of the nodes to generate permuted data sets, applied all the methods (restricting edge direction wherever necessary and possible), and counted the number of uniquely inferred graphs. We then calculated the quantiles of the number of uniquely inferred graphs across the 200 data sets. MRPC is the most stable, whereas hc and mmhc are the most sensitive to node ordering, especially on the complex graph (<xref rid="T3" ref-type="table">Table 3</xref>). Other methods are much more stable than hc or mmhc but not as stable as MRPC.</p>
      <table-wrap id="T3" position="float">
        <label>TABLE 3</label>
        <caption>
          <p>Summary statistics of the counts of uniquely inferred graphs with node permutation.</p>
        </caption>
        <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
          <thead>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="4" rowspan="1">V<sub>1</sub>→T<sub>1</sub>→T<sub>2</sub>→T<sub>3</sub></td>
            </tr>
            <tr>
              <td valign="top" align="center" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="4" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="center" rowspan="1" colspan="1">1st Quartile</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Median</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3rd Quartile</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Max</td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">MRPC</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc.stabe</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mmpc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">hc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mmhc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
            </tr>
            <tr>
              <td valign="top" align="center" colspan="5" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="4" rowspan="1">
                <bold>V<sub>1</sub>→T<sub>1</sub>←T<sub>2</sub>→T<sub>3</sub></bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="center" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="7" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>1st Quartile</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>Median</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>3rd Quartile</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>Max</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="center" colspan="5" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">MRPC</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc.stable</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mmpc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">hc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mmhc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
            </tr>
            <tr>
              <td valign="top" align="center" colspan="5" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="4" rowspan="1">
                <bold>Complex Graph in <xref ref-type="fig" rid="F3">Figure 3A</xref></bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="center" rowspan="1" colspan="1"/>
              <td valign="top" align="center" colspan="4" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>1st Quartile</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>Median</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>3rd Quartile</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>Max</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="center" colspan="5" rowspan="1">
                <hr/>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">MRPC</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">4</td>
              <td valign="top" align="center" rowspan="1" colspan="1">39</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">pc.stable</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">5</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mmpc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">hc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">42</td>
              <td valign="top" align="center" rowspan="1" colspan="1">43</td>
              <td valign="top" align="center" rowspan="1" colspan="1">45</td>
              <td valign="top" align="center" rowspan="1" colspan="1">49</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mmhc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">35</td>
              <td valign="top" align="center" rowspan="1" colspan="1">37</td>
              <td valign="top" align="center" rowspan="1" colspan="1">39</td>
              <td valign="top" align="center" rowspan="1" colspan="1">44</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <attrib>
            <italic>We generated 200 data sets for each graph and then permuted the order of the nodes in each data set. We then applied the methods and counted the number of uniquely inferred graphs among the permuted data sets. We then calculated the quantiles of the number of uniquely inferred graphs across the 200 data sets.</italic>
          </attrib>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="S3.SS5">
      <title>Runtime</title>
      <p>Kalisch and Bühlmann established that the computational complexity of the classical PC algorithm is at most polynomial in the number of nodes on sparse DAGs, but is exponential without the sparsity constraint (<xref rid="B10" ref-type="bibr">Kalisch and Bühlmann, 2007</xref>). Since MRPC uses a similar procedure to PC, the computational complexity is similar. The R implementation of MRPC builds on the pc function in the pcalg package, thus we expect that the runtime of MRPC should also be similar to pc. Additionally, whereas MRPC and pcalg are implemented in R, bnlearn implements the core functions in C, which may further reduce the runtime of the functions from bnlearn. Here, we ran each method on 1,000 independent data sets for three graphs and reported the average runtime (<xref rid="T4" ref-type="table">Table 4</xref>). As expected, MRPC and pc have similar runtime, and both of them are slightly slower than the bnlearn methods on small graphs M<sub>1</sub> and M<sub>2</sub>. On the complex graph, all the implementations have comparable runtime, except that pc.stable is slower.</p>
      <table-wrap id="T4" position="float">
        <label>TABLE 4</label>
        <caption>
          <p>Average runtime (in seconds) of each method for three graphs.</p>
        </caption>
        <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
          <thead>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1"/>
              <td valign="top" align="center" rowspan="1" colspan="1">MRPC</td>
              <td valign="top" align="center" rowspan="1" colspan="1">pc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">pc.stable</td>
              <td valign="top" align="center" rowspan="1" colspan="1">mmpc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">hc</td>
              <td valign="top" align="center" rowspan="1" colspan="1">mmhc</td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Model M<sub>1</sub> (<xref ref-type="fig" rid="F1">Figure 1A</xref>)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.007</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.006</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.002</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.002</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.002</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.003</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Model M<sub>2</sub> (<xref ref-type="fig" rid="F1">Figure 1A</xref>)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.006</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.005</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.002</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.003</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.002</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.003</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">The complex graph (<xref ref-type="fig" rid="F3">Figure 3A</xref>)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.048</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.032</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.073</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.047</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.038</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.039</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <attrib>
            <italic>For each graph, 1,000 independent data sets were simulated with a sample size of 500 and signal strength of 0.5.All jobs were run on a Mac computer with a CPU of 2.2 GHz and RAM of 16 GB.</italic>
          </attrib>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="S3.SS6">
      <title>Robustness in the Presence of Outliers</title>
      <p>When the data are suspected to contain outliers, our MRPC package allows for calculation of a robust correlation matrix from the data (<xref rid="B2" ref-type="bibr">Badsha et al., 2013</xref>). Our current implementation of the robust correlation calculation is limited to continuous data for all the columns if there is no genotype information, and for the phenotype columns if there is genotype information. In the robust correlation calculation, each sample in the data matrix is assigned a weight. Outliers tend to receive a weight near 0, thus limiting their contribution to correlation. Both MRPC and pc can take the robust correlation matrix as the input for graph inference, whereas the functions in the bnlearn package do not allow for such input and therefore do not deal with outliers. As our simulation results show, when the data do not contain outliers, all the methods infer the graph mostly accurately (<xref ref-type="fig" rid="F4">Figures 4A,B</xref>). However, when the data contain outliers, each of these methods infers one or more extra edges using Pearson correlation (<xref ref-type="fig" rid="F4">Figure 4C</xref>). Using robust correlation, however, MRPC and pc manage to downweigh the outliers and produce a graph closer to the truth (<xref ref-type="fig" rid="F4">Figure 4D</xref>).</p>
      <fig id="F4" position="float">
        <label>FIGURE 4</label>
        <caption>
          <p>Impact of outliers on graph inference. <bold>(A)</bold> The true graph under which data of sample size 1,000 with and without outliers were simulated. <bold>(B)</bold> Inference by MRPC, pc, pc.stable, mmpc, hc, and mmhc on the simulated data that do not contain outliers, using Pearson correlation as input. <bold>(C)</bold> Inference by the five functions on the simulated data that contain 10 outliers, using Pearson correlation as input. In <bold>(B)</bold> and <bold>(C)</bold> the blacklist argument in pc.stable, mmpc, hc, and mmhc was used to disallow edges pointing to a genetic variant. <bold>(D)</bold> Inference by MRPC and pc on the simulated data with 10 outliers using robust correlation as input.</p>
        </caption>
        <graphic xlink:href="fgene-12-651812-g004"/>
      </fig>
    </sec>
    <sec id="S3.SS7">
      <title>Dealing With Confounding in Causal Inference for Genomic Data</title>
      <p>We provide a few examples of dissecting the regulatory relationships among multiple genes associated with the same genetic variants, accounting for (observed) confounding under the assumption of causal sufficiency [<xref ref-type="fig" rid="F5">Figure 5</xref>; also see <xref rid="B1" ref-type="bibr">Badsha and Fu (2019)</xref>]. The gene expression data are provided by the GEUVADIS (Genetic EUropean VAriation in DISease) consortium (<xref rid="B13" ref-type="bibr">Lappalainen et al., 2013</xref>), which measured the genome wide gene expression levels in lymphoblastoid cell lines (LCLs) in a subset of samples from the 1,000 Genomes Project (<xref rid="B31" ref-type="bibr">The 1000 Genomes Project Consortium, 2015</xref>). The gene expression data have been normalized with the PEER [Probabilistic Estimation of Expression Residuals (<xref rid="B29" ref-type="bibr">Stegle et al., 2012</xref>)] normalization method by the GEUVADIS consortium; this method reduces potential impact from demographic variables and batch effect. We then performed Principal Component Analysis (PCA) on the genomewide gene expression matrix and extracted the top 10 PCs. The genotype data on these 373 Europeans are available through the 1,000 Genomes Project. We identified genes associated with the same expression quantitative trait loci (eQTLs), and for each eQTL-gene set, we used our function IdentifyAssociatedPCs() to identify associated PCs, using the q-value method (<xref rid="B30" ref-type="bibr">Storey and Tibshirani, 2003</xref>) to adjust for multiple testing. We included these PCs (FDR = 5%) as additional variables to the eQTL-gene set when we ran MRPC. The resulting causal graphs show that the PCs can have diverse relationships with the eQTL or the genes (<xref ref-type="fig" rid="F5">Figure 5</xref>). The presence of the PCs did not affect the graph structure in four of the five examples here (<xref ref-type="fig" rid="F5">Figures 5A–D</xref>). In the last example (<xref ref-type="fig" rid="F5">Figure 5E</xref>), the edge between AL355075.3 and PIP4P1 is removed after accounting for the two PCs, although the <italic>p</italic>-value (0.0008) for the test is only a little larger than a rather stringent significance threshold (0.0005) with our online FDR control method.</p>
      <fig id="F5" position="float">
        <label>FIGURE 5</label>
        <caption>
          <p>Examples of the GEUVADIS data analysis accounting for confounding variables. Each of the five sets in (<bold>A</bold>–<bold>E</bold>) contains an eQTL and multiple genes. These genes have been identified by GEUVADIS to be significantly associated with the corresponding eQTL. We derived the principal components (PCs) from the whole-genome gene expression matrix and identified the PCs that are significantly associated with the eQTLs or genes. We applied MRPC to the eQTL-gene set without and with the associated PCs. The PCs can have diverse relationships with the genes.</p>
        </caption>
        <graphic xlink:href="fgene-12-651812-g005"/>
      </fig>
    </sec>
  </sec>
  <sec id="S4">
    <title>Discussion</title>
    <p>Through simulation, we demonstrate that our MRPC method is stable and accurate on relatively small graphs. However, this method still needs much work for large graphs. In our earlier work (<xref rid="B1" ref-type="bibr">Badsha and Fu, 2019</xref>), we examined the performance of MRPC on large networks simulated in the Fifth Dialog on Reverse Engineering Assessment and Methods (DREAM5) Systems Genetics Challenge A. These networks (Net 1) contain 1,000 SNPs and 1,000 genes, each with around 2,000 edges (directed and undirected) and three different sample sizes (100, 300 and 999 individuals). We have improved the implementation of MRPC since then. However, it remains highly conservative in its inference of such large graphs and tends to infer fewer edges than there should be, similar to its performance on the 22-node graph (<xref rid="T2" ref-type="table">Table 2</xref>). On the DREAM5 networks, even at an FDR of 30%, the recall was 0.15 and the precision 0.55 for the sample size of 999, indicating that MRPC tends to retain fewer edges for which the data provide stronger evidence. MRPC performed 2–2.5 million tests on these data sets for Net 1, which took 4.6–7.5 hours on a NVIDIA Titan RTX GPU with 24 GB GPU RAM. The large number of sequential tests remains a challenge for efficiency and accuracy.</p>
  </sec>
  <sec sec-type="data-availability" id="S5">
    <title>Data Availability Statement</title>
    <p>The source code and example data sets are available in the R package MRPC (with license GPL ≥ 2) available in the <xref ref-type="supplementary-material" rid="DS1">Supplementary Material</xref> and in CRAN (<ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/MRPC/index.html">https://cran.r-project.org/web/packages/MRPC/index.html</ext-link>; official releases; standard installation) and on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/audreyqyfu/mrpc">https://github.com/audreyqyfu/mrpc</ext-link>; development; see README.md for instructions on installation).</p>
  </sec>
  <sec id="S6">
    <title>Author Contributions</title>
    <p>MB developed the software. EM and AF provided improvements on the software. AF designed the project and wrote the manuscript with input from MB and EM. All authors read and approved the final manuscript.</p>
  </sec>
  <sec sec-type="COI-statement" id="conf1">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn fn-type="financial-disclosure">
      <p><bold>Funding.</bold> This research was supported by the NIH/NHGRI R00HG007368 (to AF) and NIH/NIGMS P20GM104420 to the Institute for Modeling Collaboration and Innovation at the University of Idaho.</p>
    </fn>
  </fn-group>
  <sec id="S8">
    <title>Software Information</title>
    <p>Project name: <bold>MRPC</bold></p>
    <p>Project home page: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/MRPC/index.html">https://cran.r-project.org/web/packages/MRPC/index.html</ext-link> (official releases); <ext-link ext-link-type="uri" xlink:href="https://github.com/audreyqyfu/mrpc">https://github.com/audreyqyfu/mrpc</ext-link> (development; see README.md for detailed instructions on installation).</p>
    <p>Operating system(s): <bold>Platform independent</bold></p>
    <p>Programming language: <bold>R</bold></p>
    <p>Other requirements: <bold>R 3.6.0 or higher</bold></p>
    <p>License: <bold>GPL (≥2)</bold></p>
    <p>Any restrictions to use by non-academics: <bold>GPL (≥2)</bold>.</p>
  </sec>
  <sec id="S9" sec-type="supplementary material">
    <title>Supplementary Material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fgene.2021.651812/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fgene.2021.651812/full#supplementary-material</ext-link></p>
    <supplementary-material content-type="local-data" id="FS1">
      <label>Supplementary Figure 1</label>
      <caption>
        <p>A sample analysis pipeline using the R package MRPC for simulating and analyzing data.</p>
      </caption>
      <media xlink:href="Image_1.PDF">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="FS2">
      <label>Supplementary Figure 2</label>
      <caption>
        <p>A sample analysis pipeline using the R package MRPC for analyzing real data.</p>
      </caption>
      <media xlink:href="Image_2.PDF">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="DS1">
      <label>Supplementary Data</label>
      <caption>
        <p>R code for data analysis.</p>
      </caption>
      <media xlink:href="Data_Sheet_1.ZIP">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="DS2">
      <media xlink:href="Data_Sheet_2.ZIP">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badsha</surname><given-names>M. B.</given-names></name><name><surname>Fu</surname><given-names>A. Q.</given-names></name></person-group> (<year>2019</year>). <article-title>Learning causal biological networks with generalized Mendelian randomization.</article-title>
<source><italic>Front. Genet.</italic></source>
<volume>10</volume>:<issue>460</issue>. <pub-id pub-id-type="doi">10.3389/fgene.2019.00460</pub-id>
<?supplied-pmid 31164902?><pub-id pub-id-type="pmid">31164902</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badsha</surname><given-names>M. B.</given-names></name><name><surname>Mollah</surname><given-names>M. N.</given-names></name><name><surname>Jahan</surname><given-names>N.</given-names></name><name><surname>Kurata</surname><given-names>H.</given-names></name></person-group> (<year>2013</year>). <article-title>Robust complementary hierarchical clustering for gene expression data analysis by beta-divergence.</article-title>
<source><italic>J. Biosci. Bioeng.</italic></source>
<volume>116</volume>
<fpage>397</fpage>–<lpage>407</lpage>. <pub-id pub-id-type="doi">10.1016/j.jbiosc.2013.03.010</pub-id>
<?supplied-pmid 23608734?><pub-id pub-id-type="pmid">23608734</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colombo</surname><given-names>D.</given-names></name><name><surname>Maathuis</surname><given-names>M. H.</given-names></name></person-group> (<year>2014</year>). <article-title>Order-independent constraint-based causal structure learning.</article-title>
<source><italic>J. Mach. Learn. Res.</italic></source>
<volume>15</volume>
<fpage>3921</fpage>–<lpage>3962</lpage>.</mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dawid</surname><given-names>A. P.</given-names></name></person-group> (<year>2010</year>). <article-title>Beware of the DAG!</article-title>
<source><italic>J. Mach. Learn. Res. Proc.</italic></source>
<volume>6</volume>
<fpage>59</fpage>–<lpage>86</lpage>.</mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Didelez</surname><given-names>V.</given-names></name><name><surname>Sheehan</surname><given-names>N.</given-names></name></person-group> (<year>2007</year>). <article-title>Mendelian randomization as an instrumental variable approach to causal inference.</article-title>
<source><italic>Stat. Methods Med. Res.</italic></source>
<volume>16</volume>
<fpage>309</fpage>–<lpage>330</lpage>. <pub-id pub-id-type="doi">10.1177/0962280206077743</pub-id>
<?supplied-pmid 17715159?><pub-id pub-id-type="pmid">17715159</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guyon</surname><given-names>I.</given-names></name><name><surname>Janzing</surname><given-names>D.</given-names></name><name><surname>Schölkopf</surname><given-names>B.</given-names></name></person-group> (<year>2010</year>). <article-title>Causality: objectives and assessment.</article-title>
<source><italic>JMLR Workshop Conf. Proc.</italic></source>
<volume>6</volume>
<fpage>1</fpage>–<lpage>38</lpage>.</mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hemani</surname><given-names>G.</given-names></name><name><surname>Zheng</surname><given-names>J.</given-names></name><name><surname>Elsworth</surname><given-names>B.</given-names></name><name><surname>Wade</surname><given-names>K. H.</given-names></name><name><surname>Haberland</surname><given-names>V.</given-names></name><name><surname>Baird</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>The MR-Base platform supports systematic causal inference across the human phenome.</article-title>
<source><italic>Elife</italic></source>
<volume>7</volume>:<issue>e34408</issue>.</mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howey</surname><given-names>R.</given-names></name><name><surname>Shin</surname><given-names>S. Y.</given-names></name><name><surname>Relton</surname><given-names>C.</given-names></name><name><surname>Smith</surname><given-names>G. D.</given-names></name><name><surname>Cordell</surname><given-names>H. J.</given-names></name></person-group> (<year>2020</year>). <article-title>Bayesian network analysis incorporating genetic anchors complements conventional Mendelian randomization approaches for exploratory analysis of causal relationships in complex data.</article-title>
<source><italic>PLoS Genet.</italic></source>
<volume>16</volume>:<issue>e1008198</issue>. <pub-id pub-id-type="doi">10.1371/journal.pgen.1008198</pub-id>
<?supplied-pmid 32119656?><pub-id pub-id-type="pmid">32119656</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Javanmard</surname><given-names>A.</given-names></name><name><surname>Montanari</surname><given-names>A.</given-names></name></person-group> (<year>2018</year>). <article-title>Online rules for control of false discovery rate and false discovery exceedance.</article-title>
<source><italic>Ann. Stat.</italic></source>
<volume>46</volume>
<fpage>526</fpage>–<lpage>554</lpage>.</mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalisch</surname><given-names>M.</given-names></name><name><surname>Bühlmann</surname><given-names>P.</given-names></name></person-group> (<year>2007</year>). <article-title>Estimating high-dimensional directed acyclic graphs with the PC-algorithm.</article-title>
<source><italic>J. Mach. Learn. Res.</italic></source>
<volume>8</volume>
<fpage>613</fpage>–<lpage>636</lpage>.</mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalisch</surname><given-names>M.</given-names></name><name><surname>Mächler</surname><given-names>M.</given-names></name><name><surname>Colombo</surname><given-names>D.</given-names></name><name><surname>Maathuis</surname><given-names>M. H.</given-names></name><name><surname>Bühlmann</surname><given-names>P.</given-names></name></person-group> (<year>2012</year>). <article-title>Causal inference using graphical models with the R package pcalg.</article-title>
<source><italic>J. Stat. Softw.</italic></source>
<volume>47</volume>
<fpage>1</fpage>–<lpage>26</lpage>.</mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Koller</surname><given-names>D.</given-names></name><name><surname>Friedman</surname><given-names>N.</given-names></name></person-group> (<year>2009</year>). <source><italic>Probabilistic Graphical Models: Principles and Techniques.</italic></source>
<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lappalainen</surname><given-names>T.</given-names></name><name><surname>Sammeth</surname><given-names>M.</given-names></name><name><surname>Friedländer</surname><given-names>M. R.</given-names></name><name><surname>t Hoen</surname><given-names>P. A.</given-names></name><name><surname>Monlong</surname><given-names>J.</given-names></name><name><surname>Rivas</surname><given-names>M. A.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Transcriptome and genome sequencing uncovers functional variation in humans.</article-title>
<source><italic>Nature</italic></source>
<volume>501</volume>
<fpage>506</fpage>–<lpage>511</lpage>.<pub-id pub-id-type="pmid">24037378</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lauritzen</surname><given-names>S. L.</given-names></name></person-group> (<year>1996</year>). <source><italic>Graphical Models.</italic></source>
<publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lawlor</surname><given-names>D. A.</given-names></name><name><surname>Harbord</surname><given-names>R. M.</given-names></name><name><surname>Sterne</surname><given-names>J. A. C.</given-names></name><name><surname>Timpson</surname><given-names>N.</given-names></name><name><surname>Smith</surname><given-names>G. D.</given-names></name></person-group> (<year>2008</year>). <article-title>Mendelian randomization: using genes as instruments for making causal inferences in epidemiology.</article-title>
<source><italic>Stat. Med.</italic></source>
<volume>27</volume>
<fpage>1133</fpage>–<lpage>1163</lpage>. <pub-id pub-id-type="doi">10.1002/sim.3034</pub-id>
<?supplied-pmid 17886233?><pub-id pub-id-type="pmid">17886233</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Millstein</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>G. K.</given-names></name><name><surname>Breton</surname><given-names>C. V.</given-names></name></person-group> (<year>2016</year>). <article-title>cit: hypothesis testing software for mediation analysis in genomic applications.</article-title>
<source><italic>Bioinformatics</italic></source>
<volume>32</volume>
<fpage>2364</fpage>–<lpage>2365</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btw135</pub-id>
<?supplied-pmid 27153715?><pub-id pub-id-type="pmid">27153715</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Millstein</surname><given-names>J.</given-names></name><name><surname>Zhang</surname><given-names>B.</given-names></name><name><surname>Zhu</surname><given-names>J.</given-names></name><name><surname>Schadt</surname><given-names>E. E.</given-names></name></person-group> (<year>2009</year>). <article-title>Disentangling molecular relationships with a causal inference test.</article-title>
<source><italic>BMC Genet.</italic></source>
<volume>10</volume>:<issue>23</issue>. <pub-id pub-id-type="doi">10.1186/1471-2156-10-23</pub-id>
<?supplied-pmid 19473544?><pub-id pub-id-type="pmid">19473544</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mooij</surname><given-names>J. M.</given-names></name><name><surname>Peters</surname><given-names>J.</given-names></name><name><surname>Janzing</surname><given-names>D.</given-names></name><name><surname>Zscheischler</surname><given-names>J.</given-names></name><name><surname>Schölkopf</surname><given-names>B.</given-names></name></person-group> (<year>2016</year>). <article-title>Distinguishing cause from effect using observational data: methods and benchmarks.</article-title>
<source><italic>J. Mach. Learn. Res.</italic></source>
<volume>17</volume>
<fpage>1</fpage>–<lpage>102</lpage>. <pub-id pub-id-type="doi">10.1145/3309720</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nowzohour</surname><given-names>C.</given-names></name><name><surname>Bühlmann</surname><given-names>P.</given-names></name></person-group> (<year>2016</year>). <article-title>Score-based causal learning in additive noise models.</article-title>
<source><italic>Statistics</italic></source>
<volume>50</volume>
<fpage>471</fpage>–<lpage>485</lpage>. <pub-id pub-id-type="doi">10.1080/02331888.2015.1060237</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pearl</surname><given-names>J.</given-names></name></person-group> (<year>2009</year>). <source><italic>Causality.</italic></source>
<publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peters</surname><given-names>J.</given-names></name><name><surname>Janzing</surname><given-names>D.</given-names></name><name><surname>Schölkopf</surname><given-names>B.</given-names></name></person-group> (<year>2011</year>). <article-title>Causal inference on discrete data using additive noise models.</article-title>
<source><italic>IEEE Trans. Pattern Anal. Mach. Intell.</italic></source>
<volume>33</volume>
<fpage>2436</fpage>–<lpage>2450</lpage>. <pub-id pub-id-type="doi">10.1109/tpami.2011.71</pub-id>
<?supplied-pmid 21464504?><pub-id pub-id-type="pmid">21464504</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Peters</surname><given-names>J.</given-names></name><name><surname>Janzing</surname><given-names>D.</given-names></name><name><surname>Schölkopf</surname><given-names>B.</given-names></name></person-group> (<year>2017</year>). <source><italic>Elements of Causal Inference: Foundations and Learning Algorithms.</italic></source>
<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ramsey</surname><given-names>J. D.</given-names></name><name><surname>Zhang</surname><given-names>K.</given-names></name><name><surname>Glymour</surname><given-names>M.</given-names></name><name><surname>Romero</surname><given-names>R. S.</given-names></name><name><surname>Huang</surname><given-names>B.</given-names></name><name><surname>Ebert-Uphoff</surname><given-names>I.</given-names></name><etal/></person-group> (<year>2018</year>). “<article-title>TETRAD—A toolbox for causal discovery</article-title>,” in <source><italic>8th International Workshop on Climate Informatics</italic></source>, <publisher-loc>Boulder, CO</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richardson</surname><given-names>T.</given-names></name></person-group> (<year>1997</year>). <article-title>A characterization of Markov equivalence for directed cyclic graphs.</article-title>
<source><italic>Int. J. Approx. Reason.</italic></source>
<volume>17</volume>
<fpage>107</fpage>–<lpage>162</lpage>. <pub-id pub-id-type="doi">10.1016/s0888-613x(97)00020-0</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scutari</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>). <article-title>Learning Bayesian networks with the bnlearn R package.</article-title>
<source><italic>J. Stat. Softw.</italic></source>
<volume>35</volume>:<issue>22</issue>.</mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>G. D.</given-names></name><name><surname>Ebrahim</surname><given-names>S.</given-names></name></person-group> (<year>2003</year>). <article-title>‘Mendelian randomization’: can genetic epidemiology contribute to understanding environmental determinants of disease?</article-title>
<source><italic>Int. J. Epidemiol.</italic></source>
<volume>32</volume>
<fpage>1</fpage>–<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1093/ije/dyg070</pub-id>
<?supplied-pmid 12689998?><pub-id pub-id-type="pmid">12689998</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>G. D.</given-names></name><name><surname>Hemani</surname><given-names>G.</given-names></name></person-group> (<year>2014</year>). <article-title>Mendelian randomization: genetic anchors for causal inference in epidemiological studies.</article-title>
<source><italic>Hum. Mol. Genet.</italic></source>
<volume>23</volume>
<fpage>89</fpage>–<lpage>98</lpage>. <pub-id pub-id-type="doi">10.1201/b18084-10</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Spirtes</surname><given-names>P.</given-names></name><name><surname>Glymour</surname><given-names>C.</given-names></name><name><surname>Scheines</surname><given-names>R.</given-names></name></person-group> (<year>2000</year>). <source><italic>Causation, Prediction, and Search.</italic></source>
<publisher-loc>London</publisher-loc>: <publisher-name>The MIT Press</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stegle</surname><given-names>O.</given-names></name><name><surname>Parts</surname><given-names>L.</given-names></name><name><surname>Piipari</surname><given-names>M.</given-names></name><name><surname>Winn</surname><given-names>J.</given-names></name><name><surname>Durbin</surname><given-names>R.</given-names></name></person-group> (<year>2012</year>). <article-title>Using probabilistic estimation of expression residuals (PEER) to obtain increased power and interpretability of gene expression analyses.</article-title>
<source><italic>Nat. Protoc.</italic></source>
<volume>7</volume>
<fpage>500</fpage>–<lpage>507</lpage>. <pub-id pub-id-type="doi">10.1038/nprot.2011.457</pub-id>
<?supplied-pmid 22343431?><pub-id pub-id-type="pmid">22343431</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Storey</surname><given-names>J. D.</given-names></name><name><surname>Tibshirani</surname><given-names>R.</given-names></name></person-group> (<year>2003</year>). <article-title>Statistical significance for genomewide studies.</article-title>
<source><italic>Proc. Natl. Acad. Sci.U.S.A.</italic></source>
<volume>100</volume>
<fpage>9440</fpage>–<lpage>9445</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1530509100</pub-id>
<?supplied-pmid 12883005?><pub-id pub-id-type="pmid">12883005</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><collab>The 1000 Genomes Project Consortium</collab> (<year>2015</year>). <article-title>A global reference for human genetic variation.</article-title>
<source><italic>Nature</italic></source>
<volume>526</volume>
<fpage>68</fpage>–<lpage>74</lpage>. <pub-id pub-id-type="doi">10.1038/nature15393</pub-id>
<?supplied-pmid 26432245?><pub-id pub-id-type="pmid">26432245</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tsamardinos</surname><given-names>I.</given-names></name><name><surname>Aliferis</surname><given-names>C. F.</given-names></name><name><surname>Statnikov</surname><given-names>A.</given-names></name></person-group> (<year>2003</year>). “<article-title>Time and sample efficient discovery of Markov blankets and direct causal relations</article-title>,” in <source><italic>Proceedings of the 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</italic></source>, <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>ACM Press</publisher-name>, <fpage>673</fpage>–<lpage>678</lpage>.</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsamardinos</surname><given-names>I.</given-names></name><name><surname>Brown</surname><given-names>L. E.</given-names></name><name><surname>Aliferis</surname><given-names>C. F.</given-names></name></person-group> (<year>2006</year>). <article-title>The max-min hill-climbing Bayesian network structure learning algorithm.</article-title>
<source><italic>Mach. Learn.</italic></source>
<volume>65</volume>
<fpage>31</fpage>–<lpage>78</lpage>. <pub-id pub-id-type="doi">10.1007/s10994-006-6889-7</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verbanck</surname><given-names>M.</given-names></name><name><surname>Chen</surname><given-names>C. Y.</given-names></name><name><surname>Neale</surname><given-names>B.</given-names></name><name><surname>Do</surname><given-names>R.</given-names></name></person-group> (<year>2018</year>). <article-title>Detection of widespread horizontal pleiotropy in causal relationships inferred from Mendelian randomization between complex traits and diseases.</article-title>
<source><italic>Nat. Genet.</italic></source>
<volume>50</volume>
<fpage>693</fpage>–<lpage>698</lpage>. <pub-id pub-id-type="doi">10.1038/s41588-018-0099-7</pub-id>
<?supplied-pmid 29686387?><pub-id pub-id-type="pmid">29686387</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L.</given-names></name><name><surname>Michoel</surname><given-names>T.</given-names></name></person-group> (<year>2017</year>). <article-title>Efficient and accurate causal inference with hidden confounders from genome-transcriptome variation data.</article-title>
<source><italic>PLoS Comput. Biol.</italic></source>
<volume>13</volume>:<issue>e1005703</issue>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005703</pub-id>
<?supplied-pmid 28821014?><pub-id pub-id-type="pmid">28821014</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>F.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name></person-group><collab>The GTEx Consortium</collab>, <person-group person-group-type="author"><name><surname>Pierce</surname><given-names>B. L.</given-names></name><name><surname>Chen</surname><given-names>L. S.</given-names></name></person-group> (<year>2017</year>). <article-title>Identifying cis-mediators for trans-eQTLs across many human tissues using genomic mediation analysis.</article-title>
<source><italic>Genome Res.</italic></source>
<volume>27</volume>
<fpage>1859</fpage>–<lpage>1871</lpage>. <pub-id pub-id-type="doi">10.1101/gr.216754.116</pub-id>
<?supplied-pmid 29021290?><pub-id pub-id-type="pmid">29021290</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>J.</given-names></name><name><surname>Ming</surname><given-names>J.</given-names></name><name><surname>Hu</surname><given-names>X.</given-names></name><name><surname>Chen</surname><given-names>G.</given-names></name><name><surname>Liu</surname><given-names>J.</given-names></name><name><surname>Yang</surname><given-names>C.</given-names></name></person-group> (<year>2020</year>). <article-title>Bayesian weighted Mendelian randomization for causal inference based on summary statistics.</article-title>
<source><italic>Bioinformatics</italic></source>
<volume>36</volume>
<fpage>1501</fpage>–<lpage>1508</lpage>.<pub-id pub-id-type="pmid">31593215</pub-id></mixed-citation>
    </ref>
  </ref-list>
  <glossary>
    <title>Abbreviations</title>
    <def-list id="DL1">
      <def-item>
        <term>aSHD</term>
        <def>
          <p>Adjusted Structural Hamming Distance</p>
        </def>
      </def-item>
      <def-item>
        <term>bnlearn</term>
        <def>
          <p>Bayesian Network learn</p>
        </def>
      </def-item>
      <def-item>
        <term>CPDAG</term>
        <def>
          <p>Completed Partially Directed Acyclic Graph</p>
        </def>
      </def-item>
      <def-item>
        <term>DAG</term>
        <def>
          <p>Directed Acyclic Graph</p>
        </def>
      </def-item>
      <def-item>
        <term>DREAM5</term>
        <def>
          <p>Fifth Dialog on Reverse Engineering Assessment and Methods</p>
        </def>
      </def-item>
      <def-item>
        <term>eQTL</term>
        <def>
          <p>expression Quantitative Trait Locus</p>
        </def>
      </def-item>
      <def-item>
        <term>FCI</term>
        <def>
          <p>Fast Causal Inference</p>
        </def>
      </def-item>
      <def-item>
        <term>FDR</term>
        <def>
          <p>False discovery rate</p>
        </def>
      </def-item>
      <def-item>
        <term>RFCI</term>
        <def>
          <p>Really FCI</p>
        </def>
      </def-item>
      <def-item>
        <term>GEUVADIS</term>
        <def>
          <p>Genetic EUropean VAriation in DISease</p>
        </def>
      </def-item>
      <def-item>
        <term>GMAC</term>
        <def>
          <p>genomic mediation analysis with adaptive confounding adjustment</p>
        </def>
      </def-item>
      <def-item>
        <term>mmpc</term>
        <def>
          <p>Max-Min Parents and Children</p>
        </def>
      </def-item>
      <def-item>
        <term>mmhc</term>
        <def>
          <p>Max-Min Hill Climbing</p>
        </def>
      </def-item>
      <def-item>
        <term>MPDAG</term>
        <def>
          <p>Maximally oriented Partial DAG</p>
        </def>
      </def-item>
      <def-item>
        <term>MRPC</term>
        <def>
          <p>a PC algorithm with the principle of Mendelian Randomization</p>
        </def>
      </def-item>
      <def-item>
        <term>The PC algorithm</term>
        <def>
          <p>the Peter-Clark algorithm</p>
        </def>
      </def-item>
      <def-item>
        <term>pc</term>
        <def>
          <p>the implementation of the PC algorithm in the pcalg package</p>
        </def>
      </def-item>
      <def-item>
        <term>PCA</term>
        <def>
          <p>Principal component analysis</p>
        </def>
      </def-item>
      <def-item>
        <term>PCs</term>
        <def>
          <p>Principal Components</p>
        </def>
      </def-item>
      <def-item>
        <term>PEER</term>
        <def>
          <p>Probabilistic estimation of expression residuals</p>
        </def>
      </def-item>
      <def-item>
        <term>PMR</term>
        <def>
          <p>the principle of Mendelian randomization</p>
        </def>
      </def-item>
      <def-item>
        <term>SD</term>
        <def>
          <p>standard deviation</p>
        </def>
      </def-item>
      <def-item>
        <term>SHD</term>
        <def>
          <p>Structural Hamming Distance</p>
        </def>
      </def-item>
      <def-item>
        <term>SNP</term>
        <def>
          <p>Single nucleotide polymorphism</p>
        </def>
      </def-item>
      <def-item>
        <term>TETRAD</term>
        <def>
          <p>A TOOLBOX FOR CAUSAL DISCOVERY</p>
        </def>
      </def-item>
      <def-item>
        <term>TP</term>
        <def>
          <p>true positive</p>
        </def>
      </def-item>
      <def-item>
        <term>WGCNA</term>
        <def>
          <p>Weighted correlation network analysis for genes.</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
</back>
