<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Cheminform</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Cheminform</journal-id>
    <journal-title-group>
      <journal-title>Journal of Cheminformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-2946</issn>
    <publisher>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10797927</article-id>
    <article-id pub-id-type="pmid">38238779</article-id>
    <article-id pub-id-type="publisher-id">804</article-id>
    <article-id pub-id-type="doi">10.1186/s13321-024-00804-5</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>IDSL_MINT: a deep learning framework to predict molecular fingerprints from mass spectra</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Baygi</surname>
          <given-names>Sadjad Fakouri</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Barupal</surname>
          <given-names>Dinesh Kumar</given-names>
        </name>
        <address>
          <email>dinesh.barupal@mssm.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04a9tmd77</institution-id><institution-id institution-id-type="GRID">grid.59734.3c</institution-id><institution-id institution-id-type="ISNI">0000 0001 0670 2351</institution-id><institution>Department of Environmental Medicine and Public Health, </institution><institution>Icahn School of Medicine at Mount Sinai, </institution></institution-wrap>CAM Building, 3rd Floor, 17 E 102 St, New York, NY 10029 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>18</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2024</year>
    </pub-date>
    <volume>16</volume>
    <elocation-id>8</elocation-id>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>1</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Abstract</title>
        <p id="Par1">The majority of tandem mass spectrometry (MS/MS) spectra in untargeted metabolomics and exposomics studies lack any annotation. Our deep learning framework, Integrated Data Science Laboratory for Metabolomics and Exposomics—<bold>M</bold>ass <bold>INT</bold>erpreter (IDSL_MINT) can translate MS/MS spectra into molecular fingerprint descriptors. IDSL_MINT allows users to leverage the power of the transformer model for mass spectrometry data, similar to the large language models. Models are trained on user-provided reference MS/MS libraries via any customizable molecular fingerprint descriptors. IDSL_MINT was benchmarked using the LipidMaps database and improved the annotation rate of a test study for MS/MS spectra that were not originally annotated using existing mass spectral libraries. IDSL_MINT may improve the overall annotation rates in untargeted metabolomics and exposomics studies. The IDSL_MINT framework and tutorials are available in the GitHub repository at <ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link>.</p>
      </sec>
      <sec>
        <title>Scientific contribution</title>
        <p id="Par3">Structural annotation of MS/MS spectra from untargeted metabolomics and exposomics datasets is a major bottleneck in gaining new biological insights. Machine learning models to convert spectra into molecular fingerprints can help in the annotation process. Here, we present IDSL_MINT, a new, easy-to-use and customizable deep-learning framework to train and utilize new models to predict molecular fingerprints from spectra for the compound annotation workflows.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s13321-024-00804-5.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Mass spectrometry</kwd>
      <kwd>Metabolomics</kwd>
      <kwd>Lipidomics</kwd>
      <kwd>LipidMaps</kwd>
      <kwd>Transformer</kwd>
      <kwd>Molecular fingerprint descriptor</kwd>
      <kwd>Deep learning</kwd>
      <kwd>PyTorch</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006108</institution-id>
            <institution>National Center for Advancing Translational Sciences</institution>
          </institution-wrap>
        </funding-source>
        <award-id>UL1TR004419</award-id>
        <award-id>UL1TR004419</award-id>
        <principal-award-recipient>
          <name>
            <surname>Baygi</surname>
            <given-names>Sadjad Fakouri</given-names>
          </name>
          <name>
            <surname>Barupal</surname>
            <given-names>Dinesh Kumar</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000066</institution-id>
            <institution>National Institute of Environmental Health Sciences</institution>
          </institution-wrap>
        </funding-source>
        <award-id>P30ES023515</award-id>
        <award-id>U2CES026561</award-id>
        <principal-award-recipient>
          <name>
            <surname>Baygi</surname>
            <given-names>Sadjad Fakouri</given-names>
          </name>
          <name>
            <surname>Barupal</surname>
            <given-names>Dinesh Kumar</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100009633</institution-id>
            <institution>Eunice Kennedy Shriver National Institute of Child Health and Human Development</institution>
          </institution-wrap>
        </funding-source>
        <award-id>T32HD049311</award-id>
        <principal-award-recipient>
          <name>
            <surname>Baygi</surname>
            <given-names>Sadjad Fakouri</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© Springer Nature Switzerland AG 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par4">Metabolomics and exposomics fields deal with large volume datasets on the detection and measurement of expected and novel chemical compounds in biological samples [<xref ref-type="bibr" rid="CR1">1</xref>]. These datasets are mostly generated using untargeted assays employing a gas or liquid chromatography connected to a high-resolution mass spectrometry (HRMS). These instruments can be instructed to fragment chemical compounds in the biospecimens, and the mass to charge ratio and the intensity of those fragments can be recorded in a tandem MS/MS spectrum. In a typical study (n = 100), 2000–3000 unique MS/MS spectra can be collected. These spectra need to be annotated with chemical information such as structure, sub-structure or molecular formula in order to interpret their biological relevance. However, lack of annotations for a majority of the collected MS/MS spectra remains to be a major challenge.</p>
    <p id="Par5">Traditionally, mass spectral libraries available from commercial providers such as NIST or Wiley, in-house, and public resources such as MoNA or GNPS are utilized to annotate the experimental MS/MS spectra with a chemical structure. While this approach is straightforward to use due to the availability of thoroughly benchmarked software such as MS-DIAL, NIST MS Search, Compound Discoverer,and Mass Hunter, a large proportion (&gt; 80%) of MS/MS spectra do not have any hit in these libraries [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>].</p>
    <p id="Par6">Machine learning (ML) models can boost the annotation rates. ML models that are trained using curated MS/MS spectra can predict the structure directly from a MS/MS spectrum without the need for searching against mass spectral libraries. For example, CSI:FingerID [<xref ref-type="bibr" rid="CR4">4</xref>] can predict molecular fingerprint, Spec2Vec [<xref ref-type="bibr" rid="CR5">5</xref>] can create spectral embeddings, Mass2SMILES [<xref ref-type="bibr" rid="CR6">6</xref>] can predict SMILES strings, and MSNovelist [<xref ref-type="bibr" rid="CR7">7</xref>] can predict new structures for a MS/MS spectra. Recently, the large-language models (LLMs) created using the transformer deep learning approach have shown to outperform classical machine learning approaches for the language related tasks such as translation or generating new text. The transformer model uses encoder-decoder structure to map a sequence of tokens from one domain into a different domain, for example translating sentences in English to German. Converting a MS/MS spectrum to molecular descriptor is in a way, a language translation problem, in which token A (m/z and intensity) are translated into token B (descriptors). This idea of token translation has been explored by Spec2Vec [<xref ref-type="bibr" rid="CR5">5</xref>] to create intermediate embedding, which can be used to search mass spectral or chemical structure libraries (MS2DeepScore [<xref ref-type="bibr" rid="CR8">8</xref>] and MS2Query [<xref ref-type="bibr" rid="CR9">9</xref>]). Other individual models such as MS2Mol [<xref ref-type="bibr" rid="CR10">10</xref>], MS2Prop [<xref ref-type="bibr" rid="CR11">11</xref>], Mass2SMILES [<xref ref-type="bibr" rid="CR6">6</xref>] and MSNovelist [<xref ref-type="bibr" rid="CR7">7</xref>] use the transformer or Long Short-Term Memory (LSTM) architecture to predict chemical descriptors, two-dimensional structure or SMILES notations.</p>
    <p id="Par7">There are two ways to use deep learning in computational mass spectrometry. First to use these individual models. But they have been trained on different training datasets and these models may not be available for a local deployment. They may also not have included specific chemical classes that a user might be interested in. The second approach is to provide an easy-to-use deep learning framework in which a user can train their own models using the MS/MS data that they may have generated for in-house standards or they have access to. For routine chem-informatics tasks, Chemprop [<xref ref-type="bibr" rid="CR12">12</xref>] is a key example of this second approach to democratize the deep learning methods so anyone who has access to training data and computing power can train different models by optimizing hyperparameters for customized training sets. For example, using Chemprop as a backbone, deep neural network model to predict antibacterial activity properties of &gt; 107 million molecules from the ZINC15 database have led to the discovery of new candidate compounds with antibiotic properties [<xref ref-type="bibr" rid="CR13">13</xref>]. Similarly, Chemprop [<xref ref-type="bibr" rid="CR12">12</xref>] has been used in several other contexts to predict pharmacokinetics [<xref ref-type="bibr" rid="CR14">14</xref>] and molecular properties [<xref ref-type="bibr" rid="CR15">15</xref>], making it a central resource for mapping chemical-to-function relationships.</p>
    <p id="Par8">Inspired by Chemprop [<xref ref-type="bibr" rid="CR16">16</xref>], to democratize the deep learning in computational mass spectrometry, we have developed IDSL_MINT (<ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link>), a deep learning mass spectrometry framework, designed to create data-centric models for mass spectrometry applications using transformer models developed by Vaswani et al<italic>.</italic> [<xref ref-type="bibr" rid="CR17">17</xref>]. IDSL_MINT encompasses modules designed to predict molecular fingerprint descriptors (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). We expect that the IDSL_MINT framework will be used to train a diversity of models to predict molecular descriptors from MS/MS spectra.<fig id="Fig1"><label>Fig. 1</label><caption><p>Schematic of MS2Fingerprint model</p></caption><graphic xlink:href="13321_2024_804_Fig1_HTML" id="MO1"/></fig></p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>Modeling framework</title>
      <p id="Par9">IDSL_MINT was developed upon the transformer model architecture originally proposed by Vaswani et al<italic>.</italic> [<xref ref-type="bibr" rid="CR17">17</xref>] and is implemented within the python PyTorch framework (<ext-link ext-link-type="uri" xlink:href="https://pytorch.org">https://pytorch.org</ext-link>). The IDSL_MINT transformer model architecture for predicting molecular fingerprint is displayed in Figs. <xref rid="Fig1" ref-type="fig">1</xref>. IDSL_MINT only takes MS/MS spectra accompanied with precursor <italic>m/z</italic> values in the<italic>.msp</italic> text format. First, <italic>m/z</italic> fragments are tokenized using constant <italic>m/z</italic> interval steps, and intensity values are sorted by the maximum intensity after normalization to the unit sum of the total intensities. Similarly, precursor <italic>m/z</italic> values are tokenized and coupled with spectral entropy values [<xref ref-type="bibr" rid="CR18">18</xref>] as their pseudo-intensity values when spectral entropy is allowed in the MSP deconvolution step; otherwise, pseudo-intensity values of '2' are utilized. Tokenized precursor <italic>m/z</italic> and its pseudo-intensity are concatenated to the tokenized vectors of <italic>m/z</italic> fragments and fragment intensity values, respectively to create tokenized <italic>m/z</italic> and intensity tensors. Next, tokenized <italic>m/z</italic> tensors are embedded into the transformer model dimension. We hypothesized the intensity of ions in a mass spectrum indicates the abundance of the ions and consequently the importance of the related sub-structure. Therefore, we used a sinusoidal positional encoding similar to Vaswani et al<italic>.</italic> [<xref ref-type="bibr" rid="CR17">17</xref>] to account for the effects of intensity on the tokenized embedded <italic>m/z</italic> tokens, as presented in Eqs. (<xref rid="Equ1" ref-type="disp-formula">1</xref>) and (<xref rid="Equ2" ref-type="disp-formula">2</xref>).<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P{E}_{(pos, 2i)}=sin \left(int.\frac{pos}{{10000}^{\frac{2i}{{d}_{model}}}}\right)$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mn>10000</mml:mn></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:msup></mml:mfrac></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="13321_2024_804_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P{E}_{(pos, 2i+1)}=cos \left(int.\frac{pos}{{10000}^{\frac{2i+1}{{d}_{model}}}}\right)$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mfenced close=")" open="("><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mn>10000</mml:mn></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:msup></mml:mfrac></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="13321_2024_804_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where, <italic>PE</italic>, <italic>pos</italic>, <italic>int</italic>, and <italic>d</italic><sub><italic>model</italic></sub> represent positional encoding tensor, intensity rank order, intensity and model dimension, respectively. The intensity-weighted positional encoding tensor is summed up with the embedded m/z tokens followed by a dropout layer to control potential overfittings. This positional encoding method enabled the utilization of both the precursor <italic>m/z</italic> as molecular mass [<xref ref-type="bibr" rid="CR11">11</xref>] and the fragment ions. The embedded <italic>m/z</italic> space is converted into the encoder structure of the transformer model. In case, customized binary fingerprint bit locations are not provided within the MSP blocks for training, IDSL_MINT can generate molecular fingerprint descriptors using SMILES or InChI strings for extended connectivity fingerprint (ECFP) using an adjustable radius [<xref ref-type="bibr" rid="CR19">19</xref>] or MACCS Keys [<xref ref-type="bibr" rid="CR20">20</xref>] fingerprint types which are widely recognized in the field of cheminformatics [<xref ref-type="bibr" rid="CR21">21</xref>]. The fingerprint bit locations are submitted to the transformer decoder in an ascending order, but no positional adjustment was used on fingerprint bit locations. The output of the decoder structure of the transformer was fed into a linear layer followed by a SoftMax layer to calculate the probability of the fingerprint bit locations (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). The cross-entropy LOSS function is used with adjustable label smoothing followed by an Adam optimizer. A beam search inference is used to ensure detection of the most probable neural network trajectory and to prevent autoregressive shortcuts in transformers. Tanimoto coefficient is calculated to find similarity between predicted and the true positive fingerprints in the accuracy plots.</p>
    </sec>
    <sec id="Sec4">
      <title>Model training setup</title>
      <p id="Par10">IDSL_MINT code is publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link><underline>.</underline> IDSL_MINT was developed using Python 3.10 and implemented with PyTorch 2.0. IDSL_MINT can be executed via a simple and easy to modify YAML configuration files using a simple command “<italic>MINT_workflow –yaml path/to/yaml/file</italic>” in a Linux terminal. Typically, users should specify the criteria for MS/MS spectra input, molecular fingerprint type, transformer model settings, parameters for the cross-entropy LOSS function, and configurations for the Adam optimization strategy. The framework works only in the Linux environment. The model weights are exported at the directory outlined in the configuration file <italic>(.yaml</italic>), for the minimal LOSS value achieved during the training phase. To ensure model reproducibility, we suggest preserving training YAML files as configuration log entries to utilize consistent model parameters in the predictive stage.</p>
    </sec>
    <sec id="Sec5">
      <title>Spectral file for the test model training</title>
      <p id="Par11">IDSL.CSA [<xref ref-type="bibr" rid="CR2">2</xref>] provided fragmentation spectra databases (FSDBs) for publicly available spectral databases (<ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/7530397">https://zenodo.org/record/7530397</ext-link>) in positive and negative modes [<xref ref-type="bibr" rid="CR2">2</xref>]. A subset of LipidMaps spectra from these FSDBs originated from MassBank of North America (MoNA) and Global Natural Product Social Molecular Networking (GNPS) libraries was converted into standard<italic>.msp</italic> files after excluding in-<italic>silico</italic> predicted MSP blocks using LipidBlast method [<xref ref-type="bibr" rid="CR23">23</xref>]. Classes of lipids were derived from LipidMaps database [<xref ref-type="bibr" rid="CR24">24</xref>] via matching corresponding InChIKey14 values.</p>
    </sec>
    <sec id="Sec6">
      <title>Test data set</title>
      <p id="Par12">To benchmark the IDSL_MINT framework, we have used a publicly available untargeted metabolomics study from the Metabolomics WorkBench (accession: ST002044) [<xref ref-type="bibr" rid="CR25">25</xref>]. IDSL.IPA [<xref ref-type="bibr" rid="CR26">26</xref>] was used for peak-picking and peak alignment followed by MS/MS peak detection using IDSL.CSA [<xref ref-type="bibr" rid="CR2">2</xref>]. Unique spectra across the entire study were collected in separate MS/MS spectra files in the<italic>.msp</italic> text format for electrospray ionization (ESI) positive and negative modes.<italic>.msp</italic> text files and parameter spreadsheet used to annotate the unique spectra are provided at ( <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/records/8339614">https://zenodo.org/records/8339614</ext-link>) [<xref ref-type="bibr" rid="CR27">27</xref>] (file#<underline>CSA_spreadsheet.zip</underline>) for positive and negative modes.</p>
    </sec>
    <sec id="Sec7">
      <title>Model parameters for the test study</title>
      <p id="Par13">In the training step for the test study, only MS/MS spectra were used that had 90% of <italic>m/z</italic> fragments within a range of 50–1000 using 0.01 Da intervals. The extended connectivity fingerprint with a radius of 2 (ECFP2) was utilized to transform MS/MS mass spectrometry data. The MS2Fingerprint models include 4 hidden encoder and decoder layers and 2 attention heads (80 × 10<sup>6</sup> parameters including parameters of the embedding layer). A Google Colab notebook showing the training and prediction parameters are provided at <ext-link ext-link-type="uri" xlink:href="https://drive.google.com/file/d/1IFWTeeZ_I4tbQ-y6MEvSkQ0hb6vqited/view?usp=sharing">https://drive.google.com/file/d/1IFWTeeZ_I4tbQ-y6MEvSkQ0hb6vqited/view?usp=sharing</ext-link><underline>.</underline> Model training curves are shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S1.</p>
    </sec>
  </sec>
  <sec id="Sec8">
    <title>Results</title>
    <p id="Par14">We have developed IDSL_MINT, a cheminformatics deep learning framework, to predict molecular fingerprint descriptors from MS/MS fragmentation spectra. The framework enabled easy and straightforward training of predictive models from different mass spectral libraries, in a similar fashion to the widely accepted Chemprop approach [<xref ref-type="bibr" rid="CR16">16</xref>] which can create different models for predicting physical–chemical properties from chemical structures. The framework utilizes a transformer architecture [<xref ref-type="bibr" rid="CR17">17</xref>] in PyTorch to translate <italic>m/z</italic> values into a fingerprint bit vector. The required input for training the model is only a reference spectra library in the NIST standard<italic>.msp</italic> text format with or without fingerprint data and a model configuration text file (<italic>.yaml</italic>). Figure <xref rid="Fig2" ref-type="fig">2</xref> illustrates the overview of the input and output data in the framework.<fig id="Fig2"><label>Fig. 2</label><caption><p>Flowchart of the IDSL_MINT workflow</p></caption><graphic xlink:href="13321_2024_804_Fig2_HTML" id="MO2"/></fig></p>
    <p id="Par15">As an alternative to interact with complex python scripts, we have provided well documented <italic>yaml</italic> configuration files for selecting model parameters. Similar to Chemprop [<xref ref-type="bibr" rid="CR16">16</xref>], IDSL_MINT is directly run in a Linux terminal using a simple command (See method). We provided a Google Colaboratory notebook (<ext-link ext-link-type="uri" xlink:href="https://colab.research.google.com/drive/16A-Hw6S_04nxlopp7yefZkVB5Aakcodu">https://colab.research.google.com/drive/16A-Hw6S_04nxlopp7yefZkVB5Aakcodu</ext-link>) to demonstrate the application of the IDSL_MINT framework without any local installation. Users can train a new model on these notebooks using the test data or they can use their own input data for creating customized models. GPUs and CPUs are both supported by IDSL_MINT. The codebase and the documentation are provided at <ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link> to install IDSL_MINT in a local Linux server.</p>
    <p id="Par16">We showcase the application of IDSL_MINT for a publicly available untargeted metabolomics study (ST002044) from the Metabolomics WorkBench database. First, we processed the raw data for this study to extract MS/MS spectra in the NIST.msp format that can be used as the model evaluation set. The IDSL.CSA R package [<xref ref-type="bibr" rid="CR2">2</xref>] was used to extract 3,386 and 1,901 unique MS/MS spectra in ESI<sup>+</sup> and ESI<sup>−</sup> for this study [<xref ref-type="bibr" rid="CR27">27</xref>] (file#1 csa_spreadsheet.zip). Next, we obtained the coverage of spectra annotation by mass spectral similarity searches. IDSL.CSA can annotate 638 (out of 3386) and 299 (out of 1901) MS/MS peaks in positive and negative modes by matching the spectra against NIST 20 and LipidBlast [<xref ref-type="bibr" rid="CR23">23</xref>] libraries [<xref ref-type="bibr" rid="CR27">27</xref>] (file#1 csa_spreadsheet.zip).</p>
    <p id="Par17">Next, we carefully compiled the training dataset for the case study (ST002044) to ensure a high validity of the resulting model (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). Spectra from MoNA and GNPS public libraries in positive and negative modes were used separately to create training sets. We excluded the spectra related to compounds that were covered in the LipidBlast (in-<italic>silico</italic>) [<xref ref-type="bibr" rid="CR23">23</xref>] and NIST 20 libraries because we used these two libraries for annotating the experimental MS/MS spectra in the case study. Our case study training set included 6.96% and 4.58% of all the compounds in the LipidMaps database in positive and negative modes, respectively because most of the lipid compounds did not have publicly available MS/MS spectra. Lipid classification ontology was not covered in the MS/MS databases, so we obtained it from the LipidMaps structure SDF file in the PubChem database. Training data has 8 lipid classes and 6 classes having at least 50 spectra (Table <xref rid="Tab1" ref-type="table">1</xref>). The most over-represented lipid classes were Polyketides (PK) and Fatty Acyls (FA) and under-represented classes were Glycerolipids (GL) and Saccharolipids (SL). Extracted MS/MS LipidMaps spectra in MoNA and GNPS public libraries, and lipid classes from PubChem database were provided in the<italic>.msp</italic> text format at Zenodo entry [<xref ref-type="bibr" rid="CR27">27</xref>] (file#2 <underline>lipidmaps_msp.zip/</underline>). Despite the small size training set, we were able to train a useful model with practical prediction accuracies for an untargeted metabolomics experiment, as highlighted in the following sections.<fig id="Fig3"><label>Fig. 3</label><caption><p>Careful compilation of the training set for the case study. Unique InChIKey14 was used to compute set overlaps. Source data file is provided at Zenodo entry [<xref ref-type="bibr" rid="CR27">27</xref>] (file#3 venn.zip)</p></caption><graphic xlink:href="13321_2024_804_Fig3_HTML" id="MO3"/></fig><table-wrap id="Tab1"><label>Table 1</label><caption><p>Frequency of lipid in each class in the training data set</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Lipid class</th><th align="left">Negative</th><th align="left">Positive</th></tr></thead><tbody><tr><td align="left">Polyketides (PK)</td><td align="left">794</td><td align="left">1019</td></tr><tr><td align="left">Fatty Acyls (FA)</td><td align="left">791</td><td align="left">1294</td></tr><tr><td align="left">Glycerophospholipids (GP)</td><td align="left">339</td><td align="left">202</td></tr><tr><td align="left">Sterol Lipids (ST)</td><td align="left">289</td><td align="left">516</td></tr><tr><td align="left">Prenol Lipids (PR)</td><td align="left">141</td><td align="left">438</td></tr><tr><td align="left">Sphingolipids (SP)</td><td align="left">80</td><td align="left">54</td></tr><tr><td align="left">Glycerolipids (GL)</td><td align="left">5</td><td align="left">64</td></tr><tr><td align="left">Saccharolipids (SL)</td><td align="left">2</td><td align="left">1</td></tr></tbody></table></table-wrap></p>
    <p id="Par18">Next, we trained two deep learning models (ESI<sup>+</sup> and ESI<sup>−</sup>) using our newly created IDSL.MINT framework. The<italic>.yaml</italic> file and input<italic>.msp</italic> files are provided at Zenodo entry [<xref ref-type="bibr" rid="CR27">27</xref>](file#4 ms2fp_yaml.zip). The training in ESI<sup>+</sup> and ESI<sup>−</sup> took 70 and 45 h, respectively on 35 CPU processing threads.</p>
    <p id="Par19">Next, we evaluated the overall accuracy and the accuracy by lipid classes for the test study ST002044. Since not all lipid classes were equally represented in the training set, we expected that the model prediction accuracy would vary across the classes. Overall accuracy for the case study was 0.354 and 0.351 for positive and negative modes, respectively, where true positive being the top hit candidate when the predicted fingerprint was searched against the LipidMaps database. In terms of lipids classes, Glycerophospholipids (GP) showed an accuracy ≥ 0.50 whereas Prenol Lipids (PR) showed a really low accuracy ≤ 0.20 in both positive and negative modes (Table <xref rid="Tab2" ref-type="table">2</xref> and file#5 ms2fp_st002044_prediction.zip at [<xref ref-type="bibr" rid="CR27">27</xref>]). These variations can be attributed to the coverage of these lipid classes in the training dataset. For the case study, IDSL.CSA yielded annotations for 536 lipid compounds for both ESI modes (Table <xref rid="Tab2" ref-type="table">2</xref>). Subsequent matching of the predicted fingerprints using a Tanimoto similarity threshold of ≥ 0.6 resulted with additional 238 lipid annotations in both ESI modes. Furthermore, a spectral entropy score of ≥ 0.75 was found to align with fingerprint matches characterized by a Tanimoto similarity threshold of ≥ 0.7 shown in Table <xref rid="Tab2" ref-type="table">2</xref>. Notably, within the Glycerophospholipids (GP) lipid class, the median Tanimoto similarity stands a score of 1 across 178 annotations with a spectral entropy score of ≥ 0.75 in positive mode. We noted that 71 (ESI<sup>+</sup>) and 96 (ESI<sup>−</sup>) annotations were not part of the training set, suggesting the use of IDSL_MINT for improving annotations beyond mass spectral libraries. The results of all annotated MS/MS spectra in ST002044 by fingerprint matches with Tanimoto similarity ≥ 0.5 against LipidMaps and IDSL.CSA match is provided at Zenodo entry [<xref ref-type="bibr" rid="CR27">27</xref>](file#6 ms2fp_lipidmaps.zip and file#7 ms2fp_idsl.csa.zip).<table-wrap id="Tab2"><label>Table 2</label><caption><p>Tanimoto coefficients of ECFP2 fingerprints for the ST002044 study. Fingerprint matching assisted in adding more annotations</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Mode</th><th align="left" rowspan="2">Lipid categories</th><th align="left" colspan="3">LipidMaps (Entire top hits)</th><th align="left" colspan="3">Library match after spectral entropy ≥ 0.75)</th><th align="left" colspan="3">IDSL_MINT new high-confidence annotations (Tanimoto similarity ≥ 0.6)</th></tr><tr><th align="left">Count</th><th align="left">Mean</th><th align="left">Median</th><th align="left">Count</th><th align="left">Mean</th><th align="left">Median</th><th align="left">Count</th><th align="left">Mean</th><th align="left">Median</th></tr></thead><tbody><tr><td align="left" rowspan="7">Positive mode</td><td align="left">Fatty Acyls (FA)</td><td align="left">592</td><td char="." align="char">0.254 ± 0.270</td><td char="." align="char">0.140</td><td align="left">80</td><td char="." align="char">0.672 ± 0.330</td><td char="." align="char">0.772</td><td align="left">24</td><td char="." align="char">0.831 ± 0.121</td><td char="." align="char">0.857</td></tr><tr><td align="left">Prenol Lipids (PR)</td><td align="left">182</td><td char="." align="char">0.181 ± 0.158</td><td char="." align="char">0.138</td><td align="left">4</td><td char="." align="char">0.736 ± 0.008</td><td char="." align="char">0.731</td><td align="left">3</td><td char="." align="char">1.000 ± 0.000</td><td char="." align="char">1.000</td></tr><tr><td align="left">Polyketides (PK)</td><td align="left">233</td><td char="." align="char">0.205 ± 0.122</td><td char="." align="char">0.181</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">3</td><td char="." align="char">0.881 ± 0.068</td><td char="." align="char">0.836</td></tr><tr><td align="left">Sphingolipids (SP)</td><td align="left">56</td><td char="." align="char">0.326 ± 0.282</td><td char="." align="char">0.192</td><td align="left">16</td><td char="." align="char">0.571 ± 0.381</td><td char="." align="char">0.798</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Glycerophospholipids (GP)</td><td align="left">724</td><td char="." align="char">0.543 ± 0.350</td><td char="." align="char">0.540</td><td align="left">178</td><td char="." align="char">0.916 ± 0.154</td><td char="." align="char">1.000</td><td align="left">85</td><td char="." align="char">0.838 ± 0.111</td><td char="." align="char">0.839</td></tr><tr><td align="left">Glycerolipids (GL)</td><td align="left">60</td><td char="." align="char">0.561 ± 0.368</td><td char="." align="char">0.556</td><td align="left">35</td><td char="." align="char">0.772 ± 0.262</td><td char="." align="char">0.875</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Sterol Lipids (ST)</td><td align="left">295</td><td char="." align="char">0.302 ± 0.272</td><td char="." align="char">0.168</td><td align="left">65</td><td char="." align="char">0.669 ± 0.232</td><td char="." align="char">0.673</td><td align="left">12</td><td char="." align="char">0.805 ± 0.119</td><td char="." align="char">0.756</td></tr><tr><td align="left" rowspan="7">Negative mode</td><td align="left">Fatty Acyls (FA)</td><td align="left">437</td><td char="." align="char">0.233 ± 0.198</td><td char="." align="char">0.175</td><td align="left">8</td><td char="." align="char">0.556 ± 0.301</td><td char="." align="char">0.533</td><td align="left">22</td><td char="." align="char">0.782 ± 0.106</td><td char="." align="char">0.757</td></tr><tr><td align="left">Prenol Lipids (PR)</td><td align="left">65</td><td char="." align="char">0.139 ± 0.029</td><td char="." align="char">0.145</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Polyketides (PK)</td><td align="left">175</td><td char="." align="char">0.183 ± 0.118</td><td char="." align="char">0.166</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">3</td><td char="." align="char">0.783 ± 0.155</td><td char="." align="char">0.701</td></tr><tr><td align="left">Sphingolipids (SP)</td><td align="left">0</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Glycerophospholipids (GP)</td><td align="left">371</td><td char="." align="char">0.671 ± 0.247</td><td char="." align="char">0.704</td><td align="left">150</td><td char="." align="char">0.739 ± 0.182</td><td char="." align="char">0.714</td><td align="left">85</td><td char="." align="char">0.837 ± 0.140</td><td char="." align="char">0.849</td></tr><tr><td align="left">Glycerolipids (GL)</td><td align="left">11</td><td char="." align="char">0.335 ± 0.046</td><td char="." align="char">0.339</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Sterol Lipids (ST)</td><td align="left">121</td><td char="." align="char">0.165 ± 0.096</td><td char="." align="char">0.144</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">1</td><td char="." align="char">0.887 ± 0.000</td><td char="." align="char">0.886</td></tr></tbody></table></table-wrap></p>
  </sec>
  <sec id="Sec9">
    <title>Discussions</title>
    <p id="Par20">We have developed a deep learning framework for computational mass spectrometry in metabolomics and exposomics to train user-defined models to predict structure and molecular fingerprints from tandem mass (MS/MS) spectra. An application of this framework is presented to annotate MS/MS spectra that did not have any hits in the existing reference mass spectral libraries. It can be suggested that a combined use of both mass spectral library searches and deep learning models can improve the annotation rate in lipidomics, metabolomics and exposomics fields. As we highlighted that our work is inspired by Chemprop [<xref ref-type="bibr" rid="CR12">12</xref>], to democratize deep learning in computational mass spectrometry, in which users can train custom models by different training datasets. An example is shown as a lipid structure prediction model trained only on the lipid MS/MS spectra because a lipid extraction method was used using the sample preparation. This framework also enables open science where deep learning models created using publicly available MS/MS spectra can be made available without any restrictions.</p>
    <p id="Par21">Transformer models have revolutionized the field of natural language processing (NLP), particularly in transforming between two spaces of sequences of tokens similar to natural language structures [<xref ref-type="bibr" rid="CR17">17</xref>]. The transformer model consists of encoder and decoder structures which include self-attention mechanisms, feed-forward neural networks, and normalization layers. The ability to tokenize raw mass spectrometry data (<italic>m/z</italic> values) and molecular fingerprint bit locations allow for the adoption of this well-developed model architecture in the field of computational mass spectrometry.</p>
    <p id="Par22">The key objective in using deep learning models for mass spectrometry data processing is to transform mass spectrometry <italic>m/z</italic> values into a more applicable information space such as molecular fingerprint descriptors [<xref ref-type="bibr" rid="CR28">28</xref>]. This conversion enables utilizing MS/MS spectra in several known cheminformatics approaches such as Quantitative Structure–Activity Relationship (QSAR) modeling. The predicted fingerprints can prioritize the annotated peaks for further structure elucidation workflows which are resource-demanding in mass spectrometry-based projects. Only a limited number of high-quality mass spectral signatures should be prioritized for further in-<italic>silico</italic> analyses and laboratory experiments. QSAR models built by molecular fingerprint descriptors can be utilized to directly predict physical–chemical properties without fully knowing the two-dimensional structure. This was achieved by MS2Prop tool to predict quantitative assessment of drug-likeness (QED) [<xref ref-type="bibr" rid="CR29">29</xref>], and synthetic accessibility [<xref ref-type="bibr" rid="CR30">30</xref>].</p>
    <p id="Par23">One of the key messages of our work is that the accuracy of these deep learning models varies by chemical classes. That can be explained by limited training data for them. If a class is not well-represented in the training set of an existing model, then we need to acquire the standards, collect the MS/MS spectra for them and train a new model. This situation is regularly observed by the untargeted metabolomics and exposomics community. It is also recognized in the cheminformatics field that not every class has training data [<xref ref-type="bibr" rid="CR31">31</xref>–<xref ref-type="bibr" rid="CR33">33</xref>], an issue known as the domain of applicability [<xref ref-type="bibr" rid="CR34">34</xref>]. IDSL_MINT will enable straight-forward training of such new models, in a similar way Chemprop [<xref ref-type="bibr" rid="CR16">16</xref>] supports the QASR modeling. Users should note that a model might perform well for one class, and thus can be used reliably for that specific class, for example the case study works for lipid classes Glycerophospholipids (GP). We have shown for the case study, the 238 additional spectra could be annotated by this new approach; however, the reliable annotations were for the classes with higher accuracies. Our results underscore the need to expand the training data for these under-represented classes in the public libraries such as MoNA and GNPS databases.</p>
    <p id="Par24">Putting together the training and prediction architecture requires setting up complex python scripts, but IDSL_MINT has minimized these efforts to almost no scripting by accepting all the parameters in well-documented configuration files in a simple text format (<italic>.yaml</italic>). This idea of using a<italic>.yaml</italic> file was also adopted from the Chemprop framework [<xref ref-type="bibr" rid="CR16">16</xref>], and it makes it very straightforward to train a deep learning model for MS/MS spectra. We also use the input spectra in<italic>.msp</italic> text format which is a commonly used format in computational mass spectrometry, meaning that IDSL_MINT can be easily integrated with other workflows which handle mass spectra in this format. For example, by using only IDSL.CSA [<xref ref-type="bibr" rid="CR2">2</xref>] and IDSL_MINT, a user can extract and annotate MS/MS spectra by mass spectral similarity and the deep learning based predictive modeling.</p>
    <p id="Par25">Since there are many molecular fingerprints available in cheminformatics and new ones can be created for a collection of chemical structures, IDSL_MINT supports any type of user-provided fingerprint as long as it is in the binary vector format. This is different from existing tools SIRIUS 4 [<xref ref-type="bibr" rid="CR35">35</xref>] and CSI:FingerID [<xref ref-type="bibr" rid="CR4">4</xref>] which use a set of fixed molecular fingerprints. However, it should be noted that searching the predicted fingerprints against massive databases such as PubChem may require re-calculations of the custom fingerprints.</p>
    <p id="Par26">The main limitation of this work was that our training set was constrained to only the experimental LipidMaps library which was around &lt; 10% of total LipidMaps compounds. However, we have achieved practical accuracies for a number of lipid classes. The transformer architecture can be expanded to include neutral losses from precursor and <italic>m/z</italic> differences, which may also improve the accuracy of the model. Several advanced formats of the transformer architecture have been developed to train large language models by NLP researchers. Those advances can be tested while translating <italic>m/z</italic> tokens into molecular fingerprints tokens.</p>
    <p id="Par27">The presented IDSL_MINT test model also has several limitations. First, the results of this model could not be compared against that of existing fingerprint prediction models such as CSI:FingerID [<xref ref-type="bibr" rid="CR4">4</xref>]. Second, the model was created for a lipidomics dataset, so it cannot be generalized to other metabolomics datasets. Lastly, we did not test different molecular fingerprint types while building the model. However, it should be noted that the test model was created only to show the utility of the IDSL_MINT framework, and follow-up investigations are required to increase the impact in reference to these limitations. We also recommend that training datasets used as input for the IDSL_MINT framework are submitted to a public data repository such as Zenodo ( <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/">https://zenodo.org/</ext-link>) with a proper version control and data provenance records so the results by different modelling frameworks or models can be logically compared.”</p>
  </sec>
  <sec sec-type="supplementary-material">
    <sec id="Sec10">
      <title>Supplementary Information</title>
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="13321_2024_804_MOESM1_ESM.docx">
            <caption>
              <p><bold>Additional file 1: Figure S1.</bold> Training curves for the lipid annotation model</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>Conceptualization and methodology, Data curation, Investigation, Software, Formal analyses, Visualization, Resources, Writing-original draft, Writing-review and editing (DKB and SFB).</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>The work was in part supported by T32HD049311, K12ES033594, U2CES026561, R35ES030435, U2CES026555, P30ES023515, U2CES030859, UL1TR004419, U24ES035386, R01ES032831 and R01ES033688.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>Project name: IDSL_MINT, Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link><underline>.</underline> Operating system(s): Linux. Programming language: Python. Other requirements: None. License: MIT. Any restrictions to use by non-academics: None. Data and results are available at <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/8339614">https://zenodo.org/record/8339614</ext-link></p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par28">DKB has been a consultant for Brightseed Bio Inc, South San Francisco.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schrimpe-Rutledge</surname>
            <given-names>AC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Untargeted metabolomics strategies-challenges and emerging directions</article-title>
        <source>J Am Soc Mass Spectrom</source>
        <year>2016</year>
        <volume>27</volume>
        <issue>12</issue>
        <fpage>1897</fpage>
        <lpage>1905</lpage>
        <pub-id pub-id-type="doi">10.1007/s13361-016-1469-y</pub-id>
        <?supplied-pmid 27624161?>
        <pub-id pub-id-type="pmid">27624161</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baygi</surname>
            <given-names>SF</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Barupal</surname>
            <given-names>DK</given-names>
          </name>
        </person-group>
        <article-title>IDSL.CSA: composite spectra analysis for chemical annotation of untargeted metabolomics datasets</article-title>
        <source>Anal Chem</source>
        <year>2023</year>
        <volume>95</volume>
        <issue>25</issue>
        <fpage>9480</fpage>
        <lpage>9487</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.3c00376</pub-id>
        <?supplied-pmid 37311059?>
        <pub-id pub-id-type="pmid">37311059</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Domingo-Almenara</surname>
            <given-names>X</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Annotation: a computational solution for streamlining metabolomics analysis</article-title>
        <source>Anal Chem</source>
        <year>2018</year>
        <volume>90</volume>
        <issue>1</issue>
        <fpage>480</fpage>
        <lpage>489</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.7b03929</pub-id>
        <?supplied-pmid 29039932?>
        <pub-id pub-id-type="pmid">29039932</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Duhrkop</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Searching molecular structure databases with tandem mass spectra using CSI:FingerID</article-title>
        <source>Proc Natl Acad Sci U S A</source>
        <year>2015</year>
        <volume>112</volume>
        <issue>41</issue>
        <fpage>12580</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1509788112</pub-id>
        <?supplied-pmid 26392543?>
        <pub-id pub-id-type="pmid">26392543</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huber</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Spec2Vec: Improved mass spectral similarity scoring through learning of structural relationships</article-title>
        <source>PLoS Comput Biol</source>
        <year>2021</year>
        <volume>17</volume>
        <issue>2</issue>
        <fpage>e1008724</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1008724</pub-id>
        <?supplied-pmid 33591968?>
        <pub-id pub-id-type="pmid">33591968</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">Elser, D., F. Huber, and E. Gaquerel, <italic>Mass2SMILES: deep learning based fast prediction of structures and functional groups directly from high-resolution MS/MS spectra.</italic> bioRxiv, 2023: p. 2023.07. 06.547963</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stravs</surname>
            <given-names>MA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MSNovelist: de novo structure generation from mass spectra</article-title>
        <source>Nat Methods</source>
        <year>2022</year>
        <volume>19</volume>
        <issue>7</issue>
        <fpage>865</fpage>
        <lpage>870</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-022-01486-3</pub-id>
        <?supplied-pmid 35637304?>
        <pub-id pub-id-type="pmid">35637304</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huber</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MS2DeepScore: a novel deep learning similarity measure to compare tandem mass spectra</article-title>
        <source>J Cheminform</source>
        <year>2021</year>
        <volume>13</volume>
        <issue>1</issue>
        <fpage>84</fpage>
        <pub-id pub-id-type="doi">10.1186/s13321-021-00558-4</pub-id>
        <?supplied-pmid 34715914?>
        <pub-id pub-id-type="pmid">34715914</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Jonge</surname>
            <given-names>NF</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MS2Query: reliable and scalable MS(2) mass spectra-based analogue search</article-title>
        <source>Nature Communication</source>
        <year>2023</year>
        <volume>14</volume>
        <issue>1</issue>
        <fpage>1752</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-023-37446-4</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">Butler, T., et al., <italic>MS2Mol: A transformer model for illuminating dark chemical space from mass spectra.</italic> 2023</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Voronov, G., et al., <italic>MS2Prop: A machine learning model that directly predicts chemical properties from mass spectrometry data for novel compounds.</italic> bioRxiv, 2022: p. 2022.10. 09.511482</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Analyzing learned molecular representations for property prediction</article-title>
        <source>J Chem Inf Model</source>
        <year>2019</year>
        <volume>59</volume>
        <issue>8</issue>
        <fpage>3370</fpage>
        <lpage>3388</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.9b00237</pub-id>
        <?supplied-pmid 31361484?>
        <pub-id pub-id-type="pmid">31361484</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stokes</surname>
            <given-names>JM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A deep learning approach to antibiotic discovery</article-title>
        <source>Cell</source>
        <year>2020</year>
        <volume>180</volume>
        <issue>4</issue>
        <fpage>688</fpage>
        <lpage>702</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2020.01.021</pub-id>
        <?supplied-pmid 32084340?>
        <pub-id pub-id-type="pmid">32084340</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stoyanova</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Computational predictions of nonclinical pharmacokinetics at the drug design stage</article-title>
        <source>J Chem Inf Model</source>
        <year>2023</year>
        <volume>63</volume>
        <issue>2</issue>
        <fpage>442</fpage>
        <lpage>458</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.2c01134</pub-id>
        <?supplied-pmid 36595708?>
        <pub-id pub-id-type="pmid">36595708</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>ABT-MPNN: an atom-bond transformer-based message-passing neural network for molecular property prediction</article-title>
        <source>J Cheminform</source>
        <year>2023</year>
        <volume>15</volume>
        <issue>1</issue>
        <fpage>29</fpage>
        <pub-id pub-id-type="doi">10.1186/s13321-023-00698-9</pub-id>
        <?supplied-pmid 36843022?>
        <pub-id pub-id-type="pmid">36843022</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Heid, E., et al., <italic>Chemprop: A Machine Learning Package for Chemical Property Prediction.</italic> 2023</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vaswani</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Attention is all you need</article-title>
        <source>Advances in Neural Information Processing Systems</source>
        <year>2017</year>
        <volume>30</volume>
        <fpage>1</fpage>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Spectral entropy outperforms MS/MS dot product similarity for small-molecule compound identification</article-title>
        <source>Nat Methods</source>
        <year>2021</year>
        <volume>18</volume>
        <issue>12</issue>
        <fpage>1524</fpage>
        <lpage>1531</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-021-01331-z</pub-id>
        <?supplied-pmid 34857935?>
        <pub-id pub-id-type="pmid">34857935</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rogers</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hahn</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Extended-connectivity fingerprints</article-title>
        <source>J Chem Inf Model</source>
        <year>2010</year>
        <volume>50</volume>
        <issue>5</issue>
        <fpage>742</fpage>
        <lpage>754</lpage>
        <pub-id pub-id-type="doi">10.1021/ci100050t</pub-id>
        <?supplied-pmid 20426451?>
        <pub-id pub-id-type="pmid">20426451</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yongye</surname>
            <given-names>AB</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Consensus models of activity landscapes with multiple chemical, conformer, and property representations</article-title>
        <source>J Chem Inf Model</source>
        <year>2011</year>
        <volume>51</volume>
        <issue>6</issue>
        <fpage>1259</fpage>
        <lpage>1270</lpage>
        <pub-id pub-id-type="doi">10.1021/ci200081k</pub-id>
        <?supplied-pmid 21609014?>
        <pub-id pub-id-type="pmid">21609014</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xie</surname>
            <given-names>L</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Improvement of prediction performance with conjoint molecular fingerprint in deep learning</article-title>
        <source>Front Pharmacol</source>
        <year>2020</year>
        <volume>11</volume>
        <fpage>606668</fpage>
        <pub-id pub-id-type="doi">10.3389/fphar.2020.606668</pub-id>
        <?supplied-pmid 33488387?>
        <pub-id pub-id-type="pmid">33488387</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schwaller</surname>
            <given-names>P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Mapping the space of chemical reactions using attention-based neural networks</article-title>
        <source>Nat Mach Intell</source>
        <year>2021</year>
        <volume>3</volume>
        <issue>2</issue>
        <fpage>144</fpage>
        <lpage>152</lpage>
        <pub-id pub-id-type="doi">10.1038/s42256-020-00284-w</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kind</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>LipidBlast templates as flexible tools for creating new in-silico tandem mass spectral libraries</article-title>
        <source>Anal Chem</source>
        <year>2014</year>
        <volume>86</volume>
        <issue>22</issue>
        <fpage>11024</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="doi">10.1021/ac502511a</pub-id>
        <?supplied-pmid 25340521?>
        <pub-id pub-id-type="pmid">25340521</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fahy</surname>
            <given-names>E</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>LIPID MAPS online tools for lipid research</article-title>
        <source>Nucleic Acids Res</source>
        <year>2007</year>
        <volume>35</volume>
        <fpage>W606</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkm324</pub-id>
        <?supplied-pmid 17584797?>
        <pub-id pub-id-type="pmid">17584797</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baygi</surname>
            <given-names>SF</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>IDSLUFA Assigns high-confidence molecular formula annotations for untargeted LC/HRMS data sets in metabolomics and exposomics</article-title>
        <source>Anal Chem</source>
        <year>2022</year>
        <volume>94</volume>
        <issue>39</issue>
        <fpage>13315</fpage>
        <lpage>13322</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.2c00563</pub-id>
        <?supplied-pmid 36137231?>
        <pub-id pub-id-type="pmid">36137231</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fakouri-Baygi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Barupal</surname>
            <given-names>DK</given-names>
          </name>
        </person-group>
        <article-title>IDSL.IPA characterizes the organic chemical space in untargeted LC/HRMS data sets</article-title>
        <source>J Proteome Res</source>
        <year>2022</year>
        <volume>21</volume>
        <issue>6</issue>
        <fpage>1485</fpage>
        <lpage>1494</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jproteome.2c00120</pub-id>
        <?supplied-pmid 35579321?>
        <pub-id pub-id-type="pmid">35579321</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Barupal, S.F.B.D.K., <italic>Data and results for the IDSL.MINT publication</italic>, in <italic>Zenodo</italic>. 2023.</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ji</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Predicting a molecular fingerprint from an electron ionization mass spectrum with deep neural networks</article-title>
        <source>Anal Chem</source>
        <year>2020</year>
        <volume>92</volume>
        <issue>13</issue>
        <fpage>8649</fpage>
        <lpage>8653</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.0c01450</pub-id>
        <?supplied-pmid 32584545?>
        <pub-id pub-id-type="pmid">32584545</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bickerton</surname>
            <given-names>GR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Quantifying the chemical beauty of drugs</article-title>
        <source>Nat Chem</source>
        <year>2012</year>
        <volume>4</volume>
        <issue>2</issue>
        <fpage>90</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1038/nchem.1243</pub-id>
        <?supplied-pmid 22270643?>
        <pub-id pub-id-type="pmid">22270643</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ertl</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Schuffenhauer</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions</article-title>
        <source>J Cheminform</source>
        <year>2009</year>
        <volume>1</volume>
        <issue>1</issue>
        <fpage>8</fpage>
        <pub-id pub-id-type="doi">10.1186/1758-2946-1-8</pub-id>
        <?supplied-pmid 20298526?>
        <pub-id pub-id-type="pmid">20298526</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lo</surname>
            <given-names>Y-C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Machine learning in chemoinformatics and drug discovery</article-title>
        <source>Drug Discovery Today</source>
        <year>2018</year>
        <volume>23</volume>
        <issue>8</issue>
        <fpage>1538</fpage>
        <lpage>1546</lpage>
        <pub-id pub-id-type="doi">10.1016/j.drudis.2018.05.010</pub-id>
        <?supplied-pmid 29750902?>
        <pub-id pub-id-type="pmid">29750902</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MetaRF: attention-based random forest for reaction yield prediction with a few trails</article-title>
        <source>J Cheminform</source>
        <year>2023</year>
        <volume>15</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1186/s13321-023-00715-x</pub-id>
        <pub-id pub-id-type="pmid">36593523</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Colby</surname>
            <given-names>SM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>ISiCLE: a quantum chemistry pipeline for establishing in silico collision cross section libraries</article-title>
        <source>Anal Chem</source>
        <year>2019</year>
        <volume>91</volume>
        <issue>7</issue>
        <fpage>4346</fpage>
        <lpage>4356</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.8b04567</pub-id>
        <?supplied-pmid 30741529?>
        <pub-id pub-id-type="pmid">30741529</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sutton</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Identifying domains of applicability of machine learning models for materials science</article-title>
        <source>Nat Commun</source>
        <year>2020</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>4428</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-020-17112-9</pub-id>
        <?supplied-pmid 32887879?>
        <pub-id pub-id-type="pmid">32887879</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Duhrkop</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>SIRIUS 4: a rapid tool for turning tandem mass spectra into metabolite structure information</article-title>
        <source>Nat Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <issue>4</issue>
        <fpage>299</fpage>
        <lpage>302</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-019-0344-8</pub-id>
        <?supplied-pmid 30886413?>
        <pub-id pub-id-type="pmid">30886413</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Cheminform</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Cheminform</journal-id>
    <journal-title-group>
      <journal-title>Journal of Cheminformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-2946</issn>
    <publisher>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10797927</article-id>
    <article-id pub-id-type="pmid">38238779</article-id>
    <article-id pub-id-type="publisher-id">804</article-id>
    <article-id pub-id-type="doi">10.1186/s13321-024-00804-5</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>IDSL_MINT: a deep learning framework to predict molecular fingerprints from mass spectra</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Baygi</surname>
          <given-names>Sadjad Fakouri</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Barupal</surname>
          <given-names>Dinesh Kumar</given-names>
        </name>
        <address>
          <email>dinesh.barupal@mssm.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04a9tmd77</institution-id><institution-id institution-id-type="GRID">grid.59734.3c</institution-id><institution-id institution-id-type="ISNI">0000 0001 0670 2351</institution-id><institution>Department of Environmental Medicine and Public Health, </institution><institution>Icahn School of Medicine at Mount Sinai, </institution></institution-wrap>CAM Building, 3rd Floor, 17 E 102 St, New York, NY 10029 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>18</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2024</year>
    </pub-date>
    <volume>16</volume>
    <elocation-id>8</elocation-id>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>1</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Abstract</title>
        <p id="Par1">The majority of tandem mass spectrometry (MS/MS) spectra in untargeted metabolomics and exposomics studies lack any annotation. Our deep learning framework, Integrated Data Science Laboratory for Metabolomics and Exposomics—<bold>M</bold>ass <bold>INT</bold>erpreter (IDSL_MINT) can translate MS/MS spectra into molecular fingerprint descriptors. IDSL_MINT allows users to leverage the power of the transformer model for mass spectrometry data, similar to the large language models. Models are trained on user-provided reference MS/MS libraries via any customizable molecular fingerprint descriptors. IDSL_MINT was benchmarked using the LipidMaps database and improved the annotation rate of a test study for MS/MS spectra that were not originally annotated using existing mass spectral libraries. IDSL_MINT may improve the overall annotation rates in untargeted metabolomics and exposomics studies. The IDSL_MINT framework and tutorials are available in the GitHub repository at <ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link>.</p>
      </sec>
      <sec>
        <title>Scientific contribution</title>
        <p id="Par3">Structural annotation of MS/MS spectra from untargeted metabolomics and exposomics datasets is a major bottleneck in gaining new biological insights. Machine learning models to convert spectra into molecular fingerprints can help in the annotation process. Here, we present IDSL_MINT, a new, easy-to-use and customizable deep-learning framework to train and utilize new models to predict molecular fingerprints from spectra for the compound annotation workflows.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s13321-024-00804-5.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Mass spectrometry</kwd>
      <kwd>Metabolomics</kwd>
      <kwd>Lipidomics</kwd>
      <kwd>LipidMaps</kwd>
      <kwd>Transformer</kwd>
      <kwd>Molecular fingerprint descriptor</kwd>
      <kwd>Deep learning</kwd>
      <kwd>PyTorch</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006108</institution-id>
            <institution>National Center for Advancing Translational Sciences</institution>
          </institution-wrap>
        </funding-source>
        <award-id>UL1TR004419</award-id>
        <award-id>UL1TR004419</award-id>
        <principal-award-recipient>
          <name>
            <surname>Baygi</surname>
            <given-names>Sadjad Fakouri</given-names>
          </name>
          <name>
            <surname>Barupal</surname>
            <given-names>Dinesh Kumar</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000066</institution-id>
            <institution>National Institute of Environmental Health Sciences</institution>
          </institution-wrap>
        </funding-source>
        <award-id>P30ES023515</award-id>
        <award-id>U2CES026561</award-id>
        <principal-award-recipient>
          <name>
            <surname>Baygi</surname>
            <given-names>Sadjad Fakouri</given-names>
          </name>
          <name>
            <surname>Barupal</surname>
            <given-names>Dinesh Kumar</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100009633</institution-id>
            <institution>Eunice Kennedy Shriver National Institute of Child Health and Human Development</institution>
          </institution-wrap>
        </funding-source>
        <award-id>T32HD049311</award-id>
        <principal-award-recipient>
          <name>
            <surname>Baygi</surname>
            <given-names>Sadjad Fakouri</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© Springer Nature Switzerland AG 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par4">Metabolomics and exposomics fields deal with large volume datasets on the detection and measurement of expected and novel chemical compounds in biological samples [<xref ref-type="bibr" rid="CR1">1</xref>]. These datasets are mostly generated using untargeted assays employing a gas or liquid chromatography connected to a high-resolution mass spectrometry (HRMS). These instruments can be instructed to fragment chemical compounds in the biospecimens, and the mass to charge ratio and the intensity of those fragments can be recorded in a tandem MS/MS spectrum. In a typical study (n = 100), 2000–3000 unique MS/MS spectra can be collected. These spectra need to be annotated with chemical information such as structure, sub-structure or molecular formula in order to interpret their biological relevance. However, lack of annotations for a majority of the collected MS/MS spectra remains to be a major challenge.</p>
    <p id="Par5">Traditionally, mass spectral libraries available from commercial providers such as NIST or Wiley, in-house, and public resources such as MoNA or GNPS are utilized to annotate the experimental MS/MS spectra with a chemical structure. While this approach is straightforward to use due to the availability of thoroughly benchmarked software such as MS-DIAL, NIST MS Search, Compound Discoverer,and Mass Hunter, a large proportion (&gt; 80%) of MS/MS spectra do not have any hit in these libraries [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>].</p>
    <p id="Par6">Machine learning (ML) models can boost the annotation rates. ML models that are trained using curated MS/MS spectra can predict the structure directly from a MS/MS spectrum without the need for searching against mass spectral libraries. For example, CSI:FingerID [<xref ref-type="bibr" rid="CR4">4</xref>] can predict molecular fingerprint, Spec2Vec [<xref ref-type="bibr" rid="CR5">5</xref>] can create spectral embeddings, Mass2SMILES [<xref ref-type="bibr" rid="CR6">6</xref>] can predict SMILES strings, and MSNovelist [<xref ref-type="bibr" rid="CR7">7</xref>] can predict new structures for a MS/MS spectra. Recently, the large-language models (LLMs) created using the transformer deep learning approach have shown to outperform classical machine learning approaches for the language related tasks such as translation or generating new text. The transformer model uses encoder-decoder structure to map a sequence of tokens from one domain into a different domain, for example translating sentences in English to German. Converting a MS/MS spectrum to molecular descriptor is in a way, a language translation problem, in which token A (m/z and intensity) are translated into token B (descriptors). This idea of token translation has been explored by Spec2Vec [<xref ref-type="bibr" rid="CR5">5</xref>] to create intermediate embedding, which can be used to search mass spectral or chemical structure libraries (MS2DeepScore [<xref ref-type="bibr" rid="CR8">8</xref>] and MS2Query [<xref ref-type="bibr" rid="CR9">9</xref>]). Other individual models such as MS2Mol [<xref ref-type="bibr" rid="CR10">10</xref>], MS2Prop [<xref ref-type="bibr" rid="CR11">11</xref>], Mass2SMILES [<xref ref-type="bibr" rid="CR6">6</xref>] and MSNovelist [<xref ref-type="bibr" rid="CR7">7</xref>] use the transformer or Long Short-Term Memory (LSTM) architecture to predict chemical descriptors, two-dimensional structure or SMILES notations.</p>
    <p id="Par7">There are two ways to use deep learning in computational mass spectrometry. First to use these individual models. But they have been trained on different training datasets and these models may not be available for a local deployment. They may also not have included specific chemical classes that a user might be interested in. The second approach is to provide an easy-to-use deep learning framework in which a user can train their own models using the MS/MS data that they may have generated for in-house standards or they have access to. For routine chem-informatics tasks, Chemprop [<xref ref-type="bibr" rid="CR12">12</xref>] is a key example of this second approach to democratize the deep learning methods so anyone who has access to training data and computing power can train different models by optimizing hyperparameters for customized training sets. For example, using Chemprop as a backbone, deep neural network model to predict antibacterial activity properties of &gt; 107 million molecules from the ZINC15 database have led to the discovery of new candidate compounds with antibiotic properties [<xref ref-type="bibr" rid="CR13">13</xref>]. Similarly, Chemprop [<xref ref-type="bibr" rid="CR12">12</xref>] has been used in several other contexts to predict pharmacokinetics [<xref ref-type="bibr" rid="CR14">14</xref>] and molecular properties [<xref ref-type="bibr" rid="CR15">15</xref>], making it a central resource for mapping chemical-to-function relationships.</p>
    <p id="Par8">Inspired by Chemprop [<xref ref-type="bibr" rid="CR16">16</xref>], to democratize the deep learning in computational mass spectrometry, we have developed IDSL_MINT (<ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link>), a deep learning mass spectrometry framework, designed to create data-centric models for mass spectrometry applications using transformer models developed by Vaswani et al<italic>.</italic> [<xref ref-type="bibr" rid="CR17">17</xref>]. IDSL_MINT encompasses modules designed to predict molecular fingerprint descriptors (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). We expect that the IDSL_MINT framework will be used to train a diversity of models to predict molecular descriptors from MS/MS spectra.<fig id="Fig1"><label>Fig. 1</label><caption><p>Schematic of MS2Fingerprint model</p></caption><graphic xlink:href="13321_2024_804_Fig1_HTML" id="MO1"/></fig></p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>Modeling framework</title>
      <p id="Par9">IDSL_MINT was developed upon the transformer model architecture originally proposed by Vaswani et al<italic>.</italic> [<xref ref-type="bibr" rid="CR17">17</xref>] and is implemented within the python PyTorch framework (<ext-link ext-link-type="uri" xlink:href="https://pytorch.org">https://pytorch.org</ext-link>). The IDSL_MINT transformer model architecture for predicting molecular fingerprint is displayed in Figs. <xref rid="Fig1" ref-type="fig">1</xref>. IDSL_MINT only takes MS/MS spectra accompanied with precursor <italic>m/z</italic> values in the<italic>.msp</italic> text format. First, <italic>m/z</italic> fragments are tokenized using constant <italic>m/z</italic> interval steps, and intensity values are sorted by the maximum intensity after normalization to the unit sum of the total intensities. Similarly, precursor <italic>m/z</italic> values are tokenized and coupled with spectral entropy values [<xref ref-type="bibr" rid="CR18">18</xref>] as their pseudo-intensity values when spectral entropy is allowed in the MSP deconvolution step; otherwise, pseudo-intensity values of '2' are utilized. Tokenized precursor <italic>m/z</italic> and its pseudo-intensity are concatenated to the tokenized vectors of <italic>m/z</italic> fragments and fragment intensity values, respectively to create tokenized <italic>m/z</italic> and intensity tensors. Next, tokenized <italic>m/z</italic> tensors are embedded into the transformer model dimension. We hypothesized the intensity of ions in a mass spectrum indicates the abundance of the ions and consequently the importance of the related sub-structure. Therefore, we used a sinusoidal positional encoding similar to Vaswani et al<italic>.</italic> [<xref ref-type="bibr" rid="CR17">17</xref>] to account for the effects of intensity on the tokenized embedded <italic>m/z</italic> tokens, as presented in Eqs. (<xref rid="Equ1" ref-type="disp-formula">1</xref>) and (<xref rid="Equ2" ref-type="disp-formula">2</xref>).<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P{E}_{(pos, 2i)}=sin \left(int.\frac{pos}{{10000}^{\frac{2i}{{d}_{model}}}}\right)$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mn>10000</mml:mn></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:msup></mml:mfrac></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="13321_2024_804_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P{E}_{(pos, 2i+1)}=cos \left(int.\frac{pos}{{10000}^{\frac{2i+1}{{d}_{model}}}}\right)$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mfenced close=")" open="("><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mn>10000</mml:mn></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:msup></mml:mfrac></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="13321_2024_804_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where, <italic>PE</italic>, <italic>pos</italic>, <italic>int</italic>, and <italic>d</italic><sub><italic>model</italic></sub> represent positional encoding tensor, intensity rank order, intensity and model dimension, respectively. The intensity-weighted positional encoding tensor is summed up with the embedded m/z tokens followed by a dropout layer to control potential overfittings. This positional encoding method enabled the utilization of both the precursor <italic>m/z</italic> as molecular mass [<xref ref-type="bibr" rid="CR11">11</xref>] and the fragment ions. The embedded <italic>m/z</italic> space is converted into the encoder structure of the transformer model. In case, customized binary fingerprint bit locations are not provided within the MSP blocks for training, IDSL_MINT can generate molecular fingerprint descriptors using SMILES or InChI strings for extended connectivity fingerprint (ECFP) using an adjustable radius [<xref ref-type="bibr" rid="CR19">19</xref>] or MACCS Keys [<xref ref-type="bibr" rid="CR20">20</xref>] fingerprint types which are widely recognized in the field of cheminformatics [<xref ref-type="bibr" rid="CR21">21</xref>]. The fingerprint bit locations are submitted to the transformer decoder in an ascending order, but no positional adjustment was used on fingerprint bit locations. The output of the decoder structure of the transformer was fed into a linear layer followed by a SoftMax layer to calculate the probability of the fingerprint bit locations (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). The cross-entropy LOSS function is used with adjustable label smoothing followed by an Adam optimizer. A beam search inference is used to ensure detection of the most probable neural network trajectory and to prevent autoregressive shortcuts in transformers. Tanimoto coefficient is calculated to find similarity between predicted and the true positive fingerprints in the accuracy plots.</p>
    </sec>
    <sec id="Sec4">
      <title>Model training setup</title>
      <p id="Par10">IDSL_MINT code is publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link><underline>.</underline> IDSL_MINT was developed using Python 3.10 and implemented with PyTorch 2.0. IDSL_MINT can be executed via a simple and easy to modify YAML configuration files using a simple command “<italic>MINT_workflow –yaml path/to/yaml/file</italic>” in a Linux terminal. Typically, users should specify the criteria for MS/MS spectra input, molecular fingerprint type, transformer model settings, parameters for the cross-entropy LOSS function, and configurations for the Adam optimization strategy. The framework works only in the Linux environment. The model weights are exported at the directory outlined in the configuration file <italic>(.yaml</italic>), for the minimal LOSS value achieved during the training phase. To ensure model reproducibility, we suggest preserving training YAML files as configuration log entries to utilize consistent model parameters in the predictive stage.</p>
    </sec>
    <sec id="Sec5">
      <title>Spectral file for the test model training</title>
      <p id="Par11">IDSL.CSA [<xref ref-type="bibr" rid="CR2">2</xref>] provided fragmentation spectra databases (FSDBs) for publicly available spectral databases (<ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/7530397">https://zenodo.org/record/7530397</ext-link>) in positive and negative modes [<xref ref-type="bibr" rid="CR2">2</xref>]. A subset of LipidMaps spectra from these FSDBs originated from MassBank of North America (MoNA) and Global Natural Product Social Molecular Networking (GNPS) libraries was converted into standard<italic>.msp</italic> files after excluding in-<italic>silico</italic> predicted MSP blocks using LipidBlast method [<xref ref-type="bibr" rid="CR23">23</xref>]. Classes of lipids were derived from LipidMaps database [<xref ref-type="bibr" rid="CR24">24</xref>] via matching corresponding InChIKey14 values.</p>
    </sec>
    <sec id="Sec6">
      <title>Test data set</title>
      <p id="Par12">To benchmark the IDSL_MINT framework, we have used a publicly available untargeted metabolomics study from the Metabolomics WorkBench (accession: ST002044) [<xref ref-type="bibr" rid="CR25">25</xref>]. IDSL.IPA [<xref ref-type="bibr" rid="CR26">26</xref>] was used for peak-picking and peak alignment followed by MS/MS peak detection using IDSL.CSA [<xref ref-type="bibr" rid="CR2">2</xref>]. Unique spectra across the entire study were collected in separate MS/MS spectra files in the<italic>.msp</italic> text format for electrospray ionization (ESI) positive and negative modes.<italic>.msp</italic> text files and parameter spreadsheet used to annotate the unique spectra are provided at ( <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/records/8339614">https://zenodo.org/records/8339614</ext-link>) [<xref ref-type="bibr" rid="CR27">27</xref>] (file#<underline>CSA_spreadsheet.zip</underline>) for positive and negative modes.</p>
    </sec>
    <sec id="Sec7">
      <title>Model parameters for the test study</title>
      <p id="Par13">In the training step for the test study, only MS/MS spectra were used that had 90% of <italic>m/z</italic> fragments within a range of 50–1000 using 0.01 Da intervals. The extended connectivity fingerprint with a radius of 2 (ECFP2) was utilized to transform MS/MS mass spectrometry data. The MS2Fingerprint models include 4 hidden encoder and decoder layers and 2 attention heads (80 × 10<sup>6</sup> parameters including parameters of the embedding layer). A Google Colab notebook showing the training and prediction parameters are provided at <ext-link ext-link-type="uri" xlink:href="https://drive.google.com/file/d/1IFWTeeZ_I4tbQ-y6MEvSkQ0hb6vqited/view?usp=sharing">https://drive.google.com/file/d/1IFWTeeZ_I4tbQ-y6MEvSkQ0hb6vqited/view?usp=sharing</ext-link><underline>.</underline> Model training curves are shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S1.</p>
    </sec>
  </sec>
  <sec id="Sec8">
    <title>Results</title>
    <p id="Par14">We have developed IDSL_MINT, a cheminformatics deep learning framework, to predict molecular fingerprint descriptors from MS/MS fragmentation spectra. The framework enabled easy and straightforward training of predictive models from different mass spectral libraries, in a similar fashion to the widely accepted Chemprop approach [<xref ref-type="bibr" rid="CR16">16</xref>] which can create different models for predicting physical–chemical properties from chemical structures. The framework utilizes a transformer architecture [<xref ref-type="bibr" rid="CR17">17</xref>] in PyTorch to translate <italic>m/z</italic> values into a fingerprint bit vector. The required input for training the model is only a reference spectra library in the NIST standard<italic>.msp</italic> text format with or without fingerprint data and a model configuration text file (<italic>.yaml</italic>). Figure <xref rid="Fig2" ref-type="fig">2</xref> illustrates the overview of the input and output data in the framework.<fig id="Fig2"><label>Fig. 2</label><caption><p>Flowchart of the IDSL_MINT workflow</p></caption><graphic xlink:href="13321_2024_804_Fig2_HTML" id="MO2"/></fig></p>
    <p id="Par15">As an alternative to interact with complex python scripts, we have provided well documented <italic>yaml</italic> configuration files for selecting model parameters. Similar to Chemprop [<xref ref-type="bibr" rid="CR16">16</xref>], IDSL_MINT is directly run in a Linux terminal using a simple command (See method). We provided a Google Colaboratory notebook (<ext-link ext-link-type="uri" xlink:href="https://colab.research.google.com/drive/16A-Hw6S_04nxlopp7yefZkVB5Aakcodu">https://colab.research.google.com/drive/16A-Hw6S_04nxlopp7yefZkVB5Aakcodu</ext-link>) to demonstrate the application of the IDSL_MINT framework without any local installation. Users can train a new model on these notebooks using the test data or they can use their own input data for creating customized models. GPUs and CPUs are both supported by IDSL_MINT. The codebase and the documentation are provided at <ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link> to install IDSL_MINT in a local Linux server.</p>
    <p id="Par16">We showcase the application of IDSL_MINT for a publicly available untargeted metabolomics study (ST002044) from the Metabolomics WorkBench database. First, we processed the raw data for this study to extract MS/MS spectra in the NIST.msp format that can be used as the model evaluation set. The IDSL.CSA R package [<xref ref-type="bibr" rid="CR2">2</xref>] was used to extract 3,386 and 1,901 unique MS/MS spectra in ESI<sup>+</sup> and ESI<sup>−</sup> for this study [<xref ref-type="bibr" rid="CR27">27</xref>] (file#1 csa_spreadsheet.zip). Next, we obtained the coverage of spectra annotation by mass spectral similarity searches. IDSL.CSA can annotate 638 (out of 3386) and 299 (out of 1901) MS/MS peaks in positive and negative modes by matching the spectra against NIST 20 and LipidBlast [<xref ref-type="bibr" rid="CR23">23</xref>] libraries [<xref ref-type="bibr" rid="CR27">27</xref>] (file#1 csa_spreadsheet.zip).</p>
    <p id="Par17">Next, we carefully compiled the training dataset for the case study (ST002044) to ensure a high validity of the resulting model (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). Spectra from MoNA and GNPS public libraries in positive and negative modes were used separately to create training sets. We excluded the spectra related to compounds that were covered in the LipidBlast (in-<italic>silico</italic>) [<xref ref-type="bibr" rid="CR23">23</xref>] and NIST 20 libraries because we used these two libraries for annotating the experimental MS/MS spectra in the case study. Our case study training set included 6.96% and 4.58% of all the compounds in the LipidMaps database in positive and negative modes, respectively because most of the lipid compounds did not have publicly available MS/MS spectra. Lipid classification ontology was not covered in the MS/MS databases, so we obtained it from the LipidMaps structure SDF file in the PubChem database. Training data has 8 lipid classes and 6 classes having at least 50 spectra (Table <xref rid="Tab1" ref-type="table">1</xref>). The most over-represented lipid classes were Polyketides (PK) and Fatty Acyls (FA) and under-represented classes were Glycerolipids (GL) and Saccharolipids (SL). Extracted MS/MS LipidMaps spectra in MoNA and GNPS public libraries, and lipid classes from PubChem database were provided in the<italic>.msp</italic> text format at Zenodo entry [<xref ref-type="bibr" rid="CR27">27</xref>] (file#2 <underline>lipidmaps_msp.zip/</underline>). Despite the small size training set, we were able to train a useful model with practical prediction accuracies for an untargeted metabolomics experiment, as highlighted in the following sections.<fig id="Fig3"><label>Fig. 3</label><caption><p>Careful compilation of the training set for the case study. Unique InChIKey14 was used to compute set overlaps. Source data file is provided at Zenodo entry [<xref ref-type="bibr" rid="CR27">27</xref>] (file#3 venn.zip)</p></caption><graphic xlink:href="13321_2024_804_Fig3_HTML" id="MO3"/></fig><table-wrap id="Tab1"><label>Table 1</label><caption><p>Frequency of lipid in each class in the training data set</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Lipid class</th><th align="left">Negative</th><th align="left">Positive</th></tr></thead><tbody><tr><td align="left">Polyketides (PK)</td><td align="left">794</td><td align="left">1019</td></tr><tr><td align="left">Fatty Acyls (FA)</td><td align="left">791</td><td align="left">1294</td></tr><tr><td align="left">Glycerophospholipids (GP)</td><td align="left">339</td><td align="left">202</td></tr><tr><td align="left">Sterol Lipids (ST)</td><td align="left">289</td><td align="left">516</td></tr><tr><td align="left">Prenol Lipids (PR)</td><td align="left">141</td><td align="left">438</td></tr><tr><td align="left">Sphingolipids (SP)</td><td align="left">80</td><td align="left">54</td></tr><tr><td align="left">Glycerolipids (GL)</td><td align="left">5</td><td align="left">64</td></tr><tr><td align="left">Saccharolipids (SL)</td><td align="left">2</td><td align="left">1</td></tr></tbody></table></table-wrap></p>
    <p id="Par18">Next, we trained two deep learning models (ESI<sup>+</sup> and ESI<sup>−</sup>) using our newly created IDSL.MINT framework. The<italic>.yaml</italic> file and input<italic>.msp</italic> files are provided at Zenodo entry [<xref ref-type="bibr" rid="CR27">27</xref>](file#4 ms2fp_yaml.zip). The training in ESI<sup>+</sup> and ESI<sup>−</sup> took 70 and 45 h, respectively on 35 CPU processing threads.</p>
    <p id="Par19">Next, we evaluated the overall accuracy and the accuracy by lipid classes for the test study ST002044. Since not all lipid classes were equally represented in the training set, we expected that the model prediction accuracy would vary across the classes. Overall accuracy for the case study was 0.354 and 0.351 for positive and negative modes, respectively, where true positive being the top hit candidate when the predicted fingerprint was searched against the LipidMaps database. In terms of lipids classes, Glycerophospholipids (GP) showed an accuracy ≥ 0.50 whereas Prenol Lipids (PR) showed a really low accuracy ≤ 0.20 in both positive and negative modes (Table <xref rid="Tab2" ref-type="table">2</xref> and file#5 ms2fp_st002044_prediction.zip at [<xref ref-type="bibr" rid="CR27">27</xref>]). These variations can be attributed to the coverage of these lipid classes in the training dataset. For the case study, IDSL.CSA yielded annotations for 536 lipid compounds for both ESI modes (Table <xref rid="Tab2" ref-type="table">2</xref>). Subsequent matching of the predicted fingerprints using a Tanimoto similarity threshold of ≥ 0.6 resulted with additional 238 lipid annotations in both ESI modes. Furthermore, a spectral entropy score of ≥ 0.75 was found to align with fingerprint matches characterized by a Tanimoto similarity threshold of ≥ 0.7 shown in Table <xref rid="Tab2" ref-type="table">2</xref>. Notably, within the Glycerophospholipids (GP) lipid class, the median Tanimoto similarity stands a score of 1 across 178 annotations with a spectral entropy score of ≥ 0.75 in positive mode. We noted that 71 (ESI<sup>+</sup>) and 96 (ESI<sup>−</sup>) annotations were not part of the training set, suggesting the use of IDSL_MINT for improving annotations beyond mass spectral libraries. The results of all annotated MS/MS spectra in ST002044 by fingerprint matches with Tanimoto similarity ≥ 0.5 against LipidMaps and IDSL.CSA match is provided at Zenodo entry [<xref ref-type="bibr" rid="CR27">27</xref>](file#6 ms2fp_lipidmaps.zip and file#7 ms2fp_idsl.csa.zip).<table-wrap id="Tab2"><label>Table 2</label><caption><p>Tanimoto coefficients of ECFP2 fingerprints for the ST002044 study. Fingerprint matching assisted in adding more annotations</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Mode</th><th align="left" rowspan="2">Lipid categories</th><th align="left" colspan="3">LipidMaps (Entire top hits)</th><th align="left" colspan="3">Library match after spectral entropy ≥ 0.75)</th><th align="left" colspan="3">IDSL_MINT new high-confidence annotations (Tanimoto similarity ≥ 0.6)</th></tr><tr><th align="left">Count</th><th align="left">Mean</th><th align="left">Median</th><th align="left">Count</th><th align="left">Mean</th><th align="left">Median</th><th align="left">Count</th><th align="left">Mean</th><th align="left">Median</th></tr></thead><tbody><tr><td align="left" rowspan="7">Positive mode</td><td align="left">Fatty Acyls (FA)</td><td align="left">592</td><td char="." align="char">0.254 ± 0.270</td><td char="." align="char">0.140</td><td align="left">80</td><td char="." align="char">0.672 ± 0.330</td><td char="." align="char">0.772</td><td align="left">24</td><td char="." align="char">0.831 ± 0.121</td><td char="." align="char">0.857</td></tr><tr><td align="left">Prenol Lipids (PR)</td><td align="left">182</td><td char="." align="char">0.181 ± 0.158</td><td char="." align="char">0.138</td><td align="left">4</td><td char="." align="char">0.736 ± 0.008</td><td char="." align="char">0.731</td><td align="left">3</td><td char="." align="char">1.000 ± 0.000</td><td char="." align="char">1.000</td></tr><tr><td align="left">Polyketides (PK)</td><td align="left">233</td><td char="." align="char">0.205 ± 0.122</td><td char="." align="char">0.181</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">3</td><td char="." align="char">0.881 ± 0.068</td><td char="." align="char">0.836</td></tr><tr><td align="left">Sphingolipids (SP)</td><td align="left">56</td><td char="." align="char">0.326 ± 0.282</td><td char="." align="char">0.192</td><td align="left">16</td><td char="." align="char">0.571 ± 0.381</td><td char="." align="char">0.798</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Glycerophospholipids (GP)</td><td align="left">724</td><td char="." align="char">0.543 ± 0.350</td><td char="." align="char">0.540</td><td align="left">178</td><td char="." align="char">0.916 ± 0.154</td><td char="." align="char">1.000</td><td align="left">85</td><td char="." align="char">0.838 ± 0.111</td><td char="." align="char">0.839</td></tr><tr><td align="left">Glycerolipids (GL)</td><td align="left">60</td><td char="." align="char">0.561 ± 0.368</td><td char="." align="char">0.556</td><td align="left">35</td><td char="." align="char">0.772 ± 0.262</td><td char="." align="char">0.875</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Sterol Lipids (ST)</td><td align="left">295</td><td char="." align="char">0.302 ± 0.272</td><td char="." align="char">0.168</td><td align="left">65</td><td char="." align="char">0.669 ± 0.232</td><td char="." align="char">0.673</td><td align="left">12</td><td char="." align="char">0.805 ± 0.119</td><td char="." align="char">0.756</td></tr><tr><td align="left" rowspan="7">Negative mode</td><td align="left">Fatty Acyls (FA)</td><td align="left">437</td><td char="." align="char">0.233 ± 0.198</td><td char="." align="char">0.175</td><td align="left">8</td><td char="." align="char">0.556 ± 0.301</td><td char="." align="char">0.533</td><td align="left">22</td><td char="." align="char">0.782 ± 0.106</td><td char="." align="char">0.757</td></tr><tr><td align="left">Prenol Lipids (PR)</td><td align="left">65</td><td char="." align="char">0.139 ± 0.029</td><td char="." align="char">0.145</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Polyketides (PK)</td><td align="left">175</td><td char="." align="char">0.183 ± 0.118</td><td char="." align="char">0.166</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">3</td><td char="." align="char">0.783 ± 0.155</td><td char="." align="char">0.701</td></tr><tr><td align="left">Sphingolipids (SP)</td><td align="left">0</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Glycerophospholipids (GP)</td><td align="left">371</td><td char="." align="char">0.671 ± 0.247</td><td char="." align="char">0.704</td><td align="left">150</td><td char="." align="char">0.739 ± 0.182</td><td char="." align="char">0.714</td><td align="left">85</td><td char="." align="char">0.837 ± 0.140</td><td char="." align="char">0.849</td></tr><tr><td align="left">Glycerolipids (GL)</td><td align="left">11</td><td char="." align="char">0.335 ± 0.046</td><td char="." align="char">0.339</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Sterol Lipids (ST)</td><td align="left">121</td><td char="." align="char">0.165 ± 0.096</td><td char="." align="char">0.144</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">1</td><td char="." align="char">0.887 ± 0.000</td><td char="." align="char">0.886</td></tr></tbody></table></table-wrap></p>
  </sec>
  <sec id="Sec9">
    <title>Discussions</title>
    <p id="Par20">We have developed a deep learning framework for computational mass spectrometry in metabolomics and exposomics to train user-defined models to predict structure and molecular fingerprints from tandem mass (MS/MS) spectra. An application of this framework is presented to annotate MS/MS spectra that did not have any hits in the existing reference mass spectral libraries. It can be suggested that a combined use of both mass spectral library searches and deep learning models can improve the annotation rate in lipidomics, metabolomics and exposomics fields. As we highlighted that our work is inspired by Chemprop [<xref ref-type="bibr" rid="CR12">12</xref>], to democratize deep learning in computational mass spectrometry, in which users can train custom models by different training datasets. An example is shown as a lipid structure prediction model trained only on the lipid MS/MS spectra because a lipid extraction method was used using the sample preparation. This framework also enables open science where deep learning models created using publicly available MS/MS spectra can be made available without any restrictions.</p>
    <p id="Par21">Transformer models have revolutionized the field of natural language processing (NLP), particularly in transforming between two spaces of sequences of tokens similar to natural language structures [<xref ref-type="bibr" rid="CR17">17</xref>]. The transformer model consists of encoder and decoder structures which include self-attention mechanisms, feed-forward neural networks, and normalization layers. The ability to tokenize raw mass spectrometry data (<italic>m/z</italic> values) and molecular fingerprint bit locations allow for the adoption of this well-developed model architecture in the field of computational mass spectrometry.</p>
    <p id="Par22">The key objective in using deep learning models for mass spectrometry data processing is to transform mass spectrometry <italic>m/z</italic> values into a more applicable information space such as molecular fingerprint descriptors [<xref ref-type="bibr" rid="CR28">28</xref>]. This conversion enables utilizing MS/MS spectra in several known cheminformatics approaches such as Quantitative Structure–Activity Relationship (QSAR) modeling. The predicted fingerprints can prioritize the annotated peaks for further structure elucidation workflows which are resource-demanding in mass spectrometry-based projects. Only a limited number of high-quality mass spectral signatures should be prioritized for further in-<italic>silico</italic> analyses and laboratory experiments. QSAR models built by molecular fingerprint descriptors can be utilized to directly predict physical–chemical properties without fully knowing the two-dimensional structure. This was achieved by MS2Prop tool to predict quantitative assessment of drug-likeness (QED) [<xref ref-type="bibr" rid="CR29">29</xref>], and synthetic accessibility [<xref ref-type="bibr" rid="CR30">30</xref>].</p>
    <p id="Par23">One of the key messages of our work is that the accuracy of these deep learning models varies by chemical classes. That can be explained by limited training data for them. If a class is not well-represented in the training set of an existing model, then we need to acquire the standards, collect the MS/MS spectra for them and train a new model. This situation is regularly observed by the untargeted metabolomics and exposomics community. It is also recognized in the cheminformatics field that not every class has training data [<xref ref-type="bibr" rid="CR31">31</xref>–<xref ref-type="bibr" rid="CR33">33</xref>], an issue known as the domain of applicability [<xref ref-type="bibr" rid="CR34">34</xref>]. IDSL_MINT will enable straight-forward training of such new models, in a similar way Chemprop [<xref ref-type="bibr" rid="CR16">16</xref>] supports the QASR modeling. Users should note that a model might perform well for one class, and thus can be used reliably for that specific class, for example the case study works for lipid classes Glycerophospholipids (GP). We have shown for the case study, the 238 additional spectra could be annotated by this new approach; however, the reliable annotations were for the classes with higher accuracies. Our results underscore the need to expand the training data for these under-represented classes in the public libraries such as MoNA and GNPS databases.</p>
    <p id="Par24">Putting together the training and prediction architecture requires setting up complex python scripts, but IDSL_MINT has minimized these efforts to almost no scripting by accepting all the parameters in well-documented configuration files in a simple text format (<italic>.yaml</italic>). This idea of using a<italic>.yaml</italic> file was also adopted from the Chemprop framework [<xref ref-type="bibr" rid="CR16">16</xref>], and it makes it very straightforward to train a deep learning model for MS/MS spectra. We also use the input spectra in<italic>.msp</italic> text format which is a commonly used format in computational mass spectrometry, meaning that IDSL_MINT can be easily integrated with other workflows which handle mass spectra in this format. For example, by using only IDSL.CSA [<xref ref-type="bibr" rid="CR2">2</xref>] and IDSL_MINT, a user can extract and annotate MS/MS spectra by mass spectral similarity and the deep learning based predictive modeling.</p>
    <p id="Par25">Since there are many molecular fingerprints available in cheminformatics and new ones can be created for a collection of chemical structures, IDSL_MINT supports any type of user-provided fingerprint as long as it is in the binary vector format. This is different from existing tools SIRIUS 4 [<xref ref-type="bibr" rid="CR35">35</xref>] and CSI:FingerID [<xref ref-type="bibr" rid="CR4">4</xref>] which use a set of fixed molecular fingerprints. However, it should be noted that searching the predicted fingerprints against massive databases such as PubChem may require re-calculations of the custom fingerprints.</p>
    <p id="Par26">The main limitation of this work was that our training set was constrained to only the experimental LipidMaps library which was around &lt; 10% of total LipidMaps compounds. However, we have achieved practical accuracies for a number of lipid classes. The transformer architecture can be expanded to include neutral losses from precursor and <italic>m/z</italic> differences, which may also improve the accuracy of the model. Several advanced formats of the transformer architecture have been developed to train large language models by NLP researchers. Those advances can be tested while translating <italic>m/z</italic> tokens into molecular fingerprints tokens.</p>
    <p id="Par27">The presented IDSL_MINT test model also has several limitations. First, the results of this model could not be compared against that of existing fingerprint prediction models such as CSI:FingerID [<xref ref-type="bibr" rid="CR4">4</xref>]. Second, the model was created for a lipidomics dataset, so it cannot be generalized to other metabolomics datasets. Lastly, we did not test different molecular fingerprint types while building the model. However, it should be noted that the test model was created only to show the utility of the IDSL_MINT framework, and follow-up investigations are required to increase the impact in reference to these limitations. We also recommend that training datasets used as input for the IDSL_MINT framework are submitted to a public data repository such as Zenodo ( <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/">https://zenodo.org/</ext-link>) with a proper version control and data provenance records so the results by different modelling frameworks or models can be logically compared.”</p>
  </sec>
  <sec sec-type="supplementary-material">
    <sec id="Sec10">
      <title>Supplementary Information</title>
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="13321_2024_804_MOESM1_ESM.docx">
            <caption>
              <p><bold>Additional file 1: Figure S1.</bold> Training curves for the lipid annotation model</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>Conceptualization and methodology, Data curation, Investigation, Software, Formal analyses, Visualization, Resources, Writing-original draft, Writing-review and editing (DKB and SFB).</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>The work was in part supported by T32HD049311, K12ES033594, U2CES026561, R35ES030435, U2CES026555, P30ES023515, U2CES030859, UL1TR004419, U24ES035386, R01ES032831 and R01ES033688.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>Project name: IDSL_MINT, Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link><underline>.</underline> Operating system(s): Linux. Programming language: Python. Other requirements: None. License: MIT. Any restrictions to use by non-academics: None. Data and results are available at <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/8339614">https://zenodo.org/record/8339614</ext-link></p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par28">DKB has been a consultant for Brightseed Bio Inc, South San Francisco.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schrimpe-Rutledge</surname>
            <given-names>AC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Untargeted metabolomics strategies-challenges and emerging directions</article-title>
        <source>J Am Soc Mass Spectrom</source>
        <year>2016</year>
        <volume>27</volume>
        <issue>12</issue>
        <fpage>1897</fpage>
        <lpage>1905</lpage>
        <pub-id pub-id-type="doi">10.1007/s13361-016-1469-y</pub-id>
        <?supplied-pmid 27624161?>
        <pub-id pub-id-type="pmid">27624161</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baygi</surname>
            <given-names>SF</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Barupal</surname>
            <given-names>DK</given-names>
          </name>
        </person-group>
        <article-title>IDSL.CSA: composite spectra analysis for chemical annotation of untargeted metabolomics datasets</article-title>
        <source>Anal Chem</source>
        <year>2023</year>
        <volume>95</volume>
        <issue>25</issue>
        <fpage>9480</fpage>
        <lpage>9487</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.3c00376</pub-id>
        <?supplied-pmid 37311059?>
        <pub-id pub-id-type="pmid">37311059</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Domingo-Almenara</surname>
            <given-names>X</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Annotation: a computational solution for streamlining metabolomics analysis</article-title>
        <source>Anal Chem</source>
        <year>2018</year>
        <volume>90</volume>
        <issue>1</issue>
        <fpage>480</fpage>
        <lpage>489</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.7b03929</pub-id>
        <?supplied-pmid 29039932?>
        <pub-id pub-id-type="pmid">29039932</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Duhrkop</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Searching molecular structure databases with tandem mass spectra using CSI:FingerID</article-title>
        <source>Proc Natl Acad Sci U S A</source>
        <year>2015</year>
        <volume>112</volume>
        <issue>41</issue>
        <fpage>12580</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1509788112</pub-id>
        <?supplied-pmid 26392543?>
        <pub-id pub-id-type="pmid">26392543</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huber</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Spec2Vec: Improved mass spectral similarity scoring through learning of structural relationships</article-title>
        <source>PLoS Comput Biol</source>
        <year>2021</year>
        <volume>17</volume>
        <issue>2</issue>
        <fpage>e1008724</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1008724</pub-id>
        <?supplied-pmid 33591968?>
        <pub-id pub-id-type="pmid">33591968</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">Elser, D., F. Huber, and E. Gaquerel, <italic>Mass2SMILES: deep learning based fast prediction of structures and functional groups directly from high-resolution MS/MS spectra.</italic> bioRxiv, 2023: p. 2023.07. 06.547963</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stravs</surname>
            <given-names>MA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MSNovelist: de novo structure generation from mass spectra</article-title>
        <source>Nat Methods</source>
        <year>2022</year>
        <volume>19</volume>
        <issue>7</issue>
        <fpage>865</fpage>
        <lpage>870</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-022-01486-3</pub-id>
        <?supplied-pmid 35637304?>
        <pub-id pub-id-type="pmid">35637304</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huber</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MS2DeepScore: a novel deep learning similarity measure to compare tandem mass spectra</article-title>
        <source>J Cheminform</source>
        <year>2021</year>
        <volume>13</volume>
        <issue>1</issue>
        <fpage>84</fpage>
        <pub-id pub-id-type="doi">10.1186/s13321-021-00558-4</pub-id>
        <?supplied-pmid 34715914?>
        <pub-id pub-id-type="pmid">34715914</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Jonge</surname>
            <given-names>NF</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MS2Query: reliable and scalable MS(2) mass spectra-based analogue search</article-title>
        <source>Nature Communication</source>
        <year>2023</year>
        <volume>14</volume>
        <issue>1</issue>
        <fpage>1752</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-023-37446-4</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">Butler, T., et al., <italic>MS2Mol: A transformer model for illuminating dark chemical space from mass spectra.</italic> 2023</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Voronov, G., et al., <italic>MS2Prop: A machine learning model that directly predicts chemical properties from mass spectrometry data for novel compounds.</italic> bioRxiv, 2022: p. 2022.10. 09.511482</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Analyzing learned molecular representations for property prediction</article-title>
        <source>J Chem Inf Model</source>
        <year>2019</year>
        <volume>59</volume>
        <issue>8</issue>
        <fpage>3370</fpage>
        <lpage>3388</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.9b00237</pub-id>
        <?supplied-pmid 31361484?>
        <pub-id pub-id-type="pmid">31361484</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stokes</surname>
            <given-names>JM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A deep learning approach to antibiotic discovery</article-title>
        <source>Cell</source>
        <year>2020</year>
        <volume>180</volume>
        <issue>4</issue>
        <fpage>688</fpage>
        <lpage>702</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2020.01.021</pub-id>
        <?supplied-pmid 32084340?>
        <pub-id pub-id-type="pmid">32084340</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stoyanova</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Computational predictions of nonclinical pharmacokinetics at the drug design stage</article-title>
        <source>J Chem Inf Model</source>
        <year>2023</year>
        <volume>63</volume>
        <issue>2</issue>
        <fpage>442</fpage>
        <lpage>458</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.2c01134</pub-id>
        <?supplied-pmid 36595708?>
        <pub-id pub-id-type="pmid">36595708</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>ABT-MPNN: an atom-bond transformer-based message-passing neural network for molecular property prediction</article-title>
        <source>J Cheminform</source>
        <year>2023</year>
        <volume>15</volume>
        <issue>1</issue>
        <fpage>29</fpage>
        <pub-id pub-id-type="doi">10.1186/s13321-023-00698-9</pub-id>
        <?supplied-pmid 36843022?>
        <pub-id pub-id-type="pmid">36843022</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Heid, E., et al., <italic>Chemprop: A Machine Learning Package for Chemical Property Prediction.</italic> 2023</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vaswani</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Attention is all you need</article-title>
        <source>Advances in Neural Information Processing Systems</source>
        <year>2017</year>
        <volume>30</volume>
        <fpage>1</fpage>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Spectral entropy outperforms MS/MS dot product similarity for small-molecule compound identification</article-title>
        <source>Nat Methods</source>
        <year>2021</year>
        <volume>18</volume>
        <issue>12</issue>
        <fpage>1524</fpage>
        <lpage>1531</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-021-01331-z</pub-id>
        <?supplied-pmid 34857935?>
        <pub-id pub-id-type="pmid">34857935</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rogers</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hahn</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Extended-connectivity fingerprints</article-title>
        <source>J Chem Inf Model</source>
        <year>2010</year>
        <volume>50</volume>
        <issue>5</issue>
        <fpage>742</fpage>
        <lpage>754</lpage>
        <pub-id pub-id-type="doi">10.1021/ci100050t</pub-id>
        <?supplied-pmid 20426451?>
        <pub-id pub-id-type="pmid">20426451</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yongye</surname>
            <given-names>AB</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Consensus models of activity landscapes with multiple chemical, conformer, and property representations</article-title>
        <source>J Chem Inf Model</source>
        <year>2011</year>
        <volume>51</volume>
        <issue>6</issue>
        <fpage>1259</fpage>
        <lpage>1270</lpage>
        <pub-id pub-id-type="doi">10.1021/ci200081k</pub-id>
        <?supplied-pmid 21609014?>
        <pub-id pub-id-type="pmid">21609014</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xie</surname>
            <given-names>L</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Improvement of prediction performance with conjoint molecular fingerprint in deep learning</article-title>
        <source>Front Pharmacol</source>
        <year>2020</year>
        <volume>11</volume>
        <fpage>606668</fpage>
        <pub-id pub-id-type="doi">10.3389/fphar.2020.606668</pub-id>
        <?supplied-pmid 33488387?>
        <pub-id pub-id-type="pmid">33488387</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schwaller</surname>
            <given-names>P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Mapping the space of chemical reactions using attention-based neural networks</article-title>
        <source>Nat Mach Intell</source>
        <year>2021</year>
        <volume>3</volume>
        <issue>2</issue>
        <fpage>144</fpage>
        <lpage>152</lpage>
        <pub-id pub-id-type="doi">10.1038/s42256-020-00284-w</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kind</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>LipidBlast templates as flexible tools for creating new in-silico tandem mass spectral libraries</article-title>
        <source>Anal Chem</source>
        <year>2014</year>
        <volume>86</volume>
        <issue>22</issue>
        <fpage>11024</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="doi">10.1021/ac502511a</pub-id>
        <?supplied-pmid 25340521?>
        <pub-id pub-id-type="pmid">25340521</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fahy</surname>
            <given-names>E</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>LIPID MAPS online tools for lipid research</article-title>
        <source>Nucleic Acids Res</source>
        <year>2007</year>
        <volume>35</volume>
        <fpage>W606</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkm324</pub-id>
        <?supplied-pmid 17584797?>
        <pub-id pub-id-type="pmid">17584797</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baygi</surname>
            <given-names>SF</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>IDSLUFA Assigns high-confidence molecular formula annotations for untargeted LC/HRMS data sets in metabolomics and exposomics</article-title>
        <source>Anal Chem</source>
        <year>2022</year>
        <volume>94</volume>
        <issue>39</issue>
        <fpage>13315</fpage>
        <lpage>13322</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.2c00563</pub-id>
        <?supplied-pmid 36137231?>
        <pub-id pub-id-type="pmid">36137231</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fakouri-Baygi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Barupal</surname>
            <given-names>DK</given-names>
          </name>
        </person-group>
        <article-title>IDSL.IPA characterizes the organic chemical space in untargeted LC/HRMS data sets</article-title>
        <source>J Proteome Res</source>
        <year>2022</year>
        <volume>21</volume>
        <issue>6</issue>
        <fpage>1485</fpage>
        <lpage>1494</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jproteome.2c00120</pub-id>
        <?supplied-pmid 35579321?>
        <pub-id pub-id-type="pmid">35579321</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Barupal, S.F.B.D.K., <italic>Data and results for the IDSL.MINT publication</italic>, in <italic>Zenodo</italic>. 2023.</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ji</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Predicting a molecular fingerprint from an electron ionization mass spectrum with deep neural networks</article-title>
        <source>Anal Chem</source>
        <year>2020</year>
        <volume>92</volume>
        <issue>13</issue>
        <fpage>8649</fpage>
        <lpage>8653</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.0c01450</pub-id>
        <?supplied-pmid 32584545?>
        <pub-id pub-id-type="pmid">32584545</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bickerton</surname>
            <given-names>GR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Quantifying the chemical beauty of drugs</article-title>
        <source>Nat Chem</source>
        <year>2012</year>
        <volume>4</volume>
        <issue>2</issue>
        <fpage>90</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1038/nchem.1243</pub-id>
        <?supplied-pmid 22270643?>
        <pub-id pub-id-type="pmid">22270643</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ertl</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Schuffenhauer</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions</article-title>
        <source>J Cheminform</source>
        <year>2009</year>
        <volume>1</volume>
        <issue>1</issue>
        <fpage>8</fpage>
        <pub-id pub-id-type="doi">10.1186/1758-2946-1-8</pub-id>
        <?supplied-pmid 20298526?>
        <pub-id pub-id-type="pmid">20298526</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lo</surname>
            <given-names>Y-C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Machine learning in chemoinformatics and drug discovery</article-title>
        <source>Drug Discovery Today</source>
        <year>2018</year>
        <volume>23</volume>
        <issue>8</issue>
        <fpage>1538</fpage>
        <lpage>1546</lpage>
        <pub-id pub-id-type="doi">10.1016/j.drudis.2018.05.010</pub-id>
        <?supplied-pmid 29750902?>
        <pub-id pub-id-type="pmid">29750902</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MetaRF: attention-based random forest for reaction yield prediction with a few trails</article-title>
        <source>J Cheminform</source>
        <year>2023</year>
        <volume>15</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1186/s13321-023-00715-x</pub-id>
        <pub-id pub-id-type="pmid">36593523</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Colby</surname>
            <given-names>SM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>ISiCLE: a quantum chemistry pipeline for establishing in silico collision cross section libraries</article-title>
        <source>Anal Chem</source>
        <year>2019</year>
        <volume>91</volume>
        <issue>7</issue>
        <fpage>4346</fpage>
        <lpage>4356</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.8b04567</pub-id>
        <?supplied-pmid 30741529?>
        <pub-id pub-id-type="pmid">30741529</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sutton</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Identifying domains of applicability of machine learning models for materials science</article-title>
        <source>Nat Commun</source>
        <year>2020</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>4428</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-020-17112-9</pub-id>
        <?supplied-pmid 32887879?>
        <pub-id pub-id-type="pmid">32887879</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Duhrkop</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>SIRIUS 4: a rapid tool for turning tandem mass spectra into metabolite structure information</article-title>
        <source>Nat Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <issue>4</issue>
        <fpage>299</fpage>
        <lpage>302</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-019-0344-8</pub-id>
        <?supplied-pmid 30886413?>
        <pub-id pub-id-type="pmid">30886413</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Cheminform</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Cheminform</journal-id>
    <journal-title-group>
      <journal-title>Journal of Cheminformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-2946</issn>
    <publisher>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10797927</article-id>
    <article-id pub-id-type="pmid">38238779</article-id>
    <article-id pub-id-type="publisher-id">804</article-id>
    <article-id pub-id-type="doi">10.1186/s13321-024-00804-5</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>IDSL_MINT: a deep learning framework to predict molecular fingerprints from mass spectra</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Baygi</surname>
          <given-names>Sadjad Fakouri</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Barupal</surname>
          <given-names>Dinesh Kumar</given-names>
        </name>
        <address>
          <email>dinesh.barupal@mssm.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04a9tmd77</institution-id><institution-id institution-id-type="GRID">grid.59734.3c</institution-id><institution-id institution-id-type="ISNI">0000 0001 0670 2351</institution-id><institution>Department of Environmental Medicine and Public Health, </institution><institution>Icahn School of Medicine at Mount Sinai, </institution></institution-wrap>CAM Building, 3rd Floor, 17 E 102 St, New York, NY 10029 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>18</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2024</year>
    </pub-date>
    <volume>16</volume>
    <elocation-id>8</elocation-id>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>1</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Abstract</title>
        <p id="Par1">The majority of tandem mass spectrometry (MS/MS) spectra in untargeted metabolomics and exposomics studies lack any annotation. Our deep learning framework, Integrated Data Science Laboratory for Metabolomics and Exposomics—<bold>M</bold>ass <bold>INT</bold>erpreter (IDSL_MINT) can translate MS/MS spectra into molecular fingerprint descriptors. IDSL_MINT allows users to leverage the power of the transformer model for mass spectrometry data, similar to the large language models. Models are trained on user-provided reference MS/MS libraries via any customizable molecular fingerprint descriptors. IDSL_MINT was benchmarked using the LipidMaps database and improved the annotation rate of a test study for MS/MS spectra that were not originally annotated using existing mass spectral libraries. IDSL_MINT may improve the overall annotation rates in untargeted metabolomics and exposomics studies. The IDSL_MINT framework and tutorials are available in the GitHub repository at <ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link>.</p>
      </sec>
      <sec>
        <title>Scientific contribution</title>
        <p id="Par3">Structural annotation of MS/MS spectra from untargeted metabolomics and exposomics datasets is a major bottleneck in gaining new biological insights. Machine learning models to convert spectra into molecular fingerprints can help in the annotation process. Here, we present IDSL_MINT, a new, easy-to-use and customizable deep-learning framework to train and utilize new models to predict molecular fingerprints from spectra for the compound annotation workflows.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s13321-024-00804-5.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Mass spectrometry</kwd>
      <kwd>Metabolomics</kwd>
      <kwd>Lipidomics</kwd>
      <kwd>LipidMaps</kwd>
      <kwd>Transformer</kwd>
      <kwd>Molecular fingerprint descriptor</kwd>
      <kwd>Deep learning</kwd>
      <kwd>PyTorch</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006108</institution-id>
            <institution>National Center for Advancing Translational Sciences</institution>
          </institution-wrap>
        </funding-source>
        <award-id>UL1TR004419</award-id>
        <award-id>UL1TR004419</award-id>
        <principal-award-recipient>
          <name>
            <surname>Baygi</surname>
            <given-names>Sadjad Fakouri</given-names>
          </name>
          <name>
            <surname>Barupal</surname>
            <given-names>Dinesh Kumar</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000066</institution-id>
            <institution>National Institute of Environmental Health Sciences</institution>
          </institution-wrap>
        </funding-source>
        <award-id>P30ES023515</award-id>
        <award-id>U2CES026561</award-id>
        <principal-award-recipient>
          <name>
            <surname>Baygi</surname>
            <given-names>Sadjad Fakouri</given-names>
          </name>
          <name>
            <surname>Barupal</surname>
            <given-names>Dinesh Kumar</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100009633</institution-id>
            <institution>Eunice Kennedy Shriver National Institute of Child Health and Human Development</institution>
          </institution-wrap>
        </funding-source>
        <award-id>T32HD049311</award-id>
        <principal-award-recipient>
          <name>
            <surname>Baygi</surname>
            <given-names>Sadjad Fakouri</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© Springer Nature Switzerland AG 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par4">Metabolomics and exposomics fields deal with large volume datasets on the detection and measurement of expected and novel chemical compounds in biological samples [<xref ref-type="bibr" rid="CR1">1</xref>]. These datasets are mostly generated using untargeted assays employing a gas or liquid chromatography connected to a high-resolution mass spectrometry (HRMS). These instruments can be instructed to fragment chemical compounds in the biospecimens, and the mass to charge ratio and the intensity of those fragments can be recorded in a tandem MS/MS spectrum. In a typical study (n = 100), 2000–3000 unique MS/MS spectra can be collected. These spectra need to be annotated with chemical information such as structure, sub-structure or molecular formula in order to interpret their biological relevance. However, lack of annotations for a majority of the collected MS/MS spectra remains to be a major challenge.</p>
    <p id="Par5">Traditionally, mass spectral libraries available from commercial providers such as NIST or Wiley, in-house, and public resources such as MoNA or GNPS are utilized to annotate the experimental MS/MS spectra with a chemical structure. While this approach is straightforward to use due to the availability of thoroughly benchmarked software such as MS-DIAL, NIST MS Search, Compound Discoverer,and Mass Hunter, a large proportion (&gt; 80%) of MS/MS spectra do not have any hit in these libraries [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>].</p>
    <p id="Par6">Machine learning (ML) models can boost the annotation rates. ML models that are trained using curated MS/MS spectra can predict the structure directly from a MS/MS spectrum without the need for searching against mass spectral libraries. For example, CSI:FingerID [<xref ref-type="bibr" rid="CR4">4</xref>] can predict molecular fingerprint, Spec2Vec [<xref ref-type="bibr" rid="CR5">5</xref>] can create spectral embeddings, Mass2SMILES [<xref ref-type="bibr" rid="CR6">6</xref>] can predict SMILES strings, and MSNovelist [<xref ref-type="bibr" rid="CR7">7</xref>] can predict new structures for a MS/MS spectra. Recently, the large-language models (LLMs) created using the transformer deep learning approach have shown to outperform classical machine learning approaches for the language related tasks such as translation or generating new text. The transformer model uses encoder-decoder structure to map a sequence of tokens from one domain into a different domain, for example translating sentences in English to German. Converting a MS/MS spectrum to molecular descriptor is in a way, a language translation problem, in which token A (m/z and intensity) are translated into token B (descriptors). This idea of token translation has been explored by Spec2Vec [<xref ref-type="bibr" rid="CR5">5</xref>] to create intermediate embedding, which can be used to search mass spectral or chemical structure libraries (MS2DeepScore [<xref ref-type="bibr" rid="CR8">8</xref>] and MS2Query [<xref ref-type="bibr" rid="CR9">9</xref>]). Other individual models such as MS2Mol [<xref ref-type="bibr" rid="CR10">10</xref>], MS2Prop [<xref ref-type="bibr" rid="CR11">11</xref>], Mass2SMILES [<xref ref-type="bibr" rid="CR6">6</xref>] and MSNovelist [<xref ref-type="bibr" rid="CR7">7</xref>] use the transformer or Long Short-Term Memory (LSTM) architecture to predict chemical descriptors, two-dimensional structure or SMILES notations.</p>
    <p id="Par7">There are two ways to use deep learning in computational mass spectrometry. First to use these individual models. But they have been trained on different training datasets and these models may not be available for a local deployment. They may also not have included specific chemical classes that a user might be interested in. The second approach is to provide an easy-to-use deep learning framework in which a user can train their own models using the MS/MS data that they may have generated for in-house standards or they have access to. For routine chem-informatics tasks, Chemprop [<xref ref-type="bibr" rid="CR12">12</xref>] is a key example of this second approach to democratize the deep learning methods so anyone who has access to training data and computing power can train different models by optimizing hyperparameters for customized training sets. For example, using Chemprop as a backbone, deep neural network model to predict antibacterial activity properties of &gt; 107 million molecules from the ZINC15 database have led to the discovery of new candidate compounds with antibiotic properties [<xref ref-type="bibr" rid="CR13">13</xref>]. Similarly, Chemprop [<xref ref-type="bibr" rid="CR12">12</xref>] has been used in several other contexts to predict pharmacokinetics [<xref ref-type="bibr" rid="CR14">14</xref>] and molecular properties [<xref ref-type="bibr" rid="CR15">15</xref>], making it a central resource for mapping chemical-to-function relationships.</p>
    <p id="Par8">Inspired by Chemprop [<xref ref-type="bibr" rid="CR16">16</xref>], to democratize the deep learning in computational mass spectrometry, we have developed IDSL_MINT (<ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link>), a deep learning mass spectrometry framework, designed to create data-centric models for mass spectrometry applications using transformer models developed by Vaswani et al<italic>.</italic> [<xref ref-type="bibr" rid="CR17">17</xref>]. IDSL_MINT encompasses modules designed to predict molecular fingerprint descriptors (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). We expect that the IDSL_MINT framework will be used to train a diversity of models to predict molecular descriptors from MS/MS spectra.<fig id="Fig1"><label>Fig. 1</label><caption><p>Schematic of MS2Fingerprint model</p></caption><graphic xlink:href="13321_2024_804_Fig1_HTML" id="MO1"/></fig></p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>Modeling framework</title>
      <p id="Par9">IDSL_MINT was developed upon the transformer model architecture originally proposed by Vaswani et al<italic>.</italic> [<xref ref-type="bibr" rid="CR17">17</xref>] and is implemented within the python PyTorch framework (<ext-link ext-link-type="uri" xlink:href="https://pytorch.org">https://pytorch.org</ext-link>). The IDSL_MINT transformer model architecture for predicting molecular fingerprint is displayed in Figs. <xref rid="Fig1" ref-type="fig">1</xref>. IDSL_MINT only takes MS/MS spectra accompanied with precursor <italic>m/z</italic> values in the<italic>.msp</italic> text format. First, <italic>m/z</italic> fragments are tokenized using constant <italic>m/z</italic> interval steps, and intensity values are sorted by the maximum intensity after normalization to the unit sum of the total intensities. Similarly, precursor <italic>m/z</italic> values are tokenized and coupled with spectral entropy values [<xref ref-type="bibr" rid="CR18">18</xref>] as their pseudo-intensity values when spectral entropy is allowed in the MSP deconvolution step; otherwise, pseudo-intensity values of '2' are utilized. Tokenized precursor <italic>m/z</italic> and its pseudo-intensity are concatenated to the tokenized vectors of <italic>m/z</italic> fragments and fragment intensity values, respectively to create tokenized <italic>m/z</italic> and intensity tensors. Next, tokenized <italic>m/z</italic> tensors are embedded into the transformer model dimension. We hypothesized the intensity of ions in a mass spectrum indicates the abundance of the ions and consequently the importance of the related sub-structure. Therefore, we used a sinusoidal positional encoding similar to Vaswani et al<italic>.</italic> [<xref ref-type="bibr" rid="CR17">17</xref>] to account for the effects of intensity on the tokenized embedded <italic>m/z</italic> tokens, as presented in Eqs. (<xref rid="Equ1" ref-type="disp-formula">1</xref>) and (<xref rid="Equ2" ref-type="disp-formula">2</xref>).<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P{E}_{(pos, 2i)}=sin \left(int.\frac{pos}{{10000}^{\frac{2i}{{d}_{model}}}}\right)$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mn>10000</mml:mn></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:msup></mml:mfrac></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="13321_2024_804_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P{E}_{(pos, 2i+1)}=cos \left(int.\frac{pos}{{10000}^{\frac{2i+1}{{d}_{model}}}}\right)$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mfenced close=")" open="("><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mn>10000</mml:mn></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:msup></mml:mfrac></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="13321_2024_804_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where, <italic>PE</italic>, <italic>pos</italic>, <italic>int</italic>, and <italic>d</italic><sub><italic>model</italic></sub> represent positional encoding tensor, intensity rank order, intensity and model dimension, respectively. The intensity-weighted positional encoding tensor is summed up with the embedded m/z tokens followed by a dropout layer to control potential overfittings. This positional encoding method enabled the utilization of both the precursor <italic>m/z</italic> as molecular mass [<xref ref-type="bibr" rid="CR11">11</xref>] and the fragment ions. The embedded <italic>m/z</italic> space is converted into the encoder structure of the transformer model. In case, customized binary fingerprint bit locations are not provided within the MSP blocks for training, IDSL_MINT can generate molecular fingerprint descriptors using SMILES or InChI strings for extended connectivity fingerprint (ECFP) using an adjustable radius [<xref ref-type="bibr" rid="CR19">19</xref>] or MACCS Keys [<xref ref-type="bibr" rid="CR20">20</xref>] fingerprint types which are widely recognized in the field of cheminformatics [<xref ref-type="bibr" rid="CR21">21</xref>]. The fingerprint bit locations are submitted to the transformer decoder in an ascending order, but no positional adjustment was used on fingerprint bit locations. The output of the decoder structure of the transformer was fed into a linear layer followed by a SoftMax layer to calculate the probability of the fingerprint bit locations (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). The cross-entropy LOSS function is used with adjustable label smoothing followed by an Adam optimizer. A beam search inference is used to ensure detection of the most probable neural network trajectory and to prevent autoregressive shortcuts in transformers. Tanimoto coefficient is calculated to find similarity between predicted and the true positive fingerprints in the accuracy plots.</p>
    </sec>
    <sec id="Sec4">
      <title>Model training setup</title>
      <p id="Par10">IDSL_MINT code is publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link><underline>.</underline> IDSL_MINT was developed using Python 3.10 and implemented with PyTorch 2.0. IDSL_MINT can be executed via a simple and easy to modify YAML configuration files using a simple command “<italic>MINT_workflow –yaml path/to/yaml/file</italic>” in a Linux terminal. Typically, users should specify the criteria for MS/MS spectra input, molecular fingerprint type, transformer model settings, parameters for the cross-entropy LOSS function, and configurations for the Adam optimization strategy. The framework works only in the Linux environment. The model weights are exported at the directory outlined in the configuration file <italic>(.yaml</italic>), for the minimal LOSS value achieved during the training phase. To ensure model reproducibility, we suggest preserving training YAML files as configuration log entries to utilize consistent model parameters in the predictive stage.</p>
    </sec>
    <sec id="Sec5">
      <title>Spectral file for the test model training</title>
      <p id="Par11">IDSL.CSA [<xref ref-type="bibr" rid="CR2">2</xref>] provided fragmentation spectra databases (FSDBs) for publicly available spectral databases (<ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/7530397">https://zenodo.org/record/7530397</ext-link>) in positive and negative modes [<xref ref-type="bibr" rid="CR2">2</xref>]. A subset of LipidMaps spectra from these FSDBs originated from MassBank of North America (MoNA) and Global Natural Product Social Molecular Networking (GNPS) libraries was converted into standard<italic>.msp</italic> files after excluding in-<italic>silico</italic> predicted MSP blocks using LipidBlast method [<xref ref-type="bibr" rid="CR23">23</xref>]. Classes of lipids were derived from LipidMaps database [<xref ref-type="bibr" rid="CR24">24</xref>] via matching corresponding InChIKey14 values.</p>
    </sec>
    <sec id="Sec6">
      <title>Test data set</title>
      <p id="Par12">To benchmark the IDSL_MINT framework, we have used a publicly available untargeted metabolomics study from the Metabolomics WorkBench (accession: ST002044) [<xref ref-type="bibr" rid="CR25">25</xref>]. IDSL.IPA [<xref ref-type="bibr" rid="CR26">26</xref>] was used for peak-picking and peak alignment followed by MS/MS peak detection using IDSL.CSA [<xref ref-type="bibr" rid="CR2">2</xref>]. Unique spectra across the entire study were collected in separate MS/MS spectra files in the<italic>.msp</italic> text format for electrospray ionization (ESI) positive and negative modes.<italic>.msp</italic> text files and parameter spreadsheet used to annotate the unique spectra are provided at ( <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/records/8339614">https://zenodo.org/records/8339614</ext-link>) [<xref ref-type="bibr" rid="CR27">27</xref>] (file#<underline>CSA_spreadsheet.zip</underline>) for positive and negative modes.</p>
    </sec>
    <sec id="Sec7">
      <title>Model parameters for the test study</title>
      <p id="Par13">In the training step for the test study, only MS/MS spectra were used that had 90% of <italic>m/z</italic> fragments within a range of 50–1000 using 0.01 Da intervals. The extended connectivity fingerprint with a radius of 2 (ECFP2) was utilized to transform MS/MS mass spectrometry data. The MS2Fingerprint models include 4 hidden encoder and decoder layers and 2 attention heads (80 × 10<sup>6</sup> parameters including parameters of the embedding layer). A Google Colab notebook showing the training and prediction parameters are provided at <ext-link ext-link-type="uri" xlink:href="https://drive.google.com/file/d/1IFWTeeZ_I4tbQ-y6MEvSkQ0hb6vqited/view?usp=sharing">https://drive.google.com/file/d/1IFWTeeZ_I4tbQ-y6MEvSkQ0hb6vqited/view?usp=sharing</ext-link><underline>.</underline> Model training curves are shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S1.</p>
    </sec>
  </sec>
  <sec id="Sec8">
    <title>Results</title>
    <p id="Par14">We have developed IDSL_MINT, a cheminformatics deep learning framework, to predict molecular fingerprint descriptors from MS/MS fragmentation spectra. The framework enabled easy and straightforward training of predictive models from different mass spectral libraries, in a similar fashion to the widely accepted Chemprop approach [<xref ref-type="bibr" rid="CR16">16</xref>] which can create different models for predicting physical–chemical properties from chemical structures. The framework utilizes a transformer architecture [<xref ref-type="bibr" rid="CR17">17</xref>] in PyTorch to translate <italic>m/z</italic> values into a fingerprint bit vector. The required input for training the model is only a reference spectra library in the NIST standard<italic>.msp</italic> text format with or without fingerprint data and a model configuration text file (<italic>.yaml</italic>). Figure <xref rid="Fig2" ref-type="fig">2</xref> illustrates the overview of the input and output data in the framework.<fig id="Fig2"><label>Fig. 2</label><caption><p>Flowchart of the IDSL_MINT workflow</p></caption><graphic xlink:href="13321_2024_804_Fig2_HTML" id="MO2"/></fig></p>
    <p id="Par15">As an alternative to interact with complex python scripts, we have provided well documented <italic>yaml</italic> configuration files for selecting model parameters. Similar to Chemprop [<xref ref-type="bibr" rid="CR16">16</xref>], IDSL_MINT is directly run in a Linux terminal using a simple command (See method). We provided a Google Colaboratory notebook (<ext-link ext-link-type="uri" xlink:href="https://colab.research.google.com/drive/16A-Hw6S_04nxlopp7yefZkVB5Aakcodu">https://colab.research.google.com/drive/16A-Hw6S_04nxlopp7yefZkVB5Aakcodu</ext-link>) to demonstrate the application of the IDSL_MINT framework without any local installation. Users can train a new model on these notebooks using the test data or they can use their own input data for creating customized models. GPUs and CPUs are both supported by IDSL_MINT. The codebase and the documentation are provided at <ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link> to install IDSL_MINT in a local Linux server.</p>
    <p id="Par16">We showcase the application of IDSL_MINT for a publicly available untargeted metabolomics study (ST002044) from the Metabolomics WorkBench database. First, we processed the raw data for this study to extract MS/MS spectra in the NIST.msp format that can be used as the model evaluation set. The IDSL.CSA R package [<xref ref-type="bibr" rid="CR2">2</xref>] was used to extract 3,386 and 1,901 unique MS/MS spectra in ESI<sup>+</sup> and ESI<sup>−</sup> for this study [<xref ref-type="bibr" rid="CR27">27</xref>] (file#1 csa_spreadsheet.zip). Next, we obtained the coverage of spectra annotation by mass spectral similarity searches. IDSL.CSA can annotate 638 (out of 3386) and 299 (out of 1901) MS/MS peaks in positive and negative modes by matching the spectra against NIST 20 and LipidBlast [<xref ref-type="bibr" rid="CR23">23</xref>] libraries [<xref ref-type="bibr" rid="CR27">27</xref>] (file#1 csa_spreadsheet.zip).</p>
    <p id="Par17">Next, we carefully compiled the training dataset for the case study (ST002044) to ensure a high validity of the resulting model (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). Spectra from MoNA and GNPS public libraries in positive and negative modes were used separately to create training sets. We excluded the spectra related to compounds that were covered in the LipidBlast (in-<italic>silico</italic>) [<xref ref-type="bibr" rid="CR23">23</xref>] and NIST 20 libraries because we used these two libraries for annotating the experimental MS/MS spectra in the case study. Our case study training set included 6.96% and 4.58% of all the compounds in the LipidMaps database in positive and negative modes, respectively because most of the lipid compounds did not have publicly available MS/MS spectra. Lipid classification ontology was not covered in the MS/MS databases, so we obtained it from the LipidMaps structure SDF file in the PubChem database. Training data has 8 lipid classes and 6 classes having at least 50 spectra (Table <xref rid="Tab1" ref-type="table">1</xref>). The most over-represented lipid classes were Polyketides (PK) and Fatty Acyls (FA) and under-represented classes were Glycerolipids (GL) and Saccharolipids (SL). Extracted MS/MS LipidMaps spectra in MoNA and GNPS public libraries, and lipid classes from PubChem database were provided in the<italic>.msp</italic> text format at Zenodo entry [<xref ref-type="bibr" rid="CR27">27</xref>] (file#2 <underline>lipidmaps_msp.zip/</underline>). Despite the small size training set, we were able to train a useful model with practical prediction accuracies for an untargeted metabolomics experiment, as highlighted in the following sections.<fig id="Fig3"><label>Fig. 3</label><caption><p>Careful compilation of the training set for the case study. Unique InChIKey14 was used to compute set overlaps. Source data file is provided at Zenodo entry [<xref ref-type="bibr" rid="CR27">27</xref>] (file#3 venn.zip)</p></caption><graphic xlink:href="13321_2024_804_Fig3_HTML" id="MO3"/></fig><table-wrap id="Tab1"><label>Table 1</label><caption><p>Frequency of lipid in each class in the training data set</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Lipid class</th><th align="left">Negative</th><th align="left">Positive</th></tr></thead><tbody><tr><td align="left">Polyketides (PK)</td><td align="left">794</td><td align="left">1019</td></tr><tr><td align="left">Fatty Acyls (FA)</td><td align="left">791</td><td align="left">1294</td></tr><tr><td align="left">Glycerophospholipids (GP)</td><td align="left">339</td><td align="left">202</td></tr><tr><td align="left">Sterol Lipids (ST)</td><td align="left">289</td><td align="left">516</td></tr><tr><td align="left">Prenol Lipids (PR)</td><td align="left">141</td><td align="left">438</td></tr><tr><td align="left">Sphingolipids (SP)</td><td align="left">80</td><td align="left">54</td></tr><tr><td align="left">Glycerolipids (GL)</td><td align="left">5</td><td align="left">64</td></tr><tr><td align="left">Saccharolipids (SL)</td><td align="left">2</td><td align="left">1</td></tr></tbody></table></table-wrap></p>
    <p id="Par18">Next, we trained two deep learning models (ESI<sup>+</sup> and ESI<sup>−</sup>) using our newly created IDSL.MINT framework. The<italic>.yaml</italic> file and input<italic>.msp</italic> files are provided at Zenodo entry [<xref ref-type="bibr" rid="CR27">27</xref>](file#4 ms2fp_yaml.zip). The training in ESI<sup>+</sup> and ESI<sup>−</sup> took 70 and 45 h, respectively on 35 CPU processing threads.</p>
    <p id="Par19">Next, we evaluated the overall accuracy and the accuracy by lipid classes for the test study ST002044. Since not all lipid classes were equally represented in the training set, we expected that the model prediction accuracy would vary across the classes. Overall accuracy for the case study was 0.354 and 0.351 for positive and negative modes, respectively, where true positive being the top hit candidate when the predicted fingerprint was searched against the LipidMaps database. In terms of lipids classes, Glycerophospholipids (GP) showed an accuracy ≥ 0.50 whereas Prenol Lipids (PR) showed a really low accuracy ≤ 0.20 in both positive and negative modes (Table <xref rid="Tab2" ref-type="table">2</xref> and file#5 ms2fp_st002044_prediction.zip at [<xref ref-type="bibr" rid="CR27">27</xref>]). These variations can be attributed to the coverage of these lipid classes in the training dataset. For the case study, IDSL.CSA yielded annotations for 536 lipid compounds for both ESI modes (Table <xref rid="Tab2" ref-type="table">2</xref>). Subsequent matching of the predicted fingerprints using a Tanimoto similarity threshold of ≥ 0.6 resulted with additional 238 lipid annotations in both ESI modes. Furthermore, a spectral entropy score of ≥ 0.75 was found to align with fingerprint matches characterized by a Tanimoto similarity threshold of ≥ 0.7 shown in Table <xref rid="Tab2" ref-type="table">2</xref>. Notably, within the Glycerophospholipids (GP) lipid class, the median Tanimoto similarity stands a score of 1 across 178 annotations with a spectral entropy score of ≥ 0.75 in positive mode. We noted that 71 (ESI<sup>+</sup>) and 96 (ESI<sup>−</sup>) annotations were not part of the training set, suggesting the use of IDSL_MINT for improving annotations beyond mass spectral libraries. The results of all annotated MS/MS spectra in ST002044 by fingerprint matches with Tanimoto similarity ≥ 0.5 against LipidMaps and IDSL.CSA match is provided at Zenodo entry [<xref ref-type="bibr" rid="CR27">27</xref>](file#6 ms2fp_lipidmaps.zip and file#7 ms2fp_idsl.csa.zip).<table-wrap id="Tab2"><label>Table 2</label><caption><p>Tanimoto coefficients of ECFP2 fingerprints for the ST002044 study. Fingerprint matching assisted in adding more annotations</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Mode</th><th align="left" rowspan="2">Lipid categories</th><th align="left" colspan="3">LipidMaps (Entire top hits)</th><th align="left" colspan="3">Library match after spectral entropy ≥ 0.75)</th><th align="left" colspan="3">IDSL_MINT new high-confidence annotations (Tanimoto similarity ≥ 0.6)</th></tr><tr><th align="left">Count</th><th align="left">Mean</th><th align="left">Median</th><th align="left">Count</th><th align="left">Mean</th><th align="left">Median</th><th align="left">Count</th><th align="left">Mean</th><th align="left">Median</th></tr></thead><tbody><tr><td align="left" rowspan="7">Positive mode</td><td align="left">Fatty Acyls (FA)</td><td align="left">592</td><td char="." align="char">0.254 ± 0.270</td><td char="." align="char">0.140</td><td align="left">80</td><td char="." align="char">0.672 ± 0.330</td><td char="." align="char">0.772</td><td align="left">24</td><td char="." align="char">0.831 ± 0.121</td><td char="." align="char">0.857</td></tr><tr><td align="left">Prenol Lipids (PR)</td><td align="left">182</td><td char="." align="char">0.181 ± 0.158</td><td char="." align="char">0.138</td><td align="left">4</td><td char="." align="char">0.736 ± 0.008</td><td char="." align="char">0.731</td><td align="left">3</td><td char="." align="char">1.000 ± 0.000</td><td char="." align="char">1.000</td></tr><tr><td align="left">Polyketides (PK)</td><td align="left">233</td><td char="." align="char">0.205 ± 0.122</td><td char="." align="char">0.181</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">3</td><td char="." align="char">0.881 ± 0.068</td><td char="." align="char">0.836</td></tr><tr><td align="left">Sphingolipids (SP)</td><td align="left">56</td><td char="." align="char">0.326 ± 0.282</td><td char="." align="char">0.192</td><td align="left">16</td><td char="." align="char">0.571 ± 0.381</td><td char="." align="char">0.798</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Glycerophospholipids (GP)</td><td align="left">724</td><td char="." align="char">0.543 ± 0.350</td><td char="." align="char">0.540</td><td align="left">178</td><td char="." align="char">0.916 ± 0.154</td><td char="." align="char">1.000</td><td align="left">85</td><td char="." align="char">0.838 ± 0.111</td><td char="." align="char">0.839</td></tr><tr><td align="left">Glycerolipids (GL)</td><td align="left">60</td><td char="." align="char">0.561 ± 0.368</td><td char="." align="char">0.556</td><td align="left">35</td><td char="." align="char">0.772 ± 0.262</td><td char="." align="char">0.875</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Sterol Lipids (ST)</td><td align="left">295</td><td char="." align="char">0.302 ± 0.272</td><td char="." align="char">0.168</td><td align="left">65</td><td char="." align="char">0.669 ± 0.232</td><td char="." align="char">0.673</td><td align="left">12</td><td char="." align="char">0.805 ± 0.119</td><td char="." align="char">0.756</td></tr><tr><td align="left" rowspan="7">Negative mode</td><td align="left">Fatty Acyls (FA)</td><td align="left">437</td><td char="." align="char">0.233 ± 0.198</td><td char="." align="char">0.175</td><td align="left">8</td><td char="." align="char">0.556 ± 0.301</td><td char="." align="char">0.533</td><td align="left">22</td><td char="." align="char">0.782 ± 0.106</td><td char="." align="char">0.757</td></tr><tr><td align="left">Prenol Lipids (PR)</td><td align="left">65</td><td char="." align="char">0.139 ± 0.029</td><td char="." align="char">0.145</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Polyketides (PK)</td><td align="left">175</td><td char="." align="char">0.183 ± 0.118</td><td char="." align="char">0.166</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">3</td><td char="." align="char">0.783 ± 0.155</td><td char="." align="char">0.701</td></tr><tr><td align="left">Sphingolipids (SP)</td><td align="left">0</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Glycerophospholipids (GP)</td><td align="left">371</td><td char="." align="char">0.671 ± 0.247</td><td char="." align="char">0.704</td><td align="left">150</td><td char="." align="char">0.739 ± 0.182</td><td char="." align="char">0.714</td><td align="left">85</td><td char="." align="char">0.837 ± 0.140</td><td char="." align="char">0.849</td></tr><tr><td align="left">Glycerolipids (GL)</td><td align="left">11</td><td char="." align="char">0.335 ± 0.046</td><td char="." align="char">0.339</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td></tr><tr><td align="left">Sterol Lipids (ST)</td><td align="left">121</td><td char="." align="char">0.165 ± 0.096</td><td char="." align="char">0.144</td><td align="left">–</td><td char="." align="char">–</td><td char="." align="char">–</td><td align="left">1</td><td char="." align="char">0.887 ± 0.000</td><td char="." align="char">0.886</td></tr></tbody></table></table-wrap></p>
  </sec>
  <sec id="Sec9">
    <title>Discussions</title>
    <p id="Par20">We have developed a deep learning framework for computational mass spectrometry in metabolomics and exposomics to train user-defined models to predict structure and molecular fingerprints from tandem mass (MS/MS) spectra. An application of this framework is presented to annotate MS/MS spectra that did not have any hits in the existing reference mass spectral libraries. It can be suggested that a combined use of both mass spectral library searches and deep learning models can improve the annotation rate in lipidomics, metabolomics and exposomics fields. As we highlighted that our work is inspired by Chemprop [<xref ref-type="bibr" rid="CR12">12</xref>], to democratize deep learning in computational mass spectrometry, in which users can train custom models by different training datasets. An example is shown as a lipid structure prediction model trained only on the lipid MS/MS spectra because a lipid extraction method was used using the sample preparation. This framework also enables open science where deep learning models created using publicly available MS/MS spectra can be made available without any restrictions.</p>
    <p id="Par21">Transformer models have revolutionized the field of natural language processing (NLP), particularly in transforming between two spaces of sequences of tokens similar to natural language structures [<xref ref-type="bibr" rid="CR17">17</xref>]. The transformer model consists of encoder and decoder structures which include self-attention mechanisms, feed-forward neural networks, and normalization layers. The ability to tokenize raw mass spectrometry data (<italic>m/z</italic> values) and molecular fingerprint bit locations allow for the adoption of this well-developed model architecture in the field of computational mass spectrometry.</p>
    <p id="Par22">The key objective in using deep learning models for mass spectrometry data processing is to transform mass spectrometry <italic>m/z</italic> values into a more applicable information space such as molecular fingerprint descriptors [<xref ref-type="bibr" rid="CR28">28</xref>]. This conversion enables utilizing MS/MS spectra in several known cheminformatics approaches such as Quantitative Structure–Activity Relationship (QSAR) modeling. The predicted fingerprints can prioritize the annotated peaks for further structure elucidation workflows which are resource-demanding in mass spectrometry-based projects. Only a limited number of high-quality mass spectral signatures should be prioritized for further in-<italic>silico</italic> analyses and laboratory experiments. QSAR models built by molecular fingerprint descriptors can be utilized to directly predict physical–chemical properties without fully knowing the two-dimensional structure. This was achieved by MS2Prop tool to predict quantitative assessment of drug-likeness (QED) [<xref ref-type="bibr" rid="CR29">29</xref>], and synthetic accessibility [<xref ref-type="bibr" rid="CR30">30</xref>].</p>
    <p id="Par23">One of the key messages of our work is that the accuracy of these deep learning models varies by chemical classes. That can be explained by limited training data for them. If a class is not well-represented in the training set of an existing model, then we need to acquire the standards, collect the MS/MS spectra for them and train a new model. This situation is regularly observed by the untargeted metabolomics and exposomics community. It is also recognized in the cheminformatics field that not every class has training data [<xref ref-type="bibr" rid="CR31">31</xref>–<xref ref-type="bibr" rid="CR33">33</xref>], an issue known as the domain of applicability [<xref ref-type="bibr" rid="CR34">34</xref>]. IDSL_MINT will enable straight-forward training of such new models, in a similar way Chemprop [<xref ref-type="bibr" rid="CR16">16</xref>] supports the QASR modeling. Users should note that a model might perform well for one class, and thus can be used reliably for that specific class, for example the case study works for lipid classes Glycerophospholipids (GP). We have shown for the case study, the 238 additional spectra could be annotated by this new approach; however, the reliable annotations were for the classes with higher accuracies. Our results underscore the need to expand the training data for these under-represented classes in the public libraries such as MoNA and GNPS databases.</p>
    <p id="Par24">Putting together the training and prediction architecture requires setting up complex python scripts, but IDSL_MINT has minimized these efforts to almost no scripting by accepting all the parameters in well-documented configuration files in a simple text format (<italic>.yaml</italic>). This idea of using a<italic>.yaml</italic> file was also adopted from the Chemprop framework [<xref ref-type="bibr" rid="CR16">16</xref>], and it makes it very straightforward to train a deep learning model for MS/MS spectra. We also use the input spectra in<italic>.msp</italic> text format which is a commonly used format in computational mass spectrometry, meaning that IDSL_MINT can be easily integrated with other workflows which handle mass spectra in this format. For example, by using only IDSL.CSA [<xref ref-type="bibr" rid="CR2">2</xref>] and IDSL_MINT, a user can extract and annotate MS/MS spectra by mass spectral similarity and the deep learning based predictive modeling.</p>
    <p id="Par25">Since there are many molecular fingerprints available in cheminformatics and new ones can be created for a collection of chemical structures, IDSL_MINT supports any type of user-provided fingerprint as long as it is in the binary vector format. This is different from existing tools SIRIUS 4 [<xref ref-type="bibr" rid="CR35">35</xref>] and CSI:FingerID [<xref ref-type="bibr" rid="CR4">4</xref>] which use a set of fixed molecular fingerprints. However, it should be noted that searching the predicted fingerprints against massive databases such as PubChem may require re-calculations of the custom fingerprints.</p>
    <p id="Par26">The main limitation of this work was that our training set was constrained to only the experimental LipidMaps library which was around &lt; 10% of total LipidMaps compounds. However, we have achieved practical accuracies for a number of lipid classes. The transformer architecture can be expanded to include neutral losses from precursor and <italic>m/z</italic> differences, which may also improve the accuracy of the model. Several advanced formats of the transformer architecture have been developed to train large language models by NLP researchers. Those advances can be tested while translating <italic>m/z</italic> tokens into molecular fingerprints tokens.</p>
    <p id="Par27">The presented IDSL_MINT test model also has several limitations. First, the results of this model could not be compared against that of existing fingerprint prediction models such as CSI:FingerID [<xref ref-type="bibr" rid="CR4">4</xref>]. Second, the model was created for a lipidomics dataset, so it cannot be generalized to other metabolomics datasets. Lastly, we did not test different molecular fingerprint types while building the model. However, it should be noted that the test model was created only to show the utility of the IDSL_MINT framework, and follow-up investigations are required to increase the impact in reference to these limitations. We also recommend that training datasets used as input for the IDSL_MINT framework are submitted to a public data repository such as Zenodo ( <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/">https://zenodo.org/</ext-link>) with a proper version control and data provenance records so the results by different modelling frameworks or models can be logically compared.”</p>
  </sec>
  <sec sec-type="supplementary-material">
    <sec id="Sec10">
      <title>Supplementary Information</title>
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="13321_2024_804_MOESM1_ESM.docx">
            <caption>
              <p><bold>Additional file 1: Figure S1.</bold> Training curves for the lipid annotation model</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>Conceptualization and methodology, Data curation, Investigation, Software, Formal analyses, Visualization, Resources, Writing-original draft, Writing-review and editing (DKB and SFB).</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>The work was in part supported by T32HD049311, K12ES033594, U2CES026561, R35ES030435, U2CES026555, P30ES023515, U2CES030859, UL1TR004419, U24ES035386, R01ES032831 and R01ES033688.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>Project name: IDSL_MINT, Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/idslme/IDSL_MINT">https://github.com/idslme/IDSL_MINT</ext-link><underline>.</underline> Operating system(s): Linux. Programming language: Python. Other requirements: None. License: MIT. Any restrictions to use by non-academics: None. Data and results are available at <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/8339614">https://zenodo.org/record/8339614</ext-link></p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par28">DKB has been a consultant for Brightseed Bio Inc, South San Francisco.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schrimpe-Rutledge</surname>
            <given-names>AC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Untargeted metabolomics strategies-challenges and emerging directions</article-title>
        <source>J Am Soc Mass Spectrom</source>
        <year>2016</year>
        <volume>27</volume>
        <issue>12</issue>
        <fpage>1897</fpage>
        <lpage>1905</lpage>
        <pub-id pub-id-type="doi">10.1007/s13361-016-1469-y</pub-id>
        <?supplied-pmid 27624161?>
        <pub-id pub-id-type="pmid">27624161</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baygi</surname>
            <given-names>SF</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Barupal</surname>
            <given-names>DK</given-names>
          </name>
        </person-group>
        <article-title>IDSL.CSA: composite spectra analysis for chemical annotation of untargeted metabolomics datasets</article-title>
        <source>Anal Chem</source>
        <year>2023</year>
        <volume>95</volume>
        <issue>25</issue>
        <fpage>9480</fpage>
        <lpage>9487</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.3c00376</pub-id>
        <?supplied-pmid 37311059?>
        <pub-id pub-id-type="pmid">37311059</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Domingo-Almenara</surname>
            <given-names>X</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Annotation: a computational solution for streamlining metabolomics analysis</article-title>
        <source>Anal Chem</source>
        <year>2018</year>
        <volume>90</volume>
        <issue>1</issue>
        <fpage>480</fpage>
        <lpage>489</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.7b03929</pub-id>
        <?supplied-pmid 29039932?>
        <pub-id pub-id-type="pmid">29039932</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Duhrkop</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Searching molecular structure databases with tandem mass spectra using CSI:FingerID</article-title>
        <source>Proc Natl Acad Sci U S A</source>
        <year>2015</year>
        <volume>112</volume>
        <issue>41</issue>
        <fpage>12580</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1509788112</pub-id>
        <?supplied-pmid 26392543?>
        <pub-id pub-id-type="pmid">26392543</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huber</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Spec2Vec: Improved mass spectral similarity scoring through learning of structural relationships</article-title>
        <source>PLoS Comput Biol</source>
        <year>2021</year>
        <volume>17</volume>
        <issue>2</issue>
        <fpage>e1008724</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1008724</pub-id>
        <?supplied-pmid 33591968?>
        <pub-id pub-id-type="pmid">33591968</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">Elser, D., F. Huber, and E. Gaquerel, <italic>Mass2SMILES: deep learning based fast prediction of structures and functional groups directly from high-resolution MS/MS spectra.</italic> bioRxiv, 2023: p. 2023.07. 06.547963</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stravs</surname>
            <given-names>MA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MSNovelist: de novo structure generation from mass spectra</article-title>
        <source>Nat Methods</source>
        <year>2022</year>
        <volume>19</volume>
        <issue>7</issue>
        <fpage>865</fpage>
        <lpage>870</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-022-01486-3</pub-id>
        <?supplied-pmid 35637304?>
        <pub-id pub-id-type="pmid">35637304</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huber</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MS2DeepScore: a novel deep learning similarity measure to compare tandem mass spectra</article-title>
        <source>J Cheminform</source>
        <year>2021</year>
        <volume>13</volume>
        <issue>1</issue>
        <fpage>84</fpage>
        <pub-id pub-id-type="doi">10.1186/s13321-021-00558-4</pub-id>
        <?supplied-pmid 34715914?>
        <pub-id pub-id-type="pmid">34715914</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Jonge</surname>
            <given-names>NF</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MS2Query: reliable and scalable MS(2) mass spectra-based analogue search</article-title>
        <source>Nature Communication</source>
        <year>2023</year>
        <volume>14</volume>
        <issue>1</issue>
        <fpage>1752</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-023-37446-4</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">Butler, T., et al., <italic>MS2Mol: A transformer model for illuminating dark chemical space from mass spectra.</italic> 2023</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Voronov, G., et al., <italic>MS2Prop: A machine learning model that directly predicts chemical properties from mass spectrometry data for novel compounds.</italic> bioRxiv, 2022: p. 2022.10. 09.511482</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Analyzing learned molecular representations for property prediction</article-title>
        <source>J Chem Inf Model</source>
        <year>2019</year>
        <volume>59</volume>
        <issue>8</issue>
        <fpage>3370</fpage>
        <lpage>3388</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.9b00237</pub-id>
        <?supplied-pmid 31361484?>
        <pub-id pub-id-type="pmid">31361484</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stokes</surname>
            <given-names>JM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A deep learning approach to antibiotic discovery</article-title>
        <source>Cell</source>
        <year>2020</year>
        <volume>180</volume>
        <issue>4</issue>
        <fpage>688</fpage>
        <lpage>702</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2020.01.021</pub-id>
        <?supplied-pmid 32084340?>
        <pub-id pub-id-type="pmid">32084340</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stoyanova</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Computational predictions of nonclinical pharmacokinetics at the drug design stage</article-title>
        <source>J Chem Inf Model</source>
        <year>2023</year>
        <volume>63</volume>
        <issue>2</issue>
        <fpage>442</fpage>
        <lpage>458</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.2c01134</pub-id>
        <?supplied-pmid 36595708?>
        <pub-id pub-id-type="pmid">36595708</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>ABT-MPNN: an atom-bond transformer-based message-passing neural network for molecular property prediction</article-title>
        <source>J Cheminform</source>
        <year>2023</year>
        <volume>15</volume>
        <issue>1</issue>
        <fpage>29</fpage>
        <pub-id pub-id-type="doi">10.1186/s13321-023-00698-9</pub-id>
        <?supplied-pmid 36843022?>
        <pub-id pub-id-type="pmid">36843022</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Heid, E., et al., <italic>Chemprop: A Machine Learning Package for Chemical Property Prediction.</italic> 2023</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vaswani</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Attention is all you need</article-title>
        <source>Advances in Neural Information Processing Systems</source>
        <year>2017</year>
        <volume>30</volume>
        <fpage>1</fpage>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Spectral entropy outperforms MS/MS dot product similarity for small-molecule compound identification</article-title>
        <source>Nat Methods</source>
        <year>2021</year>
        <volume>18</volume>
        <issue>12</issue>
        <fpage>1524</fpage>
        <lpage>1531</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-021-01331-z</pub-id>
        <?supplied-pmid 34857935?>
        <pub-id pub-id-type="pmid">34857935</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rogers</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hahn</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Extended-connectivity fingerprints</article-title>
        <source>J Chem Inf Model</source>
        <year>2010</year>
        <volume>50</volume>
        <issue>5</issue>
        <fpage>742</fpage>
        <lpage>754</lpage>
        <pub-id pub-id-type="doi">10.1021/ci100050t</pub-id>
        <?supplied-pmid 20426451?>
        <pub-id pub-id-type="pmid">20426451</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yongye</surname>
            <given-names>AB</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Consensus models of activity landscapes with multiple chemical, conformer, and property representations</article-title>
        <source>J Chem Inf Model</source>
        <year>2011</year>
        <volume>51</volume>
        <issue>6</issue>
        <fpage>1259</fpage>
        <lpage>1270</lpage>
        <pub-id pub-id-type="doi">10.1021/ci200081k</pub-id>
        <?supplied-pmid 21609014?>
        <pub-id pub-id-type="pmid">21609014</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xie</surname>
            <given-names>L</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Improvement of prediction performance with conjoint molecular fingerprint in deep learning</article-title>
        <source>Front Pharmacol</source>
        <year>2020</year>
        <volume>11</volume>
        <fpage>606668</fpage>
        <pub-id pub-id-type="doi">10.3389/fphar.2020.606668</pub-id>
        <?supplied-pmid 33488387?>
        <pub-id pub-id-type="pmid">33488387</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schwaller</surname>
            <given-names>P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Mapping the space of chemical reactions using attention-based neural networks</article-title>
        <source>Nat Mach Intell</source>
        <year>2021</year>
        <volume>3</volume>
        <issue>2</issue>
        <fpage>144</fpage>
        <lpage>152</lpage>
        <pub-id pub-id-type="doi">10.1038/s42256-020-00284-w</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kind</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>LipidBlast templates as flexible tools for creating new in-silico tandem mass spectral libraries</article-title>
        <source>Anal Chem</source>
        <year>2014</year>
        <volume>86</volume>
        <issue>22</issue>
        <fpage>11024</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="doi">10.1021/ac502511a</pub-id>
        <?supplied-pmid 25340521?>
        <pub-id pub-id-type="pmid">25340521</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fahy</surname>
            <given-names>E</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>LIPID MAPS online tools for lipid research</article-title>
        <source>Nucleic Acids Res</source>
        <year>2007</year>
        <volume>35</volume>
        <fpage>W606</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkm324</pub-id>
        <?supplied-pmid 17584797?>
        <pub-id pub-id-type="pmid">17584797</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baygi</surname>
            <given-names>SF</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>IDSLUFA Assigns high-confidence molecular formula annotations for untargeted LC/HRMS data sets in metabolomics and exposomics</article-title>
        <source>Anal Chem</source>
        <year>2022</year>
        <volume>94</volume>
        <issue>39</issue>
        <fpage>13315</fpage>
        <lpage>13322</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.2c00563</pub-id>
        <?supplied-pmid 36137231?>
        <pub-id pub-id-type="pmid">36137231</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fakouri-Baygi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Barupal</surname>
            <given-names>DK</given-names>
          </name>
        </person-group>
        <article-title>IDSL.IPA characterizes the organic chemical space in untargeted LC/HRMS data sets</article-title>
        <source>J Proteome Res</source>
        <year>2022</year>
        <volume>21</volume>
        <issue>6</issue>
        <fpage>1485</fpage>
        <lpage>1494</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jproteome.2c00120</pub-id>
        <?supplied-pmid 35579321?>
        <pub-id pub-id-type="pmid">35579321</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Barupal, S.F.B.D.K., <italic>Data and results for the IDSL.MINT publication</italic>, in <italic>Zenodo</italic>. 2023.</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ji</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Predicting a molecular fingerprint from an electron ionization mass spectrum with deep neural networks</article-title>
        <source>Anal Chem</source>
        <year>2020</year>
        <volume>92</volume>
        <issue>13</issue>
        <fpage>8649</fpage>
        <lpage>8653</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.0c01450</pub-id>
        <?supplied-pmid 32584545?>
        <pub-id pub-id-type="pmid">32584545</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bickerton</surname>
            <given-names>GR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Quantifying the chemical beauty of drugs</article-title>
        <source>Nat Chem</source>
        <year>2012</year>
        <volume>4</volume>
        <issue>2</issue>
        <fpage>90</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1038/nchem.1243</pub-id>
        <?supplied-pmid 22270643?>
        <pub-id pub-id-type="pmid">22270643</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ertl</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Schuffenhauer</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions</article-title>
        <source>J Cheminform</source>
        <year>2009</year>
        <volume>1</volume>
        <issue>1</issue>
        <fpage>8</fpage>
        <pub-id pub-id-type="doi">10.1186/1758-2946-1-8</pub-id>
        <?supplied-pmid 20298526?>
        <pub-id pub-id-type="pmid">20298526</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lo</surname>
            <given-names>Y-C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Machine learning in chemoinformatics and drug discovery</article-title>
        <source>Drug Discovery Today</source>
        <year>2018</year>
        <volume>23</volume>
        <issue>8</issue>
        <fpage>1538</fpage>
        <lpage>1546</lpage>
        <pub-id pub-id-type="doi">10.1016/j.drudis.2018.05.010</pub-id>
        <?supplied-pmid 29750902?>
        <pub-id pub-id-type="pmid">29750902</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MetaRF: attention-based random forest for reaction yield prediction with a few trails</article-title>
        <source>J Cheminform</source>
        <year>2023</year>
        <volume>15</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1186/s13321-023-00715-x</pub-id>
        <pub-id pub-id-type="pmid">36593523</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Colby</surname>
            <given-names>SM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>ISiCLE: a quantum chemistry pipeline for establishing in silico collision cross section libraries</article-title>
        <source>Anal Chem</source>
        <year>2019</year>
        <volume>91</volume>
        <issue>7</issue>
        <fpage>4346</fpage>
        <lpage>4356</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.analchem.8b04567</pub-id>
        <?supplied-pmid 30741529?>
        <pub-id pub-id-type="pmid">30741529</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sutton</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Identifying domains of applicability of machine learning models for materials science</article-title>
        <source>Nat Commun</source>
        <year>2020</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>4428</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-020-17112-9</pub-id>
        <?supplied-pmid 32887879?>
        <pub-id pub-id-type="pmid">32887879</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Duhrkop</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>SIRIUS 4: a rapid tool for turning tandem mass spectra into metabolite structure information</article-title>
        <source>Nat Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <issue>4</issue>
        <fpage>299</fpage>
        <lpage>302</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-019-0344-8</pub-id>
        <?supplied-pmid 30886413?>
        <pub-id pub-id-type="pmid">30886413</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
