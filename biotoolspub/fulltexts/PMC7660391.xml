<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_PATTER100073 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?properties open_access?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Patterns (N Y)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Patterns (N Y)</journal-id>
    <journal-title-group>
      <journal-title>Patterns</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2666-3899</issn>
    <publisher>
      <publisher-name>Elsevier</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7660391</article-id>
    <article-id pub-id-type="pii">S2666-3899(20)30093-3</article-id>
    <article-id pub-id-type="doi">10.1016/j.patter.2020.100073</article-id>
    <article-id pub-id-type="publisher-id">100073</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>dtoolAI: Reproducibility for Deep Learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au1">
        <name>
          <surname>Hartley</surname>
          <given-names>Matthew</given-names>
        </name>
        <email>matthew.hartley@jic.ac.uk</email>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="fn1" ref-type="fn">2</xref>
        <xref rid="cor1" ref-type="corresp">∗</xref>
      </contrib>
      <contrib contrib-type="author" id="au2">
        <name>
          <surname>Olsson</surname>
          <given-names>Tjelvar S.G.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
      </contrib>
      <aff id="aff1"><label>1</label>Computational Systems Biology, John Innes Centre, Norwich, Norfolk NR4 7UH, UK</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>∗</label>Corresponding author <email>matthew.hartley@jic.ac.uk</email></corresp>
      <fn id="fn1">
        <label>2</label>
        <p id="ntpara0010">Lead Contact</p>
      </fn>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>23</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <day>14</day>
      <month>8</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>23</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <volume>1</volume>
    <issue>5</issue>
    <elocation-id>100073</elocation-id>
    <history>
      <date date-type="received">
        <day>11</day>
        <month>3</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>28</day>
        <month>3</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>30</day>
        <month>6</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2020 The Authors</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="CC BY-NC-ND" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/">
        <license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="abs0010">
      <title>Summary</title>
      <p>Deep learning, a set of approaches using artificial neural networks, has generated rapid recent advancements in machine learning. Deep learning does, however, have the potential to reduce the reproducibility of scientific results. Model outputs are critically dependent on the data and processing approach used to initially generate the model, but this provenance information is usually lost during model training. To avoid a future reproducibility crisis, we need to improve our deep-learning model management. The FAIR principles for data stewardship and software/workflow implementation give excellent high-level guidance on ensuring effective reuse of data and software. We suggest some specific guidelines for the generation and use of deep-learning models in science and explain how these relate to the FAIR principles. We then present dtoolAI, a Python package that we have developed to implement these guidelines. The package implements automatic capture of provenance information during model training and simplifies model distribution.</p>
    </abstract>
    <abstract abstract-type="author-highlights" id="abs0015">
      <title>Highlights</title>
      <p>
        <list list-type="simple" id="ulist0010">
          <list-item id="u0010">
            <label>•</label>
            <p id="p0010">We provide guidelines for improving the reproducibility of deep-learning models</p>
          </list-item>
          <list-item id="u0015">
            <label>•</label>
            <p id="p0015">Our Python package, dtoolAI, is a proof-of-concept implementation of these guidelines</p>
          </list-item>
          <list-item id="u0020">
            <label>•</label>
            <p id="p0020">dtoolAI supports automatic provenance annotation for DL models</p>
          </list-item>
        </list>
      </p>
    </abstract>
    <abstract abstract-type="editor-highlights" id="abs0020">
      <title>The Bigger Picture</title>
      <p>Science has made use of machine learning, a way of teaching computers to understand patterns in data, for a long time. Deep learning, based on the way that real brains process data, has brought enormous improvements in the speed and accuracy of image and language processing over the last few years. However, the “black box” nature of deep-learning models makes scientific analyses that make use of them difficult to reproduce.</p>
      <p>In this work, we show how we might be able to improve long-term reproducibility for data analyses that rely on deep-learning models. We do this by giving guidance on how specific aspects of the FAIR principles for data management can be applied to training and using these models. We also present dtoolAI, a software tool and code library we have developed. We hope that in the future, adoption of our guidelines or similar principles will improve our collective trust in results that arise from deep learning.</p>
    </abstract>
    <abstract abstract-type="teaser" id="abs0025">
      <p>Deep learning has brought impressive advances in our ability to extract information from data. However, models produced by these techniques are often difficult to reproduce or interpret. We provide guidelines for improving the reproducibility of deep-learning models, together with the Python package dtoolAI, a proof-of-concept implementation of these guidelines.</p>
    </abstract>
    <kwd-group id="kwrds0015">
      <title>Keywords</title>
      <kwd>data</kwd>
      <kwd>data management</kwd>
      <kwd>AI</kwd>
      <kwd>artificial intelligence</kwd>
      <kwd>deep learning</kwd>
      <kwd>machine learning</kwd>
      <kwd>reproducibility</kwd>
      <kwd>provenance</kwd>
      <kwd>FAIR data</kwd>
    </kwd-group>
  </article-meta>
  <notes>
    <p id="misc0010">Published: July 23, 2020</p>
  </notes>
</front>
<body>
  <sec id="sec1">
    <title>Introduction</title>
    <p id="p0025">Machine learning (ML) is a discipline involving algorithms, models, and analysis techniques that carry out tasks by making use of patterns in data, with minimal explicit rules. Deep learning (DL) approaches are a subset of ML, which is itself a subdiscipline of more general artificial intelligence.<xref rid="bib1" ref-type="bibr"><sup>1</sup></xref> DL techniques make use of artificial neural networks, simulated systems that mirror aspects of the way that real neurons work. These are responsible for many of the recent advances in ML as a whole, particularly in domains such as image recognition<xref rid="bib2" ref-type="bibr"><sup>2</sup></xref> and natural language processing.<xref rid="bib3" ref-type="bibr"><sup>3</sup></xref> These advances have resulted in great excitement about the possibilities of DL approaches within scientific workflows. Within our own discipline (biology), DL has been applied to a wide range of problems such as cell image segmentation,<xref rid="bib4" ref-type="bibr"><sup>4</sup></xref> genomic variant calling,<xref rid="bib5" ref-type="bibr"><sup>5</sup></xref> and transcription factor binding site prediction,<xref rid="bib6" ref-type="bibr"><sup>6</sup></xref> among others.</p>
    <p id="p0030">Reproducibility is a key pillar of scientific integrity. Results that support hypotheses must be replicable by others, within reasonable parameters.<xref rid="bib7" ref-type="bibr"><sup>7</sup></xref> This reproducibility has come under close scrutiny recently, with initial attention directed toward the reproducibility of studies in psychology<xref rid="bib8" ref-type="bibr"><sup>8</sup></xref> before widening to science as a whole.<xref rid="bib9" ref-type="bibr"><sup>9</sup></xref></p>
    <p id="p0035">The complexity of modern data analysis pipelines complicates reproducibility. Data analysis often involves the application of many different computational tools. The output of these pipelines (and hence the results that support or contradict scientific hypotheses) are often critically dependent on the precise functioning of these tools, which can make reproduction of their results difficult without detailed description of all parts of the pipeline.</p>
    <p id="p0040">While DL holds great potential for faster and more powerful analyses, it also presents a set of new challenges that combine these two problems of analysis pipeline complexity and reproducibility. In this paper, we explain the problems that DL can create. We also discuss how the FAIR principles for software and data have provided solutions to avoid or mitigate these problems in other domains. We then explain our guidelines for implementing specific FAIR principles in the domain of DL and present the software tool we have developed to implement these guidelines.</p>
    <sec id="sec1.1">
      <title>Reproducibility: Concepts and Terminology</title>
      <p id="p0045">Scientific research has always been dependent on our ability to repeat experiments and reproduce their results. As the use of computational approaches has developed, the reproducible research movement for software and data<xref rid="bib10" ref-type="bibr"><sup>10</sup></xref> has grown to become an important part of modern research.<xref rid="bib11" ref-type="bibr"><sup>11</sup></xref></p>
      <p id="p0050">Reproducibility can carry different meanings in the context of science, particularly where computational approaches are concerned. Three similar terms, reproducibility, repeatability, and replicability, are used by different groups in different contexts, often with different sets of meanings. This problem is discussed in depth by the National Academies of Science, Engineering, and Medicine<xref rid="bib11" ref-type="bibr"><sup>11</sup></xref> and Barba.<xref rid="bib12" ref-type="bibr"><sup>12</sup></xref> Here we will clarify our understanding of these terms and explain what we intend by them throughout the paper.</p>
      <p id="p0055">We will use the terms as follows, corresponding to classification B1 in Barba's system:</p>
      <p id="p0060"><italic>Reproducibility</italic> is the ability to regenerate results using the original researchers' data, software, and parameters. <italic>Replicability</italic> is the ability to arrive at the same result using new data. <italic>Repeatability</italic> is the ability to rerun a published analysis pipeline and arrive at the same results (see, e.g., Krishnamurthi and Vitek<xref rid="bib13" ref-type="bibr"><sup>13</sup></xref>).</p>
      <p id="p0065">With this classification, we are most concerned with reproducibility and repeatability. We care about the ability to repeat the generation of a DL model in order to reproduce its results. Since exact weight values (which define the trained model) usually depend on random initialization, we expect only to reproduce a model's results within some given tolerance.</p>
    </sec>
    <sec id="sec1.2">
      <title>Provenance</title>
      <p id="p0070">The provenance of a computational object, such as a trained DL model, is the history of the processes used to produce it, together with their input data.<xref rid="bib14" ref-type="bibr"><sup>14</sup></xref> Provenance is a key pillar of reproducibility, since providing the information necessary to allow analysis to be rerun and artifacts to be regenerated requires recording the processes of creating those artifacts and analyses.</p>
      <p id="p0075">We can distinguish between prospective provenance, whereby we capture the specification for how we will generate data, and retrospective provenance, which captures past data derivation.<xref rid="bib15" ref-type="bibr"><sup>15</sup></xref> When we look at the problems inherent in DL model training, we will be primarily concerned about retrospective provenance. In particular, we will argue that the provenance of a DL model must include the data used to train that model as well as the training parameters and hyperparameters.</p>
    </sec>
    <sec id="sec1.3">
      <title>How Deep Learning Works</title>
      <p id="p0080">A DL model has two parts, a model architecture and a set of model weights.</p>
      <p id="p0085">The model architecture describes the components of the model and how they will take the inputs to the model and transform them to produce outputs. DL models often consist of many layers of artificial neurons. A single model might have tens of thousands of neurons in total, and the architecture describes how these are connected to each other.</p>
      <p id="p0090">Each of these connections can have a different strength, and collectively a set of connection strengths is called model weights. The model architecture and model weights together constitute a usable model.</p>
      <p id="p0095">The process of training a model involves repeatedly supplying the model with data and some instructions as to how the model's response to that data should be used to update the model weights. The end result of this process is a specific set of model weights (<xref rid="fig1" ref-type="fig">Figure 1</xref>).<fig id="fig1"><label>Figure 1</label><caption><p>The DL Model Training Process</p><p>Model training uses a model architecture, weights, and hyperparameters in order to produce model weights. The model architecture and model weights are distributed together as a usable model. Training data and hyperparameters are not, generally, extractable from the model.</p></caption><graphic xlink:href="gr1"/></fig></p>
    </sec>
    <sec id="sec1.4">
      <title>ML and Reproducibility: Data</title>
      <p id="p0100">The first challenge that ML poses to reproducibility involves the training data and the training process. Since model weights depend on training data, and the operation of the model depends on those weights, we cannot reproduce the model without the training data. While the model weights arise from these data, the training process is (in general) not reversible and we cannot extract the data from the weights.</p>
      <p id="p0105">Introductory examples and tutorials in ML often use well-understood and "ready-packaged" datasets such as ImageNet,<xref rid="bib16" ref-type="bibr"><sup>16</sup></xref> CIFAR,<xref rid="bib17" ref-type="bibr"><sup>17</sup></xref> or MNIST.<xref rid="bib18" ref-type="bibr"><sup>18</sup></xref> However, when more specialized models are trained, the input data are usually highly specific, hand-curated datasets. This problem extends beyond reproducibility. The power of ML models lies in their ability to generalize beyond their training data. This generalization is very dependent on the range of those data. Without knowing the data on which a model was trained, it can be difficult to understand what the limitations of the model will be.</p>
    </sec>
    <sec id="sec1.5">
      <title>ML and Reproducibility: Training</title>
      <p id="p0110">While model weights depend on training data, they also depend on the parameters of that training process. These parameters are often referred to as hyperparameters to distinguish them from the model weights themselves. Some of these hyperparameters and other factors that we need to know in order to reproduce models are:<list list-type="simple" id="ulist0015"><list-item id="u0025"><label>•</label><p id="p0115">The loss function used during training. This function determines how the model's performance against data with known results is scored.</p></list-item><list-item id="u0030"><label>•</label><p id="p0120">The type of optimizer used during training. The optimizer determines how the model weights are updated in response to the loss of function.</p></list-item><list-item id="u0035"><label>•</label><p id="p0125">The learning rate applied during the training. This determines how fast model weights are updated in response to the optimizer output.</p></list-item><list-item id="u0040"><label>•</label><p id="p0130">How input data are preprocessed. Often "data augmentation" is applied to training data in image processing networks, for example. This involves applying randomly selected transforms such as rotation, cropping, or zooming to images to prevent the model from learning very specific features of input data.</p></list-item></list></p>
      <p id="p0135">Each of these hyperparameters may have its own parameters—for example, some optimizers have many different parameters, or learning rates might change over the training life cycle.</p>
    </sec>
    <sec id="sec1.6">
      <title>Model Distribution</title>
      <p id="p0140">Training a model is usually a much more expensive operation (in terms of computation cost) than using it. For this reason, models are usually trained on much more specialized computer hardware than that where they are applied. This distribution process needs to transfer both the model architecture and model weights. Models are often updated (i.e., retrained) with new data and these updated model weights also need to be transferred.</p>
    </sec>
    <sec id="sec1.7">
      <title>Current Solutions</title>
      <p id="p0145">Because DL model training and application involves both data and software, existing work on the reproducibility of both is an important step toward developing better DL.</p>
      <sec id="sec1.7.1">
        <title>Data Management</title>
        <p id="p0150">Effective data management in science is an important subdiscipline in its own right, in which substantial progress has been made. The FAIR principles (Findability, Accessibility, Interoperability, Reusability) have crystallized a set of high-level guidelines for how data can be stored in a way that best encourages reproducibility and reuse.<xref rid="bib19" ref-type="bibr"><sup>19</sup></xref></p>
        <p id="p0155">While these high-level principles are a critical overarching guide, they do not provide specific guidance on detailed domain-specific implementation, which is needed in the case of DL. We will discuss how to apply the FAIR principles to DL specifically when we turn to potential improvements to DL reproducibility.</p>
      </sec>
      <sec id="sec1.7.2">
        <title>Software and Workflow</title>
        <p id="p0160">DL models are trained from data, and the model weights produced by their training are also data. However, they require software for instantiation, and are both trained and used as part of wider workflows.</p>
        <p id="p0165">Recent developments have looked at how to incorporate FAIR principles in computational workflows. The challenges of doing this are described in Lamprecht et al.,<xref rid="bib20" ref-type="bibr"><sup>20</sup></xref> and specific suggestions as to how to make FAIR computational workflows in Goble et al.<xref rid="bib21" ref-type="bibr"><sup>21</sup></xref> Steps toward this process include ensuring that the metadata used and generated during workflows are recorded with analysis results and artifacts created. Ivie and Thain<xref rid="bib22" ref-type="bibr"><sup>22</sup></xref> provide a comprehensive overview of the challenges of both the theoretical and practical challenges of creating reproducible workflows. These authors also describe a range of tools, components, and concepts that can be used to solve these problems, at least in part.</p>
        <p id="p0170">Many computational experiments and analyses are carried out by scripts rather than full workflow management systems. Scripts offer a quick and flexible way to get analyses up and running.<xref rid="bib23" ref-type="bibr"><sup>23</sup></xref> However, the lack of a systematic way to manage versions and metadata within scripts can make determining the provenance of results and artifacts more difficult, a problem analyzed in detail by Pimentel et al.<xref rid="bib24" ref-type="bibr"><sup>24</sup></xref></p>
      </sec>
      <sec id="sec1.7.3">
        <title>ML Model Management</title>
        <p id="p0175">There are a number of solutions aimed at managing the process of experimenting with model training in ML. For example, cometML<xref rid="bib25" ref-type="bibr"><sup>25</sup></xref> and similar systems provide online tools for recording training experiments. These tools are primarily aimed at keeping track of model evaluation scores and hyperparameters for different models. This is important for finding the best model architecture and hyperparameters for a given problem, but is a different set of concerns from reproducibility and data provenance.</p>
        <p id="p0180">ML Schema<xref rid="bib26" ref-type="bibr"><sup>26</sup></xref> proposes an ontology for representing ML models and environments. Such a schema is an important step toward developing reproducible DL models if applied within suitable ML model training and application systems.</p>
      </sec>
      <sec id="sec1.7.4">
        <title>Model Distribution</title>
        <p id="p0185">Model distribution is often managed by providing model architecture as source code in a hosting platform such as GitHub, and model weights via cloud storage such as Amazon S3. This provides easy access to the weights but does not provide a mechanism to associate them with the input data that produced them. This is a critical missing piece of the provenance information of that trained model.</p>
      </sec>
    </sec>
    <sec id="sec1.8">
      <title>Summary</title>
      <p id="p0190">
        <list list-type="simple" id="ulist0020">
          <list-item id="u0045">
            <label>•</label>
            <p id="p0195">We cannot reproduce a DL model, or even properly understand its limitations, without access to the data on which it was trained.</p>
          </list-item>
          <list-item id="u0050">
            <label>•</label>
            <p id="p0200">We also need the details of that training process, particularly hyperparameters, to reproduce the model.</p>
          </list-item>
          <list-item id="u0055">
            <label>•</label>
            <p id="p0205">At the moment, model distribution does not usually include these key metadata.</p>
          </list-item>
          <list-item id="u0060">
            <label>•</label>
            <p id="p0210">Currently, most DL models in use are not reproducible, at least by their end users, nor do these models include the provenance information we need to properly understand their strengths and limitations.</p>
          </list-item>
          <list-item id="u0065">
            <label>•</label>
            <p id="p0215">FAIR data and software principles offer high-level solutions to these problems. They have been applied successfully in many domains of computational science, and providing specific implementations for DL would be beneficial.</p>
          </list-item>
        </list>
      </p>
    </sec>
  </sec>
  <sec id="sec2">
    <title>Results</title>
    <sec id="sec2.1">
      <title>Guidelines and Practice</title>
      <p id="p0220">The FAIR principles for data management, and recent developments in adapting and applying these principles to software, scripts, and workflows, provide an excellent framework for developing domain-specific solutions for better reproducibility. In this section, we discuss first the high-level guidelines that we have found useful for applying specific FAIR principles to solve or mitigate the problems we have described above. Second, we present the tool that we have developed to implement these guidelines.</p>
    </sec>
    <sec id="sec2.2">
      <title>Guidelines for Reproducible Deep Learning</title>
      <sec id="sec2.2.1">
        <title>Annotate Model Training Data with Metadata</title>
        <p id="p0225">Good data management practices necessitate that data have appropriate metadata to allow them to be understood.<xref rid="bib27" ref-type="bibr"><sup>27</sup></xref> Since ML models are derived from their input data, we need to ensure that these input data have suitable metadata before models based on them are trained. These metadata should follow a schema appropriate to the setting within which they will be used. Standards such as Bioschemas<xref rid="bib28" ref-type="bibr"><sup>28</sup></xref> provide a good general scheme for biological datasets (with specific adaptations to particular biological domains).</p>
      </sec>
      <sec id="sec2.2.2">
        <title>Give Those Data Persistent URIs</title>
        <p id="p0230">Reproducibility and model data provenance require us to be able to consistently refer to data on which models were trained. Achieving this consistency requires us to be able to refer uniquely to models' input data, which requires unique identifiers.</p>
        <p id="p0235">When models, or their downstream results, are published, the data used to train them should be made publicly available with a persistent identifier. Where possible, ML specific repositories, such as OpenML,<xref rid="bib29" ref-type="bibr"><sup>29</sup></xref> should be used for this to increase discoverability of data. These repositories will require specific schemas which should be kept in mind during model development.</p>
      </sec>
      <sec id="sec2.2.3">
        <title>Capture Training Parameters at Model Training Time</title>
        <p id="p0240">While the data used to train a model are the primary determinant of what that model will do, model and training hyperparameters are also a key input into the model without which the model cannot be reproduced. Hence, it is critical to record those hyperparameters at training time. This should be done using schemas that will be consistent across training and application of multiple models, for example that proposed in ML-Schema,<xref rid="bib26" ref-type="bibr"><sup>26</sup></xref> which includes defining and annotating hyperparameters.</p>
      </sec>
      <sec id="sec2.2.4">
        <title>Store These Training Parameters and Data Inputs Together with the Model</title>
        <p id="p0245">Model hyperparameters are usually defined in the program code used to train the model. While effective tools to manage program source code exist, it is very easy for the information to be either lost or separated from the model. For example, if several updates to the training code are made, each of which results in a different set of parameters and therefore a different model, associating each model with its version of program code is difficult.</p>
        <p id="p0250">Ensuring that we store these parameters together with the model avoids this danger. This means that we require a storage format (or mechanism) for ML models that also incorporates metadata about how they were trained.</p>
      </sec>
      <sec id="sec2.2.5">
        <title>Summary</title>
        <p id="p0255">Together, we can summarize these guidelines as:<list list-type="simple" id="olist0010"><list-item id="o0010"><label>1</label><p id="p0260">Provide appropriate metadata (with domain-appropriate schema) and persistent URIs for model training data.</p></list-item><list-item id="o0015"><label>2</label><p id="p0265">Add this information, together with training hyperparameters, as metadata to the generated model.</p></list-item></list></p>
      </sec>
    </sec>
    <sec id="sec2.3">
      <title>Relationship with the FAIR Principles</title>
      <p id="p0270">These guidelines implement specific aspects of the FAIR principles, giving particular focus to those elements that we consider most critical for the specific problems of DL model training and distribution. Here, we clarify this relationship using the definitions of specific subprinciples in Box 2 of Wilkinson et al.<xref rid="bib19" ref-type="bibr"><sup>19</sup></xref></p>
      <p id="p0275">The FAIR principles that are most important in training DL models in a way that support provenance annotation and reproducibility are:<list list-type="simple" id="ulist0025"><list-item id="u0070"><label>•</label><p id="p0280">F1. (Meta)data are assigned a globally unique and persistent identifier.</p></list-item><list-item id="u0075"><label>•</label><p id="p0285">F2. Data are described with rich metadata.</p></list-item><list-item id="u0080"><label>•</label><p id="p0290">A1. (Meta)data are retrievable by their identifier using a standardized communications protocol.</p></list-item><list-item id="u0085"><label>•</label><p id="p0295">R1. Metadata are richly described with a plurality of accurate and relevant attributes.</p></list-item></list></p>
      <p id="p0300">We require F1 to ensure that DL model training data are persistently identifiable, together with F2 to ensure that model consumers can understand the model's provenance. A1 and R1 allow those metadata to be used by model training software.</p>
      <p id="p0305">When creating a trained model, we also rely on:<list list-type="simple" id="ulist0030"><list-item id="u0090"><label>•</label><p id="p0310">I3. (Meta)data include qualified references to other (meta)data.</p></list-item><list-item id="u0095"><label>•</label><p id="p0315">R1.2. (Meta)data are associated with detailed provenance.</p></list-item></list></p>
      <p id="p0320">I3 ensures that the trained model references its training data, and R1.2, in the context of DL model training, requires encoding training hyperparameters and the details of any data preprocessing applied.</p>
    </sec>
    <sec id="sec2.4">
      <title>Implementation in dtoolAI</title>
      <p id="p0325">To demonstrate application of these guidelines and to improve reproducibility of DL models in both our own work and within our institution, we have developed dtoolAI. To do this, we made use of the existing dtool library<xref rid="bib30" ref-type="bibr"><sup>30</sup></xref> to take advantage of its features.</p>
      <p id="p0330">dtool is a software application programming interface (API) and set of tools to make managing heterogeneous data easier without requiring expensive centralized infrastructure. It provides the ability to annotate data with metadata that is both human readable and programmatically accessible. It also allows attaching unique URIs (Universal Resource Identifiers) to datasets. These URIs can refer to cloud-hosted data (for example, Amazon S3 or Azure storage) allowing datasets to be both uniquely identifiable and widely accessible.</p>
      <p id="p0335">We developed dtoolAI on top of dtool to take advantage of dtool's capabilities for managing metadata programmatically, as well as providing URIs. The key feature of dtoolAI is that it makes it easier to automatically capture data inputs and model hyperparameters at model training time and to distribute those metadata with the model.</p>
    </sec>
    <sec id="sec2.5">
      <title>Code Architecture</title>
      <p id="p0340">In this section, we explain how dtoolAI is arranged and packaged. dtoolAI is a package for the popular Python programming language. Python is widely used in the scientific community. It is an interpreted language and generally slower than compiled languages for direct execution of numerical code. However, most DL model work is carried out with frameworks such as Tensorflow or Pytorch in which actual computation is carried out in highly optimized code written in a compiled language but accessed via a binding language such as Python. dtoolAI uses the Pytorch framework.<xref rid="bib31" ref-type="bibr"><sup>31</sup></xref> This provides the advantages of working with a user-friendly language suitable for rapid development without compromising on execution speed. Another advantage of Python is its simple package management system, pip. We can use this to install dtoolAI with the command line instruction:<list list-type="simple" id="ulist0035"><list-item id="u0100"><p id="p0345">pip install dtoolai</p></list-item></list></p>
      <p id="p0350">dtoolAI then provides a set of useful tools and functions that can be employed by inclusion in Python scripts and programs. The most important are:<list list-type="simple" id="olist0015"><list-item id="o0020"><label>1</label><p id="p0355">A base class that allows encapsulation of data in a form that both dtool and Pytorch understand, together with developed subclasses showing how to use this for image and tensor data.</p></list-item><list-item id="o0025"><label>2</label><p id="p0360">Functions to train a DL model while capturing metadata about the model inputs and training parameters.</p></list-item><list-item id="o0030"><label>3</label><p id="p0365">Classes/functions to use the models trained in this way by applying them either to fully constructed datasets or to individual data, such as images.</p></list-item></list></p>
    </sec>
    <sec id="sec2.6">
      <title>dtoolAI, dtool, and Pytorch</title>
      <p id="p0370">Functionally, dtoolAI acts as a bridge between dtool and Pytorch. Here we explain the relationship between the three libraries, with <xref rid="fig2" ref-type="fig">Figure 2</xref> for illustration.<fig id="fig2"><label>Figure 2</label><caption><p>Relationship between dtoolAI, dtool, and pytorch</p><p>End users of the library interact directly with the dtoolAI code. dtoolAI provides the classes and functions necessary to load model training data, train DL models, and store the resulting models together with key metadata providing the provenance of those models.</p></caption><graphic xlink:href="gr2"/></fig></p>
      <p id="p0375">dtoolAI provides the direct interface for user code. It has responsibility for managing the process of transforming training data and parameters into a trained DL model while capturing training metadata and ensuring that references to input data are maintained.</p>
      <p id="p0380">dtool provides two key functions:<list list-type="simple" id="olist0020"><list-item id="o0035"><label>1</label><p id="p0385">Storage abstraction, in particular the ability for users of dtoolAI to interact with both DL model training data and trained model weights in persistent, world-accessible storage (object storage, or data served via HTTP(S) requests).</p></list-item><list-item id="o0040"><label>2</label><p id="p0390">A programmatic interface for storage and retrieval of both data and metadata associated with a DL model, allowing dtoolAI to programmatically use annotations of input data to guide model training, as well as encode that training process in the trained model objects. This programmatic access allows setting and validation of particular schemas for both for model training data and model metadata.</p></list-item></list></p>
      <p id="p0395">Pytorch provides the core neural network calculation functions for training and application of DL models. dtoolAI provides it with either suitably formatted input data and parameters to train models, or trained model weights and unlabeled data for classification. It can run on either CPU or GPU, allowing for accelerated model training and application.</p>
    </sec>
    <sec id="sec2.7">
      <title>ML Model Workflows</title>
      <p id="p0400">The workflow of using dtoolAI to train, distribute, and use ML models is:<list list-type="simple" id="olist0025"><list-item id="o0045"><label>1</label><p id="p0405">Use dtoolAI's helper functions, or the dtool library itself to create a suitable training dataset annotated with relevant metadata. Through its templating system, dtool allows specification of metadata schemas, to be entered either manually or through its API.</p></list-item><list-item id="o0050"><label>2</label><p id="p0410">Use the provided dtoolAI library functions to train the model, during which process the training data identifiers and chosen training hyperparameters are automatically captured and recorded. The resulting model is another dtool dataset.</p></list-item><list-item id="o0055"><label>3</label><p id="p0415">Use the model, by employing the dtoolAI API functions. The model can be distributed as a self-contained dataset with model weights, training hyperparameters, and references to the original training data.</p></list-item></list></p>
      <p id="p0420">This workflow is illustrated in <xref rid="fig3" ref-type="fig">Figure 3</xref>.<fig id="fig3"><label>Figure 3</label><caption><p>Creating Reproducible Models with dtoolAI</p><p>(1) We first create a dataset that combines both training data and metadata. (2) We then train a model architecture with our training dataset and hyperparameters. The resulting model dataset captures these parameters as well as references to the training data. (3) We can then use the resulting model for predictions or distribute it.</p></caption><graphic xlink:href="gr3"/></fig></p>
      <p id="p0425">When training, it is possible to use more than one dataset to train the model as long as those datasets share the same set of metadata. For example, multiple datasets containing images of flowers could be used to train an image categorization network if each of those datasets provided the same metadata labeling the images.</p>
    </sec>
  </sec>
  <sec id="sec3">
    <title>Discussion</title>
    <p id="p0430">ML approaches have been an integral part of many scientific workflows and analysis pipelines since they were first developed.<xref rid="bib32" ref-type="bibr"><sup>32</sup></xref> DL's impressive achievements in image recognition, natural language processing, and reinforcement learning have already started to translate to scientific advances.<xref rid="bib33" ref-type="bibr"><sup>33</sup></xref> DL models are, however, difficult to interpret. Models operate on input data and produce results, but determining how they produce these results can be very difficult. Understandable ML has become a research field in its own right.<xref rid="bib34" ref-type="bibr"><sup>34</sup></xref></p>
    <p id="p0435">A further problem is possible bias. ML models attempt to generalize the input data they are given. Therefore, if there are biases in the training data for a model, those biases will be reflected in the model's performance on real data. Similarly, if the real data to which the model is applied are too different from its training data, the model may not be able to generalize enough to give good results. These challenges are particularly problematic for scientific applications of ML. We need the results of scientific experiments to be reproducible. We also often apply existing techniques to new sets of data or problem domains and so need to understand the limitations of those techniques.</p>
    <p id="p0440">For all of these reasons, we need our ML models to carry retrospective provenance information with them, particularly unique identifiers for their training data, together with the parameters for preprocessing those data and training the model.</p>
    <p id="p0445">The FAIR principles—Findability, Accessibility, Interoperability, and Reusability—are designed to enhance the reuse of data. While originally developed for data management, recent work has shown how these principles can be adapted to software and workflows.<xref rid="bib20" ref-type="bibr"><sup>20</sup></xref><sup>,</sup><xref rid="bib21" ref-type="bibr"><sup>21</sup></xref> We have provided DL-specific guidance as to how the FAIR principles should be applied to improve reproducibility without compromising the speed of experimentation.</p>
    <p id="p0450">Ensuring that model training data are annotated with appropriate metadata and available at a persistent URI ensures that models trained from those data can reference that URI as part of their provenance information. During that training process, we also need to capture training hyperparameters and any preprocessing applied to the data during training. Together, these aspects of provenance provide sufficient information to reproduce the model within tolerances.</p>
    <p id="p0455">The final step to reproducibility is establishing a self-contained distribution format for ML models that combines both model weights and provenance metadata. Ideally we want both to be able to read these data directly as humans (and cross-reference the training data, so we can better understand the model) and also programmatically, such that model retraining or more detailed analysis of a model's inputs can be performed automatically.</p>
    <p id="p0460">We showed that dtool datasets work well for this purpose: they are a lightweight wrapper around the raw data (in this case model weights) that provide both human- and machine-readable metadata. dtoolAI ties dtool enhanced input data together with dtool output datasets by providing library code and routines for processing these datasets, capturing training parameters and encoding them in the output.</p>
    <sec id="sec3.1">
      <title>Current Limitations and Further Work</title>
      <p id="p0465">It is important to recognize the limitations of our current solution. We have made use of the FAIR principles to improve the reproducibility of workflows based on DL models through automated model provenance annotation. However, we are far from a full FAIR implementation, our focus being immediate reproducibility improvements to DL model training and distribution workflows within research.</p>
      <p id="p0470">Our specific implementation provides only limited interoperability. The trained models produced by dtoolAI can be used only as part of software systems or workflows that either include the dtoolAI library or access the model weights directly through Pytorch. Interoperability of trained DL models is generally limited by the implementation frameworks for those models (i.e., Pytorch models work in Pytorch, Tensorflow models work in Tensorflow). Improving this by better standards for specifying model architectures and training parameters, rather than trained models, would be a possible direction for improvement (essentially focusing on prospective rather than retrospective provenance).</p>
      <p id="p0475">dtoolAI also provides no direct findability. Trained model artifacts produced by the library can be either written directly to widely accessible storage systems or uploaded by dtool, providing a persistent URI for the model. However, this provides no direct discoverability mechanism; the URI must be shared or linked as part of a workflow description. This supports reproducibility by provenance recording, our immediate goal, but not general model sharing. A natural step to improve this would be enforcement of schemas specific to a particular model repository together with code for uploading models to that repository.</p>
      <sec id="sec3.1.1">
        <title>Wider Community Use</title>
        <p id="p0480">Adoption of common practices and standards for metadata and workflows is a community process. Our tool grew out of our development of internal guidelines within our own group and wider institute for managing DL models. Our colleagues who have tested dtoolAI have found considerable benefits for their workflows, particularly in distributing models to others while keeping provenance information for those models.</p>
        <p id="p0485">As a next step, we would like to expand use throughout the wider research software engineering community. As the group within which models must be interoperable grows, the importance of adherence to shared schemas within that group also grows. As community schemas such as Bioschemas or ML-Schema become more widely adopted, the flexible nature of dtoolAI allows end users to decide how rigorously to enforce these schemas, supporting this growth.</p>
      </sec>
      <sec id="sec3.1.2">
        <title>Model Fine-Tuning</title>
        <p id="p0490">A common approach to applying DL networks to problems that are close to the original domain on which the network trained is "fine-tuning." This takes a pretrained model (i.e., an existing set of weights) and modifies them by the application of new training data. Sometimes parts of the model are "frozen," i.e., a subset of weights is not allowed to change.</p>
        <p id="p0495">This works because the structure of DL models results in the early processing of parts of the model learning general features, while the later parts in turn associate these features with categories. We can reuse the general feature parts of the model while learning new categories.</p>
        <p id="p0500">Providing support for tracking both the original training data and later application of subsequent retraining data would allow better understanding of the training history of these models.</p>
      </sec>
      <sec id="sec3.1.3">
        <title>Recording Training Environment</title>
        <p id="p0505">Although we propose recording of training data and parameters, these are, in general, not enough to precisely reproduce model weights, i.e., to produce identical weight values from identical input. This is because model training usually relies on random elements. Initial model weights are usually chosen randomly: the order in which training data are presented to the model is often randomized, and so forth. Model training is also dependent on the specifics of the computing hardware on which training happens. Usually we are more concerned with repeatability than strict reproducibility (see Krishnamurthi and Vitek<xref rid="bib13" ref-type="bibr"><sup>13</sup></xref> for discussion of the distinction); however, there are some circumstances whereby we may wish to be able to specify more rigorously for reproduction.</p>
        <p id="p0510">It is usually impractical to replicate the whole hardware environment in which a model was trained. However, we could at least record the details of this environment for future reference. The challenges of doing so are discussed in detail by Ivie and Thain.<xref rid="bib22" ref-type="bibr"><sup>22</sup></xref></p>
      </sec>
    </sec>
    <sec id="sec3.2">
      <title>Conclusion</title>
      <p id="p0515">Progress in science relies on reproducibility. Without the ability to verify and repeat results, we cannot establish scientific consensus. ML, particularly recent advances in the DL family of techniques, has brought enormous advances in speed and accuracy to a range of data-processing problems. These techniques show great promise for application to scientific analyses. However, without careful attention to how retrospective provenance information is captured during model training and distributed together with models, they also pose a substantial risk of reducing the reproducibility of those analyses and introducing bias.</p>
      <p id="p0520">Managing DL data and models is both a software and data problem. The FAIR data principles provide core guidance on management of computational data. Recent developments in adaptation of those principles to workflows and individual software components are pointing the way toward computationally based science that embraces reproducibility and repeatability.</p>
      <p id="p0525">To apply these advances to the domain of DL requires specifying how these principles should be implemented for DL model training and distribution workflows. We have suggested specific guidelines, linked to the FAIR principles, for how to do this. These guidelines involve annotation of model training data with appropriate metadata, ensuring that those training data have persistent identifiers recording training hyperparameters and storing and distributing models in a form that retains all of this information.</p>
      <p id="p0530">We have also developed a set of tools that allow practical application of these guidelines. dtoolAI, a Python library, makes use of dtool for the formation of training data into datasets with metadata (including the specification of suitable schemas) and persistent identifiers. It then enables easy recording of training hyperparameters and input dataset identifiers in a form that automatically stores those data together with model weights, giving a packaged artifact that includes key provenance information. The artifact can then be easily distributed and its metadata can be programmatically accessed.</p>
      <p id="p0535">dtoolAI has improved the reproducibility of the ML workflows we have built on top of it, and we hope it will do the same for others.</p>
    </sec>
  </sec>
  <sec id="sec4">
    <title>Experimental Procedures</title>
    <sec id="sec4.1">
      <title>Resource Availability</title>
      <sec id="sec4.1.1">
        <title>Lead Contact</title>
        <p id="p0540">Matthew Hartley, <ext-link ext-link-type="uri" xlink:href="mailto:Matthew.Hartley@jic.ac.uk" id="intref0010">Matthew.Hartley@jic.ac.uk</ext-link> is the lead contact for this work.</p>
      </sec>
      <sec id="sec4.1.2">
        <title>Materials Availability</title>
        <p id="p0545">This work generated no non-code materials.</p>
      </sec>
      <sec sec-type="data-availability" id="sec4.1.3">
        <title>Data and Code Availability</title>
        <p id="p0550">All code associated with the work is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/jic-csb/dtoolai" id="intref0015">https://github.com/jic-csb/dtoolai</ext-link>.</p>
      </sec>
    </sec>
    <sec id="sec4.2">
      <title>dtoolAI Workflows</title>
      <p id="p0555">In the <xref rid="sec2" ref-type="sec">Results</xref> section, we explained the internal architecture and design of dtoolAI. Here we will look at some examples of how we can use it to generate reproducible ML models. Examples in this paper consist of short snippets to highlight features; full code examples are provided in the dtoolAI repository on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/jic-csb/dtoolai" id="intref0020">https://github.com/jic-csb/dtoolai</ext-link>) in the form of scripts and Jupyter notebooks, as well as library code documentation and examples of use at <ext-link ext-link-type="uri" xlink:href="https://dtoolai.readthedocs.io" id="intref0025">https://dtoolai.readthedocs.io</ext-link>.</p>
      <sec id="sec4.2.1">
        <title>Training a Simple Model</title>
        <p id="p0560">In this example, we will look at a common neural network tutorial example, recognition of handwritten digits from the MNIST dataset. In this case, we have already marked up the MNIST dataset with the metadata we need to be able to train from it directly.</p>
        <p id="p0565">Firstly, we will look at how we load the data from a persistent identifier.<list list-type="simple" id="ulist0040"><list-item id="u0105"><p id="p0570">train_dataset_uri = "<ext-link ext-link-type="uri" xlink:href="http://bit.ly/2NVFGQd" id="intref0030">http://bit.ly/2NVFGQd</ext-link>"</p></list-item><list-item id="u0110"><p id="p0575">train_ds = TensorDataSet(train_dataset_uri)</p></list-item></list></p>
        <p id="p0580">This code uses the data URI ("<ext-link ext-link-type="uri" xlink:href="http://bit.ly/2NVFGQd" id="intref0035">http://bit.ly/2NVFGQd</ext-link>") to load the data. After defining a model, loss function, and optimizer, we can then train a network from this dataset:<list list-type="simple" id="ulist0045"><list-item id="u0115"><p id="p0585">model = GenNet(∗∗params.init_params)</p></list-item><list-item id="u0120"><p id="p0590">loss_fn = torch.nn.NLLLoss()</p></list-item><list-item id="u0125"><p id="p0595">optimiser = torch.optim.SGD(model.parameters(), lr=params.learning_rate)</p></list-item><list-item id="u0130"><p id="p0600">with DerivedDataSet(base_uri, "mnist_model", train_ds) as output_ds:</p></list-item><list-item id="u0135"><p id="p0605"> train_model_with_metadata_capture(</p></list-item><list-item id="u0140"><p id="p0610"> model,</p></list-item><list-item id="u0145"><p id="p0615"> tds_train,</p></list-item><list-item id="u0150"><p id="p0620"> optimiser,</p></list-item><list-item id="u0155"><p id="p0625"> loss_fn,</p></list-item><list-item id="u0160"><p id="p0630"> params,</p></list-item><list-item id="u0165"><p id="p0635"> output_ds</p></list-item><list-item id="u0170"><p id="p0640">)</p></list-item></list></p>
        <p id="p0645">This constructs the output network as a dataset. When we run this code, the output will be a trained model dataset, with name mnist_model and stored at the base URI base_uri. Metadata about the training data and the parameters used for training (contained in the params object) are recorded in this dataset and can be viewed either through the dtool API or using a helper script, dtoolai-provenance, provided:<list list-type="simple" id="ulist0050"><list-item id="u0175"><p id="p0650">$ dtoolai-provenance example/mnistcnn/</p></list-item><list-item id="u0180"><p id="p0655">Network architecture name: dtoolai.simpleScalingCNN</p></list-item><list-item id="u0185"><p id="p0660">Model training parameters: {'batch_size': 128,</p></list-item><list-item id="u0190"><p id="p0665">'init_params': {'input_channels': 1, 'input_dim': 28},</p></list-item><list-item id="u0195"><p id="p0670">'input_channels': 1,</p></list-item><list-item id="u0200"><p id="p0675">'input_dim': 28,</p></list-item><list-item id="u0205"><p id="p0680">'learning_rate': 0.01,</p></list-item><list-item id="u0210"><p id="p0685">'loss_func': 'NLLLoss',</p></list-item><list-item id="u0215"><p id="p0690">'n_epochs': 1,</p></list-item><list-item id="u0220"><p id="p0695">'optimiser_name': 'SGD'}</p></list-item><list-item id="u0225"><p id="p0700">Source dataset URI: <ext-link ext-link-type="uri" xlink:href="http://bit.ly/2uqXxrk" id="intref0040">http://bit.ly/2uqXxrk</ext-link></p></list-item><list-item id="u0230"><p id="p0705">Source dataset name: mnist.train</p></list-item><list-item id="u0235"><p id="p0710">Source dataset readme:</p></list-item><list-item id="u0240"><p id="p0715">---</p></list-item><list-item id="u0245"><p id="p0720">dataset_name: MNIST handwritten digits</p></list-item><list-item id="u0250"><p id="p0725">project: dtoolAI demonstration datasets</p></list-item><list-item id="u0255"><p id="p0730">authors:</p></list-item><list-item id="u0260"><p id="p0735">- Yann LeCun</p></list-item><list-item id="u0265"><p id="p0740">- Corinna Cortes</p></list-item><list-item id="u0270"><p id="p0745">- Christopher J.C. Burges</p></list-item><list-item id="u0275"><p id="p0750">origin: <ext-link ext-link-type="uri" xlink:href="http://yann.lecun.com/exdb/mnist/" id="intref0045">http://yann.lecun.com/exdb/mnist/</ext-link></p></list-item><list-item id="u0280"><p id="p0755">usetype: train</p></list-item></list></p>
        <p id="p0760">We can see how the name, unique identifier (UUID), and persistent resource identifier (URI) are part of the model metadata, as well as the training parameters. We also see how we can train a model from the input data without having to explicitly download it. This helps the practical process of reproducibility.</p>
      </sec>
      <sec id="sec4.2.2">
        <title>Using the Model</title>
        <p id="p0765">Our model can now be used as part of an analysis script. We can use dtoolAI's model helper class, TrainedTorchModel to load the model from a URI and apply it:<list list-type="simple" id="ulist0055"><list-item id="u0285"><p id="p0770">model = TrainedTorchModel("<ext-link ext-link-type="uri" xlink:href="http://bit.ly/2tbPzSB" id="intref0050">http://bit.ly/2tbPzSB</ext-link>")</p></list-item></list></p>
        <p id="p0775">This will automatically download the model weights and load the model into memory. We can then apply the model with:<list list-type="simple" id="ulist0060"><list-item id="u0290"><p id="p0780">my_image = Image.open("handwritten_8.png")</p></list-item><list-item id="u0295"><p id="p0785">result = model.convert_and_predict(my_image)</p></list-item><list-item id="u0300"><p id="p0790">print(f"Classified image as {result}")</p></list-item></list></p>
        <p id="p0795">We can also access the model's history:<list list-type="simple" id="ulist0065"><list-item id="u0305"><p id="p0800">print(model.get_readme_content())</p></list-item></list>in which we would see the same data that were accessible to us after we trained the model.</p>
      </sec>
      <sec id="sec4.2.3">
        <title>Filesystem URIs and File Paths</title>
        <p id="p0805">In general, when we create model training datasets and trained models, we want to store these in permanent HTTP accessible object storage with persistent URIs. However, since this requires setting up Amazon S3 or Microsoft Azure storage credentials, for simplicity we can work with filesystem URIs in some of these examples.</p>
        <p id="p0810">For convenience's sake, we allow file URIs to be expressed as filesystem paths, such that file:///path/to/data can be addressed simply as /path/to/data/ and dtool will internally convert this into a full URI. When working with real data and models, we can either write directly to HTTP addressable object storage or upload our local filesystem data after creation using dtool, both of which result in persistent URIs.</p>
      </sec>
      <sec id="sec4.2.4">
        <title>Training a New Model with New Data</title>
        <p id="p0815">Now we will look at how we can train a model on novel data. To do this, we will firstly see how to mark up that data as a dataset. The dtoolAI package provides a helper script create-image-dataset-from-dirtree to create an input dataset from a directory of images. For example, if we have the following images:<list list-type="simple" id="ulist0070"><list-item id="u0310"><p id="p0820">$ tree image_dirtree/</p></list-item><list-item id="u0315"><p id="p0825">image_dirtree/</p></list-item><list-item id="u0320"><p id="p0830">|-- car</p></list-item><list-item id="u0325"><p id="p0835">| |-- image0001.jpg</p></list-item><list-item id="u0330"><p id="p0840">| `-- image0002.jpg</p></list-item><list-item id="u0335"><p id="p0845">|-- chair</p></list-item><list-item id="u0340"><p id="p0850">| |-- image0001.jpg</p></list-item><list-item id="u0345"><p id="p0855">| `-- image0002.jpg</p></list-item><list-item id="u0350"><p id="p0860">`-- mug</p></list-item><list-item id="u0355"><p id="p0865"> |-- image0001.jpg</p></list-item><list-item id="u0360"><p id="p0870"> `-- image0002.jpg</p></list-item></list></p>
        <p id="p0875">We can then run:<list list-type="simple" id="ulist0075"><list-item id="u0365"><p id="p0880">$ create-image-dataset-from-dirtree image_dirtree base_uri objects</p></list-item><list-item id="u0370"><p id="p0885">Created image dataset at base_uri/objects</p></list-item></list></p>
        <p id="p0890">This will create a training dataset at the base URI "base_uri" with the name "objects." For testing and development purposes, we can use file URIs, for creating distributable persistent models, we would use HTTP accessible object storage. Now we use a very similar training script to the one we saw for training on the MNIST data:<list list-type="simple" id="ulist0080"><list-item id="u0375"><p id="p0895">train_ds = ImageDataSet("base_uri/objects")</p></list-item><list-item id="u0380"><p id="p0900">model = GenNet(∗∗params.init_params)</p></list-item><list-item id="u0385"><p id="p0905">loss_fn = torch.nn.NLLLoss()</p></list-item><list-item id="u0390"><p id="p0910">optimiser = torch.optim.SGD(model.parameters(), lr=params.learning_rate)</p></list-item><list-item id="u0395"><p id="p0915">with DerivedDataSet(base_uri, "objects_model", train_ds) as output_ds:</p></list-item><list-item id="u0400"><p id="p0920"> train_model_with_metadata_capture(</p></list-item><list-item id="u0405"><p id="p0925"> model,</p></list-item><list-item id="u0410"><p id="p0930"> tds_train,</p></list-item><list-item id="u0415"><p id="p0935"> optimiser,</p></list-item><list-item id="u0420"><p id="p0940"> loss_fn,</p></list-item><list-item id="u0425"><p id="p0945"> params,</p></list-item><list-item id="u0430"><p id="p0950"> output_ds</p></list-item><list-item id="u0435"><p id="p0955">)</p></list-item></list></p>
        <p id="p0960">This will train a classifier and save the trained model, references to our input data, and training metadata.</p>
      </sec>
    </sec>
  </sec>
</body>
<back>
  <ref-list id="cebib0010">
    <title>References</title>
    <ref id="bib1">
      <label>1</label>
      <element-citation publication-type="journal" id="sref1">
        <person-group person-group-type="author">
          <name>
            <surname>LeCun</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Deep learning</article-title>
        <source>Nature</source>
        <volume>521</volume>
        <year>2015</year>
        <fpage>436</fpage>
        <lpage>444</lpage>
        <pub-id pub-id-type="pmid">26017442</pub-id>
      </element-citation>
    </ref>
    <ref id="bib2">
      <label>2</label>
      <element-citation publication-type="journal" id="sref2">
        <person-group person-group-type="author">
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G.E.</given-names>
          </name>
        </person-group>
        <article-title>ImageNet classification with deep convolutional neural networks</article-title>
        <source>Commun. ACM</source>
        <volume>60</volume>
        <year>2017</year>
        <fpage>84</fpage>
        <lpage>90</lpage>
      </element-citation>
    </ref>
    <ref id="bib3">
      <label>3</label>
      <element-citation publication-type="journal" id="sref3">
        <person-group person-group-type="author">
          <name>
            <surname>Collobert</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Weston</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Bottou</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Karlen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Kavukcuoglu</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Kuksa</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>Natural language processing (almost) from scratch</article-title>
        <source>J. Machine Learn. Res.</source>
        <volume>12</volume>
        <year>2011</year>
        <fpage>2493</fpage>
        <lpage>2537</lpage>
      </element-citation>
    </ref>
    <ref id="bib4">
      <label>4</label>
      <element-citation publication-type="journal" id="sref4">
        <person-group person-group-type="author">
          <name>
            <surname>Ronneberger</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Fischer</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Brox</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>U-Net: convolutional networks for biomedical image segmentation</article-title>
        <source>arXiv</source>
        <year>2015</year>
        <comment>1505.04597 [cs]</comment>
      </element-citation>
    </ref>
    <ref id="bib5">
      <label>5</label>
      <element-citation publication-type="journal" id="sref5">
        <person-group person-group-type="author">
          <name>
            <surname>Poplin</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>P.-C.</given-names>
          </name>
          <name>
            <surname>Alexander</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Schwartz</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Colthurst</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Ku</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Newburger</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Dijamco</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Afshar</surname>
            <given-names>P.T.</given-names>
          </name>
        </person-group>
        <article-title>A universal SNP and small-indel variant caller using deep neural networks</article-title>
        <source>Nat. Biotechnol.</source>
        <volume>36</volume>
        <year>2018</year>
        <fpage>983</fpage>
        <lpage>987</lpage>
        <pub-id pub-id-type="pmid">30247488</pub-id>
      </element-citation>
    </ref>
    <ref id="bib6">
      <label>6</label>
      <element-citation publication-type="journal" id="sref6">
        <person-group person-group-type="author">
          <name>
            <surname>Angermueller</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Pärnamaa</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Parts</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Stegle</surname>
            <given-names>O.</given-names>
          </name>
        </person-group>
        <article-title>Deep learning for computational biology</article-title>
        <source>Mol. Syst. Biol.</source>
        <volume>12</volume>
        <year>2016</year>
        <fpage>878</fpage>
        <pub-id pub-id-type="pmid">27474269</pub-id>
      </element-citation>
    </ref>
    <ref id="bib7">
      <label>7</label>
      <element-citation publication-type="journal" id="sref7">
        <person-group person-group-type="author">
          <name>
            <surname>Sandve</surname>
            <given-names>G.K.</given-names>
          </name>
          <name>
            <surname>Nekrutenko</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Taylor</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Hovig</surname>
            <given-names>E.</given-names>
          </name>
        </person-group>
        <article-title>Ten simple rules for reproducible computational research</article-title>
        <source>PLoS Comput. Biol.</source>
        <volume>9</volume>
        <year>2013</year>
        <fpage>e1003285</fpage>
        <pub-id pub-id-type="pmid">24204232</pub-id>
      </element-citation>
    </ref>
    <ref id="bib8">
      <label>8</label>
      <element-citation publication-type="journal" id="sref8">
        <person-group person-group-type="author">
          <name>
            <surname>Aarts</surname>
            <given-names>A.A.</given-names>
          </name>
          <name>
            <surname>Anderson</surname>
            <given-names>J.E.</given-names>
          </name>
          <name>
            <surname>Anderson</surname>
            <given-names>C.J.</given-names>
          </name>
          <name>
            <surname>Attridge</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Attwood</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Axt</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Babel</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Bahnik</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Baranski</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Barnett-Cowan</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Estimating the reproducibility of psychological science</article-title>
        <source>Science</source>
        <volume>349</volume>
        <year>2015</year>
        <fpage>943</fpage>
        <lpage>950</lpage>
      </element-citation>
    </ref>
    <ref id="bib9">
      <label>9</label>
      <element-citation publication-type="journal" id="sref9">
        <person-group person-group-type="author">
          <name>
            <surname>Fanelli</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Costas</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Ioannidis</surname>
            <given-names>J.P.A.</given-names>
          </name>
        </person-group>
        <article-title>Meta-assessment of bias in science</article-title>
        <source>Proc. Natl. Acad. Sci. U S A</source>
        <volume>114</volume>
        <year>2017</year>
        <fpage>3714</fpage>
        <lpage>3719</lpage>
        <pub-id pub-id-type="pmid">28320937</pub-id>
      </element-citation>
    </ref>
    <ref id="bib10">
      <label>10</label>
      <element-citation publication-type="book" id="sref10">
        <person-group person-group-type="author">
          <name>
            <surname>Claerbout</surname>
            <given-names>J.F.</given-names>
          </name>
          <name>
            <surname>Karrenbach</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <chapter-title>Electronic documents give reproducible research a new meaning</chapter-title>
        <source>SEG Technical Program Expanded Abstracts 1992 SEG Technical Program Expanded Abstracts</source>
        <year>1992</year>
        <publisher-name>Society of Exploration Geophysicists</publisher-name>
        <fpage>601</fpage>
        <lpage>604</lpage>
      </element-citation>
    </ref>
    <ref id="bib11">
      <label>11</label>
      <element-citation publication-type="book" id="sref11">
        <person-group person-group-type="author">
          <collab>Committee on Reproducibility and Replicability in Science</collab>
          <collab>Board on Behavioral, Cognitive, and Sensory Sciences</collab>
          <collab>Committee on National Statistics</collab>
          <collab>Division of Behavioral and Social Sciences and Education</collab>
          <collab>Nuclear and Radiation Studies Board</collab>
          <collab>Division on Earth and Life Studies</collab>
          <collab>Board on Mathematical Sciences and Analytics</collab>
          <collab>Committee on Applied and Theoretical Statistics</collab>
          <collab>Division on Engineering and Physical Sciences</collab>
          <collab>Board on Research Data and Information</collab>
        </person-group>
        <chapter-title>Reproducibility and Replicability in Science</chapter-title>
        <year>2019</year>
        <publisher-name>National Academies Press</publisher-name>
      </element-citation>
    </ref>
    <ref id="bib12">
      <label>12</label>
      <element-citation publication-type="journal" id="sref12">
        <person-group person-group-type="author">
          <name>
            <surname>Barba</surname>
            <given-names>L.A.</given-names>
          </name>
        </person-group>
        <article-title>Terminologies for reproducible research</article-title>
        <source>arXiv</source>
        <year>2018</year>
        <comment>1802.03311 [cs]</comment>
      </element-citation>
    </ref>
    <ref id="bib13">
      <label>13</label>
      <element-citation publication-type="journal" id="sref13">
        <person-group person-group-type="author">
          <name>
            <surname>Krishnamurthi</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Vitek</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>The real software crisis: repeatability as a core value</article-title>
        <source>Commun. ACM</source>
        <volume>58</volume>
        <year>2015</year>
        <fpage>34</fpage>
        <lpage>36</lpage>
      </element-citation>
    </ref>
    <ref id="bib14">
      <label>14</label>
      <element-citation publication-type="journal" id="sref14">
        <person-group person-group-type="author">
          <name>
            <surname>Moreau</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Groth</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Miles</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Vazquez-Salceda</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Ibbotson</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Munroe</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Rana</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Schreiber</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Tan</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>The provenance of electronic data</article-title>
        <source>Commun. ACM</source>
        <volume>51</volume>
        <year>2008</year>
        <fpage>52</fpage>
        <lpage>58</lpage>
      </element-citation>
    </ref>
    <ref id="bib15">
      <label>15</label>
      <element-citation publication-type="book" id="sref15">
        <person-group person-group-type="author">
          <name>
            <surname>Lim</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Chebotko</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Fotouhi</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <chapter-title>Prospective and retrospective provenance collection in scientific workflow environments</chapter-title>
        <source>2010 IEEE International Conference on Services Computing</source>
        <year>2010</year>
        <fpage>449</fpage>
        <lpage>456</lpage>
      </element-citation>
    </ref>
    <ref id="bib16">
      <label>16</label>
      <element-citation publication-type="book" id="sref16">
        <person-group person-group-type="author">
          <name>
            <surname>Deng</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Dong</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Socher</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Kai</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>F.F.</given-names>
          </name>
        </person-group>
        <chapter-title>ImageNet: a large-scale hierarchical image database</chapter-title>
        <source>2009 IEEE Conference on Computer Vision and Pattern Recognition</source>
        <year>2009</year>
        <publisher-name>IEEE</publisher-name>
        <fpage>248</fpage>
        <lpage>255</lpage>
      </element-citation>
    </ref>
    <ref id="bib17">
      <label>17</label>
      <element-citation publication-type="book" id="sref17">
        <person-group person-group-type="author">
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <chapter-title>Learning Multiple Layers of Features from Tiny Images. Technical Report TR-2009</chapter-title>
        <year>2009</year>
        <publisher-name>University of Toronto</publisher-name>
        <ext-link ext-link-type="uri" xlink:href="https://www.cs.toronto.edu/%7Ekriz/learning-features-2009-TR.pdf" id="intref0055">https://www.cs.toronto.edu/∼kriz/learning-features-2009-TR.pdf</ext-link>
      </element-citation>
    </ref>
    <ref id="bib18">
      <label>18</label>
      <element-citation publication-type="journal" id="sref18">
        <person-group person-group-type="author">
          <name>
            <surname>Lecun</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Bottou</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Haffner</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>Gradient-based learning applied to document recognition</article-title>
        <source>Proc. IEEE</source>
        <volume>86</volume>
        <year>1998</year>
        <fpage>2278</fpage>
        <lpage>2324</lpage>
      </element-citation>
    </ref>
    <ref id="bib19">
      <label>19</label>
      <element-citation publication-type="journal" id="sref19">
        <person-group person-group-type="author">
          <name>
            <surname>Wilkinson</surname>
            <given-names>M.D.</given-names>
          </name>
          <name>
            <surname>Dumontier</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Aalbersberg</surname>
            <given-names>I.J.</given-names>
          </name>
          <name>
            <surname>Appleton</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Axton</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Baak</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Blomberg</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Boiten</surname>
            <given-names>J.-W.</given-names>
          </name>
          <name>
            <surname>da Silva Santos</surname>
            <given-names>L.B.</given-names>
          </name>
          <name>
            <surname>Bourne</surname>
            <given-names>P.E.</given-names>
          </name>
        </person-group>
        <article-title>The FAIR Guiding Principles for scientific data management and stewardship</article-title>
        <source>Sci. Data</source>
        <volume>3</volume>
        <year>2016</year>
        <fpage>160018</fpage>
        <pub-id pub-id-type="pmid">26978244</pub-id>
      </element-citation>
    </ref>
    <ref id="bib20">
      <label>20</label>
      <element-citation publication-type="journal" id="sref20">
        <person-group person-group-type="author">
          <name>
            <surname>Lamprecht</surname>
            <given-names>A.-L.</given-names>
          </name>
          <name>
            <surname>Garcia</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Kuzak</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Martinez</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Arcila</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Martin Del Pico</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Dominguez Del Angel</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>van de Sandt</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Ison</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Martinez</surname>
            <given-names>P.A.</given-names>
          </name>
        </person-group>
        <article-title>Towards FAIR principles for research software</article-title>
        <source>Data Sci.</source>
        <volume>3</volume>
        <year>2020</year>
        <fpage>37</fpage>
        <lpage>59</lpage>
      </element-citation>
    </ref>
    <ref id="bib21">
      <label>21</label>
      <element-citation publication-type="journal" id="sref21">
        <person-group person-group-type="author">
          <name>
            <surname>Goble</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Cohen-Boulakia</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Soiland-Reyes</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Garijo</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Gil</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Crusoe</surname>
            <given-names>M.R.</given-names>
          </name>
          <name>
            <surname>Peters</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Schober</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>FAIR computational workflows</article-title>
        <source>Data Intelligence</source>
        <volume>2</volume>
        <year>2019</year>
        <fpage>108</fpage>
        <lpage>121</lpage>
      </element-citation>
    </ref>
    <ref id="bib22">
      <label>22</label>
      <element-citation publication-type="journal" id="sref22">
        <person-group person-group-type="author">
          <name>
            <surname>Ivie</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Thain</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Reproducibility in scientific computing</article-title>
        <source>ACM Comput. Surv.</source>
        <volume>51</volume>
        <year>2018</year>
        <pub-id pub-id-type="doi">10.1145/3186266</pub-id>
      </element-citation>
    </ref>
    <ref id="bib23">
      <label>23</label>
      <element-citation publication-type="journal" id="sref23">
        <person-group person-group-type="author">
          <name>
            <surname>Leipzig</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>A review of bioinformatic pipeline frameworks</article-title>
        <source>Brief. Bioinform.</source>
        <volume>18</volume>
        <year>2017</year>
        <fpage>530</fpage>
        <lpage>536</lpage>
        <pub-id pub-id-type="pmid">27013646</pub-id>
      </element-citation>
    </ref>
    <ref id="bib24">
      <label>24</label>
      <element-citation publication-type="journal" id="sref24">
        <person-group person-group-type="author">
          <name>
            <surname>Pimentel</surname>
            <given-names>J.F.</given-names>
          </name>
          <name>
            <surname>Freire</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Murta</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Braganholo</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>A survey on collecting, managing, and analyzing provenance from scripts</article-title>
        <source>ACM Comput. Surv.</source>
        <volume>52</volume>
        <year>2019</year>
        <pub-id pub-id-type="doi">10.1145/3311955</pub-id>
      </element-citation>
    </ref>
    <ref id="bib25">
      <label>25</label>
      <element-citation publication-type="other" id="sref25">
        <person-group person-group-type="author">
          <collab>Comet.ml</collab>
        </person-group>
        <article-title>Comet.ml: supercharging machine learning</article-title>
        <ext-link ext-link-type="uri" xlink:href="https://medium.com/comet-ml" id="intref0060">https://medium.com/comet-ml</ext-link>
        <year>2019</year>
      </element-citation>
    </ref>
    <ref id="bib26">
      <label>26</label>
      <element-citation publication-type="journal" id="sref26">
        <person-group person-group-type="author">
          <name>
            <surname>Publio</surname>
            <given-names>G.C.</given-names>
          </name>
          <name>
            <surname>Esteves</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Ławrynowicz</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Panov</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Soldatova</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Soru</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Vanschoren</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zafar</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <article-title>ML-schema: exposing the semantics of machine learning with schemas and ontologies</article-title>
        <source>arXiv</source>
        <year>2018</year>
        <comment>1807.05351 [cs, stat]</comment>
      </element-citation>
    </ref>
    <ref id="bib27">
      <label>27</label>
      <element-citation publication-type="journal" id="sref27">
        <person-group person-group-type="author">
          <name>
            <surname>Goodman</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Pepe</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Blocker</surname>
            <given-names>A.W.</given-names>
          </name>
          <name>
            <surname>Borgman</surname>
            <given-names>C.L.</given-names>
          </name>
          <name>
            <surname>Cranmer</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Crosas</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Stefano</surname>
            <given-names>R.D.</given-names>
          </name>
          <name>
            <surname>Gil</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Groth</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Hedstrom</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Ten simple rules for the care and feeding of scientific data</article-title>
        <source>PLoS Comput. Biol.</source>
        <volume>10</volume>
        <year>2014</year>
        <fpage>e1003542</fpage>
        <pub-id pub-id-type="pmid">24763340</pub-id>
      </element-citation>
    </ref>
    <ref id="bib28">
      <label>28</label>
      <element-citation publication-type="book" id="sref28">
        <person-group person-group-type="author">
          <name>
            <surname>Gray</surname>
            <given-names>A.J.G.</given-names>
          </name>
          <name>
            <surname>Goble</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Jimenez</surname>
          </name>
        </person-group>
        <chapter-title>Bioschemas: from potato salad to protein annotation</chapter-title>
        <source>16th International Semantic Web Conference</source>
        <year>2017</year>
        <ext-link ext-link-type="uri" xlink:href="https://iswc2017.ai.wu.ac.at/wp-content/uploads/papers/PostersDemos/paper579.pdf" id="intref0065">https://iswc2017.ai.wu.ac.at/wp-content/uploads/papers/PostersDemos/paper579.pdf</ext-link>
      </element-citation>
    </ref>
    <ref id="bib29">
      <label>29</label>
      <element-citation publication-type="journal" id="sref29">
        <person-group person-group-type="author">
          <name>
            <surname>Vanschoren</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>van Rijn</surname>
            <given-names>J.N.</given-names>
          </name>
          <name>
            <surname>Bischl</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Torgo</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>OpenML: networked science in machine learning</article-title>
        <source>ACM SIGKDD Explor. Newsl.</source>
        <volume>15</volume>
        <year>2014</year>
        <fpage>49</fpage>
        <lpage>60</lpage>
      </element-citation>
    </ref>
    <ref id="bib30">
      <label>30</label>
      <element-citation publication-type="journal" id="sref30">
        <person-group person-group-type="author">
          <name>
            <surname>Olsson</surname>
            <given-names>T.S.G.</given-names>
          </name>
          <name>
            <surname>Hartley</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Lightweight data management with dtool</article-title>
        <source>PeerJ</source>
        <volume>7</volume>
        <year>2019</year>
        <fpage>e6562</fpage>
        <pub-id pub-id-type="pmid">30867992</pub-id>
      </element-citation>
    </ref>
    <ref id="bib31">
      <label>31</label>
      <element-citation publication-type="book" id="sref31">
        <person-group person-group-type="author">
          <name>
            <surname>Paszke</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Gross</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Massa</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Lerer</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Bradbury</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Chanan</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Killeen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Gimelshein</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Antiga</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <chapter-title>PyTorch: an imperative style, high-performance deep learning library</chapter-title>
        <person-group person-group-type="editor">
          <name>
            <surname>Wallach</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Larochelle</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Beygelzimer</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Alché-Buc</surname>
            <given-names>F.D.</given-names>
          </name>
          <name>
            <surname>Fox</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Garnett</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <source>Advances in Neural Information Processing Systems 32</source>
        <year>2019</year>
        <publisher-name>Curran Associates</publisher-name>
        <fpage>8024</fpage>
        <lpage>8035</lpage>
      </element-citation>
    </ref>
    <ref id="bib32">
      <label>32</label>
      <element-citation publication-type="journal" id="sref32">
        <person-group person-group-type="author">
          <name>
            <surname>Rosenblatt</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>The perceptron: a probabilistic model for information storage and organization in the brain</article-title>
        <source>Psychol. Rev.</source>
        <volume>65</volume>
        <year>1958</year>
        <fpage>386</fpage>
        <lpage>408</lpage>
        <pub-id pub-id-type="pmid">13602029</pub-id>
      </element-citation>
    </ref>
    <ref id="bib33">
      <label>33</label>
      <element-citation publication-type="journal" id="sref33">
        <person-group person-group-type="author">
          <name>
            <surname>Hutson</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Bringing machine learning to the masses</article-title>
        <source>Science</source>
        <volume>365</volume>
        <year>2019</year>
        <fpage>416</fpage>
        <lpage>417</lpage>
        <pub-id pub-id-type="pmid">31371586</pub-id>
      </element-citation>
    </ref>
    <ref id="bib34">
      <label>34</label>
      <element-citation publication-type="journal" id="sref34">
        <person-group person-group-type="author">
          <name>
            <surname>Murdoch</surname>
            <given-names>W.J.</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Kumbier</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Abbasi-Asl</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>Interpretable machine learning: definitions, methods, and applications</article-title>
        <source>arXiv</source>
        <year>2019</year>
        <comment>1901.04592 [cs, stat]</comment>
      </element-citation>
    </ref>
  </ref-list>
  <ack id="ack0010">
    <title>Acknowledgments</title>
    <p id="p0965">We would like to thank the <italic>Patterns</italic> editorial team and the reviewers of our manuscript for their constructive feedback that resulted in a much-improved paper.</p>
    <sec id="sec5">
      <title>Author Contributions</title>
      <p id="p0970">Conceptualization, M.H.; Data Curation, T.S.G.O. and M.H.; Investigation, M.H.; Methodology, M.H; Resources, T.S.G.O. and M.H.; Software, T.S.G.O. and M.H.; Writing – Original Draft, M.H; Writing – Review &amp; Editing, T.S.G.O. and M.H.</p>
    </sec>
    <sec sec-type="COI-statement" id="sec6">
      <title>Declaration of Interests</title>
      <p id="p0975">The authors declare no competing interests.</p>
    </sec>
  </ack>
</back>
