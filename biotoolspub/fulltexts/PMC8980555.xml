<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_DCN101104 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEmmc1 docx ?>
<?FILEmmc2 docx ?>
<?FILEmmc3 xls ?>
<?FILEmmc4 docx ?>
<?FILEsi0001 svg ?>
<?FILEsi0002 svg ?>
<?FILEsi0003 svg ?>
<?FILEsi0004 svg ?>
<?FILEsi0005 svg ?>
<?FILEsi0006 svg ?>
<?FILEsi0007 svg ?>
<?FILEsi0008 svg ?>
<?FILEsi0009 svg ?>
<?FILEsi0010 svg ?>
<?FILEsi0011 svg ?>
<?FILEsi0012 svg ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Dev Cogn Neurosci</journal-id>
    <journal-id journal-id-type="iso-abbrev">Dev Cogn Neurosci</journal-id>
    <journal-title-group>
      <journal-title>Developmental Cognitive Neuroscience</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1878-9293</issn>
    <issn pub-type="epub">1878-9307</issn>
    <publisher>
      <publisher-name>Elsevier</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8980555</article-id>
    <article-id pub-id-type="pii">S1878-9293(22)00048-2</article-id>
    <article-id pub-id-type="doi">10.1016/j.dcn.2022.101104</article-id>
    <article-id pub-id-type="publisher-id">101104</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DEEP: A dual EEG pipeline for developmental hyperscanning studies</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au0005">
        <name>
          <surname>Kayhan</surname>
          <given-names>Ezgi</given-names>
        </name>
        <email>kayhan@uni-potsdam.de</email>
        <xref rid="aff0005" ref-type="aff">a</xref>
        <xref rid="aff0010" ref-type="aff">b</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <contrib contrib-type="author" id="au0010">
        <name>
          <surname>Matthes</surname>
          <given-names>Daniel</given-names>
        </name>
        <email>daniel.matthes@htwk-leipzig.de</email>
        <xref rid="aff0010" ref-type="aff">b</xref>
        <xref rid="aff0015" ref-type="aff">c</xref>
        <xref rid="cor2" ref-type="corresp">⁎⁎</xref>
      </contrib>
      <contrib contrib-type="author" id="au0015">
        <name>
          <surname>Marriott Haresign</surname>
          <given-names>Ira</given-names>
        </name>
        <xref rid="aff0020" ref-type="aff">d</xref>
      </contrib>
      <contrib contrib-type="author" id="au0020">
        <name>
          <surname>Bánki</surname>
          <given-names>Anna</given-names>
        </name>
        <xref rid="aff0025" ref-type="aff">e</xref>
      </contrib>
      <contrib contrib-type="author" id="au0025">
        <name>
          <surname>Michel</surname>
          <given-names>Christine</given-names>
        </name>
        <xref rid="aff0010" ref-type="aff">b</xref>
        <xref rid="aff0030" ref-type="aff">f</xref>
      </contrib>
      <contrib contrib-type="author" id="au0030">
        <name>
          <surname>Langeloh</surname>
          <given-names>Miriam</given-names>
        </name>
        <xref rid="aff0010" ref-type="aff">b</xref>
        <xref rid="aff0035" ref-type="aff">g</xref>
      </contrib>
      <contrib contrib-type="author" id="au0035">
        <name>
          <surname>Wass</surname>
          <given-names>Sam</given-names>
        </name>
        <xref rid="aff0020" ref-type="aff">d</xref>
      </contrib>
      <contrib contrib-type="author" id="au0040">
        <name>
          <surname>Hoehl</surname>
          <given-names>Stefanie</given-names>
        </name>
        <xref rid="aff0025" ref-type="aff">e</xref>
      </contrib>
      <aff id="aff0005"><label>a</label>Department of Developmental Psychology, University of Potsdam, Germany</aff>
      <aff id="aff0010"><label>b</label>Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany</aff>
      <aff id="aff0015"><label>c</label>Laboratory for Biosignal Processing, Leipzig University of Applied Sciences, Germany</aff>
      <aff id="aff0020"><label>d</label>Department of Psychology, University of East London, UK</aff>
      <aff id="aff0025"><label>e</label>Faculty of Psychology, University of Vienna, Austria</aff>
      <aff id="aff0030"><label>f</label>Faculty of Education, Leipzig University, Germany</aff>
      <aff id="aff0035"><label>g</label>Department of Psychology, Heidelberg University, Germany</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>⁎</label>Corresponding author at: Department of Developmental Psychology, University of Potsdam, Germany. <email>kayhan@uni-potsdam.de</email></corresp>
      <corresp id="cor2"><label>⁎⁎</label>Corresponding author at: Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany. <email>daniel.matthes@htwk-leipzig.de</email></corresp>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>28</day>
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>28</day>
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <volume>54</volume>
    <elocation-id>101104</elocation-id>
    <history>
      <date date-type="received">
        <day>15</day>
        <month>6</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>31</day>
        <month>1</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>25</day>
        <month>3</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 The Authors. Published by Elsevier Ltd.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder/>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="ab0010">
      <p>Cutting-edge hyperscanning methods led to a paradigm shift in social neuroscience. It allowed researchers to measure dynamic mutual alignment of neural processes between two or more individuals in naturalistic contexts. The ever-growing interest in hyperscanning research calls for the development of transparent and validated data analysis methods to further advance the field. We have developed and tested a dual electroencephalography (EEG) analysis pipeline, namely DEEP. Following the preprocessing of the data, DEEP allows users to calculate Phase Locking Values (PLVs) and cross-frequency PLVs as indices of inter-brain phase alignment of dyads as well as time-frequency responses and EEG power for each participant. The pipeline also includes scripts to control for spurious correlations. Our goal is to contribute to open and reproducible science practices by making DEEP publicly available together with an example mother-infant EEG hyperscanning dataset.</p>
    </abstract>
    <kwd-group id="keys0005">
      <title>Keywords</title>
      <kwd>Developmental hyperscanning</kwd>
      <kwd>Dual EEG analysis</kwd>
      <kwd>Adult-child interaction</kwd>
      <kwd>Phase Locking Value</kwd>
      <kwd>PLV</kwd>
      <kwd>Cross-frequency PLV</kwd>
      <kwd>FieldTrip</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="sec0005">
    <label>1</label>
    <title>Background</title>
    <p id="p0005">The standard neuroscientific approach studies social information processing from an observer’s viewpoint detached from the social context (<xref rid="bib18" ref-type="bibr">Hoehl and Markova, 2018</xref>). Experimental designs assessing social processes often consist of paradigms in which participants interact with stimuli presented on a computer screen. Although these experiments have contributed greatly to our understanding of social perception and cognition, they fall short of capturing several crucial aspects of social interaction, such as its bi-directionality and dynamic nature. The second-person neuroscience perspective argues that social cognition in an interactive context may differ fundamentally from situations in which social stimuli are merely passively observed (<xref rid="bib23" ref-type="bibr">King-Casas et al., 2005</xref>, <xref rid="bib50" ref-type="bibr">Schilbach et al., 2013</xref>). Interaction partners represent social exchange as a reciprocal process and act in a ‘we-mode’ as compared to acting individually (<xref rid="bib13" ref-type="bibr">Gallotti and Frith, 2013</xref>). Based on these theoretical accounts, social neuroscience research faces the need to examine interactional phenomena in more naturalistic, ecologically valid contexts. This paradigm shift has paved the way for the emergence of hyperscanning: a technique that allows for the simultaneous recording of neural activity from two or more individuals. Using this new technique, researchers can measure the dynamic mutual alignment of neural processes between interaction partners in naturalistic settings.</p>
    <p id="p0010">As the building blocks of social cognition emerge early on in human development, hyperscanning has gained momentum among developmental researchers in recent years. Hyperscanning studies involving developmental populations have addressed a variety of social exchanges including interactions between infants and adults using EEG (<xref rid="bib28" ref-type="bibr">Leong et al., 2017</xref>, <xref rid="bib29" ref-type="bibr">Leong et al., 2019</xref>, <xref rid="bib41" ref-type="bibr">Perone et al., 2020</xref>, <xref rid="bib49" ref-type="bibr">Santamaria et al., 2020</xref>, <xref rid="bib52" ref-type="bibr">Wass et al., 2018</xref>) and functional near-infrared spectroscopy (fNIRS; <xref rid="bib37" ref-type="bibr">Nguyen et al., 2020</xref>, <xref rid="bib38" ref-type="bibr">Nguyen et al., 2021</xref>; <xref rid="bib43" ref-type="bibr">Piazza et al., 2020</xref>); interactions between children and adults using EEG (<xref rid="bib4" ref-type="bibr">Bevilacqua et al., 2019</xref>), magnetoencephalography (MEG; <xref rid="bib16" ref-type="bibr">Hasegawa et al., 2016</xref>; <xref rid="bib17" ref-type="bibr">Hirata et al., 2014</xref>) and fNIRS (<xref rid="bib2" ref-type="bibr">Azhari et al., 2019</xref>, <xref rid="bib22" ref-type="bibr">Hoyniak et al., 2021</xref>, <xref rid="bib26" ref-type="bibr">Kruppa et al., 2021</xref>, <xref rid="bib34" ref-type="bibr">Miller et al., 2019</xref>, <xref rid="bib44" ref-type="bibr">Quiñones‐Camacho et al., 2020</xref>, <xref rid="bib45" ref-type="bibr">Reindl et al., 2018</xref>, <xref rid="bib46" ref-type="bibr">Reindl et al., 2021</xref>); and interactions between child and adolescent peers using EEG (<xref rid="bib10" ref-type="bibr">Dikker et al., 2017</xref>, <xref rid="bib9" ref-type="bibr">Dikker et al., 2021</xref>) and fNIRS (<xref rid="bib42" ref-type="bibr">Piazza et al., 2021</xref>).</p>
    <p id="p0015">Measures of quantifying the amount of EEG connectivity between individuals (i.e., inter-brain connectivity) are largely similar to methods that have been applied to examine EEG connectivity within individual brains (i.e., intra-brain connectivity). The most popularly used methods include (i) covariance in amplitude or power (i.e., amplitude envelope correlation, power correlation, projected power correlation [PPC]); (ii) phase synchrony, captured by the Phase Locking Value (PLV) (<xref rid="bib11" ref-type="bibr">Dumas et al., 2010</xref>, <xref rid="bib27" ref-type="bibr">Lachaux et al., 1999</xref>) or circular correlation (CCorr); and (iii) coherency-based metrics measuring the similarity of both power and phase such as Partial Directed Coherence (PDC) (<xref rid="bib28" ref-type="bibr">Leong et al., 2017</xref>), wavelet coherence and imaginary coherence (<xref rid="bib1" ref-type="bibr">Ayrolles et al., 2021</xref>, <xref rid="bib6" ref-type="bibr">Burgess, 2013</xref>). In this article, we concentrate on phase synchrony. A full discussion of the other available methods is included in the paper by Marriott Haresign and colleagues, in this special issue.</p>
    <p id="p0020">Hyperscanning research is at a turning point: the development of transparent and validated data analysis tools is urgently required to ensure the reproducibility of findings. Despite the ever-growing interest in hyperscanning methods, there have been very few attempts to validate analysis techniques across studies (<xref rid="bib1" ref-type="bibr">Ayrolles et al., 2021</xref>, <xref rid="bib6" ref-type="bibr">Burgess, 2013</xref>, <xref rid="bib36" ref-type="bibr">Nastase et al., 2019</xref>). A recent endeavor in this direction was undertaken by Ayrolles and colleagues (2021) who published a data analysis pipeline, namely HyPyP, to perform brain-to-brain connectivity analysis for M/EEG hyperscanning data. HyPyP includes tools for automated data preprocessing and documentation for various inter-brain connectivity measures. Such comprehensive, open-source hyperscanning analysis pipelines are valuable to advance the field. Despite being an important first step, HyPyP does not directly address the challenges of developmental hyperscanning studies, which is what we aim to cover with DEEP. Moreover, while the HyPyP toolbox is integrated with MNE-Python (<xref rid="bib15" ref-type="bibr">Gramfort et al., 2013</xref>), DEEP offers an alternative solution based on the FieldTrip toolbox operated in MATLAB, which is widely used for neural data analysis.</p>
    <p id="p0025">Hyperscanning methods are also increasingly used alongside naturalistic paradigms in which adults, for example caregivers, are instructed to play with their children as they would do outside of the lab (e.g., <xref rid="bib39" ref-type="bibr">Noreika et al., 2020</xref>; <xref rid="bib52" ref-type="bibr">Wass et al., 2018</xref>). Analyzing data acquired using naturalistic paradigms poses several methodological challenges such as shorter recording sessions due to long study preparation times and movement artifacts inherent in naturalistic interactions. The problem of shorter recording sessions and higher rates of data loss due to artifacts (often 25–75%) also means that generally fewer and shorter segments of usable data can be recorded from infants and children (<xref rid="bib8" ref-type="bibr">Debnath et al., 2020</xref>, <xref rid="bib14" ref-type="bibr">Georgieva et al., 2020</xref>, <xref rid="bib19" ref-type="bibr">Hoehl and Wahl, 2012</xref>). This is particularly a problem for dual (or group) EEG studies because the calculation of inter-brain phase alignment measures between two (or more) individuals requires clean data segments from all participants recorded at the same time.</p>
    <p id="p0030">Another important challenge faced by researchers analyzing dual EEG data from developmental populations is that adults and infants inherently have different EEG signal decomposition (<xref rid="bib48" ref-type="bibr">Saby and Marshall, 2012</xref>). For example, the equivalent of the alpha frequency band, which is widely examined in the 8–12 Hz range in adults, is observed at slower frequencies such as 6–9 Hz in infants (<xref rid="bib32" ref-type="bibr">Marshall et al., 2002</xref>). We acknowledge the theoretical challenge to explain how perceptual and cognitive processing change as a function of frequency across development, which is beyond the scope of this paper. Here, we address the unique methodological challenge when calculating phase alignment between EEG signals obtained from adult and child participants by introducing the cross-frequency PLV module of DEEP. The cross-frequency PLV method allows for computing phase-alignment across datasets with differing peak frequencies such as adult and infant EEG data. This is an important step forward to establishing transparent and robust data processing approaches and standardized data analysis practices for hyperscanning studies with developmental populations.</p>
    <p id="p0035">Standardized and automated EEG processing pipelines were developed in recent years to analyze infant EEG data (<xref rid="bib8" ref-type="bibr">Debnath et al., 2020</xref>, <xref rid="bib12" ref-type="bibr">Gabard-Durnam et al., 2018</xref>). To our knowledge, however, there have been no attempts to establish standardized and automated preprocessing pipelines to analyze dual EEG data of adults and children or infants. Here, we present and test a dual EEG pipeline, in short DEEP, which aims to address this gap. The pipeline provides users with a step by step command line interface with graphical elements, which we will refer to as graphical user interface (GUI) in the remainder of the paper, to analyze adult-infant/child and adult-adult EEG hyperscanning datasets. As illustrated in <xref rid="fig0005" ref-type="fig">Fig. 1</xref>, the current version of the pipeline consists of nine data processing steps including: filtering, artifact identification, artifact correction and rejection, interpolation of noisy channels, Hilbert transformation and calculation of inter-brain phase alignment measures such as PLV and cross-frequency PLV.<fig id="fig0005"><label>Fig. 1</label><caption><p>Nine data processing steps of DEEP.</p></caption><alt-text id="at0005">Fig. 1</alt-text><graphic xlink:href="gr1"/></fig></p>
    <p id="p0040">We focus here on applying phase synchronization methods as they are flexible (i.e., they can be computed over time or trials), easy to implement, and they are grounded within a large body of literature using them to look at both intra- and inter-brain phase synchrony (<xref rid="bib30" ref-type="bibr">Liu et al., 2018</xref>). We aim to keep up with the continual development of new and existing methods for computing EEG connectivity that can be applied to dual EEG data and integrate these into the current toolbox.</p>
    <p id="p0045">In addition to dual EEG data, DEEP allows users to analyze individual EEG data using time-frequency responses and/or Welch's method. Unlike other hyperscanning pipelines, DEEP allows users to run control analyses with surrogate data to account for differences in the level of phase alignment that would be observed in the data by chance (<xref rid="bib37" ref-type="bibr">Nguyen et al., 2020</xref>, <xref rid="bib45" ref-type="bibr">Reindl et al., 2018</xref>; see also <xref rid="bib6" ref-type="bibr">Burgess, 2013</xref>).</p>
    <p id="p0050">Following the overview of the pipeline, we will test the pipeline using a dataset recorded from mothers and their 8-month-old infants using dual EEG, including resting state and free play conditions. By making a ready-to-use, open-access toolbox and a complete mother-infant dual EEG dataset publicly available, we aim to facilitate open science practices in developmental research.</p>
    <p id="p0055">The scripts used in the current version of the pipeline are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/dmatthes1982/MPI_CBS-DEEP" id="ir0005">https://github.com/dmatthes1982/MPI_CBS-DEEP</ext-link> including code descriptions. The anonymized data used in this study is publicly available. In <xref rid="sec0095" ref-type="sec">Supplementary Materials</xref>, among other documentation, we include a tutorial on how to operate the pipeline with snapshots of the GUI so that users can easily navigate the analysis workflow (see <xref rid="sec0095" ref-type="sec">Supplementary Materials S1</xref>).</p>
  </sec>
  <sec id="sec0010">
    <label>2</label>
    <title>Overview of the pipeline</title>
    <p id="p0060">Below, we will describe each processing step in the pipeline in detail. We also provide a document in <xref rid="sec0095" ref-type="sec">Supplementary Materials S3</xref>, in which we list the parameters and settings used for the preprocessing of the dataset in this paper. Please note that listed passband values were used in cross-frequency PLV calculations. For PLV estimations, we used infant passband values to process both the infant and the mother data.</p>
    <sec id="sec0015">
      <label>2.1</label>
      <title>Step-1: Data import</title>
      <p id="p0065">In the current version of the pipeline, only data recorded with Brain Vision Recorder software (Brain Products GmbH, Germany) can be analyzed. For every new session, first, the data needs to be imported. The raw data consist of an * .eeg file including the EEG data, a * .vhdr header file including information about the recorded electrodes and the sampling rate, and a * .vmrk file including the trigger information. The files should be named as specified in the pipeline (e.g., Studyname_Dyadnumber). In <xref rid="sec0095" ref-type="sec">Supplementary Materials S1</xref>, we include a code to convert data recorded by other EEG systems (e.g., BioSemi) to use the pipeline.</p>
      <p id="p0070">The user can import all of the channels or exclude certain channels from the processing by manually typing the channel names. The reason behind this implementation is that channels in the periphery are known to be particularly affected by muscle and movement artifacts rendering them potentially unsuitable for analysis in many adult-infant hyperscanning studies (<xref rid="bib14" ref-type="bibr">Georgieva et al., 2020</xref>, <xref rid="bib52" ref-type="bibr">Wass et al., 2018</xref>). The electroocular (EOG) electrodes are omitted from exclusion in order to avoid accidental removal of these electrodes because they are necessary for Independent Component Analysis (ICA; for more information, see steps 3 and 4).</p>
    </sec>
    <sec id="sec0020">
      <label>2.2</label>
      <title>Step-2: Detection of channels to be interpolated and filtering data</title>
      <p id="p0075">In the second step, the user can select channels that will be interpolated later. To help the user to decide which channels should be interpolated, the noisiest channels are first identified. All available data of each participant are concatenated and the total power of each channel is calculated from 3 Hz onwards using the “DEEP_estNoisyChan” function. Based on a common definition of outliers, if values for a particular channel are above 1.5 * IQR + Q3 or below Q1 - 1.5 * IQR, the channel is considered noisy. Users should keep in mind that these graphs only highlight the channels that are noisier as compared to the other channels. We recommend users to double check their decision on which channels to interpolate by running the preprocessing steps 1–5 without any intervention on the channels and inform their decision using artifact values at step-5. In its current version, the pipeline requires some level of experience with EEG processing to make a decision on which channels to interpolate.</p>
      <p id="p0080">First, the adult data is examined. In the GUI, two figures and a window appear. The first figure depicts the total power of all channels including the bad channels that are marked in red. Using the FieldTrip data browser function (i.e., ft_databrowser), the second figure plots raw data for each channel across time. The user can scroll through the unfiltered data and zoom in and out to inspect the data. The figures together help the user to decide on the channels to interpolate at later steps.</p>
      <p id="p0085">In the “select bad channels'' window, the user can choose the channels to interpolate at step 4. If the user selects neighboring channels for interpolation, the pipeline will continue to operate. However, bad channels will be excluded from the repairment of a likewise bad neighbor. If one channel has no good neighboring channels left, the values of this channel will be set to zero. If a bad channel has only one good neighbor, the interpolated channel will be a duplicate of the neighboring good channel (for more information, see step-4). The GUI will display a warning message if a channel that will be used for re-referencing (e.g., TP10 for the linked mastoids method) is selected for interpolation.</p>
      <p id="p0090">Once bad channels for the adult data are selected, the same process starts for the infant data. Afterwards, the pipeline filters the data using a 1–48 Hz bandpass filter suppressing electrical line noise. To process the current dataset, we have used the default parameters and settings of DEEP, which can be found in DEEP_main_2 script (see <ext-link ext-link-type="uri" xlink:href="https://github.com/dmatthes1982/MPI_CBS-DEEP/blob/master/DEEP_main_2.m" id="ir0010">https://github.com/dmatthes1982/MPI_CBS-DEEP/blob/master/DEEP_main_2.m</ext-link>). Users can change the settings in the code. In <xref rid="sec0095" ref-type="sec">Supplementary Materials S1</xref>, we present a schematic of the customized channel configuration used in the current study.</p>
    </sec>
    <sec id="sec0025">
      <label>2.3</label>
      <title>Step-3: Cleaning prior to ICA</title>
      <p id="p0095">To plan the processing time, the user can either continue with the ICA decomposition step for all of the dyads (i.e., default) or select certain dyads. In this step, the preprocessed EEG data segments are again concatenated to continuous data. Next, transient artifacts in all channels are detected and rejected applying the criterion that within a 200 ms segment with a 50% overlap (i.e., 100 ms): the difference between the maximum and the minimum voltage cannot be more than 200 μV. This ensures that large artifacts will not influence the ICA process. The remaining clean segments are concatenated to a continuous data stream followed by the ICA decomposition using the default method “runica” (for more information on specifications, see <ext-link ext-link-type="uri" xlink:href="https://www.fieldtriptoolbox.org/reference/ft_componentanalysis/" id="ir0015">https://www.fieldtriptoolbox.org/reference/ft_componentanalysis/</ext-link>). This step only involves the ICA decomposition. The selection of the ICA components takes place in the next step.</p>
    </sec>
    <sec id="sec0030">
      <label>2.4</label>
      <title>Step-4: Selection of ICA components, interpolation of bad channels and re-referencing the data</title>
      <sec id="sec0035">
        <label>2.4.1</label>
        <title>Selection of ICA components</title>
        <p id="p0100">At this step, if EOG data are available, the pipeline first detects the eye movement artifacts for subsequent correction based on the criterion that the detected eye movement components show a minimum of 80% correlation with the horizontal and vertical eye electrodes (i.e., calculation of the horizontal vertical EOG signal components [EOGH, EOGV] using channels F9, F10 and V1, V2 in the current layout, respectively). This default threshold can be reduced by the user manually. Using the ft_icabrowser function (<ext-link ext-link-type="uri" xlink:href="https://www.fieldtriptoolbox.org/reference/ft_icabrowser/" id="ir0020">https://www.fieldtriptoolbox.org/reference/ft_icabrowser/</ext-link>), the GUI displays a window in which the topography of the detected components over the entire scalp are shown and highlighted with a “Reject” label. Additionally, the power spectrum density graphs as a function of frequency are illustrated together with graphs that show the variance of power over time to help the user better evaluate the detected components.</p>
        <p id="p0105">If eye electrodes are missing, no correlations can be found, thus, the pipeline does not generate automatic suggestions. In that case, the users can inspect the ICA components and mark certain components as eye artifacts manually. Whereas the ICA algorithms work well with adult data, careful visual inspection of the components might be needed for verifying eye movement components in the infant data. In that case, users are expected to have some experience with identifying eye movement artifacts. Following the verification of the eye movement components, which are done separately for the data of infants and adults, eye movement artifacts are corrected.</p>
      </sec>
      <sec id="sec0040">
        <label>2.4.2</label>
        <title>Interpolation of bad channels</title>
        <p id="p0110">Next, the noisy channels that are selected at step-2 are interpolated by using the default FieldTrip channel repair method, namely the weighted neighbor approach. The weighted neighbor approach replaces signals from bad channels with the average signal of all neighboring channels. This method inherently requires good signal from surrounding channels, thus, it does not work optimally if several noisy channels need to be interpolated that are located close to each other (for more information, see <ext-link ext-link-type="uri" xlink:href="https://www.fieldtriptoolbox.org/reference/ft_channelrepair/" id="ir0025">https://www.fieldtriptoolbox.org/reference/ft_channelrepair/</ext-link>). DEEP, by default, uses an interpolation quota by only allowing 10% of the total number of channels to be interpolated. The deactivation of this function is possible but not recommended, as it is common across developmental EEG studies to interpolate a maximum of 10% of the overall number of channels to obtain meaningful results (<xref rid="bib8" ref-type="bibr">Debnath et al., 2020</xref>).</p>
      </sec>
      <sec id="sec0045">
        <label>2.4.3</label>
        <title>Re-referencing the data</title>
        <p id="p0115">In developmental EEG studies, researchers commonly use vertex/Cz or the left or right mastoid channels as the recording reference (<xref rid="bib19" ref-type="bibr">Hoehl and Wahl, 2012</xref>). In the recording of the current dataset, we referenced all electrodes to the left mastoid (i.e., TP9) online. However, in principle, the data can be re-referenced offline to any other electrode (e.g., right mastoid) or the average of a group of electrodes (e.g., common average re-referencing). Depending on the recorded number of channels and data quality, the pipeline allows the user to choose from the following re-referencing methods: 1) common average re-reference; 2) linked mastoids re-reference; 3) robust average re-reference. The linked mastoids offline re-referencing method uses the average of two electrodes at left and right mastoids (i.e., TP9 and TP10, respectively), whereas the common average offline re-reference method takes into account all of the electrodes.</p>
        <p id="p0120">Here, we added a third offline re-referencing method, namely robust average re-referencing, which was used in the preprocessing of the example dataset. The robust average re-referencing method is similar to the common average re-referencing approach with one main difference. Instead of taking the average of all electrodes, the robust average re-referencing method uses a group of clean channels (as identified in step-2) and calculates the average of these channels to become the reference channel for re-referencing (<xref rid="bib5" ref-type="bibr">Bigdely-Shamlo et al., 2015</xref>). We think this method is particularly useful when recording EEG data from developmental populations using naturalistic paradigms, since motion contamination results in fewer channels with sufficient data quality compared to EEG recordings from adults. DEEP uses all electrodes that were not marked as bad at step-2 in robust average re-referencing. In other words, all electrodes that are not chosen for interpolation are the ones that are included in robust average re-referencing. In <xref rid="sec0095" ref-type="sec">Supplementary Materials S3</xref>, we provide the list of interpolated channels with which users can infer which channels were used in robust average re-referencing for each participant.</p>
      </sec>
    </sec>
    <sec id="sec0050">
      <label>2.5</label>
      <title>Step-5: Automatic and manual artifact detection</title>
      <p id="p0125">We acknowledge the fact that developmental labs vary in their approach to artifact detection and removal. Accordingly, in the fifth step, DEEP allows the user to choose between one of four different algorithms for performing an automatic artifact detection to clean the data further. The four options are as follows: (1) minimum-maximum threshold: the algorithm checks whether the minimum or the maximum value within the segment exceeds a default value of + −75μV, which was used for processing the data presented in this paper. The user can also adjust this default threshold value by selecting a value from a range of 50–200 μV. If the voltage values exceed the upper and lower thresholds, the segment will be marked as an artifact. This approach was successfully applied in infant EEG studies before (e.g., <xref rid="bib51" ref-type="bibr">Wahl et al., 2012</xref>). (2) Range threshold within 200 ms, sliding window: in a sliding 200 ms window, the algorithm checks whether the difference between the minimum and maximum value within the segment exceeds a certain threshold. If it is true, the segment will be marked as an artifact. This criterion was also used in infant EEG studies (e.g., <xref rid="bib33" ref-type="bibr">Michel, 2017</xref>). (3) Standard deviation threshold within 200 ms, sliding window: in a 200 ms sliding window, the algorithm checks whether the standard deviation is larger than a certain threshold. If it is true, the segment will be marked as an artifact. This criterion was used for infant data in previous studies (e.g., <xref rid="bib21" ref-type="bibr">Hoehl et al., 2008</xref>). (4) Multiple of median absolute deviation, sliding window. Thresholds and channels can be chosen for adults and infants separately.</p>
      <p id="p0130">At this step, the pipeline generates two graphs that illustrate the artifact maps for each condition. Each artifact map illustrates the artifacts in each channel over time. On the left side of the graph, the user can also view the number of artifacts for each channel in numeric form. Artifact free segments are depicted in green whereas the segments which exceed the artifact threshold are marked in red (see <xref rid="sec0095" ref-type="sec">Supplementary Materials S1</xref>). In addition to automatic artifact detection, artifacts can be selected manually in the data browser window. After the completion of step-5, the user can select further processing options such as processing individual EEG data (i.e., step-6 followed by step-8) or running inter-brain phase alignment analyses (i.e., step-6 followed by step-7). It should be noted that the artifacts are identified at this step; however, the removal of the artifacts takes place at step-7 or step-8 depending on the analysis of interest.</p>
    </sec>
    <sec id="sec0055">
      <label>2.6</label>
      <title>Step-6: Narrow-band filtering and Hilbert transformation</title>
      <p id="p0135">The GUI asks the user to choose either the same default passband settings to be used in subsequent processing steps or separate passbands for the adult and the infant data. The default settings include the following passbands for the adult data: 1) theta [4–7 Hz] 2) alpha [8–12 Hz] 3) beta [13–30 Hz] 4) gamma [31–48 Hz]. Because of the differences in frequency bands between adult and infant data, the following settings are used for the infant data: 1) theta [3–5 Hz] 2) alpha [6–9 Hz] and 3) beta [13–30 Hz] 4) gamma [31–48 Hz]. In this paper, we examine theta and alpha frequencies, as they are most commonly used in developmental studies (e.g., <xref rid="bib28" ref-type="bibr">Leong et al., 2017</xref>; <xref rid="bib52" ref-type="bibr">Wass et al., 2018</xref>). We would like to note that the pipeline also allows the users to specify passband ranges manually and analyze frequency ranges such as beta and gamma. At this step, the pipeline also estimates the Hilbert phase in each of the passbands.</p>
    </sec>
    <sec id="sec0060">
      <label>2.7</label>
      <title>Step-7: Calculation of phase locking values (PLVs) and cross-frequency PLVs</title>
      <p id="p0140">PLV is the main metric used to estimate phase-locking between two signals. It measures the extent to which phase angles are similar between two signals over time or trials. PLV is calculated as follows:<disp-formula id="eqn0005"><label>(1)</label><mml:math id="M1" altimg="si0001.svg"><mml:mrow><mml:mi>P</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>Where N is the number of observations, <inline-formula><mml:math id="M2" altimg="si0002.svg"><mml:mrow><mml:mi mathvariant="normal">ϕ</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mspace width="1em"/></mml:mrow></mml:math></inline-formula>is the phase on observation k, at time t, in channel <inline-formula><mml:math id="M3" altimg="si0003.svg"><mml:mi mathvariant="normal">ϕ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M4" altimg="si0004.svg"><mml:mrow><mml:mi mathvariant="normal">ψ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> at channel<inline-formula><mml:math id="M5" altimg="si0005.svg"><mml:mrow><mml:mspace width="1em"/><mml:mi mathvariant="normal">ψ</mml:mi></mml:mrow></mml:math></inline-formula>. If the phase angles from the two signals fluctuate over time with a consistent difference, this will lead to PLVs close to 1. If the phase angles fluctuate over time with little consistency between each of the two signals, PLVs will be close to 0. Phase locking measures connectivity between signals with a zero lag. It is worth noting that, as phase synchrony (or phase locking) is a measure of the consistency of phase angles between two signals, where these two cycles are in relation to each other is less important than how they co-vary.</p>
      <p id="p0145">Cross-frequency phase entrainment or cross-frequency PLV shares the same underlying assumption with PLV. Cross-frequency phase entrainment or PLV <italic>m:n</italic> is calculated similarly to PLV as follows:<disp-formula id="eqn0010"><label>(2)</label><mml:math id="M6" altimg="si0006.svg"><mml:mrow><mml:mi mathvariant="italic">PL</mml:mi><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">mn</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mrow><mml:mfenced close="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">ⅇ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mo>∆</mml:mo><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mi mathvariant="normal">|</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p id="p0150"><italic>N</italic> is the number of trials and <inline-formula><mml:math id="M7" altimg="si0007.svg"><mml:mrow><mml:mo>∆</mml:mo><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> is calculated as follows:<disp-formula id="eqn0015"><label>(3)</label><mml:math id="M8" altimg="si0008.svg"><mml:mrow><mml:msub><mml:mrow><mml:mo>∆</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:mspace width="1em"/><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⋅</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mfrac><mml:mo>⋅</mml:mo><mml:mi>ϕ</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mo linebreak="badbreak">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⋅</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mo>⋅</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>Where <italic>n</italic> and <italic>m</italic> are the center frequencies of the two signals, which should be integer values satisfying the equation <inline-formula><mml:math id="M9" altimg="si0009.svg"><mml:mrow><mml:mi>m</mml:mi><mml:mo>∙</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mi>n</mml:mi><mml:mo>∙</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="M10" altimg="si0010.svg"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, is the phase angle at channel <inline-formula><mml:math id="M11" altimg="si0011.svg"><mml:mi>ϕ</mml:mi></mml:math></inline-formula>, at time <italic>t,</italic> on trial <italic>k</italic>, and channel <inline-formula><mml:math id="M12" altimg="si0012.svg"><mml:mi>ψ</mml:mi></mml:math></inline-formula>. Similar to PLV, cross-frequency PLV can be applied over trials or in a time window within a trial (see Marriott Haresign et al. paper, in this special issue for more information).</p>
      <p id="p0155">DEEP applies the following steps to calculate PLVs or cross-frequency PLVs. The pipeline first segments all of the data into epochs of 1 or 5 s duration. The epoch durations can be adjusted by the user. The pipeline then rejects all of the segments which contain artifacts that were defined at step-5 (i.e., automatic and manual artifact detection). For each good epoch, it estimates one PLV or cross-frequency PLV. Following this, all estimated PLVs or cross-frequency PLVs are averaged for each condition for all of the passbands. In the current dataset, we will examine PLVs and cross-frequency PLVs at theta and alpha frequency bands. Here, we segmented the data into 1 s epochs both for theta and alpha frequencies (cf. <xref rid="bib28" ref-type="bibr">Leong et al., 2017</xref>), as we obtained cleaner data with shorter epoch durations.</p>
    </sec>
    <sec id="sec0065">
      <label>2.8</label>
      <title>Step-8: Time-frequency responses and power spectral densities using Welch’s method</title>
      <p id="p0160">DEEP also allows users to analyze individual EEG data. In this step, users can calculate either time-frequency responses (TFRs) or power spectral densities (PSDs), separately for each participant (e.g., for infants and adults). TFRs are calculated using the FieldTrip function ft_freqanalysis (for more information on default settings, see <ext-link ext-link-type="uri" xlink:href="https://www.fieldtriptoolbox.org/reference/ft_freqanalysis/" id="ir0030">https://www.fieldtriptoolbox.org/reference/ft_freqanalysis/</ext-link>). As default, the response is calculated with wavelet time-frequency transformation using Morlet wavelets, applying a Hanning window in the frequency range of 2–50 Hz in steps of 1 Hz and a time stamp of 500 ms on which the analysis is centered. These settings can manually be changed in the functions DEEP_main_8.m and in the sub-function DEEP_timeFreqanalysis.m.</p>
      <p id="p0165">At a next step, the power spectrum can be analyzed with the FieldTrip function ft_freqanalysis using the multitaper frequency transformation (“mtmfft”) method on a Hanning window with the default settings of a 1000 ms window length with 75% overlap for the frequency range of 1–50 Hz in steps of 1 Hz. The calculation of the power spectrum of the entire condition is a median operation, which allows the user to suppress the influence of outliers in the data across long periods that are common in naturalistic paradigms. These settings can manually be changed in the functions DEEP_main_8.m and in the sub-function DEEP_pWelch.m.</p>
    </sec>
    <sec id="sec0070">
      <label>2.9</label>
      <title>Step-9: Averaging PLVs or cross-frequency PLVs, TFRs and PSD values over dyads or participants</title>
      <p id="p0170">In this final step, the user can select data of dyads or participants to estimate the mean of the PLVs or cross-frequency PLVs, TFRs and PSDs for different conditions.</p>
    </sec>
  </sec>
  <sec id="sec0075">
    <label>3</label>
    <title>Results</title>
    <p id="p0175">We used a dual EEG dataset recorded from 70 8-month-old infants (36 girls, <italic>M</italic>age= 8.29 months, <italic>SD</italic>age= 8.03 days) and their mothers (<italic>M</italic>age= 33.40 years, <italic>SD</italic>age= 4.62 years). The sample included in the analyses consisted of 35 infants (22 girls, <italic>M</italic>age= 8.27 months, <italic>SD</italic>age= 8.17 days) and their mothers (<italic>M</italic>age= 34.28 years, <italic>SD</italic>age= 4.03 years). Our original study included several experimental conditions. In this paper, we analyzed two conditions: 1) resting state (45 s, marker S13) and 2) free play (150 s, marker S11). In the resting state condition, the infants and their mothers together watched an experimenter blowing bubbles as their EEG activity was recorded concurrently. In the free play condition, the mothers were instructed to play with their infants as they would do at home, without using toys. The mothers did not receive further instructions.</p>
    <p id="p0180">Previous studies (e.g., <xref rid="bib35" ref-type="bibr">Muthukumaraswamy and Singh, 2011</xref>; <xref rid="bib6" ref-type="bibr">Burgess, 2013</xref>) suggested that increases in power can lower error in phase estimation and give the appearance of increased phase locking. Though this has been primarily examined as an event-locked phenomenon, we were curious if this might also be a feature of continuous EEG recordings, which are common within developmental social neuroscience. Accordingly, we first examined whether systematic relationships could be observed between average theta and alpha power across the whole testing session (considered in the infant and adult separately) and averaged infant-adult theta and alpha cross-frequency PLVs. For comparison, we ran the same analyses with PLVs.</p>
    <p id="p0185">We found a significant relationship between infant-adult theta cross-frequency PLVs and infant theta power in the free play condition (rho=0.42, <italic>p</italic> = .01), but not in the resting state condition (rho=0.04, <italic>p</italic> = .82), indicating a positive association between infant theta power and infant-adult theta cross-frequency PLVs during free play. The relationships between infant-adult alpha cross-frequency PLVs and infant alpha power were not significant in any of the conditions. No consistent relationships between infant-adult cross-frequency PLVs and adult power were observed in either theta or alpha frequency bands. Similar to cross-frequency PLV findings, we observed a marginally significant relationship between infant theta power and infant-adult PLVs in the free play condition (rho= 0.31, <italic>p</italic> = .07) but not in the resting state condition (rho=0.24, <italic>p</italic> = .17). This increases confidence that, when considering averaged values across the whole testing session, obtained phase alignment values are largely independent of power (see <xref rid="sec0095" ref-type="sec">Supplementary Materials S4-S5</xref>, <xref rid="fig0005" ref-type="fig">Fig. 1</xref>a to d). However, one explanation for stronger power and phase locking associations for the free play condition compared with resting state condition may be that free play condition showed more rapid transient fluctuations in power, which could affect phase entrainment via the mechanisms suggested by <xref rid="bib6" ref-type="bibr">Burgess (2013)</xref>.</p>
    <p id="p0190">Next, we examined the relationships between cross-frequency PLVs and PLVs in the resting state and free play conditions at alpha and theta frequencies separately. Whereas we observed a marginally significant relationship between cross-frequency PLVs and PLVs in the resting state condition at alpha frequency (rho=0.32, <italic>p</italic> = .06), no other correlation reached significance (all <italic>ps</italic> &gt;0.14). These findings are illustrated in <xref rid="fig0010" ref-type="fig">Fig. 2</xref>a and b.<fig id="fig0010"><label>Fig. 2</label><caption><p>Scatterplots illustrating Spearman’s correlation results showing the associations between cross-frequency PLVs and PLVs. a) associations between cross-frequency PLVs and PLVs at alpha frequency in resting state and free play conditions. b) associations between cross-frequency PLVs and PLVs at theta frequency in resting state and free play conditions. Blue and red colors represent resting state and free play conditions, respectively. Lines indicate the direction of the relationship. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</p></caption><alt-text id="at0010">Fig. 2</alt-text><graphic xlink:href="gr2"/></fig></p>
    <p id="p0195">As an exploratory analysis, we examined the consistency in alpha and theta cross-frequency PLVs between the resting state and free play conditions. As shown in <xref rid="fig0015" ref-type="fig">Fig. 3</xref>a and b, we observed a strong correlation between cross-frequency PLVs in free play and resting state conditions in the alpha band (rho=0.50, <italic>p</italic> &lt; .01), but not in the theta band (rho=0.25, <italic>p</italic> = .14). Similarly, there was a significant relationship between PLVs in free play and resting state conditions in the alpha band (rho=0.37, <italic>p</italic> = .03) but not in theta band (rho= −0.11, <italic>p</italic> = .53).<fig id="fig0015"><label>Fig. 3</label><caption><p>Scatterplots illustrating Spearman’s correlation results showing the associations between different conditions. a) cross-frequency PLVs in resting state and free play conditions in the alpha and theta bands. b) PLVs in resting state and free play conditions in the alpha and theta bands. Red and blue colors represent alpha and theta frequencies, respectively. Lines indicate the direction of the relationship. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</p></caption><alt-text id="at0015">Fig. 3</alt-text><graphic xlink:href="gr3"/></fig></p>
    <p id="p0200">Also as an exploratory analysis, we examined the relationship between alpha cross-frequency PLVs and theta cross-frequency PLVs across conditions (see <xref rid="fig0020" ref-type="fig">Fig. 4</xref>a and b). Here, we observed negative relationships for both the free play (rho= −0.27, <italic>p</italic> = .12) and resting state conditions, although only the latter relationship was significant (rho= −0.46, <italic>p</italic> &lt; .01), such that stronger alpha cross-frequency PLVs were associated with lower theta cross-frequency PLVs. Regarding PLVs, we observed a relationship in the opposite direction (stronger alpha PLVs associated with increased theta PLVs), which was again only significant for the resting state condition (rho=0.49, <italic>p</italic> &lt; . 01).<fig id="fig0020"><label>Fig. 4</label><caption><p>Scatterplots illustrating Spearman’s correlation results showing the associations between different frequency bands. a) alpha cross-frequency PLVs and theta cross-frequency PLVs in resting state and free play conditions. b) alpha PLVs and theta PLVs in resting state and free play conditions. Blue and red colors represent resting state and free play conditions, respectively. Lines indicate the direction of the relationship.</p></caption><alt-text id="at0020">Fig. 4</alt-text><graphic xlink:href="gr4"/></fig></p>
  </sec>
  <sec id="sec0080">
    <label>4</label>
    <title>Discussion</title>
    <p id="p0205">Recent shifts towards studying social perception and cognition using naturalistic paradigms pave the way for cutting-edge data recording techniques such as hyperscanning. These methods allow social neuroscientists to study dynamic interactions between two or more individuals in real-life settings. However, EEG hyperscanning results have not always replicated well (<xref rid="bib24" ref-type="bibr">Konvalinka and Roepstorff, 2012</xref>). The root cause of this is unknown, however what is clear is the field's need for transparent and standardized data analysis methods to aid the replicability of findings. To our knowledge, there is only one pipeline, namely HyPyP, which aims to fulfill this urgent need in the field of dual EEG research (<xref rid="bib1" ref-type="bibr">Ayrolles et al., 2021</xref>). However, there has been no attempt to develop and test data analysis pipelines that particularly address developmental EEG hyperscanning studies. Here, we present DEEP, which allows the analysis of dual EEG data obtained from developmental populations. By giving flexibility to users in selecting different parameters and settings for the adult and the infant data, DEEP optimizes the analysis of hyperscanning data recorded from participants at different age groups. Users can preprocess the data of two individuals followed by the calculations of inter-brain phase alignment indices such as PLVs or cross-frequency PLVs. DEEP also runs control analyses on randomly generated data to validate the results. To our knowledge, this is the first dual EEG pipeline that incorporates surrogate analysis steps. In addition to analyzing data concurrently obtained from infants/children and adults, DEEP can also be used to analyze EEG data simultaneously recorded from two adults or participants at similar ages.</p>
    <p id="p0210">We tested the pipeline with an infant-adult EEG hyperscanning dataset that included a resting state and a free play condition. One interesting observation was that inter-brain phase alignment values, as quantified by the cross-frequency PLVs in theta and alpha frequencies, were negatively associated, particularly in the resting state condition in which the mother and the infant jointly watched the experimenter blowing bubbles. Although more research is needed to understand what theta synchronization and alpha desynchronization represent in terms of inter-brain synchrony, this disjunction between theta and alpha frequencies is commonly observed in intra-individual measurements of attention and learning, where alpha power suppression (i.e., desynchronization) often goes along with theta power increases (i.e., synchronization) (e.g., <xref rid="bib25" ref-type="bibr">Köster et al., 2019</xref>). Because this paper aims to introduce DEEP, we will examine these findings more in detail in separate papers.</p>
    <p id="p0215">As this is the first version of DEEP, there are still open issues that we aim to address in future versions. To start with, at the moment, DEEP only allows users to analyze EEG datasets acquired by the Brain Products EEG recording system. We will adjust the pipeline such that several EEG data structures can be read into the pipeline. In the meantime, we provide users with a data conversion method for BioSemi data, which can be found in <xref rid="sec0095" ref-type="sec">Supplementary Materials S1</xref>. Moreover, the current version of the pipeline only processes dual EEG datasets such as the ones from infant/child and adult dyads or two adults. We strive to extend the pipeline such that data from three or more individuals could be examined, which would be particularly helpful in studies that are conducted in group settings (e.g., <xref rid="bib10" ref-type="bibr">Dikker et al., 2017</xref>; <xref rid="bib47" ref-type="bibr">Reinero et al., 2021</xref>).</p>
    <p id="p0220">Although the data of the infant and the adult are processed one by one with different parameters and settings defined by the user, roughly the same basic preprocessing steps are applied to both of the datasets. In future versions, we aim to modify the pipeline to enable separate preprocessing steps for the infant and adult data. For example, given that the channels in the outer ring of electrodes are particularly noisy for the infant data (<xref rid="bib8" ref-type="bibr">Debnath et al., 2020</xref>), one can choose to remove the electrodes in the periphery for the infant data but not for the adult data, which could be particularly useful when running intra-brain analyses (e.g., see step-8). Similarly, given the differences in the efficacy of ICA methods to correct for eye movement artifacts in the adult and infant data, it would be useful to apply separate ICA processes. Moreover, it would be highly interesting to extend the pipeline by including interpersonal synchrony measures that address the directionality between the two signals (i.e., one predicts the other) such as Partial Directed Coherence (PDC; <xref rid="bib3" ref-type="bibr">Baccalá and Sameshima, 2001</xref>), which has been previously used in developmental studies (e.g., <xref rid="bib28" ref-type="bibr">Leong et al., 2017</xref>). Finally, in the future versions of the pipeline, we hope to implement further surrogate analyses methods such as the phase randomization approach to examine whether using different surrogate methods affects the results.</p>
    <p id="p0225">A common practice in infant EEG data analysis for reducing artifacts is to reject contaminated EEG epochs manually or automatically (<xref rid="bib20" ref-type="bibr">Hoehl et al., 2012</xref>). Since automatic methods are optimized for adult EEG data (<xref rid="bib5" ref-type="bibr">Bigdely-Shamlo et al., 2015</xref>, <xref rid="bib7" ref-type="bibr">da Cruz et al., 2018</xref>, <xref rid="bib40" ref-type="bibr">Pedroni et al., 2019</xref>), they often fail to detect artifacts exceeding rejection thresholds in the infant EEG data. Therefore, manual procedures such as artifact rejection based on visual inspection were widely used by developmental researchers. However, this approach decreases the replicability of the methodology and the results (<xref rid="bib8" ref-type="bibr">Debnath et al., 2020</xref>). Another important step in advancing the pipeline would be to integrate automatic ICA classification and detection algorithms that are specifically established and tested for developmental populations. For example, recently <xref rid="bib31" ref-type="bibr">Marriott Haresign et al. (2021)</xref> adapted the widely used MARA system (for ICA classification of adult data) to address the characteristics of developmental EEG data recorded using naturalistic paradigms. The retrained “iMARA” classifier was shown to discriminate artifactual ICA components from neural ICA components with a 75% accuracy rate in infant EEG data. Integrating such algorithms will further expand the pipeline by enabling the automatic identification and removal of artifactual ICA components in the infant data.</p>
  </sec>
  <sec id="sec0085">
    <label>5</label>
    <title>Conclusions</title>
    <p id="p0230">Developmental labs vary in their approach to processing EEG data. Although it remains a challenge to use automatized processing tools for developmental data due to high interindividual differences, there has been some recent progress in establishing standardized tools to analyze developmental EEG data. In this paper, we present DEEP, a pipeline which allows researchers to analyze dual EEG data obtained from infant/child-adult dyads or two adults. DEEP promotes standardized and transparent data analyses approaches while accommodating a variety of data handling approaches remediating replication issues in the field. The pipeline includes several preprocessing steps followed by the calculation of PLVs and cross-frequency PLVs as indices of inter-brain phase alignment. DEEP also allows researchers to validate their findings by running control analysis for spurious hyper-correlations. We plan to expand DEEP further in the future. The most up-to-date version of the pipeline can be accessed at <ext-link ext-link-type="uri" xlink:href="https://github.com/dmatthes1982/MPI_CBS-DEEP" id="ir0035">https://github.com/dmatthes1982/MPI_CBS-DEEP</ext-link> together with the code and descriptions. We also publish an example hyperscanning dataset from infants and adults. With DEEP, we aim to provide developmental social neuroscientists with an accessible tool to analyze EEG hyperscanning datasets. By making the codes publicly available together with an example dataset, we are committed to move the field one step further in the process of making science open and reproducible.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Declaration of Competing Interest</title>
    <p id="p0235">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
  </sec>
</body>
<back>
  <ref-list id="bibliog0005">
    <title>References</title>
    <ref id="bib1">
      <element-citation publication-type="journal" id="sbref1">
        <person-group person-group-type="author">
          <name>
            <surname>Ayrolles</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Brun</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Djalovski</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Beauxis</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Delorme</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Bourgeron</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Dikker</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Dumas</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>HyPyP: a hyperscanning python pipeline for inter-brain connectivity analysis</article-title>
        <source>Soc. Cogn. Affect. Neurosci.</source>
        <volume>16</volume>
        <issue>1–2</issue>
        <year>2021</year>
        <fpage>72</fpage>
        <lpage>83</lpage>
        <pub-id pub-id-type="doi">10.1093/scan/nsaa141</pub-id>
        <pub-id pub-id-type="pmid">33031496</pub-id>
      </element-citation>
    </ref>
    <ref id="bib2">
      <element-citation publication-type="journal" id="sbref2">
        <person-group person-group-type="author">
          <name>
            <surname>Azhari</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Leck</surname>
            <given-names>W.Q.</given-names>
          </name>
          <name>
            <surname>Gabrieli</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Bizzego</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Rigo</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Setoh</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Bornstein</surname>
            <given-names>M.H.</given-names>
          </name>
          <name>
            <surname>Esposito</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Parenting stress undermines mother-child brain-to-brain synchrony: a hyperscanning study</article-title>
        <source>Sci. Rep.</source>
        <volume>9</volume>
        <issue>1</issue>
        <year>2019</year>
        <fpage>1</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1038/s41598-019-47810-4</pub-id>
        <pub-id pub-id-type="pmid">30626917</pub-id>
      </element-citation>
    </ref>
    <ref id="bib3">
      <element-citation publication-type="journal" id="sbref3">
        <person-group person-group-type="author">
          <name>
            <surname>Baccalá</surname>
            <given-names>L.A.</given-names>
          </name>
          <name>
            <surname>Sameshima</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Partial directed coherence: a new concept in neural structure determination</article-title>
        <source>Biol. Cybern.</source>
        <volume>84</volume>
        <issue>6</issue>
        <year>2001</year>
        <fpage>463</fpage>
        <lpage>474</lpage>
        <pub-id pub-id-type="pmid">11417058</pub-id>
      </element-citation>
    </ref>
    <ref id="bib4">
      <element-citation publication-type="journal" id="sbref4">
        <person-group person-group-type="author">
          <name>
            <surname>Bevilacqua</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Davidesco</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Wan</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Chaloner</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Rowland</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Poeppel</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Dikker</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Brain-to-brain synchrony and learning outcomes vary by student–teacher dynamics: evidence from a real-world classroom electroencephalography study</article-title>
        <source>J. Cogn. Neurosci.</source>
        <volume>31</volume>
        <issue>3</issue>
        <year>2019</year>
        <fpage>401</fpage>
        <lpage>411</lpage>
        <pub-id pub-id-type="doi">10.1162/jocn_a_01274</pub-id>
        <pub-id pub-id-type="pmid">29708820</pub-id>
      </element-citation>
    </ref>
    <ref id="bib5">
      <element-citation publication-type="journal" id="sbref5">
        <person-group person-group-type="author">
          <name>
            <surname>Bigdely-Shamlo</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Mullen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Kothe</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>K.-M.</given-names>
          </name>
          <name>
            <surname>Robbins</surname>
            <given-names>K.A.</given-names>
          </name>
        </person-group>
        <article-title>The PREP pipeline: standardized preprocessing for large-scale EEG analysis</article-title>
        <source>Front. Neuroinformatics</source>
        <volume>9</volume>
        <year>2015</year>
        <fpage>16</fpage>
        <pub-id pub-id-type="doi">10.3389/fninf.2015.00016</pub-id>
      </element-citation>
    </ref>
    <ref id="bib6">
      <element-citation publication-type="journal" id="sbref6">
        <person-group person-group-type="author">
          <name>
            <surname>Burgess</surname>
            <given-names>A.P.</given-names>
          </name>
        </person-group>
        <article-title>On the interpretation of synchronization in EEG hyperscanning studies: a cautionary note</article-title>
        <source>Front. Hum. Neurosci.</source>
        <volume>7</volume>
        <year>2013</year>
        <fpage>881</fpage>
        <pub-id pub-id-type="doi">10.3389/fnhum.2013.00881</pub-id>
        <pub-id pub-id-type="pmid">24399948</pub-id>
      </element-citation>
    </ref>
    <ref id="bib7">
      <element-citation publication-type="journal" id="sbref7">
        <person-group person-group-type="author">
          <name>
            <surname>da Cruz</surname>
            <given-names>J.R.</given-names>
          </name>
          <name>
            <surname>Chicherov</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Herzog</surname>
            <given-names>M.H.</given-names>
          </name>
          <name>
            <surname>Figueiredo</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>An automatic pre-processing pipeline for EEG analysis (APP) based on robust statistics</article-title>
        <source>Clin. Neurophysiol.</source>
        <volume>129</volume>
        <issue>7</issue>
        <year>2018</year>
        <fpage>1427</fpage>
        <lpage>1437</lpage>
        <pub-id pub-id-type="doi">10.1016/j.clinph.2018.04.600</pub-id>
        <pub-id pub-id-type="pmid">29730542</pub-id>
      </element-citation>
    </ref>
    <ref id="bib8">
      <element-citation publication-type="journal" id="sbref8">
        <person-group person-group-type="author">
          <name>
            <surname>Debnath</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Buzzell</surname>
            <given-names>G.A.</given-names>
          </name>
          <name>
            <surname>Morales</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Bowers</surname>
            <given-names>M.E.</given-names>
          </name>
          <name>
            <surname>Leach</surname>
            <given-names>S.C.</given-names>
          </name>
          <name>
            <surname>Fox</surname>
            <given-names>N.A.</given-names>
          </name>
        </person-group>
        <article-title>The Maryland analysis of developmental EEG (MADE) pipeline</article-title>
        <source>Psychophysiology</source>
        <volume>57</volume>
        <issue>6</issue>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">e13580</object-id>
        <pub-id pub-id-type="doi">10.1111/psyp.13580</pub-id>
      </element-citation>
    </ref>
    <ref id="bib9">
      <element-citation publication-type="journal" id="sbref9">
        <person-group person-group-type="author">
          <name>
            <surname>Dikker</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Michalareas</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Oostrik</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Serafimaki</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Kahraman</surname>
            <given-names>H.M.</given-names>
          </name>
          <name>
            <surname>Struiksma</surname>
            <given-names>M.E.</given-names>
          </name>
          <name>
            <surname>Poeppel</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Crowdsourcing neuroscience: Inter-brain coupling during face-to-face interactions outside the laboratory</article-title>
        <source>NeuroImage</source>
        <volume>227</volume>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">117436</object-id>
        <pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117436</pub-id>
      </element-citation>
    </ref>
    <ref id="bib10">
      <element-citation publication-type="journal" id="sbref10">
        <person-group person-group-type="author">
          <name>
            <surname>Dikker</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Wan</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Davidesco</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Kaggen</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Oostrik</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>McClintock</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Rowland</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Michalareas</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Bavel</surname>
            <given-names>J.J.V.</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Poeppel</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Brain-to-brain synchrony tracks real-world dynamic group interactions in the classroom</article-title>
        <source>Curr. Biol.</source>
        <volume>27</volume>
        <issue>9</issue>
        <year>2017</year>
        <fpage>1375</fpage>
        <lpage>1380</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cub.2017.04.002</pub-id>
        <pub-id pub-id-type="pmid">28457867</pub-id>
      </element-citation>
    </ref>
    <ref id="bib11">
      <element-citation publication-type="journal" id="sbref11">
        <person-group person-group-type="author">
          <name>
            <surname>Dumas</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Nadel</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Soussignan</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Martinerie</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Garnero</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>Inter-brain synchronization during social interaction</article-title>
        <source>PLOS ONE</source>
        <volume>5</volume>
        <issue>8</issue>
        <year>2010</year>
        <object-id pub-id-type="publisher-id">e12166</object-id>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0012166</pub-id>
      </element-citation>
    </ref>
    <ref id="bib12">
      <element-citation publication-type="journal" id="sbref12">
        <person-group person-group-type="author">
          <name>
            <surname>Gabard-Durnam</surname>
            <given-names>L.J.</given-names>
          </name>
          <name>
            <surname>Mendez Leal</surname>
            <given-names>A.S.</given-names>
          </name>
          <name>
            <surname>Wilkinson</surname>
            <given-names>C.L.</given-names>
          </name>
          <name>
            <surname>Levin</surname>
            <given-names>A.R.</given-names>
          </name>
        </person-group>
        <article-title>The Harvard automated processing pipeline for electroencephalography (Happe): standardized processing software for developmental and high-artifact data</article-title>
        <source>Front. Neurosci.</source>
        <volume>12</volume>
        <year>2018</year>
        <fpage>97</fpage>
        <pub-id pub-id-type="doi">10.3389/fnins.2018.00097</pub-id>
        <pub-id pub-id-type="pmid">29535597</pub-id>
      </element-citation>
    </ref>
    <ref id="bib13">
      <element-citation publication-type="journal" id="sbref13">
        <person-group person-group-type="author">
          <name>
            <surname>Gallotti</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Frith</surname>
            <given-names>C.D.</given-names>
          </name>
        </person-group>
        <article-title>Social cognition in the we-mode</article-title>
        <source>Trends Cogn. Sci.</source>
        <volume>17</volume>
        <issue>4</issue>
        <year>2013</year>
        <fpage>160</fpage>
        <lpage>165</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tics.2013.02.002</pub-id>
        <pub-id pub-id-type="pmid">23499335</pub-id>
      </element-citation>
    </ref>
    <ref id="bib14">
      <element-citation publication-type="journal" id="sbref14">
        <person-group person-group-type="author">
          <name>
            <surname>Georgieva</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lester</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Noreika</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Yilmaz</surname>
            <given-names>M.N.</given-names>
          </name>
          <name>
            <surname>Wass</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Leong</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>Toward the understanding of topographical and spectral signatures of infant movement artifacts in naturalistic EEG</article-title>
        <source>Front. Neurosci.</source>
        <volume>14</volume>
        <year>2020</year>
        <fpage>352</fpage>
        <pub-id pub-id-type="doi">10.3389/fnins.2020.00352</pub-id>
        <pub-id pub-id-type="pmid">32410940</pub-id>
      </element-citation>
    </ref>
    <ref id="bib15">
      <element-citation publication-type="journal" id="sbref15">
        <person-group person-group-type="author">
          <name>
            <surname>Gramfort</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Luessi</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Larson</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Engemann</surname>
            <given-names>D.A.</given-names>
          </name>
          <name>
            <surname>Strohmeier</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Brodbeck</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Goj</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Jas</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Brooks</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Parkkonen</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Hämäläinen</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>MEG and EEG data analysis with MNE-Python</article-title>
        <source>Front. Neurosci.</source>
        <volume>7</volume>
        <year>2013</year>
        <fpage>267</fpage>
        <pub-id pub-id-type="doi">10.3389/fnins.2013.00267</pub-id>
        <pub-id pub-id-type="pmid">24431986</pub-id>
      </element-citation>
    </ref>
    <ref id="bib16">
      <element-citation publication-type="journal" id="sbref16">
        <person-group person-group-type="author">
          <name>
            <surname>Hasegawa</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Ikeda</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Yoshimura</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Hiraishi</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Takahashi</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Furutani</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Hayashi</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Minabe</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Hirata</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Asada</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Kikuchi</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Mu rhythm suppression reflects mother-child face-to-face interactions: a pilot study with simultaneous MEG recording</article-title>
        <source>Sci. Rep.</source>
        <volume>6</volume>
        <issue>1</issue>
        <year>2016</year>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1038/srep34977</pub-id>
        <pub-id pub-id-type="pmid">28442746</pub-id>
      </element-citation>
    </ref>
    <ref id="bib17">
      <element-citation publication-type="journal" id="sbref17">
        <person-group person-group-type="author">
          <name>
            <surname>Hirata</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Ikeda</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Kikuchi</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Kimura</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Hiraishi</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Yoshimura</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Asada</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Hyperscanning MEG for understanding mother–child cerebral interactions</article-title>
        <source>Front. Hum. Neurosci.</source>
        <volume>8</volume>
        <year>2014</year>
        <fpage>118</fpage>
        <pub-id pub-id-type="doi">10.3389/fnhum.2014.00118</pub-id>
        <pub-id pub-id-type="pmid">24624076</pub-id>
      </element-citation>
    </ref>
    <ref id="bib18">
      <element-citation publication-type="journal" id="sbref18">
        <person-group person-group-type="author">
          <name>
            <surname>Hoehl</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Markova</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Moving developmental social neuroscience toward a second-person approach</article-title>
        <source>PLOS Biol.</source>
        <volume>16</volume>
        <issue>12</issue>
        <year>2018</year>
        <object-id pub-id-type="publisher-id">e3000055</object-id>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.3000055</pub-id>
      </element-citation>
    </ref>
    <ref id="bib19">
      <element-citation publication-type="journal" id="sbref19">
        <person-group person-group-type="author">
          <name>
            <surname>Hoehl</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Wahl</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Recording infant ERP data for cognitive research</article-title>
        <source>Dev. Neuropsychol.</source>
        <volume>37</volume>
        <issue>3</issue>
        <year>2012</year>
        <fpage>187</fpage>
        <lpage>209</lpage>
        <pub-id pub-id-type="doi">10.1080/87565641.2011.627958</pub-id>
        <pub-id pub-id-type="pmid">22545658</pub-id>
      </element-citation>
    </ref>
    <ref id="bib20">
      <element-citation publication-type="journal" id="sbref20">
        <person-group person-group-type="author">
          <name>
            <surname>Hoehl</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Wahl</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Michel</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Striano</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>Effects of eye gaze cues provided by the caregiver compared to a stranger on infants’ object processing</article-title>
        <source>Dev. Cogn. Neurosci.</source>
        <volume>2</volume>
        <issue>1</issue>
        <year>2012</year>
        <fpage>81</fpage>
        <lpage>89</lpage>
        <pub-id pub-id-type="doi">10.1016/j.dcn.2011.07.015</pub-id>
        <pub-id pub-id-type="pmid">22682729</pub-id>
      </element-citation>
    </ref>
    <ref id="bib21">
      <element-citation publication-type="journal" id="sbref21">
        <person-group person-group-type="author">
          <name>
            <surname>Hoehl</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Wiese</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Striano</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>Young infants’ neural processing of objects is affected by eye gaze direction and emotional expression</article-title>
        <source>PLOS ONE</source>
        <volume>3</volume>
        <issue>6</issue>
        <year>2008</year>
        <object-id pub-id-type="publisher-id">e2389</object-id>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0002389</pub-id>
      </element-citation>
    </ref>
    <ref id="bib22">
      <element-citation publication-type="journal" id="sbref22">
        <person-group person-group-type="author">
          <name>
            <surname>Hoyniak</surname>
            <given-names>C.P.</given-names>
          </name>
          <name>
            <surname>Quiñones-Camacho</surname>
            <given-names>L.E.</given-names>
          </name>
          <name>
            <surname>Camacho</surname>
            <given-names>M.C.</given-names>
          </name>
          <name>
            <surname>Chin</surname>
            <given-names>J.H.</given-names>
          </name>
          <name>
            <surname>Williams</surname>
            <given-names>E.M.</given-names>
          </name>
          <name>
            <surname>Wakschlag</surname>
            <given-names>L.S.</given-names>
          </name>
          <name>
            <surname>Perlman</surname>
            <given-names>S.B.</given-names>
          </name>
        </person-group>
        <article-title>Adversity is linked with decreased parent-child behavioral and neural synchrony</article-title>
        <source>Dev. Cogn. Neurosci.</source>
        <volume>48</volume>
        <issue>6</issue>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">100937</object-id>
        <pub-id pub-id-type="doi">10.1016/j.dcn.2021.100937</pub-id>
      </element-citation>
    </ref>
    <ref id="bib23">
      <element-citation publication-type="journal" id="sbref23">
        <person-group person-group-type="author">
          <name>
            <surname>King-Casas</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Tomlin</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Anen</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Camerer</surname>
            <given-names>C.F.</given-names>
          </name>
          <name>
            <surname>Quartz</surname>
            <given-names>S.R.</given-names>
          </name>
          <name>
            <surname>Montague</surname>
            <given-names>P.R.</given-names>
          </name>
        </person-group>
        <article-title>Getting to know you: reputation and trust in a two-person economic exchange</article-title>
        <source>Science</source>
        <volume>308</volume>
        <issue>5718</issue>
        <year>2005</year>
        <fpage>78</fpage>
        <lpage>83</lpage>
        <pub-id pub-id-type="doi">10.1126/science.1108062</pub-id>
        <pub-id pub-id-type="pmid">15802598</pub-id>
      </element-citation>
    </ref>
    <ref id="bib24">
      <element-citation publication-type="journal" id="sbref24">
        <person-group person-group-type="author">
          <name>
            <surname>Konvalinka</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Roepstorff</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>The two-brain approach: how can mutually interacting brains teach us something about social interaction?</article-title>
        <source>Front. Hum. Neurosci.</source>
        <volume>6</volume>
        <year>2012</year>
        <fpage>215</fpage>
        <pub-id pub-id-type="doi">10.3389/fnhum.2012.00215</pub-id>
        <pub-id pub-id-type="pmid">22837744</pub-id>
      </element-citation>
    </ref>
    <ref id="bib25">
      <element-citation publication-type="journal" id="sbref25">
        <person-group person-group-type="author">
          <name>
            <surname>Köster</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Langeloh</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Hoehl</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Visually entrained theta oscillations increase for unexpected events in the infant brain</article-title>
        <source>Psychol. Sci.</source>
        <volume>30</volume>
        <issue>11</issue>
        <year>2019</year>
        <fpage>1656</fpage>
        <lpage>1663</lpage>
        <pub-id pub-id-type="doi">10.1177/0956797619876260</pub-id>
        <pub-id pub-id-type="pmid">31603724</pub-id>
      </element-citation>
    </ref>
    <ref id="bib26">
      <element-citation publication-type="journal" id="sbref26">
        <person-group person-group-type="author">
          <name>
            <surname>Kruppa</surname>
            <given-names>J.A.</given-names>
          </name>
          <name>
            <surname>Reindl</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Gerloff</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Oberwelland Weiss</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Prinz</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Herpertz-Dahlmann</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Konrad</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Schulte-Rüther</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Brain and motor synchrony in children and adolescents with ASD: an fNIRS hyperscanning study</article-title>
        <source>Soc. Cogn. Affect. Neurosci.</source>
        <volume>16</volume>
        <issue>1</issue>
        <year>2021</year>
        <fpage>103</fpage>
        <lpage>116</lpage>
        <pub-id pub-id-type="doi">10.1093/scan/nsaa092</pub-id>
        <pub-id pub-id-type="pmid">32685971</pub-id>
      </element-citation>
    </ref>
    <ref id="bib27">
      <element-citation publication-type="journal" id="sbref27">
        <person-group person-group-type="author">
          <name>
            <surname>Lachaux</surname>
            <given-names>J.-P.</given-names>
          </name>
          <name>
            <surname>Rodriguez</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Martinerie</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Varela</surname>
            <given-names>F.J.</given-names>
          </name>
        </person-group>
        <article-title>Measuring phase synchrony in brain signals</article-title>
        <source>Hum. Brain Mapp.</source>
        <volume>8</volume>
        <issue>4</issue>
        <year>1999</year>
        <fpage>194</fpage>
        <lpage>208</lpage>
        <comment>https://doi.org/10.1002%2F(SICI)1097-0193(1999)8%3A4%3C194%3A%3AAID-HBM4%3E3.0.CO%3B2-C</comment>
        <pub-id pub-id-type="pmid">10619414</pub-id>
      </element-citation>
    </ref>
    <ref id="bib28">
      <element-citation publication-type="journal" id="sbref28">
        <person-group person-group-type="author">
          <name>
            <surname>Leong</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Byrne</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Clackson</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Georgieva</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lam</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Wass</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Speaker gaze increases information coupling between infant and adult brains</article-title>
        <source>Proc. Natl. Acad. Sci. USA</source>
        <volume>114</volume>
        <issue>50</issue>
        <year>2017</year>
        <fpage>13290</fpage>
        <lpage>13295</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1702493114</pub-id>
        <pub-id pub-id-type="pmid">29183980</pub-id>
      </element-citation>
    </ref>
    <ref id="bib29">
      <mixed-citation publication-type="other" id="othref0005">Leong, V., Noreika, V., Clackson, K., Georgieva, S., Brightman, L., Nutbrown, R.,. &amp; Wass, S. (2019). Mother-infant interpersonal neural connectivity predicts infants’ social learning. <italic>PsyArXiv.</italic><ext-link ext-link-type="uri" xlink:href="https://psyarxiv.com/gueaq" id="ir0045">〈https://psyarxiv.com/gueaq〉</ext-link>.</mixed-citation>
    </ref>
    <ref id="bib30">
      <element-citation publication-type="journal" id="sbref29">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>X.</given-names>
          </name>
        </person-group>
        <article-title>Interactive brain activity: review and progress on EEG-based hyperscanning in social interactions</article-title>
        <source>Front. Psychol.</source>
        <volume>9</volume>
        <year>2018</year>
        <fpage>1862</fpage>
        <pub-id pub-id-type="doi">10.3389/fpsyg.2018.01862</pub-id>
        <pub-id pub-id-type="pmid">30349495</pub-id>
      </element-citation>
    </ref>
    <ref id="bib31">
      <mixed-citation publication-type="other" id="othref0010">Marriott Haresign, I., Phillips, E., Whitehorn, M., Noreika, V., Jones, E., Leong, V., &amp; Wass, S.V. (2021). Automatic classification of ICA components from infant EEG using MARA. bioRxiv. <pub-id pub-id-type="doi">10.1101/2021.01.22.427809</pub-id>.</mixed-citation>
    </ref>
    <ref id="bib32">
      <element-citation publication-type="journal" id="sbref30">
        <person-group person-group-type="author">
          <name>
            <surname>Marshall</surname>
            <given-names>P.J.</given-names>
          </name>
          <name>
            <surname>Bar-Haim</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Fox</surname>
            <given-names>N.A.</given-names>
          </name>
        </person-group>
        <article-title>Development of the EEG from 5 months to 4 years of age</article-title>
        <source>Clin. Neurophysiol.: Off. J. Int. Fed. Clin. Neurophysiol.</source>
        <volume>113</volume>
        <issue>8</issue>
        <year>2002</year>
        <fpage>1199</fpage>
        <lpage>1208</lpage>
        <pub-id pub-id-type="doi">10.1016/s1388-2457(02)00163-3</pub-id>
      </element-citation>
    </ref>
    <ref id="bib33">
      <element-citation publication-type="journal" id="sbref31">
        <person-group person-group-type="author">
          <name>
            <surname>Michel</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Kaduk</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Ni Choisdealbha</surname>
            <given-names>À.</given-names>
          </name>
          <name>
            <surname>Reid</surname>
            <given-names>V.M.</given-names>
          </name>
        </person-group>
        <article-title>Event-related potentials discriminate familiar and unusual goal outcomes in 5-month-olds and adults</article-title>
        <source>Dev. Psychol.</source>
        <volume>53</volume>
        <issue>10</issue>
        <year>2017</year>
        <fpage>1833</fpage>
        <pub-id pub-id-type="doi">10.1037/dev0000376</pub-id>
        <pub-id pub-id-type="pmid">28805436</pub-id>
      </element-citation>
    </ref>
    <ref id="bib34">
      <element-citation publication-type="journal" id="sbref32">
        <person-group person-group-type="author">
          <name>
            <surname>Miller</surname>
            <given-names>J.G.</given-names>
          </name>
          <name>
            <surname>Vrtička</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Shrestha</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Hosseini</surname>
            <given-names>S.M.H.</given-names>
          </name>
          <name>
            <surname>Baker</surname>
            <given-names>J.M.</given-names>
          </name>
          <name>
            <surname>Reiss</surname>
            <given-names>A.L.</given-names>
          </name>
        </person-group>
        <article-title>Inter-brain synchrony in mother-child dyads during cooperation: an fNIRS hyperscanning study</article-title>
        <source>Neuropsychologia</source>
        <volume>124</volume>
        <year>2019</year>
        <fpage>117</fpage>
        <lpage>124</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2018.12.021</pub-id>
        <pub-id pub-id-type="pmid">30594570</pub-id>
      </element-citation>
    </ref>
    <ref id="bib35">
      <element-citation publication-type="journal" id="sbref33">
        <person-group person-group-type="author">
          <name>
            <surname>Muthukumaraswamy</surname>
            <given-names>S.D.</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>K.D.</given-names>
          </name>
        </person-group>
        <article-title>A cautionary note on the interpretation of phase-locking estimates with concurrent changes in power</article-title>
        <source>Clin. Neurophysiol.</source>
        <volume>122</volume>
        <issue>11</issue>
        <year>2011</year>
        <fpage>2324</fpage>
        <lpage>2325</lpage>
        <pub-id pub-id-type="doi">10.1016/j.clinph.2011.04.003</pub-id>
        <pub-id pub-id-type="pmid">21543253</pub-id>
      </element-citation>
    </ref>
    <ref id="bib36">
      <element-citation publication-type="journal" id="sbref34">
        <person-group person-group-type="author">
          <name>
            <surname>Nastase</surname>
            <given-names>S.A.</given-names>
          </name>
          <name>
            <surname>Gazzola</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Hasson</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Keysers</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Measuring shared responses across subjects using intersubject correlation</article-title>
        <source>Soc. Cogn. Affect. Neurosci.</source>
        <volume>14</volume>
        <issue>6</issue>
        <year>2019</year>
        <fpage>667</fpage>
        <lpage>685</lpage>
        <pub-id pub-id-type="doi">10.1093/scan/nsz037</pub-id>
        <pub-id pub-id-type="pmid">31099394</pub-id>
      </element-citation>
    </ref>
    <ref id="bib37">
      <element-citation publication-type="journal" id="sbref35">
        <person-group person-group-type="author">
          <name>
            <surname>Nguyen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Schleihauf</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Kayhan</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Matthes</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Vrtička</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Hoehl</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>The effects of interaction quality on neural synchrony during mother-child problem solving</article-title>
        <source>Cortex</source>
        <volume>124</volume>
        <year>2020</year>
        <fpage>235</fpage>
        <lpage>249</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cortex.2019.11.020</pub-id>
        <pub-id pub-id-type="pmid">31927470</pub-id>
      </element-citation>
    </ref>
    <ref id="bib38">
      <element-citation publication-type="journal" id="sbref36">
        <person-group person-group-type="author">
          <name>
            <surname>Nguyen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Schleihauf</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Kungl</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Kayhan</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Hoehl</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Vrtička</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>Interpersonal neural synchrony during father–child problem solving: an fNIRS hyperscanning study</article-title>
        <source>Child Dev.</source>
        <volume>92</volume>
        <issue>4</issue>
        <year>2021</year>
        <fpage>565</fpage>
        <lpage>580</lpage>
        <pub-id pub-id-type="doi">10.1111/cdev.13510</pub-id>
      </element-citation>
    </ref>
    <ref id="bib39">
      <element-citation publication-type="journal" id="sbref37">
        <person-group person-group-type="author">
          <name>
            <surname>Noreika</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Georgieva</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Wass</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Leong</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>14 challenges and their solutions for conducting social neuroscience and longitudinal EEG research with infants</article-title>
        <source>Infant Behav. Dev.</source>
        <volume>58</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">101393</object-id>
        <pub-id pub-id-type="doi">10.1016/j.infbeh.2019.101393</pub-id>
      </element-citation>
    </ref>
    <ref id="bib40">
      <element-citation publication-type="journal" id="sbref38">
        <person-group person-group-type="author">
          <name>
            <surname>Pedroni</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Bahreini</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Langer</surname>
            <given-names>N.</given-names>
          </name>
        </person-group>
        <article-title>Automagic: standardized preprocessing of big EEG data</article-title>
        <source>NeuroImage</source>
        <volume>200</volume>
        <year>2019</year>
        <fpage>460</fpage>
        <lpage>473</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.06.046</pub-id>
        <pub-id pub-id-type="pmid">31233907</pub-id>
      </element-citation>
    </ref>
    <ref id="bib41">
      <element-citation publication-type="journal" id="sbref39">
        <person-group person-group-type="author">
          <name>
            <surname>Perone</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Gartstein</surname>
            <given-names>M.A.</given-names>
          </name>
          <name>
            <surname>Anderson</surname>
            <given-names>A.J.</given-names>
          </name>
        </person-group>
        <article-title>Dynamics of frontal alpha asymmetry in mother-infant dyads: Insights from the still face paradigm</article-title>
        <source>Infant Behav. Dev.</source>
        <volume>61</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">101500</object-id>
        <pub-id pub-id-type="doi">10.1016/j.infbeh.2020.101500</pub-id>
      </element-citation>
    </ref>
    <ref id="bib42">
      <element-citation publication-type="journal" id="sbref40">
        <person-group person-group-type="author">
          <name>
            <surname>Piazza</surname>
            <given-names>E.A.</given-names>
          </name>
          <name>
            <surname>Cohen</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Trach</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Lew-Williams</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Neural synchrony predicts children’s learning of novel words</article-title>
        <source>Cognition</source>
        <volume>214</volume>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">104752</object-id>
        <pub-id pub-id-type="doi">10.1016/j.cognition.2021.104752</pub-id>
      </element-citation>
    </ref>
    <ref id="bib43">
      <element-citation publication-type="journal" id="sbref41">
        <person-group person-group-type="author">
          <name>
            <surname>Piazza</surname>
            <given-names>E.A.</given-names>
          </name>
          <name>
            <surname>Hasenfratz</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Hasson</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Lew-Williams</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Infant and adult brains are coupled to the dynamics of natural communication</article-title>
        <source>Psychol. Sci.</source>
        <volume>31</volume>
        <issue>1</issue>
        <year>2020</year>
        <fpage>6</fpage>
        <lpage>17</lpage>
        <pub-id pub-id-type="doi">10.1177/0956797619878698</pub-id>
        <pub-id pub-id-type="pmid">31845827</pub-id>
      </element-citation>
    </ref>
    <ref id="bib44">
      <element-citation publication-type="journal" id="sbref42">
        <person-group person-group-type="author">
          <name>
            <surname>Quiñones‐Camacho</surname>
            <given-names>L.E.</given-names>
          </name>
          <name>
            <surname>Fishburn</surname>
            <given-names>F.A.</given-names>
          </name>
          <name>
            <surname>Camacho</surname>
            <given-names>M.C.</given-names>
          </name>
          <name>
            <surname>Hlutkowsky</surname>
            <given-names>C.O.</given-names>
          </name>
          <name>
            <surname>Huppert</surname>
            <given-names>T.J.</given-names>
          </name>
          <name>
            <surname>Wakschlag</surname>
            <given-names>L.S.</given-names>
          </name>
          <name>
            <surname>Perlman</surname>
            <given-names>S.B.</given-names>
          </name>
        </person-group>
        <article-title>Parent–child neural synchrony: a novel approach to elucidating dyadic correlates of preschool irritability</article-title>
        <source>J. Child Psychol. Psychiatry</source>
        <volume>61</volume>
        <issue>11</issue>
        <year>2020</year>
        <fpage>1213</fpage>
        <lpage>1223</lpage>
        <pub-id pub-id-type="doi">10.1111/jcpp.13165</pub-id>
        <pub-id pub-id-type="pmid">31769511</pub-id>
      </element-citation>
    </ref>
    <ref id="bib45">
      <element-citation publication-type="journal" id="sbref43">
        <person-group person-group-type="author">
          <name>
            <surname>Reindl</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Gerloff</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Scharke</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Konrad</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Brain-to-brain synchrony in parent-child dyads and the relationship with emotion regulation revealed by fNIRS-based hyperscanning</article-title>
        <source>NeuroImage</source>
        <volume>178</volume>
        <year>2018</year>
        <fpage>493</fpage>
        <lpage>502</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.05.060</pub-id>
        <pub-id pub-id-type="pmid">29807152</pub-id>
      </element-citation>
    </ref>
    <ref id="bib46">
      <mixed-citation publication-type="other" id="othref0015">Reindl, V., Wass, S., Leong, V., Scharke, W., Wistuba, S., Wirth, C.L., Konrad, K., &amp; Gerloff, C. (2021). Synchrony of mind and body are distinct in mother-child dyads. bioRxiv. <pub-id pub-id-type="doi">10.1101/2021.02.21.432077</pub-id>.</mixed-citation>
    </ref>
    <ref id="bib47">
      <element-citation publication-type="journal" id="sbref44">
        <person-group person-group-type="author">
          <name>
            <surname>Reinero</surname>
            <given-names>D.A.</given-names>
          </name>
          <name>
            <surname>Dikker</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Van Bavel</surname>
            <given-names>J.J.</given-names>
          </name>
        </person-group>
        <article-title>Inter-brain synchrony in teams predicts collective performance</article-title>
        <source>Soc. Cogn. Affect. Neurosci.</source>
        <volume>16</volume>
        <issue>1–2</issue>
        <year>2021</year>
        <fpage>43</fpage>
        <lpage>57</lpage>
        <pub-id pub-id-type="doi">10.1093/scan/nsaa135</pub-id>
        <pub-id pub-id-type="pmid">32991728</pub-id>
      </element-citation>
    </ref>
    <ref id="bib48">
      <element-citation publication-type="journal" id="sbref45">
        <person-group person-group-type="author">
          <name>
            <surname>Saby</surname>
            <given-names>J.N.</given-names>
          </name>
          <name>
            <surname>Marshall</surname>
            <given-names>P.J.</given-names>
          </name>
        </person-group>
        <article-title>The utility of EEG band power analysis in the study of infancy and early childhood</article-title>
        <source>Dev. Neuropsychol.</source>
        <volume>37</volume>
        <issue>3</issue>
        <year>2012</year>
        <fpage>253</fpage>
        <lpage>273</lpage>
        <pub-id pub-id-type="doi">10.1080/87565641.2011.614663</pub-id>
        <pub-id pub-id-type="pmid">22545661</pub-id>
      </element-citation>
    </ref>
    <ref id="bib49">
      <element-citation publication-type="journal" id="sbref46">
        <person-group person-group-type="author">
          <name>
            <surname>Santamaria</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Noreika</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Georgieva</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Clackson</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Wass</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Leong</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>Emotional valence modulates the topology of the parent-infant inter-brain network</article-title>
        <source>NeuroImage</source>
        <volume>207</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">116341</object-id>
        <pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116341</pub-id>
      </element-citation>
    </ref>
    <ref id="bib50">
      <element-citation publication-type="journal" id="sbref47">
        <person-group person-group-type="author">
          <name>
            <surname>Schilbach</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Timmermans</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Reddy</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Costall</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Bente</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Schlicht</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Vogeley</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Toward a second-person neuroscience</article-title>
        <source>Behav. Brain Sci.</source>
        <volume>36</volume>
        <issue>4</issue>
        <year>2013</year>
        <fpage>393</fpage>
        <lpage>414</lpage>
        <pub-id pub-id-type="doi">10.1017/S0140525×12000660</pub-id>
        <pub-id pub-id-type="pmid">23883742</pub-id>
      </element-citation>
    </ref>
    <ref id="bib51">
      <element-citation publication-type="journal" id="sbref48">
        <person-group person-group-type="author">
          <name>
            <surname>Wahl</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Michel</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Pauen</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Hoehl</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Head and eye movements affect object processing in 4-month-old infants more than an artificial orientation cue</article-title>
        <source>Br. J. Dev. Psychol.</source>
        <volume>31</volume>
        <year>2012</year>
        <fpage>212</fpage>
        <lpage>230</lpage>
        <pub-id pub-id-type="doi">10.1111/bjdp.12001</pub-id>
        <pub-id pub-id-type="pmid">23659892</pub-id>
      </element-citation>
    </ref>
    <ref id="bib52">
      <element-citation publication-type="journal" id="sbref49">
        <person-group person-group-type="author">
          <name>
            <surname>Wass</surname>
            <given-names>S.V.</given-names>
          </name>
          <name>
            <surname>Noreika</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Georgieva</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Clackson</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Brightman</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Nutbrown</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Covarrubias</surname>
            <given-names>L.S.</given-names>
          </name>
          <name>
            <surname>Leong</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>Parental neural responsivity to infants’ visual attention: how mature brains influence immature brains during social interaction</article-title>
        <source>PLOS Biol.</source>
        <volume>16</volume>
        <issue>12</issue>
        <year>2018</year>
        <object-id pub-id-type="publisher-id">e2006328</object-id>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.2006328</pub-id>
      </element-citation>
    </ref>
  </ref-list>
  <sec id="sec0095" sec-type="supplementary-material">
    <label>Appendix A</label>
    <title>Supplementary material</title>
    <p id="p0250"><supplementary-material content-type="local-data" id="ec0005"><caption><p>Supplementary material</p></caption><media xlink:href="mmc1.docx"/></supplementary-material>.</p>
    <p id="p0255"><supplementary-material content-type="local-data" id="ec0010"><caption><p>Supplementary material</p></caption><media xlink:href="mmc2.docx"/></supplementary-material>.</p>
    <p id="p0260"><supplementary-material content-type="local-data" id="ec0015"><caption><p>Supplementary material</p></caption><media xlink:href="mmc3.xls"/></supplementary-material>.</p>
    <p id="p0265"><supplementary-material content-type="local-data" id="ec0020"><caption><p>Supplementary material</p></caption><media xlink:href="mmc4.docx"/></supplementary-material>.</p>
  </sec>
  <ack id="ack0005">
    <title>Acknowledgements</title>
    <p id="p0240">We thank the families who participated in the study. We are thankful to Umut Can Vural for his assistance with data processing and the preparation of the DEEP user manual. We also thank Mohammed Alahmadi and Jessica Gärtner for their contribution to surrogate data scripts. This work is supported by the Max Planck Society. E.K. is funded by <funding-source id="gs1">the Deutsche Forschungsgemeinschaft (DFG)</funding-source> (project number: 402789467).</p>
  </ack>
  <fn-group>
    <fn id="sec0090" fn-type="supplementary-material">
      <label>Appendix A</label>
      <p id="p0245">Supplementary data associated with this article can be found in the online version at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.dcn.2022.101104" id="ir0040">doi:10.1016/j.dcn.2022.101104</ext-link>.</p>
    </fn>
  </fn-group>
</back>
