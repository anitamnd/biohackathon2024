<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6929547</article-id>
    <article-id pub-id-type="publisher-id">3276</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-019-3276-5</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Prediction of protein structural classes by different feature expressions based on 2-D wavelet denoising and fusion</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes" equal-contrib="yes">
        <name>
          <surname>Wang</surname>
          <given-names>Shunfang</given-names>
        </name>
        <address>
          <email>sfwang_66@ynu.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Wang</surname>
          <given-names>Xiaoheng</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="GRID">grid.440773.3</institution-id><institution>Department of Computer Science and Engineering, School of Information Science and Engineering, </institution><institution>Yunnan University, </institution></institution-wrap>Kunming, 650504 People’s Republic of China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>24</day>
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>24</day>
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>20</volume>
    <issue>Suppl 25</issue>
    <issue-sponsor>Publication of this supplement has not been supported by sponsorship. Information about the source of funding for publication charges can be found in the individual articles. The articles have undergone the journal's standard peer review process for supplements. The Supplement Editor declares that they have no competing interests.</issue-sponsor>
    <elocation-id>701</elocation-id>
    <permissions>
      <copyright-statement>© The Author(s). 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Protein structural class predicting is a heavily researched subject in bioinformatics that plays a vital role in protein functional analysis, protein folding recognition, rational drug design and other related fields. However, when traditional feature expression methods are adopted, the features usually contain considerable redundant information, which leads to a very low recognition rate of protein structural classes.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">We constructed a prediction model based on wavelet denoising using different feature expression methods. A new fusion idea, first fuse and then denoise, is proposed in this article. Two types of pseudo amino acid compositions are utilized to distill feature vectors. Then, a two-dimensional (2-D) wavelet denoising algorithm is used to remove the redundant information from two extracted feature vectors. The two feature vectors based on parallel 2-D wavelet denoising are fused, which is known as PWD-FU-PseAAC. The related source codes are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Xiaoheng-Wang12/Wang-xiaoheng/tree/master">https://github.com/Xiaoheng-Wang12/Wang-xiaoheng/tree/master</ext-link>.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">Experimental verification of three low-similarity datasets suggests that the proposed model achieves notably good results as regarding the prediction of protein structural classes.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Prediction of protein structural classes</kwd>
      <kwd>Different feature expressions</kwd>
      <kwd>Parallel 2-D wavelet denoising</kwd>
      <kwd>Fusion</kwd>
    </kwd-group>
    <conference xlink:href="http://ic-ic.tongji.edu.cn/2018/index.htm">
      <conf-name>2018 International Conference on Intelligent Computing (ICIC 2018) and Intelligent Computing and Biomedical Informatics (ICBI) 2018 conference</conf-name>
      <conf-loc>Wuhan and Shanghai, China</conf-loc>
      <conf-date>15-18 August 2018, 3-4 November 2018</conf-date>
    </conference>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par14">Protein structural class prediction is a heavily researched subject in bioinformatics and performs a vital role in many related fields and applications, such as protein functional analysis, protein folding recognition, protein binding, rational drug design and so on [<xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR11">11</xref>]. However, in the light of newly discovered proteins, it will take time and money to determine the structure of proteins by traditional experimental methods, so many computational methods have been proposed to predict protein structural classes. Because the sequence of amino acids determines the specific spatial structure of protein, the method of predicting structural classes by sequence is a concise and effective way, which can help guide the direction of biological experiment, save the cost of biological experiment and provide useful information for a heuristic approach [<xref ref-type="bibr" rid="CR9">9</xref>–<xref ref-type="bibr" rid="CR12">12</xref>]. In particular, when the feature information of proteins is extracted, they often contain considerable redundant information, resulting in an unsatisfactory recognition rate for structural classes of protein.</p>
    <p id="Par15">To solve the problems of redundant information and low recognition rates, many computational methods have been proposed to predict protein structural classes during the past 30 years. One such method is the feature extraction method based on the information in amino acid sequences. Initially, amino acid composition [<xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR13">13</xref>] (AAC) was used to extract the feature information. This method calculated the proportion of twenty amino acid residues in the sequence and expressed the feature information of the sequence by numerical vectors. Pseudo amino acid composition [<xref ref-type="bibr" rid="CR14">14</xref>–<xref ref-type="bibr" rid="CR19">19</xref>] (PseACC) was also used to extract its feature information. This method considered not only the composition of amino acid residues but also their hydrophobicity and other physical and chemical properties. In addition, peptide composition [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR21">21</xref>] was adopted to extract its feature information. Compared with the previous two methods, this method considered the sequence factor between amino acid residues. These methods have achieved good prediction results on high similarity datasets but poor results on low similarity datasets. The prediction accuracy of these methods can reach more than 90% on high similarity datasets but only approximately 50% on low similarity datasets. Some improved feature extraction methods have been proposed. Lukasz et al. proposed the SCPRED method [<xref ref-type="bibr" rid="CR22">22</xref>], which constructed feature vectors based on predictive secondary structure. Zhang proposed a TPM matrix to represent the feature on the predictive secondary structure [<xref ref-type="bibr" rid="CR23">23</xref>], and Dai et al. [<xref ref-type="bibr" rid="CR24">24</xref>] proposed a statistical feature method on the predictive secondary structure feature, which takes the secondary structure feature as part of the feature vector. In Ding [<xref ref-type="bibr" rid="CR25">25</xref>], a multidimensional representation vector is constructed to predict protein secondary structural classes. Some methods for fusing multiple features such as feature selection [<xref ref-type="bibr" rid="CR26">26</xref>] are also proposed. Chen et al. proposed the fusion of multiple features [<xref ref-type="bibr" rid="CR27">27</xref>], which combined the derived structure information of sequences with the physicochemical properties [<xref ref-type="bibr" rid="CR28">28</xref>]. Nanni et al. proposed a new feature fusion method based on the features of the primary sequence and the features of the secondary structure based on prediction [<xref ref-type="bibr" rid="CR29">29</xref>]. Wang et al. [<xref ref-type="bibr" rid="CR30">30</xref>] fused the improved simplified PSSM with secondary structure features. In addition, some other classical feature extraction methods have been proposed, such as Dehzangi et al., who used piecewise distribution and piecewise autocovariance ideas [<xref ref-type="bibr" rid="CR31">31</xref>]. It is noted that it is hard for the above feature fusion algorithms to reduce the redundancy of feature information, which thus makes prediction accuracy hard to improve. Based on this properity, Liu et al. used a recursive feature selection algorithm to select the optimal feature vector [<xref ref-type="bibr" rid="CR32">32</xref>].</p>
    <p id="Par16">The second is the classification algorithm. As far as the four common cases of structural classes, all-α, all-β, α/β and α + β are concerned, how to distinguish them accurately is essential an efficient multi-classification problems. Multiple classification and various machine learning algorithms have been applied to protein classification prediction, such as neural networks, fuzzy clustering, Naive Bayes, support vector machines (SVM), K-nearest neighbors (KNN) and the correlation coefficients methods [<xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR33">33</xref>–<xref ref-type="bibr" rid="CR40">40</xref>]. However, because the dataset used in protein structure prediction is usually small sample data, and the neural network classification algorithm requires a large amount of data, its performance cannot be fully developed. The fuzzy clustering algorithm also faces the same problem because the sample size is too small to cluster well, resulting in poor prediction results. For Naive Bayesian classification, the premise is that there is no correlation between the features and attributes, and it is sensitive to the form of data input. These factors affect the performance of classification prediction to a certain extent. Support Vector Machine can also play a role in classification performance when there are few data samples, but the process of searching parameters is highly time-consuming. The K-nearest neighbor algorithm is simple in theory, easy to implement, simple and efficient. This algorithm is also suitable for classification of small sample data. Later, some improved classification algorithms have been proposed. For example, Chen et al. proposed a method of fusing multiple support vector machines [<xref ref-type="bibr" rid="CR41">41</xref>]. This method divides the extracted feature vectors into three parts, each part is input into a corresponding classifier, and then synthesizes the classification results of the three parts, voting to determine the category of the samples to be tested. The improved method is to fuse the same classifier. After that step, the fusions of different types of classifiers have been proposed, such as Dehzangi and other classifiers [<xref ref-type="bibr" rid="CR42">42</xref>]. The classifiers are AdaBoost, M1, LogitBoost, SVM, MLP and Naive Bayes. However, the problem that redundant information in the feature vector affects the generalization ability of the model has not been solved by these methods.</p>
    <p id="Par17">In this article, to deal with this problem, the newly developed model for predicting structural classes of proteins is put forward based on different feature expression methods, known as PWD-FU-PseAAC. In order to prove the superiority of the proposed method, the extracted feature vectors are based on the primary sequence information of proteins. First, the features of the primary sequence of proteins are distilled by the traditional feature expression methods, type 1 pseudo amino acid composition (PseAAC) [<xref ref-type="bibr" rid="CR43">43</xref>] and type 2 pseudo amino acid composition [<xref ref-type="bibr" rid="CR44">44</xref>]. Since type 1 PseAAC is popularly used in many researches, here we explain a little about type 2 PseAAC. In Chou [<xref ref-type="bibr" rid="CR44">44</xref>], type 2 PseAAC is also called ‘amphiphilic pseudo amino acid composition’, whose form is like AAC except much more information about the distribution of the hydrophobic and hydrophilic amino acids of a protein. Second, two-dimensional multiscale wavelet denoising is used to process the feature vectors extracted by two feature expression methods, removing the redundant information from them. In the field of mathematics, a new direction of rapid and groundbreaking development is wavelet analysis, which has been increasingly widely utilized in the field of bioinformatics, particularly for protein structural prediction and functional analysis. This analysis has the characteristics of local transformation in the time domain and frequency domain and may efficaciously extract information from signals and perform multiscale fine analysis of functions or signals through scaling and translation operations. Wavelet denoising [<xref ref-type="bibr" rid="CR45">45</xref>] is one of the significant branches of wavelet analysis, which can efficaciously eliminate redundant information of the extracted feature vectors, making the information more stable and efficacious, and improving the accuracy of prediction. Due to the complexity of the protein structure, it can be reasonably to employ two-dimensional (2-D) wavelet de-noising rather than one-dimensional (1-D) wavelet de-noising. To illustrate the validity of 2-D wavelet denoising, it is compared with the 1-D wavelet denoising in the following experimental parts. Third, the new feature vectors are obtained by fusing the two different feature vectors after denoising. Finally, the optimal feature vectors are treated as input data of the KNN to predict structural classes of proteins. To estimate the performance of our presented model, we adopt the jackknife test as a validation method to carry out relevant experimental analysis on the three low-similarity datasets. The final experimental outcomes indicate that our model has higher overall prediction accuracies than other methods.</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>Datasets</title>
      <p id="Par18">To compare with current methods fairly and objectively, three low-similarity benchmark datasets, the 25PDB [<xref ref-type="bibr" rid="CR46">46</xref>], the 1189PDB [<xref ref-type="bibr" rid="CR47">47</xref>] and the 640PDB [<xref ref-type="bibr" rid="CR48">48</xref>], are selected as our experimental datasets, which are structural protein sequences with internal similarities of less than 25, 40 and 25%, respectively. The datasets have four categories, the details of which are shown in Table <xref rid="Tab1" ref-type="table">1</xref>.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Detailed information of the two datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Dataset</th><th colspan="5">Number of proteins</th></tr><tr><th>all-α</th><th>all-β</th><th>α/β</th><th>α + β</th><th>Total</th></tr></thead><tbody><tr><td>25PDB</td><td>443</td><td>443</td><td>346</td><td>441</td><td>1673</td></tr><tr><td>1189PDB</td><td>223</td><td>294</td><td>334</td><td>241</td><td>1092</td></tr><tr><td>640PDB</td><td>138</td><td>154</td><td>177</td><td>171</td><td>640</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec4">
      <title>Feature extraction</title>
      <p id="Par19">In this article, the traditional feature expression methods, two types of pseudo amino acid compositions, are applied to convert the primary sequences of protein into numerical feature vectors. As known to all, pseudo amino acid composition is an improved expression on the basis of amino acid composition, not only considering the frequency of amino acid residues in the sequence but also considering the physicochemical properties of amino acid residues. There are two types of pseudo amino acid composition: parallel correlation type and sequence correlation type. For convenience, the pseudo amino acid composition of the parallel correlation type is called type 1 pseudo amino acid composition, and that of the sequence correlation type is called type 2 pseudo amino acid composition.
<list list-type="order"><list-item><p id="Par20">Type 1 pseudo amino acid composition</p></list-item></list></p>
      <p id="Par21">Type 1 pseudo amino acid composition was proposed by Chou in 2001 [<xref ref-type="bibr" rid="CR43">43</xref>]. This composition considers not only the hydrophilicity and hydrophobicity of amino acid residues, but also the quality of side chain groups of amino acid residues. Type 1 pseudo amino acid composition is used to extract the features of structural protein sequences.</p>
      <p id="Par22">Thus, a protein sequence can be transformed into 20+ <italic>λ</italic> dimensional numerical vectors, that is, <italic>P</italic><sub><italic>PseAAC</italic> _ <italic>type</italic>1</sub> = [<italic>p</italic><sub>1</sub>, <italic>p</italic><sub>2</sub>, ......, <italic>p</italic><sub>20 + <italic>λ</italic></sub>]<sup><italic>T</italic></sup>, where <italic>p</italic><sub><italic>u</italic></sub> can be calculated from eq. (<xref rid="Equ1" ref-type="">1</xref>):
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {p}_u=\left\{{\displaystyle \begin{array}{l}\frac{f_u}{\sum \limits_{i=1}^{20}{f}_i+\omega \sum \limits_{j=1}^{\lambda }{\theta}_j}\left(1\le u\le 20\right)\\ {}\frac{\omega {\theta}_{u-20}}{\sum \limits_{i=1}^{20}{f}_i+\omega \sum \limits_{j=1}^{\lambda }{\theta}_j}\left(20+1\le u\le 20+\lambda \right)\end{array}}\right. $$\end{document}</tex-math><mml:math id="M2" display="block"><mml:msub><mml:mi>p</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="" open="{"><mml:mtable columnalign="left" displaystyle="true"><mml:mtr><mml:mtd><mml:mfrac><mml:msub><mml:mi>f</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>20</mml:mn></mml:munderover><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>ω</mml:mi><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>λ</mml:mi></mml:munderover><mml:msub><mml:mi>θ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>u</mml:mi><mml:mo>≤</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mi>ω</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>20</mml:mn></mml:munderover><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>ω</mml:mi><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>λ</mml:mi></mml:munderover><mml:msub><mml:mi>θ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mfenced close=")" open="("><mml:mrow><mml:mn>20</mml:mn><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>u</mml:mi><mml:mo>≤</mml:mo><mml:mn>20</mml:mn><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3276_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <italic>f</italic><sub><italic>i</italic></sub> is the frequency of 20 amino acid residues in protein sequence P; <italic>w</italic> is the weight factor, which is generally set to 0.05; <italic>λ</italic> is the hierarchical factor, which is less than the total length of the sequence <italic>N</italic>; <italic>θ</italic><sub><italic>j</italic></sub> is the sequence correlation coefficient of the j-th layer, which can be calculated from eq. (<xref rid="Equ2" ref-type="">2</xref>):
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\theta}_{\lambda }=\frac{1}{L-\lambda}\sum \limits_{i-1}^{L-\lambda}\varPhi \left({R}_i,{R}_{i+\lambda}\right) $$\end{document}</tex-math><mml:math id="M4" display="block"><mml:msub><mml:mi>θ</mml:mi><mml:mi>λ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:munderover><mml:mi>Φ</mml:mi><mml:mfenced close=")" open="(" separators=","><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:msub></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3276_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par23">In addition:
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \varPhi \left({R}_i,{R}_j\right)=\frac{1}{3}\left\{{\left[{H}_1\left({R}_j\right)-{H}_1\left({R}_i\right)\right]}^2+{\left[{H}_2\left({R}_j\right)-{H}_2\left({R}_i\right)\right]}^2+{\left[{H}_3\left({R}_j\right)-{H}_3\left({R}_i\right)\right]}^2\right\} $$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mi>Φ</mml:mi><mml:mfenced close=")" open="(" separators=","><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>3</mml:mn></mml:mfrac><mml:mfenced close="}" open="{"><mml:mrow><mml:msup><mml:mfenced close="]" open="["><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mo>−</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mfenced close="]" open="["><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mo>−</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mfenced close="]" open="["><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mo>−</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3276_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par24">Among them, <italic>H</italic><sub>1</sub>(<italic>R</italic><sub><italic>i</italic></sub>), <italic>H</italic><sub>2</sub>(<italic>R</italic><sub><italic>i</italic></sub>) and <italic>H</italic><sub>3</sub>(<italic>R</italic><sub><italic>i</italic></sub>) represent the hydrophobicity, hydrophilicity and the quality of side chain groups of amino acid residues, respectively.
<list list-type="simple"><list-item><label>(2)</label><p id="Par25">Type 2 pseudo amino acid composition</p></list-item></list></p>
      <p id="Par26">Type 2 pseudo amino acid composition was proposed by Chou in 2005 [<xref ref-type="bibr" rid="CR44">44</xref>] because it considers the hydrophilicity and hydrophobicity of amino acid residues, also known as amphipathic pseudo amino acid composition. In this article, type 2 pseudo amino acid composition is also used to extract the features of structural protein sequences.</p>
      <p id="Par27">Thus, a protein sequence can be transformed into 20+ 2<italic>r</italic> dimensional numerical vectors, with <italic>P</italic><sub><italic>PseAAC</italic> _ <italic>type</italic>1</sub> = [<italic>p</italic><sub>1</sub>, <italic>p</italic><sub>2</sub>, ......, <italic>p</italic><sub>20 + 2<italic>r</italic></sub>]<sup><italic>T</italic></sup>, where <italic>p</italic><sub><italic>u</italic></sub> can be calculated from equation (<xref rid="Equ4" ref-type="">4</xref>):
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {p}_u=\left\{{\displaystyle \begin{array}{l}\frac{f_u}{\sum \limits_{i=1}^{20}{f}_i+\omega \sum \limits_{j=1}^{2r}{\tau}_j}\left(1\le u\le 20\right)\\ {}\frac{\omega {\tau}_u}{\sum \limits_{i=1}^{20}{f}_i+\omega \sum \limits_{j=1}^{2r}{\tau}_j}\left(20+1\le u\le 20+2r\right)\end{array}}\right. $$\end{document}</tex-math><mml:math id="M8" display="block"><mml:msub><mml:mi>p</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="" open="{"><mml:mtable columnalign="left" displaystyle="true"><mml:mtr><mml:mtd><mml:mfrac><mml:msub><mml:mi>f</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>20</mml:mn></mml:munderover><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>ω</mml:mi><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>r</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>τ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>u</mml:mi><mml:mo>≤</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mi>ω</mml:mi><mml:msub><mml:mi>τ</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>20</mml:mn></mml:munderover><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>ω</mml:mi><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>r</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>τ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mfenced close=")" open="("><mml:mrow><mml:mn>20</mml:mn><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>u</mml:mi><mml:mo>≤</mml:mo><mml:mn>20</mml:mn><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>r</mml:mi></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3276_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <italic>r</italic> is the hierarchical factor, which is less than the total length of the sequence <italic>N</italic>; <italic>τ</italic><sub><italic>j</italic></sub> is the sequence correlation coefficient of the j-th layer, which can be calculated from eq. (<xref rid="Equ5" ref-type="">5</xref>):
<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \left\{{\displaystyle \begin{array}{l}{\tau}_1=\frac{1}{L-1}\sum \limits_{i=1}^{L-1}{H}_{i,i+1}^1\\ {}{\tau}_2=\frac{1}{L-1}\sum \limits_{i=1}^{L-1}{H}_{i,i+1}^2\\ {}{\tau}_3=\frac{1}{L-2}\sum \limits_{i=1}^{L-2}{H}_{i,i+2}^1\\ {}{\tau}_4=\frac{1}{L-2}\sum \limits_{i=1}^{L-2}{H}_{i,i+2}^2\\ {}\cdots \cdots \cdots \\ {}{\tau}_{2\lambda -1}=\frac{1}{L-\lambda}\sum \limits_{i=1}^{L-\lambda }{H}_{i,i+\lambda}^1\\ {}{\tau}_{2\lambda }=\frac{1}{L-\lambda}\sum \limits_{i=1}^{L-\lambda }{H}_{i,i+\lambda}^2\end{array}},,,\left(\lambda &lt;L\right)\right. $$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mfenced close="" open="{"><mml:mtable columnalign="left" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋯</mml:mo><mml:mo>⋯</mml:mo><mml:mo>⋯</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>λ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mi>λ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mfenced></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3276_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par28">In addition:
<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \Big\{{\displaystyle \begin{array}{l}{H}_{i,j}^1={H}^1\left({R}_i\right)\ast {H}^2\left({R}_j\right)\\ {}{H}_{i,j}^2={H}^2\left({R}_i\right)\ast {H}^2\left({R}_j\right)\end{array}} $$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mo stretchy="true">{</mml:mo><mml:mtable columnalign="left" displaystyle="true"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>H</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mfenced close=")" open="("><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>∗</mml:mo><mml:msup><mml:mi>H</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mfenced close=")" open="("><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>H</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mfenced close=")" open="("><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>∗</mml:mo><mml:msup><mml:mi>H</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mfenced close=")" open="("><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2019_3276_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where <italic>H</italic><sup>1</sup>(<italic>R</italic><sub><italic>i</italic></sub>) refer to the hydrophobicity of amino acid residues, and <italic>H</italic><sup>2</sup>(<italic>R</italic><sub><italic>i</italic></sub>) refer to the hydrophilicity of amino acid residues.</p>
    </sec>
    <sec id="Sec5">
      <title>Two-dimensional wavelet denoising</title>
      <p id="Par29">The process of wavelet denoising includes the following three parts: wavelet transform, processing of wavelet coefficients and wavelet inverse transform [<xref ref-type="bibr" rid="CR49">49</xref>]. There are three commonly used methods of wavelet denoising: wavelet threshold denoising, modulus maximum denoising and spatial correlation denoising. To suppress the noise in the high frequency section and remove redundant information, the wavelet threshold denoising method is adopted. In other words, the wavelet denoising method used refers to the wavelet threshold denoising method in this paper.</p>
      <p id="Par30">This method’s decomposition and reconstruction can be expressed as follows:
<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {f}^0\leftrightarrow \left\{{\displaystyle \begin{array}{l}{f}_L^1\leftrightarrow \Big\{\begin{array}{l}{f}_L^2\leftrightarrow \left\{...{f}_L^{n-1}\leftrightarrow \right\{\begin{array}{l}{f}_L^n\\ {}{f}_H^n\Big\{\begin{array}{l}{f}_{HH}^n\\ {}{f}_{HV}^n\\ {}{f}_{HD}^n\end{array}\end{array}\\ {}{f}_H^2\Big\{\begin{array}{l}{f}_{HH}^2\\ {}{f}_{HV}^2\\ {}{f}_{HD}^2\end{array}\end{array}\\ {}{f}_H^1\Big\{\begin{array}{l}{f}_{HH}^1\\ {}{f}_{HV}^1\\ {}{f}_{HD}^1\end{array}\end{array}}\right. $$\end{document}</tex-math><mml:math id="M14" display="block"><mml:msup><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msup><mml:mo>↔</mml:mo><mml:mfenced close="" open="{"><mml:mtable columnalign="left" displaystyle="true"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi>L</mml:mi><mml:mn>1</mml:mn></mml:msubsup><mml:mo>↔</mml:mo><mml:mo stretchy="true">{</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>↔</mml:mo><mml:mo stretchy="true">{</mml:mo><mml:mn>...</mml:mn><mml:msubsup><mml:mi>f</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>↔</mml:mo><mml:mo stretchy="true">{</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi>H</mml:mi><mml:mi>n</mml:mi></mml:msubsup><mml:mo stretchy="true">{</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HH</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HV</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HD</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi>H</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="true">{</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HH</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HV</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HD</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi>H</mml:mi><mml:mn>1</mml:mn></mml:msubsup><mml:mo stretchy="true">{</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HH</mml:mi><mml:mn>1</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HV</mml:mi><mml:mn>1</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HD</mml:mi><mml:mn>1</mml:mn></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3276_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>where <italic>f</italic><sup>0</sup> represents the original signal; <inline-formula id="IEq1"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {f}_L^i $$\end{document}</tex-math><mml:math id="M16" display="inline"><mml:msubsup><mml:mi>f</mml:mi><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3276_Article_IEq1.gif"/></alternatives></inline-formula> represents the i-th layer low frequency component obtained by wavelet decomposition; <inline-formula id="IEq2"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {f}_H^i $$\end{document}</tex-math><mml:math id="M18" display="inline"><mml:msubsup><mml:mi>f</mml:mi><mml:mi>H</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3276_Article_IEq2.gif"/></alternatives></inline-formula> represents the i-th layer high frequency component obtained by wavelet decomposition; It contains three high-frequency components, in which <inline-formula id="IEq3"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {f}_{HH}^i $$\end{document}</tex-math><mml:math id="M20" display="inline"><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HH</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3276_Article_IEq3.gif"/></alternatives></inline-formula> refers to the horizontal component, <inline-formula id="IEq4"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {f}_{HV}^i $$\end{document}</tex-math><mml:math id="M22" display="inline"><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HV</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3276_Article_IEq4.gif"/></alternatives></inline-formula> refers to the vertical component and <inline-formula id="IEq5"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {f}_{HD}^i $$\end{document}</tex-math><mml:math id="M24" display="inline"><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HD</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3276_Article_IEq5.gif"/></alternatives></inline-formula> refers to the diagonal component.</p>
      <p id="Par31">Then, the above can be expressed as:
<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \Big\{{\displaystyle \begin{array}{l}{f}^0={f}_L^0\\ {}{f}_L^{k-1}=\left(\left({f}_{HH}^k\oplus {f}_{HV}^k\oplus {f}_{HD}^k\right)\oplus \left(\left({f}_{HH}^{k+1}\oplus {f}_{HV}^{k+1}\oplus {f}_{HD}^{k+1}\right)\oplus {f}_L^{k+1}\right)\right)\end{array}}\mathrm{k}=1,\mathrm{2...}\mathrm{n} $$\end{document}</tex-math><mml:math id="M26" display="block"><mml:mo stretchy="true">{</mml:mo><mml:mtable columnalign="left" displaystyle="true"><mml:mtr><mml:mtd><mml:msup><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi>L</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HH</mml:mi><mml:mi>k</mml:mi></mml:msubsup><mml:mo>⊕</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HV</mml:mi><mml:mi>k</mml:mi></mml:msubsup><mml:mo>⊕</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HD</mml:mi><mml:mi>k</mml:mi></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>⊕</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HH</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>⊕</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HV</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>⊕</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HD</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>⊕</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable><mml:mi mathvariant="normal">k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2...</mml:mn><mml:mi mathvariant="normal">n</mml:mi></mml:math><graphic xlink:href="12859_2019_3276_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par32">where ⊕ represents the direct orthogonal sum.</p>
      <p id="Par33">In addition, formula (8) can also be expressed as (9):
<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {f}^0={f}_L^n\oplus {\sum}_{k=1}^n\left({f}_{HH}^k\oplus {f}_{HV}^k\oplus {f}_{HD}^k\right) $$\end{document}</tex-math><mml:math id="M28" display="block"><mml:msup><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msubsup><mml:mo>⊕</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HH</mml:mi><mml:mi>k</mml:mi></mml:msubsup><mml:mo>⊕</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HV</mml:mi><mml:mi>k</mml:mi></mml:msubsup><mml:mo>⊕</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi mathvariant="italic">HD</mml:mi><mml:mi>k</mml:mi></mml:msubsup></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3276_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par34">The flow chart of 2-D wavelet denoising is shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>.
<fig id="Fig1"><label>Fig. 1</label><caption><p>Flow chart of 2-D wavelet denoising</p></caption><graphic xlink:href="12859_2019_3276_Fig1_HTML" id="MO1"/></fig></p>
      <p id="Par35">In Fig. <xref rid="Fig1" ref-type="fig">1</xref>, the input is the original 2-D data and the output is the new obtained 2-D data, the intermediate procedures of the 2-D wavelet denoising is mainly as follows, which is summarized and deduced from references [<xref ref-type="bibr" rid="CR48">48</xref>–<xref ref-type="bibr" rid="CR53">53</xref>]:</p>
      <p>1) Set the wavelet basis function x, decomposition scale n and threshold value t.</p>
      <p>2) Through the wavelet transform, 2-D data are decomposed into four components, one of which is a low frequency component, and the other three of which are high frequency components: a horizontal component, a vertical component and a diagonal component.</p>
      <p id="Par39">3) The low frequency component obtained from step 2 can be further decomposed into a new low frequency component and three new high frequency components: horizontal component, vertical component and diagonal component. Repeat this process until the decomposition scale n is reached.</p>
      <p id="Par40">4) A threshold value is applied to quantize high frequency coefficients obtained by each decomposition.</p>
      <p id="Par41">5) The lastly decomposed and quantized high-frequency component is reconstructed by wavelet transform with the only low-frequency component to form a new low-frequency component. The process is repeated n times upward until the new 2-D data are synthesized.</p>
      <p id="Par42">The algorithm’s pseudocode is shown in Table <xref rid="Tab2" ref-type="table">2</xref>.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Pseudocode of the 2-D wavelet denoising algorithm</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="2">Input: 2-D data, d1 Output: new 2-D data, d2</th></tr><tr><th>1</th><th>set x, n, t, j = 0; //set wavelet function, decomposition scale, threshold value and pointer j.</th></tr></thead><tbody><tr><td>2</td><td>(L [j], h1[j], h2[j], h3[j]) = wavedec2(x, d1) //decompose data.</td></tr><tr><td>3</td><td>(h1[j], h2[j], h3[j]) = threshold(t, h1[j], h2[j], h3[j]); //quantize high frequency coefficients.</td></tr><tr><td>4</td><td>for→j = 0 to n-1: //the process of decomposition.</td></tr><tr><td>5</td><td>(L [j + 1], h1[j + 1], h2[j + 1], h3[j + 1]) = wavedec2(x, L [j]);</td></tr><tr><td>6</td><td>(h1[j + 1], h2[j + 1], h3[j + 1]) = threshold(h, h1[j + 1], h2[j + 1], h3[j + 1]); j = j + 1;</td></tr><tr><td>7</td><td>for→i = n-1 to 0: //the process of reconstruction.</td></tr><tr><td>8</td><td>L [i-1] = waverec2(x, L [i], h1[i], h2[i], h3[i]); i = i-1;</td></tr><tr><td>9</td><td>d2 = waverec2(x, L [i], h1[i], h2[i], h3[i]); //reconstruct data.</td></tr></tbody></table></table-wrap></p>
      <p id="Par43">Clearly, the key of the wavelet denoising method is undoubtedly to select the value of threshold and threshold function, which has the greatest impact on the effect of wavelet denoising. There are generally three ways to select the value of threshold: default threshold, given threshold and forced threshold. In this article, the default threshold determination model is selected to calculate the value of the threshold because it is convenient and concise. Furthermore, there are two common threshold functions: a soft threshold function and a hard threshold function. We choose a soft threshold function for quantifying because it makes reconstructed signals considerably smoother than the hard one.</p>
    </sec>
    <sec id="Sec6">
      <title>Construction of prediction model</title>
      <p id="Par44">In this article, a new method, called PWD-FU-PseAAC, is proposed to predict the structural classes of protein sequences. First, the feature information of protein sequences is extracted by the traditional feature expression method, type 1 pseudo amino acid composition and type 2 pseudo amino acid composition. Each protein sequence is converted to 20+ <italic>λ</italic> dimensional numerical vectors by type 1 pseudo amino acid composition, and each protein sequence is converted to 20+ 2<italic>r</italic> dimensional numerical vectors by type 2 pseudo amino acid composition. Second two-dimensional wavelet denoising is used to denoise the two feature vectors separately. Then, the two feature vectors after denoising are fused, which refers to splicing the first and last vectors of the two parts to form 40+ <italic>λ</italic> + 2<italic>r</italic> dimensional feature vectors. Moreover, the optimal 40+ <italic>λ</italic> + 2<italic>r</italic> dimensional feature vectors are fed into the KNN classifier for predicting. The jackknife test is used to test the performance of the model on the 25PDB, the 1189PDB and the 640PDB. According to the predicting accuracy, the parameters of the model are adjusted continuously to optimize the performance of the model. Finally, four measures are used to evaluate the performance of the predicting model. The advantages of choosing the classifier KNN are its efficiency and simplicity. Although KNN’s classifying effect is not as good as that of support vector machine (SVM), KNN requires considerably less running time than SVM, as the latter requires considerably effort to determine the optimal parameters. Therefore, considering the classifiers comprehensively, we choose KNN instead of SVM. The flow chart of the model is shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Flow chart of the PWD-FU-PseAAC method</p></caption><graphic xlink:href="12859_2019_3276_Fig2_HTML" id="MO2"/></fig></p>
      <p id="Par45">In Fig. <xref rid="Fig2" ref-type="fig">2</xref>, new method of PWD-FU-PseAAC is as follows. The feature information of protein sequences is extracted by type 1 pseudo amino acid composition and type 2 pseudo amino acid composition, respectively. Then, 2-D wavelet denoising is used to denoise the two feature vectors, respectively. Next, the two feature vectors after denoising are fused to form a 40+ <italic>λ</italic> + 2<italic>r</italic> dimensional vector, which is entered to the KNN classifier for predicting.</p>
    </sec>
    <sec id="Sec7">
      <title>Performance evaluation</title>
      <p id="Par46">Four validation methods are commonly applied to estimate the performance of the prediction model: the self-consistency test, independent dataset test, k-fold cross-validation and jackknife test [<xref ref-type="bibr" rid="CR53">53</xref>–<xref ref-type="bibr" rid="CR57">57</xref>]. Because of the objectivity and strictness of the jackknife test, in this experiment, we make use of it to examine the performance of our prediction model. The sensitivity (Sens), specificity (Spec), overall accuracy (OA) and Matthews correlation coefficient (MCC) are applied to assess the performance of our method. These measures are expressed in the following formula:
<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ Sens=\frac{TP}{TP+ FN} $$\end{document}</tex-math><mml:math id="M30" display="block"><mml:mtext mathvariant="italic">Sens</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mi mathvariant="italic">TP</mml:mi><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="12859_2019_3276_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ Spec=\frac{TN}{FP+ TN} $$\end{document}</tex-math><mml:math id="M32" display="block"><mml:mtext mathvariant="italic">Spec</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mi mathvariant="italic">TN</mml:mi><mml:mrow><mml:mi mathvariant="italic">FP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="12859_2019_3276_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ OA=\frac{TP+ TN}{TP+ TN+ FP+ FN} $$\end{document}</tex-math><mml:math id="M34" display="block"><mml:mi mathvariant="italic">OA</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="12859_2019_3276_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ MCC=\frac{TP\times TN- FP\times FN}{\sqrt{\left( TP+ FP\right)\left( TP+ FN\right)\left( TN+ FP\right)\left( TN+ FN\right)}} $$\end{document}</tex-math><mml:math id="M36" display="block"><mml:mi mathvariant="italic">MCC</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow><mml:msqrt><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msqrt></mml:mfrac></mml:math><graphic xlink:href="12859_2019_3276_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula>where <italic>TP</italic> denotes the number of true positives, <italic>FP</italic> denotes the number of false positives, <italic>TN</italic> denotes the number of true negatives, and <italic>FN</italic> denotes the number of false negatives.</p>
    </sec>
  </sec>
  <sec id="Sec8">
    <title>Results and discussion</title>
    <sec id="Sec9">
      <title>Choice of λ and <italic>r</italic> parameters</title>
      <p id="Par47">In this article, two types of pseudo amino acid compositions are used to extract feature vectors, and different parameters of λ and <italic>r</italic> will lead to inconsistency of the feature information contained in the extracted feature vectors, thereby affecting the final prediction results. Therefore, it is necessary to choose the optimal value of λ and <italic>r</italic>, and the range of λ and <italic>r</italic> are 1 to 9, therefore, this section chooses the optimal parameter of λ or <italic>r</italic> between 1 and 9. In this paper, using the 25PDB as the research object, the validity of these feature vectors extracted from two different types of pseudo amino acids is discussed respectively. The wavelet basis function of two-dimensional wavelet denoising is db4, the wavelet decomposition scale is 3, and the K value of the KNN classifier is set to 3. The experimental results of the overall prediction accuracy of protein structural classes and the prediction accuracy of each class are shown in Table <xref rid="Tab3" ref-type="table">3</xref> and Table <xref rid="Tab4" ref-type="table">4</xref>.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Prediction results of type 1 PseAAC by different values of λ on the 25PDB</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3">Class</th><th colspan="9">λ</th></tr><tr><th colspan="9">Jackknife test(%)</th></tr><tr><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th></tr></thead><tbody><tr><td>all-α</td><td>77.43</td><td>94.58</td><td>88.71</td><td>85.10</td><td>88.94</td><td>88.49</td><td>87.36</td><td>88.26</td><td>87.81</td></tr><tr><td>all-β</td><td>89.16</td><td>90.52</td><td>90.52</td><td>89.39</td><td>88.94</td><td>88.04</td><td>90.29</td><td>90.29</td><td>90.52</td></tr><tr><td>α/β</td><td>78.03</td><td>88.73</td><td>86.42</td><td>83.53</td><td>87.57</td><td>86.71</td><td>86.99</td><td>89.31</td><td>91.62</td></tr><tr><td>α + β</td><td>68.03</td><td>78.23</td><td>76.87</td><td>75.28</td><td>76.42</td><td>75.28</td><td>72.11</td><td>73.47</td><td>71.20</td></tr><tr><td>OA</td><td>78.18</td><td>87.98</td><td>85.59</td><td>83.32</td><td>85.36</td><td>84.52</td><td>84.04</td><td>85.11</td><td>84.94</td></tr></tbody></table></table-wrap>
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Prediction results of type 2 PseAAC by different values of <italic>r</italic> on the 25PDB</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3">Class</th><th colspan="9"><italic>r</italic></th></tr><tr><th colspan="9">Jackknife test(%)</th></tr><tr><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th></tr></thead><tbody><tr><td>all-α</td><td>76.07</td><td>74.49</td><td>70.88</td><td>73.81</td><td>72.23</td><td>71.11</td><td>71.11</td><td>68.17</td><td>63.43</td></tr><tr><td>all-β</td><td>87.81</td><td>88.49</td><td>85.78</td><td>83.75</td><td>84.65</td><td>83.75</td><td>82.39</td><td>79.46</td><td>79.46</td></tr><tr><td>α/β</td><td>76.01</td><td>79.77</td><td>78.90</td><td>82.08</td><td>85.55</td><td>83.82</td><td>86.71</td><td>85.55</td><td>87.57</td></tr><tr><td>α + β</td><td>61.45</td><td>65.76</td><td>60.09</td><td>62.59</td><td>56.46</td><td>51.47</td><td>50.34</td><td>47.62</td><td>44.22</td></tr><tr><td>OA</td><td>75.31</td><td>76.99</td><td>73.64</td><td>75.19</td><td>74.12</td><td>71.91</td><td>71.85</td><td>69.34</td><td>67.60</td></tr></tbody></table></table-wrap></p>
      <p id="Par48">From Tables <xref rid="Tab3" ref-type="table">3</xref> and <xref rid="Tab4" ref-type="table">4</xref>, it can be concluded that different λ<sub>1</sub> and λ<sub>2</sub> values do have an impact on the prediction results. When λ and <italic>r</italic> are 2, the overall prediction accuracy is the highest, 87.98 and 76.99% respectively. Therefore, the optimum λ and <italic>r</italic> for both types of pseudo amino acid compositions is 2.</p>
    </sec>
    <sec id="Sec10">
      <title>Choice of the wavelet function and decomposition scale</title>
      <p id="Par49">The traditional feature expression method, type 1 pseudo amino acid composition and type 2 pseudo amino acid composition, are adopted in this article, which still contains considerable redundant information. To obtain more efficacious information, two-dimensional wavelet denoising is used to process the feature vectors extracted by two feature expression methods separately, removing the redundant information from them.</p>
      <p id="Par50">However, the choice of wavelet function and decomposition scale will determine the denoising effect of the models and then further affect the final overall prediction accuracy. To further obtain efficacious information on structural proteins, we chose different wavelet functions and different decomposition scales to examine the effect on the prediction models, including db2, db4, db6, sym2, sym4, sym6, coif1, coif3, bior2.2 and bior2.4, and the decomposition scale from 2 to 5. We discussed the optimal denoising parameters of the feature vectors extracted by type 1 PseAAC and type 2 PseAAC.</p>
      <p id="Par51">The 25PDB is selected as the sample for finding the optimal parameters. Table <xref rid="Tab5" ref-type="table">5</xref> and Table <xref rid="Tab6" ref-type="table">6</xref> show that the two related factors of the wavelet function and decomposition scale do affect the effect of denoising, thereby affecting the overall prediction accuracy of the method. When the decomposition scale is 5 and the db6 wavelet function is adopted, the effect of wavelet denoising is optimal in Table <xref rid="Tab5" ref-type="table">5</xref>; when the decomposition scale is 5 and the sym4 wavelet function is adopted, the effect of wavelet denoising is optimal in Table <xref rid="Tab6" ref-type="table">6</xref>. Hence, to obtain good prediction results, we choose 5 as the decomposition scale and db4 wavelet as the wavelet function to denoise feature vectors extracted by type 1 pseudo amino acid composition; we choose 5 as the decomposition scale and sym4 wavelet as the wavelet function to denoise feature vectors extracted by type 2 pseudo amino acid composition. In addition, Table <xref rid="Tab5" ref-type="table">5</xref> and Table <xref rid="Tab6" ref-type="table">6</xref> show that when the decomposition scale is 2, regardless of the type of wavelet basis function chosen, the overall prediction accuracy is lower than other scales. With the increase of the decomposition scale, the overall prediction accuracy has an upward trend. To describe this trend more intuitively, we drew line charts of the overall prediction accuracy under different wavelet basis functions and decomposition scales, as shown in Figs. <xref rid="Fig3" ref-type="fig">3</xref> and <xref rid="Fig4" ref-type="fig">4</xref>.
<table-wrap id="Tab5"><label>Table 5</label><caption><p>Prediction results on the 25PDB by different wavelet functions and different wavelet decomposition scales using type 1 PseAAC</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3">Wavelet</th><th colspan="4">Scales</th></tr><tr><th colspan="4">Jackknife test (%)</th></tr><tr><th>2</th><th>3</th><th>4</th><th>5</th></tr></thead><tbody><tr><td>db2</td><td>78.60</td><td>80.27</td><td>82.07</td><td>87.09</td></tr><tr><td>db4</td><td>83.68</td><td>87.99</td><td>94.08</td><td><bold>94.68</bold></td></tr><tr><td>db6</td><td>75.79</td><td>83.38</td><td>89.30</td><td>93.37</td></tr><tr><td>sym2</td><td>78.60</td><td>80.27</td><td>82.07</td><td>87.09</td></tr><tr><td>sym4</td><td>77.05</td><td>85.18</td><td>90.79</td><td>91.63</td></tr><tr><td>sym6</td><td>78.06</td><td>78.30</td><td>81.59</td><td>84.82</td></tr><tr><td>coif1</td><td>76.75</td><td>83.32</td><td>87.15</td><td>90.50</td></tr><tr><td>coif3</td><td>78.90</td><td>86.01</td><td>91.57</td><td>91.69</td></tr><tr><td>bior2.2</td><td>71.07</td><td>79.20</td><td>82.90</td><td>86.61</td></tr><tr><td>bior2.4</td><td>73.52</td><td>82.37</td><td>84.88</td><td>83.68</td></tr></tbody></table></table-wrap>
<table-wrap id="Tab6"><label>Table 6</label><caption><p>Prediction results on the 25PDB by different wavelet functions and different wavelet decomposition scales using type 2 PseAAC</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3">Wavelet</th><th colspan="4">Scales</th></tr><tr><th colspan="4">Jackknife test (%)</th></tr><tr><th>2</th><th>3</th><th>4</th><th>5</th></tr></thead><tbody><tr><td>db2</td><td>74.90</td><td>84.28</td><td>88.58</td><td>91.21</td></tr><tr><td>db4</td><td>78.84</td><td>76.99</td><td>86.01</td><td>86.25</td></tr><tr><td>db6</td><td>78.00</td><td>85.00</td><td>89.90</td><td>91.15</td></tr><tr><td>sym2</td><td>74.90</td><td>84.28</td><td>88.58</td><td>91.21</td></tr><tr><td>sym4</td><td>79.01</td><td>83.32</td><td>91.57</td><td><bold>93.37</bold></td></tr><tr><td>sym6</td><td>75.43</td><td>83.44</td><td>87.45</td><td>89.60</td></tr><tr><td>coif1</td><td>76.27</td><td>83.14</td><td>91.57</td><td>91.45</td></tr><tr><td>coif3</td><td>78.90</td><td>76.93</td><td>80.63</td><td>82.96</td></tr><tr><td>bior2.2</td><td>77.82</td><td>86.61</td><td>88.64</td><td>86.07</td></tr><tr><td>bior2.4</td><td>74.30</td><td>88.16</td><td>92.77</td><td>93.19</td></tr></tbody></table></table-wrap>
<fig id="Fig3"><label>Fig. 3</label><caption><p>Prediction results by type 1 PseAAC on different decomposition scales and wavelet basis functions on the 25PDB</p></caption><graphic xlink:href="12859_2019_3276_Fig3_HTML" id="MO3"/></fig>
<fig id="Fig4"><label>Fig. 4</label><caption><p>Prediction results by type 2 PseAAC on different decomposition scales and wavelet basis functions on the 25PDB</p></caption><graphic xlink:href="12859_2019_3276_Fig4_HTML" id="MO4"/></fig></p>
      <p id="Par52">As shown in Figs. <xref rid="Fig3" ref-type="fig">3</xref> and <xref rid="Fig4" ref-type="fig">4</xref>, with the increase of decomposition scale, the overall prediction accuracy obtained by experiments is improved under different conditions of wavelet basis functions. When the decomposition scales are 4 and 5, the overall prediction accuracy obtained by the experiment is notably close, which indicates that with the increase of the scale, the overall prediction accuracy will tend to be stable, will not continue to increase, or even may decline. Moreover, it can be seen from the Figs. <xref rid="Fig3" ref-type="fig">3</xref> and <xref rid="Fig4" ref-type="fig">4</xref> that although the choice of decomposition scale and wavelet basis function will affect the overall prediction accuracy of the experiment, the influence of the decomposition scale is greater than that of the wavelet basis function.</p>
    </sec>
    <sec id="Sec11">
      <title>Comparison with 1-D wavelet denoising</title>
      <p id="Par53">To verify the superiority of the two-dimensional (2-D) wavelet denoising method, we compare it with the one-dimensional (1-D) wavelet denoising method. The 1A1W structural protein sequence in the 25PDB was selected as the experimental sample to compare the denoising effect. The decomposition scale is 5, and the sym4 wavelet is chosen as the wavelet basis function. The K value in the classifier KNN is still 3. We use the 24-dimensional numerical feature vectors extracted from the 1A1W protein sequence through the type 2 pseudo amino acid composition as the original signal. to intuitively show the comparison of the two denoising effects, we choose the form of graph to show. The comparison results of one-dimensional wavelet denoising and two-dimensional wavelet denoising are shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Comparisons of 1-D wavelet denoising and 2-D wavelet denoising on the 25PDB</p></caption><graphic xlink:href="12859_2019_3276_Fig5_HTML" id="MO5"/></fig></p>
      <p id="Par54">As seen from Fig. <xref rid="Fig5" ref-type="fig">5</xref>, the original signal is notably messy, because it contains considerable redundant information, therefore, it seems to fluctuate. After 1-D wavelet denoising, although the signal has changed, the effect of denoising is not strong. After 2-D wavelet denoising, the signal is clearly different from the original signal, becoming smoother and more stable, indicating that the effect of denoising is notably good. This finding is observed in our study. We use variance to accurately describe the difference within the signal. The variance of the original signal is 30.526. After one-dimensional wavelet denoising, the variance of the signal is 14.274. After two-dimensional wavelet denoising, the variance of the signal becomes 6.189. In summary, the denoising effect of the 2-D wavelet is better than that of the 1-D wavelet.</p>
      <p id="Par55">To sum up, two-dimensional wavelet denoising is better than one-dimensional wavelet denoising, and this 2-D wavelet denoising method can be used not only in structural classes but also in other types of protein classification models.</p>
    </sec>
    <sec id="Sec12">
      <title>Selection of the K value in the K-nearest neighbor classifier</title>
      <p id="Par56">K- nearest neighbor classifier, which is based on the similarity of sample points to select the first K sample points for voting classification. However, this K value is often unknown, and choosing different K values will produce different prediction results. Therefore, to obtain better prediction results, it is necessary to select the optimal K value. In this section, the optimal K value is selected from 1 to 9. Under different K values, the prediction accuracy of each class and the overall prediction accuracy of the protein structure class sequence are shown in Table <xref rid="Tab7" ref-type="table">7</xref>. Under different K values, the prediction accuracy of each class and the overall prediction accuracy of the protein structure class sequence are shown in Table <xref rid="Tab7" ref-type="table">7</xref>.
<table-wrap id="Tab7"><label>Table 7</label><caption><p>Prediction results by choosing different values of K on the 25PDB</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3">Class</th><th colspan="9">K</th></tr><tr><th colspan="9">Jackknife test(%)</th></tr><tr><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th></tr></thead><tbody><tr><td>all-α</td><td>97.97</td><td>98.65</td><td>95.71</td><td>96.84</td><td>93.23</td><td>94.36</td><td>93.91</td><td>94.58</td><td>93.00</td></tr><tr><td>all-β</td><td>98.87</td><td>99.10</td><td>98.65</td><td>98.87</td><td>98.42</td><td>98.65</td><td>98.65</td><td>98.87</td><td>98.65</td></tr><tr><td>α/β</td><td>97.98</td><td>97.40</td><td>95.67</td><td>96.24</td><td>93.93</td><td>94.80</td><td>93.64</td><td>93.64</td><td>92.77</td></tr><tr><td>α + β</td><td>97.51</td><td>89.80</td><td>94.78</td><td>89.11</td><td>89.57</td><td>85.71</td><td>86.17</td><td>83.45</td><td>85.26</td></tr></tbody></table></table-wrap></p>
      <p id="Par58">As shown in Table <xref rid="Tab7" ref-type="table">7</xref>, different K values have a certain impact on the prediction results. In model 1, with the increase of K values, the overall prediction accuracy decreases. When K is 1, the overall prediction accuracy is the highest, 97.91%, while when K is 9, the overall prediction accuracy is the lowest, 91.33%. To visualize the overall prediction accuracy under different K conditions, we use a line chart to describe it, as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>. From the Fig. <xref rid="Fig6" ref-type="fig">6</xref>, it is clear that different K values will affect the prediction results of the experiment, and with the increase of K values, the overall prediction accuracy has a downward trend.
<fig id="Fig6"><label>Fig. 6</label><caption><p>Prediction results by choosing different values of K on the 25PDB</p></caption><graphic xlink:href="12859_2019_3276_Fig6_HTML" id="MO6"/></fig></p>
    </sec>
    <sec id="Sec13">
      <title>Comparison of different strategies</title>
      <p id="Par59">In this paper, a feature fusion model based on parallel two-dimensional wavelet denoising is proposed. To better demonstrate the improvement of the prediction accuracy of the models, this section compares with other strategies.</p>
      <p id="Par60">Compare various strategies on the 25PDB. In the table, strategy 1 refers to the use of type 1 pseudo amino acid composition only; strategy 2 refers to the use of type 2 pseudo amino acid composition only; strategy 3 refers to the combination of type 1 pseudo amino acid composition and two-dimensional wavelet denoising; strategy 4 refers to the combination of type 2 pseudo amino acid composition with two-dimensional wavelet denoising; and strategy 5 refers to the first combination of features extracted from type 1 and type 2 pseudo amino acid composition. The feature vector fusion is then combined with two-dimensional wavelet denoising; strategy 6 refers to the model proposed in this paper. Among these strategies, the parameters λ and <italic>r</italic> in the two types of pseudo amino acid composition are both 2. In the classifier, the K value in KNN ranges from 1 to 9, and the parameters in two-dimensional wavelet denoising are also the best denoising wavelet basis function and decomposition scale. The experimental results are shown in Table <xref rid="Tab8" ref-type="table">8</xref> and Fig. <xref rid="Fig7" ref-type="fig">7</xref>.
<table-wrap id="Tab8"><label>Table 8</label><caption><p>Comparison of different strategies on the 25PDB</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Dataset</th><th colspan="6">Prediction accuracy(%)</th></tr><tr><th>Strategy</th><th>all-α</th><th>all-β</th><th>α/β</th><th>α + β</th><th>OA</th></tr></thead><tbody><tr><td rowspan="6">25PDB</td><td>1</td><td>53.05</td><td>44.24</td><td>75.72</td><td>16.55</td><td>45.79</td></tr><tr><td>2</td><td>53.05</td><td>45.37</td><td>73.41</td><td>17.23</td><td>45.79</td></tr><tr><td>3</td><td>98.19</td><td>98.19</td><td>97.11</td><td>94.10</td><td>96.89</td></tr><tr><td>4</td><td>93.00</td><td>98.87</td><td>94.80</td><td>92.97</td><td>94.92</td></tr><tr><td>5</td><td>96.16</td><td>99.32</td><td>97.98</td><td>94.78</td><td>97.01</td></tr><tr><td><bold>6</bold></td><td><bold>99.97</bold></td><td><bold>98.87</bold></td><td><bold>97.98</bold></td><td><bold>97.51</bold></td><td><bold>98.09</bold></td></tr></tbody></table></table-wrap>
<fig id="Fig7"><label>Fig. 7</label><caption><p>Comparison of different strategies on the 25PDB</p></caption><graphic xlink:href="12859_2019_3276_Fig7_HTML" id="MO7"/></fig></p>
      <p id="Par61">From Table <xref rid="Tab8" ref-type="table">8</xref> and Fig. <xref rid="Fig7" ref-type="fig">7</xref>, it can be seen that the overall prediction accuracy of model 1 proposed in this paper reaches the highest level, 98.09%, and it can be seen from the table that the idea of parallel two-dimensional wavelet denoising proposed in this chapter is effective. Compared with strategy 5, first fusing feature vectors and then denoising, the overall prediction accuracy is improved by 1.08%, while the application of two-dimensional wavelet denoising improves the prediction accuracy by 1.08%. The measurement results have a great impact. Strategy 1 and Strategy 2 do not use two-dimensional wavelet denoising, and their prediction accuracy is far from that of other strategies. In conclusion, the fusion idea proposed in this model is highly effective.</p>
    </sec>
    <sec id="Sec14">
      <title>The influence of different classifiers on prediction results</title>
      <p id="Par62">Three classifiers: Naive Bayes, KNN and SVM are used to explore the effects of different classifiers on the prediction results. The parameters of two types of pseudo amino acid composition are 2. The denoising parameters of two-dimensional wavelet denoising for the extracted feature vectors of type 1 pseudo amino acid composition: the wavelet basis function is db4 wavelet, the decomposition scale is 5, and the denoising parameters of two-dimensional wavelet denoising for the extracted feature vectors of type 2 pseudo amino acid composition: the wavelet basis function is sym4, and the decomposition scale is 5. The K value of KNN is the best 1. For SVM, the radial basis function is used as the kernel function, and the grid search strategy is used for the selection of C and G parameters. The search ranges of both are 2<sup>− 10</sup> to 2<sup>10</sup>. The jackknife method was used to test the influence of three classifiers on the prediction results on the 25PDB. The experimental results are shown in Table <xref rid="Tab9" ref-type="table">9</xref> and Fig. <xref rid="Fig8" ref-type="fig">8</xref>.
<table-wrap id="Tab9"><label>Table 9</label><caption><p>Influence of different classifiers on prediction results on the 25PDB</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Classifier</th><th colspan="5">Prediction accuracy(%)</th></tr><tr><th>all-α</th><th>all-β</th><th>α/β</th><th>α + β</th><th>OA</th></tr></thead><tbody><tr><td>Naive Bayes</td><td>95.49</td><td>97.29</td><td>90.75</td><td>49.66</td><td>82.90</td></tr><tr><td>KNN</td><td><bold>99.97</bold></td><td><bold>98.87</bold></td><td><bold>97.98</bold></td><td><bold>97.51</bold></td><td><bold>98.09</bold></td></tr><tr><td>SVM</td><td>98.65</td><td>97.97</td><td>97.11</td><td>97.51</td><td>97.85</td></tr></tbody></table></table-wrap>
<fig id="Fig8"><label>Fig. 8</label><caption><p>Influence of different classifiers on prediction results on the 25PDB</p></caption><graphic xlink:href="12859_2019_3276_Fig8_HTML" id="MO8"/></fig></p>
      <p id="Par63">As shown in Table <xref rid="Tab9" ref-type="table">9</xref> and Fig. <xref rid="Fig8" ref-type="fig">8</xref>, when the KNN is used as the classifier, the overall prediction accuracy is the highest, 98.09%. The prediction accuracy of each category is the highest, and only the prediction accuracy of the α + β class is the highest in parallel with other categories. When Naive Bayes is used as the classifier, the overall prediction accuracy is 82.90%, which is considerably less than the KNN. This finding shows that the Naive Bayes is not as effective as the KNN in this experimental condition. When SVM is used as the classifier, the overall prediction accuracy is 97.85%. The possible reason for this finding is that the range of the parameter search is not appropriate, which causes the performance of SVM not to be as good as that of KNN. Moreover, SVM takes considerably more time to find parameters than KNN; therefore, considering the classifiers comprehensively, the classifier of this model chooses KNN.</p>
    </sec>
    <sec id="Sec15">
      <title>Prediction performance of our method</title>
      <p id="Par64">The performance of a method determines whether it can be applied by everyone. Therefore, as our study is no exception, the traditional performance evaluation methods are utilized to verify the performance of our methods. In model 1, based on two types of pseudo amino acid composition methods and parallel 2-D wavelet denoising, a machine learning prediction model with the fusion of two features is proposed, which is called PWD-FU-PseAAC. First, the feature information of protein sequences is extracted by type 1 pseudo amino acid composition and type 2 pseudo amino acid composition; in other words, the primary protein sequences are converted into 20 + λ dimensional and 20 + 2<italic>r</italic> dimensional numerical vectors respectively. Second, the 2-D wavelet denoising method is used to denoise the two feature vectors separately and remove their redundancy. Then, the two feature vectors after denoising are fused, which refers to splicing the first and last vectors of the two parts to form 40 + λ + 2<italic>r</italic> dimensional feature vectors. Finally, the optimal feature vectors are input into the KNN classifier for prediction, and the results are verified by jackknife. The optimal parameters of the prediction model can be obtained from the previous experimental analysis. The values of λ and <italic>r</italic> in both types of PseAAC are 2. The db4 wavelet is used as the wavelet function, and 5 is chosen as the decomposition scale to denoise the feature vectors extracted by type 1 PseAAC; Sym4 is chosen as the wavelet function and 5 is chosen as the decomposition scale to denoise the feature vectors extracted by type 2 PseAAC. The K value in the classifier is set to 1. The performance of the model is evaluated on the 25PDB, the 1189PDB and the 640PDB. The experimental results are shown in Table <xref rid="Tab10" ref-type="table">10</xref>.
<table-wrap id="Tab10"><label>Table 10</label><caption><p>Prediction performance of model 1 on three benchmark datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Dataset</th><th>Class</th><th>Sens(%)</th><th>Spec(%)</th><th>MCC</th><th>OA(%)</th></tr></thead><tbody><tr><td rowspan="4">25PDB</td><td>all-α</td><td>97.97</td><td>99.84</td><td>0.983</td><td char="." align="char" rowspan="4">98.09</td></tr><tr><td>all-β</td><td>98.87</td><td>99.84</td><td>0.989</td></tr><tr><td>α/β</td><td>97.98</td><td>99.17</td><td>0.967</td></tr><tr><td>α + β</td><td>97.51</td><td>98.62</td><td>0.957</td></tr><tr><td rowspan="4">1189</td><td>all-α</td><td>98.21</td><td>99.66</td><td>0.980</td><td char="." align="char" rowspan="4">97.25</td></tr><tr><td>all-β</td><td>99.32</td><td>99.87</td><td>0.993</td></tr><tr><td>α/β</td><td>99.10</td><td>97.23</td><td>0.950</td></tr><tr><td>α + β</td><td>91.29</td><td>99.41</td><td>0.930</td></tr><tr><td rowspan="4">640</td><td>all-α</td><td>95.65</td><td>99.20</td><td>0.954</td><td char="." align="char" rowspan="4">96.09</td></tr><tr><td>all-β</td><td>98.05</td><td>99.59</td><td>0.979</td></tr><tr><td>α/β</td><td>97.18</td><td>96.98</td><td>0.928</td></tr><tr><td>α + β</td><td>93.57</td><td>98.93</td><td>0.936</td></tr></tbody></table></table-wrap></p>
      <p id="Par65">The results of four standard performance measures are shown in Table <xref rid="Tab10" ref-type="table">10</xref>. From the results that emerged in Table <xref rid="Tab10" ref-type="table">10</xref>, we note that we acquire 98.09, 97.25 and 96.09% overall accuracy on the 25PDB, the 1189PDB and the 640PDB, respectively. The overall accuracy obtained on three datasets was highly satisfactory. Moreover, the Matthews correlation coefficient (MCC) of α + β class proteins are lower than other classes for the three datasets. Hence, there are many challenges to identifying protein sequences of the α + β class with high very efficacy.</p>
    </sec>
    <sec id="Sec16">
      <title>Comparison with existing methods</title>
      <p id="Par66">To objectively compare our method with previously reported methods, we carried out experiments under the same conditions as the previous methods. Among these methods, the MEDP [<xref ref-type="bibr" rid="CR58">58</xref>] method is based on evolutionary information, and a new feature expression method is proposed. The SCPRED [<xref ref-type="bibr" rid="CR22">22</xref>] method is based on predictive secondary structure to construct new feature vectors. The PKS-PPSC [<xref ref-type="bibr" rid="CR59">59</xref>] method is based on predictive secondary structure to construct feature vectors, but it uses chaotic game representation and information entropy to construct feature vectors. The method reported by Zhang et al. [<xref ref-type="bibr" rid="CR23">23</xref>] is based on predictive secondary structure information, based on this information, the TPM matrix feature representation is proposed. The PSSS-PSSM [<xref ref-type="bibr" rid="CR25">25</xref>] method combines predicted secondary structure features with the PSSM matrix. The PSSS-PsePSSM [<xref ref-type="bibr" rid="CR60">60</xref>] method combines predicted secondary structure features with improved PSSM matrix, and proposes a new fusion feature expression. The WD-PseAAC [<xref ref-type="bibr" rid="CR53">53</xref>] method extracts feature vectors based on SVM, using a single feature expression method and then denoises them with wavelet denoising. Our method is to denoise the extracted feature vectors and then fuse them.</p>
      <p id="Par67">The experimental results are summarized in Table <xref rid="Tab11" ref-type="table">11</xref> and Figs. <xref rid="Fig9" ref-type="fig">9</xref>, <xref rid="Fig10" ref-type="fig">10</xref>, <xref rid="Fig11" ref-type="fig">11</xref>. From the experimental results in Table <xref rid="Tab11" ref-type="table">11</xref> and Fig. <xref rid="Fig9" ref-type="fig">9</xref>, the overall prediction accuracy of 98.1% is gained on the 25PDB, which is the highest and 5.0 to 23.3% higher than those of other methods. Furthermore, from the experimental results in Table <xref rid="Tab11" ref-type="table">11</xref> and Fig. <xref rid="Fig10" ref-type="fig">10</xref>, the overall prediction accuracy of 97.3% is also obtained on the 1189PDB, which is the highest and 6.5 to 21.5% higher than those of other methods. Moreover, from the experimental results in Table <xref rid="Tab11" ref-type="table">11</xref> and Fig. <xref rid="Fig11" ref-type="fig">11</xref>, the prediction results are also satisfactory for the 640PDB. The prediction accuracy of the four classes is the highest, and the overall prediction accuracy is the highest, 95.0%. At the same time, there are other significant changes that deserve our attention. For example, the overall prediction accuracy of our method can achieve such good results on three datasets because we have greatly enhanced the prediction rates of α/β class proteins and α + β class proteins, while the prediction rates of other methods for α/β class proteins and α + β class proteins are notably low. One of the reasons that the overall prediction accuracy of protein structural classes has been relatively low is that it is difficult to predict α/β and α + β proteins.
<table-wrap id="Tab11"><label>Table 11</label><caption><p>Comparison with other methods on three benchmark datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Dataset</th><th char="×" colspan="6">Prediction accuracy(%)</th></tr><tr><th>Method</th><th>all-α</th><th>all-β</th><th>α/β</th><th>α + β</th><th>OA</th></tr></thead><tbody><tr><td rowspan="8">25PDB</td><td>MEDP [<xref ref-type="bibr" rid="CR58">58</xref>]</td><td>87.8</td><td>78.3</td><td>76.0</td><td>57.4</td><td>74.8</td></tr><tr><td>SCPRED [<xref ref-type="bibr" rid="CR22">22</xref>]</td><td>92.6</td><td>80.1</td><td>74.0</td><td>71.0</td><td>79.7</td></tr><tr><td>PKS-PPSC [<xref ref-type="bibr" rid="CR59">59</xref>]</td><td>89.2</td><td>86.7</td><td>82.6</td><td>65.6</td><td>81.3</td></tr><tr><td>Zhang et al. [<xref ref-type="bibr" rid="CR23">23</xref>]</td><td>92.4</td><td>87.4</td><td>82.0</td><td>71.0</td><td>83.9</td></tr><tr><td>PSSS-PSSM [<xref ref-type="bibr" rid="CR25">25</xref>]</td><td>96.6</td><td>87.1</td><td>83.0</td><td>78.9</td><td>86.6</td></tr><tr><td>PSSS-PsePSSM [<xref ref-type="bibr" rid="CR60">60</xref>]</td><td>96.4</td><td>90.5</td><td>90.2</td><td>81.2</td><td>89.5</td></tr><tr><td>WD-PseAAC [<xref ref-type="bibr" rid="CR53">53</xref>]</td><td>95.7</td><td>97.7</td><td>94.8</td><td>84.4</td><td>93.1</td></tr><tr><td><bold>This paper</bold></td><td><bold>98.0</bold></td><td><bold>98.9</bold></td><td><bold>98.0</bold></td><td><bold>97.5</bold></td><td><bold>98.1</bold></td></tr><tr><td rowspan="8">1189</td><td>MEDP [<xref ref-type="bibr" rid="CR58">58</xref>]</td><td>85.2</td><td>84.0</td><td>84.4</td><td>45.2</td><td>75.8</td></tr><tr><td>SCPRED [<xref ref-type="bibr" rid="CR22">22</xref>]</td><td>89.1</td><td>86.7</td><td>89.6</td><td>53.8</td><td>80.6</td></tr><tr><td>PKS-PPSC [<xref ref-type="bibr" rid="CR59">59</xref>]</td><td>89.2</td><td>86.7</td><td>82.6</td><td>65.6</td><td>81.3</td></tr><tr><td>Zhang et al. [<xref ref-type="bibr" rid="CR23">23</xref>]</td><td>92.4</td><td>87.4</td><td>82.0</td><td>71.0</td><td>83.2</td></tr><tr><td>PSSS-PSSM [<xref ref-type="bibr" rid="CR25">25</xref>]</td><td>94.2</td><td>88.4</td><td>85.3</td><td>71.8</td><td>85.0</td></tr><tr><td>PSSS-PsePSSM [<xref ref-type="bibr" rid="CR60">60</xref>]</td><td>91.9</td><td>91.8</td><td>87.7</td><td>73.9</td><td>86.6</td></tr><tr><td>WD-PseAAC [<xref ref-type="bibr" rid="CR53">53</xref>]</td><td>98.7</td><td>99.0</td><td>94.0</td><td>68.9</td><td>90.8</td></tr><tr><td><bold>This paper</bold></td><td><bold>98.2</bold></td><td><bold>99.3</bold></td><td><bold>99.1</bold></td><td><bold>91.3</bold></td><td><bold>97.3</bold></td></tr><tr><td rowspan="8">640</td><td>MEDP [<xref ref-type="bibr" rid="CR58">58</xref>]</td><td>84.8</td><td>75.3</td><td>86.4</td><td>53.8</td><td>74.7</td></tr><tr><td>SCPRED [<xref ref-type="bibr" rid="CR22">22</xref>]</td><td>90.6</td><td>81.8</td><td>85.9</td><td>66.7</td><td>80.8</td></tr><tr><td>PKS-PPSC [<xref ref-type="bibr" rid="CR59">59</xref>]</td><td>89.1</td><td>85.1</td><td>88.1</td><td>71.4</td><td>83.1</td></tr><tr><td>Zhang et al. [<xref ref-type="bibr" rid="CR23">23</xref>]</td><td>–</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td>PSSS-PSSM [<xref ref-type="bibr" rid="CR25">25</xref>]</td><td>–</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td>PSSS-PsePSSM [<xref ref-type="bibr" rid="CR60">60</xref>]</td><td>87.0</td><td>81.2</td><td>84.7</td><td>70.8</td><td>81.0</td></tr><tr><td>WD-PseAAC [<xref ref-type="bibr" rid="CR53">53</xref>]</td><td>92.8</td><td>95.5</td><td>92.1</td><td>78.9</td><td>89.5</td></tr><tr><td><bold>This paper</bold></td><td><bold>95.7</bold></td><td><bold>98.1</bold></td><td><bold>97.2</bold></td><td><bold>93.6</bold></td><td><bold>96.1</bold></td></tr></tbody></table></table-wrap>
<fig id="Fig9"><label>Fig. 9</label><caption><p>Comparison with other methods on the 25PDB</p></caption><graphic xlink:href="12859_2019_3276_Fig9_HTML" id="MO9"/></fig>
<fig id="Fig10"><label>Fig. 10</label><caption><p>Comparison with other methods on the 1189PDB</p></caption><graphic xlink:href="12859_2019_3276_Fig10_HTML" id="MO10"/></fig>
<fig id="Fig11"><label>Fig. 11</label><caption><p>Comparison with other methods on the 640PDB</p></caption><graphic xlink:href="12859_2019_3276_Fig11_HTML" id="MO11"/></fig></p>
      <p id="Par68">In summary, through the analysis of the above experimental results, we can conclude that our models can efficaciously forecast the structural classes of protein sequences, even on the low-similarity datasets. The reason why our method is better than others is that although the traditional method is used to extract feature vectors, the feature extraction method that we adopt may not be as good as others. However, after feature extraction, we use two-dimensional wavelet denoising to denoise the redundant information in the feature vector, which makes it more recognizable. In addition, other researchers also use the method of wavelet denoising, but this paper proposes a new fusion strategy based on wavelet denoising.</p>
    </sec>
  </sec>
  <sec id="Sec17">
    <title>Conclusions</title>
    <p id="Par69">A new method, PWD-FU-PseAAC, is proposed to forecast the structural classes of protein sequences. The method ameliorates the shortcomings of traditional feature expression methods, which contain considerable redundant information that cannot result in inefficiency. Therefore, in this paper, a new idea of fusion has been proposed, in which a parallel 2-D wavelet denoising algorithm is adopted to process the extracted feature vectors before fusing them. Through related experiments, we not only verify the effect of the wavelet denoising algorithm on the models but also compare the overall accuracy of our models with those of other methods. Ultimately, we can conclude that our method is good for predicting the structural classes of protein sequences and is expected to be applied in other fields related to bioinformatics [<xref ref-type="bibr" rid="CR61">61</xref>–<xref ref-type="bibr" rid="CR74">74</xref>]. The related source codes and datesets are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Xiaoheng-Wang12/Wang-xiaoheng/tree/master">https://github.com/Xiaoheng-Wang12/Wang-xiaoheng/tree/master</ext-link>.</p>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>1-D</term>
        <def>
          <p id="Par4">One dimentonal</p>
        </def>
      </def-item>
      <def-item>
        <term>2-D</term>
        <def>
          <p id="Par5">Two dimentonal</p>
        </def>
      </def-item>
      <def-item>
        <term>ACC</term>
        <def>
          <p id="Par6">Amino acid composition</p>
        </def>
      </def-item>
      <def-item>
        <term>KNN</term>
        <def>
          <p id="Par7">K-nearest neighbors</p>
        </def>
      </def-item>
      <def-item>
        <term>MCC</term>
        <def>
          <p id="Par8">Matthews correlation coefficient</p>
        </def>
      </def-item>
      <def-item>
        <term>OA</term>
        <def>
          <p id="Par9">Overall accuracy</p>
        </def>
      </def-item>
      <def-item>
        <term>PseACC</term>
        <def>
          <p id="Par10">Pseudo amino acid composition</p>
        </def>
      </def-item>
      <def-item>
        <term>Sens</term>
        <def>
          <p id="Par11">Sensitivity</p>
        </def>
      </def-item>
      <def-item>
        <term>Spec</term>
        <def>
          <p id="Par12">Specificity</p>
        </def>
      </def-item>
      <def-item>
        <term>SVM</term>
        <def>
          <p id="Par13">Support vector machines</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>Shunfang Wang and Xiaoheng Wang contributed equally to this work.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>The authors would like to thank the reviewers and editors for their patient guidance and valuable suggestions.</p>
    <sec id="FPar1">
      <title>About this supplement</title>
      <p id="Par70">This article has been published as part of <italic>BMC Bioinformatics Volume 20 Supplement 25, 2019: Proceedings of the 2018 International Conference on Intelligent Computing (ICIC 2018) and Intelligent Computing and Biomedical Informatics (ICBI) 2018 conference: bioinformatics.</italic> The full contents of the supplement are available online at https://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-20-supplement-25.</p>
    </sec>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>Wang SF designed the research and Wang XH designed the experiments. Wang XH performed most of the numerical experiments. Wang SF and Wang XH analyzed the experimental results and wrote this paper. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Publication costs are funded by grants from National Natural Science Foundation of China (11661081), Natural Science Foundation of Yunnan Province (2017FA032) and Training Plan for Young and Middle-aged Academic Leaders of Yunnan Province (2018HB031).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The related source codes and datasets are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Xiaoheng-Wang12/Wang-xiaoheng/tree/master">https://github.com/Xiaoheng-Wang12/Wang-xiaoheng/tree/master</ext-link>.</p>
  </notes>
  <notes>
    <title>Ethics approval and consent to participate</title>
    <p id="Par71">Not applicable.</p>
  </notes>
  <notes>
    <title>Consent for publication</title>
    <p id="Par72">Not applicable.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par73">The authors declare that they have no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>Structural bioinformatics and its impact to biomedical science [J]</article-title>
        <source>Curr Med Chem</source>
        <year>2004</year>
        <volume>11</volume>
        <fpage>2105</fpage>
        <lpage>2134</lpage>
        <pub-id pub-id-type="doi">10.2174/0929867043364667</pub-id>
        <?supplied-pmid 15279552?>
        <pub-id pub-id-type="pmid">15279552</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>Progress in protein structural class prediction and its impact to bioinformatics and proteomics [J]</article-title>
        <source>Curr Protein Pept Sci</source>
        <year>2005</year>
        <volume>6</volume>
        <fpage>423</fpage>
        <lpage>436</lpage>
        <pub-id pub-id-type="doi">10.2174/138920305774329368</pub-id>
        <?supplied-pmid 16248794?>
        <pub-id pub-id-type="pmid">16248794</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peng</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Zou</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DS</given-names>
          </name>
        </person-group>
        <article-title>Discovery of relationships between long non-coding RNAs and genes in human diseases based on tensor completion [J]</article-title>
        <source>IEEE Access</source>
        <year>2018</year>
        <volume>6</volume>
        <fpage>59152</fpage>
        <lpage>59162</lpage>
        <pub-id pub-id-type="doi">10.1109/ACCESS.2018.2873013</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yi</surname>
            <given-names>HC</given-names>
          </name>
          <name>
            <surname>You</surname>
            <given-names>ZH</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DS</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A deep learning framework for robust and accurate prediction of ncRNA-protein interactions using evolutionary information [J]</article-title>
        <source>Mol Ther Nucleic Acids</source>
        <year>2018</year>
        <volume>11</volume>
        <fpage>337</fpage>
        <lpage>344</lpage>
        <pub-id pub-id-type="doi">10.1016/j.omtn.2018.03.001</pub-id>
        <?supplied-pmid 29858068?>
        <pub-id pub-id-type="pmid">29858068</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bao</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DS</given-names>
          </name>
        </person-group>
        <article-title>Novel human microbe-disease association prediction using network consistency projection [J]</article-title>
        <source>BMC Bioinformatics</source>
        <year>2017</year>
        <volume>18</volume>
        <fpage>543</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-017-1968-2</pub-id>
        <?supplied-pmid 5751545?>
        <pub-id pub-id-type="pmid">29297304</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>WL</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DS</given-names>
          </name>
        </person-group>
        <article-title>An efficient method to transcription factor binding sites imputation via simultaneous completion of multiple matrices with positional consistency [J]</article-title>
        <source>Mol BioSyst</source>
        <year>2017</year>
        <volume>13</volume>
        <fpage>1827</fpage>
        <lpage>1837</lpage>
        <pub-id pub-id-type="doi">10.1039/C7MB00155J</pub-id>
        <?supplied-pmid 28718849?>
        <pub-id pub-id-type="pmid">28718849</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chuai</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DeepCRISPR: optimized CRISPR guide RNA design by deep learning [J]</article-title>
        <source>Genome Biol</source>
        <year>2018</year>
        <volume>19</volume>
        <fpage>80</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-018-1459-4</pub-id>
        <?supplied-pmid 29945655?>
        <pub-id pub-id-type="pmid">29945655</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yuan</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>WL</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Nonconvex penalty based low-rank representation and sparse regression for eQTL mapping [J]</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinformatics</source>
        <year>2017</year>
        <volume>14</volume>
        <fpage>1154</fpage>
        <lpage>1164</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2016.2609420</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Ai</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>HLPI-ensemble: prediction of human lncRNA-protein interactions based on ensemble strategy [J]</article-title>
        <source>RNA Biol</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>797</fpage>
        <lpage>806</lpage>
        <pub-id pub-id-type="doi">10.1080/15476286.2017.1411461</pub-id>
        <?supplied-pmid 29583068?>
        <pub-id pub-id-type="pmid">29583068</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ming</surname>
            <given-names>Z</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The bipartite network projection-recommended algorithm for predicting long non-coding RNA-protein interactions [J]</article-title>
        <source>Mol Ther Nucleic Acids</source>
        <year>2018</year>
        <volume>13</volume>
        <fpage>464</fpage>
        <lpage>471</lpage>
        <pub-id pub-id-type="doi">10.1016/j.omtn.2018.09.020</pub-id>
        <?supplied-pmid 30388620?>
        <pub-id pub-id-type="pmid">30388620</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>IRWNRLPI: integrating random walk and neighborhood regularized logistic matrix factorization for lncRNA-protein interaction prediction [J]</article-title>
        <source>Front Genet</source>
        <year>2018</year>
        <volume>9</volume>
        <fpage>239</fpage>
        <pub-id pub-id-type="doi">10.3389/fgene.2018.00239</pub-id>
        <?supplied-pmid 30023002?>
        <pub-id pub-id-type="pmid">30023002</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>CT</given-names>
          </name>
        </person-group>
        <article-title>A correlation-coefficient method to predicting protein-structural classes from amino acid compositions [J]</article-title>
        <source>Eur J Biochem</source>
        <year>1992</year>
        <volume>207</volume>
        <fpage>429</fpage>
        <lpage>433</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1432-1033.1992.tb17067.x</pub-id>
        <?supplied-pmid 1633801?>
        <pub-id pub-id-type="pmid">1633801</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>CT</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Maggiora</surname>
            <given-names>GM</given-names>
          </name>
        </person-group>
        <article-title>Predicting protein structural classes from amino acid composition: application of fuzzy clustering [J]</article-title>
        <source>Protein Eng</source>
        <year>1995</year>
        <volume>8</volume>
        <fpage>425</fpage>
        <lpage>435</lpage>
        <pub-id pub-id-type="doi">10.1093/protein/8.5.425</pub-id>
        <?supplied-pmid 8532663?>
        <pub-id pub-id-type="pmid">8532663</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>TL</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>YS</given-names>
          </name>
        </person-group>
        <article-title>Using pseudo amino acid composition and binary-tree support vector machines to predict protein structural classes [J]</article-title>
        <source>Amino Acids</source>
        <year>2007</year>
        <volume>33</volume>
        <fpage>623</fpage>
        <lpage>629</lpage>
        <pub-id pub-id-type="doi">10.1007/s00726-007-0496-1</pub-id>
        <?supplied-pmid 17308864?>
        <pub-id pub-id-type="pmid">17308864</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>YX</given-names>
          </name>
          <name>
            <surname>Zou</surname>
            <given-names>XY</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Using pseudo-amino acid composition and support vector machine to predict protein structural class [J]</article-title>
        <source>J Theor Biol</source>
        <year>2006</year>
        <volume>243</volume>
        <fpage>444</fpage>
        <lpage>448</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2006.06.025</pub-id>
        <?supplied-pmid 16908032?>
        <pub-id pub-id-type="pmid">16908032</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>YS</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>TL</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein structure classes with Pseudo amino acid composition and fuzzy support vector machine network [J]</article-title>
        <source>Protein Pept Lett</source>
        <year>2007</year>
        <volume>14</volume>
        <fpage>811</fpage>
        <lpage>815</lpage>
        <pub-id pub-id-type="doi">10.2174/092986607781483778</pub-id>
        <?supplied-pmid 17979824?>
        <pub-id pub-id-type="pmid">17979824</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>TL</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>YS</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>Prediction protein structural classes with pseudo-amino acid composition: approximate entropy and hydrophobicity pattern [J]</article-title>
        <source>J Theor Biol</source>
        <year>2008</year>
        <volume>250</volume>
        <fpage>186</fpage>
        <lpage>193</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2007.09.014</pub-id>
        <?supplied-pmid 17959199?>
        <pub-id pub-id-type="pmid">17959199</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>Predicting protein structural classes with pseudo amino acid composition: an approach using geometric moments of cellular automaton image [J]</article-title>
        <source>J Theor Biol</source>
        <year>2008</year>
        <volume>254</volume>
        <fpage>691</fpage>
        <lpage>696</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2008.06.016</pub-id>
        <?supplied-pmid 18634802?>
        <pub-id pub-id-type="pmid">18634802</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>ZC</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>XB</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>Z</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Prediction of protein structural classes by Chou’s pseudo amino acid composition: approached using continuous wavelet transform and principal component analysis [J]</article-title>
        <source>Amino Acids</source>
        <year>2009</year>
        <volume>37</volume>
        <fpage>415</fpage>
        <lpage>425</lpage>
        <pub-id pub-id-type="doi">10.1007/s00726-008-0170-2</pub-id>
        <?supplied-pmid 18726140?>
        <pub-id pub-id-type="pmid">18726140</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luo</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein structural class by amino acid and polypeptide composition.[J]</article-title>
        <source>Eur J Biochem</source>
        <year>2002</year>
        <volume>269</volume>
        <fpage>4219</fpage>
        <lpage>4225</lpage>
        <pub-id pub-id-type="doi">10.1046/j.1432-1033.2002.03115.x</pub-id>
        <?supplied-pmid 12199700?>
        <pub-id pub-id-type="pmid">12199700</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Costantini</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Facchiano</surname>
            <given-names>AM</given-names>
          </name>
        </person-group>
        <article-title>Prediction of the protein structural class by specific peptide frequencies [J]</article-title>
        <source>Biochimie</source>
        <year>2009</year>
        <volume>91</volume>
        <fpage>226</fpage>
        <lpage>229</lpage>
        <pub-id pub-id-type="doi">10.1016/j.biochi.2008.09.005</pub-id>
        <?supplied-pmid 18957316?>
        <pub-id pub-id-type="pmid">18957316</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kurgan</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Cios</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>SCPRED: accurate prediction of protein structural class for sequences of twilight-zone similarity with predicting sequences [J]</article-title>
        <source>Bmc Bioinformatics</source>
        <year>2008</year>
        <volume>9</volume>
        <fpage>1</fpage>
        <lpage>15</lpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-9-226</pub-id>
        <pub-id pub-id-type="pmid">18173834</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Zhang S, Ding S, Wang T. High-accuracy prediction of protein structural class for low-similarity sequences based on predicted secondary structure [J]. Biochimie 2011;93:0–714.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dai</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>X</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Comparison study on statistical features of predicted secondary structures for protein structural class prediction: from content to position [J]</article-title>
        <source>BMC Bioinformatics</source>
        <year>2013</year>
        <volume>14</volume>
        <fpage>152</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-14-152</pub-id>
        <?supplied-pmid 23641706?>
        <pub-id pub-id-type="pmid">23641706</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>Z</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A protein structural classes prediction method based on predicted secondary structure and PSI-BLAST profile [J]</article-title>
        <source>Biochimie</source>
        <year>2014</year>
        <volume>97</volume>
        <fpage>60</fpage>
        <lpage>65</lpage>
        <pub-id pub-id-type="doi">10.1016/j.biochi.2013.09.013</pub-id>
        <?supplied-pmid 24067326?>
        <pub-id pub-id-type="pmid">24067326</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Prediction of protein structural classes based on feature selection technique [J]</article-title>
        <source>Interdiscip Sci</source>
        <year>2014</year>
        <volume>6</volume>
        <fpage>235</fpage>
        <lpage>240</lpage>
        <pub-id pub-id-type="doi">10.1007/s12539-013-0205-6</pub-id>
        <?supplied-pmid 25205501?>
        <pub-id pub-id-type="pmid">25205501</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>LX</given-names>
          </name>
          <name>
            <surname>Zou</surname>
            <given-names>XY</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Predicting protein structural class based on multi-features fusion [J]</article-title>
        <source>J Theor Biol</source>
        <year>2008</year>
        <volume>253</volume>
        <fpage>388</fpage>
        <lpage>392</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2008.03.009</pub-id>
        <?supplied-pmid 18423494?>
        <pub-id pub-id-type="pmid">18423494</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kumar</surname>
            <given-names>AV</given-names>
          </name>
          <name>
            <surname>Ali</surname>
            <given-names>RFM</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Application of data mining tools for classification of protein structural class from residue based averaged NMR chemical shifts [J]</article-title>
        <source>Biochim Biophys Acta</source>
        <year>1854</year>
        <volume>2015</volume>
        <fpage>1545</fpage>
        <lpage>1552</lpage>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nanni</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Brahnam</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lumini</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein structure classes by incorporating different protein descriptors into general Chou’s pseudo amino acid composition [J]</article-title>
        <source>J Theor Biol</source>
        <year>2014</year>
        <volume>360</volume>
        <fpage>109</fpage>
        <lpage>116</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2014.07.003</pub-id>
        <?supplied-pmid 25026218?>
        <pub-id pub-id-type="pmid">25026218</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Prediction of protein structural classes for low-similarity sequences using reduced PSSM and position-based secondary structural [J]</article-title>
        <source>Gene</source>
        <year>2015</year>
        <volume>554</volume>
        <fpage>241</fpage>
        <lpage>248</lpage>
        <pub-id pub-id-type="doi">10.1016/j.gene.2014.10.037</pub-id>
        <?supplied-pmid 25445293?>
        <pub-id pub-id-type="pmid">25445293</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dehzangi</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Proposing a highly accurate protein structural class predictor using segmentation-based features [J]</article-title>
        <source>BMC Genomics</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>1</fpage>
        <lpage>13</lpage>
        <pub-id pub-id-type="doi">10.1186/1471-2164-15-S1-S2</pub-id>
        <pub-id pub-id-type="pmid">24382143</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Qin</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Prediction of protein structural class based on gapped-dipeptides and a recursive feature selection approach [J]</article-title>
        <source>Int J Mol Sci</source>
        <year>2015</year>
        <volume>17</volume>
        <fpage>15</fpage>
        <lpage>24</lpage>
        <pub-id pub-id-type="doi">10.3390/ijms17010015</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cai</surname>
            <given-names>YD</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>GP</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein structural classes by neural network [J]</article-title>
        <source>Biochimie</source>
        <year>2000</year>
        <volume>82</volume>
        <fpage>783</fpage>
        <lpage>785</lpage>
        <pub-id pub-id-type="doi">10.1016/S0300-9084(00)01161-5</pub-id>
        <?supplied-pmid 11018296?>
        <pub-id pub-id-type="pmid">11018296</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shen</surname>
            <given-names>HB</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>XJ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Using supervised fuzzy clustering to predict protein structural classes [J]</article-title>
        <source>Biochem Biophys Res Commun</source>
        <year>2005</year>
        <volume>334</volume>
        <fpage>577</fpage>
        <lpage>581</lpage>
        <pub-id pub-id-type="doi">10.1016/j.bbrc.2005.06.128</pub-id>
        <?supplied-pmid 16023077?>
        <pub-id pub-id-type="pmid">16023077</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chinnasamy</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sung</surname>
            <given-names>WK</given-names>
          </name>
          <name>
            <surname>Mittal</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Protein structure and fold prediction using tree-augmented naive Bayesian classifier [J]</article-title>
        <source>J Bioinforma Comput Biol</source>
        <year>2005</year>
        <volume>3</volume>
        <fpage>387</fpage>
        <lpage>398</lpage>
        <pub-id pub-id-type="doi">10.1142/S0219720005001302</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>An information-theoretic approach to the prediction of protein structural class [J]</article-title>
        <source>J Comput Chem</source>
        <year>2010</year>
        <volume>31</volume>
        <fpage>1201</fpage>
        <lpage>1206</lpage>
        <pub-id pub-id-type="doi">10.1002/jcc.21503</pub-id>
        <?supplied-pmid 19777491?>
        <pub-id pub-id-type="pmid">19777491</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cai</surname>
            <given-names>YD</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>XJ</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>XB</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Prediction of protein structural classes by support vector machines [J]</article-title>
        <source>Comput Chem</source>
        <year>2002</year>
        <volume>26</volume>
        <fpage>293</fpage>
        <lpage>296</lpage>
        <pub-id pub-id-type="doi">10.1016/S0097-8485(01)00113-9</pub-id>
        <?supplied-pmid 11868916?>
        <pub-id pub-id-type="pmid">11868916</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>XD</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>RB</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein structural classes using support vector machines [J]</article-title>
        <source>Amino Acids (Vienna)</source>
        <year>2006</year>
        <volume>30</volume>
        <fpage>469</fpage>
        <lpage>475</lpage>
        <pub-id pub-id-type="doi">10.1007/s00726-005-0239-0</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cai</surname>
            <given-names>YD</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>KY</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>WC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Using LogitBoost classifier to predict protein structural classes [J]</article-title>
        <source>J Theor Biol</source>
        <year>2006</year>
        <volume>238</volume>
        <fpage>172</fpage>
        <lpage>176</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2005.05.034</pub-id>
        <?supplied-pmid 16043193?>
        <pub-id pub-id-type="pmid">16043193</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Qiao</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Ensemble learning for protein multiplex subcellular localization prediction based on weighted KNN with different features [J]</article-title>
        <source>Appl Intell</source>
        <year>2018</year>
        <volume>48</volume>
        <fpage>1813</fpage>
        <lpage>1824</lpage>
        <pub-id pub-id-type="doi">10.1007/s10489-017-1029-6</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Predicting protein structural class with pseudo-amino acid composition and support vector machine fusion network [J]</article-title>
        <source>Anal Biochem</source>
        <year>2006</year>
        <volume>357</volume>
        <fpage>116</fpage>
        <lpage>121</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ab.2006.07.022</pub-id>
        <?supplied-pmid 16920060?>
        <pub-id pub-id-type="pmid">16920060</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dehzangi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Paliwal</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Sharma</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A combination of feature extraction methods with an Ensemble of Different Classifiers for protein structural class prediction problem [J]</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <year>2013</year>
        <volume>10</volume>
        <fpage>564</fpage>
        <lpage>575</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2013.65</pub-id>
        <?supplied-pmid 24091391?>
        <pub-id pub-id-type="pmid">24091391</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein cellular attributes using pseudo amino acid composition [J]</article-title>
        <source>Proteins</source>
        <year>2001</year>
        <volume>44</volume>
        <fpage>246</fpage>
        <lpage>255</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.1035</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>Using amphiphilic pseudo amino acid composition to predict enzyme subfamily classes [J]</article-title>
        <source>Bioinformatics</source>
        <year>2005</year>
        <volume>21</volume>
        <fpage>10</fpage>
        <lpage>19</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bth466</pub-id>
        <?supplied-pmid 15308540?>
        <pub-id pub-id-type="pmid">15308540</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>WY</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Accurate prediction of subcellular location of apoptosis proteins combining Chou’s PseAAC and PsePSSM based on wavelet denoising [J]</article-title>
        <source>Oncotarget</source>
        <year>2017</year>
        <volume>8</volume>
        <fpage>107640</fpage>
        <lpage>107665</lpage>
        <?supplied-pmid 29296195?>
        <pub-id pub-id-type="pmid">29296195</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kurgan</surname>
            <given-names>LA</given-names>
          </name>
          <name>
            <surname>Homaeian</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Prediction of structural classes for protein sequences and domains—impact of prediction algorithms, sequence representation and homology, and test procedures on accuracy [J]</article-title>
        <source>Pattern Recogn</source>
        <year>2006</year>
        <volume>39</volume>
        <fpage>2323</fpage>
        <lpage>2343</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patcog.2006.02.014</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>ZX</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>How good is prediction of protein structural class by the component-coupled method?[J]</article-title>
        <source>Proteins-struct Funct Bioinformatics</source>
        <year>2015</year>
        <volume>38</volume>
        <fpage>165</fpage>
        <lpage>175</lpage>
        <pub-id pub-id-type="doi">10.1002/(SICI)1097-0134(20000201)38:2&lt;165::AID-PROT5&gt;3.0.CO;2-V</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Kurgan</surname>
            <given-names>LA</given-names>
          </name>
          <name>
            <surname>Ruan</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein structural class using novel evolutionary collocation-based sequence representation [J]</article-title>
        <source>J Comput Chem</source>
        <year>2008</year>
        <volume>29</volume>
        <fpage>1596</fpage>
        <lpage>1604</lpage>
        <pub-id pub-id-type="doi">10.1002/jcc.20918</pub-id>
        <?supplied-pmid 18293306?>
        <pub-id pub-id-type="pmid">18293306</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Qiu</surname>
            <given-names>WY</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>XM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Predicting protein submitochondrial locations by incorporating the pseudo-position specific scoring matrix into the general Chou’s pseudo-amino acid composition [J]</article-title>
        <source>J Theor Biol</source>
        <year>2018</year>
        <volume>450</volume>
        <fpage>86</fpage>
        <lpage>103</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2018.04.026</pub-id>
        <?supplied-pmid 29678694?>
        <pub-id pub-id-type="pmid">29678694</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luisier</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Blu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Unser</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>A new SURE approach to image Denoising: Interscale orthonormal wavelet Thresholding [J]</article-title>
        <source>IEEE Trans Image Process</source>
        <year>2007</year>
        <volume>16</volume>
        <fpage>593</fpage>
        <lpage>606</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2007.891064</pub-id>
        <?supplied-pmid 17357721?>
        <pub-id pub-id-type="pmid">17357721</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chang</surname>
            <given-names>SG</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Vetterli</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Adaptive wavelet thresholding for image denoising and compression [J]</article-title>
        <source>IEEE Trans Image Process</source>
        <year>2000</year>
        <volume>9</volume>
        <fpage>1532</fpage>
        <lpage>1546</lpage>
        <pub-id pub-id-type="doi">10.1109/83.862633</pub-id>
        <?supplied-pmid 18262991?>
        <pub-id pub-id-type="pmid">18262991</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <mixed-citation publication-type="other">Selesnick IW, Li KY. Video denoising using 2D and 3D dual-tree complex wavelet transforms [C]. Wavelets: Applications in Signal and Image Processing X. Int Soc Opt Photonics. 2003.</mixed-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Lou</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Prediction of protein structural class for low-similarity sequences using Chou's pseudo amino acid composition and wavelet denoising [J]</article-title>
        <source>J Mol Graph Model</source>
        <year>2017</year>
        <volume>76</volume>
        <fpage>260</fpage>
        <lpage>273</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmgm.2017.07.012</pub-id>
        <?supplied-pmid 28743071?>
        <pub-id pub-id-type="pmid">28743071</pub-id>
      </element-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>CH</given-names>
          </name>
        </person-group>
        <article-title>Independent component analysis-based penalized discriminant method for tumor classification using gene expression data [J]</article-title>
        <source>Bioinformatics</source>
        <year>2006</year>
        <volume>22</volume>
        <fpage>1855</fpage>
        <lpage>1862</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btl190</pub-id>
        <?supplied-pmid 16709589?>
        <pub-id pub-id-type="pmid">16709589</pub-id>
      </element-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deng</surname>
            <given-names>SP</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DS</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Identifying stages of kidney renal cell carcinoma by combining gene expression and DNA methylation data [J]</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <year>2017</year>
        <volume>14</volume>
        <fpage>1147</fpage>
        <lpage>1153</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2016.2607717</pub-id>
        <pub-id pub-id-type="pmid">28113675</pub-id>
      </element-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Qiu</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>SH</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>JH</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Using support vector machines for prediction of protein structural classes based on discrete wavelet transform [J]</article-title>
        <source>J Comput Chem</source>
        <year>2009</year>
        <volume>30</volume>
        <fpage>1344</fpage>
        <lpage>1350</lpage>
        <pub-id pub-id-type="doi">10.1002/jcc.21115</pub-id>
        <?supplied-pmid 19009604?>
        <pub-id pub-id-type="pmid">19009604</pub-id>
      </element-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Improving the prediction accuracy of protein structural class: approached with alternating word frequency and normalized Lempel–Ziv complexity [J]</article-title>
        <source>J Theor Biol</source>
        <year>2014</year>
        <volume>341</volume>
        <fpage>71</fpage>
        <lpage>77</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2013.10.002</pub-id>
        <?supplied-pmid 24140787?>
        <pub-id pub-id-type="pmid">24140787</pub-id>
      </element-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Kong</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Predict protein structural class for low-similarity sequences by evolutionary difference information into the general form of chou’s pseudo amino acid composition [J]</article-title>
        <source>J Theor Biol</source>
        <year>2014</year>
        <volume>355</volume>
        <fpage>105</fpage>
        <lpage>110</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2014.04.008</pub-id>
        <?supplied-pmid 24735902?>
        <pub-id pub-id-type="pmid">24735902</pub-id>
      </element-citation>
    </ref>
    <ref id="CR59">
      <label>59.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>ZL</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein structural classes for low-homology sequences based on predicted secondary structure [J]</article-title>
        <source>BMC Bioinformatics</source>
        <year>2010</year>
        <volume>11</volume>
        <fpage>S9</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-11-S1-S9</pub-id>
        <?supplied-pmid 20438656?>
        <pub-id pub-id-type="pmid">20438656</pub-id>
      </element-citation>
    </ref>
    <ref id="CR60">
      <label>60.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>SL</given-names>
          </name>
        </person-group>
        <article-title>Accurate prediction of protein structural classes by incorporating PSSS and PSSM into Chou’s general PseAAC [J]</article-title>
        <source>Chemom Intell Lab Syst</source>
        <year>2015</year>
        <volume>142</volume>
        <fpage>28</fpage>
        <lpage>35</lpage>
        <pub-id pub-id-type="doi">10.1016/j.chemolab.2015.01.004</pub-id>
      </element-citation>
    </ref>
    <ref id="CR61">
      <label>61.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Evaluation of latent membrane protein 1 and microRNA-155 for the prognostic prediction of diffuse large B cell lymphoma.[J]</article-title>
        <source>Oncol Lett</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>9725</fpage>
        <lpage>9734</lpage>
        <?supplied-pmid 29844839?>
        <pub-id pub-id-type="pmid">29844839</pub-id>
      </element-citation>
    </ref>
    <ref id="CR62">
      <label>62.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Yue</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Protein subnuclear localization based on a new effective representation and intelligent kernel linear discriminant analysis by dichotomous greedy genetic algorithm [J]</article-title>
        <source>PLoS One</source>
        <year>2018</year>
        <volume>13</volume>
        <fpage>e0195636</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0195636</pub-id>
        <?supplied-pmid 29649330?>
        <pub-id pub-id-type="pmid">29649330</pub-id>
      </element-citation>
    </ref>
    <ref id="CR63">
      <label>63.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>WZ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>iAMP-2L: a two-level multi-label classifier for identifying antimicrobial peptides and their functional types [J]</article-title>
        <source>Anal Biochem</source>
        <year>2013</year>
        <volume>436</volume>
        <fpage>168</fpage>
        <lpage>177</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ab.2013.01.019</pub-id>
        <?supplied-pmid 23395824?>
        <pub-id pub-id-type="pmid">23395824</pub-id>
      </element-citation>
    </ref>
    <ref id="CR64">
      <label>64.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>TargetFreeze: identifying antifreeze proteins via a combination of weights using sequence evolutionary information and Pseudo amino acid composition [J]</article-title>
        <source>J Membr Biol</source>
        <year>2015</year>
        <volume>248</volume>
        <fpage>1005</fpage>
        <lpage>1014</lpage>
        <pub-id pub-id-type="doi">10.1007/s00232-015-9811-z</pub-id>
        <?supplied-pmid 26058944?>
        <pub-id pub-id-type="pmid">26058944</pub-id>
      </element-citation>
    </ref>
    <ref id="CR65">
      <label>65.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deng</surname>
            <given-names>SP</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DS</given-names>
          </name>
        </person-group>
        <article-title>Predicting hub genes associated with cervical Cancer through gene co-expression networks [J]</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <year>2016</year>
        <volume>13</volume>
        <fpage>27</fpage>
        <lpage>35</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2015.2476790</pub-id>
        <pub-id pub-id-type="pmid">26415208</pub-id>
      </element-citation>
    </ref>
    <ref id="CR66">
      <label>66.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deng</surname>
            <given-names>SP</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DS</given-names>
          </name>
        </person-group>
        <article-title>Mining the bladder cancer-associated genes by an integrated strategy for the construction and analysis of differential co-expression networks [J]</article-title>
        <source>BMC Genomics</source>
        <year>2015</year>
        <volume>16</volume>
        <issue>3 Supplement</issue>
        <fpage>S4</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2164-16-S3-S4</pub-id>
        <?supplied-pmid 25707808?>
        <pub-id pub-id-type="pmid">25707808</pub-id>
      </element-citation>
    </ref>
    <ref id="CR67">
      <label>67.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>HJ</given-names>
          </name>
        </person-group>
        <article-title>Normalized feature vectors: a novel alignment-free sequence comparison method based on the numbers of adjacent amino acids [J]</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <year>2013</year>
        <volume>10</volume>
        <fpage>457</fpage>
        <lpage>467</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2013.10</pub-id>
        <?supplied-pmid 23929869?>
        <pub-id pub-id-type="pmid">23929869</pub-id>
      </element-citation>
    </ref>
    <ref id="CR68">
      <label>68.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Understanding tissue-specificity with human tissue-specific regulatory networks [J]</article-title>
        <source>SCIENCE CHINA Inf Sci</source>
        <year>2016</year>
        <volume>59</volume>
        <fpage>070105</fpage>
        <pub-id pub-id-type="doi">10.1007/s11432-016-5582-0</pub-id>
      </element-citation>
    </ref>
    <ref id="CR69">
      <label>69.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ai</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>LPI-ETSLP: lncRNA–protein interaction prediction using eigenvalue transformation-based semi-supervised link prediction [J]</article-title>
        <source>Mol BioSyst</source>
        <year>2017</year>
        <volume>13</volume>
        <fpage>1781</fpage>
        <lpage>1787</lpage>
        <pub-id pub-id-type="doi">10.1039/C7MB00290D</pub-id>
        <?supplied-pmid 28702594?>
        <pub-id pub-id-type="pmid">28702594</pub-id>
      </element-citation>
    </ref>
    <ref id="CR70">
      <label>70.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>RWLPAP: random walk for lncRNA-protein associations prediction [J]</article-title>
        <source>Protein Pept Lett</source>
        <year>2018</year>
        <volume>25</volume>
        <fpage>830</fpage>
        <lpage>837</lpage>
        <pub-id pub-id-type="doi">10.2174/0929866525666180905104904</pub-id>
        <?supplied-pmid 30182833?>
        <pub-id pub-id-type="pmid">30182833</pub-id>
      </element-citation>
    </ref>
    <ref id="CR71">
      <label>71.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Bao</surname>
            <given-names>WZ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Recurrent neural network for predicting transcription factor binding sites [J]</article-title>
        <source>Sci Rep</source>
        <year>2018</year>
        <volume>8</volume>
        <fpage>15270</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-018-33321-1</pub-id>
        <?supplied-pmid 30323198?>
        <pub-id pub-id-type="pmid">30323198</pub-id>
      </element-citation>
    </ref>
    <ref id="CR72">
      <label>72.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>YH</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>miRNA-disease association prediction with collaborative matrix factorization [J]</article-title>
        <source>Complexity</source>
        <year>2017</year>
        <volume>2017</volume>
        <fpage>1</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1155/2017/2498957</pub-id>
      </element-citation>
    </ref>
    <ref id="CR73">
      <label>73.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yuan</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DS</given-names>
          </name>
        </person-group>
        <article-title>FAACOSE: a fast adaptive ant colony optimization algorithm for detecting SNP epistasis [J]</article-title>
        <source>Complexity</source>
        <year>2017</year>
        <volume>2017</volume>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1155/2017/5024867</pub-id>
      </element-citation>
    </ref>
    <ref id="CR74">
      <label>74.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DS</given-names>
          </name>
        </person-group>
        <article-title>DiscMLA: an efficient discriminative motif learning algorithm over high-throughput datasets [J]</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>1810</fpage>
        <lpage>1820</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2016.2561930</pub-id>
        <pub-id pub-id-type="pmid">27164602</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
