<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">NPJ Digit Med</journal-id>
    <journal-id journal-id-type="iso-abbrev">NPJ Digit Med</journal-id>
    <journal-title-group>
      <journal-title>NPJ Digital Medicine</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2398-6352</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6550285</article-id>
    <article-id pub-id-type="publisher-id">67</article-id>
    <article-id pub-id-type="doi">10.1038/s41746-018-0067-8</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepTag: inferring diagnoses from veterinary clinical notes</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Nie</surname>
          <given-names>Allen</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9436-0637</contrib-id>
        <name>
          <surname>Zehnder</surname>
          <given-names>Ashley</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Page</surname>
          <given-names>Rodney L.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Yuhui</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3409-1815</contrib-id>
        <name>
          <surname>Pineda</surname>
          <given-names>Arturo Lopez</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rivas</surname>
          <given-names>Manuel A.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bustamante</surname>
          <given-names>Carlos D.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Zou</surname>
          <given-names>James</given-names>
        </name>
        <address>
          <email>jamesz@stanford.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000000419368956</institution-id><institution-id institution-id-type="GRID">grid.168010.e</institution-id><institution>Department of Biomedical Data Science, </institution><institution>Stanford University, </institution></institution-wrap>Stanford, CA 94305 USA </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 8083</institution-id><institution-id institution-id-type="GRID">grid.47894.36</institution-id><institution>Department of Clinical Sciences, </institution><institution>Colorado State University, </institution></institution-wrap>Fort Collins, CO 80523 USA </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0662 3178</institution-id><institution-id institution-id-type="GRID">grid.12527.33</institution-id><institution>Department of Computer Science and Technology, </institution><institution>Tsinghua University, </institution></institution-wrap>Beijing, China </aff>
      <aff id="Aff4"><label>4</label>Chan-Zuckerberg Biohub, San Francisco, CA 94158 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>24</day>
      <month>10</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>24</day>
      <month>10</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2018</year>
    </pub-date>
    <volume>1</volume>
    <elocation-id>60</elocation-id>
    <history>
      <date date-type="received">
        <day>27</day>
        <month>6</month>
        <year>2018</year>
      </date>
      <date date-type="rev-recd">
        <day>8</day>
        <month>10</month>
        <year>2018</year>
      </date>
      <date date-type="accepted">
        <day>10</day>
        <month>10</month>
        <year>2018</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2018</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Large scale veterinary clinical records can become a powerful resource for patient care and research. However, clinicians lack the time and resource to annotate patient records with standard medical diagnostic codes and most veterinary visits are captured in free-text notes. The lack of standard coding makes it challenging to use the clinical data to improve patient care. It is also a major impediment to cross-species translational research, which relies on the ability to accurately identify patient cohorts with specific diagnostic criteria in humans and animals. In order to reduce the coding burden for veterinary clinical practice and aid translational research, we have developed a deep learning algorithm, DeepTag, which automatically infers diagnostic codes from veterinary free-text notes. DeepTag is trained on a newly curated dataset of 112,558 veterinary notes manually annotated by experts. DeepTag extends multitask LSTM with an improved hierarchical objective that captures the semantic structures between diseases. To foster human-machine collaboration, DeepTag also learns to abstain in examples when it is uncertain and defers them to human experts, resulting in improved performance. DeepTag accurately infers disease codes from free-text even in challenging cross-hospital settings where the text comes from different clinical settings than the ones used for training. It enables automated disease annotation across a broad range of clinical diagnoses with minimal preprocessing. The technical framework in this work can be applied in other medical domains that currently lack medical coding resources.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Public health</kwd>
      <kwd>Health services</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2018</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par2">While a robust medical coding infrastructure exists in the US healthcare system for human medical records, this is not the case in veterinary medicine, which lacks coding infrastructure and standardized nomenclatures across medical institutions. Most veterinary clinical notes are not coded with standard SNOMED-CT diagnosis.<sup><xref ref-type="bibr" rid="CR1">1</xref></sup> This hampers efforts at clinical research and public health monitoring. Due to the relative ease of obtaining large volumes of free-text veterinary clinical records for research (compared to similar volumes of human medical data) and the importance of turning these volumes of text into structured data to advance clinical research, we investigated effective methods for building automatic coding systems for the veterinary records.</p>
    <p id="Par3">It is becoming increasingly accepted that spontaneous diseases in animals have important translational impact on the study of human disease for a variety of disciplines.<sup><xref ref-type="bibr" rid="CR2">2</xref></sup> Beyond the study of zoonotic diseases, which represent 60–70% of all emerging diseases, noninfectious diseases, like cancer, have become increasingly studied in companion animals as a way to mitigate some of the problems with rodent models of disease.<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> Additionally, spontaneous models of disease in companion animals are being used in drug development pipelines as these models more closely resemble the “real world” clinical settings of diseases than genetically altered mouse models.<sup><xref ref-type="bibr" rid="CR4">4</xref>–<xref ref-type="bibr" rid="CR7">7</xref></sup> However, when it comes to identifying clinical cohorts of veterinary patients on a large scale for clinical research, there are several problems. One of the first is that veterinary clinical visits rarely have diagnostic codes applied to them, either by clinicians or medical coders. There is no substantial third party payer system and no HealthIT act that applies to veterinary medicine, so there are few incentives for clinicians or hospitals to annotate their records for diseases to be able to identify patients by diagnosis. Billing codes are largely institution-specific and rarely applicable across institutions, unless hospitals are under the same management structure and records system. Some large corporate practice groups have their own internal clinical coding structures, but that data is rarely made available for outside researchers. A small number (&lt;5) academic veterinary centers (of a total of 30 veterinary schools in the US) employ dedicated medical coding staff that apply disease codes to clinical records so these records can be identified for clinical faculty for research purposes. How best to utilize this rare, well-annotated, veterinary clinical data for the development of tools that can help organize the remaining seqments of the veterinary medical domain is an open area of research.</p>
    <p id="Par4">In this paper, we develop DeepTag, a system to automatically code veterinary clinical notes. DeepTag takes free-form veterinary note as input and infers clinical diagnosis from the note. The inferred diagnosis is in the form of 42 SNOMED-CT codes. We trained DeepTag on a large set of 112,558 veterinary notes, and each note is expert labeled with a set of SNOMED-CT codes. DeepTag is a bidirectional long–short-term memory network (BLSTM) augmented with a hierarchical training objective that captures similarities between the diagnosis codes. We evaluated DeepTag’s performance on challenging cross-hospital coding tasks.</p>
    <p id="Par5">Natural language processing (NLP) techniques have improved from leveraging discrete patterns such as n-grams<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> to continuous learning algorithms like LSTMs.<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> This strategy has proven to be very successful when a sizable amount of data can be acquired. Combined with advances in optimization and classification algorithms, the field has developed algorithms that can match or exceed human performance in several traditionally difficult tasks.<sup><xref ref-type="bibr" rid="CR10">10</xref></sup></p>
    <p id="Par6">Analyzing free text such as diagnostic reports and clinical notes has been a central focus of clinical natural language processing.<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> Most of the previous research has focused on the human healthcare systems. Examples include using NLP tools to improve pneumonia screening in the emergency department, assisting in adenoma detection, assisting and simplifying hospital processes by identifying billing codes from clinical notes.<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> In an unsupervised setting, Pivovarov et al.<sup><xref ref-type="bibr" rid="CR13">13</xref></sup> have conducted experiments to discover phenotypes and diseases on a broad set of heterogeneous data.</p>
    <p id="Par7">In the domain of veterinary medicine, millions of clinical summaries are stored as electronic health records (EHR) in various hospitals and clinics. Unlike human discharge summaries that have been assigned with billing codes (ICD-9/ICD-10 codes), veterinary summaries exist primarily as free text. This makes it challenging to perform systematic analysis such as disease prevalence studies, analysis of adverse drug effects, therapeutic efficacy or outcome analysis. Veterinary domain is very favorable for an NLP system that can convert large amount of free-text notes into structured information. Such a system would benefit the veterinary community in a substantial way and can be deployed in multiple clinical settings. Veterinary medicine is a domain where clinical NLP tools can have a substantial impact in practice and be integrated into daily use.</p>
    <p id="Par8">Identifying a set of conditions/diseases from clinical notes has been actively studied.<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR14">14</xref></sup> Currently, the task of transforming free text into structured information primarily relies on two approaches: named entity recognition (NER) and automated coding. DeepTag is designed to perform automated coding rather than NER. NER requires annotation on the word level, where each word is associated with one of a few types. In the ShARe task,<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> the importance is placed on identifying disease span and then normalizing into standard terminology in SNOMED-CT or Unified Medical Language System. In other works, the focus has been on tagging each word with a specific type: adverse drug effect, severity, drug name, etc.<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> Annotating on word level is expensive, and most corpora contain only a couple of hundreds or thousands of clinical notes. Even though early shared task in this domain has proven to be successful,<sup><xref ref-type="bibr" rid="CR17">17</xref>,<xref ref-type="bibr" rid="CR18">18</xref></sup> it is still difficult to curate a large dataset in this manner.</p>
    <p id="Par9">Automated coding on the other hand takes the entire free text as input, and infers a set of codes that are used to code the entire work. Most discharge summaries in human hospitals have billing codes assigned. Baumel et al.<sup><xref ref-type="bibr" rid="CR19">19</xref></sup> proposed a text processing model for automated coding that processes each sentence first and then processes the encoded hidden states for the entire document. This multilevel approach is especially suitable for longer texts, and the method was applied to the MIMIC data, where each document is on average five times longer than the veterinary notes from Colorodo State University of Veterinary Medicine and Biomedical Sciences (CSU). Rajkomar et al.<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> used deep learning methods to process the entire EHR and make clinical predictions for a wide range of problems including automated coding. In their work, they compared three deep learning models: LSTM, time-aware feedforward neural network, and boosted time-based decision stumps. In this work, we use a new hierarchical training objective which is designed to capture the similarities among the SNOMED-CT codes. This hierarchical objective is complementary to these previous approaches in the sense that the hierarchical objective can be used on top of any architecture. Our cross-hospital evaluations also extend what is typically done in literature. Even though Rajkomar et al. had data from two hospitals, they did not investigate the performance of the model when trained on one hospital but evaluated on the other. In our work, due to the lack of coded clinical notes in the veterinary community beyond a few academic hospitals, it is especially salient for us to evaluate the model's<sup>™</sup> ability to generalize across hospitals.</p>
    <p id="Par10">Our work is also related to the work of Kavuluru et al.,<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> who experimented with different training strategies and compared which strategy is the best for automated coding, and Subotin et al.,<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> who improved upon direct label probability estimation and used a conditional probability estimator to fine-tune the label probability. Perotte et al.<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> also investigated possible methods to leverage the hierarchical structure of disease codes by using an support vector machine (SVM) algorithm on each level of the ICD-9 hierarchy tree.</p>
    <p id="Par11">Cross-hospital generalization is a significant challenge in the veterinary coding setting. Most veterinary clinics currently do not apply diagnosis codes to their notes.<sup><xref ref-type="bibr" rid="CR1">1</xref></sup> Therefore our training data can only come from a handful of university-based regional referral centers that manually code their free-text notes. The task is to train a model on such data and deploy for thousands of private hospitals and clinics. University-based centers and private hospitals and clinics have substantial variation in the writing style, the patient population, and the distribution of diseases (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). For example, the training dataset we have used in this work comes from a university-based hospital with a high-volume referral oncology service, but typical local hospitals might face more dermatologic or gastrointestinal cases.<fig id="Fig1"><label>Fig. 1</label><caption><p>System workflow and clinical note examples. Figure <bold>a</bold> shows the workflow of DeepTag with abstention. Then we show two example meta-diseases corresponding to two subsets of the 42 SNOMED-CT codes. Figure <bold>b</bold> shows two example notes from the CSU and PP datasets</p></caption><graphic xlink:href="41746_2018_67_Fig1_HTML" id="d29e409"/></fig></p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <p id="Par12">DeepTag takes clinician’s notes as input and predicts a set of SNOMED-CT disease codes. SNOMED-CT is a comprehensive and precise clinical health terminology managed by the International Health Terminology Standards Development Organization. DeepTag is a BLSTM neural network with a new hierarchical learning objective designed to capture similarities between the disease codes (see the <xref rid="MOESM1" ref-type="media">Supplementary</xref> for model details).</p>
    <p id="Par13">DeepTag is trained on 112,558 annotated veterinary notes from the CSU curated for research purposes. Each of these notes is a free-text description of a patient visit, and is manually tagged with at least one, and on average 8, out of the 41 SNOMED-CT disease codes by experts. In addition, we map every nondisease related code to an extra code. In total, DeepTag learns to tag a clinical note with a subset of 42 codes.</p>
    <p id="Par14">We evaluate DeepTag on two different datasets. One consists of 5628 randomly sampled nonoverlapping held-out documents from the same CSU dataset that the system is trained on. The other dataset contains 586 documents and are collected from a private practice (PP) located in northern California. Each of the these document is also manually annotated with the appropriate SNOMED-CT codes by human experts. We refer to this dataset as the PP dataset.</p>
    <p id="Par15">We regard the PP dataset as a “out-of-domain” dataset due to its substantial difference with regard to writing style and institution type compared to the CSU dataset.<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> The PP documents tend to be substantially shorter (average of 253 words compared to 368 words in CSU), use more abbreviations and have different distribution of diseases (see Methods section for more details).</p>
    <sec id="Sec3">
      <title>Tagging performance</title>
      <p id="Par16">We present DeepTag’s performance on the CSU and PP test data in Table <xref rid="Tab1" ref-type="table">1</xref>. To save space, we display the 20 most frequent disease codes in Table <xref rid="Tab1" ref-type="table">1</xref>. For each disease code, we report the number of training examples for the disease code (<italic>N</italic>), the scores for precision, recall, <italic>F</italic><sub>1</sub>, ROC AUC, and the number of subtypes in this disease code. While DeepTag achieves reasonable <italic>F</italic><sub>1</sub> scores overall, its performance is quite heterogeneous for different disease codes. Moreover, the performance decreases when DeepTag is applied to the out-of-domain PP test data. We identify two factors that substantially impact DeepTag’s performance: (1) the number of training examples that are tagged with the given disease code and (2) the number of subtypes, where a subtype is a SNOMED-CT code applied to either dataset that is lower in the SNOMED-CT hierarchy than the top-level disease codes DeepTag is predicting. We use the number of subtypes as a proxy for the diversity and specificity of the clinical text descriptions. Thus, a higher number of subtypes suggests a wider spectrum of diseases.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Report of DeepTag performance on the CSU test data and PP data</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th colspan="6">CSU</th><th colspan="6">PP (Cross-hospital)</th></tr><tr><th>Disease code</th><th><italic>N</italic></th><th>Prec</th><th>Rec</th><th><italic>F</italic><sub>1</sub></th><th>AUC</th><th>Sub</th><th><italic>N</italic></th><th>Prec</th><th>Rec</th><th><italic>F</italic><sub>1</sub></th><th>AUC</th><th>Sub</th></tr></thead><tbody><tr><td>Autoimmune disease</td><td>1280</td><td>94</td><td>72.3</td><td>81.4</td><td>0.86</td><td>11</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0.5</td><td>1(1)</td></tr><tr><td>Congenital disease</td><td>3345</td><td>72.9</td><td>35.9</td><td>47.3</td><td>0.68</td><td>224</td><td>17</td><td>46.7</td><td>3.5</td><td>6.4</td><td>0.52</td><td>8(6)</td></tr><tr><td>Propensity to adverse reactions</td><td>5105</td><td>89.1</td><td>70.2</td><td>78.1</td><td>0.85</td><td>8</td><td>43</td><td>67.2</td><td>12.6</td><td>19.5</td><td>0.56</td><td>7(2)</td></tr><tr><td>Metabolic disease</td><td>5265</td><td>68.9</td><td>55.4</td><td>61</td><td>0.77</td><td>82</td><td>26</td><td>56.6</td><td>48.5</td><td>51.1</td><td>0.73</td><td>12(9)</td></tr><tr><td>Disorder of auditory system</td><td>5393</td><td>81</td><td>66.2</td><td>72.8</td><td>0.83</td><td>67</td><td>64</td><td>78.8</td><td>70.3</td><td>73.8</td><td>0.84</td><td>12(6)</td></tr><tr><td>Hypersensitivity condition</td><td>6871</td><td>85.7</td><td>74.6</td><td>79.5</td><td>0.87</td><td>31</td><td>50</td><td>67.7</td><td>22.4</td><td>31.6</td><td>0.61</td><td>11(4)</td></tr><tr><td>Disorder of endocrine system</td><td>7009</td><td>79.2</td><td>66.7</td><td>72.2</td><td>0.83</td><td>84</td><td>46</td><td>44.4</td><td>21.7</td><td>28.7</td><td>0.6</td><td>8(8)</td></tr><tr><td>Disorder of hematopoietic cell proliferation</td><td>7294</td><td>95.1</td><td>87.4</td><td>91</td><td>0.94</td><td>22</td><td>16</td><td>62.7</td><td>25</td><td>34.5</td><td>0.62</td><td>6(1)</td></tr><tr><td>Disorder of nervous system</td><td>7488</td><td>76.1</td><td>63.8</td><td>69.2</td><td>0.81</td><td>243</td><td>27</td><td>40.4</td><td>26.7</td><td>30.8</td><td>0.62</td><td>19(14)</td></tr><tr><td>Disorder of cardiovascular system</td><td>8733</td><td>79.3</td><td>62.5</td><td>69.7</td><td>0.81</td><td>351</td><td>53</td><td>44.1</td><td>52.1</td><td>46.4</td><td>0.73</td><td>30(24)</td></tr><tr><td>Disorder of the genitourinary system</td><td>8892</td><td>77.7</td><td>62.6</td><td>69.3</td><td>0.81</td><td>317</td><td>44</td><td>47.8</td><td>39.1</td><td>42.2</td><td>0.68</td><td>19(12)</td></tr><tr><td>Traumatic AND/OR nontraumatic injury</td><td>9027</td><td>72.8</td><td>57.2</td><td>63.5</td><td>0.78</td><td>536</td><td>19</td><td>50.5</td><td>15.8</td><td>23.1</td><td>0.58</td><td>13(8)</td></tr><tr><td>Visual system disorder</td><td>10139</td><td>84.3</td><td>81.1</td><td>82.6</td><td>0.9</td><td>413</td><td>62</td><td>65</td><td>62.6</td><td>63.2</td><td>0.79</td><td>39(34)</td></tr><tr><td>Infectious disease</td><td>11304</td><td>71.2</td><td>53.7</td><td>60.8</td><td>0.76</td><td>260</td><td>88</td><td>63.8</td><td>23</td><td>32.3</td><td>0.6</td><td>20(10)</td></tr><tr><td>Disorder of respiratory system</td><td>11322</td><td>79.5</td><td>65.5</td><td>71.8</td><td>0.82</td><td>274</td><td>27</td><td>38.3</td><td>42.2</td><td>38.2</td><td>0.69</td><td>16(14)</td></tr><tr><td>Disorder of connective tissue</td><td>17477</td><td>75.4</td><td>67</td><td>70.7</td><td>0.81</td><td>567</td><td>24</td><td>30.4</td><td>24.2</td><td>26.3</td><td>0.61</td><td>15(11)</td></tr><tr><td>Disorder of musculoskeletal system</td><td>20060</td><td>77</td><td>73.4</td><td>74.8</td><td>0.84</td><td>670</td><td>56</td><td>54</td><td>41.4</td><td>46.1</td><td>0.69</td><td>31(19)</td></tr><tr><td>Disorder of integument</td><td>21052</td><td>84.2</td><td>71.6</td><td>77.3</td><td>0.84</td><td>360</td><td>156</td><td>65.7</td><td>60.1</td><td>62.6</td><td>0.74</td><td>58(32)</td></tr><tr><td>Disorder of digestive system</td><td>22589</td><td>76.8</td><td>67.1</td><td>71.5</td><td>0.81</td><td>694</td><td>195</td><td>58</td><td>47.9</td><td>51.3</td><td>0.65</td><td>47(36)</td></tr><tr><td>Neoplasm and/or hamartoma</td><td>36108</td><td>92.2</td><td>88.9</td><td>90.5</td><td>0.93</td><td>749</td><td>59</td><td>26.1</td><td>72.5</td><td>37.8</td><td>0.74</td><td>18(7)</td></tr></tbody></table><table-wrap-foot><p>This table reports the DeepTag’s performance (precision, recall, <italic>F</italic><sub>1</sub> and AUC) for the 20 most frequent disease codes (from a total of 42 disease codes). <italic>N</italic> indicates the total number of examples in the dataset. AUC refers to area under the receiver operator curve. Sub indicates the number of lower-level disease codes that are present in the dataset that are binned into one of the disease level codes. For the PP dataset, the Sub number in parentheses indicate the number of subtypes that are also present in CSU dataset.</p></table-wrap-foot></table-wrap></p>
      <sec id="Sec4">
        <title>Performance improves with more training examples</title>
        <p id="Par17">We first note that DeepTag works relatively well when the number of training examples for each disease code is abundant. We generate a scatter plot to capture the correlation between number of examples in the in CSU dataset and the disease code’s <italic>F</italic><sub>1</sub> score evaluated on the CSU test set. We also plot the <italic>F</italic><sub>1</sub> score for the disease code evaluated on the PP dataset and its number of training examples on the CSU dataset.</p>
        <p id="Par18">For the CSU dataset, we observe an almost linear relationship between the log number of examples and the <italic>F</italic><sub>1</sub> score in Fig. <xref rid="Fig2" ref-type="fig">2</xref>, suggesting that our large training data is crucial for the prediction performance. We observe a similar pattern when evaluating on the PP dataset, thought the correlation is weaker and the pattern is less linear. This is due to the out-of-domain nature of PP, which we investigate in depth below.<fig id="Fig2"><label>Fig. 2</label><caption><p>Per-disease code <italic>F</italic><sub>1</sub> score plotted with log of number of examples in the training dataset. Results shown here are from the DeepTag model. Each point represents a disease code, its corresponding number of training examples in CSU, and the per-disease code <italic>F</italic><sub>1</sub> score from the DeepTag model</p></caption><graphic xlink:href="41746_2018_67_Fig2_HTML" id="d29e1419"/></fig></p>
      </sec>
      <sec id="Sec5">
        <title>More diverse disease codes are harder to predict</title>
        <p id="Par19">After observing the general correlation between number of training examples and per-disease code <italic>F</italic><sub>1</sub> scores, we can investigate outliers. These are diseases that have many examples but on which DeepTag performed poorly and diseases that have few examples but DeepTag performed well. For <italic>disorder of digestive system</italic>, despite having the second highest number of training examples (22,589), both precision and recall are lower than other frequent diseases. We find that this disease code covers the second largest number of subtypes (694). On the other hand, <italic>disorder of hematopoietic cell proliferation</italic> has the highest <italic>F</italic><sub>1</sub> score with relatively few training examples (<italic>N</italic> = 7294). This disease code has only 22 subtypes. Similarly <italic>autoimmune diseases</italic> has few training examples (<italic>N</italic> = 1280) but it still has a relatively high <italic>F</italic><sub>1</sub>, and it also has only 11 subtypes.</p>
        <p id="Par20">The number of subtypes—i.e., the number of different lower-level SNOMED-CT codes that are mapped to each of the 42 higher-level disease code—can serve as an indicator for the diversity or specificity of the text descriptions. For a disease like <italic>disorder of digestive system</italic>, it subsumes many different types of diseases such as <italic>periodontal disease</italic>, <italic>hepatic disease</italic>, and <italic>disease of stomach</italic>, which all have different diagnoses. Similarly, <italic>neoplasm and/or hamartoma</italic> encapsulates many different histologic types and be categorized as benign, malignant, or unknown, thus resulting in many different lower-level codes (749 codes) being mapped into the same top-level disease code. DeepTag needs to associate diverse descriptions to the same high-level disease code, increasing the difficulty of the prediction task.</p>
        <p id="Par21">We hypothesize that disease codes with many subtypes will be difficult for the system to predict. This hypothesis suggests that the number of subtypes a disease code contains could explain some of the heterogeneity in DeepTag’s performance beyond the heterogeneity due to the training sample size.</p>
        <p id="Par22">We conduct a multiple linear regression test with both the number of training examples as well as number of subtypes each disease code contains as covariates and the <italic>F</italic><sub>1</sub> score as the outcome. In the regression, the coefficient for number of subtypes is negative with <italic>p</italic> &lt; 0.001. This indicates that, controlling for the number of training examples, having more subtypes in a disease code makes tagging more challenging and decreases DeepTag’s performance on the disease code.</p>
      </sec>
      <sec id="Sec6">
        <title>Performance on PP</title>
        <p id="Par23">Next we investigate DeepTag’s performance discrepancy between the CSU and PP test data. A primary contributing factor to the discrepancy is that the underlying text in PP is stylistically and functionally different from the text in CSU. Note that DeepTag was only trained on the CSU text and was not fine-tuned on PP. The example texts in Fig. <xref rid="Fig1" ref-type="fig">1</xref> illustrate the striking difference. In particular, PP uses many more abbreviations that are not observed in CSU.</p>
        <p id="Par24">After filtering out numbers, 15.4% of words in PP are not found in CSU. Many of the PP specific words appear to be medical acronyms that are not used in CSU or terms that describe test results or medical procedures. Since these vocabulary has no trained word embedding from the CSU dataset, DeepTag can not leverage them in the disease tagging process.</p>
        <p id="Par25">Despite having many training examples, DeepTag performs poorly on some very frequent diseases, for example, <italic>neoplasm and/or hamartoma</italic>. On the opposite end of the spectrum, the tagger does well for <italic>disorder of auditory system</italic> on both CSU and PP dataset, despite only having a moderate amount of training examples. Besides the main issue of vocabulary mismatch, many subtypes (lower-level disease codes) that get mapped to a disease code in CSU do not exist in PP, and subtypes in PP also might not exist in CSU. We refer to this as the subtype distribution shift. For example, In CSU, <italic>neoplasm and/or hamartoma</italic> has 749 observed subtypes. Only 7 out of 749 subtypes are present in PP. Moreover, there are 11 subtypes are unique to the PP dataset and are not observed in the CSU training set.</p>
        <p id="Par26">In addition to the subtype analysis, we note that for rarer diseases, the precision drop between CSU and PP is not as deep as the recall drop. This can be interpreted as the model is fairly confident and precise about the key phrases it discovered from the CSU dataset. The drop in recall in the PP dataset could be partially due the fact that PP uses many terms and phrases that are not in the CSU data.</p>
      </sec>
    </sec>
    <sec id="Sec7">
      <title>Improvements from disease similarity</title>
      <p id="Par27">The 42 disease codes can be naturally grouped into 18 meta-diseases; each meta-disease corresponds to a subset of diseases that are related to each other (see the <xref rid="MOESM1" ref-type="media">Supplementary</xref>). For example, the disease codes for “Disease caused by Arthropod” and “Disease caused by Annelida” belong to the same meta-disease: “Infectious and parasitic diseases”. We designed DeepTag to leverage this hierarchical structure amongst the disease codes. Intuitively, suppose the true disease associated with a note is <italic>A</italic> and DeepTag mistakenly predicts disease code <italic>B</italic>. Then its penalty should be larger if <italic>B</italic> is very different from <italic>A</italic>—i.e., they are in different meta-diseases—than if <italic>B</italic> and <italic>A</italic> are in the same meta-disease. More precisely, we use the grouping of similar codes into meta-diseases as a regularization in the training objective of DeepTag. Basic deep learning systems like LSTM and BLSTM do not incorporate this information.</p>
      <p id="Par28">DeepTag uses a <italic>L</italic><sub>2</sub>-based distance objective to place this constraint between disease code embeddings, which are the parameters in the final layer of the DeepTag neural network. The objective encourages the embeddings of disease codes that are in the same meta-disease to be closer to each other than the embeddings of disease codes across different meta-diseases. In addition, we investigated another approach that can also leverage disease similarity: DeepTag-M. This method computes the probability of a meta-disease based on the probability of the disease codes that are grouped into it. Instead of forcing similarity constraints on disease code embeddings, DeepTag-M encourages the model to make correct prediction on the meta-diseases as well as on the disease codes (see the <xref rid="MOESM1" ref-type="media">Supplementary</xref>).</p>
      <p id="Par29">In Table <xref rid="Tab2" ref-type="table">2</xref>, we compare the performance of DeepTag and DeepTag-M with the standard LSTM, BLSTM, text convolutional neural network (CNN), MetaMap-SVM, and MetaMap-MLP. MetaMap is a nondeep learning approach that processes each document to extract a set of medically relevant terms.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> We then train a SVM (MetaMap-SVM) or a multilayer perceptron (MetaMap-MLP) to use the extracted terms to predict disease codes.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Evaluation of trained classifiers on the CSU and PP data</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Model</th><th rowspan="2">EM</th><th colspan="2">Precision</th><th colspan="2">Recall</th><th colspan="2"><italic>F</italic><sub>1</sub></th></tr><tr><th>unwgt</th><th>wgt</th><th>unwgt</th><th>wgt</th><th>unwgt</th><th>wgt</th></tr></thead><tbody><tr><td colspan="8"><italic>CSU data</italic></td></tr><tr><td> MetaMap-SVM</td><td>32.2</td><td>52.2</td><td>74.8</td><td>54.8</td><td>75</td><td>53.2</td><td>74.8</td></tr><tr><td> MetaMap-MLP</td><td>41.2</td><td>64.7</td><td>82.6</td><td>48.5</td><td>71.8</td><td>55</td><td>76.4</td></tr><tr><td> CNN</td><td>45.1</td><td>73.1</td><td>84.4</td><td>57.2</td><td>78.4</td><td>62.2</td><td>80.9</td></tr><tr><td> LSTM</td><td>47.4</td><td>76.6</td><td>85.9</td><td>59.3</td><td>78.7</td><td>65.3</td><td>81.7</td></tr><tr><td> BLSTM</td><td>48.2</td><td>76.1</td><td>86</td><td>57.6</td><td>79.4</td><td>63.5</td><td>82.2</td></tr><tr><td> DeepTag-M</td><td><bold>48.6</bold></td><td>76.8</td><td><bold>86.3</bold></td><td>58.7</td><td>79.6</td><td>64.6</td><td>82.4</td></tr><tr><td> DeepTag</td><td>48.4</td><td><bold>79.9</bold></td><td>86.1</td><td><bold>62.1</bold></td><td><bold>79.8</bold></td><td><bold>68</bold></td><td><bold>82.4</bold></td></tr><tr><td colspan="8"><italic>PP data (cross-hospital)</italic></td></tr><tr><td> MetaMap-SVM</td><td>3.2</td><td>26.5</td><td>57.3</td><td>37.7</td><td>53.1</td><td>24.8</td><td>51.6</td></tr><tr><td> MetaMap-MLP</td><td>13.8</td><td>30.6</td><td>56.4</td><td>24.9</td><td>47.7</td><td>26.2</td><td>50.5</td></tr><tr><td> CNN</td><td>13.5</td><td>52.8</td><td>68.5</td><td>31.8</td><td>54</td><td>34.8</td><td>56</td></tr><tr><td> LSTM</td><td>13.8</td><td>48.1</td><td>65.7</td><td>31.8</td><td>51.9</td><td>33.8</td><td>54.4</td></tr><tr><td> BLSTM</td><td>13.8</td><td>47.3</td><td>66</td><td>35.6</td><td>57.9</td><td>36.9</td><td>58.4</td></tr><tr><td> DeepTag-M</td><td>17.1</td><td>53.4</td><td>68</td><td>37.9</td><td>59.9</td><td>40.6</td><td>61.1</td></tr><tr><td> DeepTag</td><td><bold>17.4</bold></td><td><bold>56.5</bold></td><td><bold>70.3</bold></td><td><bold>41.4</bold></td><td><bold>62.4</bold></td><td><bold>43.2</bold></td><td><bold>63.4</bold></td></tr></tbody></table><table-wrap-foot><p>Aggregate prediction performance across the 42 disease codes. We trained a multilayer perceptron (MetaMap-MLP) algorithm and support vector machines (MetaMap-SVM) algorithm on discrete features generated by the MetaMap, which processes a document and extracts medically relevant terms.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> CNN refers to a text convolution neural network implementation from Kim.<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> BLSTM refers to the multitask bidirectional LSTM. DeepTag is our best model, and DeepTag-M is the variation with a meta-disease loss. EM indicates the exact match ratio, which is the percentage of the clinical notes where the algorithm perfectly predicts all of the disease codes. For example, if a note has three true disease codes, then the algorithm achieves an exact match if it predicts exactly these three disease codes, no more and no less. For each precision, recall and <italic>F</italic><sub>1</sub> score, there are two ways to compute an algorithm’s performance. First we can take an unweighted average of the score across all the disease codes (unwgt) or we can take an average weighted by the number of test examples in each disease code (wgt). All the algorithms are trained on CSU and tested on a held-out CSU data and the PP data</p><p>The bold values indicate the highest value for each evaluation metric</p></table-wrap-foot></table-wrap></p>
      <p id="Par30">On the CSU dataset, DeepTag and DeepTag-M perform slightly better compared to the baseline deep learning models (CNN, LSTM, and BLSTM). All the deep learning models performed substantially better than MetaMap-SVM and MetaMap-MLP on CSU. DeepTag has higher unweighted precision, recall, and <italic>F</italic><sub>1</sub> score compared to the other models, indicating its ability to have good performance on a wide spectrum of diseases. The importance of leveraging similarity is shown on the PP dataset (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). Since it is out-of-domain, expert defined disease similarity provide much-needed regularization to make both DeepTag and DeepTag-M out-perform baseline models by a substantial margin, with DeepTag being the overall best model.<fig id="Fig3"><label>Fig. 3</label><caption><p>Performance comparison on PP. We compare the per-disease code <italic>F</italic><sub>1</sub> score between baseline LSTM model and DeepTag model on the PP dataset. The disease codes are sorted from the least frequent to the most frequent in the training dataset, which comes from CSU</p></caption><graphic xlink:href="41746_2018_67_Fig3_HTML" id="d29e2061"/></fig></p>
    </sec>
    <sec id="Sec8">
      <title>Learning to abstain</title>
      <p id="Par31">Augmenting a tagging system with the ability to abstain (decline to assign codes) can foster human-machine collaboration. When the system does not have enough confidence to make decisions, it has the option to defer to its human counterparts. This aspect is important in DeepTag because after tagging the documents, further analysis from various parties might be conducted on the tagged documents such as investigating the prevalence of certain specific diseases. In order to not mislead further clinical research, having the ability to abstain from making very erroneous predictions and ensuring highly precise tagging is an important feature.</p>
      <p id="Par32">A natural approach to decide whether to abtain on a given document is to check whether the DeepTag prediction confidence—i.e., the output of the final logistic regression—is above a set threshold. We use this approach as the baseline abstention method. This could be suboptimal if DeepTag is over-confident in its predictions. Therefore, we also developed an additional abstention wrapper on top of DeepTag that we call DeepTag-abstain. DeepTag-abstain takes the prediction confidence of the original DeepTag for each of the 42 codes and learns a nonlinear function in order to decide whether to abstain. This learning to abstain approach gives DeepTag-abstain more flexibility to assess the multilabel prediction confidence. See the <xref rid="MOESM1" ref-type="media">Supplementary</xref> for more details about DeepTag-abstain and the baseline.</p>
      <p id="Par33">In order to evaluate how well DeepTag-abstain performs compared to the baseline, we compute an abstention priority score for each document. A document with higher abstention priority score will be removed earlier than a document with lower score. We then compute the weighted average of <italic>F</italic><sub>1</sub> and exact match ratio for all the documents that are not removed.</p>
      <p id="Par34">For both baseline and DeepTag-abstain, we specify a proportion of the documents that need to be removed. We adjust the dropped portion from 0 to 0.9 (dropping 90% of the examples at the high end). An abstention method that can drop more erroneously tagged documents earlier will observe a faster increase in its performance, corresponding to a curve with steeper slope.</p>
      <p id="Par35">DeepTag-abstain demonstrates a substantial improvement over the baseline in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. We note that not all learning to abstain schemes are able to out-perform the baseline. The details of module design and improvement curve for the rest of the modules can be seen in the Supplementary Fig. <xref rid="MOESM1" ref-type="media">2</xref>.<fig id="Fig4"><label>Fig. 4</label><caption><p>Comparison of the abstention models. DeepTag-abstain is the abstention priority score estimator that uses confidence scores as input and estimate per-document accuracy of a given document. Baseline refers to the abstention scheme where the per-document abstention priority score is computed from individual disease code confidence scores without any learning. As a greater proportion of the examples are abstained from, the performance—<italic>F</italic><sub>1</sub> and Exact Match (EM)—of both methods improve. DeepTag-abstain shows faster improvement, indicating that it learns to abstain in more difficult cases</p></caption><graphic xlink:href="41746_2018_67_Fig4_HTML" id="d29e2102"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec9" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par36">In this study, we developed a multilabel classification algorithm for veterinary clinical text, which represents a medical domain with an under-resourced medical coding infrastructure. In order to improve the performance of DeepTag on diseases with rare occurrences, we investigated with loss augmentation strategies that leverage the similarity and dissimilarity between the disease codes. These augmentations provide gains over the LSTM and BLSTM baselines, which are common methods used for these types of prediction tasks. We also experimented with different methodologies to allow the model to learn to abstain on examples where the model is not confident in the predictions. We demonstrate that learned abstention rules out-perform manually set rules.</p>
    <p id="Par37">Our work demonstrates novel methods for applying broad disease codes to clinical records as well as applying those trained algorithms to an external dataset in order to examine cross-hospital generalization. We also demonstrate means to allow human domain experts to use their judgment when automated taggers have a high level of uncertainty in order to improve the overall workflow. We confirm that cross-hospital generalization is a significant concern for learned tagging systems to be deployed in real world implementations that may vary substantially from the data on which they were trained. Even though our work attempts to mitigate this problem, there is significant research to be done to optimize methods for domain adaptation. Our current work is important not only for veterinary medical records, which are rarely coded, but also may have implications for human medical records in countries with limited coding infrastructure and which are important regions of the world for public health surveillance and clinical research.</p>
    <p id="Par38">There are several aspects of the data that may have limited our ability to apply methods from our training set to our external validation set. Private veterinary practices often have data records that closely resemble the PP dataset used to evaluate our methods here. However, the large annotated dataset we used for training is from an academic institution (as these are, largely, the institutions that have dedicated medical coding staff). As can be seen from Table <xref rid="Tab2" ref-type="table">2</xref>, the performance drop due to domain mismatch is non-negligible. The domain shift comes from two parts. First, text style mismatch—private commercial notes use more abbreviations and tend to include many procedural examinations (even though many are non-informative or nondiagnostic).</p>
    <p id="Par39">Second, disease code distribution mismatch—the CSU training dataset focuses largely on neoplasm and several other tumor-related diseases, largely due to the fact that the CSU hospital is a regional tertiary referral center for cancer and cancer represents nearly 30% of the caseload. Other practices will have datasets composed of disease codes that appear with different frequencies, depending on the specializations of that particular practice. A very important path forward is to use learning algorithms that are robust to domain shift, and experimenting with unsupervised representation learning to mitigate the domain shift between academic datasets and private practice datasets.</p>
    <p id="Par40">Currently we are predicting top-level SNOMED-CT disease codes, which are not the SNOMED-CT codes that have been directly annotated on the dataset. Many of the SNOMED-CT codes that are applied to clinical records are coded as “Findings” that are not actual “Disorders” as the actual diagnosis of a patient may not be clear at the time the codes are applied. One example is an animal that is evaluated for “vomiting” and the actual cause is not determined, may have a code of “vomiting(finding)” (300359004) applied and not “vomiting(disorder)” (422400008) and these “non-disorder” disease codes are not evaluated in our current work. However, these are an important subset of codes and represent another means to identify particular patient cohorts with particular clinical signs or presentations, vs. diagnosed disorders.</p>
    <p id="Par41">Another future direction for the abstention branch of this work is to factor human cost and annotation accuracy into the model and only defer when the model believes that human experts will bring improvement to the result within an acceptable amount of cost. This is an interesting direction for experimentation.</p>
  </sec>
  <sec id="Sec10">
    <title>Methods</title>
    <sec id="Sec11">
      <title>Datasets</title>
      <sec id="Sec12">
        <title>Colorado State University dataset</title>
        <p id="Par42">The CSU dataset contains discharge summaries as well as applied diagnostic codes for clinical patients from the Colorado State University College of Veterinary Medicine and Biomedical Sciences. This institution is a tertiary referral center with an active and nationally recognized cancer center. Because of this, the CSU dataset over-represents cancer-related diseases. Rare diseases in the CSU dataset are diseases like perinatal and mental disorders, but these are also rare in the larger veterinary population as a whole and do not represent a dataset bias. Overall, there are 112,558 unique discharge summaries in CSU dataset. We split this dataset into training, validation, and test set by 0.9/0.05/0.05.</p>
      </sec>
      <sec id="Sec13">
        <title>Private practice dataset</title>
        <p id="Par43">An external validation dataset was obtained from a regional PP. These records did not have diagnostic codes available and only approximately 3% of these records had a diagnosis placed in the “Problem List” for a particular patient on a particular visit. Out of 352,597 patient records obtained that had Subjective, Objective, Assessment, Plan (SOAP) notes (i.e., notes in the “Subjective, Objective, Assessment, Plan” format), only 13,843 (3.9%) had at least one specific clinical diagnosis listed in the problem list. These diagnoses were free text and not coded to SNOMED-CT by the primary clinicians. Within the SOAP notes, additional diagnoses were frequently found within the “Assessment” field, but were not applied in a consistent standard and by using different levels of evidence, i.e., some of these diagnosis were presumptive, tentative or historical.</p>
        <p id="Par44">Two veterinary domain experts applied SNOMED-CT codes to a subset of these records and achieved consensus on the records used for validation. This dataset (PP) is used for external validation of algorithms developed using the CSU dataset. There are 586 documents in this external validation dataset.</p>
      </sec>
    </sec>
    <sec id="Sec14">
      <title>Data processing</title>
      <p id="Par45">Documents in our corpus have been tagged with SNOMED-CT codes that describe the clinical conditions present at the time of the visit being annotated. Annotations are applied from the SNOMED-CT veterinary extension (SNOMEDCT_VET), which is fully compatible to and is an extension of the International SNOMED-CT edition. It can be accessed in a dedicated browser and is maintained by the Veterinary Terminology Services Laboratory at the Virginia-Maryland Regional College of Veterinary Medicine. Medical coders applying diagnostic codes are either veterinarians or trained medical coders with expertize in the veterinary domain and the SNOMED terminology. The medical coding staff at CSU utilize post-coordinated expressions, where required, for annotations to fully describe a diagnosed condition. For this work, we only considered the core disease codes and not the subsequent modifiers for training our models. The PP dataset was similarly coded using post-coordinated terms following consultation with coding staff at multiple academic institutions that annotate records using SNOMED-CT. We further grouped the 42 disease codes into 18 meta-diseases. More details of this grouping are provided in the <xref rid="MOESM1" ref-type="media">Supplementary</xref>.</p>
    </sec>
    <sec id="Sec15">
      <title>Difference in data structures</title>
      <p id="Par46">Due to the inherent differences in clinical notes/discharge summaries prepared for patients in an academic setting compared to the shorter “SOAP” format notes prepared in private practice, there are substantial differences in the format as well as the writing style and level of detail between these two datasets. In addition, the private practice records exhibit significant differences in record styles between clinicians, as some clinicians use standardized forms while others use abbreviated clinical notes containing only references to abnormal clinical findings.</p>
      <p id="Par47">As can be seen in Supplementary Fig. <xref rid="MOESM1" ref-type="media">1</xref>, both dataset have more than 80% documents associated with more than one disease code, and in terms of document length distribution, PP dataset document is much shorter than CSU dataset, while the average PP document length is 191 words. The average CSU document length is 325 words.</p>
    </sec>
    <sec id="Sec16">
      <title>Algorithm development and analysis</title>
      <p id="Par48">We trained our modeling algorithm on CSU dataset and evaluated on a held-out portion of data from the CSU dataset as well as the PP dataset. We formulated our base model to be a recurrent neural network with LSTM. We additionally decided to run this recurrent neural network on both the forward direction and backward direction of the document (bidrectional), as is found beneficial in Graves et al.<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> We then built 42 independent binary classifiers to predict the existence of each disease code. This is the architecture found most useful in multilabel classification literature.<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> The model is trained jointly with binary cross entropy loss. We then augmented this baseline model with two losses: cluster penalty<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> and a novel meta-disease prediction loss to leverage human expert knowledge in how semantically related these disease codes are.</p>
    </sec>
    <sec id="Sec17">
      <title>Code availability</title>
      <p id="Par49">DeepTag is freely available at <ext-link ext-link-type="uri" xlink:href="https://github.com/windweller/DeepTag">https://github.com/windweller/DeepTag</ext-link>.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Electronic supplementary material</title>
    <sec id="Sec18">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41746_2018_67_MOESM1_ESM.pdf">
            <caption>
              <p>Supplement</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Publisher’s note:</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>These authors contributed equally: Allen Nie, Ashley Zehnder.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Electronic supplementary material</title>
    <p><bold>Supplementary information</bold> accompanies the paper on the <italic>npj Digital Medicine</italic> website (10.1038/s41746-018-0067-8).</p>
  </sec>
  <ack>
    <p>We would like to acknowledge the help of Devin Johnsen for her help in annotating the private practice records used in this work. We also want to thank Selina Dwight and Matthew Wright for helpful feedback. Our work is funded by the Chan-Zuckerberg Investigator Program and National Science Foundation (NSF) Grant CRII 1657155. This work was also supported by a National Human Genome Research Institute (NHGRI) grant funding the Clinical Genome Resource (ClinGen).</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>A.N. and A.Z. share co-first authorship. A.N. performed the natural language processing work, designed and built DeepTag and DeepTag-abstain, performed all the experiments, and analyzed the overall system’s performance. A.Z. acquired the data, established the meta-disease hierarchy, organized and aided in annotation of the private practice data, and provided feedback on the NLP and machine learning outputs. R.P. provided access to the training data. A.P. aided in initial data acquisition and used MetaMap software to generate features. Y.Z. ran MLP and SVM algorithms on the MetaMap features generated by A.P. M.R. and C.B. provided feedback on the project. J.Z. designed and supervised the project. A.N., A.Z., and J.Z. wrote the paper.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The data that support the findings of this study are available from Colorado State University College of Veterinary Medicine and a private practice veterinary hospital near San Francisco, but restrictions apply to the availability of these data, which were made available to Stanford for the current study, and so are not publicly available. Data are however available from the authors upon reasonable request and with permission of Colorado State University College of Veterinary Medicine and the private hospital.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par50">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>O’Neill</surname>
            <given-names>DG</given-names>
          </name>
          <name>
            <surname>Church</surname>
            <given-names>DB</given-names>
          </name>
          <name>
            <surname>McGreevy</surname>
            <given-names>PD</given-names>
          </name>
          <name>
            <surname>Thomson</surname>
            <given-names>PC</given-names>
          </name>
          <name>
            <surname>Brodbelt</surname>
            <given-names>DC</given-names>
          </name>
        </person-group>
        <article-title>Approaches to canine health surveillance</article-title>
        <source>Canine Genet. Epidemiol.</source>
        <year>2014</year>
        <volume>1</volume>
        <fpage>2</fpage>
        <pub-id pub-id-type="doi">10.1186/2052-6687-1-2</pub-id>
        <pub-id pub-id-type="pmid">26401319</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kol</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Companion animals: Translational scientist’s new best friends</article-title>
        <source>Sci. Transl. Med.</source>
        <year>2015</year>
        <volume>7</volume>
        <fpage>308ps21</fpage>
        <lpage>308ps21</lpage>
        <pub-id pub-id-type="doi">10.1126/scitranslmed.aaa9116</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>LeBlanc</surname>
            <given-names>AK</given-names>
          </name>
          <name>
            <surname>Mazcko</surname>
            <given-names>CN</given-names>
          </name>
          <name>
            <surname>Khanna</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Defining the value of a comparative approach to cancer drug development</article-title>
        <source>Clin. Cancer Res.</source>
        <year>2016</year>
        <volume>22</volume>
        <fpage>2133</fpage>
        <lpage>2138</lpage>
        <pub-id pub-id-type="doi">10.1158/1078-0432.CCR-15-2347</pub-id>
        <pub-id pub-id-type="pmid">26712689</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baraban</surname>
            <given-names>SC</given-names>
          </name>
          <name>
            <surname>Löscher</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>What new modeling approaches will help us identify promising drug treatments?</article-title>
        <source>Adv. Exp. Med. Biol.</source>
        <year>2014</year>
        <volume>813</volume>
        <fpage>283</fpage>
        <lpage>294</lpage>
        <pub-id pub-id-type="doi">10.1007/978-94-017-8914-1_23</pub-id>
        <pub-id pub-id-type="pmid">25012385</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grimm</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>From bark to bedside</article-title>
        <source>Am. Assoc. Adv. Sci.</source>
        <year>2016</year>
        <volume>353</volume>
        <fpage>638</fpage>
        <lpage>640</lpage>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hernandez</surname>
            <given-names>B</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Naturally occurring canine melanoma as a predictive comparative oncology model for human mucosal and other triple wild-type melanomas</article-title>
        <source>Int. J. Mol. Sci.</source>
        <year>2018</year>
        <volume>19</volume>
        <fpage>394</fpage>
        <pub-id pub-id-type="doi">10.3390/ijms19020394</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Klinck</surname>
            <given-names>MP</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Translational pain assessment: Could natural animal models be the missing link?</article-title>
        <source>Pain</source>
        <year>2017</year>
        <volume>158</volume>
        <fpage>1633</fpage>
        <lpage>1646</lpage>
        <pub-id pub-id-type="doi">10.1097/j.pain.0000000000000978</pub-id>
        <pub-id pub-id-type="pmid">28614187</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Jurafsky</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Martin</surname>
            <given-names>JH</given-names>
          </name>
        </person-group>
        <source>Speech and Language Processing</source>
        <year>2014</year>
        <publisher-loc>London</publisher-loc>
        <publisher-name>Pearson</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hochreiter</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Long short-term memory</article-title>
        <source>Neural Comput.</source>
        <year>1997</year>
        <volume>9</volume>
        <fpage>1735</fpage>
        <lpage>1780</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
        <pub-id pub-id-type="pmid">9377276</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Goldberg</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Neural network methods for natural language processing</article-title>
        <source>Synth. Lect. Human Lang. Technol.</source>
        <year>2017</year>
        <volume>10</volume>
        <fpage>1</fpage>
        <lpage>309</lpage>
        <pub-id pub-id-type="doi">10.2200/S00762ED1V01Y201703HLT037</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Velupillai</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Mowery</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>South</surname>
            <given-names>BR</given-names>
          </name>
          <name>
            <surname>Kvist</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dalianis</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Recent advances in clinical natural language processing in support of semantic analysis</article-title>
        <source>Yearb. Med. Inform.</source>
        <year>2015</year>
        <volume>10</volume>
        <fpage>183</fpage>
        <pub-id pub-id-type="doi">10.15265/IY-2015-009</pub-id>
        <pub-id pub-id-type="pmid">26293867</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Demner-Fushman</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Elhadad</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Aspiring to unintended consequences of natural language processing: A review of recent developments in clinical and consumer-generated text processing</article-title>
        <source>Yearb. Med. Inform.</source>
        <year>2016</year>
        <volume>1</volume>
        <fpage>224</fpage>
        <pub-id pub-id-type="doi">10.15265/IY-2016-017</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pivovarov</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Learning probabilistic phenotypes from heterogeneous ehr data</article-title>
        <source>J. Biomed. Inform.</source>
        <year>2015</year>
        <volume>58</volume>
        <fpage>156</fpage>
        <lpage>165</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jbi.2015.10.001</pub-id>
        <pub-id pub-id-type="pmid">26464024</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Lipton, Z. C., Kale, D. C., Elkan, C. &amp; Wetzel, R. Learning to diagnose with lstm recurrent neural networks. <italic>International Conference on Learning Representations</italic> (2016).</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pradhan</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Evaluating the state of the art in disorder recognition and normalization of the clinical narrative</article-title>
        <source>J. Am. Med. Inform. Assoc.</source>
        <year>2014</year>
        <volume>22</volume>
        <fpage>143</fpage>
        <lpage>154</lpage>
        <pub-id pub-id-type="doi">10.1136/amiajnl-2013-002544</pub-id>
        <pub-id pub-id-type="pmid">25147248</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Jagannatha, A. N. &amp; Yu, H. Bidirectional rnn for medical event detection in electronic health records. <italic>Proceedings of the Conference. Association for Computational Linguistics. North American Chapter. Meeting</italic> 473 (2016).</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Elhadad, N.et al. Semeval-2015 task 14: analysis of clinical text. <italic>Proceedings of the 8th International Workshop On Semantic Evaluation (Semeval 2014).</italic> 303–310 (2015).</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Pradhan, S., Elhadad, N., Chapman, W., Manandhar, S. &amp; Savova, G. Semeval-2014 task 7: analysis of clinical text. <italic>Proceedings of the 8th International Workshop on Semantic Evaluation (Semeval 2014)</italic>. 54–62 (2014).</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Baumel, T., Nassour-Kassis, J., Cohen, R., Elhadad, M. &amp; Elhadad, N. Multi-label classification of patient notes: case study on ICD code assignment. <italic>AAAI Workshops</italic> (2018).</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rajkomar</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Scalable and accurate deep learning with electronic health records</article-title>
        <source>Digit. Med.</source>
        <year>2018</year>
        <volume>1</volume>
        <fpage>18</fpage>
        <pub-id pub-id-type="doi">10.1038/s41746-018-0029-1</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kavuluru</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Rios</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>An empirical evaluation of supervised learning approaches in assigning diagnosis codes to electronic medical records</article-title>
        <source>Artif. Intell. Med.</source>
        <year>2015</year>
        <volume>65</volume>
        <fpage>155</fpage>
        <lpage>166</lpage>
        <pub-id pub-id-type="doi">10.1016/j.artmed.2015.04.007</pub-id>
        <pub-id pub-id-type="pmid">26054428</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Subotin</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Davis</surname>
            <given-names>AR</given-names>
          </name>
        </person-group>
        <article-title>A method for modeling co-occurrence propensity of clinical codes with application to ICD-10-PCS auto-coding</article-title>
        <source>J. Am. Med. Inform. Assoc.</source>
        <year>2016</year>
        <volume>23</volume>
        <fpage>866</fpage>
        <lpage>871</lpage>
        <pub-id pub-id-type="doi">10.1093/jamia/ocv201</pub-id>
        <pub-id pub-id-type="pmid">26911826</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Perotte</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Diagnosis code assignment: Models and evaluation metrics</article-title>
        <source>J. Am. Med. Inform. Assoc.</source>
        <year>2013</year>
        <volume>21</volume>
        <fpage>231</fpage>
        <lpage>237</lpage>
        <pub-id pub-id-type="doi">10.1136/amiajnl-2013-002159</pub-id>
        <pub-id pub-id-type="pmid">24296907</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Li, Q. Literature survey: domain adaptation algorithms for natural language processing, Department of Computer Science The Graduate Center, The City University of New York. 8–10 (2012).</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Aronson</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Lang</surname>
            <given-names>FM</given-names>
          </name>
        </person-group>
        <article-title>An overview of metamap: Historical perspective and recent advances</article-title>
        <source>J. Am. Med. Inform. Assoc.</source>
        <year>2010</year>
        <volume>17</volume>
        <fpage>229</fpage>
        <lpage>236</lpage>
        <pub-id pub-id-type="doi">10.1136/jamia.2009.002733</pub-id>
        <pub-id pub-id-type="pmid">20442139</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Graves, A., Fernández, S. &amp; Schmidhuber, J. Bidirectional lSTM networks for improved phoneme classification and recognition. <italic>Int. Conf. Artif. Neural Netw</italic>. <bold>3697</bold>, 799–804 (2005).</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Jacob, L., Vert, J. -P. &amp; Bach, F. R. Clustered multi-task learning: A convex formulation. <italic>Adv. Neural. Inf. Process. Syst</italic>. <bold>21</bold>, 745–752 (2009).</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Kim, Y. Convolutional neural networks for sentence classification. <italic>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</italic>. 1746–1751 (2014).</mixed-citation>
    </ref>
  </ref-list>
</back>
