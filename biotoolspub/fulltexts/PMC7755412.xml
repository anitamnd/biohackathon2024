<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7755412</article-id>
    <article-id pub-id-type="pmid">32663244</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa637</article-id>
    <article-id pub-id-type="publisher-id">btaa637</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>qSNE: quadratic rate t-SNE optimizer with automatic parameter tuning for large datasets</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Häkkinen</surname>
          <given-names>Antti</given-names>
        </name>
        <xref rid="btaa637-cor1" ref-type="corresp"/>
        <aff><institution>Research Program in Systems Oncology, Research Programs Unit, Faculty of Medicine, University of Helsinki</institution>, 00014 Helsinki, <country country="FI">Finland</country></aff>
        <!--antti.e.hakkinen@helsinki.fi-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Koiranen</surname>
          <given-names>Juha</given-names>
        </name>
        <aff><institution>Research Program in Systems Oncology, Research Programs Unit, Faculty of Medicine, University of Helsinki</institution>, 00014 Helsinki, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Casado</surname>
          <given-names>Julia</given-names>
        </name>
        <aff><institution>Research Program in Systems Oncology, Research Programs Unit, Faculty of Medicine, University of Helsinki</institution>, 00014 Helsinki, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kaipio</surname>
          <given-names>Katja</given-names>
        </name>
        <aff><institution>Research Center for Cancer, Infections and Immunity, Institute of Biomedicine, University of Turku</institution>, Turku 20014, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lehtonen</surname>
          <given-names>Oskari</given-names>
        </name>
        <aff><institution>Research Program in Systems Oncology, Research Programs Unit, Faculty of Medicine, University of Helsinki</institution>, 00014 Helsinki, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Petrucci</surname>
          <given-names>Eleonora</given-names>
        </name>
        <aff><institution>Department of Oncology and Molecular Medicine, Istituto Superiore di Sanità</institution>, Rome 00161, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hynninen</surname>
          <given-names>Johanna</given-names>
        </name>
        <aff><institution>Department of Obstetrics and Gynecology, University of Turku and Turku University Hospital</institution>, Turku 20521, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hietanen</surname>
          <given-names>Sakari</given-names>
        </name>
        <aff><institution>Department of Obstetrics and Gynecology, University of Turku and Turku University Hospital</institution>, Turku 20521, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Carpén</surname>
          <given-names>Olli</given-names>
        </name>
        <aff><institution>Research Program in Systems Oncology, Research Programs Unit, Faculty of Medicine, University of Helsinki</institution>, 00014 Helsinki, <country country="FI">Finland</country></aff>
        <aff><institution>Research Center for Cancer, Infections and Immunity, Institute of Biomedicine, University of Turku</institution>, Turku 20014, <country country="FI">Finland</country></aff>
        <aff><institution>Department of Pathology, University of Helsinki and HUSLAB, Helsinki University Hospital</institution>, Helsinki 00014, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pasquini</surname>
          <given-names>Luca</given-names>
        </name>
        <aff><institution>Major Equipments and Core Facilities, Istituto Superiore di Sanità</institution>, Rome 00161, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Biffoni</surname>
          <given-names>Mauro</given-names>
        </name>
        <aff><institution>Department of Oncology and Molecular Medicine, Istituto Superiore di Sanità</institution>, Rome 00161, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lehtonen</surname>
          <given-names>Rainer</given-names>
        </name>
        <aff><institution>Research Program in Systems Oncology, Research Programs Unit, Faculty of Medicine, University of Helsinki</institution>, 00014 Helsinki, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Hautaniemi</surname>
          <given-names>Sampsa</given-names>
        </name>
        <xref rid="btaa637-cor1" ref-type="corresp"/>
        <aff><institution>Research Program in Systems Oncology, Research Programs Unit, Faculty of Medicine, University of Helsinki</institution>, 00014 Helsinki, <country country="FI">Finland</country></aff>
        <!--sampsa.hautaniemi@helsinki.fi-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Wren</surname>
          <given-names>Jonathan</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btaa637-cor1">To whom correspondence should be addressed. <email>antti.e.hakkinen@helsinki.fi</email> or <email>sampsa.hautaniemi@helsinki.fi</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>15</day>
      <month>10</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-07-14">
      <day>14</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>14</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <volume>36</volume>
    <issue>20</issue>
    <fpage>5086</fpage>
    <lpage>5092</lpage>
    <history>
      <date date-type="received">
        <day>31</day>
        <month>1</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>06</day>
        <month>7</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>08</day>
        <month>7</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa637.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Non-parametric dimensionality reduction techniques, such as t-distributed stochastic neighbor embedding (t-SNE), are the most frequently used methods in the exploratory analysis of single-cell datasets. Current implementations scale poorly to massive datasets and often require downsampling or interpolative approximations, which can leave less-frequent populations undiscovered and much information unexploited.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We implemented a fast t-SNE package, qSNE, which uses a quasi-Newton optimizer, allowing quadratic convergence rate and automatic perplexity (level of detail) optimizer. Our results show that these improvements make qSNE significantly faster than regular t-SNE packages and enables full analysis of large datasets, such as mass cytometry data, without downsampling.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>Source code and documentation are openly available at <ext-link xlink:href="https://bitbucket.org/anthakki/qsne/" ext-link-type="uri">https://bitbucket.org/anthakki/qsne/</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>European Union’s Horizon 2020 research and innovation programme</institution>
          </institution-wrap>
        </funding-source>
        <award-id>667403</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Academy of Finland</institution>
            <institution-id institution-id-type="DOI">10.13039/501100002341</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>292402</award-id>
        <award-id>325956</award-id>
        <award-id>314395</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Sigrid Jusélius Foundation; and the Finnish Cancer Association</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Academy of Finland</institution>
            <institution-id institution-id-type="DOI">10.13039/501100002341</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>322927</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Single-cell measurement technologies have become routinely used tools in medical research (<xref rid="btaa637-B11" ref-type="bibr">Heath <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btaa637-B23" ref-type="bibr">Shalek and Benson, 2017</xref>; <xref rid="btaa637-B26" ref-type="bibr">Stuart and Satija, 2019</xref>). While these technologies offer unprecedented opportunities to understand diseases at a single-cell resolution, the vast quantity and the high dimension of the data pose challenges for the analysis. For example, mass cytometry allows simultaneously quantification of tens of proteins from hundreds of thousands of individual cells (<xref rid="btaa637-B2" ref-type="bibr">Amir <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btaa637-B16" ref-type="bibr">Levine <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="btaa637-B25" ref-type="bibr">Spitzer and Nolan, 2016</xref>) and single-cell RNA-seq technology tens of thousands of genes in thousands of cells (<xref rid="btaa637-B11" ref-type="bibr">Heath <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btaa637-B23" ref-type="bibr">Shalek and Benson, 2017</xref>; <xref rid="btaa637-B26" ref-type="bibr">Stuart and Satija, 2019</xref>). As a research project commonly features hundreds of samples, the paucity of analysis tools designed to scale to these dimensions hinders the exploitation of the information in the data to the fullest.</p>
    <p>Non-parametric dimensionality reduction techniques, such as t-distributed stochastic neighbor embedding (t-SNE) (<xref rid="btaa637-B2" ref-type="bibr">Amir <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btaa637-B17" ref-type="bibr">Linderman <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa637-B29" ref-type="bibr">van der Maaten and Hinton, 2008</xref>) and uniform manifold approximation and projection (UMAP) (<xref rid="btaa637-B3" ref-type="bibr">Becht <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa637-B19" ref-type="bibr">McInnes <italic toggle="yes">et al.</italic>, 2018</xref>) are the most frequently used methods in exploratory single-cell data analysis (<xref rid="btaa637-B3" ref-type="bibr">Becht <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa637-B6" ref-type="bibr">Butler <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btaa637-B7" ref-type="bibr">Cao <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa637-B16" ref-type="bibr">Levine <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="btaa637-B27" ref-type="bibr">Tasic <italic toggle="yes">et al.</italic>, 2018</xref>). Despite being derived from different assumptions, in fact, the methods are very similar in nature and the differences can be attributed to hyperparameter choices and approximation schemes (<xref rid="btaa637-B19" ref-type="bibr">McInnes <italic toggle="yes">et al.</italic>, 2018</xref>, see <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>). While t-SNE seems to retain clusters qualitatively better, UMAP tends to be better on continuous trajectories in practice (<xref rid="btaa637-B3" ref-type="bibr">Becht <italic toggle="yes">et al.</italic>, 2019</xref>), but this has been suggested to be solely due to different initialization (<xref rid="btaa637-B13" ref-type="bibr">Kobak and Linderman, 2019</xref>). Currently, t-SNE is the most commonly used method, especially in the mass cytometry field (<xref rid="btaa637-B2" ref-type="bibr">Amir <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btaa637-B3" ref-type="bibr">Becht <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa637-B16" ref-type="bibr">Levine <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="btaa637-B25" ref-type="bibr">Spitzer and Nolan, 2016</xref>).</p>
    <p>The main issue with the standard t-SNE is that the optimization process is naive (gradient descent) and slow. To counter this, downsampling has been traditionally used (<xref rid="btaa637-B2" ref-type="bibr">Amir <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btaa637-B5" ref-type="bibr">Bendall <italic toggle="yes">et al.</italic>, 2012</xref>; <xref rid="btaa637-B21" ref-type="bibr">Qiu <italic toggle="yes">et al.</italic>, 2011</xref>) and, more recently, interpolation schemes have been proposed (<xref rid="btaa637-B10" ref-type="bibr">Gisbrecht <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="btaa637-B17" ref-type="bibr">Linderman <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa637-B28" ref-type="bibr">van der Maaten, 2014</xref>). However, these strategies remain problematic, as less-frequent populations are likely filtered out or get intermixed in the larger patterns (as interpolation omits high-frequency features, and thus information). This can be a problem, as e.g. even a small malignant population can give rise to cancer progression due to evolutionary pressure (<xref rid="btaa637-B1" ref-type="bibr">Agarwal and Kaye, 2003</xref>; <xref rid="btaa637-B11" ref-type="bibr">Heath <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btaa637-B22" ref-type="bibr">Shaffer <italic toggle="yes">et al.</italic>, 2017</xref>). Further, the algorithm is sensitive to the selection of a fixed perplexity (a scale or level of detail parameter), which necessitates parameter tuning from the data analyst. Combined with poor performance on large datasets (<xref rid="btaa637-B4" ref-type="bibr">Belkina <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa637-B17" ref-type="bibr">Linderman <italic toggle="yes">et al.</italic>, 2019</xref>), this makes the whole process of analyzing the data laborious. Finally, the original t-SNE algorithm makes no attempt to evaluate how faithfully the visualization represents the underlying data.</p>
    <p>To address these issues, we implemented (i) a solver that converges methodologically faster and requires no tuning of the gradient descent parameters; (ii) an automatic parameter selection process, which removes the need for manual perplexity tuning; and (iii) a quality metric, which can be used to assess whether the projected model captures the original high-dimensional data. Our improvements are complementary and can be combined with previous efforts (<xref rid="btaa637-B4" ref-type="bibr">Belkina <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa637-B10" ref-type="bibr">Gisbrecht <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="btaa637-B17" ref-type="bibr">Linderman <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa637-B28" ref-type="bibr">van der Maaten, 2014</xref>), and they are general enough to be combined with GPU acceleration schemes (<xref rid="btaa637-B8" ref-type="bibr">Chan <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa637-B20" ref-type="bibr">Pezzotti <italic toggle="yes">et al.</italic>, 2020</xref>). We show that the improvements alone enable full analysis of large mass cytometry datasets, which reveals novel phenotypic structures not visible in the downsampled data. Our implementation, qSNE, is available at <ext-link xlink:href="https://bitbucket.org/anthakki/qsne/" ext-link-type="uri">https://bitbucket.org/anthakki/qsne/</ext-link> under an open (BSD) license.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 The t-SNE algorithm</title>
      <p>The t-distributed stochastic neighbor embedding (t-SNE) finds a lower-dimensional representation of a dataset such that the distribution of local distances between the samples is maintained (<xref rid="btaa637-B29" ref-type="bibr">van der Maaten and Hinton, 2008</xref>). More specifically, it optimizes the information lost (Kullback–Leibler divergence) when using a low-dimensional distribution <italic toggle="yes">Q</italic> to approximate the high-dimensional neighbor distribution <italic toggle="yes">P</italic>:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mo>≐</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mtext>KL</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mo>−</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mo>⁡</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <italic toggle="yes">m</italic> is the number of samples and <italic toggle="yes">p<sub>ij</sub></italic> (<italic toggle="yes">q<sub>ij</sub></italic>) are the high (low)-dimensional densities of the distribution <italic toggle="yes">P</italic> (<italic toggle="yes">Q</italic>) between the samples <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic>. t-SNE uses a normal distribution for <italic toggle="yes">P</italic> and a t-distribution for <italic toggle="yes">Q</italic> (<xref rid="btaa637-B29" ref-type="bibr">van der Maaten and Hinton, 2008</xref>; see <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> for details), but other distributions are possible, the normal distribution representing a diffusive random walk between the samples (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>). The diffusivity of the input space <italic toggle="yes">P</italic> is controlled by the standard deviation <italic toggle="yes">σ<sub>i</sub></italic> of the normal distribution around the sample <italic toggle="yes">i</italic>, which is set by a global perplexity parameter <italic toggle="yes">π</italic> representing the number of relevant neighbors (<xref rid="btaa637-B29" ref-type="bibr">van der Maaten and Hinton, 2008</xref>). The original algorithm by <xref rid="btaa637-B29" ref-type="bibr">van der Maaten and Hinton (2008)</xref> uses gradient descent and a momentum term to optimize the intricate cost function.</p>
    </sec>
    <sec>
      <title>2.2 The L-BFGS algorithm</title>
      <p>A gradient descent scheme only allows linear convergence, which can be prohibitively slow on large datasets. Quadratic methods (such as Newton’s method) permit quadratic convergence, but evaluating the Hessian matrix directly is too expensive, so we use the limited-memory Broyden–Fletcher–Goldfarb–Shanno method (L-BFGS) (<xref rid="btaa637-B18" ref-type="bibr">Liu and Nocedal, 1989</xref>), which uses rank-1 updates inferred from the previous updates and their gradients to numerically estimate a Newton search vector [see <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>, Algorithm (SA1)]. This combines potentially quadratic convergence with low computational overhead as the full Hessian matrix need not to be evaluated, but a low-rank approximation is used, and even that need not to be explicitly formed in the memory. Provided that the low-rank approximation can retain most of the power of the true Hessian matrix, the performance remains comparable to a true Newton method. A Newton method is also in advantageous in the sense that the step size is naturally set by the Hessian matrix magnitude.</p>
    </sec>
    <sec>
      <title>2.3 Automatic perplexity selection</title>
      <p>The neighborhood entropy <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a monotonic increasing curve from 0 to <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> as the bandwidth <italic toggle="yes">σ<sub>i</sub></italic> varies from 0 to <italic toggle="yes">∞</italic>. This entropy curve is used to locate the bandwidth corresponding to the specified perplexity value <italic toggle="yes">π</italic>. However, the curve can be also exploited to identify the bandwidths where the neighborhood structure remains insensitive. This holds also in the presence of multiple local scales, as a scale only contributes to the entropy gradient at the sensitive regions. In practice, this results in a staircase-like figure (see e.g. <xref rid="btaa637-F3" ref-type="fig">Fig. 3</xref>) where flat regions correspond to uninteresting perplexity values and highly transient sensitive. Given a perplexity range, the optimum can be located using sectioning [see <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>, Algorithm (SA3)]. We denote the optimized bandwidths by <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>σ</mml:mo><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> and the corresponding perplexity values <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>π</mml:mo><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>, and the latter no longer need to be fixed over the dataset, which also allows different (optimal) perplexity at different regions of the space.</p>
    </sec>
    <sec>
      <title>2.4 Quality of an acquired mapping</title>
      <p>For any mapping in the t-SNE framework, the source entropy <italic toggle="yes">H</italic>(<italic toggle="yes">P</italic>) represents the average number of bits needed to encode a sample of the original neighbor relationship, while the Kullback–Leibler divergence between the source and destination distributions <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mtext>KL</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the average number of extra bits needed if the output model is used encode the samples instead. These are readily available during the optimization, and can be evaluated once the optimal mapping has been obtained.</p>
      <p>To quantify the quality of the mapping, we propose the following normalized statistic:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi><mml:mo>≐</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mtext>KL</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> is the distribution around the <italic toggle="yes">i</italic>th sample for its optimal bandwidth and <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the optimal embedding distribution. This quantity has the following rationale: <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> quantifies the bits needed to represent the samples in the original space, while the cross-entropy <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mtext>KL</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> represents the number of bits needed to encode the data using the low-dimensional model, their ratio being the fraction of samples encoded in the same space with the output model. As expected, <italic toggle="yes">q</italic> is zero for one-to-one correspondence between the source and destination distributions (<inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mtext>KL</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), and unity if all the information is lost (<inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mtext>KL</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>∞</mml:mo></mml:mrow></mml:math></inline-formula>). In practice, <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is obtained as a side product of the automatic perplexity selection [through Equation (S5) after Algorithm (SA3)] and <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mtext>KL</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> as a side product of obtaining the t-SNE mapping for the optimized bandwidths [through Equation (S4) after Algorithm (SA4)].</p>
    </sec>
    <sec>
      <title>2.5 Datasets used for evaluation</title>
      <p>To illustrate the advantages of our method, qSNE, we used two publicly available (human bone marrow and MNIST) and one unpublished high-grade ovarian cancer (HGSOC) dataset. The advantage of the bone marrow and MNIST datasets is that they are manually labeled and thus it is possible to quantify whether the visualization is meaningful. For the purposes of comparison, the datasets were downsampled as it is not practical to run the original t-SNE algorithm on 100 000 s of samples, especially with various parameters. Meanwhile, the HGSOC dataset demonstrates that the improvements in qSNE enable discovering novel biomedical insights from cancer patient samples. We also analyzed a Splatter generated (<xref rid="btaa637-B30" ref-type="bibr">Zappia <italic toggle="yes">et al.</italic>, 2017</xref>) single-cell RNA-seq dataset in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>, which features a much higher dimension (18 726 genes).</p>
      <p>The first dataset, available at <ext-link xlink:href="https://github.com/lmweber/benchmark-data-Levine-32-dim" ext-link-type="uri">https://github.com/lmweber/benchmark-data-Levine-32-dim</ext-link>, quantifies a panel of surface protein markers for single cells from human bone marrow profiled using time-of-flight mass cytometry (CyTOF) measurements, which were originally used to study phenotypic heterogeneity of acute myeloid leukemia (AML) patients (<xref rid="btaa637-B16" ref-type="bibr">Levine <italic toggle="yes">et al.</italic>, 2015</xref>). The data features a total of 104 184 manually gated (labeled) cells with 32 protein markers from two individuals, and represents a typical experimental setting for a CyTOF measurement.</p>
      <p>Second, we use the MNIST database (<xref rid="btaa637-B14" ref-type="bibr">Lecun <italic toggle="yes">et al.</italic>, 1998</xref>), available at <ext-link xlink:href="http://yann.lecun.com/exdb/mnist/" ext-link-type="uri">http://yann.lecun.com/exdb/mnist/</ext-link>, which is a collection of handwritten digits (from 0 to 9). We only used the training set part of the dataset, featuring 60 000 labeled samples, which are 28 × 28 pixel images of 256 gray levels each (regarded as 784-dimensional vectors). This dataset has been frequently used to benchmark machine learning methods, and was used for evaluation e.g. by <xref rid="btaa637-B29" ref-type="bibr">van der Maaten and Hinton (2008)</xref>.</p>
      <p>The third dataset consists of CyTOF measurements of ascites samples harvested from a single HGSOC patient, before and after administering chemotherapy. These data contains 27 surface protein markers in 98 512 single cells in the primary (before chemotherapy) and 127 874 cells in the interval (after chemotherapy) sample.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <sec>
      <title>3.1 Faster t-SNE mapping through quasi-Newton optimization</title>
      <p>We implemented a quasi-Newton optimizer, based on the limited-memory Broyden–Fletcher–Goldfarb–Shanno (L-BFGS) algorithm (<xref rid="btaa637-B18" ref-type="bibr">Liu and Nocedal, 1989</xref>), on the t-distributed stochastic neighbor embedding (t-SNE) objective, which permits quadratic convergence (<xref rid="btaa637-B18" ref-type="bibr">Liu and Nocedal, 1989</xref>) as opposed to the linear convergence of the gradient descent used in the original implementation (<xref rid="btaa637-B29" ref-type="bibr">van der Maaten and Hinton, 2008</xref>). The L-BFGS optimizer exploits a numerical estimate of the local curvature to allow converge in ∼30 iterations (<inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>000</mml:mn></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>) versus the 1000 of the original variant, which yields an order of magnitude speedup even on modestly sized datasets.</p>
      <p>To evaluate the performance of qSNE, we used a human bone marrow mass cytometry dataset (Levine) (<xref rid="btaa637-B16" ref-type="bibr">Levine <italic toggle="yes">et al.</italic>, 2015</xref>), which well represents the experimental setting of a mass cytometry measurement and has also been manually gated, which provides ground truth for performance evaluation (<xref rid="btaa637-B16" ref-type="bibr">Levine <italic toggle="yes">et al.</italic>, 2015</xref>). The corresponding results for the MNIST dataset (<xref rid="btaa637-B14" ref-type="bibr">Lecun <italic toggle="yes">et al.</italic>, 1998</xref>) are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figures S1 and S2</xref>, and Splatter-generated (<xref rid="btaa637-B30" ref-type="bibr">Zappia <italic toggle="yes">et al.</italic>, 2017</xref>) single-cell RNA-seq data in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figures S5 and S6</xref>.</p>
      <p>To verify that the L-BFGS optimizer operates in the quadratic converge region in a typical setting, we compared how the t-SNE objective—Kullback–Leibler (K–L) divergence between distributions of the pairwise distances of the points in the input and output space—evolves as a function of the iteration count. The results in <xref rid="btaa637-F1" ref-type="fig">Figure 1</xref> suggest that in the initial region the L-BFGS optimizer attains a superlinear convergence, while no such effect can be observed with a gradient descent optimizer, as expected. By comparing the iteration counts required for equal progress, as shown in <xref rid="btaa637-F1" ref-type="fig">Figure 1</xref>, we verified that the convergence of the L-BFGS optimizer is indeed quadratic with respect to that of the gradient descent in the beginning of the optimization. We report that typically the convergence of the L-BFGS optimizer is quadratic in the beginning, but as the optimizer quickly arrives near to the optimum, the rate drops to linear as precision starts to limit the process. Still, the linear rate of convergence remains faster with the L-BFGS optimizer, likely as the learning rate is optimized rather than fixed. We also note that there is a natural warm-up of few iterations, as the L-BFGS optimizer needs to collect curvature information before quadratic speed can be attained.
</p>
      <fig position="float" id="btaa637-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Convergence of qSNE versus a linear t-SNE implementation. Left panels: Progress, as quantified by the excess objective value above the optimum (determined experimentally) as a function of number of iterations for the Levine (<xref rid="btaa637-B16" ref-type="bibr">Levine <italic toggle="yes">et al.</italic>, 2015</xref>) and MNIST (<xref rid="btaa637-B14" ref-type="bibr">Lecun <italic toggle="yes">et al.</italic>, 1998</xref>) datasets, randomly downsampled to 10 000 samples at perplexity 100, for both our quadratic implementation (Q) with various ranks of Hessian matrix approximation (hr) and for a linear Rtsne implementation (R). Right panels: Number of consumed iterations for equal progress (objective value) for the two methods (magenta curve). The dashed black lines indicate a linear or a quadratic fit. (Color version of this figure is available at <italic toggle="yes">Bioinformatics</italic> online.)</p>
        </caption>
        <graphic xlink:href="btaa637f1" position="float"/>
      </fig>
      <p>The results show also that the exact rank of the Hessian matrix approximation plays a minor role in the qualitative behavior of the convergence on these data. While a larger rank generally allows faster convergence, even constant-rank approximations feature the benefit of quadratic convergence and only incur a constant overhead per iteration, suggesting that the strategy is viable for speeding up practical large-scale problems. This is of course only possible if the data are inherently locally, but not necessarily globally, low-dimensional but embedded in a higher-dimensional space, which often is the case and can be expected, for example, in gene expression datasets due to inherent correlations.</p>
      <p>Often the cost surface features multiple local optima, which may imply convergence to a different optimum for different optimization paths. To evaluate whether the obtained visualizations are useful after the short quadratic walk, we visualized the projections for the two methods. The results are illustrated in <xref rid="btaa637-F2" ref-type="fig">Figure 2</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>. The obtained projections appear qualitatively similar: the bone marrow data captures the hematopoietic developmental lineages in both the qSNE and Rtsne mappings (<xref rid="btaa637-B16" ref-type="bibr">Levine <italic toggle="yes">et al.</italic>, 2015</xref>). Specifically, the hematopoietic stem cells and progenitors map in the center of the projection, while the more differentiated and matured cells are located at the exterior of the plot, and mature T-cells map to the furthest distance from the center. As shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref>, the conclusions regarding the convergence and quality of mappings hold for various datasets, downsampling factors, and for various perplexity and optimization parameters.
</p>
      <fig position="float" id="btaa637-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Levine bone marrow data mapped into 2-D. Left panel: qSNE with rank-11 Hessian matrix approximation after only 150 quasi-Newton iterations; and right panel: t-SNE after 7280 iterations (cf. <xref rid="btaa637-F1" ref-type="fig">Fig. 1</xref>). The datasets were randomly downsampled to 10 000 samples and perplexity is set to 100 in both cases</p>
        </caption>
        <graphic xlink:href="btaa637f2" position="float"/>
      </fig>
      <p>In terms of consumed CPU time qSNE is much faster than Rtsne (v0.15, using van der Maaten’s C++ implementation, see <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>), as shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3</xref>. With a single thread, an analysis for qSNE takes <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mo>∼</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:math></inline-formula> min to 2 h, while the same analyses for Rtsne take ∼2–25 h. The main benefit comes from the fact that qSNE requires an order of magnitude fewer iterations for convergence, but on the other hand the cost per iteration is slightly larger (by a constant factor if the Hessian matrix rank is <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>), but small enough to give a distinct benefit and to be insignificant even when considering an equal number of iterations. Furthermore, qSNE can fully utilize parallelization at both vector instruction and thread levels, which can give yet another order of magnitude of advantage for practical analyses in terms of wall clock time.</p>
    </sec>
    <sec>
      <title>3.2 Automatic bandwidth selection reduces parameter tuning</title>
      <p>The choice of the perplexity parameter can have big impact to the resulting t-SNE mapping and finding an optimal value through trial and error is tedious. We show that most perplexity values are not very interesting, exerting very little changes on the acquired mapping, and such regions can be automatically detected (detailed in the Section 2). This allows the analyst to focus on the relevant perplexity values. On the other hand, the perplexity parameter can be fine-tuned to an optimal value around a chosen bandwidth, provided that a sufficiently narrow range with a single optimum is selected. Moreover, a variable bandwidth across the sample space can be advantageous in case the space is not uniform, but contains clusters with various bandwidths.</p>
      <p>To exemplify the operation of the automatic perplexity selection, we generated a 10-dimensional synthetic dataset with five clusters [with standard deviation (SD) of 1] each having five subclusters (with SD of 0.25) with a total of 1000 samples (with SD of 0.01). Depending on the selected perplexity range, qSNE results in one of the possible representation of the dataset: the least perplexity optimum corresponds to the setting where each sample is separated into a separate cluster; the next one reveals each of the 25 subclusters; and the third the five high-level clusters, as shown in <xref rid="btaa637-F3" ref-type="fig">Figure 3</xref>. The highest perplexity setting will opt to form a single cluster for all the data points. The question which one of these is the most useful is of course up to the data analyst, but the number of embeddings with differing structure can be analyzed in the perplexity-bandwidth plot and fine tuning of the perplexity value can be automatically performed and allows discovering this hierarchy.
</p>
      <fig position="float" id="btaa637-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Perplexity versus bandwidth with fixed and automatic perplexity selection. Left panel: an artificial dataset of 10-D hierarchically normal data with five clusters with five subclusters each. The blue dots visualize the effective bandwidth (the chosen <italic toggle="yes">σ<sub>i</sub></italic> parameter) for each sample with the blue curve showing their median. Meanwhile, the green dots visualize the effective perplexity versus the effective bandwidth for each sample when the perplexity is automatically tuned by a factor of [2<sup>–1</sup>, 2]. The gray arrows indicate the estimated gradient field for the perplexity tuning process. The dashed black lines indicate the true bandwidths in the generated data. Visualizations of the resulting mappings are shown in insets. Right panel: the corresponding plot for Levine data downsampled to 15 000 samples. (Color version of this figure is available at <italic toggle="yes">Bioinformatics</italic> online.)</p>
        </caption>
        <graphic xlink:href="btaa637f3" position="float"/>
      </fig>
      <p>To demonstrate that the automated perplexity tuning is useful in practice, we performed perplexity analysis on the Levine dataset. For these data, the interesting levels of detail regarding a 2-D projection correspond to (i) 3-clustering into B-cells, T-cells and in less tissue-specific cells; or (ii) into a more detailed clustering including hematopoietic stem and progenitor cells and their differentiated forms (as shown in <xref rid="btaa637-F2" ref-type="fig">Fig. 2</xref>). Specifically, for the dataset downsampled to 15 000 points, these two clusterings are attracted roughly from the perplexity regions [20, 100] and [2000, 10 000]. The perplexity-bandwidth plot for the Levine dataset is shown in <xref rid="btaa637-F3" ref-type="fig">Figure 3</xref>, where the insets indicate the optimal projections.</p>
    </sec>
    <sec>
      <title>3.3 Information lost in the t-SNE mappings</title>
      <p>A projection from a high-dimensional dataset into lowerdimension loses information, so it is useful to evaluate how well the projection represents the original data. For this, we suggest to compute the fraction of information lost in the projection [see Section 2, specifically <xref rid="E2" ref-type="disp-formula">Equation (2)]</xref>, and show that this statistic can capture both the loss of local and of a more global level structure.</p>
      <p>For comparison, we evaluated the average number of retained <italic toggle="yes">n</italic>-nearest neighbors for various values of <italic toggle="yes">n</italic> (Jaccard index of the <italic toggle="yes">n</italic> nearest neighbors before and after projection). Small and large <italic toggle="yes">n</italic> represent how well the local relationships (i.e. order of the nearby samples) and global relationship (i.e. order of long-distance samples), respectively, are preserved. The Jaccard index-based metric is expensive to calculate for high-dimensional data (<xref rid="btaa637-B15" ref-type="bibr">Lee and Verleysen, 2009</xref>), while our metric is produced as a side product of t-SNE mapping (see Section 2).</p>
      <p>We analyzed synthetic datasets (<italic toggle="yes">k</italic>-dimensional multivariate normal data) with varying inherent dimension of the data embedded in a 10-D space (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>), and evaluated the information loss metric. In these, the structure is random, the complexity being set by the inherent dimension, which is easier to generate and harder to capture than a more realistic data. As shown in <xref rid="btaa637-F4" ref-type="fig">Figure 4</xref>, the metric correlates well with maintaining both local and global structures. For inherently 2-D problems, a very high degree of information is retained, which is also reflected by the number of retained neighbors at all scales. For higher-dimensional problems, less information is captured by the projection, as expected. We also verified that the metric performs well with practical problems at varying perplexity as evaluated at the characteristic level of detail as shown for the Levine and MNIST datasets.
</p>
      <fig position="float" id="btaa637-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Average number of retained neighbors versus fraction of retained information. The lines indicate 10-D normal problems with 5000 samples, with inherent dimension varying from 2 to 10 (2-D being closest to (1, 1) and 10-D furthest), colors indicating varying perplexity from 1 to 4999 at logarithmically equispaced intervals. The curves with pluses indicate how well local structure is maintained (<italic toggle="yes">n </italic>=<italic toggle="yes"> </italic>20) and <italic toggle="yes">x</italic>: s the global structure (<italic toggle="yes">n </italic>=<italic toggle="yes"> </italic>4000). The Levine and MNIST datasets are evaluated at their characteristic level of detail (i.e. <italic toggle="yes">n</italic> equal to the perplexity) for various perplexity values</p>
        </caption>
        <graphic xlink:href="btaa637f4" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.4 High-resolution analysis reveals putative chemoresistant and chemosensitive phenotypes in ovarian cancer tumors</title>
      <p>To show the benefits of qSNE on a large mass cytometry dataset, we analyzed the levels of 18 proteins in high-grade serous ovarian cancer (HGSOC) patient ascites samples before and after chemotherapy. The proteins were selected to span HGSOC cancer markers (CA-125 and HE4) (<xref rid="btaa637-B9" ref-type="bibr">Ferraro <italic toggle="yes">et al.</italic>, 2013</xref>); epithelial cell markers (MUC1, E-cadherin, EpCAM); immune and inflammatory markers (CD8a, CD45, CD3 and PD1); stromal markers (CD90, CD44 and CD146) and stemness and other markers (CD117, Sox2, CD24, CD133-APC, N-cadherin and CD166-PE). The dataset consists of 173 374 cells, which is impractical to analyze using the traditional t-SNE algorithm. However, a dataset of this scale poses no challenge to qSNE, which generated a full-resolution mapping in <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mo>∼</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> h 15 min of computation.</p>
      <p>To compare the full-resolution mapping to the traditional subsampling, we acquired a mapping using Rtsne using 10 000 randomly subsampled cells. The mappings are shown in <xref rid="btaa637-F5" ref-type="fig">Figure 5</xref> on a similar scale, and a higher fidelity version of the full dataset is shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4</xref>, the color encoding the most prominent marker. The full resolution analysis by qSNE revealed several phenotypic clusters that were not identifiable in the downsampled data. For example, various likely stromal (e.g. CD90, CD44 and CD146 high; yellow color; around the bottom of the plot; see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4</xref>) and immune cell clusters (e.g. CD8a, CD45 and CD3 high; red to orange color; bottom right) are visible in both mappings, but unlike in the full-resolution mapping, the cluster substructure is not revealed and the various smaller clusters in between the larger ones appear missing in the lower-resolution analysis. Further analysis of these high-resolution substructures showed that they correlate with whether the cells were subject to the chemotherapy or not (see <xref rid="btaa637-F5" ref-type="fig">Fig. 5</xref>), which suggests that a full-resolution analysis can aid to distinguish the chemotherapy-sensitive and -resistant phenotypes.
</p>
      <fig position="float" id="btaa637-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>t-SNE mappings for a combined sample before and after chemotherapy for an ovarian cancer patient. Left panel: qSNE (173 374 cells, perplexity 150, Hessian matrix rank 5); and right panel: Rtsne (10 000 cells, perplexity 50). The hue indicates the most prominent marker, as indicated in the legend, and the saturation its level. Black highlighting indicates clusters of interest that are not identifiable in the downsampled analysis (unhighlighted data in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4</xref>). The bottom panel shows a heatmap of the average expression of the highlighted clusters. (Color version of this figure is available at <italic toggle="yes">Bioinformatics</italic> online.)</p>
        </caption>
        <graphic xlink:href="btaa637f5" position="float"/>
      </fig>
      <p>Our expert manually annotated clusters (clusters 1–6) that were dominantly enriched in either of the HGSOC markers CA-125 or HE4 in the full-resolution analysis (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4</xref>) and were rich (&gt;50%) in interval (treated sample) cells (see inset of <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4</xref>). These clusters are highlighted in <xref rid="btaa637-F5" ref-type="fig">Figure 5</xref> along with a heatmap of their average expression. The corresponding cells in the downsampled data were found to be scattered in the several clusters, and consequently not identifiable using the lower resolution analysis alone. Of these, cluster 1 is located near the CD3-positive putative T-cell cluster, while cluster 4 is located within the CD8a positive T-cell cluster, which suggests cancer-interacting immune cell phenotypes. Meanwhile, the other clusters are unlikely to be immune cells, as they are enriched in the epithelial markers, particularly the clusters 2 and 3 located on the opposite side of the visualization. Clusters 2 and 3 are also enriched in the cancer stemness marker CD166, while clusters 5 and 6 are enriched in the leukocytic CD45 marker and in CD44, which has been associated with epithelial ovarian cancer cells with a more favorable treatment response (<xref rid="btaa637-B24" ref-type="bibr">Sillanpaa <italic toggle="yes">et al.</italic>, 2003</xref>). Each of the clusters is specific to the interval (after chemotherapy) sample rather than to the treatment naive sample, featuring significantly more interval cells than expected (<italic toggle="yes">P</italic>-values <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>1.6</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> in a conditioned binomial test).</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>Single-cell measurement technologies generate massive, high-resolution datasets. However, most of the current analysis softwares are not directly able to analyze these data and resort to downsampling, which hinders fully exploiting the high-resolution nature of the data.</p>
    <p>We report a novel implementation of the non-parametric dimensionality reduction method t-SNE, called qSNE, which utilizes a quasi-Newton t-SNE optimizer. We show that for many practical problems and parameter settings qSNE allows convergence at quadratic rate, and consequently, an order of magnitude less computation. Importantly, qSNE produces comparable visualizations, despite that it might convergence to a different optimum. In addition, we present a method optimize the input distribution bandwidth, or the perplexity parameter, automatically. This enables the data analyst to focus on only specifying the desired level of detail, and letting the optimizer to deal with parameter tuning. The perplexity tuning also opens up an avenue toward analyzing heteroscedastic data in the complex input space, where no single parameter value can produce satisfactory result. Finally, we proposed a quality metric, which can be obtained as a side product of computing the mapping. This feature is particularly important because at the moment t-SNE visualizations are used without any analysis of the model fitness, which implies that important details of a dataset may remain uncaptured by the model without any sign reported to the analyst. Herein, we propose that a quality metric should be used routinely to assess immediately whether the acquired mapping well represents the original data, which cannot be evaluated using the lower dimensional mapping alone. qSNE is best suited for datasets with 100 000 s samples with 10 to 100 features, such as large mass cytometry data, but we also demonstrated its applicability on single-cell RNA-seq data with 10 000 samples and 18 726 genes.</p>
    <p>Our improvements are general enough to be combined with future improvements, such as alternative input and output models (<xref rid="btaa637-B12" ref-type="bibr">Hinton and Roweis, 2003</xref>); tree-based spatial subdivision (<xref rid="btaa637-B28" ref-type="bibr">van der Maaten, 2014</xref>); out of sample extensions, like kernel t-SNE (<xref rid="btaa637-B10" ref-type="bibr">Gisbrecht <italic toggle="yes">et al.</italic>, 2015</xref>) and other interpolation schemes (<xref rid="btaa637-B17" ref-type="bibr">Linderman <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa637-B20" ref-type="bibr">Pezzotti <italic toggle="yes">et al.</italic>, 2020</xref>); hyperparameter optimization (<xref rid="btaa637-B4" ref-type="bibr">Belkina <italic toggle="yes">et al.</italic>, 2019</xref>); and GPU parallelization schemes (<xref rid="btaa637-B8" ref-type="bibr">Chan <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa637-B20" ref-type="bibr">Pezzotti <italic toggle="yes">et al.</italic>, 2020</xref>). Unlike some of these approaches, we focused here on the exact instead of an approximate problem, as it is application specific whether the approximate schemes allow an analysis at a comparable level of detail.</p>
    <p>We demonstrated that such improvements are critical in analyzing large datasets containing complex, infrequent features. Specifically, we demonstrated the utility by analyzing HGSOC mass cytometry data, which was not previously feasible at the attained level of detail. Our analysis revealed cluster of cells which are only identifiable at the higher level of detail, which can aid in developing efficient interventions to overcome HGSOC chemoresistance. qSNE is freely available with documentation.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btaa637_Supplementary_Data</label>
      <media xlink:href="btaa637_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors thank CSC—IT Center for Science Ltd. for compute resources.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported in part by the European Union’s Horizon 2020 research and innovation programme under Grant Agreement No. 667403 for HERCULES (Comprehensive Characterization and Effective Combinatorial Targeting of High-Grade Serous Ovarian Cancer via Single-Cell Analysis); the Academy of Finland (Project Nos. 292402, 325956 and 314395); the Sigrid Jusélius Foundation; and the Finnish Cancer Association. AH is funded by Academy of Finland Grant No. 322927. The funders had no role in the design of the study and collection, analysis and interpretation of data or in writing the manuscript.</p>
      <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa637-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Agarwal</surname><given-names>R.</given-names></string-name>, <string-name><surname>Kaye</surname><given-names>S.B.</given-names></string-name></person-group> (<year>2003</year>) 
<article-title>Ovarian cancer: strategies for overcoming resistance to chemotherapy</article-title>. <source>Nat. Rev. Cancer</source>, <volume>3</volume>, <fpage>502</fpage>–<lpage>516</lpage>.<pub-id pub-id-type="pmid">12835670</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Amir</surname><given-names>E.D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) 
<article-title>viSNE enables visualization of high dimensional single-cell data and reveals phenotypic heterogeneity of leukemia</article-title>. <source>Nat. Biotechnol</source>., <volume>31</volume>, <fpage>545</fpage>–<lpage>552</lpage>.<pub-id pub-id-type="pmid">23685480</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Becht</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>Dimensionality reduction for visualizing single-cell data using UMAP</article-title>. <source>Nat. Biotechnol</source>., <volume>37</volume>, <fpage>38</fpage>–<lpage>44</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa637-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Belkina</surname><given-names>A.C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>Automated optimized parameters for T-distributed stochastic neighbor embedding improve visualization and analysis of large datasets</article-title>. <source>Nat. Commun</source>., <volume>10</volume>, <fpage>5415</fpage>.<pub-id pub-id-type="pmid">31780669</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bendall</surname><given-names>S.C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) 
<article-title>A deep profiler’s guide to cytometry</article-title>. <source>Trends Immunol</source>., <volume>33</volume>, <fpage>323</fpage>–<lpage>332</lpage>.<pub-id pub-id-type="pmid">22476049</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Butler</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) 
<article-title>Integrating single-cell transcriptomic data across different conditions, technologies, and species</article-title>. <source>Nat. Biotechnol</source>., <volume>36</volume>, <fpage>411</fpage>–<lpage>420</lpage>.<pub-id pub-id-type="pmid">29608179</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cao</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>The single-cell transcriptional landscape of mammalian organogenesis</article-title>. <source>Nature</source>, <volume>566</volume>, <fpage>496</fpage>–<lpage>502</lpage>.<pub-id pub-id-type="pmid">30787437</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chan</surname><given-names>D.M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>GPU accelerated t-distributed stochastic neighbor embedding</article-title>. <source>J. Parallel Distrib. Comput</source>., <volume>131</volume>, <fpage>1</fpage>–<lpage>13</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa637-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ferraro</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) 
<article-title>Serum human epididymis protein 4 vs carbohydrate antigen 125 for ovarian cancer diagnosis: a systematic review</article-title>. <source>J. Clin. Pathol</source>., <volume>66</volume>, <fpage>273</fpage>–<lpage>281</lpage>.<pub-id pub-id-type="pmid">23426716</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gisbrecht</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) 
<article-title>Parametric nonlinear dimensionality reduction using kernel t-SNE</article-title>. <source>Neurocomputing</source>, <volume>147</volume>, <fpage>71</fpage>–<lpage>82</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa637-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heath</surname><given-names>J.R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) 
<article-title>Single-cell analysis tools for drug discovery and development</article-title>. <source>Nat. Rev. Drug Discov</source>., <volume>15</volume>, <fpage>204</fpage>–<lpage>216</lpage>.<pub-id pub-id-type="pmid">26669673</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B12">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Hinton</surname><given-names>G.E.</given-names></string-name>, <string-name><surname>Roweis</surname><given-names>S.T.</given-names></string-name></person-group> (<year>2003</year>) <part-title>Stochastic neighbor embedding</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Becker</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (eds.) <source>Advances in Neural Information Processing Systems</source>, <volume>Vol. 15</volume>. 
<publisher-name>MIT Press</publisher-name>, Cambridge, MA, pp. <fpage>857</fpage>–<lpage>864</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa637-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kobak</surname><given-names>D.</given-names></string-name>, <string-name><surname>Linderman</surname><given-names>G.C.</given-names></string-name></person-group> (<year>2019</year>) 
<article-title>UMAP does not preserve global structure any better than t-SNE when using the same initialization</article-title>. <source>bioRxiv</source>, doi: 10.1101/2019.12.19.877522.</mixed-citation>
    </ref>
    <ref id="btaa637-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lecun</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1998</year>) 
<article-title>Gradient-based learning applied to document recognition</article-title>. <source>Proc. IEEE</source>, <volume>86</volume>, <fpage>2278</fpage>–<lpage>2324</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa637-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>J.A.</given-names></string-name>, <string-name><surname>Verleysen</surname><given-names>M.</given-names></string-name></person-group> (<year>2009</year>) 
<article-title>Quality assessment of dimensionality reduction: rank-based criteria</article-title>. <source>Neurocomputing</source>, <volume>72</volume>, <fpage>1431</fpage>–<lpage>1443</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa637-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Levine</surname><given-names>J.H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) 
<article-title>Data-driven phenotypic dissection of AML reveals progenitor-like cells that correlate with prognosis</article-title>. <source>Cell</source>, <volume>162</volume>, <fpage>184</fpage>–<lpage>197</lpage>.<pub-id pub-id-type="pmid">26095251</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Linderman</surname><given-names>G.C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>Fast interpolation-based t-SNE for improved visualization of single-cell RNA-seq data</article-title>. <source>Nat. Methods</source>, <volume>16</volume>, <fpage>243</fpage>–<lpage>245</lpage>.<pub-id pub-id-type="pmid">30742040</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>D.C.</given-names></string-name>, <string-name><surname>Nocedal</surname><given-names>J.</given-names></string-name></person-group> (<year>1989</year>) 
<article-title>On the limited memory BFGS method for large scale optimization</article-title>. <source>Math. Program</source>., <volume>45</volume>, <fpage>503</fpage>–<lpage>528</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa637-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>McInnes</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) UMAP: uniform manifold approximation and projection for dimension reduction. <italic toggle="yes">arXiv</italic>, arXiv : 1802.03426v2.</mixed-citation>
    </ref>
    <ref id="btaa637-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pezzotti</surname><given-names>N.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) 
<article-title>GPGPU linear complexity t-SNE optimization</article-title>. <source>IEEE Trans. Vis. Comput. Graph</source>., <volume>26</volume>, <fpage>1172</fpage>–<lpage>1181</lpage>.<pub-id pub-id-type="pmid">31449023</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qiu</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) 
<article-title>Extracting a cellular hierarchy from high-dimensional cytometry data with SPADE</article-title>. <source>Nat. Biotechnol</source>., <volume>29</volume>, <fpage>886</fpage>–<lpage>891</lpage>.<pub-id pub-id-type="pmid">21964415</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shaffer</surname><given-names>S.M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) 
<article-title>Rare cell variability and drug-induced reprogramming as a mode of cancer drug resistance</article-title>. <source>Nature</source>, <volume>546</volume>, <fpage>431</fpage>–<lpage>435</lpage>.<pub-id pub-id-type="pmid">28607484</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shalek</surname><given-names>A.K.</given-names></string-name>, <string-name><surname>Benson</surname><given-names>M.</given-names></string-name></person-group> (<year>2017</year>) 
<article-title>Single-cell analyses to tailor treatments</article-title>. <source>Sci. Transl. Med</source>., <volume>9</volume>, <fpage>eaan4730</fpage>.<pub-id pub-id-type="pmid">28931656</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sillanpaa</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2003</year>) 
<article-title>CD44 expression indicates favorable prognosis in epithelial ovarian cancer</article-title>. <source>Clin. Cancer Res</source>., <volume>9</volume>, <fpage>5318</fpage>–<lpage>5324</lpage>.<pub-id pub-id-type="pmid">14614016</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Spitzer</surname><given-names>M.H.</given-names></string-name>, <string-name><surname>Nolan</surname><given-names>G.P.</given-names></string-name></person-group> (<year>2016</year>) 
<article-title>Mass cytometry: single cells, many features</article-title>. <source>Cell</source>, <volume>165</volume>, <fpage>780</fpage>–<lpage>791</lpage>.<pub-id pub-id-type="pmid">27153492</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stuart</surname><given-names>T.</given-names></string-name>, <string-name><surname>Satija</surname><given-names>R.</given-names></string-name></person-group> (<year>2019</year>) 
<article-title>Integrative single-cell analysis</article-title>. <source>Nat. Rev. Genet</source>., <volume>20</volume>, <fpage>257</fpage>–<lpage>272</lpage>.<pub-id pub-id-type="pmid">30696980</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tasic</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) 
<article-title>Shared and distinct transcriptomic cell types across neocortical areas</article-title>. <source>Nature</source>, <volume>563</volume>, <fpage>72</fpage>–<lpage>78</lpage>.<pub-id pub-id-type="pmid">30382198</pub-id></mixed-citation>
    </ref>
    <ref id="btaa637-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van der Maaten</surname><given-names>L.</given-names></string-name></person-group> (<year>2014</year>) 
<article-title>Accelerating t-SNE using tree-based algorithms</article-title>. <source>J. Mach. Learn. Res</source>., <volume>15</volume>, <fpage>3221</fpage>–<lpage>3245</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa637-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van der Maaten</surname><given-names>L.</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>G.</given-names></string-name></person-group> (<year>2008</year>) 
<article-title>Visualizing data using t-SNE</article-title>. <source>J. Mach. Learn. Res</source>., <volume>9</volume>, <fpage>2579</fpage>–<lpage>2605</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa637-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zappia</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) 
<article-title>Splatter: simulation of single-cell RNA sequencing data</article-title>. <source>Genome Biol</source>., <volume>18</volume>, <fpage>174</fpage>.<pub-id pub-id-type="pmid">28899397</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
