<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9358067</article-id>
    <article-id pub-id-type="publisher-id">4873</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-022-04873-x</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>TMbed: transmembrane proteins predicted through language model embeddings</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Bernhofer</surname>
          <given-names>Michael</given-names>
        </name>
        <address>
          <email>bernhoferm@rostlab.org</email>
          <uri>https://www.rostlab.org/</uri>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rost</surname>
          <given-names>Burkhard</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.6936.a</institution-id><institution-id institution-id-type="ISNI">0000000123222966</institution-id><institution>Department of Informatics, Bioinformatics and Computational Biology ‑ i12, Technical University of Munich (TUM), </institution></institution-wrap>Boltzmannstr. 3, 85748 Garching, Germany </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.6936.a</institution-id><institution-id institution-id-type="ISNI">0000000123222966</institution-id><institution>TUM Graduate School, Center of Doctoral Studies in Informatics and its Applications (CeDoSIA), </institution></institution-wrap>Boltzmannstr. 11, 85748 Garching, Germany </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.452925.d</institution-id><institution-id institution-id-type="ISNI">0000 0004 0562 3952</institution-id><institution>Institute for Advanced Study (TUM-IAS), </institution></institution-wrap>Lichtenbergstr. 2a, 85748 Garching, Germany </aff>
      <aff id="Aff4"><label>4</label>TUM School of Life Sciences Weihenstephan (TUM-WZW), Alte Akademie 8, Freising, Germany </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>8</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>8</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>326</elocation-id>
    <history>
      <date date-type="received">
        <day>12</day>
        <month>6</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>3</day>
        <month>8</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Despite the immense importance of transmembrane proteins (TMP) for molecular biology and medicine, experimental 3D structures for TMPs remain about 4–5 times underrepresented compared to non-TMPs. Today’s top methods such as AlphaFold2 accurately predict 3D structures for many TMPs, but annotating transmembrane regions remains a limiting step for proteome-wide predictions.
</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Here, we present TMbed, a novel method inputting embeddings from protein Language Models (pLMs, here ProtT5), to predict for each residue one of four classes: transmembrane helix (TMH), transmembrane strand (TMB), signal peptide, or other. TMbed completes predictions for entire proteomes within hours on a single consumer-grade desktop machine at performance levels similar or better than methods, which are using evolutionary information from multiple sequence alignments (MSAs) of protein families. On the per-protein level, TMbed correctly identified 94 ± 8% of the beta barrel TMPs (53 of 57) and 98 ± 1% of the alpha helical TMPs (557 of 571) in a non-redundant data set, at false positive rates well below 1% (erred on 30 of 5654 non-membrane proteins). On the per-segment level, TMbed correctly placed, on average, 9 of 10 transmembrane segments within five residues of the experimental observation. Our method can handle sequences of up to 4200 residues on standard graphics cards used in desktop PCs (e.g., NVIDIA GeForce RTX 3060).</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">Based on embeddings from pLMs and two novel filters (Gaussian and Viterbi), TMbed predicts alpha helical and beta barrel TMPs at least as accurately as any other method but at lower false positive rates. Given the few false positives and its outstanding speed, TMbed might be ideal to sieve through millions of 3D structures soon to be predicted, e.g., by AlphaFold2.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12859-022-04873-x.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Protein language models</kwd>
      <kwd>Protein structure prediction</kwd>
      <kwd>Transmembrane protein prediction</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Technische Universität München (1025)</institution>
        </funding-source>
      </award-group>
      <open-access>
        <p>Open Access funding enabled and organized by Projekt DEAL.</p>
      </open-access>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <sec id="Sec2">
      <title>Structural knowledge of TMPs 4–5 fold underrepresented</title>
      <p id="Par17">Transmembrane proteins (TMP) account for 20–30% of all proteins within any organism [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]; most TMPs cross the membrane with transmembrane helices (TMH). TMPs crossing with transmembrane beta strands (TMB), forming beta barrels, have been estimated to account for 1–2% of all proteins in Gram-negative bacteria; this variety is also present in mitochondria and chloroplasts [<xref ref-type="bibr" rid="CR3">3</xref>]. Membrane proteins facilitate many essential processes, including regulation, signaling, and transportation, rendering them targets for most known drugs [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR5">5</xref>]. Despite this immense relevance for molecular biology and medicine, only about 5% of all three-dimensional (3D) structures in the PDB [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>] constitute TMPs [<xref ref-type="bibr" rid="CR8">8</xref>–<xref ref-type="bibr" rid="CR10">10</xref>].</p>
    </sec>
    <sec id="Sec3">
      <title>Accurate 3D predictions available for proteomes need classification</title>
      <p id="Par18">The prediction of protein structure from sequence leaped in quality through AlphaFold2 [<xref ref-type="bibr" rid="CR11">11</xref>], Nature’s method of the year 2021 [<xref ref-type="bibr" rid="CR12">12</xref>]. Although AlphaFold2 appears to provide accurate predictions for only very few novel “folds”, it importantly increases the width of structural coverage [<xref ref-type="bibr" rid="CR13">13</xref>]. AlphaFold2 seems to work well on TMPs [<xref ref-type="bibr" rid="CR14">14</xref>], but for proteome-wide high-throughput studies, we still need to filter out membrane proteins from the structure predictions. Most state-of-the-art (SOTA) TMP prediction methods rely on evolutionary information in the form of multiple sequence alignments (MSA) to achieve their top performance. In our tests we included 13 such methods, namely BetAware-Deep [<xref ref-type="bibr" rid="CR15">15</xref>], BOCTOPUS2 [<xref ref-type="bibr" rid="CR16">16</xref>], CCTOP [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR18">18</xref>], HMM-TM [<xref ref-type="bibr" rid="CR19">19</xref>–<xref ref-type="bibr" rid="CR21">21</xref>], OCTOPUS [<xref ref-type="bibr" rid="CR22">22</xref>], Philius [<xref ref-type="bibr" rid="CR23">23</xref>], PolyPhobius [<xref ref-type="bibr" rid="CR24">24</xref>], PRED-TMBB2 [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR25">25</xref>], PROFtmb [<xref ref-type="bibr" rid="CR3">3</xref>], SCAMPI2 [<xref ref-type="bibr" rid="CR26">26</xref>], SPOCTOPUS [<xref ref-type="bibr" rid="CR27">27</xref>], TMSEG [<xref ref-type="bibr" rid="CR28">28</xref>], and TOPCONS2 [<xref ref-type="bibr" rid="CR29">29</xref>].</p>
    </sec>
    <sec id="Sec4">
      <title>pLMs capture crucial information without MSAs</title>
      <p id="Par19">Mimicking recent advances of Language Models (LM) in natural language processing (NLP), protein Language Models (pLMs) learn to reconstruct masked parts of protein sequences based on the unmasked local and global information [<xref ref-type="bibr" rid="CR30">30</xref>–<xref ref-type="bibr" rid="CR37">37</xref>]. Such pLMs, trained on billions of protein sequences, implicitly extract important information about protein structure and function, essentially capturing aspects of the “language of life” [<xref ref-type="bibr" rid="CR32">32</xref>]. These aspects can be extracted from the last layers of the deep learning networks into vectors, referred to as embeddings, and used as exclusive input to subsequent methods trained in supervised fashion to successfully predict aspects of protein structure and function [<xref ref-type="bibr" rid="CR30">30</xref>–<xref ref-type="bibr" rid="CR34">34</xref>, <xref ref-type="bibr" rid="CR36">36</xref>, <xref ref-type="bibr" rid="CR38">38</xref>–<xref ref-type="bibr" rid="CR43">43</xref>]. Often pLM-based methods outperform SOTA methods, which are using evolutionary information on top, and they usually require substantially fewer compute resources. Just before submitting this work, we became aware of another pLM-based TM-prediction method, namely DeepTMHMM [<xref ref-type="bibr" rid="CR44">44</xref>] using ESM-1b [<xref ref-type="bibr" rid="CR36">36</xref>] embeddings, and included it in our comparisons.</p>
      <p id="Par20">Here, we combined embeddings generated by the ProtT5 [<xref ref-type="bibr" rid="CR34">34</xref>] pLM with a simple convolutional neural network (CNN) to create a fast and highly accurate prediction method for alpha helical and beta barrel transmembrane proteins and their overall inside/outside topology. Our new method, TMbed, predicted the presence and location of any TMBs, TMHs, and signal peptides for all proteins of the human proteome within 46 min on our server machine (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1) at the same or better level of performance as other methods, which require substantially more time.</p>
    </sec>
  </sec>
  <sec id="Sec5">
    <title>Materials and methods</title>
    <sec id="Sec6">
      <title>Data set: membrane proteins (TMPs)</title>
      <p id="Par21">We collected all primary structure files for alpha helical and beta barrel transmembrane proteins (TMP) from OPM [<xref ref-type="bibr" rid="CR45">45</xref>] and mapped their PDB [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>] chain identifiers (PDB-id) to UniProtKB [<xref ref-type="bibr" rid="CR46">46</xref>] through SIFTS [<xref ref-type="bibr" rid="CR47">47</xref>, <xref ref-type="bibr" rid="CR48">48</xref>]. Toward this end, we discarded all chimeric chains, all models, and all chains for which OPM failed to map any transmembrane start or end position. This resulted in 2,053 and 206 sequence-unique PDB chains for alpha helical and beta barrel TMPs, respectively.</p>
      <p id="Par22">We used the ATOM coordinates inside the OPM files to assign the inside/outside orientation of sequence segments not within the membrane. We manually inspected inconsistent annotations (e.g., if both ends of a transmembrane segment had the same inside/outside orientation) and cross-referenced them with PDBTM [<xref ref-type="bibr" rid="CR49">49</xref>–<xref ref-type="bibr" rid="CR51">51</xref>], PDB, and UniProtKB. We then either corrected such inconsistent annotations or discarded the whole sequence. As OPM does not include signal peptide annotations, we compared our TMP data sets to the set used by SignalP 6.0 [<xref ref-type="bibr" rid="CR52">52</xref>] and all sequences in UniProtKB/Swiss-Prot with experimentally annotated signal peptides using CD-HIT [<xref ref-type="bibr" rid="CR53">53</xref>, <xref ref-type="bibr" rid="CR54">54</xref>]. For any matches with at least 95% global sequence identity (PIDE), we transferred the signal peptide annotation onto our TMPs. We removed all sequences with fewer than 50 residues to avoid noise from incorrect sequencing fragments, and all sequences with over 15,000 residues to save energy (lower computational costs).</p>
      <p id="Par23">Finally, we removed redundant sequences from the two TMP data sets by clustering them with MMseqs2 [<xref ref-type="bibr" rid="CR55">55</xref>] to at most 20% local pairwise sequence identity (PIDE) with 40% minimum alignment coverage, i.e., no pair had more than 20% PIDE for any local alignment covering at least 40% of the shorter sequence. The final non-redundant TMP data sets contained 593 alpha helical TMPs and 65 beta barrel TMPs, respectively.</p>
    </sec>
    <sec id="Sec7">
      <title>Data set: globular non-membrane proteins</title>
      <p id="Par24">We used the SignalP 6.0 (SP6) dataset for our globular proteins. As the SP6 dataset contained only the first 70 residues of each protein, we took the full sequences from UniProtKB/Swiss-Prot and transferred the signal peptide annotations. To remove any potential membrane proteins from this non-TMP data set, we compared it with CD-HIT [<xref ref-type="bibr" rid="CR53">53</xref>, <xref ref-type="bibr" rid="CR54">54</xref>] against three other data sets: (1) our TMP data sets before redundancy reduction, (2) all protein sequences from UniProtKB/Swiss-Prot with any annotations of transmembrane segments, and (3) all proteins from UniProtKB/Swiss-Prot with any subcellular location annotations for membrane. We removed all proteins from our non-TMP data set with more than 60% global PIDE to any protein in sets 1–3. Again, we dropped all sequences with less than 50 or more than 15,000 residues and applied the same redundancy reduction as before (20% PIDE at 40% alignment coverage). The final non-redundant data set contained 5,859 globular, water-soluble non-TMP proteins; 698 of these have a signal peptide.</p>
    </sec>
    <sec id="Sec8">
      <title>Additional redundancy reduction</title>
      <p id="Par25">One anonymous reviewer spotted homologs in our data set after the application of the above protocol. To address this problem, we performed another iteration of redundancy reduction for each of the three data sets using CD-HIT at 20% PIDE. In order to save energy (i.e., avoid retraining our model), we decided to remove clashes for the evaluation, i.e., if two proteins shared more than 20% PIDE, we removed both from the data set (as TMbed was trained on both in the cross-validation protocol). Thereby, this second iteration removed 235 proteins: 8 beta barrel TMPs, 22 alpha helical TMPs, and 205 globular, non-membrane proteins. Our final test data sets included 57 beta barrel TMPs, 571 alpha helical TMPs, and 5654 globular, non-membrane proteins.</p>
    </sec>
    <sec id="Sec9">
      <title>Membrane re-entrant regions</title>
      <p id="Par26">Besides transmembrane segments that cross the entire membrane, there are also others, namely membrane segments that briefly enter and exit the membrane on the same side. These are referred to as re-entrant regions [<xref ref-type="bibr" rid="CR56">56</xref>, <xref ref-type="bibr" rid="CR57">57</xref>]. Although rare, some methods explicitly predict them [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR22">22</xref>, <xref ref-type="bibr" rid="CR27">27</xref>, <xref ref-type="bibr" rid="CR58">58</xref>]. However, as OPM does not explicitly annotate such regions and since our data set already had a substantial class imbalance between beta barrel TMPs, alpha helical TMPs and, globular proteins, we decided not to predict re-entrant regions.</p>
    </sec>
    <sec id="Sec10">
      <title>Embeddings</title>
      <p id="Par27">We generated embeddings with protein Language Models (pLMs) for our data sets using a transformer-based pLM ProtT5-XL-U50 (short: ProtT5) [<xref ref-type="bibr" rid="CR34">34</xref>]. We discarded the decoder part of ProtT5, keeping only the encoder for increased efficiency (note: encoder embeddings are more informative [<xref ref-type="bibr" rid="CR34">34</xref>]). The encoder model converts a protein sequence into an embedding matrix that represents each residue in the protein, i.e., each position in the sequence, by a 1024-dimensional vector containing global and local contextualized information. We converted the ProtT5 encoder from 32-bit to 16-bit floating-point format to reduce the memory footprint on the GPU. We took the pre-trained ProtT5 model as is without any further task-specific fine-tuning.</p>
      <p id="Par28">We chose ProtT5 over other embedding models, such as ESM-1b [<xref ref-type="bibr" rid="CR36">36</xref>], based on our experience with the model and comparisons during previous projects [<xref ref-type="bibr" rid="CR34">34</xref>, <xref ref-type="bibr" rid="CR38">38</xref>]. Furthermore, ProtT5 does not require splitting long sequences, which might remove valuable global context information, while ESM-1b can only handle sequences of up to 1022 residues.</p>
    </sec>
    <sec id="Sec11">
      <title>Model architecture</title>
      <p id="Par29">Our TMbed model architecture contained three modules (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S1): a convolutional neural network (CNN) to generate per-residue predictions, a Gaussian smoothing filter, and a Viterbi decoder to find the best class label for each residue. We implemented the model in PyTorch [<xref ref-type="bibr" rid="CR59">59</xref>].</p>
      <sec id="Sec12">
        <title>Module 1: CNN</title>
        <p id="Par30">The first component of TMbed is a CNN with four layers (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S1). The first layer is a pointwise convolution, i.e., a convolution with kernel size of 1, which reduces the ProtT5 embeddings for each residue (position in the sequence) from 1024 to 64 dimensions. Next, the model applies layer normalization [<xref ref-type="bibr" rid="CR60">60</xref>] along the sequence and feature dimensions, followed by a ReLU (Rectified Linear Unit) activation function to introduce non-linearity. The second and third layers consist of two parallel depthwise convolutions; both process the output of the first layer. As depthwise convolutions process each input dimension (feature) independently while considering consecutive residues, those two layers effectively generate sliding weighted sums for each dimension. The kernel sizes of the second and third layer are 9 and 21, respectively, corresponding to the average length of transmembrane beta strands and helices. As before, the model normalizes the output of both layers and applies the ReLU function. It then concatenates the output of all three layers, constructing a 192-dimensional feature vector for each residue (position in the sequence). The fourth layer is a pointwise convolution combining the outputs from the previous three layers and generates scores for each of the five classes: transmembrane beta strand (B), transmembrane helix (H), signal peptide (S), non-membrane inside (i), and non-membrane outside (o).</p>
      </sec>
      <sec id="Sec13">
        <title>Module 2: Gaussian filter</title>
        <p id="Par31">This module smooths the output from the CNN for adjacent residues (sequence positions) to reduce noisy predictions. The filter allows flattening isolated single-residue peaks. For instance, peaks extending of only one to three residues for the classes B and H are often non-informative; similarly short peaks for class S are unlikely correct. The filter uses a Gaussian distribution with standard deviation of 1 and a kernel size of 7, i.e., its seven weights correspond to three standard deviation intervals to the left and right, as well as the central peak. A softmax function then converts the filtered class scores to a class probability distribution.</p>
      </sec>
      <sec id="Sec14">
        <title>Module 3: Viterbi decoder</title>
        <p id="Par32">The Viterbi algorithm decodes the class probabilities and assigns a class label to each residue (position in the sequence; Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Note S3, Fig. S2). The algorithm uses no trainable parameter; it scores transitions according to the predicted class probabilities. Its purpose is to enforce a simple grammar such that (1) signal peptides can only start at the N-terminus (first residue in protein), (2) signal peptides and transmembrane segments must be at least five residues long (a reasonable trade-off between filtering out false positives and still capturing weak signals), and (3) the prediction for the inside/outside orientation has to change after each transmembrane segment (to simulate crossing through the membrane). Unlike the Gaussian filter, we did not apply the Viterbi decoder during training. This simplified backpropagation and sped up training.</p>
      </sec>
    </sec>
    <sec id="Sec15">
      <title>Training details</title>
      <p id="Par33">We performed a stratified five-fold nested cross-validation for model development (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S3). First, we separated our protein sequences into four groups: beta barrel TMPs, alpha helical TMPs with only a single helix, those with multiple helices, and non-membrane proteins. We further subdivided each group into proteins with and without signal peptides. Next, we randomly and evenly distributed all eight groups into five data sets. As all of our data sets were redundancy reduced, no two splits contained similar protein sequences for any of the classes. However, similarities between proteins of two different classes were allowed, not the least to provide more conservative performance estimates.</p>
      <p id="Par34">During development, we used four of the five splits to create the model and the fifth for testing (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S3). Of the first four splits, we used three to train the model and the fourth for validation (optimize hyperparameters). We repeated this 3–1 split three more times, each time using a different split for the validation set, and calculated the average performance for every hyperparameter configuration. Next, we trained a model with the best configuration on all four development splits and estimated its final performance on the independent test split. We performed this whole process a total of five times, each time using a different of the five splits as test data and the remaining four for the development data. This resulted in five final models; each trained, optimized, and tested on independent data sets.</p>
      <p id="Par35">We applied weight decay to all trained weights of the model and added a dropout layer right before the fourth convolutional layer, i.e., the output layer of the CNN. For every training sample (protein sequence), the dropout layer randomly sets 50% of the features to zero across the entire sequence, preventing the model from relying on only a specific subset of features for the prediction.</p>
      <p id="Par36">We trained all models for 15 epochs using the AdamW [<xref ref-type="bibr" rid="CR61">61</xref>] optimizer and cross-entropy loss. We set the beta parameters to 0.9 and 0.999, used a batch size of 16 sequences, and applied exponential learning rate decay by multiplying the learning rate with a factor of 0.8 every epoch. The initial learning rate and weight decay values were part of the hyperparameters optimized during cross-validation (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2).</p>
      <p id="Par37">The final TMbed model constitutes an ensemble over the five models obtained from the five outer cross-validation iterations (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S3), i.e., one for each training/test set combination. During runtime, each model generates its own class probabilities (CNN, plus Gaussian filter), which are then averaged and processed by the Viterbi decoder to generate the class labels.</p>
    </sec>
    <sec id="Sec16">
      <title>Evaluation and other methods</title>
      <p id="Par38">We evaluated the test performance of TMbed on a per-protein level and on a per-segment level (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Note S1). For protein level statistics, we calculated recall and false positive rate (FPR). We computed those statistics for three protein classes: alpha helical TMPs, beta barrel TMPs, and globular proteins.</p>
      <p id="Par39">We distinguished correct and incorrect segment predictions using two constraints: (1) the observed and predicted segment must overlap such that the intersection of the two is at least half of their union, and (2) neither the start nor the end positions may deviate by more than five residues between the observed and predicted segment (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S4). All segments predicted meeting both these criteria were considered as “correctly predicted segments”, all others as “incorrectly predicted segments”. This allowed for a reasonable margin of error regarding the position of a predicted segment, while punishing any gaps introduced into a segment. For per-segment statistics, we calculated recall and precision. We also computed the percentage of proteins with the correct number of predicted segments (Q<sub>num</sub>), the percentage of proteins for which all segments are correctly predicted (Q<sub>ok</sub>), and the percentage of correctly predicted segments that also have the correct orientation within the membrane (Q<sub>top</sub>). We considered only proteins that actually contain the corresponding type of segment when calculating per-segment statistics, e.g., only beta barrel TMPs for transmembrane beta strand segments.</p>
      <p id="Par40">We compared TMbed to other prediction methods for alpha helical and beta barrel TMPs (details in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Note S2): BetAware-Deep [<xref ref-type="bibr" rid="CR15">15</xref>], BOCTOPUS2 [<xref ref-type="bibr" rid="CR16">16</xref>], CCTOP [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR18">18</xref>], DeepTMHMM [<xref ref-type="bibr" rid="CR44">44</xref>], HMM-TM [<xref ref-type="bibr" rid="CR19">19</xref>–<xref ref-type="bibr" rid="CR21">21</xref>], OCTOPUS [<xref ref-type="bibr" rid="CR22">22</xref>], Philius [<xref ref-type="bibr" rid="CR23">23</xref>], PolyPhobius [<xref ref-type="bibr" rid="CR24">24</xref>], PRED-TMBB2 [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR25">25</xref>], PROFtmb [<xref ref-type="bibr" rid="CR3">3</xref>], SCAMPI2 [<xref ref-type="bibr" rid="CR26">26</xref>], SPOCTOPUS [<xref ref-type="bibr" rid="CR27">27</xref>], TMSEG [<xref ref-type="bibr" rid="CR28">28</xref>], and TOPCONS2 [<xref ref-type="bibr" rid="CR29">29</xref>]. We chose those methods based on their good prediction accuracy and public popularity. For methods predicting only either alpha helical or beta barrel TMPs, we considered the corresponding other type of TMPs as globular proteins for the per-protein statistics. In addition, we generated signal peptide predictions with SignalP 6.0 [<xref ref-type="bibr" rid="CR52">52</xref>]. The performance of older TMH prediction methods could be triangulated based on previous comprehensive estimate of such methods [<xref ref-type="bibr" rid="CR28">28</xref>, <xref ref-type="bibr" rid="CR62">62</xref>].</p>
      <p id="Par41">Unless stated otherwise, all reported performance values constitute the average performance over the five independent test sets during cross-validation (c.f. <italic>Training details</italic>) and their error margins reflect the 95% confidence interval (CI), i.e., 1.96 times the sample standard error over those five splits (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Tables S5, S6). We considered two values <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A$$\end{document}</tex-math><mml:math id="M2"><mml:mi>A</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4873_Article_IEq1.gif"/></alternatives></inline-formula> and <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$B$$\end{document}</tex-math><mml:math id="M4"><mml:mi>B</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4873_Article_IEq2.gif"/></alternatives></inline-formula> statistically significantly different if they differ by more than their composite 95% confidence interval:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left| {A - B} \right| &gt; CI_{c} = \sqrt {CI_{A}^{2} + CI_{B}^{2} }$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mrow><mml:mfenced close="|" open="|"><mml:mrow><mml:mi>A</mml:mi><mml:mo>-</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:mfenced><mml:mo>&gt;</mml:mo><mml:mi>C</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mi>C</mml:mi><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:math><graphic xlink:href="12859_2022_4873_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec17">
      <title>Additional out-of-distribution benchmark</title>
      <p id="Par42">In the most general sense, machine learning models learn and predict distributions. Most membrane data sets are small and created using the same resources, including OPM [<xref ref-type="bibr" rid="CR45">45</xref>], PDBTM [<xref ref-type="bibr" rid="CR49">49</xref>–<xref ref-type="bibr" rid="CR51">51</xref>], and UniProtKB/Swiss-Prot [<xref ref-type="bibr" rid="CR46">46</xref>] that often mix experimental annotations with sophisticated algorithms [<xref ref-type="bibr" rid="CR50">50</xref>, <xref ref-type="bibr" rid="CR63">63</xref>–<xref ref-type="bibr" rid="CR65">65</xref>] to determine the boundaries of transmembrane segments, e.g., by using the 3D structure. Given these constraints, we might expect data sets from different groups to render similar results. Analyzing the validity of this assumption, we included the data set assembled for the development of DeepTMHMM [<xref ref-type="bibr" rid="CR44">44</xref>]. Three reasons made us chose this set as an alternative perspective: (1) it is recent, (2) it contains helical and beta barrel TMPs, and (3) the authors made their cross-validation predictions available, simplifying comparisons.</p>
      <p id="Par43">We created two distinct data sets from the DeepTMHMM data. First, we collected all proteins common to both data sets (TMbed and DeepTMHMM). We used those proteins to estimate how much the annotations within both data sets agree with each other. In total, there were 1788 proteins common to both data sets: 43 beta barrel TMPs, 184 alpha helical TMPs, 1,560 globular proteins, and one protein (MSPA_MYCS2; Porin MspA) which sits in the outer-membrane of <italic>Mycobacterium smegmatis </italic>[<xref ref-type="bibr" rid="CR66">66</xref>]. We classified this as beta barrel TMP while DeepTMHMM listed it, most likely incorrectly, as a globular protein. The second data set that we created contained all proteins from the DeepTMHMM data set that were non-redundant to the training data of TMbed. We used PSI-BLAST [<xref ref-type="bibr" rid="CR67">67</xref>] to find all significant (e-value &lt; 10<sup>–4</sup>) local alignments with a 20% PIDE threshold and 40% alignment coverage to remove the redundant sequences. This second data set contained 667 proteins: 14 beta barrel TMPs, 86 alpha helical TMPs, and 567 globular proteins. We generated predictions with TMbed for those proteins and compared them to the cross-validation predictions for DeepTMHMM, as well as the best performing methods from our own benchmark (CCTOP [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR18">18</xref>], TOPCONS2 [<xref ref-type="bibr" rid="CR29">29</xref>], BOCTOPUS2 [<xref ref-type="bibr" rid="CR16">16</xref>]); we used the DeepTMHMM data set annotations as ground truth.</p>
    </sec>
    <sec id="Sec18">
      <title>Data set of new membrane proteins</title>
      <p id="Par44">In order to perform a CASP-like performance evaluation, we gathered all PDB structures published since Feb 05, 2022, which is just after the data for our set and that of DeepTMHMM [<xref ref-type="bibr" rid="CR44">44</xref>] have been collected. This comprised 1,511 PDB structures (more than 250 of which related to the SARS-CoV-2 protein P0DTD1) that we could map to 1,078 different UniProtKB sequences. We then used PSI-BLAST to remove all sequences similar to our data set or that of DeepTMHMM (e-value &lt; 10<sup>–4</sup>, 20% PIDE at 40% coverage), which resulted in 333 proteins. Next, we predicted transmembrane segments within those proteins using TMbed and DeepTMHMM. For 38 proteins, either TMbed or DeepTMHMM predicted transmembrane segments. After removing any sequences shorter than 100 residues (i.e., fragments) and those in which the predicted segments were not within the resolved regions of the PDB structure, we were left with a set of 5 proteins: one beta barrel TMP and four alpha helical TMPs. Finally, we used the PPM [<xref ref-type="bibr" rid="CR63">63</xref>–<xref ref-type="bibr" rid="CR65">65</xref>] algorithm from OPM [<xref ref-type="bibr" rid="CR45">45</xref>] to estimate the actual membrane boundaries.</p>
    </sec>
  </sec>
  <sec id="Sec19">
    <title>Results and discussion</title>
    <p id="Par45">We have developed a new machine learning model, dubbed TMbed; it exclusively uses embeddings from the ProtT5 [<xref ref-type="bibr" rid="CR34">34</xref>] pLM as input to predict for each residue in a protein sequence to which of the following four “classes” it belongs: transmembrane beta strand (TMB), transmembrane helix (TMH), signal peptide (SP), or non-transmembrane segment. It also predicts the inside/outside orientation of TMBs and TMHs within the membrane, indicating which parts of a protein are inside or outside a cell or compartment. Although the prediction of signal peptides was primarily integrated to improve TMH predictions by preventing the confusion of TMHs with SPs and vice versa, we also evaluated and compared the performance for SP prediction of TMbed to that of other methods.</p>
    <sec id="Sec20">
      <title>Reaching SOTA in protein sorting</title>
      <p id="Par46">TMbed detected TMPs with TMHs and TMBs at levels similar or numerically above the best state-of-the-art (SOTA) methods that use evolutionary information from multiple sequence alignments (MSA; Table <xref rid="Tab1" ref-type="table">1</xref>: Recall). Compared to MSA-based methods, TMbed achieved this parity or improvement at a significantly lower false positive rate (FPR), tied only with DeepTMHMM [<xref ref-type="bibr" rid="CR44">44</xref>], another embedding-based method (Table <xref rid="Tab1" ref-type="table">1</xref>: FPR). Given those numbers, we expect TMbed to misclassify only about 215 proteins for a proteome with 20,000 proteins (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S10), e.g., the human proteome, while the other methods would make hundreds more mistakes (DeepTMHMM: 331, TOPCONS2: 683, BOCTOPUS2: 880). Such low FPRs suggest our method as an automated high-throughput filter for TMP detection, e.g., for the creation and annotation of databases, or the decision which AlphaFold2 [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR68">68</xref>] predictions to parse through advanced software annotating transmembrane regions in 3D structures or predictions [<xref ref-type="bibr" rid="CR45">45</xref>, <xref ref-type="bibr" rid="CR49">49</xref>, <xref ref-type="bibr" rid="CR69">69</xref>]. In the binary prediction of whether or not a protein has a signal peptide, TMbed achieved similar levels as the specialist SignalP 6.0 [<xref ref-type="bibr" rid="CR52">52</xref>] and as DeepTMHMM [<xref ref-type="bibr" rid="CR44">44</xref>], reaching 99% recall at 0.1% FPR (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S3).<table-wrap id="Tab1"><label>Table 1</label><caption><p>Per-protein performance. *</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2"/><th align="left" colspan="2">β-TMP (57)</th><th align="left" colspan="2">α-TMP (571)</th><th align="left" colspan="2">Globular (5654)</th></tr><tr><th align="left">Recall (%)</th><th align="left">FPR (%)</th><th align="left">Recall (%)</th><th align="left">FPR (%)</th><th align="left">Recall (%)</th><th align="left">FPR (%)</th></tr></thead><tbody><tr><td align="left">TMbed</td><td char="." align="char"><bold>93.8 ± 7.5</bold></td><td char="." align="char"><bold><italic>0.1</italic></bold><bold> ± </bold><bold><italic>0.1</italic></bold></td><td char="." align="char"><bold>97.5 ± 0.7</bold></td><td char="." align="char"><bold><italic>0.5</italic></bold><bold> ± </bold><bold><italic>0.2</italic></bold></td><td char="." align="char"><bold><italic>99.5</italic></bold><bold> ± </bold><bold><italic>0.2</italic></bold></td><td char="." align="char">2.8 ± 1.2</td></tr><tr><td align="left">DeepTMHMM</td><td char="." align="char">77.9 ± 12.7</td><td char="." align="char"><bold><italic>0.1</italic></bold><bold> ± </bold><bold><italic>0.1</italic></bold></td><td char="." align="char">95.8 ± 1.3</td><td char="." align="char"><bold><italic>0.5</italic></bold><bold> ± </bold><bold><italic>0.2</italic></bold></td><td char="." align="char"><bold><italic>99.5</italic></bold><bold> ± </bold><bold><italic>0.2</italic></bold></td><td char="." align="char">5.9 ± 2.2</td></tr><tr><td align="left">TMSEG</td><td char="." align="char">–</td><td char="." align="char">–</td><td char="." align="char">96.5 ± 1.0</td><td char="." align="char">2.3 ± 0.3</td><td char="." align="char">97.7 ± 0.3</td><td char="." align="char">3.5 ± 1.0</td></tr><tr><td align="left">TOPCONS2<sup>1</sup></td><td char="." align="char">–</td><td char="." align="char">–</td><td char="." align="char">94.2 ± 1.3</td><td char="." align="char">2.6 ± 0.3</td><td char="." align="char">97.4 ± 0.3</td><td char="." align="char">5.8 ± 1.3</td></tr><tr><td align="left">OCTOPUS<sup>1</sup></td><td char="." align="char">–</td><td char="." align="char">–</td><td char="." align="char">94.2 ± 1.9</td><td char="." align="char">9.1 ± 0.7</td><td char="." align="char">90.9 ± 0.7</td><td char="." align="char">5.8 ± 1.9</td></tr><tr><td align="left">Philius<sup>1</sup></td><td char="." align="char">–</td><td char="." align="char">–</td><td char="." align="char">92.5 ± 1.4</td><td char="." align="char">2.6 ± 0.2</td><td char="." align="char">97.4 ± 0.2</td><td char="." align="char">7.5 ± 1.4</td></tr><tr><td align="left">PolyPhobius<sup>1</sup></td><td char="." align="char">–</td><td char="." align="char">–</td><td char="." align="char">97.2 ± 1.1</td><td char="." align="char">5.3 ± 0.4</td><td char="." align="char">94.7 ± 0.4</td><td char="." align="char">2.8 ± 1.1</td></tr><tr><td align="left">SPOCTOPUS<sup>1</sup></td><td char="." align="char">–</td><td char="." align="char">–</td><td char="." align="char"><bold>97.5 ± 1.6</bold></td><td char="." align="char">17.2 ± 0.8</td><td char="." align="char">82.8 ± 0.8</td><td char="." align="char"><bold>2.5 ± 1.6</bold></td></tr><tr><td align="left">SCAMPI2 (MSA)</td><td char="." align="char">–</td><td char="." align="char">–</td><td char="." align="char">94.2 ± 1.6</td><td char="." align="char">5.6 ± 0.3</td><td char="." align="char">94.4 ± 0.3</td><td char="." align="char">5.8 ± 1.6</td></tr><tr><td align="left">CCTOP<sup>2</sup></td><td char="." align="char"/><td char="." align="char"/><td char="." align="char">96.1 ± 2.1</td><td char="." align="char">3.7 ± 0.6</td><td char="." align="char">96.3 ± 0.6</td><td char="." align="char">3.9 ± 2.1</td></tr><tr><td align="left">HMM-TM (MSA)<sup>3</sup></td><td char="." align="char">–</td><td char="." align="char">–</td><td char="." align="char">97.3 ± 1.6</td><td char="." align="char">21.4 ± 0.5</td><td char="." align="char">78.6 ± 0.5</td><td char="." align="char">2.7 ± 1.6</td></tr><tr><td align="left">BOCTOPUS2</td><td char="." align="char">84.0 ± 13.3</td><td char="." align="char">4.2 ± 0.5</td><td char="." align="char">–</td><td char="." align="char">–</td><td char="." align="char">95.8 ± 0.5</td><td char="." align="char">16.0 ± 13.3</td></tr><tr><td align="left">BetAware-Deep</td><td char="." align="char">85.1 ± 9.3</td><td char="." align="char">4.7 ± 0.3</td><td char="." align="char">–</td><td char="." align="char">–</td><td char="." align="char">95.3 ± 0.3</td><td char="." align="char">14.9 ± 9.3</td></tr><tr><td align="left">PRED-TMBB2<sup>4</sup></td><td char="." align="char">88.8 ± 12.1</td><td char="." align="char">7.1 ± 0.4</td><td char="." align="char">–</td><td char="." align="char">–</td><td char="." align="char">92.9 ± 0.4</td><td char="." align="char">11.2 ± 12.1</td></tr><tr><td align="left">PROFtmb</td><td char="." align="char">91.9 ± 9.0</td><td char="." align="char">6.1 ± 0.5</td><td char="." align="char">–</td><td char="." align="char">–</td><td char="." align="char">93.9 ± 0.5</td><td char="." align="char">8.1 ± 9.0</td></tr></tbody></table><table-wrap-foot><p>*Evaluation of the ability to distinguish between 57 beta barrel TMPs (β-TMP), 571 alpha helical TMPs (α-TMP) and 5654 globular, water-soluble non-TMP proteins in our data set. Recall and false positive rate (FPR) were averaged over the five independent cross-validation test sets; error margins given for the 95% confidence interval (1.96*standard error); bold: best values for each column; italics: differences statistically significant with over 95% confidence (only computed between best and 2nd best, or all methods ranked 1 and those ranked lower)</p><p><sup>1</sup>Evaluation missing for one of 5,654 globular proteins</p><p><sup>2</sup>Evaluation missing for one of 571 α-TMPs and six of 5,654 globular proteins</p><p><sup>3</sup>Evaluation includes only 51 β-TMPs, 552 α-TMPs, and 5,524 globular proteins due to runtime errors</p><p><sup>4</sup>The local PRED-TMBB2 version did not include the pre-filtering step of the web server. This caused a FPR for β-TMP of almost 78%. Thus, we listed the statistics for the web server predictions, which did not include MSA input</p></table-wrap-foot></table-wrap></p>
      <p id="Par47">Many of the beta barrel TMPs that prediction methods missed had only two or four transmembrane beta strands (TMB). Such proteins cannot form a pore on their own, instead they have to form complexes with other proteins to function as TMPs, either by binding to other proteins or by forming multimers with additional copies of the same proteins by, e.g., trimerization. In fact, all four beta barrel TMPs missed by TMbed fell into this category. Thus, as all other methods, TMbed performed, on average, worse for beta barrel TMPs that cannot form pores alone. This appeared unsurprising, as the input to all methods were single proteins. For TMPs with TMHs, we also observed lower performance in the distinction between TMP/other for TMPs with a single TMH (recall: 93 ± 3%) compared to those with multiple TMHs (recall: 99 ± 1%). However, TMPs with single helices can function alone.</p>
      <p id="Par48">The embedding-based methods TMbed (introduced here using ProtT5 [<xref ref-type="bibr" rid="CR34">34</xref>]) and DeepTMHMM [<xref ref-type="bibr" rid="CR44">44</xref>] (based on ESM-1b [<xref ref-type="bibr" rid="CR36">36</xref>]) performed at least on par with the SOTA using evolutionary information from MSA (Table <xref rid="Tab1" ref-type="table">1</xref>). While this was already impressive, the real advantage was in the speed. For instance, our method, TMbed, predicted all 6,517 proteins in our data set in about 13 min (i.e., about eight sequences per second) on our server machine (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1); this runtime included generating the ProtT5 embeddings. The other embedding-based method, DeepTMHMM, needed about twice as long (23 min). Meanwhile, methods that search databases and generate MSAs usually take several seconds or minutes for a single protein sequence [<xref ref-type="bibr" rid="CR70">70</xref>], or require significant amounts of computing resources (e.g., often more than 100 GB of memory) to achieve comparable runtimes [<xref ref-type="bibr" rid="CR55">55</xref>].</p>
    </sec>
    <sec id="Sec21">
      <title>Excellent transmembrane segment prediction performance</title>
      <p id="Par49">TMbed reached the highest performance for transmembrane segments amongst all methods evaluated (Tables <xref rid="Tab2" ref-type="table">2</xref>, <xref rid="Tab3" ref-type="table">3</xref>). With recall and precision values of 89 ± 1% for TMHs, it significantly outperformed the second best and only other embedding-based method, DeepTMHMM, (80 ± 2%, Table <xref rid="Tab2" ref-type="table">2</xref>). TMbed essentially predicted 62% of all transmembrane helical (TMH) TMPs completely correctly (Q<sub>ok</sub>, i.e., all TMHs within ± 5 residues of true annotation). DeepTMHMM reached second place with Q<sub>ok</sub> of 46 ± 4%. This difference between TMbed and DeepTMHMM was over twice that between DeepTMHMM and the two methods performing third best by this measure, CCTOP [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR18">18</xref>] and TOPCONS2 [<xref ref-type="bibr" rid="CR29">29</xref>], which are based on evolutionary information.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Per-segment performance for TMH (transmembrane helices). *</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2"/><th align="left" colspan="5">TMH (571/2936)</th></tr><tr><th align="left">Recall (%)</th><th align="left">Precision (%)</th><th align="left">Q<sub>ok</sub> (%)</th><th align="left">Q<sub>num</sub> (%)</th><th align="left">Q<sub>top</sub> (%)</th></tr></thead><tbody><tr><td align="left">TMbed</td><td char="." align="char"><bold><italic>88.7</italic></bold><bold> ± </bold><bold><italic>0.6</italic></bold></td><td char="." align="char"><bold><italic>88.7</italic></bold><bold> ± </bold><bold><italic>0.7</italic></bold></td><td char="." align="char"><bold><italic>62.4</italic></bold><bold> ± </bold><bold><italic>3.7</italic></bold></td><td char="." align="char"><bold>86.0 ± 2.3</bold></td><td char="." align="char"><bold>96.4 ± 2.7</bold></td></tr><tr><td align="left">DeepTMHMM</td><td char="." align="char">80.0 ± 2.4</td><td char="." align="char">80.5 ± 2.4</td><td char="." align="char">46.2 ± 4.8</td><td char="." align="char">85.7 ± 3.5</td><td char="." align="char">96.3 ± 2.2</td></tr><tr><td align="left">TMSEG</td><td char="." align="char">74.5 ± 2.4</td><td char="." align="char">77.1 ± 1.7</td><td char="." align="char">35.6 ± 2.4</td><td char="." align="char">69.9 ± 2.7</td><td char="." align="char">83.8 ± 4.7</td></tr><tr><td align="left">TOPCONS2</td><td char="." align="char">76.4 ± 1.5</td><td char="." align="char">78.4 ± 0.8</td><td char="." align="char">41.0 ± 3.1</td><td char="." align="char">74.4 ± 3.3</td><td char="." align="char">91.7 ± 3.1</td></tr><tr><td align="left">OCTOPUS</td><td char="." align="char">71.6 ± 1.5</td><td char="." align="char">75.7 ± 1.4</td><td char="." align="char">36.0 ± 2.8</td><td char="." align="char">67.6 ± 3.4</td><td char="." align="char">87.5 ± 3.1</td></tr><tr><td align="left">Philius</td><td char="." align="char">70.8 ± 2.2</td><td char="." align="char">73.7 ± 0.8</td><td char="." align="char">34.2 ± 3.7</td><td char="." align="char">66.9 ± 3.4</td><td char="." align="char">87.5 ± 2.9</td></tr><tr><td align="left">PolyPhobius</td><td char="." align="char">76.0 ± 2.1</td><td char="." align="char">76.4 ± 1.1</td><td char="." align="char">40.3 ± 3.5</td><td char="." align="char">74.5 ± 2.8</td><td char="." align="char">86.8 ± 2.7</td></tr><tr><td align="left">SPOCTOPUS</td><td char="." align="char">71.5 ± 1.2</td><td char="." align="char">75.8 ± 1.2</td><td char="." align="char">35.7 ± 3.3</td><td char="." align="char">67.4 ± 5.5</td><td char="." align="char">87.2 ± 3.4</td></tr><tr><td align="left">SCAMPI2 (MSA)</td><td char="." align="char">72.3 ± 2.7</td><td char="." align="char">74.1 ± 1.5</td><td char="." align="char">33.5 ± 3.0</td><td char="." align="char">72.2 ± 4.5</td><td char="." align="char">90.6 ± 3.5</td></tr><tr><td align="left">CCTOP<sup>1</sup></td><td char="." align="char">77.0 ± 1.7</td><td char="." align="char">79.4 ± 1.0</td><td char="." align="char">41.9 ± 3.6</td><td char="." align="char">82.6 ± 2.7</td><td char="." align="char">92.6 ± 2.6</td></tr><tr><td align="left">HMM-TM (MSA)<sup>2</sup></td><td char="." align="char">73.3 ± 1.7</td><td char="." align="char">72.5 ± 1.2</td><td char="." align="char">33.5 ± 1.4</td><td char="." align="char">72.1 ± 3.0</td><td char="." align="char">88.3 ± 4.2</td></tr></tbody></table><table-wrap-foot><p>*Segment performance for transmembrane helix (TMH) prediction based on 571 alpha helical TMPs (α-TMP) with a total of 2936 TMHs. Recall, Precision, Q<sub>ok</sub>, Q<sub>num</sub>, and Q<sub>top</sub> were averaged over the five independent cross-validation test sets; error margins given for the 95% confidence interval (1.96*standard error); bold: best values for each column; italics: differences statistically significant with over 95% confidence (only computed between best and 2nd best).</p><p><sup>1</sup>Evaluation missing for one of 571 α-TMPs.</p><p><sup>2</sup>Evaluation includes only 552 of the 571 α-TMPs due to runtime errors of the method.</p></table-wrap-foot></table-wrap><table-wrap id="Tab3"><label>Table 3</label><caption><p>Per-segment performance for TMB (transmembrane beta strands). *</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2"/><th align="left" colspan="5">TMB (57/768)</th></tr><tr><th align="left">Recall (%)</th><th align="left">Precision (%)</th><th align="left">Q<sub>ok</sub> (%)</th><th align="left">Q<sub>num</sub> (%)</th><th align="left">Q<sub>top</sub> (%)</th></tr></thead><tbody><tr><td align="left">TMbed</td><td char="." align="char"><bold>95.0 ± 4.3</bold></td><td char="." align="char"><bold><italic>99.2</italic></bold><bold> ± </bold><bold><italic>0.7</italic></bold></td><td char="." align="char"><bold><italic>80.5</italic></bold><bold> ± </bold><bold><italic>11.4</italic></bold></td><td char="." align="char"><bold>88.1 ± 6.9</bold></td><td char="." align="char"><bold>98.1 ± 3.8</bold></td></tr><tr><td align="left">DeepTMHMM</td><td char="." align="char">85.9 ± 6.6</td><td char="." align="char">92.5 ± 4.7</td><td char="." align="char">46.1 ± 7.6</td><td char="." align="char">74.3 ± 13.0</td><td char="." align="char">97.2 ± 4.4</td></tr><tr><td align="left">BOCTOPUS2</td><td char="." align="char">85.3 ± 9.2</td><td char="." align="char">96.6 ± 2.0</td><td char="." align="char">56.6 ± 18.9</td><td char="." align="char">71.2 ± 11.8</td><td char="." align="char">98.0 ± 2.0</td></tr><tr><td align="left">BetAware-Deep</td><td char="." align="char">67.1 ± 6.5</td><td char="." align="char">62.2 ± 11.4</td><td char="." align="char">8.7 ± 5.3</td><td char="." align="char">60.9 ± 14.1</td><td char="." align="char">95.7 ± 5.4</td></tr><tr><td align="left">PRED-TMBB2 (MSA)</td><td char="." align="char">85.4 ± 1.9</td><td char="." align="char">75.6 ± 4.8</td><td char="." align="char">18.4 ± 15.0</td><td char="." align="char">44.5 ± 26.7</td><td char="." align="char">95.9 ± 3.4</td></tr><tr><td align="left">PROFtmb</td><td char="." align="char">78.2 ± 10.1</td><td char="." align="char">78.0 ± 6.9</td><td char="." align="char">20.2 ± 12.8</td><td char="." align="char">46.6 ± 11.7</td><td char="." align="char">97.2 ± 1.0</td></tr></tbody></table><table-wrap-foot><p>*Segment performance for transmembrane beta strand (TMB) prediction based on 57 beta barrel TMPs (β-TMP) with a total of 768 TMBs. Recall, Precision, Q<sub>ok</sub>, Q<sub>num</sub>, and Q<sub>top</sub> were averaged over the five independent cross-validation test sets; error margins given for the 95% confidence interval (1.96*standard error); bold: best values for each column; italics: differences statistically significant with over 95% confidence (only computed between best and 2nd best)</p></table-wrap-foot></table-wrap></p>
      <p id="Par50">The results were largely similar for beta barrel TMPs (TMBs) with TMbed achieving the top performance by all measures: reaching 95% recall and an almost perfect 99% precision. The most pronounced difference was a 23 percentage points lead in Q<sub>ok</sub> with 80%, compared to BOCTOPUS2 [<xref ref-type="bibr" rid="CR16">16</xref>] with 57% in second place. Overall, TMbed predicted the correct number of transmembrane segments in 86–88% of TMPs and correctly oriented 98% of TMBs and 96% of TMHs. For signal peptides, TMbed performed on par with SignalP 6.0, reaching 93% recall and 95% precision (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S3). For this task, both methods appeared to be slightly outperformed by DeepTMHMM. However, none of those differences exceeded the 95% confidence interval, i.e., the numerically consistent differences were not statistically significant. On top, the signal peptide expert method SignalP 6.0 is the only of the three that distinguishes between different types of signal peptides.</p>
      <p id="Par51">As for the overall per-protein distinction between TMP and non-TMP, the per-segment recall and precision also slightly correlated with the number of transmembrane segments, i.e., the more TMHs or TMBs in a protein the higher the performance (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4). Again, as for the TMP/non-TMP distinction, beta barrel TMPs with only two or four TMBs differed most to those with eight or more.</p>
    </sec>
    <sec id="Sec22">
      <title>Gaussian filter and Viterbi decoder improve segment performance</title>
      <p id="Par52">TMbed introduced a Gaussian filter smoothing over some local peaks in the prediction and a Viterbi decoder implicitly enforcing some “grammar-like” rules (Materials &amp; Methods). We investigated the effect of these concepts by comparing the final TMbed architecture to three simpler alternatives: one variant used only the CNN, the other two variants combined the simple CNN with either the Gaussian filter or the Viterbi decoder, not both as TMbed. For the variants without the Gaussian filter, we retrained the CNN using the same hyperparameters but without the filter. Individually, both modules (filter and decoder) significantly improved precision and Q<sub>ok</sub> for both TMH and TMB, while recall remained largely unaffected (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S9). Clearly, either step already improved over just the CNN. However, which of the two was most important depended on the type of TMP: for TMH proteins Viterbi decoder mattered more, for TMB proteins the Gaussian filter. Both steps together performed best throughout without adding any significant overhead to the overall computational costs compared to the other components.</p>
    </sec>
    <sec id="Sec23">
      <title>Self-predictions reveal potential membrane proteins</title>
      <p id="Par53">We checked for potential overfitting of our model by predicting the complete data set with the final TMbed ensemble. This meant that four of the five models had seen each of those proteins during training. While the number of misclassified proteins went down, we found that there were still some false predictions, indicating that our models did not simply learn the training data by heart (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Tables S7, S8). In fact, upon closer inspection of the 11 false positive predictions (8 alpha helical and 3 beta barrel TMPs), those appear to be transmembrane proteins incorrectly classified as globular proteins in our data set due to missing annotations in UniProtKB/Swiss-Prot, rather than incorrect predictions. Two of them, P09489 and P40601, have automatic annotations for an autotransporter domain, which facilitates transport through the membrane. Further, we processed the predicted AlphaFold2 [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR68">68</xref>] structures of all 11 proteins using the PPM [<xref ref-type="bibr" rid="CR45">45</xref>] algorithm, which tries to embed 3D structures into a membrane bilayer. For eight of those, the predicted transmembrane segments correlated well with the predicted 3D structures and membrane boundaries (Fig. <xref rid="Fig1" ref-type="fig">1</xref>; Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S5). For the other three, the 3D structures and membrane boundaries still indicate transmembrane domains within those proteins, but the predicted transmembrane segments only cover parts of those domains (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S5, last row). Together, these predictions provided convincing evidence for considering all eleven proteins as TMPs.<fig id="Fig1"><label>Fig. 1</label><caption><p>Potential transmembrane proteins in the globular data set. AlphaFold2 [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR68">68</xref>] structure of extracellular serine protease (P09489) and Lipase 1 (P40601). Transmembrane segments (dark purple) predicted by TMbed correlate well with membrane boundaries (dotted lines: red = outside, blue = inside) predicted by the PPM [<xref ref-type="bibr" rid="CR45">45</xref>] web server. Images created using Mol* Viewer [<xref ref-type="bibr" rid="CR71">71</xref>]. Though our data set lists them as globular proteins, the predicted structures indicate transmembrane domains, which align with segments predicted by our method. The predicted domains overlap with autotransporter domains detected by the UniProtKB [<xref ref-type="bibr" rid="CR46">46</xref>] automatic annotation system. Transmembrane segment predictions were made with the final TMbed ensemble model</p></caption><graphic xlink:href="12859_2022_4873_Fig1_HTML" id="MO1"/></fig></p>
    </sec>
    <sec id="Sec24">
      <title>Predicting the human proteome in less than an hour</title>
      <p id="Par54">Given that our new method already outperformed the SOTA using evolutionary information from MSAs, the even more important advantage was speed. To estimate prediction throughput, we applied TMbed to all human proteins in 20,375 UniProtKB/Swiss-Prot (version: April 2022; excluding TITIN_HUMAN due to its extreme length of 34,350 residues). Overall, it took our server machine (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1) only 46 min to generate all embeddings and predictions (estimate for consumer-grade PC in the next section). TMbed identified 14 beta barrel TMPs and 4,953 alpha helical TMPs, matching previous estimates for alpha helical TMPs [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR28">28</xref>]. Two of the 14 TMBs appear to be false positives as TMbed predicted only a single TMB in each protein. The other 12 proteins are either part of the Gasdermin family (A to E), or associated with the mitochondrion, including three proteins for a voltage-dependent anion-selective channel and the TOM40 import receptor.</p>
      <p id="Par55">Further, we generated predictions for all proteins from UniProtKB/Swiss-Prot (version: May 2022), excluding sequences above 10,000 residues (20 proteins). Processing those 566,976 proteins took about 8.5 h on our server machine. TMbed predicted 1,702 beta barrel TMPs and 77,296 alpha helical TMPs (predictions available via our GitHub repository).</p>
    </sec>
    <sec id="Sec25">
      <title>Hardware requirements</title>
      <p id="Par56">Our model needs about 2.5 GB of memory on the GPU when in 16-bit format. The additional memory needed during inference grows with the square of sequence length due to the attention mechanism of the transformer architecture. On our consumer-grade desktop PC (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1), this translated to a maximum sequence length of about 4,200 residues without maxing out the 12 GB of GPU memory. This barred 76 (0.4%) of the 20,376 human proteins from analysis on a personal consumer-hardware solution (NVIDIA GeForce RTX 3060). The prediction (including embedding generation) for 99.6% of the human proteome (20,376 proteins) took about 57 min on our desktop PC. While it is possible to run the model on a CPU, instead of on a GPU, we do not recommend this due to over tenfold larger runtimes. More importantly, the current lack of support of 16-bit floating-point format on CPUs would imply doubling the memory footprint of the model and computations.</p>
    </sec>
    <sec id="Sec26">
      <title>Out-of-distribution performance</title>
      <p id="Par57">The two pLM-based methods DeepTMHMM [<xref ref-type="bibr" rid="CR44">44</xref>] and TMbed appeared to reach similar performance according to the additional out-of-distribution data set (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Tables S11, S12). While DeepTMHMM reached higher scores for beta barrel proteins (Q<sub>ok</sub> of 79 ± 22% vs. 64 ± 26%), these were not quite statistically significant. On the other hand, TMbed managed to outperform DeepTMHMM for alpha helical TMPs (Q<sub>ok</sub> of 53 ± 11% vs. 47 ± 10%), though again without statistical significance. Furthermore, TMbed performed on par with the OPM baseline (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S12), i.e., using the OPM annotations as predictions for the DeepTMHMM data set, implying that TMbed reached its theoretical performance limit on that data set. Surprisingly, TOPCONS2 and CCTOP both outperformed TMbed and DeepTMHMM with Q<sub>ok</sub> of 65 ± 10% and 64 ± 10% (both not statistically significant), respectively.</p>
      <p id="Par58">Taking a closer look at the length distribution for the transmembrane segments in the TMbed and DeepTMHMM data set annotations and predictions (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S6) revealed differences. First, while the TMB segments in both data sets averaged 9 residues in length, the DeepTMHMM distribution was slightly shifted toward shorter segments (left in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S6A) but with a wider spread towards longer segments (right in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S6A). Both of these features were mirrored in the distribution of predicted TMBs. In contrast, the TMH distributions for DeepTMHMM showed an unexpected peak for TMH with 21 residues (both in the annotations used to train DeepTMHMM and in the predictions). In fact, the peak for annotated TMHs at 21 was more than double the value of the two closest length-bins (TMH = 20|22) combined. As the lipid bilayer remains largely invisible in X-ray structures, the exact begin and ends of TMHs may have some errors [<xref ref-type="bibr" rid="CR28">28</xref>, <xref ref-type="bibr" rid="CR45">45</xref>, <xref ref-type="bibr" rid="CR49">49</xref>–<xref ref-type="bibr" rid="CR51">51</xref>, <xref ref-type="bibr" rid="CR62">62</xref>]. Thus, when plotting the distribution of TMH length, we expected some kind of normal distribution with a peak around 20-odd residues with more points for longer than for shorter TMHs [<xref ref-type="bibr" rid="CR72">72</xref>]. In stark contrast to this expectation, the distribution observed for the TMHs used to develop DeepTMHMM appeared to have been obtained through some very different protocol (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S6B).</p>
      <p id="Par59">In contrast, the distributions for the annotations from OMP and the predictions from TMbed appeared to be more normally distributed with TMH lengths exhibiting a slight peak at 22 residues. The larger the AI model, the more it succeeds in reproducing features of the development set even when those might be based on less experimentally supported aspects. The DeepTMHMM model reproduced the dubious experimental distribution of TMHs exceedingly (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S6B, e.g., orange line and bars around peak at 16). Although we do not know the origin of this bias in the DeepTMHMM data set, we have seen similar bias in some prediction methods and automated annotations in UniProtKB/Swiss-Prot. In fact, a quick investigation showed that for 80 of the 184 common alpha helical TMPs the DeepTMHMM annotations matched those found in UniProtKB but not the OPM annotation in our TMbed data set. Of those annotations, 66% (303 of 459) were 21-residues long TMHs, accounting for 73% of all such segments; the other 104 TMPs contained only 19% (114 of 593) TMHs of length 21. This led us to believe that the DeepTMHMM data set contained, in part, length-biased annotations found in UniProtKB. Other examples of methods with length biases include SCAMPI2 and TOPCONS2 that both predicted exclusively TMHs with 21 residues; OCTOPUS and SPOCTOPUS predicted only TMHs of length 15, 21, and 31 (with more than 90% of those being 21 residues). BOCTOPUS2 predicted only beta strands of length 8, 9, and 10, with about 80% of them being nine residues long.</p>
      <p id="Par60">Since TMHs are around 21 residues long, such bias is not necessarily relevant. However, it might point to why performance appears better against some data sets supported less by high-resolution experiments than by others.</p>
    </sec>
    <sec id="Sec27">
      <title>Performance on new membrane proteins</title>
      <p id="Par61">Although, the small data set size did not allow for statistically significant results (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S13), TMbed performed numerically better than the other methods; in particular, BOCTOPUS2 failed to predict the only beta barrel TMP. While TMbed and DeepTMHMM both missed two of the 30 transmembrane beta strands, TMbed placed the remaining ones, on average, more accurately (recall: 93% vs 87%; precision: 100% vs. 93%). All methods performed worse for the alpha helical TMPs than on the other two benchmark data set, though with a sample size of only four proteins (25 TMHs total), we cannot be sure if this is an effect of testing on novel membrane proteins or simply by chance. Nevertheless, the transmembrane segments predicted by TMbed fit quite well to the membrane boundaries estimated by the PPM [<xref ref-type="bibr" rid="CR63">63</xref>–<xref ref-type="bibr" rid="CR65">65</xref>] algorithm (Fig. <xref rid="Fig2" ref-type="fig">2</xref>).<fig id="Fig2"><label>Fig. 2</label><caption><p>New membrane proteins. PDB structures for probable flagellin 1 (Q9YAN8; 7TXI [<xref ref-type="bibr" rid="CR73">73</xref>]), protein-serine O-palmitoleoyltransferase porcupine (Q9H237; 7URD [<xref ref-type="bibr" rid="CR74">74</xref>]), choline transporter-like protein 1 (Q8WWI5; 7WWB [<xref ref-type="bibr" rid="CR75">75</xref>]), S-layer protein SlpA (Q9RRB6; 7ZGY [<xref ref-type="bibr" rid="CR76">76</xref>]), and membrane protein (P0DTC5; 8CTK [<xref ref-type="bibr" rid="CR77">77</xref>]). Transmembrane segments (dark purple) predicted by TMbed; membrane boundaries (dotted lines: red = outside, blue = inside) predicted by the PPM [<xref ref-type="bibr" rid="CR45">45</xref>] web server. Images created using Mol* Viewer [<xref ref-type="bibr" rid="CR71">71</xref>]</p></caption><graphic xlink:href="12859_2022_4873_Fig2_HTML" id="MO2"/></fig></p>
    </sec>
    <sec id="Sec28">
      <title>No data leakage through pLM</title>
      <p id="Par62">pLMs such as ProtT5 [<xref ref-type="bibr" rid="CR34">34</xref>] used by TMbed or ESM-1b [<xref ref-type="bibr" rid="CR36">36</xref>] used by DeepTMHMM are pre-trained on billions of protein sequences. Typically, these include all protein sequences known today. In particular, they include all membrane and non-membrane proteins used in this study. In fact, assuming that the TMPs of known structure account for about 2–5% [<xref ref-type="bibr" rid="CR78">78</xref>, <xref ref-type="bibr" rid="CR79">79</xref>] of all TMPs and that TMPs account for about 20–25% of all proteins, we assume pLMs have been trained on over 490 million TMPs that remain to be experimentally characterized. For the development of AI/ML solutions, it is crucial to establish that methods do not over-fit to existing data but that they will also work for new, unseen data. This implies that in the standard cross-validation process, it is important to not leak any data from development (training and validation used for hyperparameter optimization and model choice) to test set (used to assess performance). This implies the necessity for redundancy reduction. This also implies that the conditions for the test set are exactly the same as those that will be encountered in future predictions. For instance, if today’s experimental annotations were biased toward bacterial proteins, we might expect performance to be worse for eukaryotic proteins and vice versa.</p>
      <p id="Par63">Both TMbed introduced here and DeepTMHMM are based on the embeddings of pre-trained pLMs; both accomplish the TM-prediction through a subsequent step dubbed transfer learning, in which they use the pLM embeddings as input to train a new AI/ML model in supervised manner on some annotations about membrane segments. Could any data leak from the training of pLMs into the subsequent step of training the TM-prediction methods? Strictly speaking, if no experimental annotations are used, no annotations can leak: the pLMs used here never saw any annotation other than protein sequences.</p>
      <p id="Par64">Even when no annotations could have leaked because none were used for the pLM, should we still ascertain that the conditions for the test set and for the protein for which the method will be applied in the future are identical? We claim that we do not have to ascertain this. However, we cannot support any data for (nor against) this claim. To play devil’s advocate, let us assume we had to. The reality is that the vast majority of all predictions likely to be made over the next five years will be for proteins included in these pLMs. In other words, the conditions for future use-cases are exactly the same as those used in our assessment.</p>
    </sec>
  </sec>
  <sec id="Sec29">
    <title>Conclusions</title>
    <p id="Par65">TMbed predicts alpha helical (TMH) and beta barrel (TMB) transmembrane proteins (TMPs) with high accuracy (Table <xref rid="Tab1" ref-type="table">1</xref>), performing at least on par or even better than state-of-the-art (SOTA) methods, which depend on evolutionary information from multiple sequence alignments (MSA; Tables <xref rid="Tab1" ref-type="table">1</xref>, <xref rid="Tab2" ref-type="table">2</xref>, <xref rid="Tab3" ref-type="table">3</xref>). In contrast, TMbed exclusively inputs sequence embeddings from the protein language model (pLM) ProtT5. Our novel method shines, in particular, through its low false positive rate (FPR; Table <xref rid="Tab1" ref-type="table">1</xref>), incorrectly predicting fewer than 1% of globular proteins to be TMPs. TMbed also numerically outperformed all other tested methods in terms of correctly predicting transmembrane segments (on average, 9 out of 10 segments were correct; Tables <xref rid="Tab2" ref-type="table">2</xref>, <xref rid="Tab3" ref-type="table">3</xref>). Despite its top performance, the even more significant advantage of TMbed is speed: the high throughput rate of the ProtT5 [<xref ref-type="bibr" rid="CR34">34</xref>] encoder enables predictions for entire proteomes within an hour, given a suitable GPU (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1). On top, the method runs on consumer-grade GPUs as found in more recent gaming and desktop PCs. Thus, TMbed can be used as a proteome-scale filtering step to scan for transmembrane proteins. Validating the predicted segments with AlphaFold2 [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR68">68</xref>] structures and the PPM [<xref ref-type="bibr" rid="CR45">45</xref>] method could be combined into a fast pipeline to discover new membrane proteins, as we have demonstrated with a few proteins. Finally, we provide predictions for 566,976 proteins from UniProtKB/Swiss-Prot (version: May 2022) via our GitHub repository.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec30">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2022_4873_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1</bold>. Supporting Online Material (SOM) containing additional figures, tables and notes.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>CI</term>
        <def>
          <p id="Par4">Confidence interval</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par5">Convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>MSA</term>
        <def>
          <p id="Par6">Multiple sequence alignment</p>
        </def>
      </def-item>
      <def-item>
        <term>OPM</term>
        <def>
          <p id="Par7">Orientations of proteins in membranes database</p>
        </def>
      </def-item>
      <def-item>
        <term>PDB</term>
        <def>
          <p id="Par8">Protein data bank</p>
        </def>
      </def-item>
      <def-item>
        <term>PDBTM</term>
        <def>
          <p id="Par9">Protein data bank of transmembrane proteins</p>
        </def>
      </def-item>
      <def-item>
        <term>pLM</term>
        <def>
          <p id="Par10">Protein language model</p>
        </def>
      </def-item>
      <def-item>
        <term>SIFTS</term>
        <def>
          <p id="Par11">Structure integration with function, taxonomy and sequence</p>
        </def>
      </def-item>
      <def-item>
        <term>SOTA</term>
        <def>
          <p id="Par12">State-of-the-art</p>
        </def>
      </def-item>
      <def-item>
        <term>SP</term>
        <def>
          <p id="Par13">Signal peptide</p>
        </def>
      </def-item>
      <def-item>
        <term>TMB</term>
        <def>
          <p id="Par14">Transmembrane beta strand</p>
        </def>
      </def-item>
      <def-item>
        <term>TMH</term>
        <def>
          <p id="Par15">Transmembrane helix</p>
        </def>
      </def-item>
      <def-item>
        <term>TMP</term>
        <def>
          <p id="Par16">Transmembrane protein</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Thanks to Tim Karl and Inga Weise for their help with technical and administrative issues; to Tobias Olenyi, Michael Heinzinger, and Christian Dallago for thoughtful discussions, help with ProtT5, and help with the manuscript; to Konstantinos Tsirigos and Ioannis Tamposis for their support with setting up HMM-TM and PRED-TMBB2; to Pier Luigi Martelli for providing us with BetAware-Deep predictions. Thanks to all who deposit their experimental data in public databases, and to those who maintain them. Last but not least, we thank the reviewers for their constructive criticism, which helped to improve our manuscript.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>MB collected the data sets, developed and evaluated the TMbed model, and took the lead in writing the manuscript. BR supervised and guided the work, and co-wrote the manuscript. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Open Access funding enabled and organized by Projekt DEAL. The server machine to run the ProtT5 model was funded by Software Campus Funding (BMBF 01IS17049).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>Our code, method, and data sets are freely available in the GitHub repository, <ext-link ext-link-type="uri" xlink:href="https://github.com/BernhoferM/TMbed">https://github.com/BernhoferM/TMbed</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethical approval and consent to participate</title>
      <p id="Par66">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par67">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par68">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fagerberg</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Jonasson</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>von Heijne</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Uhlen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Berglund</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Prediction of the human membrane proteome</article-title>
        <source>Proteomics</source>
        <year>2010</year>
        <volume>10</volume>
        <issue>6</issue>
        <fpage>1141</fpage>
        <lpage>1149</lpage>
        <pub-id pub-id-type="doi">10.1002/pmic.200900258</pub-id>
        <?supplied-pmid 20175080?>
        <pub-id pub-id-type="pmid">20175080</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Comparing function and structure between entire proteomes</article-title>
        <source>Protein Sci</source>
        <year>2001</year>
        <volume>10</volume>
        <issue>10</issue>
        <fpage>1970</fpage>
        <lpage>1979</lpage>
        <pub-id pub-id-type="doi">10.1110/ps.10101</pub-id>
        <?supplied-pmid 11567088?>
        <pub-id pub-id-type="pmid">11567088</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bigelow</surname>
            <given-names>HR</given-names>
          </name>
          <name>
            <surname>Petrey</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Przybylski</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Predicting transmembrane beta-barrels in proteomes</article-title>
        <source>Nucleic Acids Res</source>
        <year>2004</year>
        <volume>32</volume>
        <issue>8</issue>
        <fpage>2566</fpage>
        <lpage>2577</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkh580</pub-id>
        <?supplied-pmid 15141026?>
        <pub-id pub-id-type="pmid">15141026</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Overington</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Al-Lazikani</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Hopkins</surname>
            <given-names>AL</given-names>
          </name>
        </person-group>
        <article-title>How many drug targets are there?</article-title>
        <source>Nat Rev Drug Discov</source>
        <year>2006</year>
        <volume>5</volume>
        <issue>12</issue>
        <fpage>993</fpage>
        <lpage>996</lpage>
        <pub-id pub-id-type="doi">10.1038/nrd2199</pub-id>
        <?supplied-pmid 17139284?>
        <pub-id pub-id-type="pmid">17139284</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>von Heijne</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>The membrane protein universe: what's out there and why bother?</article-title>
        <source>J Intern Med</source>
        <year>2007</year>
        <volume>261</volume>
        <issue>6</issue>
        <fpage>543</fpage>
        <lpage>557</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1365-2796.2007.01792.x</pub-id>
        <pub-id pub-id-type="pmid">17547710</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">ww PDBc. Protein Data Bank: the single global archive for 3D macromolecular structure data. Nucleic Acids Res. 2019;47(D1):D520–D8.</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Berman</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Henrick</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Nakamura</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Announcing the worldwide Protein Data Bank</article-title>
        <source>Nat Struct Biol</source>
        <year>2003</year>
        <volume>10</volume>
        <issue>12</issue>
        <fpage>980</fpage>
        <pub-id pub-id-type="doi">10.1038/nsb1203-980</pub-id>
        <?supplied-pmid 14634627?>
        <pub-id pub-id-type="pmid">14634627</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hendrickson</surname>
            <given-names>WA</given-names>
          </name>
        </person-group>
        <article-title>Atomic-level analysis of membrane-protein structure</article-title>
        <source>Nat Struct Mol Biol</source>
        <year>2016</year>
        <volume>23</volume>
        <issue>6</issue>
        <fpage>464</fpage>
        <lpage>467</lpage>
        <pub-id pub-id-type="doi">10.1038/nsmb.3215</pub-id>
        <?supplied-pmid 27273628?>
        <pub-id pub-id-type="pmid">27273628</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Varga</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Dobson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Remenyi</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Tusnady</surname>
            <given-names>GE</given-names>
          </name>
        </person-group>
        <article-title>TSTMP: target selection for structural genomics of human transmembrane proteins</article-title>
        <source>Nucleic Acids Res</source>
        <year>2017</year>
        <volume>45</volume>
        <issue>D1</issue>
        <fpage>D325</fpage>
        <lpage>D330</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw939</pub-id>
        <?supplied-pmid 27924015?>
        <pub-id pub-id-type="pmid">27924015</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Newport</surname>
            <given-names>TD</given-names>
          </name>
          <name>
            <surname>Sansom</surname>
            <given-names>MSP</given-names>
          </name>
          <name>
            <surname>Stansfeld</surname>
            <given-names>PJ</given-names>
          </name>
        </person-group>
        <article-title>The MemProtMD database: a resource for membrane-embedded protein structures and their lipid interactions</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <issue>D1</issue>
        <fpage>D390</fpage>
        <lpage>D397</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky1047</pub-id>
        <?supplied-pmid 30418645?>
        <pub-id pub-id-type="pmid">30418645</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jumper</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Evans</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Pritzel</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Green</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Figurnov</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ronneberger</surname>
            <given-names>O</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Highly accurate protein structure prediction with AlphaFold</article-title>
        <source>Nature</source>
        <year>2021</year>
        <volume>596</volume>
        <issue>7873</issue>
        <fpage>583</fpage>
        <lpage>589</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-021-03819-2</pub-id>
        <?supplied-pmid 34265844?>
        <pub-id pub-id-type="pmid">34265844</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Marx</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Method of the Year: protein structure prediction</article-title>
        <source>Nat Methods</source>
        <year>2022</year>
        <volume>19</volume>
        <issue>1</issue>
        <fpage>5</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-021-01359-1</pub-id>
        <?supplied-pmid 35017741?>
        <pub-id pub-id-type="pmid">35017741</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Bordin N, Sillitoe I, Nallapareddy V, Rauer C, Lam SD, Waman VP, et al. AlphaFold2 reveals commonalities and novelties in protein structure space for 21 model organisms. bioRxiv. 2022:2022.06.02.494367.</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hegedus</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Geisler</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lukacs</surname>
            <given-names>GL</given-names>
          </name>
          <name>
            <surname>Farkas</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Ins and outs of AlphaFold2 transmembrane protein structure predictions</article-title>
        <source>Cell Mol Life Sci</source>
        <year>2022</year>
        <volume>79</volume>
        <issue>1</issue>
        <fpage>73</fpage>
        <pub-id pub-id-type="doi">10.1007/s00018-021-04112-1</pub-id>
        <?supplied-pmid 35034173?>
        <pub-id pub-id-type="pmid">35034173</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Madeo</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Savojardo</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Martelli</surname>
            <given-names>PL</given-names>
          </name>
          <name>
            <surname>Casadio</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>BetAware-deep: an accurate web server for discrimination and topology prediction of prokaryotic transmembrane beta-barrel proteins</article-title>
        <source>J Mol Biol</source>
        <year>2021</year>
        <volume>433</volume>
        <issue>11</issue>
        <fpage>166729</fpage>
        <pub-id pub-id-type="doi">10.1016/j.jmb.2020.166729</pub-id>
        <?supplied-pmid 33972021?>
        <pub-id pub-id-type="pmid">33972021</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hayat</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Peters</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Shu</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Tsirigos</surname>
            <given-names>KD</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Inclusion of dyad-repeat pattern improves topology prediction of transmembrane beta-barrel proteins</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <issue>10</issue>
        <fpage>1571</fpage>
        <lpage>1573</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw025</pub-id>
        <?supplied-pmid 26794316?>
        <pub-id pub-id-type="pmid">26794316</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dobson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Remenyi</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Tusnady</surname>
            <given-names>GE</given-names>
          </name>
        </person-group>
        <article-title>The human transmembrane proteome</article-title>
        <source>Biol Direct</source>
        <year>2015</year>
        <volume>10</volume>
        <fpage>31</fpage>
        <pub-id pub-id-type="doi">10.1186/s13062-015-0061-x</pub-id>
        <?supplied-pmid 26018427?>
        <pub-id pub-id-type="pmid">26018427</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dobson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Remenyi</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Tusnady</surname>
            <given-names>GE</given-names>
          </name>
        </person-group>
        <article-title>CCTOP: a Consensus Constrained TOPology prediction web server</article-title>
        <source>Nucleic Acids Res</source>
        <year>2015</year>
        <volume>43</volume>
        <issue>W1</issue>
        <fpage>W408</fpage>
        <lpage>W412</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv451</pub-id>
        <?supplied-pmid 25943549?>
        <pub-id pub-id-type="pmid">25943549</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bagos</surname>
            <given-names>PG</given-names>
          </name>
          <name>
            <surname>Liakopoulos</surname>
            <given-names>TD</given-names>
          </name>
          <name>
            <surname>Hamodrakas</surname>
            <given-names>SJ</given-names>
          </name>
        </person-group>
        <article-title>Algorithms for incorporating prior topological information in HMMs: application to transmembrane proteins</article-title>
        <source>BMC Bioinform</source>
        <year>2006</year>
        <volume>7</volume>
        <fpage>189</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-7-189</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tamposis</surname>
            <given-names>IA</given-names>
          </name>
          <name>
            <surname>Sarantopoulou</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Theodoropoulou</surname>
            <given-names>MC</given-names>
          </name>
          <name>
            <surname>Stasi</surname>
            <given-names>EA</given-names>
          </name>
          <name>
            <surname>Kontou</surname>
            <given-names>PI</given-names>
          </name>
          <name>
            <surname>Tsirigos</surname>
            <given-names>KD</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Hidden neural networks for transmembrane protein topology prediction</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2021</year>
        <volume>19</volume>
        <fpage>6090</fpage>
        <lpage>6097</lpage>
        <pub-id pub-id-type="doi">10.1016/j.csbj.2021.11.006</pub-id>
        <?supplied-pmid 34849210?>
        <pub-id pub-id-type="pmid">34849210</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tamposis</surname>
            <given-names>IA</given-names>
          </name>
          <name>
            <surname>Theodoropoulou</surname>
            <given-names>MC</given-names>
          </name>
          <name>
            <surname>Tsirigos</surname>
            <given-names>KD</given-names>
          </name>
          <name>
            <surname>Bagos</surname>
            <given-names>PG</given-names>
          </name>
        </person-group>
        <article-title>Extending hidden Markov models to allow conditioning on previous observations</article-title>
        <source>J Bioinform Comput Biol</source>
        <year>2018</year>
        <volume>16</volume>
        <issue>5</issue>
        <fpage>1850019</fpage>
        <pub-id pub-id-type="doi">10.1142/S0219720018500191</pub-id>
        <?supplied-pmid 30353782?>
        <pub-id pub-id-type="pmid">30353782</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Viklund</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>OCTOPUS: improving topology prediction by two-track ANN-based preference scores and an extended topological grammar</article-title>
        <source>Bioinformatics</source>
        <year>2008</year>
        <volume>24</volume>
        <issue>15</issue>
        <fpage>1662</fpage>
        <lpage>1668</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btn221</pub-id>
        <?supplied-pmid 18474507?>
        <pub-id pub-id-type="pmid">18474507</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Reynolds</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Kall</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Riffle</surname>
            <given-names>ME</given-names>
          </name>
          <name>
            <surname>Bilmes</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Noble</surname>
            <given-names>WS</given-names>
          </name>
        </person-group>
        <article-title>Transmembrane topology and signal peptide prediction using dynamic bayesian networks</article-title>
        <source>PLoS Comput Biol</source>
        <year>2008</year>
        <volume>4</volume>
        <issue>11</issue>
        <fpage>e1000213</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1000213</pub-id>
        <?supplied-pmid 18989393?>
        <pub-id pub-id-type="pmid">18989393</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kall</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Krogh</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sonnhammer</surname>
            <given-names>EL</given-names>
          </name>
        </person-group>
        <article-title>An HMM posterior decoder for sequence feature prediction that includes homology information</article-title>
        <source>Bioinformatics</source>
        <year>2005</year>
        <volume>21</volume>
        <issue>Suppl 1</issue>
        <fpage>i251</fpage>
        <lpage>i257</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bti1014</pub-id>
        <?supplied-pmid 15961464?>
        <pub-id pub-id-type="pmid">15961464</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tsirigos</surname>
            <given-names>KD</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bagos</surname>
            <given-names>PG</given-names>
          </name>
        </person-group>
        <article-title>PRED-TMBB2: improved topology prediction and detection of beta-barrel outer membrane proteins</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <issue>17</issue>
        <fpage>i665</fpage>
        <lpage>i671</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw444</pub-id>
        <?supplied-pmid 27587687?>
        <pub-id pub-id-type="pmid">27587687</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peters</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Tsirigos</surname>
            <given-names>KD</given-names>
          </name>
          <name>
            <surname>Shu</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Improved topology prediction using the terminal hydrophobic helices rule</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <issue>8</issue>
        <fpage>1158</fpage>
        <lpage>1162</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btv709</pub-id>
        <?supplied-pmid 26644416?>
        <pub-id pub-id-type="pmid">26644416</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Viklund</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Bernsel</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Skwark</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>SPOCTOPUS: a combined predictor of signal peptides and membrane protein topology</article-title>
        <source>Bioinformatics</source>
        <year>2008</year>
        <volume>24</volume>
        <issue>24</issue>
        <fpage>2928</fpage>
        <lpage>2929</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btn550</pub-id>
        <?supplied-pmid 18945683?>
        <pub-id pub-id-type="pmid">18945683</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bernhofer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kloppmann</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Reeb</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>TMSEG: Novel prediction of transmembrane helices</article-title>
        <source>Proteins</source>
        <year>2016</year>
        <volume>84</volume>
        <issue>11</issue>
        <fpage>1706</fpage>
        <lpage>1716</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.25155</pub-id>
        <?supplied-pmid 27566436?>
        <pub-id pub-id-type="pmid">27566436</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tsirigos</surname>
            <given-names>KD</given-names>
          </name>
          <name>
            <surname>Peters</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Shu</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Kall</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>The TOPCONS web server for consensus prediction of membrane protein topology and signal peptides</article-title>
        <source>Nucleic Acids Res</source>
        <year>2015</year>
        <volume>43</volume>
        <issue>W1</issue>
        <fpage>W401</fpage>
        <lpage>W407</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv485</pub-id>
        <?supplied-pmid 25969446?>
        <pub-id pub-id-type="pmid">25969446</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Asgari</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Mofrad</surname>
            <given-names>MR</given-names>
          </name>
        </person-group>
        <article-title>Continuous distributed representation of biological sequences for deep proteomics and genomics</article-title>
        <source>PLoS ONE</source>
        <year>2015</year>
        <volume>10</volume>
        <issue>11</issue>
        <fpage>e0141287</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0141287</pub-id>
        <?supplied-pmid 26555596?>
        <pub-id pub-id-type="pmid">26555596</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alley</surname>
            <given-names>EC</given-names>
          </name>
          <name>
            <surname>Khimulya</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Biswas</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>AlQuraishi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Church</surname>
            <given-names>GM</given-names>
          </name>
        </person-group>
        <article-title>Unified rational protein engineering with sequence-based deep representation learning</article-title>
        <source>Nat Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <issue>12</issue>
        <fpage>1315</fpage>
        <lpage>1322</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-019-0598-1</pub-id>
        <?supplied-pmid 31636460?>
        <pub-id pub-id-type="pmid">31636460</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Heinzinger</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Elnaggar</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Dallago</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Nechaev</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Matthes</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Modeling aspects of the language of life through transfer-learning protein sequences</article-title>
        <source>BMC Bioinform</source>
        <year>2019</year>
        <volume>20</volume>
        <issue>1</issue>
        <fpage>723</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-019-3220-8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bepler</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Berger</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Learning the protein language: evolution, structure, and function</article-title>
        <source>Cell Syst</source>
        <year>2021</year>
        <volume>12</volume>
        <issue>6</issue>
        <fpage>654</fpage>
        <lpage>69 e3</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2021.05.017</pub-id>
        <?supplied-pmid 34139171?>
        <pub-id pub-id-type="pmid">34139171</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <mixed-citation publication-type="other">Elnaggar A, Heinzinger M, Dallago C, Rehawi G, Wang Y, Jones L, et al. ProtTrans: towards cracking the language of Lifes code through self-supervised deep learning and high performance computing. IEEE Trans Pattern Anal Mach Intell. 2021.</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ofer</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Brandes</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Linial</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>The language of proteins: NLP, machine learning &amp; protein sequences</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2021</year>
        <volume>19</volume>
        <fpage>1750</fpage>
        <lpage>1758</lpage>
        <pub-id pub-id-type="doi">10.1016/j.csbj.2021.03.022</pub-id>
        <?supplied-pmid 33897979?>
        <pub-id pub-id-type="pmid">33897979</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rives</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Meier</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sercu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Goyal</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2021</year>
        <volume>118</volume>
        <issue>15</issue>
        <fpage>e2016239118</fpage>
        <pub-id pub-id-type="doi">10.1073/pnas.2016239118</pub-id>
        <?supplied-pmid 33876751?>
        <pub-id pub-id-type="pmid">33876751</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Johnston</surname>
            <given-names>KE</given-names>
          </name>
          <name>
            <surname>Arnold</surname>
            <given-names>FH</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>KK</given-names>
          </name>
        </person-group>
        <article-title>Protein sequence design with deep generative models</article-title>
        <source>Curr Opin Chem Biol</source>
        <year>2021</year>
        <volume>65</volume>
        <fpage>18</fpage>
        <lpage>27</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cbpa.2021.04.004</pub-id>
        <?supplied-pmid 34051682?>
        <pub-id pub-id-type="pmid">34051682</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Marquet C, Heinzinger M, Olenyi T, Dallago C, Erckert K, Bernhofer M, et al. Embeddings from protein language models predict conservation and variant effects. Hum Genet. 2021.</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Littmann</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Heinzinger</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dallago</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Weissenow</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Protein embeddings and deep learning predict binding residues for various ligand classes</article-title>
        <source>Sci Rep</source>
        <year>2021</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>23916</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-021-03431-4</pub-id>
        <?supplied-pmid 34903827?>
        <pub-id pub-id-type="pmid">34903827</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Littmann</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Heinzinger</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dallago</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Olenyi</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Embeddings from deep learning transfer GO annotations beyond homology</article-title>
        <source>Sci Rep</source>
        <year>2021</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>1160</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-020-80786-0</pub-id>
        <?supplied-pmid 33441905?>
        <pub-id pub-id-type="pmid">33441905</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sledzieski</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Cowen</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Berger</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>D-SCRIPT translates genome to phenome with sequence-based, structure-aware, genome-scale predictions of protein-protein interactions</article-title>
        <source>Cell Syst</source>
        <year>2021</year>
        <volume>12</volume>
        <issue>10</issue>
        <fpage>969</fpage>
        <lpage>82 e6</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2021.08.010</pub-id>
        <?supplied-pmid 34536380?>
        <pub-id pub-id-type="pmid">34536380</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <mixed-citation publication-type="other">Heinzinger M, Littmann M, Sillitoe I, Bordin N, Orengo C, Rost B. Contrastive learning on protein embeddings enlightens midnight zone. bioRxiv. 2022:2021.11.14.468528.</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Weißenow K, Heinzinger M, Rost B. Protein language model embeddings for fast, accurate, alignment-free protein structure prediction. bioRxiv. 2021:2021.07.31.454572.</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <mixed-citation publication-type="other">Hallgren J, Tsirigos KD, Pedersen MD, Almagro Armenteros JJ, Marcatili P, Nielsen H, et al. DeepTMHMM predicts alpha and beta transmembrane proteins using deep neural networks. bioRxiv. 2022:2022.04.08.487609.</mixed-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lomize</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Pogozheva</surname>
            <given-names>ID</given-names>
          </name>
          <name>
            <surname>Joo</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Mosberg</surname>
            <given-names>HI</given-names>
          </name>
          <name>
            <surname>Lomize</surname>
            <given-names>AL</given-names>
          </name>
        </person-group>
        <article-title>OPM database and PPM web server: resources for positioning of proteins in membranes</article-title>
        <source>Nucleic Acids Res</source>
        <year>2012</year>
        <volume>40</volume>
        <issue>Database issue</issue>
        <fpage>D370</fpage>
        <lpage>D376</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkr703</pub-id>
        <?supplied-pmid 21890895?>
        <pub-id pub-id-type="pmid">21890895</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>UniProt</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>UniProt: the universal protein knowledgebase in 2021</article-title>
        <source>Nucleic Acids Res</source>
        <year>2021</year>
        <volume>49</volume>
        <issue>D1</issue>
        <fpage>D480</fpage>
        <lpage>D489</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkaa1100</pub-id>
        <pub-id pub-id-type="pmid">33237286</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dana</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Gutmanas</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tyagi</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Qi</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>O'Donovan</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Martin</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>SIFTS: updated Structure Integration with Function, Taxonomy and Sequences resource allows 40-fold increase in coverage of structure-based annotations for proteins</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <issue>D1</issue>
        <fpage>D482</fpage>
        <lpage>D489</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky1114</pub-id>
        <?supplied-pmid 30445541?>
        <pub-id pub-id-type="pmid">30445541</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Velankar</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Dana</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Jacobsen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>van Ginkel</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Gane</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>SIFTS: structure integration with function, taxonomy and sequences resource</article-title>
        <source>Nucleic Acids Res</source>
        <year>2013</year>
        <volume>41</volume>
        <issue>Database issue</issue>
        <fpage>D483</fpage>
        <lpage>D489</lpage>
        <?supplied-pmid 23203869?>
        <pub-id pub-id-type="pmid">23203869</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kozma</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Simon</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Tusnady</surname>
            <given-names>GE</given-names>
          </name>
        </person-group>
        <article-title>PDBTM: Protein Data Bank of transmembrane proteins after 8 years</article-title>
        <source>Nucleic Acids Res</source>
        <year>2013</year>
        <volume>41</volume>
        <issue>Database issue</issue>
        <fpage>D524</fpage>
        <lpage>D529</lpage>
        <?supplied-pmid 23203988?>
        <pub-id pub-id-type="pmid">23203988</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tusnady</surname>
            <given-names>GE</given-names>
          </name>
          <name>
            <surname>Dosztanyi</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Simon</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Transmembrane proteins in the Protein Data Bank: identification and classification</article-title>
        <source>Bioinformatics</source>
        <year>2004</year>
        <volume>20</volume>
        <issue>17</issue>
        <fpage>2964</fpage>
        <lpage>2972</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bth340</pub-id>
        <?supplied-pmid 15180935?>
        <pub-id pub-id-type="pmid">15180935</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tusnady</surname>
            <given-names>GE</given-names>
          </name>
          <name>
            <surname>Dosztanyi</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Simon</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>PDB_TM: selection and membrane localization of transmembrane proteins in the protein data bank</article-title>
        <source>Nucleic Acids Res</source>
        <year>2005</year>
        <volume>33</volume>
        <issue>Database issue</issue>
        <fpage>D275</fpage>
        <lpage>D278</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gki002</pub-id>
        <?supplied-pmid 15608195?>
        <pub-id pub-id-type="pmid">15608195</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <mixed-citation publication-type="other">Teufel F, Almagro Armenteros JJ, Johansen AR, Gislason MH, Pihl SI, Tsirigos KD, et al. SignalP 6.0 predicts all five types of signal peptides using protein language models. Nat Biotechnol. 2022.</mixed-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Niu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>CD-HIT: accelerated for clustering the next-generation sequencing data</article-title>
        <source>Bioinformatics</source>
        <year>2012</year>
        <volume>28</volume>
        <issue>23</issue>
        <fpage>3150</fpage>
        <lpage>3152</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bts565</pub-id>
        <?supplied-pmid 23060610?>
        <pub-id pub-id-type="pmid">23060610</pub-id>
      </element-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Godzik</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences</article-title>
        <source>Bioinformatics</source>
        <year>2006</year>
        <volume>22</volume>
        <issue>13</issue>
        <fpage>1658</fpage>
        <lpage>1659</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btl158</pub-id>
        <?supplied-pmid 16731699?>
        <pub-id pub-id-type="pmid">16731699</pub-id>
      </element-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mirdita</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Steinegger</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Soding</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>MMseqs2 desktop and local web server app for fast, interactive sequence searches</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <issue>16</issue>
        <fpage>2856</fpage>
        <lpage>2858</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty1057</pub-id>
        <?supplied-pmid 30615063?>
        <pub-id pub-id-type="pmid">30615063</pub-id>
      </element-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Papaloukas</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Granseth</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Viklund</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Estimating the length of transmembrane helices using Z-coordinate predictions</article-title>
        <source>Protein Sci</source>
        <year>2008</year>
        <volume>17</volume>
        <issue>2</issue>
        <fpage>271</fpage>
        <lpage>278</lpage>
        <pub-id pub-id-type="doi">10.1110/ps.073036108</pub-id>
        <?supplied-pmid 18096645?>
        <pub-id pub-id-type="pmid">18096645</pub-id>
      </element-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Granseth</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Viklund</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>ZPRED: predicting the distance to the membrane center for residues in alpha-helical membrane proteins</article-title>
        <source>Bioinformatics</source>
        <year>2006</year>
        <volume>22</volume>
        <issue>14</issue>
        <fpage>e191</fpage>
        <lpage>e196</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btl206</pub-id>
        <?supplied-pmid 16873471?>
        <pub-id pub-id-type="pmid">16873471</pub-id>
      </element-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nugent</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
        </person-group>
        <article-title>Transmembrane protein topology prediction using support vector machines</article-title>
        <source>BMC Bioinform</source>
        <year>2009</year>
        <volume>10</volume>
        <fpage>159</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-10-159</pub-id>
      </element-citation>
    </ref>
    <ref id="CR59">
      <label>59.</label>
      <mixed-citation publication-type="other">Paszke A, Gross S, Massa F, Lerer A, Bradbury J, Chanan G, et al. PyTorch: an imperative style, high-performance deep learning library. 2019.</mixed-citation>
    </ref>
    <ref id="CR60">
      <label>60.</label>
      <mixed-citation publication-type="other">Lei Ba J, Kiros JR, Hinton GE. Layer normalization, 2016 July 01, 2016: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1607.06450">arXiv:1607.06450</ext-link>. <ext-link ext-link-type="uri" xlink:href="https://ui.adsabs.harvard.edu/abs/2016arXiv160706450L">https://ui.adsabs.harvard.edu/abs/2016arXiv160706450L</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR61">
      <label>61.</label>
      <mixed-citation publication-type="other">Loshchilov I, Hutter F. Decoupled weight decay regularization 2017 November 01, 2017. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1711.05101">arXiv:1711.05101</ext-link>. <ext-link ext-link-type="uri" xlink:href="https://ui.adsabs.harvard.edu/abs/2017arXiv171105101L">https://ui.adsabs.harvard.edu/abs/2017arXiv171105101L</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR62">
      <label>62.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Reeb</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kloppmann</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Bernhofer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Evaluation of transmembrane helix predictions in 2014</article-title>
        <source>Proteins</source>
        <year>2015</year>
        <volume>83</volume>
        <issue>3</issue>
        <fpage>473</fpage>
        <lpage>484</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.24749</pub-id>
        <?supplied-pmid 25546441?>
        <pub-id pub-id-type="pmid">25546441</pub-id>
      </element-citation>
    </ref>
    <ref id="CR63">
      <label>63.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lomize</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Pogozheva</surname>
            <given-names>ID</given-names>
          </name>
          <name>
            <surname>Mosberg</surname>
            <given-names>HI</given-names>
          </name>
        </person-group>
        <article-title>Anisotropic solvent model of the lipid bilayer. 2. Energetics of insertion of small molecules, peptides, and proteins in membranes</article-title>
        <source>J Chem Inf Model</source>
        <year>2011</year>
        <volume>51</volume>
        <issue>4</issue>
        <fpage>930</fpage>
        <lpage>946</lpage>
        <pub-id pub-id-type="doi">10.1021/ci200020k</pub-id>
        <?supplied-pmid 21438606?>
        <pub-id pub-id-type="pmid">21438606</pub-id>
      </element-citation>
    </ref>
    <ref id="CR64">
      <label>64.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lomize</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Pogozheva</surname>
            <given-names>ID</given-names>
          </name>
          <name>
            <surname>Lomize</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Mosberg</surname>
            <given-names>HI</given-names>
          </name>
        </person-group>
        <article-title>Positioning of proteins in membranes: a computational approach</article-title>
        <source>Protein Sci</source>
        <year>2006</year>
        <volume>15</volume>
        <issue>6</issue>
        <fpage>1318</fpage>
        <lpage>1333</lpage>
        <pub-id pub-id-type="doi">10.1110/ps.062126106</pub-id>
        <?supplied-pmid 16731967?>
        <pub-id pub-id-type="pmid">16731967</pub-id>
      </element-citation>
    </ref>
    <ref id="CR65">
      <label>65.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lomize</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Todd</surname>
            <given-names>SC</given-names>
          </name>
          <name>
            <surname>Pogozheva</surname>
            <given-names>ID</given-names>
          </name>
        </person-group>
        <article-title>Spatial arrangement of proteins in planar and curved membranes by PPM 3.0</article-title>
        <source>Protein Sci</source>
        <year>2022</year>
        <volume>31</volume>
        <issue>1</issue>
        <fpage>209</fpage>
        <lpage>220</lpage>
        <pub-id pub-id-type="doi">10.1002/pro.4219</pub-id>
        <?supplied-pmid 34716622?>
        <pub-id pub-id-type="pmid">34716622</pub-id>
      </element-citation>
    </ref>
    <ref id="CR66">
      <label>66.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mahfoud</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sukumaran</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hulsmann</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Grieger</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Niederweis</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Topology of the porin MspA in the outer membrane of Mycobacterium smegmatis</article-title>
        <source>J Biol Chem</source>
        <year>2006</year>
        <volume>281</volume>
        <issue>9</issue>
        <fpage>5908</fpage>
        <lpage>5915</lpage>
        <pub-id pub-id-type="doi">10.1074/jbc.M511642200</pub-id>
        <?supplied-pmid 16352610?>
        <pub-id pub-id-type="pmid">16352610</pub-id>
      </element-citation>
    </ref>
    <ref id="CR67">
      <label>67.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Altschul</surname>
            <given-names>SF</given-names>
          </name>
          <name>
            <surname>Madden</surname>
            <given-names>TL</given-names>
          </name>
          <name>
            <surname>Schaffer</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>W</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>
        <source>Nucleic Acids Res</source>
        <year>1997</year>
        <volume>25</volume>
        <issue>17</issue>
        <fpage>3389</fpage>
        <lpage>3402</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/25.17.3389</pub-id>
        <?supplied-pmid 9254694?>
        <pub-id pub-id-type="pmid">9254694</pub-id>
      </element-citation>
    </ref>
    <ref id="CR68">
      <label>68.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Varadi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Anyango</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Deshpande</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Nair</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Natassia</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Yordanova</surname>
            <given-names>G</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>AlphaFold Protein Structure Database: massively expanding the structural coverage of protein-sequence space with high-accuracy models</article-title>
        <source>Nucleic Acids Res</source>
        <year>2022</year>
        <volume>50</volume>
        <issue>D1</issue>
        <fpage>D439</fpage>
        <lpage>D444</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkab1061</pub-id>
        <?supplied-pmid 34791371?>
        <pub-id pub-id-type="pmid">34791371</pub-id>
      </element-citation>
    </ref>
    <ref id="CR69">
      <label>69.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tunyasuvunakool</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Adler</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Green</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Zielinski</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zidek</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Highly accurate protein structure prediction for the human proteome</article-title>
        <source>Nature</source>
        <year>2021</year>
        <volume>596</volume>
        <issue>7873</issue>
        <fpage>590</fpage>
        <lpage>596</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-021-03828-1</pub-id>
        <?supplied-pmid 34293799?>
        <pub-id pub-id-type="pmid">34293799</pub-id>
      </element-citation>
    </ref>
    <ref id="CR70">
      <label>70.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bernhofer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dallago</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Karl</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Satagopam</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Heinzinger</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Littmann</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>PredictProtein—predicting protein structure and function for 29 years</article-title>
        <source>Nucleic Acids Res</source>
        <year>2021</year>
        <volume>49</volume>
        <issue>W1</issue>
        <fpage>W535</fpage>
        <lpage>W540</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkab354</pub-id>
        <?supplied-pmid 33999203?>
        <pub-id pub-id-type="pmid">33999203</pub-id>
      </element-citation>
    </ref>
    <ref id="CR71">
      <label>71.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sehnal</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Bittrich</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Deshpande</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Svobodova</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Berka</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Bazgier</surname>
            <given-names>V</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Mol* Viewer: modern web app for 3D visualization and analysis of large biomolecular structures</article-title>
        <source>Nucleic Acids Res</source>
        <year>2021</year>
        <volume>49</volume>
        <issue>W1</issue>
        <fpage>W431</fpage>
        <lpage>W437</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkab314</pub-id>
        <?supplied-pmid 33956157?>
        <pub-id pub-id-type="pmid">33956157</pub-id>
      </element-citation>
    </ref>
    <ref id="CR72">
      <label>72.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kauko</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hedin</surname>
            <given-names>LE</given-names>
          </name>
          <name>
            <surname>Thebaud</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Cristobal</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>von Heijne</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Repositioning of transmembrane alpha-helices during membrane protein folding</article-title>
        <source>J Mol Biol</source>
        <year>2010</year>
        <volume>397</volume>
        <issue>1</issue>
        <fpage>190</fpage>
        <lpage>201</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmb.2010.01.042</pub-id>
        <?supplied-pmid 20109468?>
        <pub-id pub-id-type="pmid">20109468</pub-id>
      </element-citation>
    </ref>
    <ref id="CR73">
      <label>73.</label>
      <mixed-citation publication-type="other">Wang F, Cvirkaite-Krupovic V, Baquero DP, Krupovic M, Egelman EH. Cryo-EM of A. pernix flagellum.</mixed-citation>
    </ref>
    <ref id="CR74">
      <label>74.</label>
      <mixed-citation publication-type="other">Liu Y, Qi X, Li X. Catalytic and inhibitory mechanisms of porcupine-mediated Wnt acylation.</mixed-citation>
    </ref>
    <ref id="CR75">
      <label>75.</label>
      <mixed-citation publication-type="other">Xie T, Chi X, Huang B, Ye F, Zhou Q, Huang J. Rational exploration of fold atlas for human solute carrier proteins. Structure. 2022.</mixed-citation>
    </ref>
    <ref id="CR76">
      <label>76.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Farci</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Haniewicz</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>de Sanctis</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Iesu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Kereiche</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Winterhalter</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The cryo-EM structure of the S-layer deinoxanthin-binding complex of Deinococcus radiodurans informs properties of its environmental interactions</article-title>
        <source>J Biol Chem</source>
        <year>2022</year>
        <volume>298</volume>
        <issue>6</issue>
        <fpage>102031</fpage>
        <pub-id pub-id-type="doi">10.1016/j.jbc.2022.102031</pub-id>
        <?supplied-pmid 35577074?>
        <pub-id pub-id-type="pmid">35577074</pub-id>
      </element-citation>
    </ref>
    <ref id="CR77">
      <label>77.</label>
      <mixed-citation publication-type="other">Dolan KA, Kern DM, Kotecha A, Brohawn SG. Cryo-EM structure of SARS-CoV-2 M protein in lipid nanodiscs.</mixed-citation>
    </ref>
    <ref id="CR78">
      <label>78.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pieper</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Schlessinger</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kloppmann</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>GA</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Dumont</surname>
            <given-names>ME</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Coordinating the impact of structural genomics on the human alpha-helical transmembrane proteome</article-title>
        <source>Nat Struct Mol Biol</source>
        <year>2013</year>
        <volume>20</volume>
        <issue>2</issue>
        <fpage>135</fpage>
        <lpage>138</lpage>
        <pub-id pub-id-type="doi">10.1038/nsmb.2508</pub-id>
        <?supplied-pmid 23381628?>
        <pub-id pub-id-type="pmid">23381628</pub-id>
      </element-citation>
    </ref>
    <ref id="CR79">
      <label>79.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kloppmann</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Punta</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Structural genomics plucks high-hanging membrane proteins</article-title>
        <source>Curr Opin Struct Biol</source>
        <year>2012</year>
        <volume>22</volume>
        <issue>3</issue>
        <fpage>326</fpage>
        <lpage>332</lpage>
        <pub-id pub-id-type="doi">10.1016/j.sbi.2012.05.002</pub-id>
        <?supplied-pmid 22622032?>
        <pub-id pub-id-type="pmid">22622032</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
