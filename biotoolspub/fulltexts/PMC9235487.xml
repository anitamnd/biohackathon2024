<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9235487</article-id>
    <article-id pub-id-type="pmid">35758821</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac257</article-id>
    <article-id pub-id-type="publisher-id">btac257</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>ISCB/Ismb 2022</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Macromolecular Sequence, Structure, and Function</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DECODE: a computational pipeline to discover T cell receptor binding rules</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Papadopoulou</surname>
          <given-names>Iliana</given-names>
        </name>
        <aff>
          <institution>IBM Research Europe, 8803 Rüschlikon, Switzerland</institution>
        </aff>
        <aff>
          <institution>ETH Zurich, Department of Biosystems Science and Engineering (D-BSSE), 4058 Basel, Switzerland</institution>
        </aff>
        <xref rid="btac257-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Nguyen</surname>
          <given-names>An-Phi</given-names>
        </name>
        <aff>
          <institution>IBM Research Europe, 8803 Rüschlikon, Switzerland</institution>
        </aff>
        <aff><institution>ETH Zurich, Department of Mathematics</institution> (D-Math), 8092 Zurich, <country country="CH">Switzerland</country></aff>
        <xref rid="btac257-FM1" ref-type="author-notes"/>
        <xref rid="btac257-cor1" ref-type="corresp"/>
        <!--uye@zurich.ibm.com-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Weber</surname>
          <given-names>Anna</given-names>
        </name>
        <aff>
          <institution>IBM Research Europe, 8803 Rüschlikon, Switzerland</institution>
        </aff>
        <aff>
          <institution>ETH Zurich, Department of Biosystems Science and Engineering (D-BSSE), 4058 Basel, Switzerland</institution>
        </aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Martínez</surname>
          <given-names>María Rodríguez</given-names>
        </name>
        <aff>
          <institution>IBM Research Europe, 8803 Rüschlikon, Switzerland</institution>
        </aff>
        <xref rid="btac257-cor1" ref-type="corresp"/>
        <!--mrm@zurich.ibm.com-->
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btac257-cor1">To whom correspondence should be addressed. E-mail: <email>uye@zurich.ibm.com</email> or <email>mrm@zurich.ibm.com</email></corresp>
      <fn id="btac257-FM1">
        <p>The authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="collection">
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-06-27">
      <day>27</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>27</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <volume>38</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISCB ISMB 2022 Proceedings</issue-title>
    <fpage>i246</fpage>
    <lpage>i254</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac257.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Understanding the mechanisms underlying T cell receptor (TCR) binding is of fundamental importance to understanding adaptive immune responses. A better understanding of the biochemical rules governing TCR binding can be used, e.g. to guide the design of more powerful and safer T cell-based therapies. Advances in repertoire sequencing technologies have made available millions of TCR sequences. Data abundance has, in turn, fueled the development of many computational models to predict the binding properties of TCRs from their sequences. Unfortunately, while many of these works have made great strides toward predicting TCR specificity using machine learning, the black-box nature of these models has resulted in a limited understanding of the rules that govern the binding of a TCR and an epitope.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We present an <italic toggle="yes">easy-to-use</italic> and <italic toggle="yes">customizable</italic> computational pipeline, <monospace>DECODE</monospace>, to extract the binding rules from <italic toggle="yes">any</italic> black-box model designed to predict the TCR-epitope binding. <monospace>DECODE</monospace> offers a range of analytical and visualization tools to guide the user in the extraction of such rules. We demonstrate our pipeline on a recently published TCR-binding prediction model, <monospace>TITAN</monospace>, and show how to use the provided metrics to assess the quality of the computed rules. In conclusion, <monospace>DECODE</monospace> can lead to a better understanding of the sequence motifs that underlie TCR binding. Our pipeline can facilitate the investigation of current immunotherapeutic challenges, such as cross-reactive events due to off-target TCR binding.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>Code is available publicly at <ext-link xlink:href="https://github.com/phineasng/DECODE" ext-link-type="uri">https://github.com/phineasng/DECODE</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>European Union’s Horizon 2020 Research And Innovation Programme</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Marie Sklodowska-Curie</institution>
          </institution-wrap>
        </funding-source>
        <award-id>813545</award-id>
        <award-id>H2020- ICT-2018-2</award-id>
        <award-id>826121</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>The adaptive immune system relies on the selective recognition of foreign antigens by T cells (<xref rid="btac257-B17" ref-type="bibr">Kumar <italic toggle="yes">et al.</italic>, 2018</xref>). T cells recognize short antigenic peptides presented on major histocompatibility complex (MHC) proteins by binding the complex with their T cell receptors (TCRs). A large diversity of TCRs (<xref rid="btac257-B18" ref-type="bibr">Laydon <italic toggle="yes">et al.</italic>, 2015</xref>) ensures that all of the vast space of possible antigenic peptides can be recognized by the immune system.</p>
    <p>In recent years, experimental advances have allowed the identification of T cells that recognize specific antigens. High-throughput sequencing of their TCRs has allowed linking large numbers of TCR sequences to antigen specificity. The increase in available data regarding TCR specificity has resulted in the development of many machine-learning models aiming to predict TCR specificity from sequences (<xref rid="btac257-B6" ref-type="bibr">Dash <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac257-B26" ref-type="bibr">De Neuter <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac257-B9" ref-type="bibr">Fischer <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac257-B11" ref-type="bibr">Gielis <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac257-B12" ref-type="bibr">Glanville <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac257-B15" ref-type="bibr">Jokinen <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac257-B23" ref-type="bibr">Moris <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac257-B34" ref-type="bibr">Sidhom <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac257-B39" ref-type="bibr">Weber <italic toggle="yes">et al.</italic>, 2021</xref>). These efforts are paving the way for the potential decoding of the information present in a patient’s TCR repertoire regarding its immune history, which might reveal information about past and present infections, as well as about disorders of the immune system, such as autoimmune diseases.</p>
    <p>Unfortunately, TCR specificity prediction models are often black-box algorithms with <italic toggle="yes">limited interpretability</italic>. That means that despite the continuous improvement in predictive performances, these models fail to provide insights about the biochemical rules that govern the TCR–epitope interaction. Understanding and being able to accurately predict the binding of new TCRs to target epitopes is an essential step to design more powerful and safer T cell therapies, which represent a promising new approach for cancer immunotherapies.</p>
    <p>Motivated by the need of interpretation in the TCR-epitope binding prediction problem, in this work, we provide an <italic toggle="yes">easy-to-use</italic> explainability pipeline to extract biological insights from <italic toggle="yes">any</italic> TCR-binding prediction model.</p>
    <sec>
      <title>1.1 Motivation</title>
      <p>In order to increase the explainability of machine-learning models, recent work, e.g. Tcr epITope bimodal Attention Networks (<monospace>TITAN</monospace>) (<xref rid="btac257-B39" ref-type="bibr">Weber <italic toggle="yes">et al.</italic>, 2021</xref>), has proposed to augment deep-learning architectures with interpretable components, such as attention layers (<xref rid="btac257-B38" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic>, 2017</xref>). This is an example of <italic toggle="yes">ante-hoc</italic>, or built-in, strategies to tackle interpretability. However, the application of attention mechanisms and, more generally, <italic toggle="yes">ante-hoc</italic> approaches to the TCR-binding prediction problem suffers from two main drawbacks:
</p>
      <list list-type="bullet">
        <list-item>
          <p><italic toggle="yes">Local interpretability</italic>: given the complex nature of both the model and the task, <italic toggle="yes">ante-hoc</italic> techniques often generate only local explanations, i.e. explanations that are valid only for few samples. This results at best in the <italic toggle="yes">partial</italic> understanding of the biological mechanism underlying TCR binding.</p>
        </list-item>
        <list-item>
          <p><italic toggle="yes">Modification and retraining of the original model is needed</italic>: <italic toggle="yes">ante-hoc</italic> approaches need to be embedded in the existing models, which requires retraining the whole new model <italic toggle="yes">from scratch</italic>. Disregarding the amount of work that this might require, this is only possible if the model’s code has been released. Furthermore, there is no guarantee that the modification does not result in a decrease in performance (<xref rid="btac257-B9" ref-type="bibr">Fischer <italic toggle="yes">et al.</italic>, 2020</xref>).</p>
        </list-item>
      </list>
      <p>To address these issues, we introduce <monospace>DECODE</monospace> (DEcoding t Cell receptOr binDing rulEs), a <italic toggle="yes">post-hoc</italic> explainability pipeline that does not need access to a model’s architecture, and therefore, can be applied to models with proprietary or unreleased code. <monospace>DECODE</monospace> has been designed to discover the rules that <italic toggle="yes">any</italic> TCR specificity prediction algorithm follows to make its predictions. Our only requirement is to have access to a black-box model that can make a binding/non-binding prediction for a given TCR-epitope pair.</p>
      <p>The two main components of <monospace>DECODE</monospace> are:
</p>
      <list list-type="bullet">
        <list-item>
          <p>A <italic toggle="yes">clustering</italic> step to enable <italic toggle="yes">global</italic> explainability. This allows the user to understand a model in its entirety and not only on individual cases.</p>
        </list-item>
        <list-item>
          <p>An <italic toggle="yes">explainability</italic> step based on <monospace>Anchors</monospace>, a model-agnostic approach that explains the behavior of complex models using high-precision rules (<xref rid="btac257-B31" ref-type="bibr">Ribeiro <italic toggle="yes">et al.</italic>, 2018</xref>).</p>
        </list-item>
      </list>
      <p>Using these two components, <monospace>DECODE</monospace> creates explanations for <italic toggle="yes">each</italic> cluster of TCRs in the form of easily understood <italic toggle="yes">if-then</italic> rules.</p>
      <p><monospace>DECODE</monospace> is easy to use, offers a wide range of visualizations for the generated binding rules and can be applied to any text/categorically based model. We demonstrate our pipeline on the recently published <monospace>TITAN</monospace> model (<xref rid="btac257-B39" ref-type="bibr">Weber <italic toggle="yes">et al.</italic>, 2021</xref>). To facilitate the visualization of the generated explanations and the investigation of the associated TCR-binding mechanisms, we have retrained <monospace>TITAN</monospace> to predict the binding to a single-epitope, the peptide KLGGALQAK from Cytomegalovirus.</p>
    </sec>
    <sec>
      <title>1.2 Related work</title>
      <p>Several works have recently focused on predicting TCR specificity from sequence using machine learning [for a review see <xref rid="btac257-B24" ref-type="bibr">Mösch <italic toggle="yes">et al.</italic> (2019)</xref>]. Since the small number of epitopes is currently a limiting factor, many approaches have limited their scope and build supervised classifiers that predict the binding of a TCR to a limited pool of epitopes. Among these models, decision trees (<xref rid="btac257-B26" ref-type="bibr">De Neuter <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac257-B11" ref-type="bibr">Gielis <italic toggle="yes">et al.</italic>, 2019</xref>) and Gaussian process methods (<xref rid="btac257-B15" ref-type="bibr">Jokinen <italic toggle="yes">et al.</italic>, 2021</xref>) have been proposed. On the other side, <monospace>TITAN</monospace> (<xref rid="btac257-B39" ref-type="bibr">Weber <italic toggle="yes">et al.</italic>, 2021</xref>) used a bimodal, sequence-based neural network for predicting TCR-epitope binding probability and significantly outperformed the state-of-the-art.</p>
      <p>Regarding the problem of identifying informative motifs and sequence patterns that confer TCR its specificity properties, several approaches have been proposed. <monospace>GLIPH</monospace> (<xref rid="btac257-B12" ref-type="bibr">Glanville <italic toggle="yes">et al.</italic>, 2017</xref>) clusters TCRs according to amino -acid similarity and the presence of conserved motifs; TCR-specific distance measures have been defined to enable clustering and visualization of similar TCR sequences (<xref rid="btac257-B6" ref-type="bibr">Dash <italic toggle="yes">et al.</italic>, 2017</xref>); and variational autoencoders have been used to improve the extraction of TCR meaningful features, named concepts, from TCR repertoires (<xref rid="btac257-B34" ref-type="bibr">Sidhom <italic toggle="yes">et al.</italic>, 2021</xref>).</p>
      <p>With the exception of <monospace>TITAN</monospace>, which uses attention layers to highlight informative amino acids, none of the previous approaches has focused on investigating the biochemical rules that govern TCR binding. As discussed in Section 1.1, attention mechanisms can highlight patterns in the input data that a neural network finds informative; however, they cannot provide human-understandable rules predictive of TCR binding.</p>
      <p>Here, we aim to explore alternative approaches for interpretability. Besides <italic toggle="yes">ante-hoc</italic> approaches to interpretability, i.e. models that are interpretable by construction, such as decision trees, many <italic toggle="yes">post-hoc</italic> approaches have been developed in recent years. These methods can shed light on the decision process of a machine-learning model after it has been trained. They are often model-agnostic, in the sense that they do not need any information about the model itself, and are therefore applicable to any predictive model. Two popular examples are <monospace>LIME</monospace> (<xref rid="btac257-B30" ref-type="bibr">Ribeiro <italic toggle="yes">et al.</italic>, 2016</xref>), which learns a local linear model, and <monospace>Anchors</monospace> (<xref rid="btac257-B31" ref-type="bibr">Ribeiro <italic toggle="yes">et al.</italic>, 2018</xref>), which generates local <italic toggle="yes">if-then</italic> rules, similar to a local decision tree. Feature attribution methods are another type of <italic toggle="yes">post-hoc</italic> interpretable methods that aim to highlight the features that are most important toward a prediction. However, while they can detect <italic toggle="yes">which</italic> features may have been used for a prediction, they do not elucidate <italic toggle="yes">how</italic> they are used. Feature attributions can be either model specific, e.g. gradient-based methods (<xref rid="btac257-B3" ref-type="bibr">Ancona <italic toggle="yes">et al.</italic>, 2018</xref>) applied to a neural network, or model agnostic, e.g. SHAP (<xref rid="btac257-B20" ref-type="bibr">Lundberg and Lee, 2017</xref>).</p>
      <p>In this work, we choose <monospace>Anchors</monospace> as the core component of the explainability step of <monospace>DECODE</monospace>. <monospace>Anchors</monospace> does not makes any linearity assumption (as <monospace>LIME</monospace> does), and therefore is able to find more complex rules. Further, logical rules can be more directly interpreted by human experts (<xref rid="btac257-B10" ref-type="bibr">Fürnkranz <italic toggle="yes">et al.</italic>, 2020</xref>) compared to importance scores, and thus <monospace>Anchors</monospace> are expected to result in more user-friendly explanations than feature attribution methods.</p>
    </sec>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Overview of the pipeline</title>
      <p>In this section, we expand on the computational steps of the <monospace>DECODE</monospace> pipeline. <xref rid="btac257-F1" ref-type="fig">Figure 1</xref> graphically shows the main steps, consisting of:</p>
      <fig position="float" id="btac257-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Overview of DECODE interpretability pipeline. The test data are split into binding and non-binding samples based on the predictions of the model. Both sets of samples are clustered and the medoid of each cluster is chosen as a representative example of the cluster. Note that the medoid is an actual sample from the cluster it represents. The pipeline allows for the use of different clustering algorithms, see Section 2.3. For each medoid, DECODE generates a set of rules using <monospace>Anchors</monospace>. Finally, the pipeline offers a range of visualizations and evaluation metrics for the final anchor rules</p>
        </caption>
        <graphic xlink:href="btac257f1" position="float"/>
      </fig>
      <list list-type="order">
        <list-item>
          <p>A preparation phase (Section 2.2) to load the model to interpret and to prepare the data;</p>
        </list-item>
        <list-item>
          <p>A clustering phase (Section 2.3), where representative samples of the dataset heterogeneity are identified;</p>
        </list-item>
        <list-item>
          <p>An explainability phase (Section 2.4), where the explanations about the representative samples retrieved at the previous step are computed.</p>
        </list-item>
      </list>
      <p>Our pipeline further provides a framework to analyze and evaluate both the clustering (Section 2.3.1) and the generated explanations (Section 2.4.1). The user can define the specific algorithms to use in the preprocessing and clustering phase, as well as other parameters, in an <italic toggle="yes">easily customizable</italic><monospace>json</monospace> file. For the simplest predictive models, the user does not need to inspect the code and can setup the pipeline simply by specifying the mentioned configuration <monospace>json</monospace> file, making the pipeline particularly user-friendly even for practitioners <italic toggle="yes">with little to no experience in programming</italic>.</p>
    </sec>
    <sec>
      <title>2.2 TCR prediction model and data preparation</title>
      <p>The very first step of our pipeline takes care of loading the model and the data. The model should provide a <monospace>predict</monospace> function that returns a predicted class for an input batch. The data should be loaded in a format compatible with the model. For the simplest cases [e.g. a <monospace>scikit</monospace> (<xref rid="btac257-B29" ref-type="bibr">Pedregosa <italic toggle="yes">et al.</italic>, 2011</xref>) model using data in a <monospace>numpy</monospace> (<xref rid="btac257-B13" ref-type="bibr">Harris <italic toggle="yes">et al.</italic>, 2020</xref>) array format], our pipeline already provides the loading functions. For more complex cases [e.g. <monospace>tensorflow</monospace> (<xref rid="btac257-B2" ref-type="bibr">Abadi <italic toggle="yes">et al.</italic>, 2015</xref>), <monospace>pytorch</monospace> (<xref rid="btac257-B28" ref-type="bibr">Paszke <italic toggle="yes">et al.</italic>, 2019</xref>) or <monospace>command-line</monospace> tools], the user should provide their own loading functions.</p>
      <p>After loading, the pipeline will take care of splitting the samples in binding and non-binding partitions, as predicted by the loaded model. In the remainder, we will refer to these partitions as <italic toggle="yes">splits</italic>. The clustering will be run <italic toggle="yes">separately</italic> for these two partitions. Since we expect the binding and non-binding rules to be different, this separation step will help the explainability phase to detect ‘higher quality’ rules.</p>
      <p>As the final (sub)step of this first phase, the user can optionally specify how to further (pre)process the data. This step is necessary only if the data format expected by the model is not the same as the format expected by the clustering and explainability steps. For example, the user may want to provide a precomputed distance matrix to speed up some clustering algorithms.</p>
    </sec>
    <sec>
      <title>2.3 Clustering</title>
      <p>After the loading and preparation phase, the pipeline will identify clusters in each of the samples splits. The pipeline readily provides different clustering algorithms, including <monospace>K-medoids</monospace> (<xref rid="btac257-B27" ref-type="bibr">Park and Jun, 2009</xref>), <monospace>BIRCH</monospace> (<xref rid="btac257-B41" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 1996</xref>) or <monospace>OPTICS</monospace> (<xref rid="btac257-B4" ref-type="bibr">Ankerst <italic toggle="yes">et al.</italic>, 1999</xref>). Similarly to the loading functions in the previous step, the user can provide their own custom clustering algorithm.</p>
      <p>In case it is not clear which clustering algorithm (or which hyperparameters) should be preferred, our pipeline allows the user to run multiple algorithms. The pipeline then provides facilities to select the best clustering algorithm according to a user-defined criterion (Section 2.3.1).</p>
      <p>Furthermore, if different clustering outcomes are produced, the pipeline offers the possibility of finding a consensus clustering using the <monospace>ClusterEnsemble</monospace> package (<xref rid="btac257-B35" ref-type="bibr">Strehl and Ghosh, 2003</xref>).</p>
      <sec>
        <label>2.3.1</label>
        <title>Clustering evaluation</title>
        <p>The pipeline provides both quantitative and qualitative ways to evaluate the clustering algorithms (and the hyperparameters) selected by the user. Quantitative methods include established criteria, such as the <monospace>davies-bouldin</monospace> score (<xref rid="btac257-B7" ref-type="bibr">Davies and Bouldin, 1979</xref>) or the <monospace>Silhouette</monospace> coefficient (<xref rid="btac257-B32" ref-type="bibr">Rousseeuw, 1987</xref>). The qualitative assessment strategies consist of dimensionality reduction algorithms that will project the samples to a 2D space and color-code them using the labels provided by each clustering algorithm. Examples of provided projection methods are <monospace>t-SNE</monospace> (<xref rid="btac257-B37" ref-type="bibr">Van Der Maaten and Hinton, 2008</xref>) and <monospace>LLE</monospace> (Locally Linear Embeddings) (<xref rid="btac257-B33" ref-type="bibr">Roweis and Saul, 2000</xref>). We show an example of clustering evaluation and visualization in Section 3.3.</p>
      </sec>
    </sec>
    <sec>
      <title>2.4 Anchors</title>
      <p>We generate human-readable explanations using <monospace>Anchors</monospace> (<xref rid="btac257-B31" ref-type="bibr">Ribeiro <italic toggle="yes">et al.</italic>, 2018</xref>). An anchor is an explanation presented as an <italic toggle="yes">if-then</italic> rule. More specifically to our use case, <italic toggle="yes">for each of the cluster representative samples</italic>, the computed rule takes the following form:</p>
      <p>
        <disp-quote content-type="extract">
          <p>
            <monospace>IF</monospace>
            <monospace>(amino</monospace>
            <monospace>acid</monospace>
            <monospace>X</monospace>
            <monospace>is</monospace>
            <monospace>in</monospace>
            <monospace>position</monospace>
            <monospace>i)</monospace>
          </p>
          <p>
            <monospace> </monospace>
            <monospace> </monospace>
            <monospace> </monospace>
            <monospace>AND</monospace>
            <monospace>(amino</monospace>
            <monospace>acid</monospace>
            <monospace>Y</monospace>
            <monospace>is</monospace>
            <monospace>in</monospace>
            <monospace>position</monospace>
            <monospace>j)</monospace>
          </p>
          <p>
            <monospace> </monospace>
            <monospace> </monospace>
            <monospace> </monospace>
            <monospace>AND</monospace>
            <monospace>etc..</monospace>
            <monospace>THEN</monospace>
          </p>
          <p>
            <monospace>the</monospace>
            <monospace>samples</monospace>
            <monospace>is</monospace>
            <monospace>PREDICTION,</monospace>
          </p>
        </disp-quote>
      </p>
      <p>where <monospace>X</monospace> and <monospace>Y</monospace> represent some amino acid, <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic> may take any value within the length of the input and <monospace>PREDICTION</monospace> depends on what kind of rule we are trying to explain (i.e. either <italic toggle="yes">binding</italic> or <italic toggle="yes">non-binding</italic>).</p>
      <p>The <italic toggle="yes">quality</italic> of these rules and the <italic toggle="yes">completeness</italic> of the overview they provide in explaining a TCR prediction model depend on a number of factors, including the clustering algorithm and the hyperparameters of the <monospace>Anchors</monospace> algorithm (discussed in Section 3.4). In the next section, we introduce some metrics to evaluate anchors.</p>
      <p>Finally, note that there exists a trade-off between the quality of the explanations and the computational resources (memory and time) required for their generation. For reference, in our experiments on a single <monospace>Intel Xeon CPU E5-2667 (@3.30 GHz)</monospace>, computing a single anchor with default parameters requires between 15 min and 3 h, depending on the complexity of the rule. With less restrictive parameters leading to lower quality rules, the computation can be shortened to 2 min up to 30 min.</p>
      <sec>
        <label>2.4.1</label>
        <title>Anchors evaluation</title>
        <p>Ideally, we would like a set of anchors to <italic toggle="yes">faithfully</italic> represent the underlying model and be <italic toggle="yes">complete</italic> with respect to the whole space of samples. In layman terms, this means that:
</p>
        <list list-type="bullet">
          <list-item>
            <p>The anchors should be able to replicate the same prediction of the model. That means that if a sample fulfills an anchor rule, this rule should lead to the same prediction as the one provided by the model.</p>
          </list-item>
          <list-item>
            <p>The anchors should not <italic toggle="yes">overlap</italic>, i.e. different anchors should not be applicable to the same sample simultaneously. This is especially important if the rules were generated from clusters belonging to different data splits (Section 2.2). If a sample fulfills two anchor rules associated with different predictions, how can a user decide which one is correct?</p>
          </list-item>
          <list-item>
            <p>The set of anchor rules should be able to cover the whole sample space. Only if this condition is fulfilled, we may be able to understand globally the model.</p>
          </list-item>
        </list>
        <p>The last two points mean in particular that any admissible input sample should ideally fulfill exactly one of the generated anchor rules. The listed desiderata can be evaluated using standard predictive performance metrics (<italic toggle="yes">accuracy</italic>, <italic toggle="yes">precision</italic> and <italic toggle="yes">recall</italic>), and other overlap/completeness metrics that we will introduce later in this section. The predictive performance metrics follow the usual definitions:
<disp-formula id="E1"><mml:math id="M1" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mtext>Accuracy</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>Precision</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>Recall</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where TP are true positives, TN are true negatives, FP are false positives and FN are true negatives. We provide these metrics at three different levels, and the definition of a TP will depend on the level at which the metric is computed. For a visual description of these metrics, please refer to <xref rid="btac257-F2" ref-type="fig">Figure 2</xref>. A more detailed description of the figure can be found in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S1</xref>.</p>
        <fig position="float" id="btac257-F2">
          <label>Fig. 2.</label>
          <caption>
            <p>Cluster metrics: graphical visualization. Blue stars represent samples predicted as binding by the model we want to explain. Red crosses are samples predicted as non-binding. The thick continuous line is the decision boundary of the model. We can identify three clusters for the binding samples, and two for the non-binding ones. As an example, we graphically visualize the three levels of metrics applied to the non-binding anchors. The black crosses denote the medoids of the (non-binding) clusters. Dotted circles denote the boundary decisions of the computed anchors: all the samples within the circle fulfill the anchor rule. Red rectangles highlight the true positives according to the anchor rules. CL metrics considers true positives the samples that fulfill the anchor rule <italic toggle="yes">and</italic> belong to the same cluster as the medoid used to compute the rule. CS level metrics considers true positives all the samples that fulfill the anchor rule and belong to the <italic toggle="yes">same split</italic> as the medoid considered. Finally, SL metrics considers true positives all the samples that fulfill any of the anchor rules of a split and belongs to that same split</p>
          </caption>
          <graphic xlink:href="btac257f2" position="float"/>
        </fig>
        <list list-type="bullet">
          <list-item>
            <p><bold>Cluster level</bold> (CL): a sample is considered a true positive if it fulfills <italic toggle="yes">only</italic> the anchor rule generated from the medoid of its cluster. Perfect performance at this level (simultaneously for <italic toggle="yes">all</italic> the clusters) would give us all the desiderata mentioned above. In particular, if all anchor rules are accurate, then they are faithful; if they are all precise, then there is no overlap; and if they all have perfect recall, then we have complete coverage.</p>
          </list-item>
          <list-item>
            <p><bold>Cluster-split</bold> <bold>(CS)</bold> <bold>level</bold> : an anchor rule prediction on a sample is considered a true positive if it leads to the same model-prediction of the sample. In particular, the sample does not need to belong to the same cluster from which the anchor is generated. In turn, this means that high precision does not guarantee <italic toggle="yes">no-overlap</italic>. This level is more relaxed than the previous one: low performance at the CL level, but high performance on the CS level may be acceptable. This would mean that there are overlapping rules, but at least these rules lead to the same prediction. However, while this situation might be acceptable from a predictive point of view, it poses a problem for interpretability. For instance, if two rules apply, which one should we choose? Should both the rules be considered simultaneously?</p>
          </list-item>
          <list-item>
            <p><bold>Split level</bold> (SP): a sample is considered a true positive if it fulfills <italic toggle="yes">any</italic> of the rules generated from the clusters of its same <italic toggle="yes">split</italic>. This is a further relaxation of the CL level.</p>
          </list-item>
        </list>
        <p>A different way of understanding the differences between the different anchor metrics is by considering the question being answered by each metric. At the CL, we are answering the question how many samples in a particular cluster fulfil the cluster's rule. This leads to a score per cluster. At the CS level, we are answering the question “how many samples in a split fulfil the cluster's rule”. The answer also leads to a score per cluster. At the SP level, the question being answered is “how many samples in a split fulfil any of the rules”. Therefore, we only get one score for the whole set of anchor rules (see <xref rid="btac257-F7" ref-type="fig">Figure 4</xref> for an example).</p>
        <p>If a set of anchors performs poorly on the above metrics, we might conclude that this set is not ideal, in terms of either faithfulness or completeness. Computing the overlap and completeness of the rules might result in useful information to adjust the parameters of the pipeline. With this goal in mind, we propose a simple counting measure to monitor the degree of overlap between rules. Given two anchors, the <italic toggle="yes">overlap</italic> is the number of (sub-)rules that are compatible, i.e. they require the <italic toggle="yes">same</italic> amino acids in the <italic toggle="yes">same</italic> positions. For anchors computed from the same split, it is acceptable to have a high count of overlaps. This might simply mean that the rules are redundant. However, high overlap is not desirable for anchors generated from different splits: if both rules apply and lead to conflicting predictions, how should the sample be interpreted?</p>
        <p>To monitor the degree of completeness, for each sample in a validation/test set, we simply count the number of anchors that are applicable to that sample. Ideally, all samples should fulfill one and only one anchor. If there are a high number of samples with zero applicable anchors, it would mean that the generated set of anchors is far from completeness.</p>
      </sec>
      <sec>
        <label>2.4.2</label>
        <title>Anchors visualization</title>
        <p>To facilitate interpretability, we visualize the textual anchor rules similarly to a sequence motif (e.g. <xref rid="btac257-F7" ref-type="fig">Fig. 7</xref>). Since models may take as an input very long sequences, we further facilitate rule visualization by allowing the split of the motif in multiple regions, e.g. the Framework Regions (FRs) and Complementarity-Determining Regions (CDRs) for a TCR.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>As a proof of concept, we apply our pipeline to two recently published deep-learning models for TCR-binding prediction, <monospace>TITAN</monospace> (<xref rid="btac257-B39" ref-type="bibr">Weber <italic toggle="yes">et al.</italic>, 2021</xref>) and pMHC-TCR-binding prediction network <monospace>(pMTnet)</monospace> (<xref rid="btac257-B19" ref-type="bibr">Lu <italic toggle="yes">et al.</italic>, 2021</xref>). To keep our proof of concept simple, we analyze both models only on a <italic toggle="yes">single epitope</italic>: the peptide KLGGALQAK from Cytomegalovirus. This peptide was selected for being the one with the largest number of associated TCRs in our dataset (Section 3.2).</p>
    <sec>
      <title>3.1 The models to interpret</title>
      <sec>
        <title>3.1.1 TITAN</title>
        <p><monospace>TITAN</monospace> (<xref rid="btac257-B39" ref-type="bibr">Weber <italic toggle="yes">et al.</italic>, 2021</xref>) is a bimodal attention-based neural network that takes as input a sequence representing an epitope and a sequence representing a TCR.</p>
        <p><monospace>TITAN</monospace> can leverage different encodings, but in our experiments, we use a SMILES (<xref rid="btac257-B40" ref-type="bibr">Weininger, 1988</xref>) representation for the fixed epitope and BLOSUM encodings for the TCRs. Both sequences are padded with a special ‘&lt;PAD&gt;’ token so that the lengths of the input sequences for <monospace>TITAN</monospace> are fixed to 500 for the epitope and 500 for the TCR. To help the training of the model, the actual TCR sequence is preceded by a ‘&lt;START&gt;’ token and is followed by a ‘&lt;STOP&gt;’ token. We specifically retrain <monospace>TITAN</monospace> for 50 epochs on a dataset containing solely the selected epitope. Details about the dataset are provided in the next section. On this dataset, <monospace>TITAN</monospace> achieves an accuracy of 77%.</p>
      </sec>
      <sec>
        <label>3.1.2</label>
        <title>pMTnet</title>
        <p><monospace>pMTnet</monospace> (<xref rid="btac257-B19" ref-type="bibr">Lu <italic toggle="yes">et al.</italic>, 2021</xref>) is a transfer learning-based model that predicts TCR -epitope binding based on an Atchley factor encoding of the <italic toggle="yes">CDR3</italic> loop of the TCR and a joint encoding of epitope and MHC similar to the netMHCpan model. <monospace>pMTnet</monospace> outputs the fractional rank of each TCR compared to 10 000 background receptors, i.e. its rank divided by 10 000, which we use as a proxy for the binding probability. We load the trained model provided on Github and interpret the predictions on our test set, where the model achieves an accuracy of 50%. We want to highlight that our test dataset is not well suited for a fair judgment of pMTnets performance, since it likely contains more noise than the dataset that pMTnet was trained to achieve high performance on and we did not retrain or finetune pMTnet on the single -epitope prediction task.</p>
      </sec>
    </sec>
    <sec>
      <title>3.2 Data</title>
      <p>As mentioned above, we choose to focus only on the peptide KLGGALQAK. We build our peptide-specific dataset starting from a 10X Genomics study (<xref rid="btac257-B1" ref-type="bibr">10X Genomics, 2020</xref>), which identified 13 647 different TCRs binding to this peptide. Since no true negative data exists, we create non-binding pairs by retrieving TCRs that have not been found to bind to this peptide. We compose this ‘negative’ subset using three different sources:
</p>
      <list list-type="bullet">
        <list-item>
          <p>4207 TCRs included in the VDJ database (<xref rid="btac257-B5" ref-type="bibr">Bagaev <italic toggle="yes">et al.</italic>, 2020</xref>) that bind to different targets;</p>
        </list-item>
        <list-item>
          <p>3951 naive TCR sequences from another 10X Genomics study; and</p>
        </list-item>
        <list-item>
          <p>5399 TCR sequences generated with the tool <monospace>IGor</monospace> (<xref rid="btac257-B22" ref-type="bibr">Marcou <italic toggle="yes">et al.</italic>, 2018</xref>).</p>
        </list-item>
      </list>
      <p>For our analysis, we focus solely on TCR<italic toggle="yes">β</italic> chain sequences. After processing and cleaning, we obtain a balanced dataset of 21 832 samples, which we split in a training/test set. We run the interpretability analysis for both models on the <italic toggle="yes">same</italic> test set comprised of 2K samples.</p>
    </sec>
    <sec>
      <title>3.3 Clustering results</title>
      <p>As underlying distance metric for the clustering phase, we use the Levenshtein distance, a string metric that counts the number of amino-acid edits (insertions, deletions or substitutions) necessary to turn a sequence into another. Unfortunately, not all algorithms allow for arbitrary distances. Therefore, in our case study, we restrict our analysis to <monospace>K-Medoids</monospace>, <monospace>OPTICS</monospace> and <monospace>AgglomerativeClustering</monospace> (<xref rid="btac257-B25" ref-type="bibr">Müllner, 2011</xref>). We run <monospace>K-Medoids</monospace> and <monospace>AgglomerativeClustering</monospace> with the number of clusters varying in a range between 5 and 20. For <monospace>OPTICS</monospace>, we define a range for the density parameter <italic toggle="yes">ϵ</italic> that leads to a comparable number of clusters (between 2 and 31).</p>
      <p>Because of the same distance metric constraint as above, we are restricted to use the <monospace>Silhouette score</monospace> for the quantitative assessment of the cluster partitions. For qualitative analysis, we use <monospace>t-SNE</monospace>. <xref rid="btac257-F3" ref-type="fig">Figure 3</xref> shows the <monospace>Silhouette score</monospace> for each algorithms and different number of clusters. For each algorithm, we further plot the <monospace>t-SNE</monospace> projections color-coded according to the best clustering as measured by the <monospace>Silhouette score</monospace>, e.g. for <monospace>AgglomerativeClustering</monospace>, we use the cluster labeling obtained by setting the number of clusters to 20.</p>
      <fig position="float" id="btac257-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Comparison of clustering algorithms. Top-left shows the mean Silhouette score <italic toggle="yes">s</italic> for all three different clustering methods and a number of different numbers of clusters. <monospace>AgglomerativeClustering</monospace> achieves high scores for all numbers of clusters, with higher scores for higher numbers of clusters and a maximum of <italic toggle="yes">s </italic>=<italic toggle="yes"> </italic>0.66 for <italic toggle="yes">k </italic>=<italic toggle="yes"> </italic>20. <monospace>OPTICS</monospace> shows an optimum for <italic toggle="yes">k </italic>=<italic toggle="yes"> </italic>14 clusters with a score of <italic toggle="yes">s </italic>=<italic toggle="yes"> </italic>0.47, while <italic toggle="yes"><monospace>K</monospace></italic><monospace>-medoids</monospace> has low scores for any number of clusters. The other plots show <monospace>t-SNE</monospace> plots, where samples are color-coded according to their cluster assignment. The plots were generated for the number of clusters resulting in the highest Silhouette score for each clustering method, respectively. All clustering results are shown for the binding class</p>
        </caption>
        <graphic xlink:href="btac257f3" position="float"/>
      </fig>
      <p>For demonstration purposes, we focus this part of the analysis on the binding split. However, similar results are obtained for the non-binding split (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S2</xref>).</p>
      <p>From <xref rid="btac257-F3" ref-type="fig">Figure 3</xref>, we notice that the top performing clustering for the binding split is <monospace>AgglomerativeClustering</monospace> with 20 clusters. Note that clustering metrics are just a <italic toggle="yes">heuristic</italic> to guide the selection of the clustering algorithm, but there is no guarantee that this will lead to the best possible anchor explanations. This selection step is necessary since the algorithm to compute <monospace>Anchors</monospace> is computationally expensive, and running it for each possible clustering result may be prohibitive.</p>
      <p>We further note that the best <monospace>OPTICS</monospace> setting (<inline-formula id="IE2"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mo>ϵ</mml:mo><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, corresponding to 14 clusters) seems to be qualitatively similar to <monospace>AgglomerativeClustering</monospace> with 20 clusters, as per <monospace>t-SNE</monospace> visualization. As we mentioned above, quantitative clustering metrics may not correlate with the final quality of anchors. Therefore, a user may decide to select <monospace>OPTICS</monospace> over <monospace>AgglomerativeClustering</monospace> in order to compute a lower number of anchor rules, and reduce the computational burden. In the following, we select the results from the <monospace>Agglomerative Clustering</monospace> algorithm as a basis for the explainability phase.</p>
    </sec>
    <sec>
      <title>3.4 Anchors metrics</title>
      <p>The pipeline runs the <monospace>Anchors</monospace> algorithm as provided by the <monospace>alibi</monospace> package (<xref rid="btac257-B16" ref-type="bibr">Klaise <italic toggle="yes">et al.</italic>, 2021</xref>) with parameters that generate more precise rules compared to the default parameters. More precisely, we use <inline-formula id="IE3"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mo>δ</mml:mo><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>τ</mml:mo><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula> and a threshold of 0.9. <xref rid="btac257-F4" ref-type="fig">Figure 4</xref> shows the metrics at the three different levels, as introduced in Section 2.4.1.</p>
      <fig position="float" id="btac257-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Anchors metrics. The accuracy, precision and recall of non-binding anchors (blue) and binding anchors (orange) are shown for the anchors generated from the clusters identified by the <monospace>AgglomerativeClustering</monospace> algorithm with 20 clusters. From left to right: CL metrics, CS level metrics and SP metrics for a total of 40 anchors (20 non-binding, 20 binding). Note that for the split metrics, we are jointly considering the 20 rules for each split at the same time (resulting in one metric per split)</p>
        </caption>
        <graphic xlink:href="btac257f4" position="float"/>
      </fig>
      <p>The leftmost plot in <xref rid="btac257-F4" ref-type="fig">Figure 4</xref> shows the metrics at the CL. Overall, the non-binding anchors (blue) and binding anchors (orange) seem to do a good job at identifying their own cluster (relatively high-accuracy). Notable difference is the fact that, tendentially, non-binding anchors have low precision and high recall, while the contrary holds true for binding anchors. Simply put, the <monospace>Anchors</monospace> algorithms generate for non-binding clusters decision rules that are less-specific for their own clusters. On the other hand, the rules generated for binding clusters seem to be too specific to the cluster centroid. That is, the binding anchor rules do not seem to well represent the other samples belonging to their own cluster.</p>
      <p>Since non-binding anchors perform reasonably well at retrieving samples from their own cluster (high recall), a legitimate question is: how general are the non-binding rules? That is, do non-binding anchors recognize also non-binding samples not belonging to the same cluster? The CS level metrics (center plot in <xref rid="btac257-F4" ref-type="fig">Fig. 4</xref>) help us answer these questions. Interestingly, now the non-binding anchors behavior is more similar to the binding ones. This means that the validity of a non-binding rule extends solely to its cluster, and not much further. Unsurprisingly, the specificity of the binding rules is further exacerbated at the SL.</p>
      <p>The SL metrics help us understand if the rules belonging to the same split may <italic toggle="yes">collectively</italic> be able to identify their own split. The rightmost plot in <xref rid="btac257-F4" ref-type="fig">Figure 4</xref> shows that the set of rules retains similar accuracy/precision performance to the CS level, while significantly improving on the recall. This means that overall the <monospace>Anchors</monospace> algorithm managed to compute explanations that are faithful to the underlying biology, but not complete/global enough. That is, we have gained an understanding of how the model is functioning only for a subset of samples.</p>
      <p>In summary, these multi-level metrics help us understand if the explanations generated from the pipeline are faithful to the model, and the extent of their validity/globality. They further may help us pinpoint which steps of the pipeline may require improvement. For example, changing the default <monospace>Anchors</monospace> parameters may improve the generality of binding rules (higher recall). Further, the ability of non-binding rules to recognize their own cluster, while not being able to collectively recognize the non-binding split, suggests that a different clustering algorithm/parameters setting could be used to find better representative non-binding samples.</p>
      <p>To have a clearer idea of how to change the pipeline settings to improve the generated explanations, we can have a look at the rule overlaps and the completeness/coverage of the rules. The overlaps between anchors can be visualized as a heatmap, similarly to interaction matrices (left plot in <xref rid="btac257-F5" ref-type="fig">Fig. 5</xref>). The completeness can be readily visualized with a histogram (right plot in <xref rid="btac257-F5" ref-type="fig">Fig. 5</xref>) counting how many (<italic toggle="yes">y</italic>-axis) samples fulfill a certain number of anchors (<italic toggle="yes">x</italic>-axis).</p>
      <fig position="float" id="btac257-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>Anchors overlap and completeness analysis. Results are reported for the test set consisting of around 2k samples. Left plot shows the overlap between anchors visualized as a heatpmap: non-binding rules are located in top-left corner of the matrix, while binding rules in the bottom right. Color denotes the number of overlapping rules, with brighter colors indicating a higher number of rules. While there is some overlap of anchors rules within the same data splits (i.e. the binding and non-binding partitions), there is no overlap across splits. That means that no sample fulfills both a binding and a non-binding rule. Right plot shows completeness, i.e. a histogram depicting how many samples (<italic toggle="yes">y</italic>-axis) fulfill a certain number of anchors (<italic toggle="yes">x</italic>-axis). With the pipeline settings used for this experiment, most samples do not fulfill any anchor rule, around 300 samples fulfill either 1 or 10 rules, and few fulfill 11 rules. Therefore, the rules obtained in this experiment are not a <italic toggle="yes">complete</italic> set of rules</p>
        </caption>
        <graphic xlink:href="btac257f5" position="float"/>
      </fig>
      <p>The left plot in <xref rid="btac257-F5" ref-type="fig">Figure 5</xref> suggests that there is quite some overlap between non-binding rules (top-left quadrant of the interaction matrix), which together with the previous conclusions, may suggest that a solution is to select a different clustering algorithm that <italic toggle="yes">better separates</italic> the clusters. As desirable, there is no overlap between non-binding and binding rules.</p>
      <p>The anchor fulfillment histogram reveals that there is a considerably high number of samples not covered by the anchors, in agreement with the SL metrics. Namely, most samples do not fulfill any anchor rule, around 300 samples fulfill 1 rule and 10 rules, and a few samples fulfill 11 rules. The latter samples are likely to be non-binding samples whose rules tend to be less specific. This visualization confirms once again that a better clustering algorithm (or better parameters/metrics) might be the right solution.</p>
      <p>An ablation study (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section S3</xref>) confirms that by varying clustering parameters, we can trade-off precision, coverage and completeness of the generated anchor rules.</p>
    </sec>
    <sec>
      <title>3.5 Anchors visual analysis</title>
      <p>While the perfomance metrics shown in the previous section are far from ideal, this does not mean that we cannot attempt a biological interpretation of the model. While the previous results suggest that the explanations may not be able to give a complete overview of the model, they do seem to provide a correct interpretation.</p>
      <sec>
        <label>3.5.1</label>
        <title>Distribution of rules in biologically significant regions</title>
        <p>The input sequences for an underlying TCR-binding prediction model may be too long for the user to properly interpret them. Indeed, in our case study, the input TCR sequences are 150 (500 if we consider the padding) characters long (Section 3.1.1). To make the anchor analysis more user-friendly, we provide functionalities to align samples and anchor rules, and extract various regions of interest, i.e. the FRs and CDRs (Section 2.4.1). A preliminary overview of the locations of anchor (sub)rules can be obtained by counting how many anchor rules fall into each of the regions. For a more fair comparison of the regions, these counts are normalized by the length of each of the regions. <xref rid="btac257-F6" ref-type="fig">Figure 6</xref> reports these counts separately for non-binding and binding splits. Apart from the four FRs and three CDRs, we report counts also for rules falling in a part of the sequence that was not aligned to either the FRs or the CDRs (‘Other’), in the padded region of the sequence (‘PAD’), or on either the start or stop token (‘Start’/‘Stop’).</p>
        <fig position="float" id="btac257-F6">
          <label>Fig. 6.</label>
          <caption>
            <p>Histograms showing the distribution of anchor rules on the different regions of a TCR sequences normalized to the length of the region. The figure reports the number of anchors on the four FRs, three CDRs, other regions of the sequence not aligned with either the FRs or the CDRs (‘Other’), in the padded regions (‘PAD’), and on either the start or stop token (‘Start’/‘Stop’). Left plot: binding rules. Right plot: non-binding rules</p>
          </caption>
          <graphic xlink:href="btac257f6" position="float"/>
        </fig>
        <p>Interestingly, both non-binding and binding rules seem to put a similar emphasis on the CDR2 and CDR1 regions as on the CDR3. While it is generally agreed that the CDR3 region is more directly implicated in binding an epitope, which might lead to an expected higher concentration of rules in this region, all CDRs are physically involved in the binding, and therefore, it is reasonable to find rules concentrating on the CDR2 and CDR1 region. Another interesting result is the fact that <monospace>TITAN</monospace> binding rules seem to have a preference also for the FRs. FRs have a supporting role for binding, e.g. by increasing the surface density of TCRs, without impacting their affinity (<xref rid="btac257-B36" ref-type="bibr">Thomas <italic toggle="yes">et al.</italic>, 2019</xref>). Rules in FRs might also indicate a preference toward certain TCR gene segments when binding our target peptide (<xref rid="btac257-B8" ref-type="bibr">Davis and Bjorkman, 1988</xref>). We observe that non-binding rules in general exhibit a far lower density of rules, a sign that they are far less strict than the binding rules. Moreover, many non-binding rules seem to fall in the ‘Other’ region, which may not have any biological significance. This is somewhat expected: the non-binding samples of our dataset (Section 3.2) are randomly sampled from a huge and heterogeneous pool of unspecific TCRs, and therefore may not be characterized by any ‘non-binding pattern’. Of course, there could be other reasons for these biased results that should be investigated, such as <monospace>TITAN</monospace> picking up spurious correlations in the dataset.</p>
      </sec>
      <sec>
        <title>3.5.2 Visual interpretation of an anchor</title>
        <p>After the preliminary analysis, a user can visually inspect the generated anchor rules, as explained in Section 2.4.1. As a demonstrative example, in <xref rid="btac257-F7" ref-type="fig">Figure 7</xref>, we show two binding rules, one from <monospace>TITAN</monospace> and one from pMTnet. Each rule (top row) is compared to the sequence logo of the same region (bottom row), which reports the amino-acid frequencies in the binding split. Note that <monospace>DECODE</monospace> does <italic toggle="yes">not</italic> simply detect the most frequent amino acids, which would be a trivial task, but instead identifies rules that explain the prediction of <monospace>TITAN</monospace> and <monospace>pMTnet</monospace> for a particular cluster of samples. Applying <monospace>DECODE</monospace> to two different models let us exploit their specific advantages. <monospace>TITAN</monospace> uses the whole TCR variable sequence as input and can therefore inform on preferential V or J segment use. Indeed, the anchor shown in <xref rid="btac257-F7" ref-type="fig">Fig. 7</xref> directly implies a use of the TRBV19 segment, indicating that TCRs with this gene segment have a high likelihood of binding the KLGGALQAK-A*03:01 complex we examine. This is a non-trivial finding, as the use of TRBV19 is not higher in the KLGGALQAK binders listed in VDJdb compared to the whole VDJ database. While associations of TRBV segments and epitopes or MHCs are not uncommon, this specific interaction may represent a new biological finding. Nevertheless, experimental validation would be needed to confirm this result. <monospace>pMTnet</monospace> on the other hand has only the CDR3 region as input and therefore provides more detailed insight into the features important in this region. The example shown in <xref rid="btac257-F1" ref-type="fig">Figure 2.4.1</xref> is typical for the rules we observe (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> for all anchors), with mainly polar amino acids across the whole CDR3 sequence being of high importance.</p>
        <fig position="float" id="btac257-F7">
          <label>Fig. 7.</label>
          <caption>
            <p>Binding anchor rule examples from TITAN (left) and pMTnet (right). Top row represents the anchor rule, while the bottom row shows the sequence logo of the whole binding split. For TITAN, we focus on the CDR2 region, where many rules fall. pMTnet uses only the CDR3 sequence as input, so gives more specific results for this region</p>
          </caption>
          <graphic xlink:href="btac257f7" position="float"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>In this article, we introduce <monospace>DECODE</monospace>, an easy-to-use and customizable pipeline to interpret <italic toggle="yes">any</italic> model for TCR-binding prediction in a faithful and global way. Faithfulness is achieved by leveraging an established high-precision interpretable method, <monospace>Anchors</monospace>. Globality is attained by obtaining representative samples of the dataset via <italic toggle="yes">clustering</italic>, and finally applying <monospace>Anchors</monospace> to each of them. We demonstrate how easy it is to extract and understand the binding rules by DECODE-ing <monospace>TITAN</monospace> and <monospace>pMTnet</monospace>, two recently published TCR-binding prediction models.</p>
    <p><monospace>DECODE</monospace> is easy to setup thanks to a customizable <monospace>json</monospace> configuration file that the user can modify to select the best hyperparameters for their dataset. User-friendliness is further enabled by a range of metrics and visualization tools to help the user in the selection of the best clustering method and the best <monospace>Anchors</monospace> parameters, and in the understanding of the (non-)binding rules.</p>
    <p>We note that our pipeline can be applied to both good performing and poor performing models. In the former case, the higher the performance of a model, the more likely the extracted rules will have a biological meaning. In the latter case, if the model does not achieve a good accuracy, <monospace>DECODE</monospace> may be able to highlight the weaknesses of the model and guide future improvements.</p>
    <p>In the future, we plan to expand the selection of clustering algorithms and visualization tools and enable an interactive exploration of the binding rules. Moreover, we aim to further improve the user-friendliness in at least two ways: first, by further simplifying the customization of the configuration file; and, secondly, by providing a framework to guide the user in the selection of the best hyperparameters [e.g. simple grid search, or Bayesian Optimization (<xref rid="btac257-B14" ref-type="bibr">Hutter <italic toggle="yes">et al.</italic>, 2011</xref>)].</p>
    <p>We believe that our work will be able to support the immunology research community in understanding the intricate mechanisms underlying TCR binding, and ultimately contribute to the development of novel and safer immunotherapies.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the European Union’s Horizon 2020 Research And Innovation Programme under the Marie Sklodowska-Curie program [Grant Agreement No. 813545] and H2020- ICT-2018-2 program [Grant Agreement No. 826121].</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac257_Supplementary_Data</label>
      <media xlink:href="btac257_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac257-B1">
      <mixed-citation publication-type="other">10X Genomics. (<year>2020</year>) <italic toggle="yes">A New Way of Exploring Immunity-Linking Highly Multiplexed Antigen Recognition to Immune Repertoire and Phenotype</italic>. <ext-link xlink:href="https://www.10xgenomics.com/resources/application-notes/a-new-way-of-exploring-immunity-linking-highly-multiplexed-antigen-recognition-to-immune-repertoire-and-phenotype/" ext-link-type="uri">https://www.10xgenomics.com/resources/application-notes/a-new-way-of-exploring-immunity-linking-highly-multiplexed-antigen-recognition-to-immune-repertoire-and-phenotype/</ext-link>.</mixed-citation>
    </ref>
    <ref id="btac257-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Abadi</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <italic toggle="yes">TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems</italic>. <ext-link xlink:href="https://www.tensorflow.org/" ext-link-type="uri">https://www.tensorflow.org/</ext-link>.</mixed-citation>
    </ref>
    <ref id="btac257-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ancona</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) Towards better understanding of gradient-based attribution methods for Deep Neural Networks. In: <italic toggle="yes">6th International Conference on Learning Representations (ICLR 2018), Vancouver, Canada</italic>.</mixed-citation>
    </ref>
    <ref id="btac257-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ankerst</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1999</year>) <article-title>OPTICS: ordering points to identify the clustering structure</article-title>. <source>SIGMOD Rec</source>., <volume>28</volume>, <fpage>49</fpage>–<lpage>60</lpage>.</mixed-citation>
    </ref>
    <ref id="btac257-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bagaev</surname><given-names>D.V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>VDJdb in 2019: database extension, new analysis infrastructure and a T-cell receptor motif compendium</article-title>. <source>Nucleic Acids Res</source>., <volume>48</volume>, <fpage>D1057</fpage>–<lpage>D1062</lpage>.<pub-id pub-id-type="pmid">31588507</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dash</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> ( <year>2017</year>) <article-title>Quantifiable predictive features define epitope-specific T cell receptor repertoires</article-title>. <source>Nature</source>, <volume>547</volume>, <fpage>89</fpage>–<lpage>93</lpage>.<pub-id pub-id-type="pmid">28636592</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Davies</surname><given-names>D.L.</given-names></string-name>, <string-name><surname>Bouldin</surname><given-names>D.W.</given-names></string-name></person-group> (<year>1979</year>) <article-title>A cluster separation measure</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell</source>., <volume>PAMI-1</volume>, <fpage>224</fpage>–<lpage>227</lpage>.</mixed-citation>
    </ref>
    <ref id="btac257-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Davis</surname><given-names>M.M.</given-names></string-name>, <string-name><surname>Bjorkman</surname><given-names>P.J.</given-names></string-name></person-group> (<year>1988</year>) <article-title>T-cell antigen receptor genes and T-cell recognition</article-title>. <source>Nature</source>, <volume>334</volume>, <fpage>395</fpage>–<lpage>402</lpage>.<pub-id pub-id-type="pmid">3043226</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fischer</surname><given-names>D.S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Predicting antigen specificity of single T cells based on TCR CDR 3 regions</article-title>. <source>Mol. Syst. Biol</source>., <volume>16</volume>, <fpage>e9416</fpage>.<pub-id pub-id-type="pmid">32779888</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fürnkranz</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>On cognitive preferences and the plausibility of rule-based models</article-title>. <source>Mach. Learn</source>., <volume>109</volume>, <fpage>853</fpage>–<lpage>898</lpage>.</mixed-citation>
    </ref>
    <ref id="btac257-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gielis</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Detection of enriched T cell epitope specificity in full T cell receptor sequence repertoires</article-title>. <source>Front. Immunol</source>., <volume>10</volume>, <fpage>2820</fpage>.<pub-id pub-id-type="pmid">31849987</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glanville</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> ( <year>2017</year>) <article-title>Identifying specificity groups in the T cell receptor repertoire</article-title>. <source>Nature</source>, <volume>547</volume>, <fpage>94</fpage>–<lpage>98</lpage>.<pub-id pub-id-type="pmid">28636589</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harris</surname><given-names>C.R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Array programming with NumPy</article-title>. <source>Nature</source>, <volume>585</volume>, <fpage>357</fpage>–<lpage>362</lpage>.<pub-id pub-id-type="pmid">32939066</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B14">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Hutter</surname><given-names>F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) <part-title>Sequential model-based optimization for general algorithm configuration</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Coello</surname><given-names>C.A.C.</given-names></string-name></person-group> (ed.) <source>Learning and Intelligent Optimization</source>. <publisher-name>Springer</publisher-name>, <publisher-loc>Berlin, Heidelberg</publisher-loc>, pp. <fpage>507</fpage>–<lpage>523</lpage>.</mixed-citation>
    </ref>
    <ref id="btac257-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jokinen</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Predicting recognition between T cell receptors and epitopes with TCRGP</article-title>. <source>PLoS Comput. Biol</source>., <volume>17</volume>, <fpage>e1008814</fpage>.<pub-id pub-id-type="pmid">33764977</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Klaise</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Alibi explain: algorithms for explaining machine learning models</article-title>. <source>J. Mach. Learn. Res</source>., <volume>22</volume>, <fpage>1</fpage>–<lpage>7</lpage>.</mixed-citation>
    </ref>
    <ref id="btac257-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kumar</surname><given-names>B.V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Human T cell development, localization, and function throughout life</article-title>. <source>Immunity</source>, <volume>48</volume>, <fpage>202</fpage>–<lpage>213</lpage>.<pub-id pub-id-type="pmid">29466753</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Laydon</surname><given-names>D.J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>Estimating T-cell repertoire diversity: limitations of classical estimators and a new approach</article-title>. <source>Phil. Trans. R Soc. B</source>, <volume>370</volume>, <fpage>20140291</fpage>.<pub-id pub-id-type="pmid">26150657</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lu</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Deep learning-based prediction of the t cell receptor–antigen binding specificity</article-title>. <source>Nat. Mach. Intell</source>., <volume>3</volume>, <fpage>864</fpage>–<lpage>875</lpage>.<pub-id pub-id-type="pmid">36003885</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lundberg</surname><given-names>S.M.</given-names></string-name>, <string-name><surname>Lee</surname><given-names>S.-I.</given-names></string-name></person-group> (<year>2017</year>) A unified approach to interpreting model predictions. In: <italic toggle="yes">Proceedings of the 31st International Conference on Neural Information Processing Systems</italic>. pp. <fpage>4768</fpage>–<lpage>4777</lpage>. Curran Associates Inc., Red Hook, NY, USA.</mixed-citation>
    </ref>
    <ref id="btac257-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marcou</surname><given-names>Q.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>High-throughput immune repertoire analysis with IGoR</article-title>. <source>Nat. Commun</source>., <volume>9</volume>, <fpage>561</fpage>.<pub-id pub-id-type="pmid">29422654</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B23">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Moris</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) Current challenges for unseen-epitope TCR interaction prediction and a new perspective derived from image classification. <italic toggle="yes">Briefings in Bioinformatics</italic>, <bold>22</bold>(4), <fpage>1</fpage>–<lpage>12</lpage>. <ext-link xlink:href="https://pubmed.ncbi.nlm.nih.gov/33346826/" ext-link-type="uri">https://pubmed.ncbi.nlm.nih.gov/33346826/</ext-link>.</mixed-citation>
    </ref>
    <ref id="btac257-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mösch</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Machine learning for cancer immunotherapies based on epitope recognition by T cell receptors</article-title>. <source>Front. Genet</source>., <volume>10</volume>, <fpage>1141</fpage>.<pub-id pub-id-type="pmid">31798635</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Müllner</surname><given-names>D.</given-names></string-name></person-group> (<year>2011</year>) <italic toggle="yes">Modern Hierarchical, Agglomerative Clustering Algorithms</italic>. <ext-link xlink:href="https://arxiv.org/abs/1109.2378" ext-link-type="uri">https://arxiv.org/abs/1109.2378</ext-link>.</mixed-citation>
    </ref>
    <ref id="btac257-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Neuter</surname><given-names>N.D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>On the feasibility of mining CD8+ T cell receptor patterns underlying immunogenic peptide recognition</article-title>. <source>Immunogenetics</source>, <volume>70</volume>, <fpage>159</fpage>–<lpage>168</lpage>.<pub-id pub-id-type="pmid">28779185</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Park</surname><given-names>H.S.</given-names></string-name>, <string-name><surname>Jun</surname><given-names>C.H.</given-names></string-name></person-group> (<year>2009</year>) <article-title>A simple and fast algorithm for K-medoids clustering</article-title>. <source>Expert Syst. Appl</source>., <volume>36</volume>, <fpage>3336</fpage>–<lpage>3341</lpage>.</mixed-citation>
    </ref>
    <ref id="btac257-B28">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Paszke</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <part-title>Pytorch: an imperative style, high-performance deep learning library</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Wallach</surname><given-names>H.</given-names></string-name></person-group>  <etal>et al</etal> (eds) <source>Advances in Neural Information Processing Systems, Vancouver, Canada, Vol. 32</source>. pp. <fpage>8024</fpage>–<lpage>8035</lpage>. <publisher-name>Curran Associates, Inc</publisher-name>. <ext-link xlink:href="http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf" ext-link-type="uri">http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="btac257-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pedregosa</surname><given-names>F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) <article-title>Scikit-learn: machine learning in python</article-title>. <source>J. Mach. Learn. Res</source>., <volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="btac257-B30">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ribeiro</surname><given-names>M.T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) “Why should I trust you?” explaining the predictions of any classifier. In: <italic toggle="yes">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</italic>. pp. <fpage>1135</fpage>–<lpage>1144</lpage>.</mixed-citation>
    </ref>
    <ref id="btac257-B31">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name>Ribeiro, M.T., </string-name></person-group><italic toggle="yes">et al.</italic> (2018). Anchors: High-Precision Model-Agnostic Explanations. In: <italic toggle="yes">Proceedings of the AAAI Conference on Artificial Intelligence, San Francisco, California</italic>, Vol. <italic toggle="yes">32</italic>.</mixed-citation>
    </ref>
    <ref id="btac257-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rousseeuw</surname><given-names>P.J.</given-names></string-name></person-group> (<year>1987</year>) <article-title>Silhouettes: a graphical aid to the interpretation and validation of cluster analysis</article-title>. <source>J. Comput. Appl. Math</source>., <volume>20</volume>, <fpage>53</fpage>–<lpage>65</lpage>.</mixed-citation>
    </ref>
    <ref id="btac257-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roweis</surname><given-names>S.T.</given-names></string-name>, <string-name><surname>Saul</surname><given-names>L.K.</given-names></string-name></person-group> (<year>2000</year>) <article-title>Nonlinear dimensionality reduction by locally linear embedding</article-title>. <source>Science</source>, <volume>290</volume>, <fpage>2323</fpage>–<lpage>2326</lpage>.<pub-id pub-id-type="pmid">11125150</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sidhom</surname><given-names>J.-W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>DeepTCR is a deep learning framework for revealing sequence concepts within T-cell repertoires</article-title>. <source>Nat. Commun</source>., <volume>12</volume>, <fpage>1605</fpage>.<pub-id pub-id-type="pmid">33707415</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Strehl</surname><given-names>A.</given-names></string-name>, <string-name><surname>Ghosh</surname><given-names>J.</given-names></string-name></person-group> (<year>2003</year>) <article-title>Cluster ensembles — a knowledge reuse framework for combining multiple partitions</article-title>. <source>J. Mach. Learn. Res</source>., <volume>3</volume>, <fpage>583</fpage>–<lpage>617</lpage>.</mixed-citation>
    </ref>
    <ref id="btac257-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Thomas</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Framework engineering to produce dominant T cell receptors with enhanced antigen-specific function</article-title>. <source>Nat. Commun</source>., <volume>10</volume>, <fpage>4451</fpage>.<pub-id pub-id-type="pmid">31575864</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B37">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Van Der Maaten</surname><given-names>L.</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>G.</given-names></string-name></person-group> (<year>2008</year>) Visualizing data using t-SNE. <italic toggle="yes">Technical report</italic>.</mixed-citation>
    </ref>
    <ref id="btac257-B38">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Vaswani</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <part-title>Attention is all you need</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Guyon</surname><given-names>I.</given-names></string-name></person-group>  <etal>et al</etal> (eds) <source>Advances in Neural Information Processing Systems</source>, Vol. <volume>30</volume>. <publisher-name>Curran Associates, Inc</publisher-name>. <ext-link xlink:href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" ext-link-type="uri">https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="btac257-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weber</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>TITAN: T -cell receptor specificity prediction with bimodal attention networks</article-title>. <source>Bioinformatics</source>, <volume>37</volume>, <fpage>i237</fpage>–<lpage>i244</lpage>.<pub-id pub-id-type="pmid">34252922</pub-id></mixed-citation>
    </ref>
    <ref id="btac257-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weininger</surname><given-names>D.</given-names></string-name></person-group> (<year>1988</year>) <article-title>SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules</article-title>. <source>J. Chem. Inf. Model</source>., <volume>28</volume>, <fpage>31</fpage>–<lpage>36</lpage>.</mixed-citation>
    </ref>
    <ref id="btac257-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1996</year>) <article-title>BIRCH: an efficient data clustering method for very large databases</article-title>. <source>SIGMOD Rec</source>., <volume>25</volume>, <fpage>103</fpage>–<lpage>114</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
