<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8189677</article-id>
    <article-id pub-id-type="pmid">33230554</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa950</article-id>
    <article-id pub-id-type="publisher-id">btaa950</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>RepeatFS: a file system providing reproducibility through provenance and automation</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-5398-6916</contrib-id>
        <name>
          <surname>Westbrook</surname>
          <given-names>Anthony</given-names>
        </name>
        <xref rid="btaa950-cor1" ref-type="corresp"/>
        <aff>
          <institution>Department of Computer Science</institution>
        </aff>
        <aff>
          <institution>Hubbard Center for Genome Studies</institution>
        </aff>
        <!--anthony.westbrook@unh.edu-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Varki</surname>
          <given-names>Elizabeth</given-names>
        </name>
        <aff>
          <institution>Department of Computer Science</institution>
        </aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Thomas</surname>
          <given-names>W Kelley</given-names>
        </name>
        <aff>
          <institution>Hubbard Center for Genome Studies</institution>
        </aff>
        <aff><institution>Department of Molecular Cellular and Biomedical Sciences, University of New Hampshire</institution>, Durham, NH 03824, <country country="US">USA</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Jonathan</surname>
          <given-names>Wren</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btaa950-cor1">To whom correspondence should be addressed. <email>anthony.westbrook@unh.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>5</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-11-24">
      <day>24</day>
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>24</day>
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <volume>37</volume>
    <issue>9</issue>
    <fpage>1292</fpage>
    <lpage>1296</lpage>
    <history>
      <date date-type="received">
        <day>31</day>
        <month>7</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>11</day>
        <month>10</month>
        <year>2020</year>
      </date>
      <date date-type="editorial-decision">
        <day>26</day>
        <month>10</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>10</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa950.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Reproducibility is of central importance to the scientific process. The difficulty of consistently replicating and verifying experimental results is magnified in the era of big data, in which bioinformatics analysis often involves complex multi-application pipelines operating on terabytes of data. These processes result in thousands of possible permutations of data preparation steps, software versions and command-line arguments. Existing reproducibility frameworks are cumbersome and involve redesigning computational methods. To address these issues, we developed RepeatFS, a file system that records, replicates and verifies informatics workflows with no alteration to the original methods. RepeatFS also provides several other features to help promote analytical transparency and reproducibility, including provenance visualization and task automation.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We used RepeatFS to successfully visualize and replicate a variety of bioinformatics tasks consisting of over a million operations with no alteration to the original methods. RepeatFS correctly identified all software inconsistencies that resulted in replication differences.</p>
      </sec>
      <sec id="s3">
        <title>Availabilityand implementation</title>
        <p>RepeatFS is implemented in Python 3. Its source code and documentation are available at <ext-link xlink:href="https://github.com/ToniWestbrook/repeatfs" ext-link-type="uri">https://github.com/ToniWestbrook/repeatfs</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>New Hampshire-INBRE through an Institutional Development Award (IDeA)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>P20GM103506</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of General Medical Sciences of the NIH</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="5"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>The foundation of science is built upon the acquisition and analysis of empirical evidence. The formulation and testing of hypotheses are rooted in these observations. This methodology provides the capability not only to understand the world around us but also to make effective predictions given specific conditions. As such, accurate forecasts require a reproducible experimental design; repetition of a deterministic process with differing results indicates a lack of rigor and eliminates the confidence in the prediction. Given the importance of repeatability, the enterprise of science currently faces a significant struggle. A 2016 <italic toggle="yes">Nature</italic> survey completed by over 1500 researchers found that more than 70% have attempted to reproduce another scientist’s findings without success (<xref rid="btaa950-B4" ref-type="bibr">Baker, 2016</xref>, 500), and more than half were unable to replicate their own results. Subsequently, numerous supporting studies have been performed across a range of biological disciplines, including genomics (<xref rid="btaa950-B16" ref-type="bibr">Kanwal <italic toggle="yes">et al.</italic>, 2017</xref>), biomedical sciences (<xref rid="btaa950-B9" ref-type="bibr">Coiera <italic toggle="yes">et al.</italic>, 2018</xref>) and computational biology (<xref rid="btaa950-B13" ref-type="bibr">Garijo <italic toggle="yes">et al.</italic>, 2013</xref>), each noting challenges involved in ensuring reproducibility.</p>
    <p>While many factors in the research process can result in a deviation from the original experimental methods, each study notes informatics as especially problematic, often responsible for introducing unintended variation into replication studies. Respondents of the <italic toggle="yes">Nature</italic> survey corroborate this concern, with over 82% noting that ‘insufficient computer code or protocol information’ is at least sometimes involved, if not very often or always. Reasons for this stem from the vast number of available software applications and reference databases (<xref rid="btaa950-B10" ref-type="bibr">Davis-Turak <italic toggle="yes">et al.</italic>, 2017</xref>); differences in versions, parameters and configuration files (<xref rid="btaa950-B18" ref-type="bibr">Kim et al., 2018</xref>); and a wide variety of data formats and conversion techniques (<xref rid="btaa950-B21" ref-type="bibr">Lewis et al., 2016</xref>). As a typical informatics workflow has the potential for thousands of combinations of these attributes, it quickly becomes apparent that provenance for recording the exact environment and steps performed by a researcher is critical in replicating results.</p>
    <p>Informatics software has attempted to address this reproducibility issue with limited success. Virtual environments, such as Docker (<xref rid="btaa950-B11" ref-type="bibr">Docker, 2020</xref>) and Anaconda (<xref rid="btaa950-B3" ref-type="bibr">Anaconda Software Distribution, 2020</xref>), ensure the versions of software match between original and repeated analyses, but cannot verify these programs are executed using the same parameters, reference databases or other runtime options. Analysis platforms such as Galaxy (<xref rid="btaa950-B1" ref-type="bibr">Afgan <italic toggle="yes">et al.</italic>, 2018</xref>) and QIIME 2 (<xref rid="btaa950-B7" ref-type="bibr">Bolyen <italic toggle="yes">et al.</italic>, 2019</xref>) require the researcher to operate within the provided set of tools, forcing methods to be redesigned and precluding the ability to use many external packages. Generic pipeline frameworks such as Ruffus (<xref rid="btaa950-B14" ref-type="bibr">Goodstadt, 2010</xref>), Bpipe (<xref rid="btaa950-B25" ref-type="bibr">Sadedin et al., 2012</xref>), Snakemake (<xref rid="btaa950-B19" ref-type="bibr">Köster et al., 2012</xref>) and SoS (<xref rid="btaa950-B29" ref-type="bibr">Wang et al., 2019</xref>), while designed to work with any program, require the researcher to write scripts to migrate their workflow into the framework. This not only requires learning an additional language and rewriting each step of the workflow but potentially introduces new mistakes. Thus, current solutions have limitations that prevent their widespread adoption.</p>
    <p>To provide robust provenance capabilities without requiring the user to learn new platforms or languages, we developed RepeatFS, a file system that transparently records process, file and read/write activity for every application. Informatics methods may be used without alteration, and the complete provenance history of any file may be exported, visualized and replicated. Replication supports process verification, ensuring the same parameters, software versions and resulting files are produced for each step in the provenance record, including provenance histories with multiple versions of the same application. RepeatFS also has the ability to reconstruct script files, should these be missing or unavailable during the replication process.</p>
    <p>In addition to these provenance services, RepeatFS provides ‘virtual dynamic files’ (VDFs) for commonly performed informatics tasks, such as converting between file formats or filtering delimited tables. VDFs are displayed in a directory listing as normal files, though they do not reside on disk. For each file matching a file type designated by the user, a corresponding VDF will be shown in the directory listing. This VDF will be named the same as the source file but will end in a new extension that indicates the type of data the VDF contains. When the VDF is accessed, RepeatFS automatically runs one or more pre-configured programs, such as a file conversion utility, using the source file as input. The output of this program is streamed into the VDF. An example configuration would show a FASTA VDF for each FASTQ file present on disk. If opened, the FASTA file would contain the sequences from the FASTQ file with the quality scores removed; RepeatFS automatically runs the conversion utility when the FASTA file is accessed. This process ensures these tasks are always performed in an identical manner and reduces the risk of error. Though VDFs are created in this unique way, the system treats them as normal files, and they may be viewed, copied and used as input for other applications.</p>
    <p>By offering both provenance tracking and VDFs, RepeatFS reduces the risk of user error and promotes reproducibility. RepeatFS is written in Python 3, supports all major underlying single and multiuser file systems (ext4, Lustre, BeeGFS) and is user installable on Linux (soon available for MacOS). RepeatFS does not currently support recording provenance across different file systems.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>To demonstrate the effectiveness of RepeatFS, we established two primary goals. The first was to run two common bioinformatics pipelines on a source computer system, then visualize, replicate and verify the results on a mix of destination server environments with differing levels of similarity to the source. The second goal was to demonstrate a variety of common tasks using VDFs. Widely used open-source software was utilized for all tests, and no application employed their own provenance tracking capabilities.</p>
    <sec>
      <title>2.1 Evaluating provenance tracking</title>
      <p>The reproduction of a target file requires the exact replicated execution of every program that created or modified that file. All files previously read by those programs must also be reproduced, and this process must be recursively repeated until the entire program tree has been re-created. For this reason, the foundation of the RepeatFS replication system relies upon a complete and detailed historical provenance record of every file operation performed on all monitored files. In order to effectively test and demonstrate this functionality, two bioinformatics pipelines were constructed and used. These pipelines were limited in scope to aid verification and visualization but contained a large volume of different file operations to create a complex provenance history. No such restrictions are required during normal use of RepeatFS.</p>
      <p>The first pipeline performed genome annotation using the <italic toggle="yes">SRA toolkit</italic>(<xref rid="btaa950-B20" ref-type="bibr">Leinonen et al., 2011</xref>) for obtaining reads, <italic toggle="yes">Trimmomatic</italic> (<xref rid="btaa950-B6" ref-type="bibr">Bolger <italic toggle="yes">et al.</italic>, 2014</xref>) for adapter and quality trimming, <italic toggle="yes">SPAdes</italic> (<xref rid="btaa950-B5" ref-type="bibr">Bankevich <italic toggle="yes">et al.</italic>, 2012</xref>) for genome assembly and <italic toggle="yes">Prokka</italic> (<xref rid="btaa950-B26" ref-type="bibr">Seemann, 2014</xref>) for genome annotation. Nearly one million, paired-end reads of <italic toggle="yes">E.coli</italic> were used as input. The resulting GFF file was used as the target file for replication. The second pipeline performed phylogenetic inference of a 16S gene tree using <italic toggle="yes">wget</italic> to obtain the SILVA (<xref rid="btaa950-B24" ref-type="bibr">Quast et al., 2012</xref>) reference database, <italic toggle="yes">bioawk</italic> (<xref rid="btaa950-B22" ref-type="bibr">Li, 2011</xref>) to filter the reference for entries belonging to a particular taxonomic rank, <italic toggle="yes">MAFFT</italic> (<xref rid="btaa950-B17" ref-type="bibr">Katoh, 2002</xref>) for multi-sequence alignment and <italic toggle="yes">RAxML</italic> (<xref rid="btaa950-B27" ref-type="bibr">Stamatakis, 2014</xref>) for maximum-likelihood based phylogenetic inference. The SILVA reference was filtered for the 718 present members of the Yersinia genus. The resulting Newick file was used as the target file for replication.</p>
      <p>After executing each pipeline on the source server environment <italic toggle="yes">EnvSrc</italic>, provenance was exported for each target file. Each export file was copied to two destination server environments, <italic toggle="yes">EnvDst1</italic> and <italic toggle="yes">EnvDst2</italic>. Neither pipeline shell script was copied from <italic toggle="yes">EnvSrc</italic>. <italic toggle="yes">EnvDst1</italic> contained identical versions of all software as <italic toggle="yes">EnvSrc</italic>, while <italic toggle="yes">EnvDst2</italic> was modified to contain different versions of software used by each pipeline: <italic toggle="yes">BLAST</italic> (<xref rid="btaa950-B2" ref-type="bibr">Altschul <italic toggle="yes">et al.</italic>, 1990</xref>), a well-known application used by <italic toggle="yes">Prokka</italic>, was upgraded to a later version, and RAxML was recompiled with different default options. The exported provenance was then imported into RepeatFS to perform pipeline script reconstruction, replication and result verification. As a secondary confirmation, the resulting target file was compared using <italic toggle="yes">diff</italic> to the original to note any inconsistencies.</p>
    </sec>
    <sec>
      <title>2.2 Evaluating virtual dynamic files</title>
      <p>As the purpose of VDFs is to automate commonly executed commands, two classes of tests were designed to demonstrate the effectiveness of VDFs across a variety of bioinformatics tasks. The first class defined VDFs for converting genomics file formats and instructed RepeatFS to provide a corresponding converted file for each original file in a directory. This configuration included VDF FASTA files for FASTQ files via FASTX-Toolkit (<xref rid="btaa950-B15" ref-type="bibr">Gordon, 2014</xref>), VDF sorted BAM files for SAM files via Samtools (<xref rid="btaa950-B23" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2009</xref>) and VDF Phylip (Felsenstein) files for Clustal (<xref rid="btaa950-B28" ref-type="bibr">Thompson et al., 1994</xref>) files via BioPython (<xref rid="btaa950-B8" ref-type="bibr">Cock <italic toggle="yes">et al.</italic>, 2009</xref>). The second class defined VDFs for analysis tasks and included FASTA and SAM file parsing routines. These VDFs provided FASTA headers via grep, alignment statistics via Samtools, and taxon abundance via cut, sort and uniq. Though by no means an exhaustive list of possible functions VDFs can provide, these examples illustrate a representative sample of typical bioinformatics tasks.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>Following the execution of both pipelines within EnvSrc, we calculated and noted metrics relevant to the size and complexity of the provenance as recorded by RepeatFS (<xref rid="btaa950-T1" ref-type="table">Table 1</xref>). Though only comprised of fewer than 10 applications, together both pipelines yielded nearly 1.5 million IO operations. The number of total documented command-line parameters available across all applications was nearly 400. Lastly, the number of different versions and releases that have been publicly available during the lifetime of each application was estimated at over 400.</p>
    <table-wrap position="float" id="btaa950-T1">
      <label>Table 1.</label>
      <caption>
        <p>Provenance complexity</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="1" colspan="1">Executable</th>
            <th rowspan="1" colspan="1">IO Ops</th>
            <th rowspan="1" colspan="1">Parameters</th>
            <th rowspan="1" colspan="1">Releases</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">Fastq-dump</td>
            <td rowspan="1" colspan="1">268 552</td>
            <td rowspan="1" colspan="1">43</td>
            <td rowspan="1" colspan="1">48</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Trimmomatic</td>
            <td rowspan="1" colspan="1">261 775</td>
            <td rowspan="1" colspan="1">17</td>
            <td rowspan="1" colspan="1">39</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">SPAdes</td>
            <td rowspan="1" colspan="1">609 644</td>
            <td rowspan="1" colspan="1">53</td>
            <td rowspan="1" colspan="1">32</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Prokka</td>
            <td rowspan="1" colspan="1">39194</td>
            <td rowspan="1" colspan="1">39</td>
            <td rowspan="1" colspan="1">25</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <bold>
                <italic toggle="yes">Pipeline 1 total</italic>
              </bold>
            </td>
            <td rowspan="1" colspan="1">
              <bold>1 179 165</bold>
            </td>
            <td rowspan="1" colspan="1">
              <bold>152</bold>
            </td>
            <td rowspan="1" colspan="1">
              <bold>144</bold>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Wget</td>
            <td rowspan="1" colspan="1">96 449</td>
            <td rowspan="1" colspan="1">148</td>
            <td rowspan="1" colspan="1">35</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">GZip</td>
            <td rowspan="1" colspan="1">202 196</td>
            <td rowspan="1" colspan="1">18</td>
            <td rowspan="1" colspan="1">12</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Bioawk</td>
            <td rowspan="1" colspan="1">6547</td>
            <td rowspan="1" colspan="1">Many*</td>
            <td rowspan="1" colspan="1">1</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">MAFFT</td>
            <td rowspan="1" colspan="1">1496</td>
            <td rowspan="1" colspan="1">8</td>
            <td rowspan="1" colspan="1">177</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">RAxML</td>
            <td rowspan="1" colspan="1">2356</td>
            <td rowspan="1" colspan="1">69</td>
            <td rowspan="1" colspan="1">68</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <bold>
                <italic toggle="yes">Pipeline 2 total</italic>
              </bold>
            </td>
            <td rowspan="1" colspan="1">
              <bold>309 044</bold>
            </td>
            <td rowspan="1" colspan="1">
              <bold>243</bold>
            </td>
            <td rowspan="1" colspan="1">
              <bold>293</bold>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <bold>
                <italic toggle="yes">Combined total</italic>
              </bold>
            </td>
            <td rowspan="1" colspan="1">
              <bold>1 488 209</bold>
            </td>
            <td rowspan="1" colspan="1">
              <bold>395</bold>
            </td>
            <td rowspan="1" colspan="1">
              <bold>437</bold>
            </td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>IO operations were recorded as any direct request by an application against the RepeatFS file system (e.g. open, read, write), as well as operations performed indirectly by the operating system as a result of these requests. Application parameter counts only include those explicitly documented by the usage output. As Bioawk extends Awk, a domain-specific language with all commands available as parameters, this number was not included in calculations. Releases were estimated using changelogs, version control repository releases (Github) and numbering systems. Releases were confined to the application only and did not include linked libraries. Each pipeline was executed under amd64 Debian and CentOS Linux.</p>
    <p>Utilizing RepeatFS provenance visualization, we manually confirmed the accuracy of the process execution and file access records (<xref rid="btaa950-F1" ref-type="fig">Figs 1</xref> and <xref rid="btaa950-F2" ref-type="fig">2</xref>). Each shell script process was expanded to examine the activity of all child processes and ensure each application executed as expected. RepeatFS successfully recorded all operations and correctly grouped files with identical read/write activity.</p>
    <fig position="float" id="btaa950-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>A provenance graph was generated by RepeatFS for the target annotation file (green) for pipeline 1. Relationships between processes (red) and files (blue) are shown for every causal read or write operation (black arrows) that affected the creation or modification of the target file. Each pipeline shell script was expanded to display spawned child processes (red arrows). Files with identical read and write processes are automatically grouped and counted, greatly reducing the visual complexity of the graph. Though top-level graphs are shown here, we were also able to further expand and verify sub-process activity under parent programs, such as SPAdes and Prokka</p>
      </caption>
      <graphic xlink:href="btaa950f1" position="float"/>
    </fig>
    <fig position="float" id="btaa950-F2">
      <label>Fig. 2.</label>
      <caption>
        <p>A provenance graph was generated by RepeatFS for the target tree file (green) for pipeline 2. Relationships between processes (red) and files (blue) are shown for every causal read or write operation (black arrows) that affected the creation or modification of the target file. Each pipeline shell script was expanded to display spawned child processes (red arrows). Files with identical read and write processes are automatically grouped and counted, greatly reducing the visual complexity of the graph. </p>
      </caption>
      <graphic xlink:href="btaa950f2" position="float"/>
    </fig>
    <p>Following visualization, we used the exported provenance from <italic toggle="yes">EnvSrc</italic> for each target file as the basis of replication in <italic toggle="yes">EnvDst1</italic> and <italic toggle="yes">EnvDst2</italic>. RepeatFS was able to successfully reconstruct and execute the original pipeline scripts in both environments, and noted software version differences in <italic toggle="yes">BLAST</italic> and <italic toggle="yes">RAxML</italic> in <italic toggle="yes">EnvDst2</italic>. Comparing the resulting target files for each pipeline revealed that <italic toggle="yes">EnvSrc</italic> and <italic toggle="yes">EnvDst1</italic> yielded identical results, while the output from <italic toggle="yes">EnvDst2</italic> contained differences for both pipelines caused by the difference in software versions.</p>
    <p>Finally, the contents of the six VDFs were compared with the results created by manually running the commands associated with each VDF definition; in all cases, the two files were identical. In addition, each VDF was copied into a separate directory outside of RepeatFS, confirming the ability to export the results of these files to an outside environment.</p>
  </sec>
  <sec>
    <title>4 Implementation</title>
    <sec>
      <title>4.1 Functional overview</title>
      <p>To provide a universal and reliable method of recording provenance, we elected to implement RepeatFS as a file system, providing the ability to monitor all I/O operations. This avoids reconstructing provenance through incomplete and ambiguous information derived from command history logs, process lists or environment variables. RepeatFS utilizes the popular FUSE interface, allowing the user to run one or more instances without requiring system administrator privileges. When accessing disk files, RepeatFS acts as an interface, receiving applicable system calls, relaying them to the underlying file system and returning the results (see Operation Processing in <xref rid="btaa950-F3" ref-type="fig">Fig. 3</xref>).</p>
      <fig position="float" id="btaa950-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>RepeatFS structure, outlining the flow of data originating from a system call issued by a process. The system call is first directed into RepeatFS by FUSE. Once the operation is received, information necessary to later reconstruct provenance is stored within a database and then sent for routing. Operations performed on real files are relayed to the underlying file system, and those performed on VDFs are handled by the block cache system. Since RepeatFS is a multithreaded file system, multiple system calls and VDF task processes may be serviced concurrently</p>
        </caption>
        <graphic xlink:href="btaa950f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>4.2 VDF processing</title>
      <p>Many bioinformatics applications are designed to write output to a stdout stream so the user may utilize a pipe and relay the results to a receiving program. This allows the receiving program to immediately begin processing output before the sending program has finished execution. Using these standard memory-based POSIX pipes is limited however, as the data are lost once the receiving program reads it. Multiple programs may not simultaneously receive the same data from a pipe, and the sending program must be run again with a new pipe for each repeated execution.</p>
      <p>For programs that write directly to disk files instead of stdout streams, these issues are solved as multiple applications may read the output file concurrently. However, the application reading the data is normally unaware of the total amount to read. While pipes indicate if all data have been sent, disk files cannot provide this indication and all data must be written to a file before other programs may safely access it. The performance improvement of a receiving program concurrently processing the data are therefore lost. In addition, temporary disk files must be used, decreasing performance and increasing unnecessary file clutter.</p>
      <p>RepeatFS solves the limitations of both pipes and disk files by providing VDFs. System calls made to VDFs are not relayed to the underlying file system and are instead routed through RepeatFS’s custom block cache system, reducing the number of disk accesses (see <italic toggle="yes">Block Cache System</italic> in <xref rid="btaa950-F3" ref-type="fig">Fig. 3</xref>). When a process issues a read request, if the requested block is present in the memory cache, the data are immediately retrieved. If the block is present in the disk cache, it is transferred to the memory cache and then returned. In the event of the first cache miss, RepeatFS executes the shell command to populate the VDF as defined in the configuration file. These commands may provide output via a stdout stream or writes to a file, and the user may configure which destination to receive. RepeatFS will route this output into a buffer and transfer the requested data to the appropriate location in the block memory cache, thereby populating the missing block (see <italic toggle="yes">Process Output Handler</italic> in <xref rid="btaa950-F3" ref-type="fig">Fig. 3</xref>). Each subsequent cache miss for the file will cause RepeatFS to transfer additional output to the next location within the block memory cache until the application ends and no further output remains. Should the memory cache size ever exceed the configured maximum, RepeatFS will flush the oldest, unwritten blocks out to the disk cache.</p>
      <p>Since VDFs are presented as disk files and not pipes, multiple receiving programs may access them concurrently. Unlike normal disk files however, RepeatFS will pause any reads made to blocks not yet written by the sending program; once the block is written, the read will resume, allowing receiving programs to begin reading data before the sending program has finished. This hybrid approach offers the benefits of both pipe and disk-based file access.</p>
    </sec>
    <sec>
      <title>4.3 Storing and retrieving provenance</title>
      <p>After receiving a system call for either disk files or VDFs, RepeatFS records the operation within a SQL database, noting the time it occurred, the file targeted by the operation and details about the process issuing the call. This information includes attributes necessary to subsequently reconstruct provenance, including command-line parameters, current working directory and the executable’s checksum. Operation records associated with high throughput operations such as reads and writes are temporarily cached in memory and later flushed to the database to improve performance.</p>
      <p>When visualizing or replicating the provenance of a file of interest, RepeatFS iteratively traces through I/O activity within the database by repeatedly executing two queries. The first query retrieves all the past write operations made to the file, noting the execution details of each process that performed a write. For each of these processes, the second query retrieves any read operations made to other files by the process prior to the time the process wrote to the file of interest, since it is likely the data obtained from these reads were used as input for the internal routines that wrote to the file of interest. A simple example of this would be a sorting program which reads words from an input file and then writes a sorted list of these words to an output file; the words written are dependent on the words read. In lieu of a computationally expensive analysis of machine code to determine dependence, RepeatFS instead assumes data written by a process is dependent on all data read earlier by the process.</p>
      <p>Finally, each file targeted by these reads then becomes the start of a new iteration, and the entire process is continually repeated. An additional constraint ensures that only files written before the second query’s read time are included in the next iteration. This recursively reconstructs the provenance tree while accounting for temporal correctness; only data read by a process prior to the time the process produced output could have affected this output. Recursion will end once no further processes are associated with any provenance branch. The earliest file in a provenance branch was created by a process that used input data from outside of RepeatFS, such as from another file system, a network location or the keyboard.</p>
    </sec>
  </sec>
  <sec>
    <title>5 Implementation</title>
    <p>As shown with the example pipelines, the number of parameters and versions of the component applications create thousands of potential runtime combinations, each of which may lead to a different resulting output. Though the pipelines consisted of only nine total applications, the combined number of file system operations was over one million, illustrating that the number of applications utilized in a pipeline is a poor predictor of provenance size or complexity. RepeatFS does not limit the numbers of applications or file operations used in a pipeline.</p>
    <p>Though some attributes associated with execution variability, such as parameters and configuration files, may be faithfully reproduced using careful notetaking, others are potentially unknown to the user. Applications may reference internal values or proprietary data files, each of which may vary between versions. <xref rid="btaa950-T1" ref-type="table">Table 1</xref> illustrates the magnitude of software versions and file access counts for a small selection of bioinformatics applications, but this issue is inherent within all software. This problem clearly demonstrates the need for a record of provenance at the file system level, as well as an automated way of replicating and verifying the large number of potential execution variations.</p>
    <p>By using the provenance graphs produced by RepeatFS, we were able to easily ascertain many details about the inner components of each pipeline that could potentially cause differing outputs in future executions. We were also able to automatically replicate the results of both complex pipelines with complete fidelity when run using an environment identical to the original, even without access to the original pipeline shell scripts. When run in a modified environment, RepeatFS was able to correctly warn of the potential for different results due to the mismatch in software versions. Performing the same level of verification manually would not only require arduous amounts of work but also require detailed technical knowledge of each component in the pipeline, creating the potential for human error. In addition, each of the six tasks we performed using VDFs resulted in identical results, showing this feature reduces workload for repeatedly run tasks and strengthens reproducibility.</p>
    <p>Most importantly, we were able to accomplish these replication and verification tasks easily without the need to write scripts or modify our bioinformatics methods to fit within a custom framework. Thus, RepeatFS avoids introducing variability and errors into a pipeline caused by misconfiguring the workflow management system. As the correct replication of results is still dependent on matching software versions, we recommend utilizing RepeatFS with software managed by a virtual or container environment, such as Anaconda or Docker. When used in this manner, RepeatFS is an easy-to-use tool for ensuring reproducibility for virtually any type of informatics analysis.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by New Hampshire-INBRE through an Institutional Development Award (IDeA), P20GM103506, from the National Institute of General Medical Sciences of the NIH.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btaa950_Supplementary_Data</label>
      <media xlink:href="btaa950_supplementary_data.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa950-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Afgan</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) 
<article-title>The Galaxy platform for accessible, reproducible and collaborative biomedical analyses: 2018 update</article-title>. <source>Nucleic Acids Res</source>., <volume>46</volume>, <fpage>W537</fpage>–<lpage>W544</lpage>.<pub-id pub-id-type="pmid">29790989</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altschul</surname><given-names>S.F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1990</year>) 
<article-title>Basic local alignment search tool</article-title>. <source>J. Mol. Biol</source>., <volume>215</volume>, <fpage>403</fpage>–<lpage>410</lpage>.<pub-id pub-id-type="pmid">2231712</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B3">
      <mixed-citation publication-type="other">Anaconda Software Distribution. (<year>2020</year>) Anaconda Inc.</mixed-citation>
    </ref>
    <ref id="btaa950-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baker</surname><given-names>M.</given-names></string-name></person-group> (<year>2016</year>) 
<article-title>1,500 scientists lift the lid on reproducibility</article-title>. <source>Nature</source>, <volume>533</volume>, <fpage>452</fpage>–<lpage>454</lpage>.<pub-id pub-id-type="pmid">27225100</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bankevich</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) 
<article-title>SPAdes: a new genome assembly algorithm and its applications to single-cell sequencing</article-title>. <source>J. Comput. Biol</source>., <volume>19</volume>, <fpage>455</fpage>–<lpage>477</lpage>.<pub-id pub-id-type="pmid">22506599</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bolger</surname><given-names>A.M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) 
<article-title>Trimmomatic: a flexible trimmer for Illumina sequence data</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>2114</fpage>–<lpage>2120</lpage>.<pub-id pub-id-type="pmid">24695404</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B7">
      <mixed-citation publication-type="book">Bolyen,E. <source><italic toggle="yes">et al.</italic></source> (2019) Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2. <italic toggle="yes">Nat. Biotechnol.</italic>, <bold>37</bold>, 852–857.</mixed-citation>
    </ref>
    <ref id="btaa950-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cock</surname><given-names>P.J.A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2009</year>) 
<article-title>Biopython: freely available Python tools for computational molecular biology and bioinformatics</article-title>. <source>Bioinformatics</source>, <volume>25</volume>, <fpage>1422</fpage>–<lpage>1423</lpage>.<pub-id pub-id-type="pmid">19304878</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Coiera</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) 
<article-title>Does health informatics have a replication crisis?</article-title>  <source>J. Am. Med. Inform. Assoc</source>., <volume>25</volume>, <fpage>963</fpage>–<lpage>968</lpage>.<pub-id pub-id-type="pmid">29669066</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Davis-Turak</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) 
<article-title>Genomics pipelines and data integration: challenges and opportunities in the research setting</article-title>. <source>Expert Rev. Mol. Diagn</source>., <volume>17</volume>, <fpage>225</fpage>–<lpage>237</lpage>.<pub-id pub-id-type="pmid">28092471</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B11">
      <mixed-citation publication-type="other">Docker. (<year>2020</year>) Docker Inc.</mixed-citation>
    </ref>
    <ref id="btaa950-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Felsenstein</surname><given-names>J.</given-names></string-name></person-group> PHYLIP (Phylogeny Inference Package).</mixed-citation>
    </ref>
    <ref id="btaa950-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garijo</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) 
<article-title>Quantifying reproducibility in computational biology: the case of the tuberculosis drugome</article-title>. <source>PLoS One</source>, <volume>8</volume>, <fpage>e80278</fpage>.<pub-id pub-id-type="pmid">24312207</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goodstadt</surname><given-names>L.</given-names></string-name></person-group> (<year>2010</year>) 
<article-title>Ruffus: a lightweight Python library for computational pipelines</article-title>. <source>Bioinformatics</source>, <volume>26</volume>, <fpage>2778</fpage>–<lpage>2779</lpage>.<pub-id pub-id-type="pmid">20847218</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gordon</surname><given-names>A.</given-names></string-name></person-group> (<year>2014</year>) FASTX-toolkit.</mixed-citation>
    </ref>
    <ref id="btaa950-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kanwal</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) 
<article-title>Investigating reproducibility and tracking provenance – a genomic workflow case study</article-title>. <source>BMC Bioinformatics</source>, <volume>18</volume>, <fpage>337</fpage>.<pub-id pub-id-type="pmid">28701218</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katoh</surname><given-names>K.</given-names></string-name></person-group> (<year>2002</year>) 
<article-title>MAFFT: a novel method for rapid multiple sequence alignment based on fast Fourier transform</article-title>. <source>Nucleic Acids Res</source>., <volume>30</volume>, <fpage>3059</fpage>–<lpage>3066</lpage>.<pub-id pub-id-type="pmid">12136088</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>Y.-M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) 
<article-title>Experimenting with reproducibility: a case study of robustness in bioinformatics</article-title>. <source>GigaScience</source>, <volume>7</volume>, <fpage>giy077</fpage>.<pub-id pub-id-type="pmid">29961842</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Köster</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) 
<article-title>Snakemake—a scalable bioinformatics workflow engine</article-title>. <source>Bioinformatics</source>, <volume>28</volume>, <fpage>2520</fpage>–<lpage>2522</lpage>.<pub-id pub-id-type="pmid">22908215</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Leinonen</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) 
<article-title>The sequence read archive</article-title>. <source>Nucleic Acids Res</source>., <volume>39</volume>, <fpage>D19</fpage>–<lpage>D21</lpage>.<pub-id pub-id-type="pmid">21062823</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lewis</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) 
<article-title>Where next for the reproducibility agenda in computational biology?</article-title>  <source>BMC Syst. Biol</source>., <volume>10</volume>, <fpage>52</fpage>.<pub-id pub-id-type="pmid">27422148</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B22">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>H.</given-names></string-name></person-group> (<year>2011</year>) Bioawk.</mixed-citation>
    </ref>
    <ref id="btaa950-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>H.</given-names></string-name></person-group>  <etal>et al</etal>; 1000 Genome Project Data Processing Subgroup. (<year>2009</year>) 
<article-title>The Sequence alignment/map format and SAMtools</article-title>. <source>Bioinformatics</source>, <volume>25</volume>, <fpage>2078</fpage>–<lpage>2079</lpage>.<pub-id pub-id-type="pmid">19505943</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Quast</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) 
<article-title>The SILVA ribosomal RNA gene database project: improved data processing and web-based tools</article-title>. <source>Nucleic Acids Res</source>., <volume>41</volume>, <fpage>D590</fpage>–<lpage>D596</lpage>.<pub-id pub-id-type="pmid">23193283</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sadedin</surname><given-names>S.P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) 
<article-title>Bpipe: a tool for running and managing bioinformatics pipelines</article-title>. <source>Bioinf. Oxf. Engl</source>., <volume>28</volume>, <fpage>1525</fpage>–<lpage>1526</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa950-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Seemann</surname><given-names>T.</given-names></string-name></person-group> (<year>2014</year>) 
<article-title>Prokka: rapid prokaryotic genome annotation</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>2068</fpage>–<lpage>2069</lpage>.<pub-id pub-id-type="pmid">24642063</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stamatakis</surname><given-names>A.</given-names></string-name></person-group> (<year>2014</year>) 
<article-title>RAxML version 8: a tool for phylogenetic analysis and post-analysis of large phylogenies</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>1312</fpage>–<lpage>1313</lpage>.<pub-id pub-id-type="pmid">24451623</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Thompson</surname><given-names>J.D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1994</year>) 
<article-title>CLUSTAL W: improving the sensitivity of progressive multiple sequence alignment through sequence weighting, position-specific gap penalties and weight matrix choice</article-title>. <source>Nucleic Acids Res</source>., <volume>22</volume>, <fpage>4673</fpage>–<lpage>4680</lpage>.<pub-id pub-id-type="pmid">7984417</pub-id></mixed-citation>
    </ref>
    <ref id="btaa950-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>Script of Scripts: a pragmatic workflow system for daily computational research</article-title>. <source>PLoS Comput. Biol</source>., <volume>15</volume>, <fpage>e1006843</fpage>.<pub-id pub-id-type="pmid">30811390</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
