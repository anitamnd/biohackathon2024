<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Gigascience</journal-id>
    <journal-id journal-id-type="iso-abbrev">Gigascience</journal-id>
    <journal-id journal-id-type="publisher-id">gigascience</journal-id>
    <journal-title-group>
      <journal-title>GigaScience</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2047-217X</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7407261</article-id>
    <article-id pub-id-type="doi">10.1093/gigascience/giaa077</article-id>
    <article-id pub-id-type="publisher-id">giaa077</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Technical Note</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI00960</subject>
        <subject>AcademicSubjects/SCI02254</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>VariantSpark: Cloud-based machine learning for association study of complex phenotype and large-scale genomic data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-8799-7776</contrib-id>
        <name>
          <surname>Bayat</surname>
          <given-names>Arash</given-names>
        </name>
        <!--<email>ab.arashbayat@csiro.au</email>-->
        <aff><institution>Health and Biosecurity, Commonwealth Scientific and Industrial Research Organisation (CSIRO)</institution>, 11 Julius Ave North Ryde NSW 2113 <country country="AU">Australia</country></aff>
        <xref ref-type="corresp" rid="cor1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Szul</surname>
          <given-names>Piotr</given-names>
        </name>
        <aff><institution>Data61, Commonwealth Scientific and Industrial Research Organisation (CSIRO)</institution>, 5 Garden St Eveleigh NSW 2015 <country country="AU">Australia</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>O’Brien</surname>
          <given-names>Aidan R</given-names>
        </name>
        <aff><institution>Health and Biosecurity, Commonwealth Scientific and Industrial Research Organisation (CSIRO)</institution>, 11 Julius Ave North Ryde NSW 2113 <country country="AU">Australia</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dunne</surname>
          <given-names>Robert</given-names>
        </name>
        <aff><institution>Data61, Commonwealth Scientific and Industrial Research Organisation (CSIRO)</institution>, 5 Garden St Eveleigh NSW 2015 <country country="AU">Australia</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hosking</surname>
          <given-names>Brendan</given-names>
        </name>
        <aff><institution>Health and Biosecurity, Commonwealth Scientific and Industrial Research Organisation (CSIRO)</institution>, 11 Julius Ave North Ryde NSW 2113 <country country="AU">Australia</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jain</surname>
          <given-names>Yatish</given-names>
        </name>
        <aff><institution>Health and Biosecurity, Commonwealth Scientific and Industrial Research Organisation (CSIRO)</institution>, 11 Julius Ave North Ryde NSW 2113 <country country="AU">Australia</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hosking</surname>
          <given-names>Cameron</given-names>
        </name>
        <aff><institution>Health and Biosecurity, Commonwealth Scientific and Industrial Research Organisation (CSIRO)</institution>, 11 Julius Ave North Ryde NSW 2113 <country country="AU">Australia</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Luo</surname>
          <given-names>Oscar J</given-names>
        </name>
        <aff><institution>Department of Systems Biomedical Sciences, School of Medicine, Jinan University</institution>, 601 Huangpu Ave, Guangzhou, Guangdong Province, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Twine</surname>
          <given-names>Natalie</given-names>
        </name>
        <aff><institution>Health and Biosecurity, Commonwealth Scientific and Industrial Research Organisation (CSIRO)</institution>, 11 Julius Ave North Ryde NSW 2113 <country country="AU">Australia</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-8033-9810</contrib-id>
        <name>
          <surname>Bauer</surname>
          <given-names>Denis C</given-names>
        </name>
        <!--<email>denis.bauer@csiro.au</email>-->
        <aff><institution>Health and Biosecurity, Commonwealth Scientific and Industrial Research Organisation (CSIRO)</institution>, 11 Julius Ave North Ryde NSW 2113 <country country="AU">Australia</country></aff>
        <aff><institution>Department of Biomedical Sciences,</institution> Macquarie University NSW 2109 <country country="AU">Australia</country></aff>
        <xref ref-type="corresp" rid="cor2"/>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="cor1">Correspondence address. Arash Bayat, Health and Biosecurity, Commonwealth Scientific and Industrial Research Organisation (CSIRO), Australia. E-mail: <email>ab.arashbayat@csiro.au</email></corresp>
      <corresp id="cor2">Correspondence address. Denis C. Bauer, Health and Biosecurity, Commonwealth Scientific and Industrial Research Organisation (CSIRO), Australia. E-mail: <email>denis.bauer@csiro.au</email></corresp>
    </author-notes>
    <pub-date pub-type="epub" iso-8601-date="2020-08-06">
      <day>06</day>
      <month>8</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>8</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>06</day>
      <month>8</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>9</volume>
    <issue>8</issue>
    <elocation-id>giaa077</elocation-id>
    <history>
      <date date-type="received">
        <day>26</day>
        <month>9</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>01</day>
        <month>5</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="giaa077.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="abs1">
        <title>Background</title>
        <p>Many traits and diseases are thought to be driven by &gt;1 gene (polygenic). Polygenic risk scores (PRS) hence expand on genome-wide association studies by taking multiple genes into account when risk models are built. However, PRS only considers the additive effect of individual genes but not epistatic interactions or the combination of individual and interacting drivers. While evidence of epistatic interactions ais found in small datasets, large datasets have not been processed yet owing to the high computational complexity of the search for epistatic interactions.</p>
      </sec>
      <sec id="abs2">
        <title>Findings</title>
        <p>We have developed VariantSpark, a distributed machine learning framework able to perform association analysis for complex phenotypes that are polygenic and potentially involve a large number of epistatic interactions. Efficient multi-layer parallelization allows VariantSpark to scale to the whole genome of population-scale datasets with 100,000,000 genomic variants and 100,000 samples.</p>
      </sec>
      <sec id="abs3">
        <title>Conclusions</title>
        <p>Compared with traditional monogenic genome-wide association studies, VariantSpark better identifies genomic variants associated with complex phenotypes. VariantSpark is 3.6 times faster than ReForeSt and the only method able to scale to ultra-high-dimensional genomic data in a manageable time.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Commonwealth Scientific and Industrial Research Organisation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000943</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="12"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Findings</title>
    <p>Traditional genome-wide association studies (GWAS) evaluate genomic variants (referred to hereinafter as “variants") across the genomes of many samples for statistical association with the phenotype in question. These studies are aimed at detecting variants associated with common and complex traits and diseases, such as heart disease, diabetes, and height [<xref rid="bib1" ref-type="bibr">1</xref>]. GWAS has been successful at identifying &gt;50,000 associated variants in thousands of complex phenotypes (GWAS catalog [<xref rid="bib2" ref-type="bibr">2</xref>]). Yet, many phenotypes with genetic components remain only partially explained by genetics, the so-called missing heritability problem [<xref rid="bib3" ref-type="bibr">3</xref>].</p>
    <p>One possible explanation is that these phenotypes are driven by an additive effect of several variants (“polygenic phenotype"), resulting in a small association power for each variant [<xref rid="bib4" ref-type="bibr">4–7</xref>]. Polygenic risk score (PRS) takes into account this additive effect to compute the genomic risk factor for a trait [<xref rid="bib8" ref-type="bibr">8</xref>]. PRS refers to a range of statistical methods that consider the GWAS association power as a weight for the variant. Given the weight and the risk allele for each variant, PRS computes the genomic risk factor for a given sample [<xref rid="bib9" ref-type="bibr">9</xref>]. For many phenotypes, PRS is shown to be a more accurate predictor of risk than single variants alone [<xref rid="bib10" ref-type="bibr">10</xref>], which statistically supports the idea of the phenotype being polygenic.</p>
    <p>Another explanation is the existence of epistatic interaction (referred to hereinafter as “interaction") between sets of variants [<xref rid="bib11" ref-type="bibr">11</xref>] (“epistatic phenotype"). In an interaction, the combination of ≥2 variants highly correlate with the phenotype but individual variants do not show a strong correlation with the phenotype. Thus the phenotype cannot be explained by the individual variants. Variant interactions remain invisible to traditional GWAS and subsequently to PRS methods. Several algorithms have been developed to speed up the search for the interactions [<xref rid="bib12" ref-type="bibr">12</xref>,<xref rid="bib13" ref-type="bibr">13</xref>], and they have been successful to identify significant statistical interactions [<xref rid="bib14" ref-type="bibr">14</xref>]. There is also evidence that interactions are biologically relevant [<xref rid="bib15" ref-type="bibr">15</xref>]. However, the high computational complexity of these methods prevents them from being applied to whole-genome data. Pruning the dataset is an option but does not guarantee to preserve all the interacting variants.</p>
    <p>Given that there is statistical proof for the existence of both polygenic phenotype and epistatic phenotype, there is a likelihood of a complex phenotype to exist—a phenotype that is driven by several variants individually as well as several sets of interactive variants. A novel association approach is hence needed to take into account the individual variant association power, as well as the association power driven by the interactive variants. Furthermore, such a methodology needs to be applicable to genomic-scale data. Taking all variants into account reduces the chance of missing important interactions. Note that the association of interactive variants is only visible when all of them are combined. The computational complexity of such analyses made them infeasible in the past; however, combining more efficient algorithms with parallel computing resources has opened up a new avenue.</p>
    <p>One promising algorithm to use is random forest (RF) [<xref rid="bib16" ref-type="bibr">16</xref>], which is a machine learning approach used in many modern bioinformatics analyses [<xref rid="bib17" ref-type="bibr">17</xref>] including genomics [<xref rid="bib18" ref-type="bibr">18–20</xref>]. It is designed to identify interactions between the given features (variants in the context of GWAS) and incorporate them into a prediction model. RF also computes a metric for each variant called “importance score" that is an indicator of the association power for a variant. Importance score combines individual and interaction association power into a single value. Thus RF is a perfect candidate for the association study of a complex phenotype. The randomness in the RF model is the key to avoid over-fitting, making it a robust method. Unlike black box models such as deep learning [<xref rid="bib21" ref-type="bibr">21</xref>], the RF model is readable and can be used to extract important rules and identify interactive features. Even though RF is not a deterministic algorithm, it is an accurate approximation with a manageable computational requirement.</p>
    <p>There are 2 layers of parallelization to speed up an algorithm: multi-threading and distributed computing. The former is a common approach that allows programmers to use all processors and memory available in a single computer, usually a high-performance computer (HPC). The latter allows a program to be executed in parallel on multiple independent computers connected by a network (known as a computer cluster, referred to hereinafter as a “cluster"). Given that the network is far slower than processors and memory, it is critical to implement the program in a way that reduces network operation and avoid a potential bottleneck. Apache Spark [<xref rid="bib22" ref-type="bibr">22</xref>] (referred to hereinafter as “Spark") is a widely used platform for distributed computing. Distributed computing is a potential solution [<xref rid="bib23" ref-type="bibr">23</xref>] to overcome the ever-increasing quantity of genomic data, exceeding astronomical data in volume [<xref rid="bib24" ref-type="bibr">24</xref>].</p>
    <p>Here, we introduce VariantSpark, a Spark-based software package for association study of complex phenotypes and genomic-scale datasets. VariantSpark is the first publicly available distributed implementation of RF with the following features to reduce networking, to maximize resource utilization, and to suit genomic datasets:</p>
    <list list-type="bullet">
      <list-item>
        <p>Vertical data partitioning</p>
      </list-item>
      <list-item>
        <p>Processing multiple nodes of multiple trees in parallel</p>
      </list-item>
      <list-item>
        <p>Efficiently storing genomic data in fast and a low-level Spark memory structure (Resilient Distributed Dataset [RDD])</p>
      </list-item>
    </list>
    <p>The wider VariantSpark software suite implements k-means clustering and is compatible with standard genomic data formats (e.g., VCF), and is integrated with Hail [<xref rid="bib25" ref-type="bibr">25</xref>] to offer a range of other standard genomic analyses in a distributed manner. To assess VariantSpark’s capability we compare it against the state-of-the-art bioinformatics implementation of RF, as well as the latest application-agnostic distributed implementations of RF. Ranger [<xref rid="bib26" ref-type="bibr">26</xref>] is one of the fastest multi-threaded RFs, written in C++. As reported by its developer, Ranger is 180 times faster than the parallel version of the widely used randomForest R package [<xref rid="bib27" ref-type="bibr">27</xref>] and requires 3.5 times less memory. It is also 2.2 and 2.6 times faster than randomForestSRC [<xref rid="bib28" ref-type="bibr">28</xref>] and Random-Jungle [<xref rid="bib29" ref-type="bibr">29</xref>], respectively. Ranger also implements a save-memory mode that is 1.6 times slower than normal mode but requires half the memory. To the best of our knowledge, no other multi-threaded RF claimed to be faster than Ranger. Despite this, processing data from whole-genome sequencing [<xref rid="bib30" ref-type="bibr">30</xref>] remains practically impossible using this method. RF needs to maintain the complete dataset decompressed in memory. So a dataset of 100 million variants and 10,000 samples requires 1 TB of memory (assuming 1 byte per genotype), which is unlikely available on standard HPC.</p>
    <p>A cluster, on the other hand, can easily scale to hold hundreds of terabytes of data (as most cloud providers can supply). The most popular distributed implementation of RF is Google’s PLANET [<xref rid="bib31" ref-type="bibr">31</xref>], which is integrated into the Spark machine learning library (MLlib) [<xref rid="bib32" ref-type="bibr">32</xref>]. PLANET uses horizontal partitioning, which is a parallelization along the wrong dimension because it does not allow high-dimensional data to be loaded into memory as required for random access by the RF algorithm. PLANET is faster than the randomForest R package, with comparisons to other implementations provided in Bayat et al. [<xref rid="bib33" ref-type="bibr">33</xref>]. ReForeSt [<xref rid="bib34" ref-type="bibr">34</xref>] is, to the best of our knowledge, the fastest distributed implementation of RF and is up to 3 times faster than MLlib (PLANET). ReForeSt uses similar partitioning as in Spark MLl, extends a machine learning benchmark study [<xref rid="bib35" ref-type="bibr">35</xref>], and was shown to be faster than XGBOOST [<xref rid="bib36" ref-type="bibr">36</xref>] and H2O [<xref rid="bib37" ref-type="bibr">37</xref>] for the largest dataset in the study (10M) [<xref rid="bib38" ref-type="bibr">38</xref>]. Parallel Random Forest (PRF) [<xref rid="bib39" ref-type="bibr">39</xref>] is another distributed RF that takes a vertical partitioning approach and claims to be twice as fast as MLlib. The implementation has not been released and hence could not be included in our comparison. The only other relevant distributed algorithm that also implements vertical partitioning relevant for high-dimensional data is Yggdrasil [<xref rid="bib40" ref-type="bibr">40</xref>]. Yet, Yggdrasil is limited to Decision Tree [<xref rid="bib41" ref-type="bibr">41</xref>] (DT) and does not expand to build an RF mode. However, none of these tools were tested in ultra-high-dimensional data, which we define as datasets with &gt;10M features.</p>
    <p>Here, we first compare the performance of VariantSpark with the approach used in traditional GWAS, logistic regression (LR) [<xref rid="bib42" ref-type="bibr">42</xref>]. We consider various simulated phenotypes, including complex phenotypes, and different-sized datasets, to compare the tools’ ability to detect associated variants. Then we compare VariantSpark’s runtime with Ranger, ReForeSt, and Yggdrasil. Finally, we demonstrate the scalability of VariantSpark and evaluate sensitivity to hyper-parameter choices.</p>
    <sec id="sec1-1">
      <title>Datasets</title>
      <p>Two different sets of synthetic datasets are used in this study, both of which are publicly available [<xref rid="bib43" ref-type="bibr">43</xref>] for the replication of this study (see <xref ref-type="supplementary-material" rid="sup15">Supplementary Data File 4</xref>). The first set uses real genotypes taken from the 1000-Genomes (1KG) Project [<xref rid="bib44" ref-type="bibr">44</xref>] and a simulated phenotype made by Polygenic Epistatic Phenotype Simulator (PEPS) [<xref rid="bib45" ref-type="bibr">45</xref>]. In the second set, both genotype and phenotype are simulated by VariantSpark’s embedded simulator. The phenotype is a function of 5 randomly selected variants and a given noise parameter.</p>
      <sec id="h3content1594050591166">
        <title>Real genotype and simulated phenotype</title>
        <p>We use these datasets to compare the accuracy of VariantSpark with LR. A set of phenotypes are simulated for 1KG samples using PEPS that uses real genotype data and simulates a binary phenotype associated with a subset of randomly selected variants.</p>
        <p>PEPS first forms <italic>n</italic>-way truth-variables, which are used to simulate the phenotype. A variable could be an individual variant (1-way variable) or set of <italic>n</italic> variants with epistatic interaction (<italic>n</italic>-way variable), so 2-way variables are pairwise epistatic interactions; 3-, 4-, and 5-way variables are higher-order epistatic interactions. Each variant is involved in only 1 variable. Variants involved in truth-variables (associated with the phenotype) are called truth-variants (TVs) and are to be discovered by VariantSpark or LR.</p>
        <p>Table <xref rid="tbl1" ref-type="table">1</xref> lists 9 PEPS simulated phenotypes (provided in <xref ref-type="supplementary-material" rid="sup15">Supplementary Data File 3</xref>) in 3 categories: PI, PE, and PX. PI phenotypes are made of only 1-way variables (individual variant). PE phenotypes are made of 2-way or higher-order variables (epistatic variables only). PX phenotypes include epistatic and individual variables (complex phenotype). In each category, there are 3 phenotypes with low (L), moderate (M), and high (H) number of TVs.</p>
        <table-wrap id="tbl1" orientation="portrait" position="float">
          <label>Table 1:</label>
          <caption>
            <p>Nine phenotypes simulated with PEPS</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th rowspan="2" colspan="1">Phenotype name</th>
                <th rowspan="2" align="center" colspan="1">Category</th>
                <th colspan="5" align="center" rowspan="1">No. of <italic>n</italic>-way truth-variables</th>
                <th colspan="2" align="center" rowspan="1">Total No.</th>
              </tr>
              <tr>
                <th align="center" rowspan="1" colspan="1">1-way</th>
                <th align="center" rowspan="1" colspan="1">2-way</th>
                <th align="center" rowspan="1" colspan="1">3-way</th>
                <th align="center" rowspan="1" colspan="1">4-way</th>
                <th align="center" rowspan="1" colspan="1">5-way</th>
                <th align="center" rowspan="1" colspan="1">Truth-variables</th>
                <th align="center" rowspan="1" colspan="1">Truth-variants</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">PIL</td>
                <td rowspan="1" colspan="1">PI</td>
                <td rowspan="1" colspan="1">5</td>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">0</td>
                <td align="right" rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">5</td>
                <td rowspan="1" colspan="1">5</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PIM</td>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">50</td>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">0</td>
                <td align="right" rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">50</td>
                <td rowspan="1" colspan="1">50</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PIH</td>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">500</td>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">0</td>
                <td align="right" rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">500</td>
                <td rowspan="1" colspan="1">500</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PEL</td>
                <td rowspan="1" colspan="1">PE</td>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">2</td>
                <td rowspan="1" colspan="1">2</td>
                <td rowspan="1" colspan="1">2</td>
                <td align="right" rowspan="1" colspan="1">2</td>
                <td rowspan="1" colspan="1">8</td>
                <td rowspan="1" colspan="1">28</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PEM</td>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">20</td>
                <td rowspan="1" colspan="1">20</td>
                <td rowspan="1" colspan="1">20</td>
                <td align="right" rowspan="1" colspan="1">20</td>
                <td rowspan="1" colspan="1">80</td>
                <td rowspan="1" colspan="1">280</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PEH</td>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">50</td>
                <td rowspan="1" colspan="1">50</td>
                <td rowspan="1" colspan="1">50</td>
                <td align="right" rowspan="1" colspan="1">50</td>
                <td rowspan="1" colspan="1">200</td>
                <td rowspan="1" colspan="1">700</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PXL</td>
                <td rowspan="1" colspan="1">PX</td>
                <td rowspan="1" colspan="1">5</td>
                <td rowspan="1" colspan="1">3</td>
                <td rowspan="1" colspan="1">2</td>
                <td rowspan="1" colspan="1">1</td>
                <td align="right" rowspan="1" colspan="1">1</td>
                <td rowspan="1" colspan="1">12</td>
                <td rowspan="1" colspan="1">26</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PXM</td>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">50</td>
                <td rowspan="1" colspan="1">25</td>
                <td rowspan="1" colspan="1">17</td>
                <td rowspan="1" colspan="1">13</td>
                <td align="right" rowspan="1" colspan="1">10</td>
                <td rowspan="1" colspan="1">115</td>
                <td rowspan="1" colspan="1">253</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PXH</td>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">500</td>
                <td rowspan="1" colspan="1">250</td>
                <td rowspan="1" colspan="1">167</td>
                <td rowspan="1" colspan="1">125</td>
                <td align="right" rowspan="1" colspan="1">100</td>
                <td rowspan="1" colspan="1">1,142</td>
                <td rowspan="1" colspan="1">2,501</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>The 1KG dataset consists of 2,504 samples and ∼80M variants with multi-allelic variants converted to multiple bi-allelic variants. We generate 4 subsets of this dataset by randomly selecting variants, 2 by adding the TVs of all phenotypes back if they were removed by this process (see Table <xref rid="tbl2" ref-type="table">2</xref>).</p>
        <table-wrap id="tbl2" orientation="portrait" position="float">
          <label>Table 2:</label>
          <caption>
            <p>1000-Genome dataset and its subsets</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Dataset</th>
                <th align="center" rowspan="1" colspan="1">No. of variants</th>
                <th align="center" rowspan="1" colspan="1">% of truth-variants Included</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">1KG-80M</td>
                <td rowspan="1" colspan="1">81,647,203</td>
                <td rowspan="1" colspan="1">100</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">1KG-5M</td>
                <td rowspan="1" colspan="1">5,000,516</td>
                <td rowspan="1" colspan="1">6.1</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">1KG-500K</td>
                <td rowspan="1" colspan="1">500,446</td>
                <td rowspan="1" colspan="1">0.6</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">1KG-5M-T</td>
                <td rowspan="1" colspan="1">5,016,789</td>
                <td rowspan="1" colspan="1">100</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">1KG-500K-T</td>
                <td rowspan="1" colspan="1">517,729</td>
                <td rowspan="1" colspan="1">100</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="req-159406790056625090">
              <p>There are 2,504 samples in these datasets.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec id="h3content1594050625938">
        <title>Simulated Genotype and Simulated Phenotype</title>
        <p>These datasets, listed in Table <xref rid="tbl3" ref-type="table">3</xref>, are used for the runtime analysis of VariantSpark. We start from 1,000 samples and 10,000 variants and increase the number of samples or variants 10 times at each step to reach either 100,000 samples and 10,000,000 or 10,000 samples and 100,000,000 variants. These genotypes are simulated with random distribution of phenotypes using the VariantSpark gen-features command.</p>
        <table-wrap id="tbl3" orientation="portrait" position="float">
          <label>Table 3:</label>
          <caption>
            <p>Synthetic datasets generated by VariantSpark</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th rowspan="2" colspan="1"> Dataset</th>
                <th rowspan="2" colspan="1"> Size</th>
                <th colspan="3" align="center" rowspan="1">No.</th>
              </tr>
              <tr>
                <th align="center" rowspan="1" colspan="1">Samples (nS)</th>
                <th align="center" rowspan="1" colspan="1">Variants (nV)</th>
                <th align="center" rowspan="1" colspan="1">Genotypes nS × nV</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">1K-10K</td>
                <td rowspan="1" colspan="1">10M</td>
                <td rowspan="1" colspan="1">1,000</td>
                <td rowspan="1" colspan="1">10,000</td>
                <td rowspan="1" colspan="1">1e7</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">1K-100K</td>
                <td rowspan="1" colspan="1">100M</td>
                <td rowspan="1" colspan="1">1,000</td>
                <td rowspan="1" colspan="1">100,000</td>
                <td rowspan="1" colspan="1">1e8</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">1K-1M</td>
                <td rowspan="1" colspan="1">1B</td>
                <td rowspan="1" colspan="1">1,000</td>
                <td rowspan="1" colspan="1">1,000,000</td>
                <td rowspan="1" colspan="1">1e9</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">1K-10M</td>
                <td rowspan="1" colspan="1">10B</td>
                <td rowspan="1" colspan="1">1,000</td>
                <td rowspan="1" colspan="1">10,000,000</td>
                <td rowspan="1" colspan="1">1e10</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">1K-100M</td>
                <td rowspan="1" colspan="1">100B</td>
                <td rowspan="1" colspan="1">1,000</td>
                <td rowspan="1" colspan="1">100,000,000</td>
                <td rowspan="1" colspan="1">1e11</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">10K-10K</td>
                <td rowspan="1" colspan="1">100M</td>
                <td rowspan="1" colspan="1">10,000</td>
                <td rowspan="1" colspan="1">10,000</td>
                <td rowspan="1" colspan="1">1e8</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">10K-100K</td>
                <td rowspan="1" colspan="1">1B</td>
                <td rowspan="1" colspan="1">10,000</td>
                <td rowspan="1" colspan="1">100,000</td>
                <td rowspan="1" colspan="1">1e9</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">10K-1M</td>
                <td rowspan="1" colspan="1">10B</td>
                <td rowspan="1" colspan="1">10,000</td>
                <td rowspan="1" colspan="1">1,000,000</td>
                <td rowspan="1" colspan="1">1e10</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">10K-10M</td>
                <td rowspan="1" colspan="1">100B</td>
                <td rowspan="1" colspan="1">10,000</td>
                <td rowspan="1" colspan="1">10,000,000</td>
                <td rowspan="1" colspan="1">1e11</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">10K-100M</td>
                <td rowspan="1" colspan="1">1T</td>
                <td rowspan="1" colspan="1">10,000</td>
                <td rowspan="1" colspan="1">100,000,000</td>
                <td rowspan="1" colspan="1">1e12</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">100K-10K</td>
                <td rowspan="1" colspan="1">1B</td>
                <td rowspan="1" colspan="1">100,000</td>
                <td rowspan="1" colspan="1">10,000</td>
                <td rowspan="1" colspan="1">1e9</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">100K-100K</td>
                <td rowspan="1" colspan="1">10B</td>
                <td rowspan="1" colspan="1">100,000</td>
                <td rowspan="1" colspan="1">100,000</td>
                <td rowspan="1" colspan="1">1e10</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">100K-1M</td>
                <td rowspan="1" colspan="1">100B</td>
                <td rowspan="1" colspan="1">100,000</td>
                <td rowspan="1" colspan="1">1,000,000</td>
                <td rowspan="1" colspan="1">1e11</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">100K-10M</td>
                <td rowspan="1" colspan="1">1T</td>
                <td rowspan="1" colspan="1">100,000</td>
                <td rowspan="1" colspan="1">10,000,000</td>
                <td rowspan="1" colspan="1">1e12</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>The phenotype is simulated using VariantSpark gen-label commands and based on 5 randomly selected variants all with equal contributions (all weights are set to 1.0). To make a more complex phenotype, the mean and the standard deviation of the noise, <italic>-</italic>gm and <italic>-</italic>gs parameters, respectively, are both set to 0.5. The fraction of noise variants, <italic>-</italic>gvf parameter, is set to 100/nV to include 100 noise variants (randomly selected from the variants in the dataset).</p>
        <p>For the comparison to other tools, we subset variants from the 10K-10M dataset and include the 5 TVs in all subsets. We start from 100 variants and double it at each step. These datasets are listed in Table <xref rid="tbl4" ref-type="table">4</xref>.</p>
        <table-wrap id="tbl4" orientation="portrait" position="float">
          <label>Table 4:</label>
          <caption>
            <p>Datasets for high-resolution comparison of the VariantSpark runtime with other implementations of RF</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Dataset</th>
                <th align="center" rowspan="1" colspan="1">No. of variants (nV)</th>
                <th rowspan="1" colspan="1">Dataset</th>
                <th align="center" rowspan="1" colspan="1">No. of variants (nV)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">1X</td>
                <td rowspan="1" colspan="1">100</td>
                <td rowspan="1" colspan="1">512X</td>
                <td rowspan="1" colspan="1">51,200</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">2X</td>
                <td rowspan="1" colspan="1">200</td>
                <td rowspan="1" colspan="1">1KX</td>
                <td rowspan="1" colspan="1">102,400</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">4X</td>
                <td rowspan="1" colspan="1">400</td>
                <td rowspan="1" colspan="1">2KX</td>
                <td rowspan="1" colspan="1">204,800</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">8X</td>
                <td rowspan="1" colspan="1">800</td>
                <td rowspan="1" colspan="1">4KX</td>
                <td rowspan="1" colspan="1">409,600</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">16X</td>
                <td rowspan="1" colspan="1">1,600</td>
                <td rowspan="1" colspan="1">8KX</td>
                <td rowspan="1" colspan="1">819,200</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">32X</td>
                <td rowspan="1" colspan="1">3,200</td>
                <td rowspan="1" colspan="1">16KX</td>
                <td rowspan="1" colspan="1">1,638,400</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">64X</td>
                <td rowspan="1" colspan="1">6,400</td>
                <td rowspan="1" colspan="1">32KX</td>
                <td rowspan="1" colspan="1">3,276,800</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">128X</td>
                <td rowspan="1" colspan="1">12,800</td>
                <td rowspan="1" colspan="1">64KX</td>
                <td rowspan="1" colspan="1">6,553,600</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">256X</td>
                <td rowspan="1" colspan="1">25,600</td>
                <td rowspan="1" colspan="1">10M</td>
                <td rowspan="1" colspan="1">10,000,000</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="req-159406828283525090">
              <p>X represents 100 and KX represents 102,400. 10M is identical to the 10K-10M dataset. Each dataset includes 10,000 samples.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
    </sec>
    <sec id="sec1-2">
      <title>Compute resources</title>
      <p>For reproducibility, all tests are performed on Amazon Web Services (AWS) compute resources. We use AWS EC2 (Elastic Compute Cloud) and EMR (Elastic Map Reduce) for HPC and cluster compute, respectively. We use clusters of different sizes listed in Table <xref rid="tbl5" ref-type="table">5</xref>. For all clusters, the master-node is an r4.2xlarge EC2 instance with 8 virtual central processing unit (vCPU) and 61 GB of memory. Compute-nodes are r4.4xlarge with 16 vCPU and 122 GB of memory except for C256-S and C256-L, where we use r4.2xlare and r4.8xlarge EC2 instances as compute-nodes. The r4.8xlarge has 32 vCPU and 244 GB of memory.</p>
      <table-wrap id="tbl5" orientation="portrait" position="float">
        <label>Table 5:</label>
        <caption>
          <p>EMR clusters and compute-nodes</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th rowspan="2" colspan="1">Cluster</th>
              <th rowspan="2" align="center" colspan="1">Compute-nodes</th>
              <th colspan="2" rowspan="1">Master + compute</th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">vCPU</th>
              <th rowspan="1" colspan="1">Memory (GB)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">C16</td>
              <td rowspan="1" colspan="1">1 × r4.4xlarge</td>
              <td rowspan="1" colspan="1">8 + 16</td>
              <td rowspan="1" colspan="1">61 + 122</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">C32</td>
              <td rowspan="1" colspan="1">2 × r4.4xlarge</td>
              <td rowspan="1" colspan="1">8 + 32</td>
              <td rowspan="1" colspan="1">61 + 244</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">C64</td>
              <td rowspan="1" colspan="1">4 × r4.4xlarge</td>
              <td rowspan="1" colspan="1">8 + 64</td>
              <td rowspan="1" colspan="1">61 + 488</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">C128</td>
              <td rowspan="1" colspan="1">8 × r4.4xlarge</td>
              <td rowspan="1" colspan="1">8 + 128</td>
              <td rowspan="1" colspan="1">61 + 976</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">C256</td>
              <td rowspan="1" colspan="1">16 × r4.4xlarge</td>
              <td rowspan="1" colspan="1">8 + 256</td>
              <td rowspan="1" colspan="1">61 + 1,952</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">C512</td>
              <td rowspan="1" colspan="1">32 × r4.4xlarge</td>
              <td rowspan="1" colspan="1">8 + 512</td>
              <td rowspan="1" colspan="1">61 + 3,904</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">C1024</td>
              <td rowspan="1" colspan="1">64 × r4.4xlarge</td>
              <td rowspan="1" colspan="1">8 + 1,024</td>
              <td rowspan="1" colspan="1">61 + 7,808</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">C256-S</td>
              <td rowspan="1" colspan="1">32 × r4.2xlarge</td>
              <td rowspan="1" colspan="1">8 + 256</td>
              <td rowspan="1" colspan="1">61 + 1,952</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">C256-L</td>
              <td rowspan="1" colspan="1">8 × r4.8xlarge</td>
              <td rowspan="1" colspan="1">8 + 256</td>
              <td rowspan="1" colspan="1">61 + 1,952</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="sec1-3">
      <title>Experimental set-up</title>
      <p>The combination of 9 phenotypes described in Table <xref rid="tbl1" ref-type="table">1</xref> and 5 genotype datasets described in Table <xref rid="tbl2" ref-type="table">2</xref> results in 9 × 5 = 45 case/control datasets, which we process with both VariantSpark and LR Wald test implemented in Hail. We pass the first 2 principal component analysis vectors as co-variate to LR. VariantSpark uses the following parameters for this experiment: nTree = 1,000, mTry = 0.1 × nV, maxD = 15, and minNS = 50.</p>
      <p>We ranked the variants on the basis of <italic>P</italic>-value computed by LR and importance score computed by VariantSpark. We replicates the experiments 3 times (similar phenotypes are simulated but different randomly selected TVs are used to form the phenotype). In the last 2 replicates, we did not process the 1KG-80M dataset with VariantSpark owing to high computational cost. Owing to technical issues, the VariantSpark results for PIL on 1KG-80M were missed for the first replicate.</p>
      <p>VariantSpark and ReForeSt are executed on a C256 cluster while Ranger is executed on r4.16xlarge computer with 64 vCPU and 488 GB of memory, which is the practical limit of HPC. We apply maxD = 15 and minNS = 50 where applicable and build 1,000 trees (nTree = 1,000) with mTry = 0.1 × nV. We build a DT with Yggdrasil 10 times. For VariantSpark we build a forest with 10 trees and set mTry = nV because this parameter setting mimics growing a DT.</p>
      <p>When testing VariantSpark’s scalability the following parameters were applied to all experiments below, unless mentioned otherwise: maxD = 15, minNS = 50, mTry = 0.1 × nV, and rbs = 100 (grow 100 trees in parallel).</p>
      <list list-type="bullet">
        <list-item>
          <p>Dataset size: The expected runtime to build 1,000 trees for all datasets in Table <xref rid="tbl3" ref-type="table">3</xref> on C256 cluster. Because the actual runtime is too high for larger datasets, we build fewer trees (i.e., 500, 100, or 10) and record the data load time (β) and average train time per tree (θ) reported by VariantSpark. The expected runtime for 1,000 trees is computed as β + (1,000 × θ). The exact number of trees for each dataset and the un-normalized runtime can be found in <xref ref-type="supplementary-material" rid="sup15">Supplementary Data File 1</xref>.</p>
        </list-item>
        <list-item>
          <p>Cluster size: 500 trees are built for 10K-1M dataset on clusters of different sizes (see Table <xref rid="tbl5" ref-type="table">5</xref>). We also replicate this experiment for a 10 times larger dataset (10K-10M) but only on C256, C512, and C1024 clusters.</p>
        </list-item>
        <list-item>
          <p>Compute-node size: 1,000 trees are built for 10K-1M dataset on C256-S, C256, and C256-L. This experiment is replicated 3 times to show that VariantSpark runtime variation is negligible.</p>
        </list-item>
        <list-item>
          <p>Batch size (rbs): 500 trees are built for 10K-1M dataset with rbs equal to 10, 50, 100, or 500.</p>
        </list-item>
      </list>
      <p>The following experiments are performed to show the effect of different parameters on the VariantSpark runtime and out-of-bag (OOB) error rate (prediction accuracy) when processing the 10K-1M dataset.</p>
      <list list-type="bullet">
        <list-item>
          <p>Unlimited: 500 trees are built with no limits on the depth of the tree or the node size.</p>
        </list-item>
        <list-item>
          <p>Maximum depth (maxD): 500 trees are built with no limits on the node size but the maxD varies as follows: 3, 5, 7, 9, 11, 13, 15, 20, 25, 100.</p>
        </list-item>
        <list-item>
          <p>Minimum node size (minNS): 500 trees are built with no limits on depth of the trees but the minNS varies as follows: 5, 10, 50, 100, 500, 1,000.</p>
        </list-item>
        <list-item>
          <p>mTry: 500 trees are built with the mTry varying as follows: 10, 50, 100, 500, 1,000, 5,000, 10,000, 100,000.</p>
        </list-item>
        <list-item>
          <p>nTree: Starting from 100 trees and doubling the number of trees up to 1,600 trees.</p>
        </list-item>
      </list>
    </sec>
    <sec id="sec1-4">
      <title>Result 1: VariantSpark detects complex genomic interactions</title>
      <p>We compare the performance of VariantSpark with LR using phenotypes of different complexity and different sized datasets. First, we report how many TVs, i.e., variants associated with the phenotype, can be detected by the respective approaches.</p>
      <p>Fig. <xref ref-type="fig" rid="fig1">1a</xref> shows the fraction of TVs found in the top <italic>r</italic> ranked-variants (RVs) for all phenotype categories (see Table <xref rid="tbl1" ref-type="table">1</xref>) and dataset sizes. More TVs can be detected with higher value of <italic>r</italic>, so we let <italic>r</italic> vary between <italic>t</italic>, 2<italic>t</italic>, 5<italic>t</italic>, and 10<italic>t</italic>, where <italic>t</italic> is the number of TVs (note, <italic>t</italic> is different for each phenotype). We do not consider the order of variants in the list of RVs. All experiments were replicated 3 times. We highlight results from the first replicate for 1KG-80M (2,504 samples and 80M features), 1KG-5M-T (5M variants subset including all truth variants), and 1KG-500K-T here, but other results (second and third replicates, as well as 1KG-5M and 1KG-500K subsets) are reported in <xref ref-type="supplementary-material" rid="sup15">Supplementary Data File 1</xref> and support the same conclusion.</p>
      <fig id="fig1" orientation="portrait" position="float">
        <label>Figure 1:</label>
        <caption>
          <p>VariantSpark comparison with Logistic-Regression on their ability to detect phenotype-associated variants. Phenotype labels (i.e., PIL, PIM, ...) are described in Table <xref rid="tbl1" ref-type="table">1</xref>.</p>
        </caption>
        <graphic xlink:href="giaa077fig1"/>
      </fig>
      <p>Ideally, all TVs are expected to be listed in the top <italic>t</italic> RVs, resulting in a maximum value of 1. VariantSpark indeed achieves this for 2 datasets (1KG-500K-T, 1KG-5M-T) and phenotypes with low numbers of individually associated variables (PIL). LR, on the other hand, only detects all TVs in the smaller of these 2 datasets and only when expanding the list to the top 2<italic>t</italic> RVs.</p>
      <p>More generally, VariantSpark detects either more TV or an equivalent proportion for most phenotypes and data set sizes. VariantSpark especially outperforms LR for epistatic (PE) and complex (PX) phenotypes where interactions are involved (achieving scores up to X times better than LR). This is because the association power gained by the interaction between variants remains invisible to LR.</p>
      <p>Conversely, LR performs ≤2.2 times better than VariantSpark on datasets withdividual TVs (PIM and PIH). This gain over VariantSpark is likely due to the need to tune hyper-parameter choices for each dataset, which has resulted in non-optimal performance in these instances (see Hyper-Parameter Tuning section).</p>
      <p>For phenotypes with a high number of TVs (i.e., PIH, PEH, and PXH) the detection rate is low for both VariantSpark and LR, especially in the case of the largest dataset (1KG-80M). For such complex phenotypes, detecting all TVs, even in the top 10<italic>t</italic> RVs, is a difficult task.</p>
      <p>Fig. <xref ref-type="fig" rid="fig2">2a</xref> illustrates a more in-depth comparison of VariantSpark and LR processing the 1KG-80M dataset with PXH phenotype. Note, in this dataset the truth variables are not necessarily present, reflecting a more realistic scenario of associated variants being filtered out by various pre-processing and quality control steps. We hence perform a more qualitative analysis by considering the detection of variants that correlate with TVs (i.e., variants in the same haplotype as a TV). The horizontal axis lists all TVs even if they were not included in the dataset. For each TV we look for the most correlated variant in the top 10<italic>t</italic> RVs and plot the maximum absolute value of the Pearson correlation coefficient (γ). High γ indicates that the detected variant highly correlates with the TV and possibly identifies the same genomic region as the TV. TVs are sorted on the basis of their LR γ. The γ-values for all experiments and both methods are listed in <xref ref-type="supplementary-material" rid="sup15">Supplementary Data File 2</xref>.</p>
      <fig id="fig2" orientation="portrait" position="float">
        <label>Figure 2:</label>
        <caption>
          <p>Comparison of exclusively detected variants and correlation with prediction accuracy.</p>
        </caption>
        <graphic xlink:href="giaa077fig2"/>
      </fig>
      <p>As shown in Fig. <xref ref-type="fig" rid="fig2">2a</xref> while LR quickly exhausts its ability to detect the TV or equivalent variants (γ decreases to &lt;0.5), VariantSpark’s γ stays &gt;0.75 for more variants. We define the number of exclusively detected TVs by VariantSpark as the number of TVs where the VariantSpark γ is &gt;0.75 and LR γ is &lt;0.5. The number of exclusively detected variants by LR is defined similarly. We quantify the number of exclusively detected variants by either method on the 1KG-500K and 1KG-5M datasets. As shown in Fig. <xref ref-type="fig" rid="fig2">2b</xref> the number of exclusively detected TVs by VariantSpark is up to 4.6 times higher than LR (if both VariantSpark and LR detect TVs exclusively). Complete numerical comparisons including for 1KG-5M-T and 1KG-500K-T datasets and the other 2 replicates are provided in <xref ref-type="supplementary-material" rid="sup15">Supplementary Data File 1</xref>.</p>
      <p>It is worth noting that association accuracy, i.e., the ability to recover TV, is distinct from prediction accuracy, i.e., predicting the correct label for a sample. As shown in Fig. <xref ref-type="fig" rid="fig2">2b</xref>, prediction accuracy shows only a moderate correlation with association accuracy (correlation coefficient equal to −0.84). This is because a sufficiently large feature set can create a model that can predict the label by chance, while choosing the TV is a less stochastic process, as demonstrated by the larger value range on the vertical axis. When finding disease genes where the TVs are unknown, using the prediction accuracy to the known labels can only be used as a rough proxy.</p>
    </sec>
    <sec id="sec1-5">
      <title>Result 2: VariantSpark outperforms state-of-the-art HPC and distributed implementations</title>
      <p>We benchmark VariantSpark against the fastest HPC and distributed implementation of RF, respectively: Ranger and ReForeSt. We record the runtime of all 3 tools on synthetic datasets with 10,000 samples and doubling the number of variants, starting from 100 to 6.5 million and then 10 million.</p>
      <p>Fig. <xref ref-type="fig" rid="fig3">3</xref> shows that only VariantSpark and ReForeSt were able to process the 2 largest datasets. Ranger fails to process datasets of &gt;1.6M variants, and while in save-memory mode, it processes up to 3.2M, it does so 1.4 times slower than in normal mode. Ranger is executed on a computer with 488 GB of memory. Yet it could not process a dataset of &gt;3.2M owing to excessive memory usage. Note that the biggest dataset in the comparison (10M x 10K) has 100 billion genotypes, which can be loaded into 100 GB of memory, and VariantSpark processes it with a peak memory usage of 120 GB.</p>
      <fig id="fig3" orientation="portrait" position="float">
        <label>Figure 3:</label>
        <caption>
          <p>VariantSpark’s runtime compared with other implementations of Random Forest (RF) and Decision Tree (DT). The RF and DT workloads are different and should not be compared with each other. The number of variants in the dataset is doubled at each step (see Table <xref rid="tbl4" ref-type="table">4</xref> for the list of datasets used for the comparison). The thin unmarked black line illustrates the case if the runtime increases linearly starting from the average runtime of VariantSpark and Reforest for a dataset of 1.6M variants.</p>
        </caption>
        <graphic xlink:href="giaa077fig3"/>
      </fig>
      <p>For the largest dataset that Ranger processed (1.6M), ReForeSt and VariantSpark performed 4.1 and 4.6 times faster than Ranger, respectively. Ranger advertises a special GWAS mode, but we were unable to successfully run this mode. The quoted runtime in the Ranger publication (for 10,000 samples, 150,000 variants, and mTry = 15,000) shows that GWAS mode is twice as fast as normal mode and uses the same amount of memory as save-memory mode. Given this information, the GWAS mode would not be able to process datasets with &gt;3.2M variants and would remain slower than VariantSpark and ReForeSt.</p>
      <p>VariantSpark and ReForeSt performed comparably for 1.6M variants (5,450 and 6,044 seconds, respectively); after this point, the runtime of ReForeSt increases exponentially while VariantSpark increases sub-linearly. Note the thin unmarked black line illustrating a linear runtime increase starting from the average runtime of VariantSpark and Reforest for a dataset of 1.6M variants (5,747 seconds). VariantSpark is 3.6 times faster than ReForeSt processing a dataset with 10M variants, a difference that increases further for larger datasets owing to the exponential vs sub-linear runtime behavior.</p>
      <p>We also compare VariantSpark with Yggdrasil, as the only other vertical partitioning implementation. Because Yggdrasil only builds a single DT, we run VariantSpark with mTry equal to the number of variants to emulate building a DT and record the runtime of building DTs 10 times with each method. As shown in Fig. <xref ref-type="fig" rid="fig3">3</xref>, Yggdrasil’s runtime increased dramatically for 3M variants and took 35 hours to complete (possibly due to excessive memory usage). VariantSpark performed 9 and 87.4 times faster than Yggdrasil for a dataset of 1.6M and 3.2M variants, respectively. As mentioned, the biggest dataset requires 100 GB memory to be loaded. While Yggdrasil is executed on a computer cluster with 2 TB of memory, it processes the 3.2M dataset with difficulty.</p>
    </sec>
    <sec id="sec1-6">
      <title>Result 3: VariantSpark scales at most linearly with sample and variant increases</title>
      <p>We test VariantSpark’s scalability by recording the runtime when increasing the number of variants 10 times at each step, with 1,000, 10,000, and 100,000 samples, respectively. As shown in Fig. <xref ref-type="fig" rid="fig4">4a</xref>, the runtime increases sub-linearly with the increasing number of variants and increases linearly with the increasing number of samples. Note that both axes are on a logarithmic scale.</p>
      <fig id="fig4" orientation="portrait" position="float">
        <label>Figure 4:</label>
        <caption>
          <p>VariantSpark runtime as a function of size of (a) the dataset, (b) the cluster, and (c) the compute-nodes. VariantSpark runtime and accuracy as a function of (d) mTry and nTree and (e) maxD and minNS. (f) The effect of maxD and minNS on the average depth and the number of nodes per tree.</p>
        </caption>
        <graphic xlink:href="giaa077fig4"/>
      </fig>
      <p>VariantSpark can use distributed compute resources efficiently and scales linearly with the size of the cluster as shown in Fig. <xref ref-type="fig" rid="fig4">4b</xref>. It records the speed-up gained when doubling the size of the cluster processing the 10K sample and 1M variant dataset. Up to the C512 cluster, the runtime can be halved (speed-up ∼2). However, using a C1024 cluster, the speed-up decreases to 1.5, which is due to the 10K-1M dataset not being large enough to be efficiently partitioned over 1,024 CPUs and networking becomes a bottleneck. The 2-fold speed-up on this larger cluster is achieved when processing a 10 times larger dataset (10K-10M).</p>
      <p>We also investigate whether high-performance compute-nodes perform better than commodity ones, by running the same job on 3 clusters of the overall same capacity but with different numbers and sizes of compute-nodes. Each cluster processes the job 3 times with minimum and maximum runtimes plotted. Fig. <xref ref-type="fig" rid="fig4">4c</xref> shows that compute-node choice has little effect on the runtime. Interestingly, the most expensive HPC computer node (8 computers each with 32 vCPU) delivered a worse runtime compared to a commodity set-up (32 computers each with 8 vCPU), with the best performance delivered by a moderate size computer (16 computers each with 16 vCPU). This is because of the balance between CPUs, memory, and network performance. The runtime variation between replicates is &lt;10%, with the largest difference observed in clusters utilizing more compute-nodes. This is likely due to the increase in networking between nodes, which is subject to external fluctuations.</p>
    </sec>
    <sec id="sec1-7">
      <title>Result 4: Hyper-parameter tuning is different for ultra-high-dimensional data</title>
      <p>There are 4 important parameters to set when building an RF model:</p>
      <list list-type="bullet">
        <list-item>
          <p>nTree: Number of trees in the forest</p>
        </list-item>
        <list-item>
          <p>mTry: Number of variants evaluated at each node of a tree</p>
        </list-item>
        <list-item>
          <p>maxD: Maximum depth of a tree to grow</p>
        </list-item>
        <list-item>
          <p>minNS: Minimum number of samples in a node to be processed</p>
        </list-item>
      </list>
      <p>Here, we show that parameter choice substantially affects the performance and accuracy of the trained model. We varied these parameters and recorded runtime and OOB. Also, we record the average number of nodes per tree and average tree depth to show the effect of maxD and minNS on the RF model.</p>
      <p>As a rule of thumb, it is recommended to set mTry to the square root of nV; however, our findings show that this recommendation does not suit the analysis of genome-wide datasets. Fig. <xref ref-type="fig" rid="fig4">4d</xref> shows the effect of mTry on the runtime and accuracy of the RF model (10K-1M dataset). mTry = 0.1 × nV = 100,000 shows a substantial improvement in the accuracy compared to the previously recommended mTry = (nV)<sup>1/2</sup> = 1,000.</p>
      <p>Applying limits to RF training to keep trees shallow and efficient affects the runtime and accuracy of the model. Fig. <xref ref-type="fig" rid="fig4">4e</xref> shows the runtime and OOB of VariantSpark when no limits are applied, as well as when maximum depth (maxD) and minimum node size (minNS) are set. Applying these limits reduces the runtime up to 4.8 times. Interestingly, applying these limits also reduces OOB (increases accuracy). This is because deep down in the trees, there are fewer samples in nodes and it is more likely for a variant to gain information by chance. In other words, there is less statistical support for the information obtained from the bottom of a deep tree, and this pushes the model to overfit the data. Also illustrated in this figure is the effect of maxD and minNS on runtime. Note, getting the best accuracy by setting optimal parameter values depends on the complexity of the phenotype and the size of the dataset and hence likely differs between datasets.</p>
      <p>Fig. <xref ref-type="fig" rid="fig4">4d</xref> shows that increasing the number of trees nTree increases the runtime linearly as expected. Also, the OOB is reduced (higher prediction accuracy) when doubling the nTree at each step. However, the reduction in OOB is slowed down when training excessive numbers of trees. In other words, we cannot reduce OOB to zero by increasing the number of trees. At this stage, it is not possible to predefine the optimal number of trees because it depends on the complexity of the phenotype and the size of the dataset.</p>
      <p>The effect of VariantSpark batch size (number of trees processed in parallel) is recorded in <xref ref-type="supplementary-material" rid="sup15">Supplementary Data File 1</xref>. An appropriate batch size (depending on the size of cluster and networking performance) can result in the highest speed-up at no cost to the accuracy.</p>
    </sec>
  </sec>
  <sec sec-type="methods" id="sec2">
    <title>Methods</title>
    <p>VariantSpark is a distributed implementation of the original RF classification algorithm [<xref rid="bib16" ref-type="bibr">16</xref>]. It accepts ordinal features and a categorical response variable. In the context of GWAS, features are genomic variants and encoded to 0, 1, and 2 for 0/0, 0/1, and 1/1 genotypes, respectively. This is the VariantSpark default encoding when the data are provided in a genomic VCF format. It is possible to use a more complex encoding in a comma-separated value (CSV) format. The user can combine other ordinal omics data with genomics data for multi-omics analysis. In case/control studies, the response variable is a binary phenotype. Yet, VariantSpark can perform multi-class analysis too.</p>
    <sec id="sec2-1">
      <title>Importance score captures interactions</title>
      <p>When processing a node of a tree, RF evaluates randomly selected variants to separate samples of a node into 2 child nodes (a binary tree). The goal is to keep samples of the same class in 1 of the child nodes. The best split is the variant that results in the highest separation of samples. The best split maximizes the “information gained," which is a metric that measures the quality of separation. VariantSpark uses Gini-Index impurity as described in [<xref rid="bib16" ref-type="bibr">16</xref>] to compute information gained as used in the original RF.</p>
      <p>The samples in each node are selected as a result of the best split in all parent nodes. Thus the best split and information gained in each node depend on all variants selected in the upstream nodes (to the root) and the interaction between them. Given a large number of trees built in an RF model a variant can be selected as the best split in various nodes in the forest. The information gained by the variant in each of these nodes discloses part of its interactions (with variants selected in upstream nodes above it). The importance score of a variant, computed as the average information gained for the variant, represents all of its interactions discovered by the RF model.</p>
    </sec>
    <sec id="sec2-2">
      <title>Algorithmic computational complexity</title>
      <p>Here we describe the theoretical dependency of VariantSpark’s runtime on different parameters. The runtime of the core computation (excluding loading data to memory) is expected to be linear in nTree × nNode × mTry × nS. The nTree and mTry are directly given by the user and represent the number of trees in the forest and the number of variables to be evaluated for each node of each tree, respectively. nS represents the number of samples in the dataset. To evaluate each variant at each node of a tree, the algorithm needs to loop through all samples. nNode represents the average number of non-leaf nodes per tree.</p>
      <p>The value of nNode is determined after the RF is trained because it depends on mTry, maxD, and minNS, as well as the complexity of the phenotype and the size of the dataset. The lower mTry, the lower the chance for a node to divide into pure (leaf) nodes, thus the higher nNode. With a lower maxD or a higher minNS, trees are smaller (nNode is lower). Also, more samples in the dataset result in deeper trees (nodes get purer with more splits), which ultimately increases the nNode. If a phenotype depends only on a few strongly associated signals, trees are shallower and the nNode is smaller.</p>
      <p>Given nV = 100M, nS = 10K, nTree = 10K, nNode = 100, and mTry = 0.1 × nV a computer should perform 10<sup>17</sup> operations to build the RF model. This massive computational requirement indicates the importance of using a distributed computing platform for such analysis.</p>
      <p>The number of classes in the phenotype and the number of different values a feature can take also affects the processing time. However, we did not consider their effect because for most analysis the phenotype is a binary value and bi-allelic genotypes are encoded to 0, 1, and 2. The time it takes to load data into memory is a linear function of nS × nV (number of samples and variants in the dataset, respectively).</p>
    </sec>
    <sec id="sec2-3">
      <title>Distributed computing</title>
      <p>VariantSpark is implemented on top of Apache Spark, a fast distributed computing platform. In the Spark platform, the dataset is partitioned in the memory of several computers (compute-nodes), controlled by a central computer (master-node). In most implementations of machine learning algorithms, the dataset is partitioned by samples (horizontal partitioning) such that each compute-node contains the data for all features and a set of samples. This is because most machine learning datasets include a large number of samples and a small number of features. However, in genomic datasets, it is the number of features that outgrows the number of samples by several orders of magnitude. Partitioning by variants (vertical partitioning) is more effective for genomic data.</p>
      <p>Vertical partitioning helps to reduce slow networking operations. If data are partitioned by samples, to process each node of a tree, each compute-node in the cluster must partially evaluate the selected mTry variants and send back results to the master node of the cluster for aggregation. However, when partitioning by variants, each compute-node evaluates a subset of the mTry variants (existing in its local memory) and only sends the information about the best local split to the master-node (Fig. <xref ref-type="fig" rid="fig5">5</xref>).</p>
      <fig id="fig5" orientation="portrait" position="float">
        <label>Figure 5:</label>
        <caption>
          <p>Illustration of partitioning strategies for distributed computing implementations of RF. For genomics data the number of features is larger than the number of samples. Here, vertical partitioning better balances data divisions and makes communication between compute-nodes (C) and the master-node (M) more efficient. Specifically, training each node of each tree with vertical partitioning enables each each compute-node to find the local best split in the allocated partition and to only communicate the best local split with the master (small green squares). In contrast with horizontal partitioning, each compute-node must communicate the summary statistics of all allocated samples with the master node (large orange tables).</p>
        </caption>
        <graphic xlink:href="giaa077fig5"/>
      </fig>
      <p>Another important optimization in VariantSpark is parallelizing the processing of several nodes from several trees in a batch such that network operations never become a bottleneck. Finally, VariantSpark uses Spark RDD, which provides the lowest level of access to the memory to deliver the highest performance.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec3">
    <title>Conclusion</title>
    <p>While there is evidence for polygenic and epistatic phenotypes, polygenic-epistatic phenotypes have not been studied yet, likely because the existing GWAS methods are underpowered to perform such compute-intensive association studies. VariantSpark is the first methodology to perform complex association analyses on whole-genome sequencing experiments and outperforms other state-of-the-art implementations.</p>
    <p>The results provided in this article first demonstrate the capability of VariantSpark in detecting associative signals of complex interactions, and second elaborate the performance and scalability when processing large-scale datasets. Akin to deep learning methods, VariantSpark’s hyper-parameters need to be iteratively tuned to each dataset, which is made possible by VariantSpark’s speed and scalability.</p>
    <p>VariantSpark is not a replacement for traditional association analysis but a complement. The results of traditional GWAS (LR) and VariantSpark should be considered together to gain insights into the full influence of the genome on disease and other phenotypes. Similarly, VariantSpark’s output may be usable to prioritize variants in PRS to reduce noise levels.</p>
  </sec>
  <sec id="sec4">
    <title>Availability of Source Code and Requirements</title>
    <p>VariantSpark source code and compilation instructions:</p>
    <list list-type="bullet">
      <list-item>
        <p>Project name: VariantSpark</p>
      </list-item>
      <list-item>
        <p>Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/aehrc/VariantSpark">https://github.com/aehrc/VariantSpark</ext-link></p>
      </list-item>
      <list-item>
        <p>Operating system(s): Platform independent (Java Virtual Machine)</p>
      </list-item>
      <list-item>
        <p>Programming language: Scala with Python and Hail Interface</p>
      </list-item>
      <list-item>
        <p>Other requirements: Java 8, Apache Spark 2</p>
      </list-item>
      <list-item>
        <p>License: CSIRO Open Source Software Licence v1.0, based on MIT/BSD</p>
      </list-item>
      <list-item>
        <p>
          <ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/RRID:SCR_018383">RRID:SCR_018383</ext-link>
        </p>
      </list-item>
      <list-item>
        <p>BioTools: biotools:variantspark (<ext-link ext-link-type="uri" xlink:href="https://bio.tools/">https://bio.tools/</ext-link>)</p>
      </list-item>
    </list>
    <p>AWS CloudFormation templates to simplify the configuration and installation process:</p>
    <list list-type="bullet">
      <list-item>
        <p>Project name: VariantSpark-AWS</p>
      </list-item>
      <list-item>
        <p>Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/aehrc/VariantSpark-aws">https://github.com/aehrc/VariantSpark-aws</ext-link></p>
      </list-item>
      <list-item>
        <p>Programming language: YAML</p>
      </list-item>
      <list-item>
        <p>License: CSIRO Open Source Software Licence v1.0, based on MIT/BSD</p>
      </list-item>
    </list>
  </sec>
  <sec sec-type="materials" id="h1content1594061146143">
    <title>Availability of Supporting Data and Materials</title>
    <p>An archival copy of the code is also available in GigaDB [<xref rid="bib43" ref-type="bibr">43</xref>]. Finally, to facilitate the use of VariantSpark on AWS cloud, we extended our CloudFormation templates and made it available on the AWS Marketplace (<ext-link ext-link-type="uri" xlink:href="https://aws.amazon.com/marketplace/pp/AEHRC-VariantSpark-Notebook/B07YVND4TD">https://aws.amazon.com/marketplace/pp/AEHRC-VariantSpark-Notebook/B07YVND4TD</ext-link>) such that a user with minimal technical knowledge can get access to a computer cluster of any size with VariantSpark, Hail, and Jupyter Notebook installed and ready to use.</p>
  </sec>
  <sec id="h1content1594061218410">
    <title>Additional Files</title>
    <p><bold>Supplementary Data File 1</bold>. Provides an extended and more detailed numerical comparison for all figures.</p>
    <p><bold>Supplementary Data File 2</bold>. Includes the maximum correlation values (γ) for all experiments.</p>
    <p><bold>Supplementary Data File 3</bold>. Provides all PEPS simulated phenotypes for 1000-Genomes dataset with truth-variants and PEPS configuration files.</p>
    <p>Supplementary Data File 4. Explains access to raw data and output file (available on GigaScience Database [<xref rid="bib43" ref-type="bibr">43</xref>]) as well as technical instruction including:</p>
    <list list-type="bullet">
      <list-item>
        <p>1000-Genome data and subsets in vcf compressed format.</p>
      </list-item>
      <list-item>
        <p>Dataset simulated with VariantSpark.</p>
      </list-item>
      <list-item>
        <p>Complete correlation matrix between TVs and RVs for all analyses.</p>
      </list-item>
      <list-item>
        <p>List of RVs for all analyses.</p>
      </list-item>
      <list-item>
        <p>Random Forest model created by VariantSpark in JSON format (used to compute average tree depth and number of nodes).</p>
      </list-item>
      <list-item>
        <p>Instructions to create an AWS EMR cluster via terminal.</p>
      </list-item>
      <list-item>
        <p>Instructions to submit VariantSpark jobs to the cluster.</p>
      </list-item>
    </list>
  </sec>
  <sec id="sec6">
    <title>Abbreviations</title>
    <p>1KG: 1000-Genomes; AWS: Amazon Web Services; DT: decision tree; GWAS: genome-wide association study; HPC: high-performance computer; LR: logistic regression; OOB: out-of-bag error rate; PEPS: Polygenic Epistatic Phenotype Simulator; PRS: polygenic risk score; RDD: Resilient Distributed Dataset; RF: random forest; RV: ranked variant; TV: truth variant; vCPU: virtual central processing unit.</p>
  </sec>
  <sec id="sec7">
    <title>Definitions</title>
    <list list-type="bullet">
      <list-item>
        <p>nS: Number of samples in dataset</p>
      </list-item>
      <list-item>
        <p>nV: Number of variants in dataset</p>
      </list-item>
      <list-item>
        <p>nTree: Number of trees</p>
      </list-item>
      <list-item>
        <p>mTry: Number of variables to evaluate at each node of a tree</p>
      </list-item>
      <list-item>
        <p>maxD: Maximum depth of a tree</p>
      </list-item>
      <list-item>
        <p>minNS: Minimum number of samples in each node to be processed</p>
      </list-item>
      <list-item>
        <p>rbs: Number of trees to be processed in parallel</p>
      </list-item>
      <list-item>
        <p>γ: Maximum absolute Pearson correlation coefficient between a truth-variant and any of the ranked-variants</p>
      </list-item>
    </list>
  </sec>
  <sec id="sec8">
    <title>Funding</title>
    <p>Funding was from CSIRO Health and Biosecurity. The authors gratefully acknowledge AWS cloud credits that were used to fund the cloud cost of this work.</p>
  </sec>
  <sec id="sec9">
    <title>Authors' Contributions</title>
    <p>A.B. and D.C.B. designed the experiment. P.S., A.B., B.H., Y.J., C.H., and A.R.O. implemented the software used in this research. A.B. and R.D. conducted the experiments. A.B., D.C.B., O.J.L., and N.T. wrote the manuscript. All authors read and approved the manuscript.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>giaa077_GIGA-D-19-00335_Original_Submission</label>
      <media xlink:href="giaa077_giga-d-19-00335_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup2">
      <label>giaa077_GIGA-D-19-00335_Revision_1</label>
      <media xlink:href="giaa077_giga-d-19-00335_revision_1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup3">
      <label>giaa077_GIGA-D-19-00335_Revision_2</label>
      <media xlink:href="giaa077_giga-d-19-00335_revision_2.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup4">
      <label>giaa077_GIGA-D-19-00335_Revision_3</label>
      <media xlink:href="giaa077_giga-d-19-00335_revision_3.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup5">
      <label>giaa077_GIGA-D-19-00335_Revision_4</label>
      <media xlink:href="giaa077_giga-d-19-00335_revision_4.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup6">
      <label>giaa077_Response_to_Reviewer_Comments_Original_Submission</label>
      <media xlink:href="giaa077_response_to_reviewer_comments_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup7">
      <label>giaa077_Response_to_Reviewer_Comments_Revision_1</label>
      <media xlink:href="giaa077_response_to_reviewer_comments_revision_1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup8">
      <label>giaa077_Response_to_Reviewer_Comments_Revision_2</label>
      <media xlink:href="giaa077_response_to_reviewer_comments_revision_2.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup9">
      <label>giaa077_Response_to_Reviewer_Comments_Revision_3</label>
      <media xlink:href="giaa077_response_to_reviewer_comments_revision_3.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup10">
      <label>giaa077_Reviewer_1_Report_Original_Submission</label>
      <caption>
        <p>Brendan Lawlor -- 10/13/2019 Reviewed</p>
      </caption>
      <media xlink:href="giaa077_reviewer_1_report_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup11">
      <label>giaa077_Reviewer_1_Report_Revision_1</label>
      <caption>
        <p>Brendan Lawlor -- 5/19/2020 Reviewed</p>
      </caption>
      <media xlink:href="giaa077_reviewer_1_report_revision_1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup12">
      <label>giaa077_Reviewer_2_Report_Original_Submission</label>
      <caption>
        <p>Joshua W. K. Ho, PhD -- 10/18/2019 Reviewed</p>
      </caption>
      <media xlink:href="giaa077_reviewer_2_report_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup13">
      <label>giaa077_Reviewer_2_Report_Revision_1</label>
      <caption>
        <p>Joshua W. K. Ho, PhD -- 5/12/2020 Reviewed</p>
      </caption>
      <media xlink:href="giaa077_reviewer_2_report_revision_1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup14">
      <label>giaa077_Reviewer_3_Report_Original_Submission</label>
      <caption>
        <p>Faraz Faghri -- 11/4/2019 Reviewed</p>
      </caption>
      <media xlink:href="giaa077_reviewer_3_report_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup15">
      <label>giaa077_Supplemental_Files</label>
      <media xlink:href="giaa077_supplemental_files.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="bib1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Visscher</surname><given-names>PM</given-names></name>, <name name-style="western"><surname>Wray</surname><given-names>NR</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>Q</given-names></name>, <etal>et al.</etal></person-group><article-title>10 years of GWAS discovery: biology, function, and translation</article-title>. <source>Am J Hum Genet</source>. <year>2017</year>;<volume>101</volume>(<issue>1</issue>):<fpage>5</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">28686856</pub-id></mixed-citation>
    </ref>
    <ref id="bib2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>MacArthur</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Bowler</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Cerezo</surname><given-names>M</given-names></name>, <etal>et al.</etal></person-group><article-title>The new NHGRI-EBI Catalog of published genome-wide association studies (GWAS Catalog)</article-title>. <source>Nucleic Acids Res</source>. <year>2017</year>;<volume>45</volume>(<issue>D1</issue>):<fpage>D896</fpage>–<lpage>D901</lpage>.<pub-id pub-id-type="pmid">27899670</pub-id></mixed-citation>
    </ref>
    <ref id="bib3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Manolio</surname><given-names>TA</given-names></name>, <name name-style="western"><surname>Collins</surname><given-names>FS</given-names></name>, <name name-style="western"><surname>Cox</surname><given-names>NJ</given-names></name>, <etal>et al.</etal></person-group><article-title>Finding the missing heritability of complex diseases</article-title>. <source>Nature</source>. <year>2009</year>;<volume>461</volume>(<issue>7265</issue>):<fpage>747</fpage>–<lpage>53</lpage>.<pub-id pub-id-type="pmid">19812666</pub-id></mixed-citation>
    </ref>
    <ref id="bib4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Boyle</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>YI</given-names></name>, <name name-style="western"><surname>Pritchard</surname><given-names>JK</given-names></name></person-group><article-title>An expanded view of complex traits: from polygenic to omnigenic</article-title>. <source>Cell</source>. <year>2017</year>;<volume>169</volume>(<issue>7</issue>):<fpage>1177</fpage>–<lpage>86</lpage>.<pub-id pub-id-type="pmid">28622505</pub-id></mixed-citation>
    </ref>
    <ref id="bib5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nicod</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Davies</surname><given-names>RW</given-names></name>, <name name-style="western"><surname>Cai</surname><given-names>N</given-names></name>, <etal>et al.</etal></person-group><article-title>Genome-wide association of multiple complex traits in outbred mice by ultra-low-coverage sequencing</article-title>. <source>Nat Genet</source>. <year>2016</year>;<volume>48</volume>(<issue>8</issue>):<fpage>912</fpage>.<pub-id pub-id-type="pmid">27376238</pub-id></mixed-citation>
    </ref>
    <ref id="bib6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Manolio</surname><given-names>TA</given-names></name>, <name name-style="western"><surname>Pasquale</surname><given-names>LR</given-names></name>, <etal>et al.</etal></person-group><article-title>Genome partitioning of genetic variation for complex traits using common SNPs</article-title>. <source>Nat Genet</source>. <year>2011</year>;<volume>43</volume>(<issue>6</issue>):<fpage>519</fpage>–<lpage>25</lpage>.<pub-id pub-id-type="pmid">21552263</pub-id></mixed-citation>
    </ref>
    <ref id="bib7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Manolio</surname><given-names>TA</given-names></name>, <name name-style="western"><surname>Collins</surname><given-names>FS</given-names></name>, <name name-style="western"><surname>Cox</surname><given-names>NJ</given-names></name>, <etal>et al.</etal></person-group><article-title>Finding the missing heritability of complex diseases</article-title>. <source>Nature</source>. <year>2009</year>;<volume>461</volume>(<issue>7265</issue>):<fpage>747</fpage>–<lpage>53</lpage>.<pub-id pub-id-type="pmid">19812666</pub-id></mixed-citation>
    </ref>
    <ref id="bib8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wray</surname><given-names>NR</given-names></name>, <name name-style="western"><surname>Goddard</surname><given-names>ME</given-names></name>, <name name-style="western"><surname>Visscher</surname><given-names>PM</given-names></name></person-group><article-title>Prediction of individual genetic risk to disease from genome-wide association studies</article-title>. <source>Genome Res</source>. <year>2007</year>;<volume>17</volume>(<issue>10</issue>):<fpage>1520</fpage>–<lpage>28</lpage>.<pub-id pub-id-type="pmid">17785532</pub-id></mixed-citation>
    </ref>
    <ref id="bib9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chatterjee</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Shi</surname><given-names>J</given-names></name>, <name name-style="western"><surname>García-Closas</surname><given-names>M</given-names></name></person-group><article-title>Developing and evaluating polygenic risk prediction models for stratified disease prevention</article-title>. <source>Nat Rev Genet</source>. <year>2016</year>;<volume>17</volume>(<issue>7</issue>):<fpage>392</fpage>.<pub-id pub-id-type="pmid">27140283</pub-id></mixed-citation>
    </ref>
    <ref id="bib10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mavaddat</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Pharoah</surname><given-names>PD</given-names></name>, <name name-style="western"><surname>Michailidou</surname><given-names>K</given-names></name>, <etal>et al.</etal></person-group><article-title>Prediction of breast cancer risk based on profiling with common genetic variants</article-title>. <source>J Natl Cancer Inst</source>. <year>2015</year>;<volume>107</volume>(<issue>5</issue>), doi:<pub-id pub-id-type="doi">10.1093/jnci/djv036</pub-id>.</mixed-citation>
    </ref>
    <ref id="bib11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Phillips</surname><given-names>PC</given-names></name></person-group><article-title>Epistasis—the essential role of gene interactions in the structure and evolution of genetic systems</article-title>. <source>Nat Rev Genet</source>. <year>2008</year>;<volume>9</volume>(<issue>11</issue>):<fpage>855</fpage>–<lpage>67</lpage>.<pub-id pub-id-type="pmid">18852697</pub-id></mixed-citation>
    </ref>
    <ref id="bib12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Niel</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Sinoquet</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Dina</surname><given-names>C</given-names></name>, <etal>et al.</etal></person-group><article-title>A survey about methods dedicated to epistasis detection</article-title>. <source>Front Genet</source>. <year>2015</year>;<volume>6</volume>:<fpage>285</fpage>.<pub-id pub-id-type="pmid">26442103</pub-id></mixed-citation>
    </ref>
    <ref id="bib13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Sun</surname><given-names>Y</given-names></name>, <etal>et al.</etal></person-group><article-title>Performance analysis of novel methods for detecting epistasis</article-title>. <source>BMC Bioinformatics</source>. <year>2011</year>;<volume>12</volume>:<fpage>475</fpage>.<pub-id pub-id-type="pmid">22172045</pub-id></mixed-citation>
    </ref>
    <ref id="bib14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wan</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>Q</given-names></name>, <etal>et al.</etal></person-group><article-title>BOOST: a fast approach to detecting gene-gene interactions in genome-wide case-control studies</article-title>. <source>Am J Hum Genet</source>. <year>2010</year>;<volume>87</volume>(<issue>3</issue>):<fpage>325</fpage>–<lpage>40</lpage>.<pub-id pub-id-type="pmid">20817139</pub-id></mixed-citation>
    </ref>
    <ref id="bib15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Evans</surname><given-names>DM</given-names></name>, <name name-style="western"><surname>Spencer</surname><given-names>CC</given-names></name>, <name name-style="western"><surname>Pointon</surname><given-names>JJ</given-names></name>, <etal>et al.</etal></person-group><article-title>Interaction between ERAP1 and HLA-B27 in ankylosing spondylitis implicates peptide handling in the mechanism for HLA-B27 in disease susceptibility</article-title>. <source>Nat Genet</source>. <year>2011</year>;<volume>43</volume>(<issue>8</issue>):<fpage>761</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">21743469</pub-id></mixed-citation>
    </ref>
    <ref id="bib16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Breiman</surname><given-names>L</given-names></name></person-group><article-title>Random Forests</article-title>. <source>Mach Learn</source>. <year>2001</year>;<volume>45</volume>(<issue>1</issue>):<fpage>5</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="bib17">
      <label>17.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Qi</surname><given-names>Y</given-names></name></person-group><article-title>Random forest for bioinformatics</article-title>. In: <person-group person-group-type="editor"><name name-style="western"><surname>Zhang</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Ma</surname><given-names>Y</given-names></name></person-group><source>Ensemble Machine Learning</source>. <publisher-name>Springer</publisher-name>; <year>2012</year>:<fpage>307</fpage>–<lpage>23</lpage>.</mixed-citation>
    </ref>
    <ref id="bib18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Ishwaran</surname><given-names>H</given-names></name></person-group><article-title>Random forests for genomic data analysis</article-title>. <source>Genomics</source>. <year>2012</year>;<volume>99</volume>(<issue>6</issue>):<fpage>323</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">22546560</pub-id></mixed-citation>
    </ref>
    <ref id="bib19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Goldstein</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Polley</surname><given-names>EC</given-names></name>, <name name-style="western"><surname>Briggs</surname><given-names>FB</given-names></name></person-group><article-title>Random forests for genetic association studies</article-title>. <source>Stat Appl Genet Mol Biol</source>. <year>2011</year>;<volume>10</volume>(<issue>1</issue>):<fpage>32</fpage>.<pub-id pub-id-type="pmid">22889876</pub-id></mixed-citation>
    </ref>
    <ref id="bib20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>O’Brien</surname><given-names>AR</given-names></name>, <name name-style="western"><surname>Saunders</surname><given-names>NFW</given-names></name>, <name name-style="western"><surname>Guo</surname><given-names>Y</given-names></name>, <etal>et al.</etal></person-group><article-title>VariantSpark: population scale clustering of genotype information</article-title>. <source>BMC Genomics</source>. <year>2015</year>;<volume>16</volume>:<fpage>1052</fpage>.<pub-id pub-id-type="pmid">26651996</pub-id></mixed-citation>
    </ref>
    <ref id="bib21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Eraslan</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Avsec</surname><given-names>Ž</given-names></name>, <name name-style="western"><surname>Gagneur</surname><given-names>J</given-names></name>, <etal>et al.</etal></person-group><article-title>Deep learning: new computational modelling techniques for genomics</article-title>. <source>Nat Rev Genet</source>. <year>2019</year>;<volume>20</volume>(<issue>7</issue>):<fpage>389</fpage>–<lpage>403</lpage>.<pub-id pub-id-type="pmid">30971806</pub-id></mixed-citation>
    </ref>
    <ref id="bib22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zaharia</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Xin</surname><given-names>RS</given-names></name>, <name name-style="western"><surname>Wendell</surname><given-names>P</given-names></name>, <etal>et al.</etal></person-group><article-title>Apache Spark: a unified engine for big data processing</article-title>. <source>Commun ACM</source>. <year>2016</year>;<volume>59</volume>(<issue>11</issue>):<fpage>56</fpage>–<lpage>65</lpage>.</mixed-citation>
    </ref>
    <ref id="bib23">
      <label>23.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Massie</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Nothaft</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Hartl</surname><given-names>C</given-names></name>, <etal>et al.</etal></person-group><article-title>ADAM: genomics formats and processing patterns for cloud scale computing</article-title>. <comment>Technical Report No. UCB/EECS-2013-207</comment><publisher-name>EECS Department, University of California Berkeley</publisher-name>; <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="bib24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stephens</surname><given-names>ZD</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>SY</given-names></name>, <name name-style="western"><surname>Faghri</surname><given-names>F</given-names></name>, <etal>et al.</etal></person-group><article-title>Big data: astronomical or genomical?</article-title>. <source>PLoS Biol</source>. <year>2015</year>;<volume>13</volume>(<issue>7</issue>):<fpage>e1002195</fpage>.<pub-id pub-id-type="pmid">26151137</pub-id></mixed-citation>
    </ref>
    <ref id="bib25">
      <label>25.</label>
      <mixed-citation publication-type="book"><comment>Hail library. <ext-link ext-link-type="uri" xlink:href="https://github.com/hail-is/hail">https://github.com/hail-is/hail</ext-link>. Accessed on July 1, 2019</comment>.</mixed-citation>
    </ref>
    <ref id="bib26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wright</surname><given-names>MN</given-names></name>, <name name-style="western"><surname>Ziegler</surname><given-names>A</given-names></name></person-group><article-title>Ranger: a fast implementation of random forests for high dimensional data in C++ and R</article-title>. <source>J Stat Softw</source>. <year>2016</year>;<volume>77</volume>, doi:<pub-id pub-id-type="doi">10.18637/jss.v077.i01</pub-id>.</mixed-citation>
    </ref>
    <ref id="bib27">
      <label>27.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Liaw</surname><given-names>A</given-names></name></person-group>, <comment>randomForest package for R</comment>, <comment><ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/randomForest/randomForest.pdf">https://cran.r-project.org/web/packages/randomForest/randomForest.pdf</ext-link>. Accessed on July1, 2019</comment>.</mixed-citation>
    </ref>
    <ref id="bib28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ishwaran</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Kogalur</surname><given-names>UB</given-names></name>, <name name-style="western"><surname>Blackstone</surname><given-names>EH</given-names></name>, <etal>et al.</etal></person-group><article-title>Random survival forests</article-title>. <source>Ann Appl Stat</source>. <year>2008</year>;<volume>2</volume>(<issue>3</issue>):<fpage>841</fpage>–<lpage>60</lpage>.</mixed-citation>
    </ref>
    <ref id="bib29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schwarz</surname><given-names>DF</given-names></name>, <name name-style="western"><surname>König</surname><given-names>IR</given-names></name>, <name name-style="western"><surname>Ziegler</surname><given-names>A</given-names></name></person-group><article-title>On safari to Random Jungle: a fast implementation of random forests for high-dimensional data</article-title>. <source>Bioinformatics</source>. <year>2010</year>;<volume>26</volume>(<issue>14</issue>):<fpage>1752</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">20505004</pub-id></mixed-citation>
    </ref>
    <ref id="bib30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Telenti</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Pierce</surname><given-names>LCT</given-names></name></person-group><article-title>Deep sequencing of 10,000 human genomes</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2016</year>;<volume>113</volume>(<issue>42</issue>):<fpage>11901</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">27702888</pub-id></mixed-citation>
    </ref>
    <ref id="bib31">
      <label>31.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Bayardo</surname><given-names>BP</given-names></name>, <name name-style="western"><surname>Herbach</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Basu</surname><given-names>S</given-names></name>, <etal>et al.</etal></person-group><article-title>PLANET: massively parallel learning of tree ensembles with MapReduce</article-title>. In: <source>Proceedings of the 35th International Conference on Very Large Data Bases</source>. <year>2009</year>, doi:<pub-id pub-id-type="doi">10.14778/1687553.1687569</pub-id>.</mixed-citation>
    </ref>
    <ref id="bib32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Meng</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Bradley</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Yavuz</surname><given-names>B</given-names></name>, <etal>et al.</etal></person-group><article-title>MLlib: Machine learning in Apache Spark</article-title>. <source>J Mach Learn Res</source>. <year>2016</year>;<volume>17</volume>(<issue>1</issue>):<fpage>1235</fpage>–<lpage>41</lpage>.</mixed-citation>
    </ref>
    <ref id="bib33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bayat</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Szul</surname><given-names>P</given-names></name>, <name name-style="western"><surname>O’Brien</surname><given-names>AR</given-names></name>, <etal>et al.</etal></person-group><article-title>VariantSpark, a random forest machine learning implementation for ultra high dimensional data</article-title>. <source>bioRxiv</source>. <year>2019</year>, doi:<pub-id pub-id-type="doi">10.1101/702902</pub-id>.</mixed-citation>
    </ref>
    <ref id="bib34">
      <label>34.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Lulli</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Oneto</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Anguita</surname><given-names>D</given-names></name></person-group><article-title>ReForeSt: random forests in Apache Spark</article-title>. In: <person-group person-group-type="editor"><name name-style="western"><surname>Lintas</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Rovetta</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Verschure</surname><given-names>P</given-names></name><etal>et al</etal>. <etal>et al.</etal></person-group>, eds. <source>International Conference on Artificial Neural Networks</source>. <publisher-loc>Cham</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2017</year>:<fpage>331</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="bib35">
      <label>35.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pafka</surname><given-names>S</given-names></name></person-group><comment>benchm-ml. <ext-link ext-link-type="uri" xlink:href="https://github.com/szilard/benchm-ml">https://github.com/szilard/benchm-ml</ext-link>. Accessed on July 1, 2019</comment>.</mixed-citation>
    </ref>
    <ref id="bib36">
      <label>36.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Guestrin</surname><given-names>C</given-names></name></person-group><article-title>Xgboost: a scalable tree boosting system</article-title>. In: <source>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</source>. <publisher-name>ACM</publisher-name>; <year>2016</year>:<fpage>785</fpage>–<lpage>94</lpage>.</mixed-citation>
    </ref>
    <ref id="bib37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><comment>H2O: Open-source machine learning platform for enterprises. <ext-link ext-link-type="uri" xlink:href="https://www.h2o.ai/h2o/">https://www.h2o.ai/h2o/</ext-link>. Accessed on July 1, 2019</comment>.</mixed-citation>
    </ref>
    <ref id="bib38">
      <label>38.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Oneto</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Cipollini</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Lulli</surname><given-names>A</given-names></name>, <etal>et al.</etal></person-group>ReForeSt. <comment><ext-link ext-link-type="uri" xlink:href="https://github.com/alessandrolulli/reforest">https://github.com/alessandrolulli/reforest</ext-link>. Accessed on July 1, 2019</comment>.</mixed-citation>
    </ref>
    <ref id="bib39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Tang</surname><given-names>Z</given-names></name>, <etal>et al.</etal></person-group><article-title>A parallel random forest algorithm for big data in a spark cloud computing environment</article-title>. <source>IEEE Trans Parallel Distrib Syst</source>. <year>2016</year>;<volume>28</volume>(<issue>4</issue>):<fpage>919</fpage>–<lpage>33</lpage>.</mixed-citation>
    </ref>
    <ref id="bib40">
      <label>40.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Abuzaid</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Bradley</surname><given-names>JK</given-names></name>, <name name-style="western"><surname>Liang</surname><given-names>FT</given-names></name>, <etal>et al.</etal></person-group><article-title>Yggdrasil: an optimized system for training deep decision trees at scale</article-title>. <source>Adv Neural Inf Process Syst</source>. <year>2016</year>;<volume>29</volume>:<fpage>3817</fpage>–<lpage>25</lpage>.</mixed-citation>
    </ref>
    <ref id="bib41">
      <label>41.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Breiman</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Friedman</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Olshen</surname><given-names>RA</given-names></name>, <etal>et al.</etal></person-group><source>Classification and Regression Trees</source>. <edition>1</edition>st ed. <publisher-loc>Belmont, CA, USA</publisher-loc>: <publisher-name>Wadsworth</publisher-name>; <year>1984</year>.</mixed-citation>
    </ref>
    <ref id="bib42">
      <label>42.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Kleinbaum</surname><given-names>DG</given-names></name>, <name name-style="western"><surname>Dietz</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Gail</surname><given-names>M</given-names></name>, <etal>et al.</etal></person-group><source>Logistic Regression</source>. <publisher-name>Springer</publisher-name>; <year>2002</year>.</mixed-citation>
    </ref>
    <ref id="bib43">
      <label>43.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bayat</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Szul</surname><given-names>P</given-names></name>, <name name-style="western"><surname>O’Brien</surname><given-names>AR</given-names></name>, <etal>et al.</etal></person-group><article-title>Supporting data for “VariantSpark: cloud-based machine learning for association study of complex phenotype and large-scale genomic data.”</article-title>. <source>GigaScience Database</source>. <year>2020</year>; <pub-id pub-id-type="doi">10.5524/100759</pub-id>.</mixed-citation>
    </ref>
    <ref id="bib44">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>1000 Genomes Project Consortium</collab></person-group><article-title>A global reference for human genetic variation</article-title>. <source>Nature</source>. <year>2015</year>;<volume>526</volume>(<issue>7571</issue>):<fpage>68</fpage>.<pub-id pub-id-type="pmid">26432245</pub-id></mixed-citation>
    </ref>
    <ref id="bib45">
      <label>45.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Bayat</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hosking</surname><given-names>B</given-names></name></person-group>, <comment>PEPS: Polygenic Epistatic Phenotype Simulator. <ext-link ext-link-type="uri" xlink:href="https://github.com/aehrc/PEPS">https://github.com/aehrc/PEPS</ext-link>. Accessed on July 1, 2019</comment>.</mixed-citation>
    </ref>
  </ref-list>
</back>
