<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLoS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8687584</article-id>
    <article-id pub-id-type="pmid">34879076</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1009682</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-21-01483</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Chemistry</subject>
          <subj-group>
            <subject>Chemical Compounds</subject>
            <subj-group>
              <subject>Organic Compounds</subject>
              <subj-group>
                <subject>Amino Acids</subject>
                <subj-group>
                  <subject>Basic Amino Acids</subject>
                  <subj-group>
                    <subject>Lysine</subject>
                  </subj-group>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Chemistry</subject>
          <subj-group>
            <subject>Organic Chemistry</subject>
            <subj-group>
              <subject>Organic Compounds</subject>
              <subj-group>
                <subject>Amino Acids</subject>
                <subj-group>
                  <subject>Basic Amino Acids</subject>
                  <subj-group>
                    <subject>Lysine</subject>
                  </subj-group>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Amino Acids</subject>
              <subj-group>
                <subject>Basic Amino Acids</subject>
                <subj-group>
                  <subject>Lysine</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Mathematical Functions</subject>
            <subj-group>
              <subject>Convolution</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Chemistry</subject>
          <subj-group>
            <subject>Chemical Reactions</subject>
            <subj-group>
              <subject>Methylation</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Statistical Methods</subject>
            <subj-group>
              <subject>Forecasting</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical Methods</subject>
              <subj-group>
                <subject>Forecasting</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Molecular Biology</subject>
          <subj-group>
            <subject>Molecular Biology Techniques</subject>
            <subj-group>
              <subject>Sequencing Techniques</subject>
              <subj-group>
                <subject>Protein Sequencing</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Molecular Biology Techniques</subject>
          <subj-group>
            <subject>Sequencing Techniques</subject>
            <subj-group>
              <subject>Protein Sequencing</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Post-Translational Modification</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Data Management</subject>
          <subj-group>
            <subject>Data Mining</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Development of an experiment-split method for benchmarking the generalization of a PTM site predictor: Lysine methylome as an example</article-title>
      <alt-title alt-title-type="running-head">Development of an experiment-split method for benchmarking the generalization of a model</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0736-8759</contrib-id>
        <name>
          <surname>Zou</surname>
          <given-names>Guoyang</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8569-8780</contrib-id>
        <name>
          <surname>Zou</surname>
          <given-names>Yang</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ma</surname>
          <given-names>Chenglong</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhao</surname>
          <given-names>Jiaojiao</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0266-8939</contrib-id>
        <name>
          <surname>Li</surname>
          <given-names>Lei</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff003" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>School of Basic Medicine, Qingdao University, Qingdao, China</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>College of Life Science, Qingdao University, Qingdao, China</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>School of Data Science and Software Engineering, Qingdao University, Qingdao, China</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Wang</surname>
          <given-names>Edwin</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>University of Calgary, CANADA</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>guoyang_zou@163.com</email> (GZ); <email>leili@qdu.edu.cn</email> (LL)</corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>8</day>
      <month>12</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>12</month>
      <year>2021</year>
    </pub-date>
    <volume>17</volume>
    <issue>12</issue>
    <elocation-id>e1009682</elocation-id>
    <history>
      <date date-type="received">
        <day>14</day>
        <month>8</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>25</day>
        <month>11</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2021 Zou et al</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Zou et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1009682.pdf"/>
    <abstract>
      <p>Many computational classifiers have been developed to predict different types of post-translational modification sites. Their performances are measured using cross-validation or independent test, in which experimental data from different sources are mixed and randomly split into training and test sets. However, the self-reported performances of most classifiers based on this measure are generally higher than their performances in the application of new experimental data. It suggests that the cross-validation method overestimates the generalization ability of a classifier. Here, we proposed a generalization estimate method, dubbed experiment-split test, where the experimental sources for the training set are different from those for the test set that simulate the data derived from a new experiment. We took the prediction of lysine methylome (Kme) as an example and developed a deep learning-based Kme site predictor (called DeepKme) with outstanding performance. We assessed the experiment-split test by comparing it with the cross-validation method. We found that the performance measured using the experiment-split test is lower than that measured in terms of cross-validation. As the test data of the experiment-split method were derived from an independent experimental source, this method could reflect the generalization of the predictor. Therefore, we believe that the experiment-split method can be applied to benchmark the practical performance of a given PTM model. DeepKme is free accessible via <ext-link xlink:href="https://github.com/guoyangzou/DeepKme" ext-link-type="uri">https://github.com/guoyangzou/DeepKme</ext-link>.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>The performance of a model for predicting post-translational modification sites is commonly evaluated using the cross-validation method, where the data derived from different experimental sources are mixed and randomly separated into the training dataset and validation dataset. However, the performance measured through cross-validation is generally higher than the performance in the application of new experimental data, indicating that the cross-validation method overestimates the generalization of a model. In this study, we proposed a generalization estimate method, dubbed experiment-split test, where the experimental sources for the training set are different from those for the test set that simulate the data derived from a new experiment. We took the prediction of lysine methylome as an example and developed a deep learning-based Kme site predictor DeepKme with outstanding performance. We found that the performance measured by the experiment-split method is lower than that measured in terms of cross-validation. As the test data of the experiment-split method were derived from an independent experimental source, this method could reflect the generalization of the prediction model. Therefore, the experiment-split method can be applied to benchmark the practical prediction performance.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100014718</institution-id>
            <institution>Innovative Research Group Project of the National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>31770821; 32071430</award-id>
      </award-group>
      <funding-statement>This work was supported in part by the National Natural Science Foundation of China under Grant 31770821 and Grant 32071430. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="7"/>
      <table-count count="3"/>
      <page-count count="14"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>PLOS Publication Stage</meta-name>
        <meta-value>vor-update-to-uncorrected-proof</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>Publication Update</meta-name>
        <meta-value>2021-12-20</meta-value>
      </custom-meta>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All the data are accessible through <ext-link xlink:href="https://github.com/guoyangzou/DeepKme/tree/main/orig_dataset" ext-link-type="uri">https://github.com/guoyangzou/DeepKme/tree/main/orig_dataset</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All the data are accessible through <ext-link xlink:href="https://github.com/guoyangzou/DeepKme/tree/main/orig_dataset" ext-link-type="uri">https://github.com/guoyangzou/DeepKme/tree/main/orig_dataset</ext-link>.</p>
  </notes>
</front>
<body>
  <disp-quote>
    <p>This is a <italic toggle="yes">PLOS Computational Biology</italic> Benchmarking paper.</p>
  </disp-quote>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Protein lysine methylation, as one type of dynamic and reversible post-translational modifications (PTMs) by protein lysine methyltransferases and demethylases, plays an important role in cell signaling and regulation [<xref rid="pcbi.1009682.ref001" ref-type="bibr">1</xref>]. This modification contains three different types: mono-, di- and tri-methylation (i.e. Kme1, Kme2 and Kme3). The majority of Kme sites are discovered through the combination of affinity purification and high-throughput mass spectrometry. Besides those identified by experiments, a bunch of computational approaches were developed for the prediction of Kme sites. A few predictors were based on Support Vector Machine (SVM) combined with different features, such as intrinsic disorder information [<xref rid="pcbi.1009682.ref002" ref-type="bibr">2</xref>] or linear functional motif as the feature [<xref rid="pcbi.1009682.ref003" ref-type="bibr">3</xref>]. Recently, a few predictors [<xref rid="pcbi.1009682.ref004" ref-type="bibr">4</xref>,<xref rid="pcbi.1009682.ref005" ref-type="bibr">5</xref>] were based on deep-learning (DL) algorithms. Cross-validation is the general method to evaluate prediction models using a limited data set. This data set is commonly composed of experimental data from different sources and randomly split into training and validation sets. The cross-validation evaluation is often considered the measure of the generalization ability. However, it is found that the self-reported performance, which was documented in the original literature calculated in terms of cross-validation and/or the independent test, overestimates the real accuracy based on newly constructed independent datasets [<xref rid="pcbi.1009682.ref006" ref-type="bibr">6</xref>–<xref rid="pcbi.1009682.ref008" ref-type="bibr">8</xref>]. It indicates that the self-reported performance may not be indicative of prediction quality. Therefore, experimentalists should be careful to use PTM predictors and independent assessments are necessary to evaluate their performances in practice [<xref rid="pcbi.1009682.ref007" ref-type="bibr">7</xref>,<xref rid="pcbi.1009682.ref008" ref-type="bibr">8</xref>].</p>
    <p>Here, we proposed a method for generalization estimation, called the experiment-split test, to benchmark models for their practical performances. In this method, the data of the training and test sets are derived from different experiments and the common data between both sets are removed from the test set so that both sets are independent. Therefore, the test set simulates a newly constructed independent dataset. To evaluate this novel method, we took the prediction of lysine methylome (Kme) as an example. We developed a DL-based predictor DeepKme with superior performance to existing methods. We found that the performance measured using cross-validation was larger than that measured using the experiment-split test. As the test set in the experiment-split method is derived from an independent experimental source, the experiment-split performance reflects the generalization ability of the predictor. DeepKme is free accessible via <ext-link xlink:href="https://github.com/guoyangzou/DeepKme" ext-link-type="uri">https://github.com/guoyangzou/DeepKme</ext-link>.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>Methods</title>
    <sec id="sec003">
      <title>Dataset construction and pre-processing</title>
      <p>The data about lysine methylation sites were collected through three approaches: database integration, data mining, and literature curation (<xref rid="pcbi.1009682.g001" ref-type="fig">Fig 1A</xref>), which include GPS-MSP [<xref rid="pcbi.1009682.ref009" ref-type="bibr">9</xref>], iPTMnet [<xref rid="pcbi.1009682.ref010" ref-type="bibr">10</xref>], PLMD [<xref rid="pcbi.1009682.ref011" ref-type="bibr">11</xref>], PhosphoSitePlus [<xref rid="pcbi.1009682.ref012" ref-type="bibr">12</xref>], dbPTM [<xref rid="pcbi.1009682.ref013" ref-type="bibr">13</xref>], UniProt [<xref rid="pcbi.1009682.ref014" ref-type="bibr">14</xref>] and literature [<xref rid="pcbi.1009682.ref015" ref-type="bibr">15</xref>]. We initially collected 5450 Kme sites from 2989 human proteins and all the sites were annotated with the original experimental sources (<xref rid="pcbi.1009682.s001" ref-type="supplementary-material">S1</xref> and <xref rid="pcbi.1009682.s002" ref-type="supplementary-material">S2</xref> Tables). We used a sequence window of 61 amino acids in length with “K” in the center to represent the site. If the central lysine residue is located near the N-terminus or C-terminus of the protein sequence, the symbol “X” is added at the related terminus to ensure the window sizes of the sequences are the same. After removing the replicates, 5229 Kme sequences were retained (<xref rid="pcbi.1009682.g001" ref-type="fig">Fig 1B</xref>). Four different labels (i.e. Kme1, Kme2, Kme3 and Kme) were assigned to each sequence if the sequence was modified by lysine mono-, di-, tri-methylation or methylation. Moreover, we collected 638,805 lysine sites without methylation annotations from human proteome as negative samples and their related sequences were unique and different from the positive sequences (<xref rid="pcbi.1009682.g001" ref-type="fig">Fig 1B and 1C</xref>).</p>
      <fig position="float" id="pcbi.1009682.g001">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009682.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>The working flow of data collection.</title>
        </caption>
        <graphic xlink:href="pcbi.1009682.g001" position="float"/>
      </fig>
    </sec>
    <sec id="sec004">
      <title>Experiment-split method</title>
      <p><xref rid="pcbi.1009682.g002" ref-type="fig">Fig 2</xref> illustrates the experiment-split test method. For instance, we collected data from <italic toggle="yes">n</italic> different experimental sources and therefore we could make the tests <italic toggle="yes">n</italic> times. In test <italic toggle="yes">i</italic>, the PTM data from the experimental source <italic toggle="yes">i</italic> were used as positives of the independent test dataset; the data from the rest experimental sources were considered the positive samples in the training dataset. It should be noted that the common data between the training and test sets are removed from the test set so that both sets are independent. For convenience and the consideration of computational cost, we randomly chose 40000 samples from all the non-PTM-containing proteins as negatives and split them into half, one for training and the other for testing. We reason that the performance estimation may be unreliable if the number of positive samples in the test set is extremely small or few test sets are available. Therefore, we balanced these two numbers. In this study, we evaluated the prediction performance based on at least five test sets and each containing at least five positive samples.</p>
      <fig position="float" id="pcbi.1009682.g002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009682.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Illustration of the experiment-split method.</title>
          <p><italic toggle="yes">En</italic> represents the data from the <italic toggle="yes">n</italic>th experimental source. Test <italic toggle="yes">n</italic> represents that the <italic toggle="yes">En</italic> data is used for the independent test and the rest experimental data for the training.</p>
        </caption>
        <graphic xlink:href="pcbi.1009682.g002" position="float"/>
      </fig>
    </sec>
    <sec id="sec005">
      <title>Feature encodings</title>
      <sec id="sec006">
        <title>One-Hot (OH) encoding</title>
        <p>It is represented by the conversion of the 20 types of amino acids to 20 binary bits. By considering the complemented symbol “X”, 21 (= 20+1) binary bits are used to represent a single position in the peptide sequence (<xref rid="pcbi.1009682.s005" ref-type="supplementary-material">S1 Fig</xref>). For example, the amino acid “Q” is represented by “100000000000000000000” and “H” is represented by “000000000000000000010”.</p>
      </sec>
      <sec id="sec007">
        <title>Position-Specific Scoring Matrix (PSSM) encoding</title>
        <p>It is generated through running the PSI-BLAST program and described elsewhere [<xref rid="pcbi.1009682.ref016" ref-type="bibr">16</xref>,<xref rid="pcbi.1009682.ref017" ref-type="bibr">17</xref>].</p>
      </sec>
      <sec id="sec008">
        <title>Word Embedding (WE) encoding</title>
        <p>Each item of the input sequence is encoded by One-Hot encoding to a 21-dimension binary vector, followed by a fully connected layer without nonlinear activation function which is used to decrease the vector to a five-dimension vector.</p>
      </sec>
    </sec>
    <sec id="sec009">
      <title>Model construction</title>
      <sec id="sec010">
        <title>The 1D-CNN Model with OH Encoding (CNN<sub>OH</sub>)</title>
        <p>This model contains four layers, listed below (<xref rid="pcbi.1009682.g003" ref-type="fig">Fig 3</xref>).</p>
        <list list-type="order">
          <list-item>
            <p>Input layer. Each input sequence of 61 amino acids is encoded by the OH encoding to a 61×21 binary matrix.</p>
          </list-item>
          <list-item>
            <p>Convolution layer. It consisted of two convolution sublayers, each followed by individual max-pooling sublayers, respectively. The first convolution sublayer includes 256 different convolution kernels with the size of 9×21. Each kernel is applied to the 61×21 matrix from the input layer and results in a feature vector with the size of 53 (= 61–9+1). Thus, the 256 kernels output a 53×256 matrix. Next, a pooling kernel with the size of 2 is applied to the feature matrix and produces a 26×256 matrix. In the second convolution sublayer, 32 different convolution kernels with the size 7×256 are applied to generate a 20×32 matrix, followed by a pooling kernel with size 2 that produces a 10×32 data matrix.</p>
          </list-item>
          <list-item>
            <p>Fully connected layer. The 10×32 data matrix generated from the convolution layer is nonlinearly transformed to 128 representative features.</p>
          </list-item>
          <list-item>
            <p>Output layer. The modification score is calculated based on the 128 features using the ‘Sigmoid’ function.</p>
          </list-item>
        </list>
        <fig position="float" id="pcbi.1009682.g003">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1009682.g003</object-id>
          <label>Fig 3</label>
          <caption>
            <title>The graph representation of the CNN<sub>OH</sub> model.</title>
            <p>(A) The input sequence consists of 61 amino acids. (B) In the input layer, the input sequence is represented by a binary matrix using the One-Hot encoding. (C) The convolution layer contains two convolution sublayers and two max-pooling sublayers. D) Fully connected layer. The output matrix from the convolution layer is nonlinearly transformed to 128 representative features. E) Output layer. The modification score is calculated based on the 128 features. The details are described in the Methods section.</p>
          </caption>
          <graphic xlink:href="pcbi.1009682.g003" position="float"/>
        </fig>
      </sec>
      <sec id="sec011">
        <title>The 1D-CNN Model with PSSM Encoding (CNN<sub>PSSM</sub>)</title>
        <p>It is similar to CNN<sub>OH</sub> except that the encoding approach is changed from OH to PSSM.</p>
      </sec>
      <sec id="sec012">
        <title>The 1D-CNN Model with WE layer (CNN<sub>WE</sub>)</title>
        <p>It is similar to CNN<sub>OH</sub> except that a fully connected layer is added behind the input layer of CNN<sub>OH</sub> that converts the 21-dimension binary vector into a five-dimension WE vector.</p>
      </sec>
      <sec id="sec013">
        <title>The LSTM Model with OH Encoding (LSTM<sub>OH</sub>)</title>
        <p>This model contains three layers (<xref rid="pcbi.1009682.g004" ref-type="fig">Fig 4</xref>).</p>
        <list list-type="order">
          <list-item>
            <p>Input layer. The sequence is represented by a 61×21 matrix through the OH encoding.</p>
          </list-item>
          <list-item>
            <p>LSTM layer. It includes seven LSTM sublayers. Every sublayer contains 61 sequentially connected LSTM cells, corresponding to the 61 amino acids of the input sequence. Each LSTM cell contains 32 hidden neuron units and outputs a vector with the size of 32. Every cell is used to process the information from the corresponding amino acid and the upstream LSTM cell. Next, 61 vectors outputted from the first LSTM sublayer are fed to the next LSTM sublayer. The same process is replicated until the last LSTM sublayer. Lastly, the vector from the 61st LSTM cell in the 7th LSTM sublayer is regarded as the output of the LSTM layer to represent the features of the input peptide sequence.</p>
          </list-item>
          <list-item>
            <p>Output layer. The vector of 32 features from the LSTM layer is used to calculate the modification score through the “Sigmoid” function.</p>
          </list-item>
        </list>
        <fig position="float" id="pcbi.1009682.g004">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1009682.g004</object-id>
          <label>Fig 4</label>
          <caption>
            <title>Graph representation of the LSTM<sub>OH</sub>.</title>
            <p>A) The input sequence consists of 61 amino acids. B) In the input layer, the sequence is represented by a 61×21 matrix through the One-Hot encoding. C) The LSTM layer includes seven LSTM sublayers. Every sublayer contains 61 sequentially connected LSTM cells, each of which contains 32 hidden neuron units. The output data from the former LSTM sublayer are fed to the latter LSTM sublayer. D) Output layer. The output from the LSTM layer is used to calculate the modification score.</p>
          </caption>
          <graphic xlink:href="pcbi.1009682.g004" position="float"/>
        </fig>
      </sec>
      <sec id="sec014">
        <title>The LSTM Model with PSSM Encoding (LSTM<sub>PSSM</sub>)</title>
        <p>It is similar to LSTM<sub>OH</sub> except that the encoding method is changed from OH to PSSM.</p>
      </sec>
      <sec id="sec015">
        <title>The LSTM Model with the WE layer (LSTM<sub>WE</sub>)</title>
        <p>It is similar to LSTM<sub>OH</sub> except that a fully connected layer is added behind the input layer of CNN<sub>OH</sub> that converts the 21-dimension binary vector into a five-dimension WE vector.</p>
      </sec>
      <sec id="sec016">
        <title>The GRU Models with OH Encoding (GRU<sub>OH</sub>), PSSM Encoding (GRU<sub>PSSM</sub>) or the WE layer (GRU<sub>WE</sub>)</title>
        <p>The models are similar to the corresponding LSTM models except that the LSTM cells are replaced by the GRU cells.</p>
      </sec>
    </sec>
    <sec id="sec017">
      <title>The strategy of avoiding overfitting</title>
      <p>The parameters in the DL models are trained and optimized based on binary cross-entropy loss function using the Adam algorithm. The maximum of the training cycles is set through the optimized number of epochs to ensure that the loss function value converged. In each epoch, the training dataset is separated with the batch size as 512 and iterated. To avoid overfitting, the early-stopping strategy is applied, where the training process is stopped early when the training loss does not go down within 25 consecutive iterations. The model with the smallest training loss is saved as the best model. Moreover, the dropout rates of the two CNN layers are set at 0.5 and 0.7 respectively, which are obtained through manual hyperparameter optimization.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="sec018">
    <title>Results</title>
    <sec id="sec019">
      <title>Existing Kme models evaluated using new data showed overestimation</title>
      <p>Most PTM predictors are measured using cross-validation but the blind assessment are not generally performed. Here, we took lysine methylome as the study case and investigated the reported Kme classifiers GPS-MSP and MusiteDeep [<xref rid="pcbi.1009682.ref005" ref-type="bibr">5</xref>] using multiple experimental sources as the test sets, which were independent of the training datasets of the models. The number of experimental sources varies according to the number of sources used for the model training. For instance, 29 different sources were used as the test sets to estimate the performance of the GPS-MSP Kme model whereas 49 distinct sources were selected for MusiteDeep. In addition, the common data between the training set and the test set were discarded from the test set. As GPS-MSP provided the predicted sensitivity value when the specificity value was set as 0.9, we fixed the specificity value as 0.9 as well for the independent test and used the same data preprocessing for the GPS-MSP construction. We performed the tests for all the four modification models and the sensitivity values were significantly lower than the self-reported values (Tables <xref rid="pcbi.1009682.t001" ref-type="table">1</xref> and <xref rid="pcbi.1009682.s003" ref-type="supplementary-material">S3</xref> and <xref rid="pcbi.1009682.g005" ref-type="fig">Fig 5</xref>), suggesting that the self-reported performance of GPS-MSP was overestimated. In addition, since the MusiteDeep performance was assessed using the AUC value, we used the AUC value to estimate its performance. Our calculated mean AUC value (0.606) is significantly smaller than the reported value (0.951; P = 0, single-sample t-test; Tables <xref rid="pcbi.1009682.t001" ref-type="table">1</xref> and <xref rid="pcbi.1009682.s003" ref-type="supplementary-material">S3</xref> and <xref rid="pcbi.1009682.g005" ref-type="fig">Fig 5</xref>). These two analyses indicate that the self-reported performance fails to represent the generalization ability. This caused our interest to develop a method for generalization estimation. It should be noted that GPS-MSP was designed to predict both lysine and arginine methylation sites and it may have a good prediction performance for arginine methylation sites.</p>
      <table-wrap position="float" id="pcbi.1009682.t001">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009682.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>The comparison between evaluated performances of GPS-MSP and MusiteDeep and their self-reported performances.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1009682.t001" id="pcbi.1009682.t001g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <tbody>
              <tr>
                <td align="center" colspan="5" rowspan="1">GPS-MSP</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Type</td>
                <td align="center" rowspan="1" colspan="1">Number of test datasets<xref rid="t001fn001" ref-type="table-fn"><sup>a</sup></xref></td>
                <td align="center" rowspan="1" colspan="1">Sn (tested in this study)<xref rid="t001fn002" ref-type="table-fn"><sup>b</sup></xref></td>
                <td align="center" rowspan="1" colspan="1">Sn (reported)<xref rid="t001fn002" ref-type="table-fn"><sup>b</sup></xref></td>
                <td align="center" rowspan="1" colspan="1">P value<xref rid="t001fn004" ref-type="table-fn"><sup>d</sup></xref></td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Kme1</td>
                <td align="center" rowspan="1" colspan="1">29</td>
                <td align="center" rowspan="1" colspan="1">0.088±0.103<xref rid="t001fn003" ref-type="table-fn"><sup>c</sup></xref></td>
                <td align="center" rowspan="1" colspan="1">0.466 [<xref rid="pcbi.1009682.ref011" ref-type="bibr">11</xref>]</td>
                <td align="center" rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Kme2</td>
                <td align="center" rowspan="1" colspan="1">12</td>
                <td align="center" rowspan="1" colspan="1">0.173±0.219<xref rid="t001fn003" ref-type="table-fn"><sup>c</sup></xref></td>
                <td align="center" rowspan="1" colspan="1">0.422 [<xref rid="pcbi.1009682.ref011" ref-type="bibr">11</xref>]</td>
                <td align="center" rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Kme3</td>
                <td align="center" rowspan="1" colspan="1">6</td>
                <td align="center" rowspan="1" colspan="1">0.072±0.076<xref rid="t001fn003" ref-type="table-fn"><sup>c</sup></xref></td>
                <td align="center" rowspan="1" colspan="1">0.764 [<xref rid="pcbi.1009682.ref011" ref-type="bibr">11</xref>]</td>
                <td align="center" rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Kme</td>
                <td align="center" rowspan="1" colspan="1">29</td>
                <td align="center" rowspan="1" colspan="1">0.160±0.113<xref rid="t001fn003" ref-type="table-fn"><sup>c</sup></xref></td>
                <td align="center" rowspan="1" colspan="1">0.445 [<xref rid="pcbi.1009682.ref011" ref-type="bibr">11</xref>]</td>
                <td align="center" rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td align="center" colspan="5" rowspan="1">MusiteDeep</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Type</td>
                <td align="center" rowspan="1" colspan="1">Number of test datasets</td>
                <td align="center" rowspan="1" colspan="1">AUC (tested in this study)</td>
                <td align="center" rowspan="1" colspan="1">AUC (reported)</td>
                <td align="center" rowspan="1" colspan="1">P value<xref rid="t001fn004" ref-type="table-fn"><sup>d</sup></xref></td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Kme</td>
                <td align="center" rowspan="1" colspan="1">49</td>
                <td align="center" rowspan="1" colspan="1">0.606±0.103<xref rid="t001fn003" ref-type="table-fn"><sup>c</sup></xref></td>
                <td align="center" rowspan="1" colspan="1">0.951 [<xref rid="pcbi.1009682.ref006" ref-type="bibr">6</xref>]</td>
                <td align="center" rowspan="1" colspan="1">0</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t001fn001">
            <p><sup>a</sup>Test datasets are derived from different experimental sources</p>
          </fn>
          <fn id="t001fn002">
            <p><sup>b</sup>Sensitivity value when specificity was set 0.9</p>
          </fn>
          <fn id="t001fn003">
            <p><sup>c</sup>These values represent the average and standard deviation (SD), respectively</p>
          </fn>
          <fn id="t001fn004">
            <p><sup>d</sup>P-value was calculated using a single-sample t-test.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <fig position="float" id="pcbi.1009682.g005">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009682.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <title>Performance of GPS-MSP and MusiteDeep assessed using different experimental sources.</title>
          <p>It included the GPS-MSP prediction performances for Kme1 (A), Kme2 (B), Kme3 (C) and Kme (D), and the MusiteDeep performance for Kme (E).</p>
        </caption>
        <graphic xlink:href="pcbi.1009682.g005" position="float"/>
      </fig>
    </sec>
    <sec id="sec020">
      <title>CNN<sub>OH</sub> and CNN<sub>PSSM</sub> performed best in the constructed models</title>
      <p>Computational approaches for predicting PTM sites are based on different algorithms and various predefined characteristics. Generally, the RF and SVM algorithm shows comparable prediction performance in traditional machine-learning (ML) algorithms [<xref rid="pcbi.1009682.ref018" ref-type="bibr">18</xref>,<xref rid="pcbi.1009682.ref019" ref-type="bibr">19</xref>]. Deep-learning algorithms have been widely used in PTMs prediction and demonstrated better performances than traditional ML algorithms [<xref rid="pcbi.1009682.ref004" ref-type="bibr">4</xref>,<xref rid="pcbi.1009682.ref020" ref-type="bibr">20</xref>–<xref rid="pcbi.1009682.ref024" ref-type="bibr">24</xref>]. Therefore, we only constructed and compared DL models for Kme prediction.</p>
      <p>We collected 4423 Kme1 sites, 635 Kme2 sites, 419 Kme3 sites and 5450 Kme sites from different sources (<xref rid="pcbi.1009682.g001" ref-type="fig">Fig 1</xref>). We constructed ten different DL models with distinct DL architectures and encoding approaches, e.g. CNN<sub>OH</sub>, LSTM<sub>WE</sub> and GRU<sub>PSSM</sub> (see <xref rid="sec002" ref-type="sec">Methods</xref> for details). Here, we selected the Kme1 type as the study case with the same number of positive and negative samples and constructed the related classifiers and compared their performances in terms of ten-fold cross-validation. The AUC values of CNN<sub>OH</sub> and CNN<sub>PSSM</sub> were similar (AUC = 0.817, P = 0.223) and significantly larger than those of other classifiers (P&lt;2.28×10<sup>−3</sup>) (<xref rid="pcbi.1009682.g006" ref-type="fig">Fig 6</xref>). Therefore, we selected CNN<sub>OH</sub> to construct the model DeepKme for the prediction of Kme1/Kme2/Kme3/Kme sites. The average AUC values of DeepKme for Kme1/Kme2/Kme3/Kme were 0.8355/0.7002/0.7579/0.8062 using ten-fold cross-validation, respectively.</p>
      <fig position="float" id="pcbi.1009682.g006">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009682.g006</object-id>
        <label>Fig 6</label>
        <caption>
          <title>The performances of different DL models for the prediction of Kme1 sites using ten-fold cross-validation.</title>
        </caption>
        <graphic xlink:href="pcbi.1009682.g006" position="float"/>
      </fig>
    </sec>
    <sec id="sec021">
      <title>Evaluation of generalization ability using experiment-split test and comparison with cross-validation</title>
      <p><ext-link xlink:href="https://linguaholic.com/linguablog/most-if-not-all-punctuation-commas/" ext-link-type="uri">Most if not all</ext-link> the models developed before are assessed in terms of cross-validation and/or independent test. The datasets of cross-validation and the independent test are a mixture of different experimental sources. Although the validation set and the independent set are different from the training set, they are not from the independent experimental source. This may be the main reason why the models fail to reach the reported performances in practice. Here, we developed the experiment-split method for estimating generalization (see <xref rid="sec002" ref-type="sec">Methods</xref> for detail). This method is based on the fact that there are multiple experimental sources and each of them can be considered the independent test set to estimate the performance. We performed 27/12/9/40 independent tests for the Kme1/Kme2/Kme3/Kme models, respectively. The mean AUC values for these models is 0.766, 0.660, 0.729 and 0.747, respectively (<xref rid="pcbi.1009682.t002" ref-type="table">Table 2</xref>). Specifically, the AUC values for the Kme1/Kme models are smaller than the corresponding AUC values calculated based on ten-fold cross-validation (P = 0.018 or 0.013), whereas the AUC values for the Kme2/Kme3 models are similar to the AUC values in terms of cross-validation (P = 0.16 or 0.44) (<xref rid="pcbi.1009682.t002" ref-type="table">Table 2</xref>). These comparisons indicate that the experiment-split method is the better measure of the generalization for the Kme1/Kme models than cross-validation, whereas both measures are comparable for the Kme2/Kme3 models. Additionally, the standard deviation (SD) values of the cross-validation performances are narrower than those of the experiment-split performances (P = 1.83E-2, paired t-test; <xref rid="pcbi.1009682.t002" ref-type="table">Table 2</xref>). For instance, the SD value of the former for the Kme2 model is smaller than 0.03 while that of the latter is larger than 0.08. It suggests that the data from different experimental sources are divergent and the mixture of these sources in cross-validation reduces the data diversity.</p>
      <table-wrap position="float" id="pcbi.1009682.t002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009682.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Performance comparison of CNN<sub>OH</sub> models between cross-validation and experiment-split test.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1009682.t002" id="pcbi.1009682.t002g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" rowspan="1" colspan="1">Modification type</th>
                <th align="center" rowspan="1" colspan="1">10-fold cross-validation<xref rid="t002fn001" ref-type="table-fn"><sup>a</sup></xref></th>
                <th align="center" rowspan="1" colspan="1">Experiment-split<xref rid="t002fn001" ref-type="table-fn"><sup>a</sup></xref></th>
                <th align="center" rowspan="1" colspan="1">P value<xref rid="t002fn002" ref-type="table-fn"><sup>b</sup></xref></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>Kme1</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.836±0.011</td>
                <td align="center" rowspan="1" colspan="1">0.766±0.141</td>
                <td align="center" rowspan="1" colspan="1">0.018</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>Kme2</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.700±0.026</td>
                <td align="center" rowspan="1" colspan="1">0.660±0.088</td>
                <td align="center" rowspan="1" colspan="1">0.16</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>Kme3</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.758±0.039</td>
                <td align="center" rowspan="1" colspan="1">0.729±0.096</td>
                <td align="center" rowspan="1" colspan="1">0.44</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>Kme</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.806±0.012</td>
                <td align="center" rowspan="1" colspan="1">0.747±0.140</td>
                <td align="center" rowspan="1" colspan="1">0.013</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t002fn001">
            <p><sup>a</sup>Average and SD of the AUC values</p>
          </fn>
          <fn id="t002fn002">
            <p><sup>b</sup>P-value was calculated using paired t-test.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>We compared the performances of GPS-MSP, MusiteDeep and our CNN<sub>OH</sub> model using the experiment-split method. As the three models are constructed using different training data and the data from the experimental sources for testing need to be independent of each training data, the test datasets for each model may be different and positive samples from the same experimental sources may also be distinct. Therefore, the construction of the test sets is complex compared to the construction of traditional cross-validation and independent datasets. Despite it, we reason that their performances can be fairly compared using statistical analysis. We collected the AUC values for the three models calculated using the experimental-split method (<xref rid="pcbi.1009682.s003" ref-type="supplementary-material">S3</xref> and <xref rid="pcbi.1009682.s004" ref-type="supplementary-material">S4</xref> Tables) and summarized them in <xref rid="pcbi.1009682.t003" ref-type="table">Table 3</xref>. The AUC values of the CNN<sub>OH</sub> models are statistically larger than those of the GPS-MSP and MusiteDeep models (<xref rid="pcbi.1009682.t003" ref-type="table">Table 3</xref>). Therefore, the CNN<sub>OH</sub> models have outstanding generation ability.</p>
      <table-wrap position="float" id="pcbi.1009682.t003">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009682.t003</object-id>
        <label>Table 3</label>
        <caption>
          <title>Comparison of experiment-split performances for the models.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1009682.t003" id="pcbi.1009682.t003g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" rowspan="1" colspan="1">Modification type</th>
                <th align="center" rowspan="1" colspan="1">CNN<sub>OH</sub><xref rid="t003fn001" ref-type="table-fn"><sup>a</sup></xref></th>
                <th align="center" rowspan="1" colspan="1">GPS-MSP<xref rid="t003fn001" ref-type="table-fn"><sup>a</sup></xref></th>
                <th align="center" rowspan="1" colspan="1">P value<xref rid="t002fn002" ref-type="table-fn"><sup>b</sup></xref></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>Kme1</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.766±0.143</td>
                <td align="center" rowspan="1" colspan="1">0.568±0.079</td>
                <td align="center" rowspan="1" colspan="1">3.13E-8</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>Kme2</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.660±0.092</td>
                <td align="center" rowspan="1" colspan="1">0.565±0.118</td>
                <td align="center" rowspan="1" colspan="1">0.039</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>Kme3</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.729±0.102</td>
                <td align="center" rowspan="1" colspan="1">0.515±0.092</td>
                <td align="center" rowspan="1" colspan="1">4.48E-3</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>Kme</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.747±0.141</td>
                <td align="center" rowspan="1" colspan="1">0.539±0.082</td>
                <td align="center" rowspan="1" colspan="1">9.42E-10</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">
                  <bold>CNN</bold>
                  <sub>
                    <bold>OH</bold>
                  </sub>
                  <xref rid="t003fn001" ref-type="table-fn">
                    <sup>
                      <bold>a</bold>
                    </sup>
                  </xref>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>MusiteDeep</bold>
                  <xref rid="t003fn001" ref-type="table-fn">
                    <sup>
                      <bold>a</bold>
                    </sup>
                  </xref>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>P value</bold>
                  <xref rid="t003fn002" ref-type="table-fn">
                    <sup>
                      <bold>b</bold>
                    </sup>
                  </xref>
                </td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>Kme</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.747±0.141</td>
                <td align="center" rowspan="1" colspan="1">0.606±0.103</td>
                <td align="center" rowspan="1" colspan="1">2.11E-3</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t003fn001">
            <p><sup>a</sup>Average and SD of the AUC values</p>
          </fn>
          <fn id="t003fn002">
            <p><sup>b</sup>P-value was calculated using the student’s t-test.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec022">
    <title>Discussion and conclusions</title>
    <p>Cross-validation is the common resampling technique to evaluate machine-learning models constructed using a limited amount of samples. It is used to assess the <ext-link xlink:href="https://en.wikipedia.org/wiki/Generalization_error" ext-link-type="uri">generalization of a predictive model</ext-link> to independent data sets and estimate the practical accuracy of a <ext-link xlink:href="https://en.wikipedia.org/wiki/Predictive_modelling" ext-link-type="uri">predictive model</ext-link>. Nevertheless, based on newly constructed independent datasets, the cross-validation performance is repeatedly found to overestimate the real accuracy measured on independent datasets [<xref rid="pcbi.1009682.ref006" ref-type="bibr">6</xref>–<xref rid="pcbi.1009682.ref008" ref-type="bibr">8</xref>]. For example, 11 online programs for the prediction of four lysine PTM types (i.e. acetylation, methylation, SUMOylation and ubiquitination) were assessed and nine of them performed close to random [<xref rid="pcbi.1009682.ref008" ref-type="bibr">8</xref>]. To further estimate the reported performance in literature, we tested two models (GPS-MSP [<xref rid="pcbi.1009682.ref009" ref-type="bibr">9</xref>] and MusiteDeep [<xref rid="pcbi.1009682.ref005" ref-type="bibr">5</xref>]) using different experimental sources. GPS-MSP was designed to predict lysine and arginine PTM sites based on the traditional machine-learning algorithm whereas MusiteDeep was developed to predict the sites of multiple PTM types based on a deep-learning algorithm. We found that the performances of both models in terms of the independent test were lower than the self-reported performances. This observation is consistent with the previous observations [<xref rid="pcbi.1009682.ref006" ref-type="bibr">6</xref>–<xref rid="pcbi.1009682.ref008" ref-type="bibr">8</xref>].</p>
    <p>To find the proper measure indicative of prediction quality in practice, we developed the experiment-split method. This method requires numerous experimental sources so that each source can be considered the independent test dataset. We took lysine methylome as the study case because of a variety of experimental sources available. We constructed four CNN<sub>OH</sub> models corresponding to the prediction of Kme1/Kme2/Kme3/Kme, respectively. We found that the experiment-split performances of the Kme1/Kme models were smaller than the related cross-validation performances, whereas the experiment-split performances for the Kme2/Kme3 models were similar to those evaluated using the cross-validation. As the test set of the experiment-split method is the data from an independent experimental source, the experiment-split measure could reflect the generalization ability of a model.</p>
    <p>Although the experiment-split method is suitable to assess the generation ability of a prediction model, it has several disadvantages. First, it requires a variety of experimental sources. The more the number of experimental sources, the more reliable the experiment-split performance. Second, different experimental sources are not uniform in size and the performance of the model built based on a small training dataset may be lower than that of the model constructed using a large training dataset. Therefore, the experimental sources with big PTM data are suitable to be considered part of the training set rather than the test set. We suggest here that the independent test data set should occupy less than 1/5 of the total collected data. Third, the experiment-split performances are diverse for different experiment sources, suggesting the difficulty in reliably estimating the prediction performance for a given experiment. It is true since the PTMs in the different cells or tissues are catalyzed by different enzymes with diverse characteristics and the PTMs identified from these cells or tissues have distinct features. If the data set to be predicted contains the information included in the training set, the developed model may show good prediction performance; otherwise, the performance seems poor. The suggested solution for this disadvantage is the collection of more experimental sources for testing and statistical analyses need to be used for the estimation. Although the experiment-split method has these drawbacks, this method is reliable to estimate the generalization of a predictor compared to cross-validation (<xref rid="pcbi.1009682.g007" ref-type="fig">Fig 7</xref> and <xref rid="pcbi.1009682.t002" ref-type="table">Table 2</xref>).</p>
    <fig position="float" id="pcbi.1009682.g007">
      <object-id pub-id-type="doi">10.1371/journal.pcbi.1009682.g007</object-id>
      <label>Fig 7</label>
      <caption>
        <title>The CNN<sub>OH</sub> performances were assessed by the experiment-split method.</title>
        <p>The performances of the CNN<sub>OH</sub> model for Kme1 (A), Kme2 (B), Kme3 (C) and Kme (D) were evaluated using various independent experimental sources, respectively.</p>
      </caption>
      <graphic xlink:href="pcbi.1009682.g007" position="float"/>
    </fig>
  </sec>
  <sec id="sec023" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pcbi.1009682.s001" position="float" content-type="local-data">
      <label>S1 Table</label>
      <caption>
        <title>Summary of the data size from different resources.</title>
        <p>(DOCX)</p>
      </caption>
      <media xlink:href="pcbi.1009682.s001.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1009682.s002" position="float" content-type="local-data">
      <label>S2 Table</label>
      <caption>
        <title>Summary of the data size from different experimental sources.</title>
        <p>(DOCX)</p>
      </caption>
      <media xlink:href="pcbi.1009682.s002.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1009682.s003" position="float" content-type="local-data">
      <label>S3 Table</label>
      <caption>
        <title>Prediction performance for MSP and MusiteDeep in terms of the experiment-split test.</title>
        <p>(DOCX)</p>
      </caption>
      <media xlink:href="pcbi.1009682.s003.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1009682.s004" position="float" content-type="local-data">
      <label>S4 Table</label>
      <caption>
        <title>Prediction performance for CNN<sub>OH</sub> in terms of the experiment-split test.</title>
        <p>(DOCX)</p>
      </caption>
      <media xlink:href="pcbi.1009682.s004.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1009682.s005" position="float" content-type="local-data">
      <label>S1 Fig</label>
      <caption>
        <title>Illustration of the One-Hot encoding.</title>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pcbi.1009682.s005.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1009682.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Murn</surname><given-names>J</given-names></name>, <name><surname>Shi</surname><given-names>Y</given-names></name>. <article-title>The winding path of protein methylation research: milestones and new frontiers</article-title>. <source>Nature Reviews Molecular Cell Biology</source>. <year>2017</year>;<volume>18</volume>: <fpage>517</fpage>–<lpage>527</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nrm.2017.35</pub-id><?supplied-pmid 28512349?><pub-id pub-id-type="pmid">28512349</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Daily</surname><given-names>KM</given-names></name>, <name><surname>Radivojac</surname><given-names>P</given-names></name>, <name><surname>Dunker</surname><given-names>AK</given-names></name>. <article-title>Intrinsic Disorder and Prote in Modifications: Building an SVM Predictor for Methylation.</article-title><source>2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology</source>. <year>2005</year>. pp. <fpage>1</fpage>–<lpage>7</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/CIBCB.2005.1594957</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Plewczynski</surname><given-names>D</given-names></name>, <name><surname>Tkacz</surname><given-names>A</given-names></name>, <name><surname>Wyrwicz</surname><given-names>LS</given-names></name>, <name><surname>Rychlewski</surname><given-names>L</given-names></name>. <article-title>AutoMotif server: prediction of single residue post-translational modifications in proteins</article-title>. <source>Bioinformatics</source>. <year>2005</year>;<volume>21</volume>: <fpage>2525</fpage>–<lpage>2527</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/bti333</pub-id><?supplied-pmid 15728119?><pub-id pub-id-type="pmid">15728119</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>Z</given-names></name>, <name><surname>Liu</surname><given-names>X</given-names></name>, <name><surname>Li</surname><given-names>F</given-names></name>, <name><surname>Li</surname><given-names>C</given-names></name>, <name><surname>Marquez-Lago</surname><given-names>T</given-names></name>, <name><surname>Leier</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Large-scale comparative assessment of computational predictors for lysine post-translational modification sites</article-title>. <source>Brief Bioinformatics</source>. <year>2019</year>;<volume>20</volume>: <fpage>2267</fpage>–<lpage>2290</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/bby089</pub-id><?supplied-pmid 30285084?><pub-id pub-id-type="pmid">30285084</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>D</given-names></name>, <name><surname>Liu</surname><given-names>D</given-names></name>, <name><surname>Yuchi</surname><given-names>J</given-names></name>, <name><surname>He</surname><given-names>F</given-names></name>, <name><surname>Jiang</surname><given-names>Y</given-names></name>, <name><surname>Cai</surname><given-names>S</given-names></name>, <etal>et al</etal>. <article-title>MusiteDeep: a deep-learning based webserver for protein post-translational modification site prediction and visualization</article-title>. <source>Nucleic Acids Research</source>. <year>2020</year>;<volume>48</volume>: <fpage>W140</fpage>–<lpage>W146</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkaa275</pub-id><?supplied-pmid 32324217?><pub-id pub-id-type="pmid">32324217</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Peters</surname><given-names>B</given-names></name>, <name><surname>Brenner</surname><given-names>SE</given-names></name>, <name><surname>Wang</surname><given-names>E</given-names></name>, <name><surname>Slonim</surname><given-names>D</given-names></name>, <name><surname>Kann</surname><given-names>MG</given-names></name>. <article-title>Putting benchmarks in their rightful place: The heart of computational biology</article-title>. <source>PLOS Computational Biology</source>. <year>2018</year>;<volume>14</volume>: <fpage>e1006494</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006494</pub-id><?supplied-pmid 30408027?><pub-id pub-id-type="pmid">30408027</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Piovesan</surname><given-names>D</given-names></name>, <name><surname>Hatos</surname><given-names>A</given-names></name>, <name><surname>Minervini</surname><given-names>G</given-names></name>, <name><surname>Quaglia</surname><given-names>F</given-names></name>, <name><surname>Monzon</surname><given-names>AM</given-names></name>, <name><surname>Tosatto</surname><given-names>SCE</given-names></name>. <article-title>Assessing predictors for new post translational modification sites: A case study on hydroxylation.</article-title><source>PLoS Comput Biol</source>. <year>2020</year>;<volume>16</volume>: <fpage>e1007967</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007967</pub-id><?supplied-pmid 32569263?><pub-id pub-id-type="pmid">32569263</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Schwartz</surname><given-names>D.</given-names></name><article-title>Prediction of lysine post-translational modifications using bioinformatic tools</article-title>. <source>Essays Biochem</source>. <year>2012</year>;<volume>52</volume>: <fpage>165</fpage>–<lpage>177</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1042/bse0520165</pub-id><?supplied-pmid 22708570?><pub-id pub-id-type="pmid">22708570</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Deng</surname><given-names>W</given-names></name>, <name><surname>Wang</surname><given-names>Y</given-names></name>, <name><surname>Ma</surname><given-names>L</given-names></name>, <name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Ullah</surname><given-names>S</given-names></name>, <name><surname>Xue</surname><given-names>Y</given-names></name>. <article-title>Computational prediction of methylation types of covalently modified lysine and arginine residues in proteins</article-title>. <source>Brief Bioinformatics</source>. <year>2017</year>;<volume>18</volume>: <fpage>647</fpage>–<lpage>658</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/bbw041</pub-id><?supplied-pmid 27241573?><pub-id pub-id-type="pmid">27241573</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>H</given-names></name>, <name><surname>Arighi</surname><given-names>CN</given-names></name>, <name><surname>Ross</surname><given-names>KE</given-names></name>, <name><surname>Ren</surname><given-names>J</given-names></name>, <name><surname>Li</surname><given-names>G</given-names></name>, <name><surname>Chen</surname><given-names>S-C</given-names></name>, <etal>et al</etal>. <article-title>iPTMnet: an integrated resource for protein post-translational modification network discovery</article-title>. <source>Nucleic Acids Res</source>. <year>2018</year>;<volume>46</volume>: <fpage>D542</fpage>–<lpage>D550</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkx1104</pub-id><?supplied-pmid 29145615?><pub-id pub-id-type="pmid">29145615</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Xu</surname><given-names>H</given-names></name>, <name><surname>Zhou</surname><given-names>J</given-names></name>, <name><surname>Lin</surname><given-names>S</given-names></name>, <name><surname>Deng</surname><given-names>W</given-names></name>, <name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Xue</surname><given-names>Y</given-names></name>. <article-title>PLMD: An updated data resource of protein lysine modifications</article-title>. <source>Journal of Genetics and Genomics</source>. <year>2017</year>;<volume>44</volume>: <fpage>243</fpage>–<lpage>250</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jgg.2017.03.007</pub-id><?supplied-pmid 28529077?><pub-id pub-id-type="pmid">28529077</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Hornbeck</surname><given-names>PV</given-names></name>, <name><surname>Zhang</surname><given-names>B</given-names></name>, <name><surname>Murray</surname><given-names>B</given-names></name>, <name><surname>Kornhauser</surname><given-names>JM</given-names></name>, <name><surname>Latham</surname><given-names>V</given-names></name>, <name><surname>Skrzypek</surname><given-names>E</given-names></name>. <article-title>PhosphoSitePlus, 2014: mutations, PTMs and recalibrations</article-title>. <source>Nucleic Acids Res</source>. <year>2015</year>;<volume>43</volume>: <fpage>D512</fpage>–<lpage>520</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gku1267</pub-id><?supplied-pmid 25514926?><pub-id pub-id-type="pmid">25514926</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>K-Y</given-names></name>, <name><surname>Lee</surname><given-names>T-Y</given-names></name>, <name><surname>Kao</surname><given-names>H-J</given-names></name>, <name><surname>Ma</surname><given-names>C-T</given-names></name>, <name><surname>Lee</surname><given-names>C-C</given-names></name>, <name><surname>Lin</surname><given-names>T-H</given-names></name>, <etal>et al</etal>. <article-title>dbPTM in 2019: exploring disease association and cross-talk of post-translational modifications</article-title>. <source>Nucleic Acids Res</source>. <year>2019</year>;<volume>47</volume>: <fpage>D298</fpage>–<lpage>D308</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gky1074</pub-id><?supplied-pmid 30418626?><pub-id pub-id-type="pmid">30418626</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><collab>UniProt Consortium</collab>. <article-title>Update on activities at the Universal Protein Resource (UniProt) in 2013</article-title>. <source>Nucleic Acids Res</source>. <year>2013</year>;<volume>41</volume>: <fpage>D43</fpage>–<lpage>47</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gks1068</pub-id><?supplied-pmid 23161681?><pub-id pub-id-type="pmid">23161681</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>R</given-names></name>, <name><surname>Huang</surname><given-names>M</given-names></name>, <name><surname>Li</surname><given-names>L</given-names></name>, <name><surname>Kaneko</surname><given-names>T</given-names></name>, <name><surname>Voss</surname><given-names>C</given-names></name>, <name><surname>Zhang</surname><given-names>L</given-names></name>, <etal>et al</etal>. <article-title>Affinity Purification of Methyllysine Proteome by Site-Specific Covalent Conjugation</article-title>. <source>Anal Chem</source>. <year>2018</year>;<volume>90</volume>: <fpage>13876</fpage>–<lpage>13881</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1021/acs.analchem.8b02796</pub-id><?supplied-pmid 30395435?><pub-id pub-id-type="pmid">30395435</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Altschul</surname><given-names>SF</given-names></name>, <name><surname>Madden</surname><given-names>TL</given-names></name>, <name><surname>Schäffer</surname><given-names>AA</given-names></name>, <name><surname>Zhang</surname><given-names>J</given-names></name>, <name><surname>Zhang</surname><given-names>Z</given-names></name>, <name><surname>Miller</surname><given-names>W</given-names></name>, <etal>et al</etal>. <article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>. <source>Nucleic Acids Res</source>. <year>1997</year>;<volume>25</volume>: <fpage>3389</fpage>–<lpage>3402</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/25.17.3389</pub-id><?supplied-pmid 9254694?><pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>Z</given-names></name>, <name><surname>Zhao</surname><given-names>P</given-names></name>, <name><surname>Li</surname><given-names>F</given-names></name>, <name><surname>Leier</surname><given-names>A</given-names></name>, <name><surname>Marquez-Lago</surname><given-names>TT</given-names></name>, <name><surname>Wang</surname><given-names>Y</given-names></name>, <etal>et al</etal>. <article-title>iFeature: a Python package and web server for features extraction and selection from protein and peptide sequences</article-title>. <source>Bioinformatics</source>. <year>2018</year>;<volume>34</volume>: <fpage>2499</fpage>–<lpage>2502</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/bty140</pub-id><?supplied-pmid 29528364?><pub-id pub-id-type="pmid">29528364</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>K-Y</given-names></name>, <name><surname>Hsu</surname><given-names>JB-K</given-names></name>, <name><surname>Lee</surname><given-names>T-Y</given-names></name>. <article-title>Characterization and Identification of Lysine Succinylation Sites based on Deep Learning Method</article-title>. <source>Sci Rep</source>. <year>2019</year>;<volume>9</volume>: <fpage>16175</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-019-52552-4</pub-id><?supplied-pmid 31700141?><pub-id pub-id-type="pmid">31700141</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Lyu</surname><given-names>X</given-names></name>, <name><surname>Li</surname><given-names>S</given-names></name>, <name><surname>Jiang</surname><given-names>C</given-names></name>, <name><surname>He</surname><given-names>N</given-names></name>, <name><surname>Chen</surname><given-names>Z</given-names></name>, <name><surname>Zou</surname><given-names>Y</given-names></name>, <etal>et al</etal>. <article-title>DeepCSO: A Deep-Learning Network Approach to Predicting Cysteine S-Sulphenylation Sites.</article-title><source>Front Cell Dev Biol</source>. <year>2020</year>;<fpage>8</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fcell.2020.00008</pub-id><?supplied-pmid 32117959?><pub-id pub-id-type="pmid">32117959</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>Z</given-names></name>, <name><surname>He</surname><given-names>N</given-names></name>, <name><surname>Huang</surname><given-names>Y</given-names></name>, <name><surname>Qin</surname><given-names>WT</given-names></name>, <name><surname>Liu</surname><given-names>X</given-names></name>, <name><surname>Li</surname><given-names>L</given-names></name>. <article-title>Integration of A Deep Learning Classifier with A Random Forest Approach for Predicting Malonylation Sites</article-title>. <source>Genomics, Proteomics &amp; Bioinformatics</source>. <year>2018</year>;<volume>16</volume>: <fpage>451</fpage>–<lpage>459</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.gpb.2018.08.004</pub-id><?supplied-pmid 30639696?><pub-id pub-id-type="pmid">30639696</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>Y</given-names></name>, <name><surname>He</surname><given-names>N</given-names></name>, <name><surname>Chen</surname><given-names>Y</given-names></name>, <name><surname>Chen</surname><given-names>Z</given-names></name>, <name><surname>Li</surname><given-names>L</given-names></name>. <article-title>BERMP: a cross-species classifier for predicting m6A sites by integrating a deep learning algorithm and a random forest approach</article-title>. <source>Int J Biol Sci</source>. <year>2018</year>;<volume>14</volume>: <fpage>1669</fpage>–<lpage>1677</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.7150/ijbs.27819</pub-id><?supplied-pmid 30416381?><pub-id pub-id-type="pmid">30416381</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>X</given-names></name>, <name><surname>Sha</surname><given-names>Y</given-names></name>, <name><surname>Zhao</surname><given-names>Y</given-names></name>, <name><surname>He</surname><given-names>N</given-names></name>, <name><surname>Li</surname><given-names>L</given-names></name>. <article-title>DeepKcrot: A Deep-Learning Architecture for General and Species-Specific Lysine Crotonylation Site Prediction</article-title>. <source>IEEE Access.</source><year>2021</year>;<volume>9</volume>: <fpage>49504</fpage>–<lpage>49513</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/ACCESS.2021.3068413</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>L</given-names></name>, <name><surname>Zou</surname><given-names>Y</given-names></name>, <name><surname>He</surname><given-names>N</given-names></name>, <name><surname>Chen</surname><given-names>Y</given-names></name>, <name><surname>Chen</surname><given-names>Z</given-names></name>, <name><surname>Li</surname><given-names>L</given-names></name>. <article-title>DeepKhib: A Deep-Learning Framework for Lysine 2-Hydroxyisobutyrylation Sites Prediction.</article-title><source>Front Cell Dev Biol</source>. <year>2020</year>;<fpage>8</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fcell.2020.00008</pub-id><?supplied-pmid 32117959?><pub-id pub-id-type="pmid">32117959</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009682.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>Zhao</surname><given-names>Y</given-names></name>, <name><surname>He</surname><given-names>N</given-names></name>, <name><surname>Chen</surname><given-names>Z</given-names></name>, <name><surname>Li</surname><given-names>L</given-names></name>. <article-title>Identification of Protein Lysine Crotonylation Sites by a Deep Learning Framework With Convolutional Neural Networks</article-title>. <source>IEEE Access</source>. <year>2020</year>;<volume>8</volume>: <fpage>14244</fpage>–<lpage>14252</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/ACCESS.2020.2966592</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
