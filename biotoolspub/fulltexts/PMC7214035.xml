<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7214035</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa085</article-id>
    <article-id pub-id-type="publisher-id">btaa085</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Bioimage Informatics</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>ColocML: machine learning quantifies co-localization between mass spectrometry images</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Ovchinnikova</surname>
          <given-names>Katja</given-names>
        </name>
        <xref ref-type="aff" rid="btaa085-aff1">b1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Stuart</surname>
          <given-names>Lachlan</given-names>
        </name>
        <xref ref-type="aff" rid="btaa085-aff1">b1</xref>
        <xref ref-type="author-notes" rid="btaa085-FM2"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rakhlin</surname>
          <given-names>Alexander</given-names>
        </name>
        <xref ref-type="aff" rid="btaa085-aff2">b2</xref>
        <xref ref-type="author-notes" rid="btaa085-FM2"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Nikolenko</surname>
          <given-names>Sergey</given-names>
        </name>
        <xref ref-type="aff" rid="btaa085-aff3">b3</xref>
        <xref ref-type="aff" rid="btaa085-aff4">b4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Alexandrov</surname>
          <given-names>Theodore</given-names>
        </name>
        <xref ref-type="corresp" rid="btaa085-cor1"/>
        <xref ref-type="aff" rid="btaa085-aff1">b1</xref>
        <xref ref-type="aff" rid="btaa085-aff5">b5</xref>
        <xref ref-type="aff" rid="btaa085-aff6">b6</xref>
        <!--<email>theodore.alexandrov@embl.de</email>-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Valencia</surname>
          <given-names>Alfonso</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <aff id="btaa085-aff1"><label>b1</label><institution>Structural and Computational Biology Unit</institution>, <institution>European Molecular Biology Laboratory</institution>, Heidelberg, Germany</aff>
    <aff id="btaa085-aff2"><label>b2</label><institution>Neuromation OU</institution>, Tallinn, Estonia</aff>
    <aff id="btaa085-aff3">
      <label>b3</label>
      <institution>National Research Institute Higher School of Economics</institution>
    </aff>
    <aff id="btaa085-aff4"><label>b4</label><institution>Steklov Institute of Mathematics at St. Petersburg</institution>, St. Petersburg, Russia</aff>
    <aff id="btaa085-aff5"><label>b5</label><institution>Metabolomics Core Facility, European Molecular Biology Laboratory</institution>, Heidelberg, Germany</aff>
    <aff id="btaa085-aff6"><label>b6</label><institution>Skaggs School of Pharmacy and Pharmaceutical Sciences, University of California San Diego</institution>, La Jolla, CA, USA</aff>
    <author-notes>
      <fn id="btaa085-FM2">
        <label>
          <sup>†</sup>
        </label>
        <p>The authors wish it to be known that Lachlan Stuart and Alexander Rakhlin contributed equally.</p>
      </fn>
      <corresp id="btaa085-cor1">To whom correspondence should be addressed. <email>theodore.alexandrov@embl.de</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>15</day>
      <month>5</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-02-12">
      <day>12</day>
      <month>2</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>12</day>
      <month>2</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>10</issue>
    <fpage>3215</fpage>
    <lpage>3224</lpage>
    <history>
      <date date-type="received">
        <day>04</day>
        <month>9</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>22</day>
        <month>1</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>04</day>
        <month>2</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa085.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Imaging mass spectrometry (imaging MS) is a prominent technique for capturing distributions of molecules in tissue sections. Various computational methods for imaging MS rely on quantifying spatial correlations between ion images, referred to as co-localization. However, no comprehensive evaluation of co-localization measures has ever been performed; this leads to arbitrary choices and hinders method development.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We present ColocML, a machine learning approach addressing this gap. With the help of 42 imaging MS experts from nine laboratories, we created a gold standard of 2210 pairs of ion images ranked by their co-localization. We evaluated existing co-localization measures and developed novel measures using term frequency–inverse document frequency and deep neural networks. The semi-supervised deep learning Pi model and the cosine score applied after median thresholding performed the best (Spearman 0.797 and 0.794 with expert rankings, respectively). We illustrate these measures by inferring co-localization properties of 10 273 molecules from 3685 public METASPACE datasets.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p><ext-link ext-link-type="uri" xlink:href="https://github.com/metaspace2020/coloc">https://github.com/metaspace2020/coloc</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>European Union’s Horizon 2020 programme</institution>
          </institution-wrap>
        </funding-source>
        <award-id>Nº634402</award-id>
        <award-id>Nº777222</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Russian Foundation for Basic Research</institution>
            <institution-id institution-id-type="DOI">10.13039/501100002261</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>18-54-74005</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>European Research Council Consolidator</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>METACELL</institution>
          </institution-wrap>
        </funding-source>
        <award-id>Nº773089</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Metabolites and lipids play key roles in fuelling and making up cells, ultimately determining their types and states. Concentrations of metabolites and lipids are carefully regulated to maintain homeostasis in tissues, organs and organisms, and are profoundly and sometimes irreversibly altered in disease. Capturing spatial distributions of molecules in tissue sections is a prerequisite for any hypothesis-driven or discovery-oriented investigation of biology and medicine on the levels of tissues and the organism. In the past two decades, a window of opportunity has been opened by the development and further maturation of imaging mass spectrometry (imaging MS), a powerful and versatile technology for spatial molecular analysis (<xref rid="btaa085-B6" ref-type="bibr">Buchberger <italic>et al.</italic>, 2018</xref>; <xref rid="btaa085-B9" ref-type="bibr">Doerr, 2018</xref>; <xref rid="btaa085-B10" ref-type="bibr">Dreisewerd and Yew, 2017</xref>) with a particular interest in clinical (<xref rid="btaa085-B23" ref-type="bibr">Vaysse <italic>et al.</italic>, 2017</xref>) and pharmaceutical applications (<xref rid="btaa085-B22" ref-type="bibr">Schulz <italic>et al.</italic>, 2019</xref>). For a tissue section, imaging MS generates a hyperspectral image encompassing thousands to millions of ion images, each image representing the distribution of a particular molecule or several molecules in the section. Rapid development and growing popularity of imaging MS, as well as the high dimensionality and sheer size of generated data, measuring up to hundreds of gigabytes for a tissue section, have stimulated the development of computational methods and software (<xref rid="btaa085-B2" ref-type="bibr">Alexandrov, 2012</xref>). Various methods have been developed for low-dimensional data representation (based on PCA, NMF, t-SNE, bi-clustering), finding spatial regions of interest with spatial segmentation, search for markers associated with a region of interest, and, recently, for metabolite annotation (<xref rid="btaa085-B21" ref-type="bibr">Palmer <italic>et al.</italic>, 2017</xref>). Many of these methods use some measure of spatial similarity between ion images, often referred to as <italic>spatial co-localization</italic>. Various measures for quantifying co-localization have been proposed, including the Pearson correlation, cosine score, Euclidean L<sub>2</sub>-measures (<xref rid="btaa085-B2" ref-type="bibr">Alexandrov, 2012</xref>; <xref rid="btaa085-B3" ref-type="bibr">Alexandrov <italic>et al.</italic>, 2010</xref>; <xref rid="btaa085-B16" ref-type="bibr">McCombie <italic>et al.</italic>, 2005</xref>; <xref rid="btaa085-B17" ref-type="bibr">McDonnell <italic>et al.</italic>, 2008</xref>) sometimes applied to transformed images, e.g. after hotspot removal or log-transformation (<xref rid="btaa085-B25" ref-type="bibr">Watrous <italic>et al.</italic>, 2011</xref>). Recently, new measures adopted from other fields have been proposed, including the structural similarity index (SSIM) and hypergeometric similarity measure (<xref rid="btaa085-B1" ref-type="bibr">Aaron <italic>et al.</italic>, 2018</xref>; <xref rid="btaa085-B11" ref-type="bibr">Ekelöf <italic>et al.</italic>, 2018</xref>; <xref rid="btaa085-B13" ref-type="bibr">Kaddi <italic>et al.</italic>, 2011</xref>). However, despite the ubiquity of using spatial co-localization in imaging MS and a variety of measures proposed, no rigorous and comprehensive evaluation of co-localization measures has ever been performed.</p>
    <p>This leads to arbitrary and often <italic>ad hoc</italic> choice of a co-localization measure in every particular study, laboratory or software package. Moreover, it hinders the progress of imaging MS methods since new co-localization measures are faced with scepticism without objective criteria to demonstrate their advantages. This gap has persisted for over a decade due to the lack of ground truth data that would allow one to evaluate a measure objectively. Obtaining ground truth data is challenging because it requires a comprehensive inventory of which molecules are represented in imaging MS data and which of them are co-localized. This is not possible for tissues and hardly possible even for authentic standards due to our limited understanding of ionization of complex mixtures.</p>
    <p>Here, we are addressing this apparent gap by presenting ColocML, a machine learning approach to quantify co-localization between ion images. First, we present a gold standard set of pairs of ion images ranked by imaging MS experts by the perceived co-localization. This effort was enabled by METASPACE, the open knowledge base of spatial metabolomes (<xref rid="btaa085-B5" ref-type="bibr">Alexandrov <italic>et al.</italic>, 2019</xref>), through being able to select a large number of public representative datasets, employ modern web-based technologies for user-friendly and facilitated image ranking, engage a large number of experts and consolidate their rankings into a high-quality gold standard set. Second, using the gold standard set of pairs of images manually ranked by their co-localization, we have evaluated a variety of co-localization measures, including the cosine score, Pearson correlation and SSIM. Moreover, we propose several novel measures for co-localization, e.g. using term frequency–inverse document frequency (tf–idf) adopted from natural language processing as well as approaches based on deep learning.</p>
    <p>We found the semi-supervised deep learning-based Pi model as well as the cosine score applied after median thresholding to be the most optimal spatial co-localization measures for imaging MS. We propose to use them in data analysis methods relying on co-localization. Our work provides a gold standard set [available at GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/metaspace2020/coloc">https://github.com/metaspace2020/coloc</ext-link>)] which can be used for evaluating future measures, and illustrates how using open-access data, web technologies, community engagement and deep learning open novel avenues to addressing long-standing challenges in imaging MS.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Experiment design to collect expert knowledge</title>
      <p>In artificial intelligence and computer vision, a gold standard set is a collection of images manually tagged or ranked by experts called rankers. Having a gold standard set enables training and evaluation of machine learning models and algorithms. However, creating an unbiased, representative and high-quality gold standard set is a substantial challenge on its own. To the best of our knowledge, there exists no gold standard set of co-localized images for imaging MS. We aimed at creating a gold standard set that would quantify the perceived by experts degree of co-localization for different ions. We designed the gold standard set to consist of <italic>target-comparison sets</italic> where each set includes one <italic>target ion</italic> and 10 <italic>comparison ions</italic> ranked according to their co-localization with the target ion.</p>
      <p>To create a gold standard set of co-localized ion images, we selected public datasets from METASPACE with the aim to have a manageable number of diverse yet representative high-quality datasets from different laboratories. First, we selected laboratories with at least three active contributors of public data, nine laboratories in total. For every laboratory, we selected active contributors to METASPACE, 42 rankers in total. We aimed at asking each ranker to rank up to 20 sets and at every set to be ranked by three rankers. For each laboratory, we randomly selected round (20 × N_TL × 2/3) public datasets submitted by this laboratory to METASPACE, where N_TL is the number of rankers from a given laboratory.</p>
      <p>From each dataset, we randomly selected 1 target ion and 10 comparison ions constituting a target-comparison set. We then used the RankColoc web app (described later) to go through the target-comparison sets and exclude noisy images or images with only a few pixels. For each laboratory, we aimed at obtaining round (20 × N_TL/3) high-quality sets, although it was not always possible due to the quality of the datasets. This allowed us to have the same target-comparison set ranked by three rankers to later estimate the between-rankers agreement and to obtain average ranks.</p>
    </sec>
    <sec>
      <title>2.2 Pilot study</title>
      <p>Before creating the gold standard set, we ran a pilot study to investigate the difficulty of ranking ion images in the target-comparison sets according to their co-localization, as well as to learn potential pitfalls and obstacles of the ranking process. The pilot study was basically a full study including dataset selection, web app implementation, rankers recruitment, gold standard set creation and agreement evaluation, but performed in a smaller format with five rankers only.</p>
    </sec>
    <sec>
      <title>2.3 Web app for manual ranking of ion images</title>
      <p>The RankColoc web app (<ext-link ext-link-type="uri" xlink:href="https://github.com/metaspace2020/coloc/tree/master/RankColoc">https://github.com/metaspace2020/coloc/tree/master/RankColoc</ext-link>) was developed with the aim to facilitate image ranking as well as help inspect ranked sets. For a public dataset in METASPACE, the web app downloads ion images from METASPACE using the GraphQL API (<ext-link ext-link-type="uri" xlink:href="https://github.com/metaspace2020/metaspace/tree/master/metaspace/python-client">https://github.com/metaspace2020/metaspace/tree/master/metaspace/python-client</ext-link>), and shows a target and 10 comparison ion images. The web app helps a ranker rank each comparison image from 0 to 9 by dragging and dropping it into 1 of the 10 rank boxes or leave it unranked. Several images can be assigned the same rank. The web app page includes instructions for rankers. For each ranker, we assigned a collection of target-comparison sets and generated unique URLs containing the sets and the ranker ID. Ranking results were stored in real time, associated with the ranker ID, and could be opened by either the same ranker or a curator. <xref ref-type="fig" rid="btaa085-F1">Figure 1</xref> shows screenshots of RankColoc web app with examples of the ranked sets. <xref ref-type="supplementary-material" rid="sup1">Supplementary Video S1</xref> illustrates the ranking process.</p>
      <fig id="btaa085-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>Screenshots of the RankColoc web app showing two target-comparison sets ranked by experts. (<bold>a</bold>) MALDI-imaging dataset from a wheat seed section, submitted to METASPACE by Dhaka Bhandari, Justus Liebig University Giessen. (<bold>b</bold>) MALDI-imaging dataset from a rat brain tissue section, submitted to METASPACE by Berin Boughton, University of Melbourne (METASPACE URLs, for example datasets: <ext-link ext-link-type="uri" xlink:href="https://metaspace2020.eu/annotations?ds=2018-06-28_09h17m56s">https://metaspace2020.eu/annotations?ds=2018-06-28_09h17m56s</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://metaspace2020.eu/annotations?ds=2016-12-01_18h38m52s">https://metaspace2020.eu/annotations?ds=2016-12-01_18h38m52s</ext-link>)</p>
        </caption>
        <graphic xlink:href="btaa085f1"/>
      </fig>
    </sec>
    <sec>
      <title>2.4 Evaluating obtained rankings</title>
      <p>We assessed the complexity of the task and reproducibility of the rankers’ judgements by calculating pairwise correlations between the rankers, i.e. correlations between their ranks of comparison ion images in the same sets. The images left unranked (i.e. perceived by rankers as completely not co-localized with the target ion image) were assigned the rank 10. We computed average Spearman and Kendall ranker-pairwise rank correlation for each laboratory, ranker and set.</p>
    </sec>
    <sec>
      <title>2.5 Creating the gold standard set</title>
      <p>To ensure the high quality of the resulting gold standard set, we have excluded (i) sets for which the average Spearman pairwise correlation between rankers was &lt;0.4, and (ii) rankers whose average Spearman correlation with other rankers was &lt;0.4. After some rankers were excluded, some sets ended up with just one ranking. We excluded those sets as well. The resulting gold standard set contains pairs of ion images (target image and a comparison image) with each pair assigned an average rank across three rankers. The ranks range from 0, representing the highest co-localization, to 10, representing the lowest or no co-localization.</p>
    </sec>
    <sec>
      <title>2.6 Co-localization measures that require no learning</title>
      <p>Our implementation of the co-localization measures is available at the GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/metaspace2020/coloc/tree/master/measures">https://github.com/metaspace2020/coloc/tree/master/measures</ext-link>).</p>
      <sec>
        <title>2.6.1 Correlation and cosine-based measures</title>
        <p>First, we considered the commonly used co-localization measures: Pearson correlation, Spearman correlation and cosine similarity applied to flattened ion images, i.e. 1D vectors of pixel intensities.</p>
      </sec>
      <sec>
        <title>2.6.2 SSIM measure</title>
        <p>Following (<xref rid="btaa085-B11" ref-type="bibr">Ekelöf <italic>et al.</italic>, 2018</xref>), we considered the SSIM (<xref rid="btaa085-B24" ref-type="bibr">Wang <italic>et al.</italic>, 2004</xref>) with the Gaussian weights.</p>
      </sec>
      <sec>
        <title>2.6.3 tf–idf-Based measure</title>
        <p>We developed a measure based on the tf–idf concept from the field of natural language processing (<xref rid="btaa085-B15" ref-type="bibr">Leskovec <italic>et al.</italic>, 2014</xref>). Using flattened ion images, we calculated the tf–idf value for each pixel–ion pair to quantify how important a pixel <inline-formula id="IE1"><mml:math id="IM1"><mml:mi>p</mml:mi></mml:math></inline-formula> is for the particular ion <inline-formula id="IE2"><mml:math id="IM2"><mml:mi>i</mml:mi></mml:math></inline-formula> with respect to all ions in the dataset <inline-formula id="IE3"><mml:math id="IM3"><mml:mi>D</mml:mi></mml:math></inline-formula>:
<disp-formula id="E1"><mml:math id="M1"><mml:mtable><mml:mtr><mml:mtd><mml:mtext>tf</mml:mtext><mml:mo>−</mml:mo><mml:mtext>idf</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>tf</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo> </mml:mo><mml:mo>*</mml:mo><mml:mo> </mml:mo><mml:mtext>idf</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>tf</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>int</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>′</mml:mo><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msub></mml:mrow><mml:mo> </mml:mo></mml:munderover><mml:mo> </mml:mo><mml:mtext>int</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>′</mml:mo><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>idf</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>/</mml:mo><mml:mo>|</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msub><mml:mo>:</mml:mo><mml:mtext>int</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula id="IE4"><mml:math id="IM4"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the set of all pixels in <inline-formula id="IE5"><mml:math id="IM5"><mml:mi>D</mml:mi></mml:math></inline-formula>, <inline-formula id="IE6"><mml:math id="IM6"><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the set of all ions in <inline-formula id="IE7"><mml:math id="IM7"><mml:mi>D</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE8"><mml:math id="IM8"><mml:mi mathvariant="normal">int</mml:mi><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> is the intensity of <inline-formula id="IE9"><mml:math id="IM9"><mml:mi>i</mml:mi></mml:math></inline-formula> in <inline-formula id="IE10"><mml:math id="IM10"><mml:mi>p</mml:mi></mml:math></inline-formula>. We then created tf–idf vectors of the same dimensionality as the intensity vectors and quantified co-localization of ion images as the cosine similarity between the corresponding tf–idf vectors.</p>
      </sec>
      <sec>
        <title>2.6.4 Image transformations</title>
        <p>For all considered ion intensity-based measures, we applied the following transformations to the ion image prior to calculating co-localization: (i) hotspot removal, namely reducing intensities of pixels with intensities &gt;0.99 quantile by replacing them with the 0.99 quantile value; (ii) denoising by applying the median filter (<xref rid="btaa085-B12" ref-type="bibr">Huang <italic>et al.</italic>, 1979</xref>) with a square window of size ranging from 1 (no filter applied) to 5 with step 1; (iii) applying quantile thresholding, namely setting to zero those pixel intensities which are below a given quantile value, for quantiles ranging from 0 to 0.9 with step 0.05. Evaluation whether using a transformation is beneficial as well as optimizing the size of the median filter and the quantile value was performed using the 5-fold cross-validation for each measure. Measures with the best performing filters were then applied to the entire gold standard set.</p>
      </sec>
    </sec>
    <sec>
      <title>2.7 Co-localization measures based on deep learning</title>
      <p>Our implementation of the co-localization measures is available at the GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/metaspace2020/coloc/tree/master/measures">https://github.com/metaspace2020/coloc/tree/master/measures</ext-link>).</p>
      <p>With the advent of deep learning, models based on neural networks have become the method of choice for processing unstructured data such as images. Therefore, in our study we have developed several methods exploiting current state-of-the-art deep learning approaches that would learn ion co-localization from the gold standard set.</p>
      <sec>
        <title>2.7.1 Xception-based model</title>
        <p>This model, illustrated in <xref ref-type="fig" rid="btaa085-F2">Figure 2</xref>, is based on the well-known Xception convolutional architecture designed to extract informative features from images (<xref rid="btaa085-B8" ref-type="bibr">Chollet, 2017</xref>). We introduced the following modifications. First, the input has two channels corresponding to the target and comparison ion images. The two channels pass through the Xception architecture without the final classification layer, which in our case is replaced with a regression output. The Xception-based model is supervised, and its target variable is the rank as specified in the gold standard set, with the mean squared error (MSE) loss function.</p>
        <fig id="btaa085-F2" orientation="portrait" position="float">
          <label>Fig. 2.</label>
          <caption>
            <p>Architecture of the Xception-based deep learning model</p>
          </caption>
          <graphic xlink:href="btaa085f2"/>
        </fig>
      </sec>
      <sec>
        <title>2.7.2 Mu model</title>
        <p>The Mu model is a variation of the Xception-based model with the difference that the top layers are replaced with two 2048-dimensional outputs followed by a discriminator. The mu model encodes a pair of ion images into two 2048-dimensional representations, computed image similarity as the Pearson correlation coefficient between the representations, and then regresses the similarity score onto the rank target with the MSE loss.</p>
      </sec>
      <sec>
        <title>2.7.3 Unsupervised UMAP</title>
        <p>We developed a model based on the uniform manifold approximation and projection (UMAP), a recently developed non-linear dimensionality reduction technique with broad applications in biology (<xref rid="btaa085-B18" ref-type="bibr">McInnes <italic>et al.</italic>, 2018</xref>). In this model, we applied UMAP to embed flattened ion images (i.e. 1D vectors of pixel intensities) into 20D space using the ‘cosine’ distance metric. After the unsupervised embedding model defined the distance between ion images, we calculated the Pearson correlation coefficient between the corresponding embedded vectors to rank comparison images with respect to the target image. This model is unsupervised and does not use the gold standard set.</p>
      </sec>
      <sec>
        <title>2.7.4 UMAP+GBT model</title>
        <p>Since in our case supervision is actually possible, we extended the UMAP model with a supervised model on top. Namely, we used gradient boosted trees (GBT), a state-of-the-art regression model (<xref rid="btaa085-B7" ref-type="bibr">Chen and Guestrin, 2016</xref>), feeding UMAP 20D features as input and regressing them onto rank targets from the gold standard set with the MSE loss function.</p>
      </sec>
      <sec>
        <title>2.7.5 Pi model</title>
        <p>The Pi model is based on the recently developed approach of temporal ensembling for semi-supervised learning (<xref rid="btaa085-B14" ref-type="bibr">Laine and Aila, 2016</xref>). This approach uses an ensemble of network outputs from different training epochs as quasi-targets for training on unlabelled samples, which has been shown to significantly improve the final model quality. In our case, the Pi model follows the general architecture of the Xception-based model, but the last layers are replaced with two heads for two loss components: (i) supervised loss as in the Xception-based model, the MSE between the network prediction and the rank and (ii) unsupervised loss intended to stabilize the network prediction; we define it as the squared error between network predictions on a pair of ion images and the same pair of ion images subjected to various image augmentations (intensities and geometric transformations).</p>
        <p>The unsupervised loss component has allowed us to use ∼40 000 unlabelled ion images from 3685 public METASPACE datasets, gathering ∼56 000 unlabelled pairs from them for training in addition to the labelled gold standard set.</p>
      </sec>
    </sec>
    <sec>
      <title>2.8 Evaluation of the co-localization measures</title>
      <p>For each set, we calculate Spearman and Kendall correlation coefficients separately for each target-comparison set and report the mean and median values over all sets.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 The co-localization gold standard set</title>
      <p>We have initially selected 239 datasets from METASPACE with 304 target-comparison sets of ion images for 42 rankers from 9 laboratories (<xref rid="btaa085-T1" ref-type="table">Table 1</xref>).</p>
      <table-wrap id="btaa085-T1" orientation="portrait" position="float">
        <label>Table 1.</label>
        <caption>
          <p>Information about the co-localization gold standard set created from public METASPACE datasets contributed by nine laboratories with target-comparison sets ranked manually by 42 experts from these laboratories</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="3" colspan="1">Laboratory</th>
              <th rowspan="3" colspan="1">Number of rankers</th>
              <th rowspan="3" colspan="1">Number of datasets</th>
              <th rowspan="3" colspan="1">Number of sets</th>
              <th colspan="4" rowspan="1">Average pairwise agreement<hr/></th>
            </tr>
            <tr>
              <th colspan="2" rowspan="1">Spearman<hr/></th>
              <th colspan="2" rowspan="1">Kendall<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">Mean</th>
              <th rowspan="1" colspan="1">Med</th>
              <th rowspan="1" colspan="1">Mean</th>
              <th rowspan="1" colspan="1">Med</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">University of Copenhagen</td>
              <td rowspan="1" colspan="1">8</td>
              <td rowspan="1" colspan="1">66</td>
              <td rowspan="1" colspan="1">78</td>
              <td rowspan="1" colspan="1">0.534</td>
              <td rowspan="1" colspan="1">0.730</td>
              <td rowspan="1" colspan="1">0.489</td>
              <td rowspan="1" colspan="1">0.620</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">EMBL</td>
              <td rowspan="1" colspan="1">8</td>
              <td rowspan="1" colspan="1">33</td>
              <td rowspan="1" colspan="1">53</td>
              <td rowspan="1" colspan="1">0.763</td>
              <td rowspan="1" colspan="1">0.804</td>
              <td rowspan="1" colspan="1">0.666</td>
              <td rowspan="1" colspan="1">0.710</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">University of Melbourne</td>
              <td rowspan="1" colspan="1">6</td>
              <td rowspan="1" colspan="1">29</td>
              <td rowspan="1" colspan="1">40</td>
              <td rowspan="1" colspan="1">0.806</td>
              <td rowspan="1" colspan="1">0.836</td>
              <td rowspan="1" colspan="1">0.732</td>
              <td rowspan="1" colspan="1">0.742</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">JLU Giessen</td>
              <td rowspan="1" colspan="1">5</td>
              <td rowspan="1" colspan="1">29</td>
              <td rowspan="1" colspan="1">33</td>
              <td rowspan="1" colspan="1">0.612</td>
              <td rowspan="1" colspan="1">0.688</td>
              <td rowspan="1" colspan="1">0.545</td>
              <td rowspan="1" colspan="1">0.597</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">IBMP</td>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">20</td>
              <td rowspan="1" colspan="1">20</td>
              <td rowspan="1" colspan="1">0.638</td>
              <td rowspan="1" colspan="1">0.681</td>
              <td rowspan="1" colspan="1">0.550</td>
              <td rowspan="1" colspan="1">0.604</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PNNL</td>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">20</td>
              <td rowspan="1" colspan="1">20</td>
              <td rowspan="1" colspan="1">0.686</td>
              <td rowspan="1" colspan="1">0.687</td>
              <td rowspan="1" colspan="1">0.596</td>
              <td rowspan="1" colspan="1">0.609</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">MPI Bremen</td>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">19</td>
              <td rowspan="1" colspan="1">20</td>
              <td rowspan="1" colspan="1">0.843</td>
              <td rowspan="1" colspan="1">0.925</td>
              <td rowspan="1" colspan="1">0.787</td>
              <td rowspan="1" colspan="1">0.879</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">UT Austin</td>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">16</td>
              <td rowspan="1" colspan="1">20</td>
              <td rowspan="1" colspan="1">0.808</td>
              <td rowspan="1" colspan="1">0.866</td>
              <td rowspan="1" colspan="1">0.745</td>
              <td rowspan="1" colspan="1">0.770</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">M4I</td>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">7</td>
              <td rowspan="1" colspan="1">20</td>
              <td rowspan="1" colspan="1">0.730</td>
              <td rowspan="1" colspan="1">0.680</td>
              <td rowspan="1" colspan="1">0.660</td>
              <td rowspan="1" colspan="1">0.608</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Total</td>
              <td rowspan="1" colspan="1">42</td>
              <td rowspan="1" colspan="1">239</td>
              <td rowspan="1" colspan="1">304</td>
              <td rowspan="1" colspan="1">0.700</td>
              <td rowspan="1" colspan="1">0.773</td>
              <td rowspan="1" colspan="1">0.629</td>
              <td rowspan="1" colspan="1">0.666</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <bold>Final version after filtering out rankers and sets</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>38</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>182</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>234</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.791</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.800</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.711</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.708</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic>Note:</italic> The bold highlighted row corresponds to the best results.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.2 Pilot study</title>
      <p>The pilot study was crucial to inform us about the complexity and subjectivity of the task and to design the final version of the web app and the study accordingly. In particular, we learned that ranking comparison images was more natural for the rankers than ordering them because this allowed the rankers to assign the same rank to several comparison images. Selecting high-quality datasets and skipping noisy ion images and images with just a few non-zero pixels was crucial for obtaining reproducible rankings. Some rankers preferred to leave non-co-localized images unranked and we have implemented this option for the final study.</p>
    </sec>
    <sec>
      <title>3.3 Agreement between experts</title>
      <p><xref rid="btaa085-T1" ref-type="table">Table 1</xref> shows the average pairwise ranker correlation values for each laboratory that represent agreement between rankers. Note that the agreement values cannot and shall not be compared across different laboratories because every laboratory ranked images from different METASPACE datasets. For example, ranking images with a simple and clear spatial structure led to higher agreement values. The mean correlation across all sets was 0.700 (Spearman) and 0.629 (Kendall). After excluding sets and rankers with low agreement, the mean agreements for the final version of the gold standard set is 0.791 (Spearman) and 0.711 (Kendall).</p>
    </sec>
    <sec>
      <title>3.4 The gold standard set</title>
      <p>The final version of the gold standard set includes 234 sets with 2210 ion image pairs from 182 public imaging datasets from METASPACE ranked by 38 rankers from 9 laboratories, available at <ext-link ext-link-type="uri" xlink:href="https://github.com/metaspace2020/coloc/tree/master/GS">https://github.com/metaspace2020/coloc/tree/master/GS</ext-link>. The datasets represented human (37%), mouse (21%), pig (7%), rat (6%) and other organisms; brain (27%), kidney (11%), skin (9%), seed (4%) and other organs; MALDI (84%) and DESI (16%) ionization; DHB (44%), DAN (17%), DHA (6%), BPYN (5%) and other MALDI matrices; Orbitrap (69%) and FTICR (31%) mass analysers; positive (68%) and negative (32%) polarity. For every target-comparison pair of ion images, average rank across three rankers has been assigned. The ranks range from 0, representing the highest co-localization, to 10, representing the lowest or no co-localization.</p>
    </sec>
    <sec>
      <title>3.5 Evaluation of co-localization measures that require no learning</title>
      <p><xref rid="btaa085-T2" ref-type="table">Table 2</xref> shows the performance of co-localization measures requiring no learning, measured using the gold standard set as Spearman and Kendall rank correlation with the expert rankings. For each measure, we show its best performance and optimal image transformation parameters. The best performing measure is the cosine similarity with quantile threshold 0.5, without hotspot removal and with median filter with window size 3. The second best measure is the Pearson correlation measure with no image transformation applied. The SSIM measure recently proposed in the context of imaging MS (<xref rid="btaa085-B11" ref-type="bibr">Ekelöf <italic>et al.</italic>, 2018</xref>) was outperformed by other measures.</p>
      <table-wrap id="btaa085-T2" orientation="portrait" position="float">
        <label>Table 2.</label>
        <caption>
          <p>Performance of the co-localization measures requiring no learning</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="3" colspan="1">Co-localization measure</th>
              <th colspan="6" rowspan="1">Correlation with the expert rankings in the gold standard set<hr/></th>
              <th colspan="3" rowspan="2">Optimal parameters of image transformations<hr/></th>
            </tr>
            <tr>
              <th colspan="3" rowspan="1">Spearman<hr/></th>
              <th colspan="3" rowspan="1">Kendall<hr/></th>
            </tr>
            <tr>
              <th align="left" rowspan="1" colspan="1">Mean</th>
              <th align="left" rowspan="1" colspan="1">Med</th>
              <th align="left" rowspan="1" colspan="1">Mean SD</th>
              <th align="left" rowspan="1" colspan="1">Mean</th>
              <th align="left" rowspan="1" colspan="1">Med</th>
              <th align="left" rowspan="1" colspan="1">Mean SD</th>
              <th align="left" rowspan="1" colspan="1">Quant value</th>
              <th align="left" rowspan="1" colspan="1">Hotspot remov.</th>
              <th align="left" rowspan="1" colspan="1">Med win size</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Cosine</td>
              <td rowspan="1" colspan="1">
                <bold>0.794</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.849</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.012</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.682</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.720</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.014</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.5</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>No</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>3</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">tf–idf-cosine</td>
              <td rowspan="1" colspan="1">0.769</td>
              <td rowspan="1" colspan="1">0.825</td>
              <td rowspan="1" colspan="1">0.012</td>
              <td rowspan="1" colspan="1">0.653</td>
              <td rowspan="1" colspan="1">0.689</td>
              <td rowspan="1" colspan="1">0.013</td>
              <td rowspan="1" colspan="1">0.65</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">0</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Spearman</td>
              <td rowspan="1" colspan="1">0.737</td>
              <td rowspan="1" colspan="1">0.783</td>
              <td rowspan="1" colspan="1">0.011</td>
              <td rowspan="1" colspan="1">0.620</td>
              <td rowspan="1" colspan="1">0.647</td>
              <td rowspan="1" colspan="1">0.013</td>
              <td rowspan="1" colspan="1">0.7</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">0</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Pearson</td>
              <td rowspan="1" colspan="1">0.788</td>
              <td rowspan="1" colspan="1">0.838</td>
              <td rowspan="1" colspan="1">0.014</td>
              <td rowspan="1" colspan="1">0.674</td>
              <td rowspan="1" colspan="1">0.719</td>
              <td rowspan="1" colspan="1">0.013</td>
              <td rowspan="1" colspan="1">0</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">0</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SSIM</td>
              <td rowspan="1" colspan="1">0.559</td>
              <td rowspan="1" colspan="1">0.623</td>
              <td rowspan="1" colspan="1">0.015</td>
              <td rowspan="1" colspan="1">0.581</td>
              <td rowspan="1" colspan="1">0.488</td>
              <td rowspan="1" colspan="1">0.016</td>
              <td rowspan="1" colspan="1">0</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">0</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic>Note:</italic> The values of the Spearman and Kendall correlation coefficients to the gold standard are shown, together with the optimal parameters for image transformations. ‘Mean’ and ‘Med’ stand for the mean and median of the correlation values across the gold standard. ‘Mean SD’ is the standard deviation of the mean correlation value over 100 bootstrapped samples from the gold standard. The best performance is achieved by the cosine measure. The bold highlighted row corresponds to the best results.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p><xref rid="btaa085-T3" ref-type="table">Table 3</xref> shows the effect of using different types of image transformation on the performance of the cosine measure. Surprisingly, applying hotspot removal did not improve the performance. Denoising images by using the moving median filter improved the performance only marginally (Spearman correlation from 0.792 to 0.794), whereas using quantile thresholding led to a larger improvement (Spearman correlation from 0.779 to 0.794). However, taken into account the SD values of the mean estimates, this improvement cannot be claimed to be significant.</p>
      <table-wrap id="btaa085-T3" orientation="portrait" position="float">
        <label>Table 3.</label>
        <caption>
          <p>The effect of using different types of image transformations onto the performance of the cosine-based measure</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="3" colspan="1">Image transformation applied before calculating cosine similarity</th>
              <th colspan="6" rowspan="1">Correlation with the expert rankings in the gold standard set<hr/></th>
              <th colspan="3" rowspan="2" align="left">Optimal parameters of image transformations<hr/></th>
            </tr>
            <tr>
              <th colspan="3" rowspan="1">Spearman<hr/></th>
              <th colspan="3" rowspan="1">Kendall<hr/></th>
            </tr>
            <tr>
              <th align="left" rowspan="1" colspan="1">Mean</th>
              <th align="left" rowspan="1" colspan="1">Med</th>
              <th align="left" rowspan="1" colspan="1">Mean SD</th>
              <th align="left" rowspan="1" colspan="1">Mean</th>
              <th align="left" rowspan="1" colspan="1">Med</th>
              <th align="left" rowspan="1" colspan="1">Mean SD</th>
              <th align="left" rowspan="1" colspan="1">Quant value</th>
              <th align="left" rowspan="1" colspan="1">Hotspot remov.</th>
              <th align="left" rowspan="1" colspan="1">Med win size</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Quantile thresholding, hotspot removal, denoising</td>
              <td rowspan="1" colspan="1">
                <bold>0.794</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.849</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.012</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.682</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.720</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.014</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.5</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>No</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>3</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Quantile thresholding, hotspot removal (no denoising)</td>
              <td rowspan="1" colspan="1">0.792</td>
              <td rowspan="1" colspan="1">0.844</td>
              <td rowspan="1" colspan="1">0.012</td>
              <td rowspan="1" colspan="1">0.681</td>
              <td rowspan="1" colspan="1">0.720</td>
              <td rowspan="1" colspan="1">0.012</td>
              <td rowspan="1" colspan="1">0.5</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Hotspot removal, denoising (no quantile thresholding)</td>
              <td rowspan="1" colspan="1">0.779</td>
              <td rowspan="1" colspan="1">0.842</td>
              <td rowspan="1" colspan="1">0.012</td>
              <td rowspan="1" colspan="1">0.665</td>
              <td rowspan="1" colspan="1">0.719</td>
              <td rowspan="1" colspan="1">0.013</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">No</td>
              <td rowspan="1" colspan="1">3</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <p><italic>Note:</italic> The optimal parameters for image transformations are shown. ‘Mean’ and ‘Med’ stand for the mean and median of the correlation values across the gold standard. ‘Mean SD’ is the standard deviation of the mean correlation value over 100 bootstrapped samples from the gold standard. The bold highlighted row corresponds to the best results.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.6 Evaluation of co-localization measures based on deep learning</title>
      <p><xref rid="btaa085-T4" ref-type="table">Table 4</xref> shows the performance of co-localization measures based on deep learning models. The Pi model achieved the best performance, with a slight improvement over cosine similarity and similar to the human-to-human agreement between the experts in our study (mean Spearman of 0.791; see <xref rid="btaa085-T1" ref-type="table">Table 1</xref>). This is no surprise since the Pi model is a state-of-the-art semi-supervised model that makes use of both labelled data from the gold standard set and unlabelled data from METASPACE.</p>
      <table-wrap id="btaa085-T4" orientation="portrait" position="float">
        <label>Table 4.</label>
        <caption>
          <p>The performance of deep learning-based models measured as Spearman and Kendall correlations with expert rankings in the gold standard set</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="3" colspan="1">Image transformation applied before calculating cosine similarity</th>
              <th colspan="6" rowspan="1">Correlation with the expert rankings in the gold standard set<hr/></th>
            </tr>
            <tr>
              <th colspan="3" rowspan="1">Spearman<hr/></th>
              <th colspan="3" rowspan="1">Kendall<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">Mean</th>
              <th rowspan="1" colspan="1">Med</th>
              <th rowspan="1" colspan="1">Mean SD</th>
              <th rowspan="1" colspan="1">Mean</th>
              <th rowspan="1" colspan="1">Med</th>
              <th rowspan="1" colspan="1">Mean SD</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Xception model</td>
              <td rowspan="1" colspan="1">0.777</td>
              <td rowspan="1" colspan="1">0.820</td>
              <td rowspan="1" colspan="1">0.011</td>
              <td rowspan="1" colspan="1">0.682</td>
              <td rowspan="1" colspan="1">0.716</td>
              <td rowspan="1" colspan="1">0.011</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <bold>Pi model</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.797</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.847</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.011</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.712</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.752</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.011</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Unsupervised UMAP</td>
              <td rowspan="1" colspan="1">0.761</td>
              <td rowspan="1" colspan="1">0.827</td>
              <td rowspan="1" colspan="1">0.012</td>
              <td rowspan="1" colspan="1">0.656</td>
              <td rowspan="1" colspan="1">0.686</td>
              <td rowspan="1" colspan="1">0.015</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">UMAP+GBT</td>
              <td rowspan="1" colspan="1">0.758</td>
              <td rowspan="1" colspan="1">0.845</td>
              <td rowspan="1" colspan="1">0.016</td>
              <td rowspan="1" colspan="1">0.672</td>
              <td rowspan="1" colspan="1">0.741</td>
              <td rowspan="1" colspan="1">0.016</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Mu model</td>
              <td rowspan="1" colspan="1">0.725</td>
              <td rowspan="1" colspan="1">0.804</td>
              <td rowspan="1" colspan="1">0.016</td>
              <td rowspan="1" colspan="1">0.638</td>
              <td rowspan="1" colspan="1">0.705</td>
              <td rowspan="1" colspan="1">0.016</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn4">
            <p><italic>Note:</italic> ‘Mean’ and ‘Med’ stand for the mean and median of the correlation values across the gold standard. ‘Mean SD’ is the standard deviation of the mean correlation value over 100 bootstrapped samples from the gold standard. The best performance is achieved by the semi-supervised Pi model that makes use of both labelled and unlabelled data. The bold highlighted row corresponds to the best results.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.7 Inferring molecular relationships by mining public METASPACE data</title>
      <p>We have applied the best derived co-localization measures to illustrate how they can be used on a large scale to mine data from the public knowledge base METASPACE. More specifically, we aimed to infer co-localization relationships between all molecules represented in public METASPACE annotations. For this, we downloaded ion images for all annotations from 3685 public datasets in METASPACE using its API (<ext-link ext-link-type="uri" xlink:href="https://github.com/metaspace2020/metaspace/tree/master/metaspace/python-client">https://github.com/metaspace2020/metaspace/tree/master/metaspace/python-client</ext-link>), calculated co-localizations between all ion images within a dataset using either the cosine score after median (0.5 quantile) thresholding or deep learning Pi model, the best performing methods in their respective classes, and averaged co-localization across all datasets. Finally, we visualized all 10 273 resulting molecular formulas in a 2D space using UMAP with the average co-localization used as the pre-computed distance. The annotations that are more co-localized on average are shown closer to each other (<xref ref-type="fig" rid="btaa085-F3">Fig. 3</xref>).</p>
      <fig id="btaa085-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>Visualization of co-localization molecular relationships as learned from METASPACE. Dots representing annotations (each corresponding to 1 of 10 273 unique molecular formulas) are mapped based on their average co-localization across 3685 public METASPACE datasets. For a molecular class, the green colour represents unambiguous assignment when all isomers belong to the class whereas the red colour represents ambiguous assignment when some isotopes belong to another class. (Color version of this figure is available at <italic>Bioinformatics</italic> online.)</p>
        </caption>
        <graphic xlink:href="btaa085f3"/>
      </fig>
      <p>To investigate whether the inferred co-localization properties are associated with chemical properties of the molecules, we highlighted glycerolipids, an important class of lipids which are known to be easily detectable by imaging MS (<xref ref-type="fig" rid="btaa085-F3">Fig. 3a</xref>). Note that the assignment of a molecular annotation (formula) to a molecular class was performed accounting for potential ambiguity, with unambiguously assigned annotations shown in green and ambiguously assigned annotations shown in red (<xref ref-type="fig" rid="btaa085-F3">Fig. 3</xref>). One can see that glycerolipids indeed form dense clusters that indicates their high average co-localization. A subclass of glycerolipids, triradylcglycerols (with the classes names as in HDMB) represent the majority of the glycerolipids in METASPACE and form the densest clusters (<xref ref-type="fig" rid="btaa085-F3">Fig. 3b</xref>). Sparser representation of glycerolipids in the negative polarity data (<xref ref-type="fig" rid="btaa085-F3">Fig. 3c</xref>) illustrates the common knowledge of the positive mode being the preferred way of ionization for this class of lipids. Using another co-localization measure (deep learning-based Pi model instead of the cosine) also confirms the findings but shows a visible difference in data organization. This reflects the robust capacity of both measures to capture chemically associated co-localization and also shows the differences between them, which can be potentially used in the future to further improve the results.</p>
      <p>Another class of lipids, glycerophospholipids, represents a large part of molecules in METASPACE, clearly forming a cluster in the UMAP chemical space (<xref ref-type="fig" rid="btaa085-F3">Fig. 3e</xref>). Performing examination in a way similar to <xref ref-type="fig" rid="btaa085-F3">Figure 3a–</xref>d, one can see that the molecular subclass of glycerophospholipids, glycerophosphoethanolamines, represents the core of the cluster of co-localized glycerophospholipids (<xref ref-type="fig" rid="btaa085-F3">Fig. 3f</xref>). Opposite to glycerolipids, glycerophospholipids are known to be ionizable in both positive and negative modes, and this is reflected in their strong presence as well as clustered appearance on <xref ref-type="fig" rid="btaa085-F3">Figure 3g</xref>. Examining deep learning Pi score-based mapping (<xref ref-type="fig" rid="btaa085-F3">Fig. 3h</xref>), one can see that despite dense spacing, there is clearly less separation visible to the class of glycerolipids (<xref ref-type="fig" rid="btaa085-F3">Fig. 3h</xref> versus d) compared to the cosine score-based UMAP visualization (<xref ref-type="fig" rid="btaa085-F3">Fig. 3g</xref> versus a), which makes cosine score-based results easier for interpretation.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <sec>
      <title>4.1 Other approaches to obtain gold standard data</title>
      <p>In addition to the approach presented in this manuscript, we have also considered creating gold standard data either by simulating it or by authentic standards or mixtures of standards. However, our pilot experiments indicated that neither of these approaches would be adequate for evaluating co-localization due to being over-simplistic as well as not representing complex spatial patterns, noise and background adequately enough. Simulating imaging MS data is by itself an unsolved challenge and proposed methods are rather limited and did not gain recognition. Spotting authentic standards, first, would hardly represent the variety of technologies, spatial resolutions and types of tissues that we can get access to through METASPACE. Second, experimental data from spotted authentic standards would provide only a limited insight into which ions should be co-localized because of in-source fragmentation and clusters formation which potentially can lead to co-detections of ions even from different standards. For example, adenosine could be detected from both spotted ADP and ATP as an in-source fragment and this represents only one known example out of various possible in-source fragments.</p>
    </sec>
    <sec>
      <title>4.2 Gold standard</title>
      <p>Creating a high-quality gold standard set of expert-ranked pairs of target-comparison images was possibly the most challenging part of the study. Not only it required scientific formulation of the co-localization problem and development of an experiment design able to capture the perceived extent of co-localization from the experts, but it was also the most time-consuming part of our study to organize the whole ranking experiment by selecting datasets, recruiting almost 50 experts, communicating with them, reminding them to complete the task, and when necessary coming back to them with requests for corrections. Altogether it required 95 emails solely for communicating with the rankers. Despite having expertise in performing crowdsourcing studies in imaging MS (<xref rid="btaa085-B19" ref-type="bibr">Ovchinnikova <italic>et al.</italic>, 2019</xref>; <xref rid="btaa085-B20" ref-type="bibr">Palmer <italic>et al.</italic>, 2015</xref>) and overwhelmingly positive support of METASPACE users in performing the ranking, running this study would not be possible without access to diverse public data in METASPACE and without using modern web technologies employed for the RankColoc web app that both critically facilitated the process. The achieved average pairwise correlation between the rankers (mean Spearman 0.791) confirms a strong inter-ranker agreement. This indicates that there is a consensus between experts with respect to perceived co-localization and, importantly, that this consensus was successfully captured in the gold standard set, thus validating our efforts.</p>
      <p>Performing the pilot study was essential to avoid pitfalls and refine the experimental design and the web app for more objective ranking before engaging a large number of experts. Nevertheless, after performing the complete study, we see opportunities for next-level improvement. For example, in the spirit of active learning, we could choose comparison ions not randomly but those ions where our models are most uncertain about their ranking.</p>
      <p><xref ref-type="fig" rid="btaa085-F4">Figure 4</xref> shows the statistics for the properties of the METASPACE datasets selected for the gold standard. When selecting them, we mainly were driven by the requirement of having at least three rankers from every laboratory. Thus, big laboratories with high numbers of active METASPACE received more representation in the gold standard set. This also led to some bias towards the types of samples and the mass spectrometry used. However, comparing the properties of the datasets in the gold standard to the overall METASPACE (<xref rid="btaa085-B5" ref-type="bibr">Alexandrov <italic>et al.</italic>, 2019</xref>), we see that in general the gold standard is relatively representative. We have evaluated whether there is a significant bias due to overrepresentation of brain tissue datasets in the gold standard. For this, we 10 times randomly sub-sampled one-third of all brain datasets in the gold standard. The calculated the averaged mean Spearman for the best cosine measure was 0.787 which is lower than for the full gold standard (0.794) but the difference is not significant. This indicates that the effect of this particular bias is present but not significant.</p>
      <fig id="btaa085-F4" orientation="portrait" position="float">
        <label>Fig. 4.</label>
        <caption>
          <p>Histograms of the properties of the public METASPACE datasets selected for the gold standard</p>
        </caption>
        <graphic xlink:href="btaa085f4"/>
      </fig>
      <p>Taking into account the efforts necessary for producing such a gold standard set, we do not expect it to be repeated on a larger scale in the near future. However, we are considering to implement an online approach where a target-comparison set or a reduced version of it will be occasionally shown to METASPACE users. This approach would provide a continuous population of the gold standard set. However, it should be carefully designed to ensure the quality and check for consistency, since the ranking task will be split into small subtasks and performed over a period of time by a larger diverse crowd of rankers.</p>
    </sec>
    <sec>
      <title>4.3 Co-localization measures</title>
      <p>We hope that our results, comparing a variety of deep learning models, and this discussion will be helpful for future deep learning applications in imaging MS. In <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S1</xref> and <xref ref-type="supplementary-material" rid="sup1">Tables S1 and S2</xref>, we show values for all developed methods for an example target-comparison set.</p>
      <p>Interestingly, the unsupervised model UMAP performed on par with the supervised UMAP+GBT model, namely its own version enhanced with supervision through GBT. This may indicate that the structural properties of co-localization are relatively evident in the data.</p>
      <p>At the same time, the achieved performance for both the best deep learning model (mean Spearman 0.797 for the Pi model) and the cosine measure (mean Spearman 0.794) are close to the average pairwise agreement between the rankers (mean Spearman 0.791) that indicates that we achieved close to theoretically best performance. This would also explain only a slight improvement when using an advanced deep learning-based methods compared to the cosine similarity.</p>
      <p>The slight positive difference of the best performance compared to the average pairwise agreement between rankers (0.797 or 0.794 versus 0.791) does not necessarily indicate an overfitting but can be due to the averaging of rankings in the produced gold standard set, thus introducing positive effects of averaging compared to the values used for the rankers agreement calculation.</p>
      <p>We would like to note other specifics of the considered problem which potentially do not allow to capitalize on the full potential of the deep learning methods: ion images from the same dataset have the same size and structure and can be compared pixel-by-pixel after flattening. Ion images also do not undergo changes in the view angle or brightness or other non-linear deformations that would apply to, e.g. photos used in computer vision where deep learning significantly benefits from its capacity to extract abstract visual features thus allowing comparison of different images showing the same object. Here, future efforts can be focused on developing next-level methods for spatial association between molecules that would consider ‘molecular microenvironment’ rather than ‘tissue section’ context.</p>
      <p>The results potentially indicate a bottleneck in the size of the gold standard set (2340 pairs of ranked images), since the best performance was achieved by a semi-supervised model which, besides the gold standard set, used all public METASPACE data for deriving a representation of ion images.</p>
      <p>It was somewhat surprising to obtain the best performance for the cosine measure applied after the median thresholding which, for an ion image, sets all pixel intensities smaller than the median intensity to zero thus neglecting half of the pixels. Note that the cosine measure applied after the median thresholding considers only the areas where both images have high-intensity pixels (with intensities above the median value). Furthermore, zeroing half of the pixels provides an efficient denoising by substantially reducing the values of the cosine measure between noisy images. Compared to two similarly looking images, cosine distance between two random (noisy) images is reduced more after median thresholding due to the smaller overlap in the sets of non-zero pixels. Taking these considerations into account, we speculate that the cosine measure combined with the median thresholding achieves high performance because it corresponds to the perception of rankers which make their judgement about the similarity of images based on high-intensity areas of images. Continuing this line of discussion, let us bring attention to the second best performing measure which was the Pearson correlation without any image transformation applied. Since Pearson correlation is not recommended for highly skewed distributions whereas the intensities in imaging MS are Poisson distributed (<xref rid="btaa085-B3" ref-type="bibr">Alexandrov <italic>et al.</italic>, 2010</xref>), we evaluated whether the log-transformation of pixel intensities would improve the performance. Interestingly, it was not the case and the mean Spearman with the expert rankings after log-transformation was 0.742 that is lower than without any transformation (0.788). Potentially, this reflects the same assumption we made about rankers perception, as using the Pearson correlation for highly skewed data without log-transformation makes it biased towards high-intensity pixels.</p>
      <p>Comparing the best co-localization measures (deep learning Pi model and cosine similarity after median thresholding), we investigated how well they correspond to expert ranking for each target-comparison pair from the gold standard. <xref ref-type="fig" rid="btaa085-F5">Figure 5</xref> shows that there is no visible difference between these two measures: for 50% of all target-comparison sets both measures achieve high performance (Spearman correlation with the expert ranking is &gt;0.8). Despite the fact that error analysis of low-valued sets has not revealed any factors that would allow us to improve the measures, one can potentially combine the considered measures and thus achieve a better performance with an ensemble ranking. Interestingly, <xref ref-type="fig" rid="btaa085-F4">Figure 4</xref> highlights that the target-comparison pairs for which both measures performed well have also visibly high values of the rankers agreement. This provides another confirmation that the developed co-localization measures reproduce the perceived co-localization when experts themselves agree on it.</p>
      <fig id="btaa085-F5" orientation="portrait" position="float">
        <label>Fig. 5.</label>
        <caption>
          <p>Scatterplot showing for each of 2340 target-comparison sets from the gold standard how well the best co-localization measures (deep learning Pi model, cosine similarity after median thresholding) reproduce the average (ø) expert ranking, as measured by the Spearman correlation. Each dot is coloured according to the rankers agreement for the respective target-comparison set</p>
        </caption>
        <graphic xlink:href="btaa085f5"/>
      </fig>
    </sec>
    <sec>
      <title>4.4 Applications</title>
      <p>A wide coverage of organisms, organs, ionization types, MALDI matrices and mass analysers represented in the imaging MS datasets used in the gold standard set ensures broad applicability for the findings and measures developed in this study. We expect key applications of the developed and evaluated co-localization methods to be in the search for molecular biomarkers associated with either a particular molecule or a region of interest. They should also improve distance-based methods for data analysis, e.g. representation of the full dataset using clustering of ion images (<xref rid="btaa085-B4" ref-type="bibr">Alexandrov <italic>et al.</italic>, 2013</xref>). Moreover, we expect this work to provide a scientifically rigorous justification for using these measures in systems biology approaches aimed at uncovering molecular relationships between molecules by assuming the tissue representing cells of different phenotypes. Here, cutting-edge methods relying on distance or similarity measures, such as UMAP demonstrated in this paper, can replace more conventional methods such as PCA, NMF or t-SNE.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btaa085_Supplementary_Data</label>
      <media xlink:href="btaa085_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We thank the rankers of public METASPACE data who shared their data publicly and helped us create the gold standard set: Asta Mari-a Joensen, Charlotte Bagger, Julian Schneemann, Meghan Friis, Fernanda Endringer Pinto, Anne Mette Handler, Andreas Danielsen, Katharina Clitherow, Sophie Jacobsen (Janfelt Lab, University of Copenhagen), Mohammed Shahraz, Don Nguyen, Sergio Triana, Veronika Saharuka, Luca Rappez, Cristina Gonzalez Lopez, Aslihan Inal (EMBL), Dinaiz Thinagaran, Sanuli Paralkar, Farheen Farzana, Edita Ritmejeryte, Nicholas Sing, Berin Boughton (Metabolomics Australia, University of Melbourne), Michael Waletzko, Dhaka Bhandari, Domenic Dreisbach, Patrik Kadesch (Spengler Lab, Justus Liebig University Giessen), Elisa Ruhland, Julien Delecolle, Claire Villette (Heintz Lab, IBMP, University of Strasbourg), Dusan Velickovic, Christopher Anderton, Arunima Bhattacharjee (Anderton Lab, Pacific Northwest National Laboratory), Manuel Liebeke, Benedikt Geier, Emilia Sogen (Liebeke Lab, Max Planck Institute for Marine Microbiology Bremen), Marta Sans, Jialing Zhang, Kyana Garza (Eberlin Lab, University of Texas Austin) and Shane Ellis, Pieter Kooijman, Lennart Huizing (M4I Institute, Maastricht University). We thank the reviewers and the editor for helping us improve the manuscript.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by the European Union’s Horizon 2020 programme [Nº634402, Nº777222 to K.O., L.S., T.A.], the Russian Foundation for Basic Research [18-54-74005 to S.N., T.A.] and the European Research Council Consolidator [METACELL Nº773089 to T.A.].</p>
      <p><italic>Conflict of Interest</italic>: Until 2020, Theodore Alexandrov was on the Scientific Advisory Board of SCiLS, a company developing software for imaging mass spectrometry.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa085-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aaron</surname><given-names>J.S.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Image co-localization—co-occurrence versus correlation</article-title>. <source>J. Cell Sci</source>., <volume>131</volume>, <fpage>jcs211847</fpage>.<pub-id pub-id-type="pmid">29439158</pub-id></mixed-citation>
    </ref>
    <ref id="btaa085-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alexandrov</surname><given-names>T.</given-names></name></person-group> (<year>2012</year>) 
<article-title>MALDI imaging mass spectrometry: statistical data analysis and current computational challenges</article-title>. <source>BMC Bioinformatics</source>, <volume>13</volume>, S11.</mixed-citation>
    </ref>
    <ref id="btaa085-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alexandrov</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Spatial segmentation of imaging mass spectrometry data with edge-preserving image denoising and clustering</article-title>. <source>J. Proteome Res</source>., <volume>9</volume>, <fpage>6535</fpage>–<lpage>6546</lpage>.<pub-id pub-id-type="pmid">20954702</pub-id></mixed-citation>
    </ref>
    <ref id="btaa085-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alexandrov</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Analysis and interpretation of imaging mass spectrometry data by clustering mass-to-charge images according to their spatial similarity</article-title>. <source>Anal. Chem</source>., <volume>85</volume>, <fpage>11189</fpage>–<lpage>11195</lpage>.<pub-id pub-id-type="pmid">24180335</pub-id></mixed-citation>
    </ref>
    <ref id="btaa085-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Alexandrov</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) METASPACE: a community-populated knowledge base of spatial metabolomes in health and disease. <italic>bioRxiv</italic>, pp. 1–22. <pub-id pub-id-type="doi">10.1101/539478</pub-id>.</mixed-citation>
    </ref>
    <ref id="btaa085-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Buchberger</surname><given-names>A.R.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Mass spectrometry imaging: a review of emerging advancements and future insights</article-title>. <source>Anal. Chem</source>., <volume>90</volume>, <fpage>240</fpage>–<lpage>265</lpage>.<pub-id pub-id-type="pmid">29155564</pub-id></mixed-citation>
    </ref>
    <ref id="btaa085-B7">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>Guestrin</surname><given-names>C.</given-names></name></person-group> (<year>2016</year>) XGBoost: a scalable tree boosting system. In: <italic>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</italic>, <italic>San Francisco, California, USA</italic>, pp. <fpage>785</fpage>–<lpage>94</lpage>. ACM.</mixed-citation>
    </ref>
    <ref id="btaa085-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Chollet</surname><given-names>F.</given-names></name></person-group> (<year>2017</year>) Xception: deep learning with depthwise separable convolutions. In: <italic>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</italic>, <italic>Honolulu, HI, USA</italic> pp. <fpage>1800</fpage>–<lpage>1807</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa085-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Doerr</surname><given-names>A.</given-names></name></person-group> (<year>2018</year>) 
<article-title>Mass spectrometry imaging takes off</article-title>. <source>Nat. Methods</source>, <volume>15</volume>, <fpage>32</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa085-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dreisewerd</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Yew</surname><given-names>J.Y.</given-names></name></person-group> (<year>2017</year>) 
<article-title>Mass spectrometry imaging goes three dimensional</article-title>. <source>Nat. Methods</source>, <volume>14</volume>, <fpage>1139</fpage>–<lpage>1140</lpage>.<pub-id pub-id-type="pmid">29190273</pub-id></mixed-citation>
    </ref>
    <ref id="btaa085-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ekelöf</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Evaluation of digital image recognition methods for mass spectrometry imaging data analysis</article-title>. <source>J. Am. Soc. Mass Spectrom</source>., <volume>29</volume>, <fpage>2467</fpage>–<lpage>2470</lpage>.<pub-id pub-id-type="pmid">30324263</pub-id></mixed-citation>
    </ref>
    <ref id="btaa085-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huang</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>1979</year>) 
<article-title>A fast two-dimensional median filtering algorithm</article-title>. <source>IEEE Trans. Acoust. Speech Signal Process</source>., <volume>27</volume>, <fpage>13</fpage>–<lpage>18</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa085-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Kaddi</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) Hypergeometric similarity measure for spatial analysis in tissue imaging mass spectrometry. In: <italic>Proceedings IEEE Int Conf Bioinformatics Biomed</italic>, <italic>Atlanta, GA, USA</italic> pp. <fpage>604</fpage>–<lpage>607</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa085-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Laine</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Aila</surname><given-names>T.</given-names></name></person-group> (<year>2016</year>) Temporal ensembling for semi-supervised learning. <italic>arXiv [cs.NE].</italic> arXiv. pp. 1–13. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1610.02242">http://arxiv.org/abs/1610.02242</ext-link>.</mixed-citation>
    </ref>
    <ref id="btaa085-B15">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Leskovec</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) <source>Mining of Massive Datasets</source>. 
<publisher-name>Cambridge University Press, Cambridge</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btaa085-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>McCombie</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (<year>2005</year>) 
<article-title>Spatial and spectral correlations in MALDI mass spectrometry images by clustering and multivariate analysis</article-title>. <source>Anal. Chem</source>., <volume>77</volume>, <fpage>6118</fpage>–<lpage>6124</lpage>.<pub-id pub-id-type="pmid">16194068</pub-id></mixed-citation>
    </ref>
    <ref id="btaa085-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>McDonnell</surname><given-names>L.A.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>Mass spectrometry image correlation: quantifying colocalization</article-title>. <source>J. Proteome Res</source>., <volume>7</volume>, <fpage>3619</fpage>–<lpage>3627</lpage>.<pub-id pub-id-type="pmid">18570456</pub-id></mixed-citation>
    </ref>
    <ref id="btaa085-B18">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>McInnes</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) UMAP: uniform manifold approximation and projection for dimension reduction. <italic>arXiv [stat.ML]</italic> arXiv. pp. 1–51. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1802.03426">http://arxiv.org/abs/1802.03426</ext-link>.</mixed-citation>
    </ref>
    <ref id="btaa085-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Ovchinnikova</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) OffsampleAI: artificial intelligence approach to recognize off-sample mass spectrometry images. BMC Bioinformatics, in press. <pub-id pub-id-type="doi">10.1186/s12859-020-3425-x</pub-id>.</mixed-citation>
    </ref>
    <ref id="btaa085-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Palmer</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Using collective expert judge-ments to evaluate quality measures of mass spectrometry images</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>i375</fpage>–<lpage>384</lpage>.<pub-id pub-id-type="pmid">26072506</pub-id></mixed-citation>
    </ref>
    <ref id="btaa085-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Palmer</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>FDR-controlled metabolite annotation for high-resolution imaging mass spectrometry</article-title>. <source>Nat. Methods</source>, <volume>14</volume>, <fpage>57</fpage>–<lpage>60</lpage>.<pub-id pub-id-type="pmid">27842059</pub-id></mixed-citation>
    </ref>
    <ref id="btaa085-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schulz</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Advanced MALDI mass spectrometry imaging in pharmaceutical research and drug development</article-title>. <source>Curr. Opin. Biotechnol</source>., <volume>55</volume>, <fpage>51</fpage>–<lpage>59</lpage>.<pub-id pub-id-type="pmid">30153614</pub-id></mixed-citation>
    </ref>
    <ref id="btaa085-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vaysse</surname><given-names>P.-M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Mass spectrometry imaging for clinical research—latest developments, applications, and current limitations</article-title>. <source>Analyst</source>, <volume>142</volume>, <fpage>2690</fpage>–<lpage>2712</lpage>.<pub-id pub-id-type="pmid">28642940</pub-id></mixed-citation>
    </ref>
    <ref id="btaa085-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Z.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) 
<article-title>Image quality assessment: from error visibility to structural similarity</article-title>. <source>IEEE Trans. Image Process</source>., <volume>13</volume>, <fpage>600</fpage>–<lpage>612</lpage>.<pub-id pub-id-type="pmid">15376593</pub-id></mixed-citation>
    </ref>
    <ref id="btaa085-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Watrous</surname><given-names>J.D.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>The evolving field of imaging mass spectrometry and its impact on future biological research</article-title>. <source>J. Mass Spectrom</source>., <volume>46</volume>, <fpage>209</fpage>–<lpage>222</lpage>.<pub-id pub-id-type="pmid">21322093</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
