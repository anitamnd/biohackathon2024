<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Nucleic Acids Res</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nucleic Acids Res</journal-id>
    <journal-id journal-id-type="publisher-id">nar</journal-id>
    <journal-title-group>
      <journal-title>Nucleic Acids Research</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0305-1048</issn>
    <issn pub-type="epub">1362-4962</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10164589</article-id>
    <article-id pub-id-type="pmid">36912104</article-id>
    <article-id pub-id-type="doi">10.1093/nar/gkad157</article-id>
    <article-id pub-id-type="publisher-id">gkad157</article-id>
    <article-categories>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI00010</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>Narese/9</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Methods Online</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Multi-task learning from multimodal single-cell omics with Matilda</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Chunlei</given-names>
        </name>
        <aff><institution>Computational Systems Biology Group, Children's Medical Research Institute, Faculty of Medicine and Health, The University of Sydney</institution>, <addr-line>Westmead</addr-line>, NSW <addr-line>2145</addr-line>, <country country="AU">Australia</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Huang</surname>
          <given-names>Hao</given-names>
        </name>
        <aff><institution>Computational Systems Biology Group, Children's Medical Research Institute, Faculty of Medicine and Health, The University of Sydney</institution>, <addr-line>Westmead</addr-line>, NSW <addr-line>2145</addr-line>, <country country="AU">Australia</country></aff>
        <aff><institution>School of Mathematics and Statistics, The University of Sydney</institution>, <addr-line>Sydney</addr-line>, NSW <addr-line>2006</addr-line>, <country country="AU">Australia</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-1098-3138</contrib-id>
        <name>
          <surname>Yang</surname>
          <given-names>Pengyi</given-names>
        </name>
        <!--pengyi.yang@sydney.edu.au-->
        <aff><institution>Computational Systems Biology Group, Children's Medical Research Institute, Faculty of Medicine and Health, The University of Sydney</institution>, <addr-line>Westmead</addr-line>, NSW <addr-line>2145</addr-line>, <country country="AU">Australia</country></aff>
        <aff><institution>School of Mathematics and Statistics, The University of Sydney</institution>, <addr-line>Sydney</addr-line>, NSW <addr-line>2006</addr-line>, <country country="AU">Australia</country></aff>
        <aff><institution>Charles Perkins Centre, The University of Sydney</institution>, <addr-line>Sydney</addr-line>, NSW <addr-line>2006</addr-line>, <country country="AU">Australia</country></aff>
        <xref rid="COR1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="COR1">To whom correspondence should be addressed. Tel: +61 2 9351 3039; Fax: +61 2 9351 4534; Email: <email>pengyi.yang@sydney.edu.au</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>08</day>
      <month>5</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-03-13">
      <day>13</day>
      <month>3</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>13</day>
      <month>3</month>
      <year>2023</year>
    </pub-date>
    <volume>51</volume>
    <issue>8</issue>
    <fpage>e45</fpage>
    <lpage>e45</lpage>
    <history>
      <date date-type="accepted">
        <day>21</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>28</day>
        <month>1</month>
        <year>2023</year>
      </date>
      <date date-type="received">
        <day>20</day>
        <month>10</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press on behalf of Nucleic Acids Research.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact <email>journals.permissions@oup.com</email></license-p>
      </license>
    </permissions>
    <self-uri xlink:href="gkad157.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>Multimodal single-cell omics technologies enable multiple molecular programs to be simultaneously profiled at a global scale in individual cells, creating opportunities to study biological systems at a resolution that was previously inaccessible. However, the analysis of multimodal single-cell omics data is challenging due to the lack of methods that can integrate across multiple data modalities generated from such technologies. Here, we present Matilda, a multi-task learning method for integrative analysis of multimodal single-cell omics data. By leveraging the interrelationship among tasks, Matilda learns to perform data simulation, dimension reduction, cell type classification, and feature selection in a single unified framework. We compare Matilda with other state-of-the-art methods on datasets generated from some of the most popular multimodal single-cell omics technologies. Our results demonstrate the utility of Matilda for addressing multiple key tasks on integrative multimodal single-cell omics data analysis. Matilda is implemented in Pytorch and is freely available from <ext-link xlink:href="https://github.com/PYangLab/Matilda" ext-link-type="uri">https://github.com/PYangLab/Matilda</ext-link>.</p>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Health and Medical Research Council</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000925</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>1173469</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Sydney Research Accelerator (SOAR)</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="14"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="SEC1">
    <title>INTRODUCTION</title>
    <p>Recent development of multimodal single-cell omics technologies enables multiple modalities of cellular regulatory circuitry to be simultaneously profiled in individual cells (<xref rid="B1" ref-type="bibr">1</xref>). Data generated from these technologies create new opportunities for integrative analysis of cellular programs that are inaccessible from analysing each data modality alone and hence promise to provide a more holistic characterization of cellular systems at single-cell resolution (<xref rid="B2" ref-type="bibr">2</xref>). A large number of computational methods have been developed for single-cell RNA-sequencing (scRNA-seq) data to perform tasks such as data simulation (<xref rid="B3" ref-type="bibr">3</xref>), dimension reduction (<xref rid="B4" ref-type="bibr">4</xref>) and classification of cell types (<xref rid="B5" ref-type="bibr">5</xref>,<xref rid="B6" ref-type="bibr">6</xref>), and feature selection (<xref rid="B7" ref-type="bibr">7</xref>,<xref rid="B8" ref-type="bibr">8</xref>). While methods designed for scRNA-seq data analysis can be applied to analyse RNA modality in multimodal single-cell omics data, most of them cannot take advantage of other available data modalities and therefore could not fully utilize the information embedded in such data. The lack of computational methods that can integrate across data modalities is a key issue in multimodal single-cell omics data analysis and greatly hinder biological discovery from such data (<xref rid="B9" ref-type="bibr">9</xref>,<xref rid="B10" ref-type="bibr">10</xref>).</p>
    <p>Here we present Matilda, a neural network-based multi-task learning method for integrative analysis of multimodal single-cell omics data (Figure <xref rid="F1" ref-type="fig">1A</xref>). Although previously methods developed for scRNA-seq data analysis typically address different tasks (e.g. data simulation, cell type classification) independently, a key observation in Matilda is that many common tasks in multimodal single-cell omics data analysis are closely related to each other. The modularity nature of neural networks employed in Matilda makes it well-suited for integrating multiple data modalities and performing multiple tasks in a single unified framework. For example, the data simulated by the variational autoencoder (VAE) (<xref rid="B11" ref-type="bibr">11</xref>), a key component of Matilda, can be augmented to the original data to improve cell type classification. By leveraging such relationships, Matilda simultaneously performs data simulation, dimension reduction, cell type classification, and feature selection across data modalities (Figure <xref rid="F1" ref-type="fig">1A</xref>), therefore, achieving multiple key tasks in integrative analysis of multimodal single-cell omics data.</p>
    <fig position="float" id="F1">
      <label>Figure 1.</label>
      <caption>
        <p>Matilda framework and multimodal single-cell data simulation. (<bold>A</bold>) Schematic summary of the main components in Matilda framework, including multimodal single-cell data simulation, data augmentation, multimodal integrated visualization, cell type classification, and gradient descent-based feature selection. (<bold>B</bold>) UMAP visualization of cell-type-specific simulations of RNA, ADT, and ATAC modalities in the TEA-seq dataset (GSE158013) using Matilda. The Upper and lower panels show real (red), and Matilda simulated (blue) naïve B cells and CD14 monocytes, respectively.</p>
      </caption>
      <graphic xlink:href="gkad157fig1" position="float"/>
    </fig>
    <p>Matilda performs data simulation, cell type classification, and feature selection for single-cell multimodal omics data in a single multi-task learning framework. To evaluate the performance of Matilda on multiple tasks in multimodal single-cell omics data analysis, we applied Matilda to a collection of datasets generated from popular multimodal single-cell omics technologies including those profiling three modalities using TEA-seq (gene expression [RNA], cell surface proteins [ADT], and chromatin accessibility [ATAC]) (<xref rid="B12" ref-type="bibr">12</xref>), and those profiling two modalities using CITE-seq (RNA and ADT) (<xref rid="B13" ref-type="bibr">13–15</xref>) and SHARE-seq (RNA and ATAC) (<xref rid="B16" ref-type="bibr">16</xref>). While there are currently few methods specifically designed for data simulation, cell type classification, and feature selection using multiple modalities in these datasets, various methods (e.g. Sparsim (<xref rid="B17" ref-type="bibr">17</xref>) for data simulation, scClassify (<xref rid="B5" ref-type="bibr">5</xref>) for cell type classification, MAST (<xref rid="B8" ref-type="bibr">8</xref>) for feature selection) have been developed for single-cell RNA-sequencing (scRNA-seq) data and therefore can be applied using the RNA modality in these datasets. Using a range of evaluation criteria, we show that Matilda outperforms other state-of-the-art methodologies designed for various tasks using single or multiple data modalities. Our results demonstrate the utility of Matilda as the first comprehensive method for addressing multiple key tasks in multimodal single-cell omics data analysis.</p>
  </sec>
  <sec sec-type="materials|methods" id="SEC2">
    <title>MATERIALS AND METHODS</title>
    <sec id="SEC2-1">
      <title>Datasets and preprocessing</title>
      <sec id="SEC2-1-1">
        <title>TEA-seq dataset</title>
        <p>TEA-seq enables simultaneous single-cell profiling of transcripts, epitopes, and chromatin accessibility (<xref rid="B12" ref-type="bibr">12</xref>). The processed matrices of TEA-seq data from measuring PBMC were downloaded from the NCBI Gene Expression Omnibus (GEO) under the accession number GSE158013, with raw RNA expression, ADT expression, and peak accessibility (ATAC) measured for the same cells in four data batches. We summarized the matrix of ATAC from peak level to gene activity scores using the ‘CreateGeneActivityMatrix’ function in Seurat package (<xref rid="B14" ref-type="bibr">14</xref>). Genes with fewer than 1% quantifications across cells in each of the three modalities were removed, respectively. This resulted in a dataset with 6310 (9855 RNA, 46 ADT, 17141 ATAC); 6545 (9852 RNA, 46 ADT, 17081 ATAC); 6534 (9911 RNA, 46 ADT, 16552 ATAC); and 6748 (9859 RNA, 46 ADT, 16620 ATAC) numbers of cells in each of the four data batches. The cell type information was obtained from the original study and for each of the four data batches the number of cell types are 11, 11, 10 and 10.</p>
      </sec>
      <sec id="SEC2-1-2">
        <title>CITE-seq dataset by Stephenson et al.</title>
        <p>This CITE-seq dataset measures PBMC from healthy individuals and from COVID-19 patients (<xref rid="B15" ref-type="bibr">15</xref>). Only the data from healthy individuals were used in this study. The raw matrices of RNA and ADT and the annotation of cells to their respective cell types from the original study were downloaded from the EMBL-EBI ArrayExpress database under the accession number E-MTAB-10026, with 30313 healthy cells from Cambridge medical centre (batch 1) and 64262 healthy cells from NCL medical centre (batch 2). RNA and ADT in this dataset were filtered by removing those that expressed in less than 1% of the cells and cell types were filtered by removing those that have less than 10 cells. After filtering, there are 30313 cells from 17 cell types (10668 RNA, 192 ADT) in batch 1 and 64257 cells from 16 cell types (10618 RNA, 192 ADT) in batch 2 of the dataset for downstream analysis.</p>
      </sec>
      <sec id="SEC2-1-3">
        <title>CITE-seq dataset by Hao et al</title>
        <p>The raw RNA and ADT matrices from this CITE-seq dataset generated by Hao <italic toggle="yes">et al.</italic> (<xref rid="B14" ref-type="bibr">14</xref>) from PBMC 2 were downloaded from NCBI GEO under the accession number GSE164378. The dataset contains two batches and the cells in both batches were annotated to 31 cell types. As the above, RNA and ADT in this dataset were filtered by removing those that expressed in &lt;1% of the cells and cell types were filtered by removing those that have less than 10 cells. This resulted in 67090 cells (11 451 RNA, 228 ADT) in batch 1 and 94674 cells (12 347 RNA, 228 ADT) in batch 2 of the dataset.</p>
      </sec>
      <sec id="SEC2-1-4">
        <title>CITE-seq dataset by Ramaswamy et al</title>
        <p>The raw RNA and ADT matrices of PBMC from three healthy donors in this CITE-seq dataset generated by Ramaswamy <italic toggle="yes">et al.</italic> (<xref rid="B13" ref-type="bibr">13</xref>) were downloaded from NCBI GEO under the accession number GSE166489. Each patient sample corresponds to one data batch. After filtering RNA and ADT expressed in less than 1% of the cells and discarding cell types that have fewer than 10 cells, we obtained 8641 cells and 26 cell types in batch 1 (11062 RNA, 189 ADT), 9523 cells and 26 cell types in batch 2 (10 801 RNA, 189 ADT), and 10 410 cells and 28 cell types (11 039 RNA, 189 ADT) in batch 3 of this dataset.</p>
      </sec>
      <sec id="SEC2-1-5">
        <title>SHARE-seq dataset</title>
        <p>The SHARE-seq data that measures RNA and ATAC from matched cells in mouse skin samples were downloaded from NCBI GEO under the accession number GSE140203 (<xref rid="B16" ref-type="bibr">16</xref>). The dataset contains raw count of RNA and ATAC of cells annotated to 22 cell types. Similar to the above, we first removed peaks with no expression across cells, and then summarized the ATAC data from peak level into gene activity scores using the ‘CreateGeneActivityMatrix’ function in Seurat. We filtered out RNA and ATAC quantified in fewer than 1% of the cells and cell types that have less than 10 cells, resulting in a dataset with 32231 cells (8926 RNA, 14 034 ATAC) for the subsequent analyses.</p>
      </sec>
    </sec>
    <sec id="SEC2-2">
      <title>Matilda design</title>
      <sec id="SEC2-2-1">
        <title>Multi-task learning architecture</title>
        <p>The multi-task neural networks in Matilda consist of multimodality-specific encoders and decoders in a variational autoencoder (VAE) component for data simulation and a fully-connected classification network for cell type classification. The encoders in the VAE component are shareable for both data simulation and classification tasks, and consist of one learnable point-wise parameter layer and one fully-connected layer to the input layer. Because ADT modality has significantly fewer features than RNA and ATAC modalities, we set empirically, based on model selection, the numbers of neurons for encoders of RNA, ADT, and ATAC modalities to be 185, 30, and 185, respectively. To learn a latent space that integrates the information from across modalities, we concatenated the output from the encoder trained from each data modality to perform joint learning using a fully-connected layer with 100 neurons, followed by a VAE reparameterization process (<xref rid="B11" ref-type="bibr">11</xref>). Next, the fully-connected layer of the latent space is split into two branches with one branch fed into the decoders and the other branch fed into the fully-connected classification network. For the decoder branch, it consists of multiple decoders each corresponds to an input data modality. Each decoder consists of one fully-connected layer to the output layer that has the same number of neurons as the features in the corresponding data modality. For each fully-connected layer in the VAE component, batch normalization (<xref rid="B18" ref-type="bibr">18</xref>), shortcut (<xref rid="B19" ref-type="bibr">19</xref>) were utilized in the model. ReLU activation was used in all fully-connected layers except in the reparameterization process. Dropout (<italic toggle="yes">r</italic> = 0.2) was utilized only for fully-connected layers in encoders. For the classification branch, it consists of the latent space as input to a fully-connected layer with a dimension equal to the number of cell types in the training data. The fully-connected layer outputs a probability vector for cell type prediction through a SoftMax function.</p>
      </sec>
      <sec id="SEC2-2-2">
        <title>Loss function</title>
        <p>Let <inline-formula><tex-math id="M0001" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$X$\end{document}</tex-math></inline-formula> be the single-cell multimodal omic data from <inline-formula><tex-math id="M0001a" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$N$\end{document}</tex-math></inline-formula> modalities, the VAE component of Matilda contains two procedures: (i) the encoders encode each modality in the data <inline-formula><tex-math id="M0002" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$X$\end{document}</tex-math></inline-formula> individually, and concatenate them for joint learning. This process projected the high-dimensional <inline-formula><tex-math id="M0003" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$X$\end{document}</tex-math></inline-formula> into a low-dimensional latent space. We denote the posterior distribution of this process as <inline-formula><tex-math id="M0004" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${q}_\theta ( {z{\rm{|}}X} )$\end{document}</tex-math></inline-formula>, where <inline-formula><tex-math id="M0005" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\theta$\end{document}</tex-math></inline-formula> is the learnable parameter of the neural network in this procedure; (ii) the decoders reconstruct the low-dimensional latent space to the high-dimensional original data space. We denote the posterior distribution of this process as <inline-formula><tex-math id="M0006" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${p}_\varphi ( {X{\rm{|}}z} )$\end{document}</tex-math></inline-formula>, where <inline-formula><tex-math id="M0007" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\varphi$\end{document}</tex-math></inline-formula> is the learnable parameter of the neural network in this procedure. The loss function of the data simulation component can be represented as the negative log-likelihood with a regularizer:</p>
        <disp-formula id="M1">
          <label>(1)</label>
          <tex-math id="M0008" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{eqnarray*}{L}_{sim}\ \left( {\theta ,\varphi } \right) &amp;=&amp; {\rm{\ }} - {E}_{z\sim{q}_\theta \left( {z{\rm{|}}X} \right)}\left[ {log{p}_\varphi \left( {X{\rm{|}}z} \right)} \right]\nonumber\\ &amp;&amp;+ KL({q}_\theta \left( {z{\rm{|}}X} \right)||p\left( z \right))\end{eqnarray*}$$\end{document}</tex-math>
        </disp-formula>
        <p>The first term is the reconstruction loss using the expectation of negative log-likelihood. This term encourages the decoder to learn to reconstruct the original data <inline-formula><tex-math id="M0009" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$X$\end{document}</tex-math></inline-formula> using the low-dimensional representation <inline-formula><tex-math id="M00010" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$z$\end{document}</tex-math></inline-formula>. The second term is the Kullback-Leibler <inline-formula><tex-math id="M00011" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$( {KL} )$\end{document}</tex-math></inline-formula> divergence between the encoder's distribution <inline-formula><tex-math id="M00012" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${q}_\theta ( {z{\rm{|}}X} )$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M00013" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$p( z )$\end{document}</tex-math></inline-formula>, where <inline-formula><tex-math id="M00014" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$p( z )$\end{document}</tex-math></inline-formula> is specified as a standard Normal distribution as <inline-formula><tex-math id="M00015" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$p( z )\sim N( {0,1} )$\end{document}</tex-math></inline-formula>. This divergence measures the information loss when using <inline-formula><tex-math id="M00016" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${q}_\theta ( {z{\rm{|}}X} )$\end{document}</tex-math></inline-formula> to represent <inline-formula><tex-math id="M00017" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$p( z )$\end{document}</tex-math></inline-formula>. The encoder network parameters are in turn optimized using stochastic gradient descent via back-propagation, which is made possible by the reparameterization trick (<xref rid="B11" ref-type="bibr">11</xref>).</p>
        <p>For the loss function of the classification component, we use cross-entropy loss with label smoothing (<xref rid="B20" ref-type="bibr">20</xref>). Label smoothing is a regularizer technique, which replaces one-hot real label vector <inline-formula><tex-math id="M00018" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${y}_{real}$\end{document}</tex-math></inline-formula> with a mixture of <inline-formula><tex-math id="M00019" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${y}_{real}$\end{document}</tex-math></inline-formula> and the uniform distribution:</p>
        <disp-formula id="M2">
          <label>(2)</label>
          <tex-math id="M00020" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}{y}_{ls}= \left( {1 - \alpha } \right)\ \times \ {y}_{real}\ + \ \alpha /K \end{equation*}$$\end{document}</tex-math>
        </disp-formula>
        <p>where <inline-formula><tex-math id="M00021" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$K$\end{document}</tex-math></inline-formula> is the number of label classes, and <inline-formula><tex-math id="M00022" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\alpha$\end{document}</tex-math></inline-formula> is a hyperparameter that determines the amount of smoothing. Then, the classification loss can be represented as:</p>
        <disp-formula id="M3">
          <label>(3)</label>
          <tex-math id="M00023" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}{L}_{cla} = - {\rm{\Sigma }}_{i\ = \ 1}^{i\ = \ K}y_{ls}^ilogy_{output}^i \end{equation*}$$\end{document}</tex-math>
        </disp-formula>
        <p>where <inline-formula><tex-math id="M00024" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$y_{output}^i$\end{document}</tex-math></inline-formula> is the predicted label for the <inline-formula><tex-math id="M00025" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${i}^{th}$\end{document}</tex-math></inline-formula> cell.</p>
        <p>To learn Matilda, we combined the simulation loss and classification loss to give the following overall loss function:</p>
        <disp-formula id="M4">
          <label>(4)</label>
          <tex-math id="M00026" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}{\rm{\ }}{L}_{sum} = {L}_{sim}+ {\rm{\lambda }} \times {L}_{cla} \end{equation*}$$\end{document}</tex-math>
        </disp-formula>
        <p>where <inline-formula><tex-math id="M00027" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\rm{\lambda }}$\end{document}</tex-math></inline-formula> is a weighting coefficient that determines the importance of the classification term against the data simulation term from Matilda.</p>
      </sec>
      <sec id="SEC2-2-3">
        <title>Data augmentation and balancing strategy</title>
        <p>During the model training process, Matilda performs data augmentation and balancing using simulated data from the VAE component. Specifically, Matilda first ranks the cell types in the training dataset by the number of cells in each type. The cell type corresponding to the median number is used as the reference and those that have smaller numbers of cells are augmented to have the same number of cells as the median using VAE simulated single-cell multimodal data for each cell type. Cell types that have larger numbers of cells than the median number are randomly down-sampled to match the median number of cells as well. This strategy helps Matilda to mitigate imbalanced cell type distribution in the data (<xref rid="B21" ref-type="bibr">21</xref>) and better learn the molecular features of under-represented and rare cell types.</p>
      </sec>
      <sec id="SEC2-2-4">
        <title>Joint feature selection from multiple modalities</title>
        <p>Leveraging its neural network architecture, Matilda implements two approaches, i.e. integrated gradient (IG) (<xref rid="B22" ref-type="bibr">22</xref>) descent and saliency (<xref rid="B23" ref-type="bibr">23</xref>) based procedures, to detect the most informative features simultaneously from each of all data modalities. Specifically, for the IG method, to assess the importance of each feature, the trained model was used for back-propagation of the partial derivatives from the output units of the classification network to the input units of the encoders, where each input unit represents an individual feature from a given modality in the input data <inline-formula><tex-math id="M00028" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$X$\end{document}</tex-math></inline-formula>. The importance score of each input feature of each cell is determined by approximating the integral gradients of the model's output to its input:</p>
        <disp-formula id="M5">
          <label>(5)</label>
          <tex-math id="M00029" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}{\rm{\ }}{S}_j = \mathop \smallint \limits_{\tau = 0}^1 {X}_j\ \times \ \frac{{\partial F\left( {\tau \times X} \right)}}{{\partial {X}_j}}d\tau \end{equation*}$$\end{document}</tex-math>
        </disp-formula>
        <p>where<inline-formula><tex-math id="M00030" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\ F$\end{document}</tex-math></inline-formula><inline-formula><tex-math id="M00031" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\ F$\end{document}</tex-math></inline-formula> represents the classification branch of the multi-task neural networks, and <inline-formula><tex-math id="M00032" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\frac{{\partial F( {\tau \times X} )}}{{\partial {X}_j}}$\end{document}</tex-math></inline-formula> is the gradient of <inline-formula><tex-math id="M00033" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$F( X )$\end{document}</tex-math></inline-formula> along with the <inline-formula><tex-math id="M00034" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$j^{th}$\end{document}</tex-math></inline-formula> feature. We aggregated these derivatives across cells within each cell type. These aggregated gradients indicate the importance of each feature from each data modality in predicting each cell type. The top-ranked features from each cell type can be selected based on their aggregated derivatives for subsequent analyses. For the saliency method, a cell-type-specific importance score of a feature <inline-formula><tex-math id="M00035" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$j$\end{document}</tex-math></inline-formula> is computed using the derivative:</p>
        <disp-formula id="M6">
          <label>(6)</label>
          <tex-math id="M00036" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}{\rm{\ }}{S}_j = {\left. {\frac{{\partial F\left( X \right)}}{{\partial X}}} \right|}_{{X}_j}\ \end{equation*}$$\end{document}</tex-math>
        </disp-formula>
        <p>The magnitude of the derivative <inline-formula><tex-math id="M00037" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${S}_j$\end{document}</tex-math></inline-formula> indicates the effect of feature <inline-formula><tex-math id="M00038" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$j$\end{document}</tex-math></inline-formula> on the classification score.</p>
      </sec>
      <sec id="SEC2-2-5">
        <title>Matilda model training</title>
        <p>Matilda adopts a two-step training strategy. In the first step, i.e. before augmentation and balancing, we train a network from scratch. In the second step, i.e. after augmentation and balancing, we inherit the weights from the first step as the initial value and fine-tune the networks using augmented and balanced data. Several key hyper-parameters may impact the performance of Matilda. These include the number of layers in the neural networks, the number of neurons in each layer, the parameter <inline-formula><tex-math id="M00039" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\lambda$\end{document}</tex-math></inline-formula> that balances the VAE data reconstruction and cell type classification in the multi-tasking learning, and other parameters such as learning rate, number of epochs, batch size, and dropout rate. To optimize these hyper-parameters, we used the training datasets of CITE-seq, SHARE-seq, and TEA-seq to evaluate the model performance with different parameter combinations based on measurements including (a) the distance between the umap of simulated data and real data and (b) the classification accuracy before and after data augmentation. These allowed us to determine the following Matilda settings that were used in subsequent experiments. Specifically, for both steps in the training process, batch size was set to 64 cells in learning from all datasets. The epoch was set to 30 for all datasets except the CITE-seq dataset generated by Hao <italic toggle="yes">et al.</italic> (GSE164378) which contains the largest number of cells. Since large datasets do not need many training epochs for the neural networks to converge, we set this to 10 for this CITE-seq dataset (GSE164378) for improving training efficiency. The parameter <inline-formula><tex-math id="M00040" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\lambda$\end{document}</tex-math></inline-formula> for balancing loss function in multi-tasking learning was empirically set to 0.1 for all datasets and the parameter <inline-formula><tex-math id="M00041" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\alpha$\end{document}</tex-math></inline-formula> in label smoothing was set to 0.1 according to (<xref rid="B24" ref-type="bibr">24</xref>). In the first stage, we empirically determined the learning rate of 0.02 in the training process. In the second stage, we fine-tuned the networks with an initial learning rate of 0.02 for the first half of epochs and 0.002 for the second half of epochs. In Matilda, all input data modalities were normalized by the ‘NormalizeData’ function in Seurat (<xref rid="B14" ref-type="bibr">14</xref>) and then scaled using a <italic toggle="yes">z</italic>-score transformation to a similar range.</p>
      </sec>
    </sec>
    <sec id="SEC2-3">
      <title>Settings for other classification methods</title>
      <sec id="SEC2-3-1">
        <title>CHETAH</title>
        <p>Raw count matrices of RNA modality from each dataset were used as input for CHETAH (v1.8.0) (<xref rid="B6" ref-type="bibr">6</xref>) and the function ‘CHETAHclassifier’ was used to perform cell type classification, following the author's tutorial (<ext-link xlink:href="https://github.com/jdekanter/CHETAH" ext-link-type="uri">https://github.com/jdekanter/CHETAH</ext-link>).</p>
      </sec>
      <sec id="SEC2-3-2">
        <title>scmapCell</title>
        <p>Raw count matrices of RNA modality from each dataset were first normalized using ‘NormalizeData’ function in Seurat and then used as input for scmap (v1.14.0) (<xref rid="B25" ref-type="bibr">25</xref>) as suggested (<ext-link xlink:href="https://github.com/hemberg-lab/scmap" ext-link-type="uri">https://github.com/hemberg-lab/scmap</ext-link>). By default, the top 500 most informative genes were used and the function ‘scmapCell2Cluster’ annotates cells in the query dataset to their respective cell types based on the reference data.</p>
      </sec>
      <sec id="SEC2-3-3">
        <title>scClassify</title>
        <p>Raw count matrices of RNA modality from each dataset were first normalized using the ‘NormalizeData’ function in Seurat and then used as input for scClassify (v1.4.0) (<xref rid="B5" ref-type="bibr">5</xref>). The default parameters, e.g. tree = ‘HOPACH’, algorithm = ‘WKNN’, selectFeatures = ‘limma’, similarity = ‘pearson’, were used as suggested in the pipeline (<ext-link xlink:href="https://github.com/SydneyBioX/scClassify" ext-link-type="uri">https://github.com/SydneyBioX/scClassify</ext-link>).</p>
      </sec>
      <sec id="SEC2-3-4">
        <title>singleCellNet</title>
        <p>Raw count matrices of RNA modality from each dataset were first normalized using the ‘NormalizeData’ function in Seurat and then used as input for singleCellNet (v0.1.0) (<xref rid="B26" ref-type="bibr">26</xref>). ‘scn_train’ function with the default parameters of nTopGenes = 10, nRand = 70, nTrees = 1000, nTopGenePairs = 25, dLevel = ‘newAnn’, colName_samp = ‘cell’ was used for training the model. The trained models were subsequently used for predicting the cell types for cells in the query data using ‘scn_predict’ and ‘assess_comm’ with default parameters (<ext-link xlink:href="https://github.com/pcahan1/singleCellNet" ext-link-type="uri">https://github.com/pcahan1/singleCellNet</ext-link>).</p>
      </sec>
      <sec id="SEC2-3-5">
        <title>CelliD</title>
        <p>The raw count matrices of RNA modality from each dataset were used as input for CelliD (v1.0.0) (<xref rid="B27" ref-type="bibr">27</xref>). Following the author's pipeline (<ext-link xlink:href="https://github.com/RausellLab/CelliD" ext-link-type="uri">https://github.com/RausellLab/CelliD</ext-link>), we use the function ‘RunMCA’ to perform Multiple Correspondence Analysis (MCA) dimension reduction for both reference and query data. Then extract gene signatures in each cell type using the function ‘GetGroupGeneSet’ with default parameters dims = 1:50, n.features = 200, group.by = ‘cell.type’. The cell-to-cell matching and label transferring across data were generated using the function ‘RunCellHGT’.</p>
      </sec>
      <sec id="SEC2-3-6">
        <title>scID</title>
        <p>Raw count matrices of RNA modality from each dataset were first normalized using the ‘NormalizeData’ function in Seurat and then used as input for the R package scID (v2.2) (<xref rid="B28" ref-type="bibr">28</xref>). Following the author's tutorial (<ext-link xlink:href="https://github.com/BatadaLab/scID" ext-link-type="uri">https://github.com/BatadaLab/scID</ext-link>), we used the function ‘scid_multiclass’ with default parameters for identifying cell types in the query datasets.</p>
      </sec>
      <sec id="SEC2-3-7">
        <title>UMINT</title>
        <p>UMINT package version (c084930) (<xref rid="B29" ref-type="bibr">29</xref>) was used in this study. Following the author's tutorial (<ext-link xlink:href="https://github.com/deeplearner87/UMINT" ext-link-type="uri">https://github.com/deeplearner87/UMINT</ext-link>), raw count matrices of RNA and/or ATAC modalities from each dataset were first normalized using the ‘NormalizeData’ function in Seurat, followed by ‘FindVatiableFeatures’, ‘ScaleData’ and ‘RunPCA’. Raw count matrices of ADT modality were normalized using the ‘NormalizeData’ function with the parameter normalization.method = ‘CLR’, margin = 2, followed by ‘ScaleData’ and ‘RunPCA’. The multimodal embeddings from UMINT were obtained and used for cell type classification.</p>
      </sec>
    </sec>
    <sec id="SEC2-4">
      <title>Settings for other simulation methods</title>
      <sec id="SEC2-4-1">
        <title>SPARSim</title>
        <p>Following the author's pipeline (<ext-link xlink:href="https://gitlab.com/sysbiobig/sparsim" ext-link-type="uri">https://gitlab.com/sysbiobig/sparsim</ext-link>), raw count matrices of RNA modality from each dataset were used as input for SPARSim (v0.9.5) (<xref rid="B17" ref-type="bibr">17</xref>). Data were first normalized using the ‘scran_normalization’ function in SPARSim package and data parameters were estimated by ‘SPARSim_estimate_parameter_from_data’ function. The function ‘SPARSim_simulation’ was then used for generating simulated data.</p>
      </sec>
      <sec id="SEC2-4-2">
        <title>cscGAN</title>
        <p>Following the author's pipeline (<ext-link xlink:href="https://github.com/imsb-uke/scGAN" ext-link-type="uri">https://github.com/imsb-uke/scGAN</ext-link>), raw count matrices of RNA modality from each dataset were first normalized using the ‘process_files’ function in cscGAN (Github version 988ad95) (<xref rid="B30" ref-type="bibr">30</xref>). Default parameters and training iteration of 6000 was used for model training and the ‘run_exp’ function was used for generating simulated data from the trained model.</p>
      </sec>
      <sec id="SEC2-4-3">
        <title>ACTIVA</title>
        <p>Following the author's pipeline (<ext-link xlink:href="https://github.com/SindiLab/ACTIVA" ext-link-type="uri">https://github.com/SindiLab/ACTIVA</ext-link>), raw count matrices of RNA modality from each dataset were used as input for ACTIVA (<xref rid="B31" ref-type="bibr">31</xref>). Data was first pre-processed using the ‘Scanpy_IO’ function in ACTIVA package (v0.0.3). Then, the model was trained using the ‘ACTIVA’ function with the default parameters. The function ‘generate_subpopulation’ was then used for generating simulated data.</p>
      </sec>
    </sec>
    <sec id="SEC2-5">
      <title>Settings for other dimension reduction methods</title>
      <sec id="SEC2-5-1">
        <title>Seurat</title>
        <p>Seurat package (v4.1.0) (<xref rid="B14" ref-type="bibr">14</xref>) was used for dimension reduction of all CITE-seq datasets. The raw count matrices of RNA and ADT were used as input, which were then normalized by the ‘NormalizeData’ function in Seurat. By default, the top 2000 most variable genes were selected from RNA modality by ‘FindVariableFeatures’ function and data are subsequently scaled by ‘ScaleData’ function. Data from ADT modality were processed similarly as those of RNA modality, except using parameters of normalization.method = ‘CLR’ and margin = 2 in the in ‘NormalizeData’ function, as suggested in the author's pipeline (<ext-link xlink:href="https://satijalab.org/seurat/" ext-link-type="uri">https://satijalab.org/seurat/</ext-link>). PCA was performed using the ‘runPCA’ function and the function ‘FindMultiModalNeighbors’ integrates RNA and ADT modalities using the PCA results. The joint visualization of RNA and ADT were generated using ‘wnn.umap’ function.</p>
      </sec>
      <sec id="SEC2-5-2">
        <title>totalVI</title>
        <p>The totalVI procedure implemented in the scvi-tools package (v0.15.0) (<xref rid="B4" ref-type="bibr">4</xref>) was used for dimension reduction of all CITE-seq datasets. Following the author's tutorial (<ext-link xlink:href="https://github.com/scverse/scvi-tools" ext-link-type="uri">https://github.com/scverse/scvi-tools</ext-link>), the raw count matrices of RNA and ADT were first normalized using the ‘normalize_total’ and ‘log1p’ functions and then the top 4000 most variable genes were selected using the ‘highly_variable_genes’ function. The data were subsequently used as input for model training using ‘scvi.model.TOTALVI.setup_anndata’, ‘scvi.model.TOTALVI’, and ‘train’ functions in scvi-tools. The latent space of RNA and ADT modalities was generated using the ‘get_latent_representation’ function.</p>
      </sec>
      <sec id="SEC2-5-3">
        <title>Conos</title>
        <p>Conos package (v1.4.5) (<xref rid="B32" ref-type="bibr">32</xref>) was used for dimension reduction of the SHARE-seq dataset. Following the author's pipeline (<ext-link xlink:href="https://github.com/kharchenkolab/conos" ext-link-type="uri">https://github.com/kharchenkolab/conos</ext-link>), the raw count matrices of RNA and ATAC were normalized by the ‘basicP2proc’ function in pagoda2 package (v1.0.8), where recommended parameters of n.odgenes = 3e3, nPcs = 30, min.cells.per.gene = -1, make.geneknn = FALSE, and n.cores = 1 were used. Next, the joint graph was built using buildGraph with k = 15, k.self = 5, k.self.weigh = 0.01, ncomps = 30, n.odgenes = 5e3, and space = ‘PCA’ in Conos. The joint visualization of RNA and ATAC were generated using ‘largeVis’ in function ‘embedGraph’ with default parameter alpha = 1/2.</p>
      </sec>
      <sec id="SEC2-5-4">
        <title>MultiVI</title>
        <p>The MultiVI procedure implemented in the scvi-tools (v0.15.0) (<xref rid="B33" ref-type="bibr">33</xref>) was used for dimension reduction of the SHARE-seq dataset. Following the author's pipeline (<ext-link xlink:href="https://github.com/scverse/scvi-tools" ext-link-type="uri">https://github.com/scverse/scvi-tools</ext-link>), the raw count matrices of RNA and gene activity score matrices from ATAC and the paired matrix of RNA and ATAC were used as input. These data were first concatenated using the ‘organize_multiome_anndatas’ function in scvi-tools and then used for model training using ‘scvi.model.MULTIVI.setup_anndata’, ‘scvi.model.MULTIVI’ and ‘train’ functions in scvi-tools. The latent space of RNA and ATAC modalities was generated using the ‘get_latent_representation’ function.</p>
      </sec>
      <sec id="SEC2-5-5">
        <title>Multigrate</title>
        <p>The Multigrate method (<xref rid="B34" ref-type="bibr">34</xref>) was used for the dimension reduction of all datasets. Following the author's pipeline (<ext-link xlink:href="https://github.com/theislab/multigrate" ext-link-type="uri">https://github.com/theislab/multigrate</ext-link>), the raw count matrices of RNA, ADT or ATAC were used as input. RNA and ATAC data were first normalized using the ‘normalize_total’ and ‘log1p’ functions, and then the top 4000 most variable genes were selected using the ‘highly_variable_genes’ function. For ADT data, we perform CLR transformation using ‘clr’ function. Next, we combine the multimodality data using ‘organize_multiome_anndatas’ function and train the Multigrate models using ‘MultiVAE.setup_anndata’, ‘MultiVAE’, and ‘train’ functions in the Multigrate package (v0.0.2). The latent space was generated using the ‘get_latent_representation’ function.</p>
      </sec>
    </sec>
    <sec id="SEC2-6">
      <title>Settings for other feature selection methods</title>
      <p>We performed feature selection from the RNA modality of each dataset using a collection of methods: (i) simple one-sided <italic toggle="yes">t</italic>-test and Wilcoxon rank sum test, (ii) popular methods based on differential expression analysis including Limma (v3.48.3) (<xref rid="B7" ref-type="bibr">7</xref>) and MAST (v.1.2.1) (<xref rid="B8" ref-type="bibr">8</xref>), (iii) methods based on maximizing classification performance including logistic regression (LR) and receiver operating curve (ROC) implemented in the ‘FindMarkers’ function in Seurat 2 and (iv) deep learning based feature selection methods, including PROPOSE and scCapsNet with the following settings:</p>
      <sec id="SEC2-6-1">
        <title>PROPOSE</title>
        <p>The PROPOSE procedure (<xref rid="B35" ref-type="bibr">35</xref>) was used for feature selection of RNA modality from all datasets. Following the author's pipeline (<ext-link xlink:href="https://github.com/iancovert/propose" ext-link-type="uri">https://github.com/iancovert/propose</ext-link>), the raw count matrices were first binarized to {0,1} according to the sign of the values and then used for model training using the ‘PROPOSE’ function in propose package (Github version 41fd568) with the number of marker genes as 100 and other parameters as default.</p>
      </sec>
      <sec id="SEC2-6-2">
        <title>scCapsNet</title>
        <p>The scCapsNet (Github version b21ca07) procedure was used for feature selection of RNA modality from all datasets. The raw count matrices were normalized using the ‘log2’ function in the numpy package. Following the author's pipeline (<ext-link xlink:href="https://github.com/wanglf19/scCaps" ext-link-type="uri">https://github.com/wanglf19/scCaps</ext-link>), the models were trained using the default network and parameters.</p>
      </sec>
    </sec>
    <sec id="SEC2-7">
      <title>Performance evaluation</title>
      <sec id="SEC2-7-1">
        <title>Cell type classification evaluation</title>
        <p>We evaluated the accuracy of a cell type classification model by calculating their average accuracy as the sum of the accuracy in all cell types divided by the number of cell types in a dataset. The average accuracy of all cell types accounts for the performance of a classification model in both the major and minor cell types. We used two pipelines, referred to as ‘intra-dataset’ and ‘inter-dataset’ classification, for cell type classification model evaluation. While intra-dataset classification splits training and test data from one batch of a dataset, inter-dataset classification splits training and test data from different batches in a dataset. For intra-dataset classification, we performed five-fold cross-validation repeated five times with different seeding on each batch of each dataset. For inter-dataset classification, we select the common features and cell types from different batches in the same dataset with different data batches and train on one batch and test on another batch.</p>
      </sec>
      <sec id="SEC2-7-2">
        <title>Simulation evaluation</title>
        <p>We used the correlation heatmaps to visualize the correlation structure of select features in each data modality of each dataset. Specifically, we first applied the functions ‘modelGeneVar’ and ‘getTopHVGs’ from the scran R package (v1.20.1) (<xref rid="B36" ref-type="bibr">36</xref>) to select the top 100 high variable genes (HVGs) based on their variability calculated from each data modality in each dataset (except the ADT modality of the TEA-seq dataset) and then calculated pairwise Pearson's correlation coefficients from these HVGs across all cells in each dataset. Since the ADT modality of the TEA-seq dataset only contains 46 ADTs, we used all of them in the correlation analysis and heatmap visualization. For comparison to other simulation methods in RNA modality, we used the same visualization methods as above for each simulation method and also quantified the performance of each simulation method by calculating the overall Pearson's correlation of real and simulated data and represented these as boxplots.</p>
      </sec>
      <sec id="SEC2-7-3">
        <title>Dimension reduction evaluation</title>
        <p>We used the performance of a simple <italic toggle="yes">k</italic>-means clustering algorithm to assess cell type clustering on dimension reduced dataset generated from each modality integration and dimension reduction method. Similar to cell type classification, we used intra-dataset and inter-dataset for assessing cell type clustering. In particular, we used the latent space of the test dataset obtained either from five-fold cross-validation or a data batch for cell type clustering and compared the concordance between the clustering output and the cell type labels from their original studies. The five-fold cross-validation procedure in the intra-dataset clustering was repeated five times with different seeding. We assessed the clustering concordance using four evaluation metrics, including Adjusted Rand Index (ARI), Normalized Mutual Information (NMI), Fowlkes-Mallows index (FM), and Jaccard index (Jaccard). Briefly, let <inline-formula><tex-math id="M00042" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$N$\end{document}</tex-math></inline-formula> be the number of cells in the dataset, <inline-formula><tex-math id="M00043" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{U\ }} = \ \{ {U}_1,{U}_2, \ldots ,{U}_R\}$\end{document}</tex-math></inline-formula> be the cell type annotation from the original study, and <inline-formula><tex-math id="M00044" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{V\ }} = \ \{ {V}_1,{V}_2, \ldots ,{V}_c\}$\end{document}</tex-math></inline-formula> be the partition generated by clustering, the pairs between <inline-formula><tex-math id="M00045" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{U}}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M00046" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{V}}$\end{document}</tex-math></inline-formula> can be classified into one of the four types: (i) <inline-formula><tex-math id="M00047" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${N}_{11}$\end{document}</tex-math></inline-formula>: the number of pairs that are in the same partition in both <inline-formula><tex-math id="M00048" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{U}}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M00049" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{V}}$\end{document}</tex-math></inline-formula>; (ii) <inline-formula><tex-math id="M00050" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${N}_{00}:$\end{document}</tex-math></inline-formula> the number of pairs that are in different partitions in <inline-formula><tex-math id="M00051" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{U}}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M00052" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{V}}$\end{document}</tex-math></inline-formula>; (iii) <inline-formula><tex-math id="M00053" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${N}_{01}$\end{document}</tex-math></inline-formula>: the number of pairs that are in the same partition in <inline-formula><tex-math id="M00054" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{U}}$\end{document}</tex-math></inline-formula> but in different partitions in <inline-formula><tex-math id="M00055" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{V}}$\end{document}</tex-math></inline-formula>; (iv) <inline-formula><tex-math id="M00056" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${N}_{10}$\end{document}</tex-math></inline-formula>: the number of pairs that are in different partitions in <inline-formula><tex-math id="M00057" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{U}}$\end{document}</tex-math></inline-formula> but in the same partition in <inline-formula><tex-math id="M00058" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{V}}$\end{document}</tex-math></inline-formula>. Given the above notation, we defined the ARI, NMI, FM, Jaccard metrics as follows:</p>
        <disp-formula id="M7">
          <label>(7)</label>
          <tex-math id="M00059" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}ARI\ ( {{\boldsymbol{U}},{\boldsymbol{V}}}) = \frac{{2( {{N}_{00}{N}_{11} - {N}_{01}{N}_{10}} )}}{{({N}_{00} + {N}_{01})( {{N}_{01} + {N}_{11}} ) + ( {{N}_{00} + {N}_{10}} )( {{N}_{10} + {N}_{11}} )}}\ \end{equation*}$$\end{document}</tex-math>
        </disp-formula>
        <disp-formula id="M8">
          <label>(8)</label>
          <tex-math id="M00060" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}Jaccard\ \left( {{\boldsymbol{U}},V} \right) = \frac{{{N}_{11}}}{{{N}_{11} + {N}_{10} + {N}_{01}}}\ \end{equation*}$$\end{document}</tex-math>
        </disp-formula>
        <disp-formula id="M9">
          <label>(9)</label>
          <tex-math id="M00061" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}FM\ \left( {{\boldsymbol{U}},{\boldsymbol{V}}} \right) = \ \sqrt {\left( {\frac{{{N}_{11}}}{{{N}_{11} + {N}_{01}}}} \right)\left( {\frac{{{N}_{11}}}{{{N}_{11} + {N}_{10}}}} \right)} \end{equation*}$$\end{document}</tex-math>
        </disp-formula>
        <disp-formula id="M10">
          <label>(10)</label>
          <tex-math id="M00062" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}NMI\ \left( {{\boldsymbol{U}},{\boldsymbol{V}}} \right) = \ \frac{{I\left( {{\boldsymbol{U}};{\boldsymbol{V}}} \right)}}{{H\left( {\boldsymbol{U}} \right) + H\left( {\boldsymbol{V}} \right)}}\end{equation*}$$\end{document}</tex-math>
        </disp-formula>
        <p>where <inline-formula><tex-math id="M00063" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$I( {{\boldsymbol{U}};{\boldsymbol{V}}} )$\end{document}</tex-math></inline-formula> is the mutual information between <inline-formula><tex-math id="M00064" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{U}}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M00065" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\boldsymbol{V}}$\end{document}</tex-math></inline-formula>, defined as</p>
        <disp-formula id="M11">
          <label>(11)</label>
          <tex-math id="M00066" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}I\ \left( {{\boldsymbol{U}};{\boldsymbol{V}}} \right) = {\rm{\Sigma }}_{i = 1}^R\ {\rm{\Sigma }}_{j\ = \ 1}^C\frac{{\left| {{U}_i \cap {U}_j} \right|}}{N}lo{g}_2\frac{{N\left| {{U}_i \cap {V}_j} \right|}}{{\left| {{U}_i} \right|\left| {{V}_j} \right|}}\end{equation*}$$\end{document}</tex-math>
        </disp-formula>
        <p>and <inline-formula><tex-math id="M00067" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$H( \cdot )$\end{document}</tex-math></inline-formula> is the entropy of partitions, in which <inline-formula><tex-math id="M00068" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$H( {\boldsymbol{U}} )$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M00069" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$H( {\boldsymbol{V}} )$\end{document}</tex-math></inline-formula> are calculated</p>
        <disp-formula id="M12">
          <label>(12)</label>
          <tex-math id="M00070" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}H\ \left( {\boldsymbol{V}} \right) = \ - {\rm{\Sigma }}_{j\ = \ 1}^C\frac{{\left| {{V}_j} \right|}}{N}log\frac{{\left| {{V}_j} \right|}}{N}\end{equation*}$$\end{document}</tex-math>
        </disp-formula>
        <disp-formula id="M13">
          <label>(13)</label>
          <tex-math id="M00071" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}H\ \left( {\boldsymbol{U}} \right) = \ - {\rm{\Sigma }}_{i\ = \ 1}^R\frac{{\left| {{U}_i} \right|}}{N}log\frac{{\left| {{U}_i} \right|}}{N}\end{equation*}$$\end{document}</tex-math>
        </disp-formula>
      </sec>
      <sec id="SEC2-7-4">
        <title>Feature selection evaluation</title>
        <p>We used the classification of each cell type to evaluate the performance of features selected for that cell type. Specifically, we used a ‘one-vs-all’ procedure in that we classified each cell type against all remaining cell types using the top 100 features selected for that cell type from different feature selection methods. Note that only Matilda selected features from all data modalities whereas the other feature selection methods were designed for analysing gene expression data and thus used only to select features from RNA modality of each dataset. The classification accuracy for each cell type was calculated using the ‘intra-dataset’ procedure in that feature selection was conducted on training datasets and their utility/effectiveness in cell type classification were verified on test datasets generated from five-fold cross-validation repeated five times.</p>
      </sec>
      <sec id="SEC2-7-5">
        <title>Running time evaluation</title>
        <p>We evaluated running time on a server with AMD(R) Ryzen processor CPU (16 cores and 64 Gb total memory) and one RTX3090 graphics processing unit. We used the CITE-seq datasets generated by Hao <italic toggle="yes">et al.</italic> (GSE164378) and Ramaswamy <italic toggle="yes">et al.</italic> (GSE166489) to benchmark the running time, given the large numbers of cells in these two datasets. To evaluate the impact of the number of cells from the training datasets, we kept the number of cells to 2k in the test dataset and varied the number of cells in the training datasets from 1k, 2k, 3k, 5k, 10k, 20k, to 30k. Similarly, to evaluate the impact of the number of cells from test dataset, we kept the number of cells in the training dataset to 2k and varied the those in the test datasets from 1k, 2k, 3k, 5k, 10k, 20k, to 30k as above. The elapsed run time was evaluated by the R function ‘system.time()’ and Python function ‘time.time()’ for methods implemented using R and Python, respectively.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results" id="SEC3">
    <title>RESULTS</title>
    <sec id="SEC3-1">
      <title>Multimodal single-cell data simulation</title>
      <p>We applied Matilda to five recent multimodal single-cell omics datasets including a TEA-seq dataset that profiles RNA, ADT and ATAC modalities in human PBMC samples; three CITE-seq datasets that profile RNA and ADT modalities in human PBMC samples; and a SHARE-seq dataset that profiles RNA and ATAC modalities in mouse skin samples (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>). To test if Matilda is able to simulate multimodal omics data in a cell-type-specific manner, we first visualized cells using each modality on UMAPs (Figure <xref rid="F1" ref-type="fig">1B</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref>) and highlighted cells from representative cell types using real and Matilda simulated data. We found that Matilda not only precisely simulates each data modality in a cell-type-specific manner but also denoizes the outliers in the real data, (e.g. ADT modality of B cells and CD14 cells in CITE-seq data; <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2a</xref>).</p>
      <p>To further assess the performance of Matilda on data simulation, we compared the correlation structure of highly variable genes (HVGs) by each data modality using real data and those simulated by Matilda (Figure <xref rid="F2" ref-type="fig">2A</xref>–<xref rid="F2" ref-type="fig">C</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3</xref>). We found that data simulated by Matilda closely resemble the correlation structure of real data across all modalities. While no other methods are currently available for simulating multimodal single-cell omics data besides Matilda, various methods have been developed for simulating from scRNA-seq data (<xref rid="B3" ref-type="bibr">3</xref>). We, therefore, compared the simulation results of Matilda on RNA modality with those generated from scGAN (<xref rid="B30" ref-type="bibr">30</xref>), a simulation method based on deep generative adversarial networks, ACTIVA (<xref rid="B31" ref-type="bibr">31</xref>), a deep learning method based on adversarial VAE, and Sparsim (<xref rid="B17" ref-type="bibr">17</xref>), one of the best performing simulation methods based on mixture modelling (<xref rid="B3" ref-type="bibr">3</xref>). We found that in most cases data simulated from Matilda for the RNA modality better preserve the correlation structure in the real data compared to alternative methods as quantified in Figure <xref rid="F2" ref-type="fig">2D</xref>–<xref rid="F2" ref-type="fig">F</xref>. These results demonstrate the ability of Matilda on simulating multiple data modalities in a cell-type-specific manner in multimodal single-cell omics datasets.</p>
      <fig position="float" id="F2">
        <label>Figure 2.</label>
        <caption>
          <p>(<bold>A</bold>–<bold>C</bold>) Heatmap visualization of the correlation structure of RNA modality of real and simulated TEA-seq dataset (GSE158013), CITE-seq (E-MTAB-10026) and SHARE-seq dataset (GSE140203) using Matilda, scGAN, ACTIVA and Sparsim. The top-100 highly variable genes (HVGs) selected from the RNA modality of the real data were used for the heatmap. (<bold>D</bold>–<bold>F</bold>) Pearson's correlation of simulated data from each simulation method with real data using RNA modality for TEA-seq dataset (GSE158013), CITE-seq (E-MTAB-10026) and SHARE-seq dataset (GSE140203). Centre line, median; box limits, upper and lower quartiles; whiskers, 1.5× interquartile range; points, outliers.</p>
        </caption>
        <graphic xlink:href="gkad157fig2" position="float"/>
      </fig>
    </sec>
    <sec id="SEC3-2">
      <title>Multimodal data integration and dimension reduction</title>
      <p>During model training, Matilda learns to combine and reduce the feature dimensions of multimodal single-cell omics data to a latent space using its VAE component in the framework (Figure <xref rid="F1" ref-type="fig">1A</xref>). The trained VAE of Matilda thus can be used for multimodal feature integration and dimension reduction of both the training and new data. Several alternative methods are available for such tasks. These include Seurat (<xref rid="B14" ref-type="bibr">14</xref>) and totalVI (<xref rid="B4" ref-type="bibr">4</xref>), which are designed for integrating RNA and ADT modalities in CITE-seq data; Conos (<xref rid="B32" ref-type="bibr">32</xref>) and multiVI (<xref rid="B33" ref-type="bibr">33</xref>), which are designed for integrating RNA and ATAC modalities such as these in SHARE-seq data; and Multigrate (<xref rid="B34" ref-type="bibr">34</xref>), which is not limited to specific paired assays and can be applied to both bi- and tri-modality data. Comparing to these methods, we found that the dimension reduced data from Matilda shows significantly better cell type separation under UMAP projection (Figure <xref rid="F3" ref-type="fig">3A</xref>, <xref rid="F3" ref-type="fig">B</xref>).</p>
      <fig position="float" id="F3">
        <label>Figure 3.</label>
        <caption>
          <p>Assessment of Matilda for multimodal integrated dimension reduction and visualization. (A, B) Visualization and (C–E) quantification of joint multimodal dimension reduction results. (<bold>A</bold>) Visualizations of CITE-seq data (E-MTAB-10026) using Matilda, Seurat, totalVI, and Multigrate. (<bold>B</bold>) Visualizations of SHARE-seq data (GSE140203) using Matilda, Conos, MultiVI, and Multigrate. Cells are colour-coded by their types on the UMAPs. Quantifications were based on <italic toggle="yes">k</italic>-means clustering concordance using dimension reduced data from each method and the cell-type annotation from the original publication by ARI, NMI, FM, and Jaccard index. Either (<bold>D</bold>) 5-fold cross-validation repeated five times with different random seedings or (<bold>D</bold>) data from different batches from CITE-seq data (E-MTAB-10026) were used for capturing the variability in quantifications. (<bold>E</bold>) Quantification of <italic toggle="yes">k</italic>-means clustering concordance using dimension reduced data from Matilda, Conos, Multigrate, and MultiVI with cell-type annotations from the original study by ARI, NMI, FM, and Jaccard index on SHARE-seq data (GSE140203). Centre line, median; box limits, upper and lower quartiles; whiskers, 1.5× interquartile range; points, outliers.</p>
        </caption>
        <graphic xlink:href="gkad157fig3" position="float"/>
      </fig>
      <p>To further quantify these visual observations, we clustered the dimension reduced data generated from each method using a simple <italic toggle="yes">k</italic>-means clustering algorithm and analysed the concordance of the clustering output with the cell type labels provided from their original studies using a panel of concordance metrics including ARI, NMI, FM, and Jaccard index (see Materials and Methods). We found that in most cases Matilda generated dimension reduced datasets led to higher clustering concordance with respect to the original cell type labels across all datasets irrespective of the metrics (Figure <xref rid="F3" ref-type="fig">3C</xref>–<xref rid="F3" ref-type="fig">E</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4</xref>). These results demonstrate the superior performance of Matilda for integrating and reducing feature dimensions in multimodal single-cell omics data and its utility for subsequent applications such as data visualization and clustering of cell types.</p>
    </sec>
    <sec id="SEC3-3">
      <title>Cell type classification using multiple data modalities</title>
      <p>To evaluate Matilda on cell type classification using multimodal single-cell omics data, we performed both five-fold cross-validation (repeated 5 times) and training and test using different batches within each dataset (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1b</xref>). While several methods have been developed recently for transferring cell type labels across different data modalities for multimodal single-cell omics data (<xref rid="B37" ref-type="bibr">37–39</xref>), there are currently few methods specifically designed for cell type classification by using all data modalities from such data. To this end, we resorted to comparing methods that are developed for cell type classification from scRNA-seq data by using RNA modality only (<xref rid="B40" ref-type="bibr">40</xref>) and UMINT (<xref rid="B31" ref-type="bibr">31</xref>), a method designed for integrating multiple data modalities to low-dimensional embeddings which can be used for cell type classification. We found that Matilda classifies cells significantly more accurately across all datasets under both the cross-validation settings (Figure <xref rid="F4" ref-type="fig">4A</xref>) and those from training and test using different batches within each dataset (Figure <xref rid="F4" ref-type="fig">4B</xref>) than other state-of-the-art cell type classification methods that use only RNA modality or those from using integrated embeddings generated by UMINT. The breakdown of the classification results from training and test using each pair of data batches reveals that Matilda led to higher cell type classification accuracy across all pairs in all four datasets that contain multiple data batches (Figure <xref rid="F4" ref-type="fig">4C</xref>).</p>
      <fig position="float" id="F4">
        <label>Figure 4.</label>
        <caption>
          <p>(A, B) Cell type classification of each multimodal single-cell omics data. Either (<bold>A</bold>) 5-fold cross-validation repeated five times with different random seedings or (<bold>B</bold>) data from different batches were used for benchmarking the performance of each method. Error bar, SD. (<bold>C</bold>) Ranking summary of cell type classification accuracy across data batches for each method.</p>
        </caption>
        <graphic xlink:href="gkad157fig4" position="float"/>
      </fig>
      <p>To test if the performance of Matilda is impacted by the reduced size of the training data, we performed a stratified sampling of each cell type from CITE-seq and TEA-seq datasets generated by Ramaswamy <italic toggle="yes">et al.</italic> (<xref rid="B13" ref-type="bibr">13</xref>) and Swanson <italic toggle="yes">et al.</italic> (<xref rid="B12" ref-type="bibr">12</xref>), respectively, 80%, 50% and 20% of cells and trained each classification model using these subsampled datasets. We found that the performance of Matilda is largely maintained even when the model was trained on a small proportion of cells from the original datasets (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S5</xref>). It is worth noting that the improved cell type classification accuracy of Matilda is not a sacrifice in speed on model training or classification of test data (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S6</xref>). Since Matilda uses multi-task learning and the simulated data from the VAE component for data augmentation, we also evaluated the impact of these procedures on cell type classification accuracy. We found that, across all five datasets, multi-task learning indeed improved cell type classification than learning each task independently (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S7a</xref>), and data augmentation resulted in better performance than those without (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S7b</xref>). Together, these results demonstrate the utility of multi-task learning and data augmentation from simulation for improving cell type classification and highlight Matilda's increased cell type classification accuracy using multimodalities compared to alternative methods that use only RNA modality.</p>
    </sec>
    <sec id="SEC3-4">
      <title>Feature selection from multiple data modalities</title>
      <p>Finally, the neural network trained for cell type classification in Matilda can be used for multimodal feature selection using methods such as integrated gradient (IG) descent (<xref rid="B22" ref-type="bibr">22</xref>) and saliency procedures (<xref rid="B23" ref-type="bibr">23</xref>), and thus can lead to the selection of cell-type-specific features across all available modalities in the datasets. Figure <xref rid="F5" ref-type="fig">5A</xref>, <xref rid="F5" ref-type="fig">B</xref> visualize top-ranked features selected by Matilda using IG for CD14 monocytes and Naïve B cells, respectively, in each data modality in the TEA-seq dataset. The RNA and ADT expression levels and the ATAC activity of selected genes across all cell types in the dataset are shown in Figure <xref rid="F5" ref-type="fig">5C</xref>, <xref rid="F5" ref-type="fig">D</xref>. As expected, these analyses reveal that features selected by Matilda for each data modality show expression specificity towards their respective cell types, demonstrating their potential usage for characterizing cell identity and their underlying molecular programs.</p>
      <fig position="float" id="F5">
        <label>Figure 5.</label>
        <caption>
          <p>(<bold>A, B</bold>) For TEA-seq data (GSE158013), UMAPs highlight representative markers selected from each of the three modalities for CD14 monocytes and Naïve B cells. (<bold>C, D</bold>) violin plots of levels of selected markers for CD14 monocytes and Naïve B cells in their respective modalities across all cell types. (<bold>E</bold>) Classification of each cell type in TEA-seq data (GSE158013) using features selected by different methods. Cell types are arranged from low to high based on the number of cells in each cell type. Feature selection methods are also ranked based on the performance of their selected features in classifying each cell type (upper panel). Error bar, SE.</p>
        </caption>
        <graphic xlink:href="gkad157fig5" position="float"/>
      </fig>
      <p>To evaluate the top features selected by Matilda across multiple data modalities and those selected from RNA modality using popular methods such as <italic toggle="yes">t</italic>-test and limma (<xref rid="B7" ref-type="bibr">7</xref>), and those specifically designed for scRNA-seq (e.g. MAST (<xref rid="B8" ref-type="bibr">8</xref>), ROC), and recently proposed deep learning feature selection methods, including PROPOSE (<xref rid="B35" ref-type="bibr">35</xref>) and scCapsNet (<xref rid="B41" ref-type="bibr">41</xref>), we compared their utility in classifying each cell type in each dataset. We found that cell-type-specific features selected by Matilda from multiple data modalities on average resulted in more accurate discrimination of their respective cell types as shown by the scatter plot and the overall rankings of methods in each dataset (Figure <xref rid="F5" ref-type="fig">5E</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S8</xref>). Within the two feature selection methods implemented in Matilda, IG appears to perform slightly better than saliency and is hence the recommended approach in Matilda for feature selection from multimodal single-cell omics data. Together, these results demonstrate Matilda as a useful approach for feature selection from multiple data modalities for cell type characterization and other downstream analyses.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="SEC4">
    <title>DISCUSSION</title>
    <p>The key motivation for using multi-task learning in Matilda is that many common tasks in single-cell multimodal omics data analysis are interrelated. Learning these tasks in parallel may therefore improve the performance of the model on each individual task. Furthermore, the rationale for using neural network models in Matilda is due to their modularity which fits well with the multiple data modalities and tasks. This allows the integration of data modalities and information sharing of tasks which together enable complementary information to be extracted and hence lead to more accurate characterizations of cellular programs. With the advance in single-cell multimodal omics technologies, we expect more data modalities to become available in the near future. The modularity and flexibility of Matilda allow integration when additional modality becomes available in such data.</p>
    <p>One common criticism of neural network-based learning models is that a large number of examples need to be provided during the training process. We demonstrated in our experiments that Matilda's performance in cell type classification is largely maintained even with a relatively small number of cells in the training datasets. This may be due to the data simulation and augmentation component implemented in Matilda which increases the number of cells in the training datasets, especially for the rare cell types. However, dealing with cell types with an extremely small number of cells is still a challenge and may require alternative approaches.</p>
    <p>While the current implementation of Matilda deals with datasets profiling discrete cell types, studies that look at transitional processes such as development and organogenesis create datasets with transient cell types. To analyse such datasets will require reformatting the loss function in the Matilda framework such as changing the classification component to a regression component. The potential mismatch of cell types in the training and query datasets may also have a significant impact on the performance of Matilda. A solution may be to utilize the prediction probability of the neural network for deciding whether a cell in a query dataset should be classified or not. These form the key directions for our future work.</p>
    <p>Various methods have been developed for label transfer across modalities using different single-cell omics data (e.g. scRNA-seq, scATA-seq) (<xref rid="B37" ref-type="bibr">37–39</xref>,<xref rid="B42" ref-type="bibr">42</xref>,<xref rid="B43" ref-type="bibr">43</xref>). Such label transfer methods are distinguished from methods such as Matilda and UMINT that integrate multiple data modalities in the same cells (referred to as ‘vertical integration’) (<xref rid="B44" ref-type="bibr">44</xref>) since the embeddings of cells generated from label transfer methods are from individual data modalities. While the embeddings generated from label transfer methods can provide useful alignment of data modalities, they could not be directly used for multimodality cell type classification as performed by Matilda and UMINT.</p>
    <p>In sum, Matilda is so far the first method for simultaneous simulation and supervised classification of cells using multiple modalities in single-cell multimodal omics data. It is also the first method for joint feature selection from multiple data modalities. Matilda addresses multiple key tasks in single-cell multimodal omics data analysis in a single unified framework.</p>
  </sec>
  <sec sec-type="data-availability" id="SEC5">
    <title>DATA AVAILABILITY</title>
    <p>All the datasets used in this study are publicly available. The ‘TEA-seq dataset’ was downloaded from NCBI GEO under the accession number GSE158013. The ‘CITE-seq dataset by Stephenson et al’ was downloaded from the EMBL-EBI Array Express database under the accession number E-MTAB-10026. The ‘CITE-seq dataset by Hao et al’ was downloaded from NCBI GEO under the accession number GSE164378. The ‘CITE-seq dataset by Ramaswamy et al’ was downloaded from NCBI GEO under the accession number GSE166489. The ‘SHARE-seq’ was downloaded from NCBI GEO under the accession number GSE140203. Matilda was implemented using PyTorch (version 1.9.1) with code available at <ext-link xlink:href="https://github.com/PYangLab/Matilda" ext-link-type="uri">https://github.com/PYangLab/Matilda</ext-link>.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>gkad157_Supplemental_File</label>
      <media xlink:href="gkad157_supplemental_file.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ACK1">
    <title>ACKNOWLEDGEMENTS</title>
    <p>We think the intellectual feedback from the Computational Systems Biology Group at Children's Medical Research Institute (CMRI) and engagement from the colleagues at the School of Mathematics and Statistics, The University of Sydney and Sydney Precision Bioinformatics Alliance.</p>
    <p><italic toggle="yes">Author contributions:</italic> Conceptualization, C.L., P.Y.; Methodology, C.L., P.Y.; Investigation, C.L., H.H., P.Y.; Data generation, C.L., H.H.; Writing – Original Draft, C.L., P.Y.; Writing – Review &amp; Editing, all authors; Supervision, P.Y.; Funding Acquisition, P.Y.</p>
  </ack>
  <sec id="SEC7">
    <title>SUPPLEMENTARY DATA</title>
    <p><ext-link xlink:href="https://academic.oup.com/nar/article-lookup/doi/10.1093/nar/gkad157#supplementary-data" ext-link-type="uri">Supplementary Data</ext-link> are available at NAR Online.</p>
  </sec>
  <sec id="SEC8">
    <title>FUNDING</title>
    <p>National Health and Medical Research Council (NHMRC) Investigator Grant [1173469 to P.Y.]. Funding for open access charge: Sydney Research Accelerator (SOAR) prize.</p>
    <p><italic toggle="yes">Conflict of interest statement</italic>. None declared.</p>
  </sec>
  <ref-list id="REF1">
    <title>REFERENCES</title>
    <ref id="B1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stuart</surname><given-names>T.</given-names></string-name>, <string-name><surname>Satija</surname><given-names>R.</given-names></string-name></person-group><article-title>Integrative single-cell analysis</article-title>. <source>Nat. Rev. Genet.</source><year>2019</year>; <volume>20</volume>:<fpage>257</fpage>–<lpage>272</lpage>.<pub-id pub-id-type="pmid">30696980</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhu</surname><given-names>C.</given-names></string-name>, <string-name><surname>Preissl</surname><given-names>S.</given-names></string-name>, <string-name><surname>Ren</surname><given-names>B.</given-names></string-name></person-group><article-title>Single-cell multimodal omics: the power of many</article-title>. <source>Nat. Methods</source>. <year>2020</year>; <volume>17</volume>:<fpage>11</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">31907462</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cao</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>P.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>J.Y.H.</given-names></string-name></person-group><article-title>A benchmark study of simulation methods for single-cell RNA sequencing data</article-title>. <source>Nat. Commun.</source><year>2021</year>; <volume>12</volume>:<fpage>6911</fpage>.<pub-id pub-id-type="pmid">34824223</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gayoso</surname><given-names>A.</given-names></string-name>, <string-name><surname>Steier</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Lopez</surname><given-names>R.</given-names></string-name>, <string-name><surname>Regier</surname><given-names>J.</given-names></string-name>, <string-name><surname>Nazor</surname><given-names>K.L.</given-names></string-name>, <string-name><surname>Streets</surname><given-names>A.</given-names></string-name>, <string-name><surname>Yosef</surname><given-names>N.</given-names></string-name></person-group><article-title>Joint probabilistic modeling of single-cell multi-omic data with totalVI</article-title>. <source>Nat. Methods</source>. <year>2021</year>; <volume>18</volume>:<fpage>272</fpage>–<lpage>282</lpage>.<pub-id pub-id-type="pmid">33589839</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Cao</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Kim</surname><given-names>H.J.</given-names></string-name>, <string-name><surname>Salim</surname><given-names>A.</given-names></string-name>, <string-name><surname>Speed</surname><given-names>T.P.</given-names></string-name>, <string-name><surname>Lin</surname><given-names>D.M.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>P.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>J.Y.H.</given-names></string-name></person-group><article-title>scClassify: sample size estimation and multiscale classification of cells using single and multiple reference</article-title>. <source>Mol. Syst. Biol.</source><year>2020</year>; <volume>16</volume>:<fpage>e9389</fpage>.<pub-id pub-id-type="pmid">32567229</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Kanter</surname><given-names>J.K.</given-names></string-name>, <string-name><surname>Lijnzaad</surname><given-names>P.</given-names></string-name>, <string-name><surname>Candelli</surname><given-names>T.</given-names></string-name>, <string-name><surname>Margaritis</surname><given-names>T.</given-names></string-name>, <string-name><surname>Holstege</surname><given-names>F.C.P.</given-names></string-name></person-group><article-title>CHETAH: a selective, hierarchical cell type identification method for single-cell RNA sequencing</article-title>. <source>Nucleic Acids Res.</source><year>2019</year>; <volume>47</volume>:<fpage>e95</fpage>.<pub-id pub-id-type="pmid">31226206</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ritchie</surname><given-names>M.E.</given-names></string-name>, <string-name><surname>Phipson</surname><given-names>B.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>D.</given-names></string-name>, <string-name><surname>Hu</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Law</surname><given-names>C.W.</given-names></string-name>, <string-name><surname>Shi</surname><given-names>W.</given-names></string-name>, <string-name><surname>Smyth</surname><given-names>G.K.</given-names></string-name></person-group><article-title>limma powers differential expression analyses for RNA-sequencing and microarray studies</article-title>. <source>Nucleic Acids Res.</source><year>2015</year>; <volume>43</volume>:<fpage>e47</fpage>.<pub-id pub-id-type="pmid">25605792</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Finak</surname><given-names>G.</given-names></string-name>, <string-name><surname>McDavid</surname><given-names>A.</given-names></string-name>, <string-name><surname>Yajima</surname><given-names>M.</given-names></string-name>, <string-name><surname>Deng</surname><given-names>J.</given-names></string-name>, <string-name><surname>Gersuk</surname><given-names>V.</given-names></string-name>, <string-name><surname>Shalek</surname><given-names>A.K.</given-names></string-name>, <string-name><surname>Slichter</surname><given-names>C.K.</given-names></string-name>, <string-name><surname>Miller</surname><given-names>H.W.</given-names></string-name>, <string-name><surname>McElrath</surname><given-names>M.J.</given-names></string-name>, <string-name><surname>Prlic</surname><given-names>M.</given-names></string-name><etal>et al</etal>.</person-group><article-title>MAST: a flexible statistical framework for assessing transcriptional changes and characterizing heterogeneity in single-cell RNA sequencing data</article-title>. <source>Genome Biol.</source><year>2015</year>; <volume>16</volume>:<fpage>278</fpage>.<pub-id pub-id-type="pmid">26653891</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ma</surname><given-names>A.</given-names></string-name>, <string-name><surname>McDermaid</surname><given-names>A.</given-names></string-name>, <string-name><surname>Xu</surname><given-names>J.</given-names></string-name>, <string-name><surname>Chang</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Q.</given-names></string-name></person-group><article-title>Integrative methods and practical challenges for single-cell multi-omics</article-title>. <source>Trends Biotechnol.</source><year>2020</year>; <volume>38</volume>:<fpage>1007</fpage>–<lpage>1022</lpage>.<pub-id pub-id-type="pmid">32818441</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Efremova</surname><given-names>M.</given-names></string-name>, <string-name><surname>Teichmann</surname><given-names>S.A.</given-names></string-name></person-group><article-title>Computational methods for single-cell omics across modalities</article-title>. <source>Nat. Methods</source>. <year>2020</year>; <volume>17</volume>:<fpage>14</fpage>–<lpage>17</lpage>.<pub-id pub-id-type="pmid">31907463</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <label>11.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>D.P.</given-names></string-name>, <string-name><surname>Welling</surname><given-names>M.</given-names></string-name></person-group><article-title>Auto-encoding variational bayes</article-title>. <year>2014</year>; <comment>arXiv doi:</comment><comment>10 December 2022, preprint: not peer reviewed</comment><uri xlink:href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</uri>.</mixed-citation>
    </ref>
    <ref id="B12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Swanson</surname><given-names>E.</given-names></string-name>, <string-name><surname>Lord</surname><given-names>C.</given-names></string-name>, <string-name><surname>Reading</surname><given-names>J.</given-names></string-name>, <string-name><surname>Heubeck</surname><given-names>A.T.</given-names></string-name>, <string-name><surname>Genge</surname><given-names>P.C.</given-names></string-name>, <string-name><surname>Thomson</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Weiss</surname><given-names>M.D.</given-names></string-name>, <string-name><surname>Li</surname><given-names>X.</given-names></string-name>, <string-name><surname>Savage</surname><given-names>A.K.</given-names></string-name>, <string-name><surname>Green</surname><given-names>R.R.</given-names></string-name><etal>et al</etal>.</person-group><article-title>Simultaneous trimodal single-cell measurement of transcripts, epitopes, and chromatin accessibility using TEA-seq</article-title>. <source>Elife</source>. <year>2021</year>; <volume>10</volume>:<fpage>e63632</fpage>.<pub-id pub-id-type="pmid">33835024</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ramaswamy</surname><given-names>A.</given-names></string-name>, <string-name><surname>Brodsky</surname><given-names>N.N.</given-names></string-name>, <string-name><surname>Sumida</surname><given-names>T.S.</given-names></string-name>, <string-name><surname>Comi</surname><given-names>M.</given-names></string-name>, <string-name><surname>Asashima</surname><given-names>H.</given-names></string-name>, <string-name><surname>Hoehn</surname><given-names>K.B.</given-names></string-name>, <string-name><surname>Li</surname><given-names>N.</given-names></string-name>, <string-name><surname>Liu</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Shah</surname><given-names>A.</given-names></string-name>, <string-name><surname>Ravindra</surname><given-names>N.G.</given-names></string-name><etal>et al</etal>.</person-group><article-title>Immune dysregulation and autoreactivity correlate with disease severity in SARS-CoV-2-associated multisystem inflammatory syndrome in children</article-title>. <source>Immunity</source>. <year>2021</year>; <volume>54</volume>:<fpage>1083</fpage>–<lpage>1095</lpage>.<pub-id pub-id-type="pmid">33891889</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hao</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Hao</surname><given-names>S.</given-names></string-name>, <string-name><surname>Andersen-Nissen</surname><given-names>E.</given-names></string-name>, <string-name><surname>Mauck</surname><given-names>W.M.</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>S.</given-names></string-name>, <string-name><surname>Butler</surname><given-names>A.</given-names></string-name>, <string-name><surname>Lee</surname><given-names>M.J.</given-names></string-name>, <string-name><surname>Wilk</surname><given-names>A.J.</given-names></string-name>, <string-name><surname>Darby</surname><given-names>C.</given-names></string-name>, <string-name><surname>Zager</surname><given-names>M.</given-names></string-name><etal>et al</etal>.</person-group><article-title>Integrated analysis of multimodal single-cell data</article-title>. <source>Cell</source>. <year>2021</year>; <volume>184</volume>:<fpage>3573</fpage>–<lpage>3587</lpage>.<pub-id pub-id-type="pmid">34062119</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stephenson</surname><given-names>E.</given-names></string-name>, <string-name><surname>Reynolds</surname><given-names>G.</given-names></string-name>, <string-name><surname>Botting</surname><given-names>R.A.</given-names></string-name>, <string-name><surname>Calero-Nieto</surname><given-names>F.J.</given-names></string-name>, <string-name><surname>Morgan</surname><given-names>M.D.</given-names></string-name>, <string-name><surname>Tuong</surname><given-names>Z.K.</given-names></string-name>, <string-name><surname>Bach</surname><given-names>K.</given-names></string-name>, <string-name><surname>Sungnak</surname><given-names>W.</given-names></string-name>, <string-name><surname>Worlock</surname><given-names>K.B.</given-names></string-name>, <string-name><surname>Yoshida</surname><given-names>M.</given-names></string-name><etal>et al</etal>.</person-group><article-title>Single-cell multi-omics analysis of the immune response in COVID-19</article-title>. <source>Nat. Med.</source><year>2021</year>; <volume>27</volume>:<fpage>904</fpage>–<lpage>916</lpage>.<pub-id pub-id-type="pmid">33879890</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ma</surname><given-names>S.</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>B.</given-names></string-name>, <string-name><surname>LaFave</surname><given-names>L.M.</given-names></string-name>, <string-name><surname>Earl</surname><given-names>A.S.</given-names></string-name>, <string-name><surname>Chiang</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Hu</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Ding</surname><given-names>J.</given-names></string-name>, <string-name><surname>Brack</surname><given-names>A.</given-names></string-name>, <string-name><surname>Kartha</surname><given-names>V.K.</given-names></string-name>, <string-name><surname>Tay</surname><given-names>T.</given-names></string-name><etal>et al</etal>.</person-group><article-title>Chromatin potential identified by shared single-cell profiling of RNA and Chromatin</article-title>. <source>Cell</source>. <year>2020</year>; <volume>183</volume>:<fpage>1103</fpage>–<lpage>1116</lpage>.<pub-id pub-id-type="pmid">33098772</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baruzzo</surname><given-names>G.</given-names></string-name>, <string-name><surname>Patuzzi</surname><given-names>I.</given-names></string-name>, <string-name><surname>Di Camillo</surname><given-names>B.</given-names></string-name></person-group><article-title>SPARSim single cell: a count data simulator for scRNA-seq data</article-title>. <source>Bioinforma. Oxf. Engl.</source><year>2020</year>; <volume>36</volume>:<fpage>1468</fpage>–<lpage>1475</lpage>.</mixed-citation>
    </ref>
    <ref id="B18">
      <label>18.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ioffe</surname><given-names>S.</given-names></string-name>, <string-name><surname>Szegedy</surname><given-names>C.</given-names></string-name></person-group><article-title>Batch normalization: accelerating deep network training by reducing internal covariate shift</article-title>. <year>2015</year>; <comment>arXiv doi:</comment><comment>02 March 2015, preprint: not peer reviewed</comment><uri xlink:href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</uri>.</mixed-citation>
    </ref>
    <ref id="B19">
      <label>19.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>K.</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>X.</given-names></string-name>, <string-name><surname>Ren</surname><given-names>S.</given-names></string-name>, <string-name><surname>Sun</surname><given-names>J.</given-names></string-name></person-group><article-title>Deep residual learning for image recognition</article-title>. <source>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</source>. <year>2016</year>; <publisher-loc>Las Vegas, NV, USA</publisher-loc><publisher-name>IEEE</publisher-name><fpage>770</fpage>–<lpage>778</lpage>.</mixed-citation>
    </ref>
    <ref id="B20">
      <label>20.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Müller</surname><given-names>R.</given-names></string-name>, <string-name><surname>Kornblith</surname><given-names>S.</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>G.</given-names></string-name></person-group><article-title>When does label smoothing help</article-title>. <year>2020</year>; <comment>arXiv doi:</comment><comment>10 June 2020, preprint: not peer reviewed</comment><uri xlink:href="https://arxiv.org/abs/1906.02629">https://arxiv.org/abs/1906.02629</uri>.</mixed-citation>
    </ref>
    <ref id="B21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>H.</given-names></string-name>, <string-name><surname>Garcia</surname><given-names>E.A</given-names></string-name></person-group><article-title>Learning from imbalanced data</article-title>. <source>IEEE Trans. Knowl. Data Eng.</source><year>2009</year>; <volume>21</volume>:<fpage>1263</fpage>–<lpage>1284</lpage>.</mixed-citation>
    </ref>
    <ref id="B22">
      <label>22.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Sundararajan</surname><given-names>M.</given-names></string-name>, <string-name><surname>Taly</surname><given-names>A.</given-names></string-name>, <string-name><surname>Yan</surname><given-names>Q.</given-names></string-name></person-group><article-title>Axiomatic attribution for deep networks</article-title>. <year>2017</year>; <comment>arXiv doi:</comment><comment>13 June 2017, preprint: not peer reviewed</comment><uri xlink:href="https://arxiv.org/abs/1703.01365">https://arxiv.org/abs/1703.01365</uri>.</mixed-citation>
    </ref>
    <ref id="B23">
      <label>23.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Simonyan</surname><given-names>K.</given-names></string-name>, <string-name><surname>Vedaldi</surname><given-names>A.</given-names></string-name>, <string-name><surname>Zisserman</surname><given-names>A.</given-names></string-name></person-group><article-title>Deep inside convolutional networks: visualising image classification models and saliency maps</article-title>. <year>2014</year>; <comment>arXiv doi:</comment><comment>19 April 2014, preprint: not peer reviewed</comment><uri xlink:href="https://arxiv.org/abs/1312.6034">https://arxiv.org/abs/1312.6034</uri>.</mixed-citation>
    </ref>
    <ref id="B24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Luo</surname><given-names>W.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>B.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>X.</given-names></string-name>, <string-name><surname>Liu</surname><given-names>W.</given-names></string-name>, <string-name><surname>Cheng</surname><given-names>K.-T.</given-names></string-name></person-group><article-title>Bi-real net: binarizing deep network towards real-network performance</article-title>. <source>Int. J. Comput. Vis.</source><year>2020</year>; <volume>128</volume>:<fpage>202</fpage>–<lpage>219</lpage>.</mixed-citation>
    </ref>
    <ref id="B25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kiselev</surname><given-names>V.Y.</given-names></string-name>, <string-name><surname>Yiu</surname><given-names>A.</given-names></string-name>, <string-name><surname>Hemberg</surname><given-names>M.</given-names></string-name></person-group><article-title>scmap: projection of single-cell RNA-seq data across data sets</article-title>. <source>Nat. Methods</source>. <year>2018</year>; <volume>15</volume>:<fpage>359</fpage>–<lpage>362</lpage>.<pub-id pub-id-type="pmid">29608555</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tan</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Cahan</surname><given-names>P.</given-names></string-name></person-group><article-title>SingleCellNet: a computational tool to classify single cell RNA-seq data across platforms and across species</article-title>. <source>Cell Syst.</source><year>2019</year>; <volume>9</volume>:<fpage>207</fpage>–<lpage>213</lpage>.<pub-id pub-id-type="pmid">31377170</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cortal</surname><given-names>A.</given-names></string-name>, <string-name><surname>Martignetti</surname><given-names>L.</given-names></string-name>, <string-name><surname>Six</surname><given-names>E.</given-names></string-name>, <string-name><surname>Rausell</surname><given-names>A.</given-names></string-name></person-group><article-title>Gene signature extraction and cell identity recognition at the single-cell level with cell-ID</article-title>. <source>Nat. Biotechnol.</source><year>2021</year>; <volume>39</volume>:<fpage>1095</fpage>–<lpage>1102</lpage>.<pub-id pub-id-type="pmid">33927417</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Boufea</surname><given-names>K.</given-names></string-name>, <string-name><surname>Seth</surname><given-names>S.</given-names></string-name>, <string-name><surname>Batada</surname><given-names>N.N.</given-names></string-name></person-group><article-title>scID uses discriminant analysis to identify transcriptionally equivalent cell types across single-cell RNA-seq data with batch effect</article-title>. <source>Iscience</source>. <year>2020</year>; <volume>23</volume>:<fpage>100914</fpage>.<pub-id pub-id-type="pmid">32151972</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <label>29.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Maitra</surname><given-names>C.</given-names></string-name>, <string-name><surname>Seal</surname><given-names>D.B.</given-names></string-name>, <string-name><surname>Das</surname><given-names>V.</given-names></string-name>, <string-name><surname>De</surname><given-names>R.K.</given-names></string-name></person-group><article-title>UMINT: unsupervised neural network for single cell multi-omics integration</article-title>. <year>2022</year>; <comment>bioRxiv doi:</comment><comment>22 April 2022, preprint: not peer reviewed</comment><pub-id pub-id-type="doi">10.1101/2022.04.21.489041</pub-id>.</mixed-citation>
    </ref>
    <ref id="B30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marouf</surname><given-names>M.</given-names></string-name>, <string-name><surname>Machart</surname><given-names>P.</given-names></string-name>, <string-name><surname>Bansal</surname><given-names>V.</given-names></string-name>, <string-name><surname>Kilian</surname><given-names>C.</given-names></string-name>, <string-name><surname>Magruder</surname><given-names>D.S.</given-names></string-name>, <string-name><surname>Krebs</surname><given-names>C.F.</given-names></string-name>, <string-name><surname>Bonn</surname><given-names>S.</given-names></string-name></person-group><article-title>Realistic in silico generation and augmentation of single-cell RNA-seq data using generative adversarial networks</article-title>. <source>Nat. Commun.</source><year>2020</year>; <volume>11</volume>:<fpage>166</fpage>.<pub-id pub-id-type="pmid">31919373</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heydari</surname><given-names>A.A.</given-names></string-name>, <string-name><surname>Davalos</surname><given-names>O.A.</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>L.</given-names></string-name>, <string-name><surname>Hoyer</surname><given-names>K.K.</given-names></string-name>, <string-name><surname>Sindi</surname><given-names>S.S.</given-names></string-name></person-group><article-title><italic toggle="yes">ACTIVA</italic>: realistic single-cell RNA-seq generation with automatic cell-type identification using introspective variational autoencoders</article-title>. <source>Bioinformatics</source>. <year>2022</year>; <volume>38</volume>:<fpage>2194</fpage>–<lpage>2201</lpage>.<pub-id pub-id-type="pmid">35179571</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barkas</surname><given-names>N.</given-names></string-name>, <string-name><surname>Petukhov</surname><given-names>V.</given-names></string-name>, <string-name><surname>Nikolaeva</surname><given-names>D.</given-names></string-name>, <string-name><surname>Lozinsky</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Demharter</surname><given-names>S.</given-names></string-name>, <string-name><surname>Khodosevich</surname><given-names>K.</given-names></string-name>, <string-name><surname>Kharchenko</surname><given-names>P.V.</given-names></string-name></person-group><article-title>Joint analysis of heterogeneous single-cell RNA-seq dataset collections</article-title>. <source>Nat. Methods</source>. <year>2019</year>; <volume>16</volume>:<fpage>695</fpage>–<lpage>698</lpage>.<pub-id pub-id-type="pmid">31308548</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <label>33.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ashuach</surname><given-names>T.</given-names></string-name>, <string-name><surname>Gabitto</surname><given-names>M.I.</given-names></string-name>, <string-name><surname>Jordan</surname><given-names>M.I.</given-names></string-name>, <string-name><surname>Yosef</surname><given-names>N.</given-names></string-name></person-group><article-title>MultiVI: deep generative model for the integration of multi-modal data</article-title>. <year>2021</year>; <comment>bioRxiv doi:</comment><comment>20 August 2021, preprint: not peer reviewed</comment><pub-id pub-id-type="doi">10.1101/2021.08.20.457057</pub-id>.</mixed-citation>
    </ref>
    <ref id="B34">
      <label>34.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lotfollahi</surname><given-names>M.</given-names></string-name>, <string-name><surname>Litinetskaya</surname><given-names>A.</given-names></string-name>, <string-name><surname>Theis</surname><given-names>F.J.</given-names></string-name></person-group><article-title>Multigrate: single-cell multi-omic data integration</article-title>. <year>2022</year>; <comment>bioRxiv doi:</comment><comment>17 March 2022, preprint: not peer reviewed</comment><pub-id pub-id-type="doi">10.1101/2022.03.16.484643</pub-id>.</mixed-citation>
    </ref>
    <ref id="B35">
      <label>35.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Covert</surname><given-names>I.</given-names></string-name>, <string-name><surname>Gala</surname><given-names>R.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>T.</given-names></string-name>, <string-name><surname>Svoboda</surname><given-names>K.</given-names></string-name>, <string-name><surname>Sümbül</surname><given-names>U.</given-names></string-name>, <string-name><surname>Lee</surname><given-names>S.-I.</given-names></string-name></person-group><article-title>Predictive and robust gene selection for spatial transcriptomics</article-title>. <year>2022</year>; <comment>bioRxiv doi:</comment><comment>26 December 2022, preprint: not peer reviewed</comment><pub-id pub-id-type="doi">10.1101/2022.05.13.491738</pub-id>.</mixed-citation>
    </ref>
    <ref id="B36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lun</surname><given-names>A.T.L.</given-names></string-name>, <string-name><surname>McCarthy</surname><given-names>D.J.</given-names></string-name>, <string-name><surname>Marioni</surname><given-names>J.C.</given-names></string-name></person-group><article-title>A step-by-step workflow for low-level analysis of single-cell RNA-seq data with Bioconductor</article-title>. <source>F1000Research</source>. <year>2016</year>; <volume>5</volume>:<fpage>2122</fpage>.<pub-id pub-id-type="pmid">27909575</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stuart</surname><given-names>T.</given-names></string-name>, <string-name><surname>Butler</surname><given-names>A.</given-names></string-name>, <string-name><surname>Hoffman</surname><given-names>P.</given-names></string-name>, <string-name><surname>Hafemeister</surname><given-names>C.</given-names></string-name>, <string-name><surname>Papalexi</surname><given-names>E.</given-names></string-name>, <string-name><surname>Mauck</surname><given-names>W.M.</given-names></string-name>, <string-name><surname>Hao</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Stoeckius</surname><given-names>M.</given-names></string-name>, <string-name><surname>Smibert</surname><given-names>P.</given-names></string-name>, <string-name><surname>Satija</surname><given-names>R.</given-names></string-name></person-group><article-title>Comprehensive integration of single-cell data</article-title>. <source>Cell</source>. <year>2019</year>; <volume>177</volume>:<fpage>1888</fpage>–<lpage>1902</lpage>.<pub-id pub-id-type="pmid">31178118</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>T.-Y.</given-names></string-name>, <string-name><surname>Wan</surname><given-names>S.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>J.Y.H.</given-names></string-name>, <string-name><surname>Wong</surname><given-names>W.H.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y.X.R.</given-names></string-name></person-group><article-title>scJoint integrates atlas-scale single-cell RNA-seq and ATAC-seq data with transfer learning</article-title>. <source>Nat. Biotechnol.</source><year>2022</year>; <volume>40</volume>:<fpage>703</fpage>–<lpage>710</lpage>.<pub-id pub-id-type="pmid">35058621</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cao</surname><given-names>Z.-J.</given-names></string-name>, <string-name><surname>Gao</surname><given-names>G.</given-names></string-name></person-group><article-title>Multi-omics single-cell data integration and regulatory inference with graph-linked embedding</article-title>. <source>Nat. Biotechnol.</source><year>2022</year>; <volume>40</volume>:<fpage>1458</fpage>–<lpage>1466</lpage>.<pub-id pub-id-type="pmid">35501393</pub-id></mixed-citation>
    </ref>
    <ref id="B40">
      <label>40.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abdelaal</surname><given-names>T.</given-names></string-name>, <string-name><surname>Michielsen</surname><given-names>L.</given-names></string-name>, <string-name><surname>Cats</surname><given-names>D.</given-names></string-name>, <string-name><surname>Hoogduin</surname><given-names>D.</given-names></string-name>, <string-name><surname>Mei</surname><given-names>H.</given-names></string-name>, <string-name><surname>Reinders</surname><given-names>M.J.T.</given-names></string-name>, <string-name><surname>Mahfouz</surname><given-names>A.</given-names></string-name></person-group><article-title>A comparison of automatic cell identification methods for single-cell RNA sequencing data</article-title>. <source>Genome Biol.</source><year>2019</year>; <volume>20</volume>:<fpage>194</fpage>.<pub-id pub-id-type="pmid">31500660</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <label>41.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>L.</given-names></string-name>, <string-name><surname>Nie</surname><given-names>R.</given-names></string-name>, <string-name><surname>Yu</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Xin</surname><given-names>R.</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>C.</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J.</given-names></string-name>, <string-name><surname>Cai</surname><given-names>J.</given-names></string-name></person-group><article-title>An interpretable deep-learning architecture of capsule networks for identifying cell-type gene expression programs from single-cell RNA-sequencing data</article-title>. <source>Nat. Mach. Intell.</source><year>2020</year>; <volume>2</volume>:<fpage>693</fpage>–<lpage>703</lpage>.</mixed-citation>
    </ref>
    <ref id="B42">
      <label>42.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Peng</surname><given-names>T.</given-names></string-name>, <string-name><surname>Chen</surname><given-names>G.M.</given-names></string-name>, <string-name><surname>Tan</surname><given-names>K.</given-names></string-name></person-group><article-title>GLUER: integrative analysis of single-cell omics and imaging data by deep neural network</article-title>. <year>2021</year>; <comment>bioRxiv doi:</comment><comment>26 January 2021, preprint: not peer reviewed</comment><pub-id pub-id-type="doi">10.1101/2021.01.25.427845</pub-id>.</mixed-citation>
    </ref>
    <ref id="B43">
      <label>43.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Demetci</surname><given-names>P.</given-names></string-name>, <string-name><surname>Santorella</surname><given-names>R.</given-names></string-name>, <string-name><surname>Sandstede</surname><given-names>B.</given-names></string-name>, <string-name><surname>Singh</surname><given-names>R.</given-names></string-name></person-group><article-title>Unsupervised integration of single-cell multi-omics datasets with disparities in cell-type representation</article-title>. <year>2021</year>; <comment>bioRxiv doi:</comment><comment>11 November 2021, preprint: not peer reviewed</comment><pub-id pub-id-type="doi">10.1101/2021.11.09.467903</pub-id>.</mixed-citation>
    </ref>
    <ref id="B44">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Argelaguet</surname><given-names>R.</given-names></string-name>, <string-name><surname>Cuomo</surname><given-names>A.S.E.</given-names></string-name>, <string-name><surname>Stegle</surname><given-names>O.</given-names></string-name>, <string-name><surname>Marioni</surname><given-names>J.C.</given-names></string-name></person-group><article-title>Computational principles and challenges in single-cell data integration</article-title>. <source>Nat. Biotechnol.</source><year>2021</year>; <volume>39</volume>:<fpage>1202</fpage>–<lpage>1215</lpage>.<pub-id pub-id-type="pmid">33941931</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
