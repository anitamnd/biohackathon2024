<?properties open_access?>
<?subarticle pcbi.1007549.r001?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput. Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-id journal-id-type="pmc">ploscomp</journal-id>
    <journal-title-group>
      <journal-title>PLoS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6961866</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1007549</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-19-01130</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Brain Mapping</subject>
            <subj-group>
              <subject>Functional Magnetic Resonance Imaging</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Diagnostic Medicine</subject>
          <subj-group>
            <subject>Diagnostic Radiology</subject>
            <subj-group>
              <subject>Magnetic Resonance Imaging</subject>
              <subj-group>
                <subject>Functional Magnetic Resonance Imaging</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Imaging Techniques</subject>
          <subj-group>
            <subject>Diagnostic Radiology</subject>
            <subj-group>
              <subject>Magnetic Resonance Imaging</subject>
              <subj-group>
                <subject>Functional Magnetic Resonance Imaging</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Radiology and Imaging</subject>
          <subj-group>
            <subject>Diagnostic Radiology</subject>
            <subj-group>
              <subject>Magnetic Resonance Imaging</subject>
              <subj-group>
                <subject>Functional Magnetic Resonance Imaging</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Imaging Techniques</subject>
          <subj-group>
            <subject>Neuroimaging</subject>
            <subj-group>
              <subject>Functional Magnetic Resonance Imaging</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Neuroimaging</subject>
            <subj-group>
              <subject>Functional Magnetic Resonance Imaging</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Cognitive Science</subject>
            <subj-group>
              <subject>Cognitive Psychology</subject>
              <subj-group>
                <subject>Learning</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Psychology</subject>
          <subj-group>
            <subject>Cognitive Psychology</subject>
            <subj-group>
              <subject>Learning</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Social Sciences</subject>
        <subj-group>
          <subject>Psychology</subject>
          <subj-group>
            <subject>Cognitive Psychology</subject>
            <subj-group>
              <subject>Learning</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Learning and Memory</subject>
            <subj-group>
              <subject>Learning</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
              <subj-group>
                <subject>Machine Learning Algorithms</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Cognitive Science</subject>
            <subj-group>
              <subject>Cognitive Psychology</subject>
              <subj-group>
                <subject>Learning</subject>
                <subj-group>
                  <subject>Human Learning</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Psychology</subject>
          <subj-group>
            <subject>Cognitive Psychology</subject>
            <subj-group>
              <subject>Learning</subject>
              <subj-group>
                <subject>Human Learning</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Social Sciences</subject>
        <subj-group>
          <subject>Psychology</subject>
          <subj-group>
            <subject>Cognitive Psychology</subject>
            <subj-group>
              <subject>Learning</subject>
              <subj-group>
                <subject>Human Learning</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Learning and Memory</subject>
            <subj-group>
              <subject>Learning</subject>
              <subj-group>
                <subject>Human Learning</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Programming Languages</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Cognitive Science</subject>
            <subj-group>
              <subject>Cognition</subject>
              <subj-group>
                <subject>Memory</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Learning and Memory</subject>
            <subj-group>
              <subject>Memory</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Cognitive Science</subject>
            <subj-group>
              <subject>Cognitive Neuroscience</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Cognitive Neuroscience</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>BrainIAK tutorials: User-friendly learning materials for advanced fMRI analysis</article-title>
      <alt-title alt-title-type="running-head">Tutorials for advanced fMRI analysis</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4911-2885</contrib-id>
        <name>
          <surname>Kumar</surname>
          <given-names>Manoj</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Writing – original draft</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ellis</surname>
          <given-names>Cameron T.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0730-5240</contrib-id>
        <name>
          <surname>Lu</surname>
          <given-names>Qihong</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5222-5277</contrib-id>
        <name>
          <surname>Zhang</surname>
          <given-names>Hejia</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff003">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7323-2393</contrib-id>
        <name>
          <surname>Capotă</surname>
          <given-names>Mihai</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff004">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Willke</surname>
          <given-names>Theodore L.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <xref ref-type="aff" rid="aff004">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ramadge</surname>
          <given-names>Peter J.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff003">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Turk-Browne</surname>
          <given-names>Nicholas B.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Norman</surname>
          <given-names>Kenneth A.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff005">
          <sup>5</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Princeton Neuroscience Institute, Princeton University, Princeton, New Jersey, United States of America</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Department of Psychology, Yale University, New Haven, Connecticut, United States of America</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Center for Statistics and Machine Learning, Princeton University, Princeton, New Jersey, United States of America</addr-line>
    </aff>
    <aff id="aff004">
      <label>4</label>
      <addr-line>Brain-Inspired Computing Lab, Intel Corporation, Hillsboro, Oregon, United States of America</addr-line>
    </aff>
    <aff id="aff005">
      <label>5</label>
      <addr-line>Department of Psychology, Princeton University, Princeton, New Jersey, United States of America</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Marinazzo</surname>
          <given-names>Daniele</given-names>
        </name>
        <role>Editor</role>
        <xref ref-type="aff" rid="edit1"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Ghent University, BELGIUM</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>mk35@princeton.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>15</day>
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <volume>16</volume>
    <issue>1</issue>
    <elocation-id>e1007549</elocation-id>
    <history>
      <date date-type="received">
        <day>6</day>
        <month>7</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>17</day>
        <month>11</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2020 Kumar et al</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Kumar et al</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1007549.pdf"/>
    <abstract>
      <p>Advanced brain imaging analysis methods, including multivariate pattern analysis (MVPA), functional connectivity, and functional alignment, have become powerful tools in cognitive neuroscience over the past decade. These tools are implemented in custom code and separate packages, often requiring different software and language proficiencies. Although usable by expert researchers, novice users face a steep learning curve. These difficulties stem from the use of new programming languages (e.g., Python), learning how to apply machine-learning methods to high-dimensional fMRI data, and minimal documentation and training materials. Furthermore, most standard fMRI analysis packages (e.g., AFNI, FSL, SPM) focus on preprocessing and univariate analyses, leaving a gap in how to integrate with advanced tools. To address these needs, we developed BrainIAK (brainiak.org), an open-source Python software package that seamlessly integrates several cutting-edge, computationally efficient techniques with other Python packages (e.g., <ext-link ext-link-type="uri" xlink:href="https://nilearn.github.io/user_guide.html">Nilearn</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://scikit-learn.org/stable/">Scikit-learn</ext-link>) for file handling, visualization, and machine learning. To disseminate these powerful tools, we developed user-friendly tutorials (in Jupyter format; <ext-link ext-link-type="uri" xlink:href="https://brainiak.org/tutorials/">https://brainiak.org/tutorials/</ext-link>) for learning BrainIAK and advanced fMRI analysis in Python more generally. These materials cover techniques including: MVPA (pattern classification and representational similarity analysis); parallelized searchlight analysis; background connectivity; full correlation matrix analysis; inter-subject correlation; inter-subject functional connectivity; shared response modeling; event segmentation using hidden Markov models; and real-time fMRI. For long-running jobs or large memory needs we provide detailed guidance on high-performance computing clusters. These notebooks were successfully tested at multiple sites, including as problem sets for courses at Yale and Princeton universities and at various workshops and hackathons. These materials are freely shared, with the hope that they become part of a pool of open-source software and educational materials for large-scale, reproducible fMRI analysis and accelerated discovery.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>The analysis of brain activity, as measured using functional magnetic resonance imaging (fMRI), has led to significant discoveries about how the brain processes information and how this is affected by disease. However, exhaustive multivariate analyses in space and time, run across a large number of subjects, can be complex and computationally intensive, creating a high barrier for entry into this field. Furthermore, the materials available to learn these methods do not encompass all the methods used, work is often published with no publicly available code, and the analyses are often difficult to run on large datasets without cluster computing. We have created interactive software tutorials that make it easy to understand and execute advanced analyses on fMRI data using the BrainIAK package—an open-source package built in Python. We have released these tutorials freely to the public and have significantly reduced computational roadblocks for users by making it possible to run the tutorials with a web browser and internet connection. We hope that this facilitated access and the usability of the underlying code—a compendium for how to program and optimize the latest fMRI analyses—will accelerate training, reproducibility, and discovery in cognitive neuroscience.</p>
    </abstract>
    <funding-group>
      <funding-statement>Funding for this project was provided by Intel Labs (<ext-link ext-link-type="uri" xlink:href="https://www.intel.com/intellabs">https://www.intel.com/intellabs</ext-link>) to P.J.R., N.B.T.-B, and K.A.N. The funders had no role in study design, data collection and analysis, or decision to publish. M.C. and T.L.W. were involved in the development of the BrainIAK package and in preparation of the manuscript as noted in the author contributions.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="0"/>
      <table-count count="1"/>
      <page-count count="12"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>The data are publicly available and hosted on Zotero: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2598755">https://doi.org/10.5281/zenodo.2598755</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>The data are publicly available and hosted on Zotero: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2598755">https://doi.org/10.5281/zenodo.2598755</ext-link>.</p>
  </notes>
</front>
<body>
  <disp-quote>
    <p>This is a <italic>PLOS Computational Biology</italic> Software paper.</p>
  </disp-quote>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>The latest methods for analyzing brain activity recorded via functional magnetic resonance imaging (fMRI) are complex to learn and execute. This is particularly true for multivariate pattern analysis (MVPA) methods, which focus on extracting information about a person’s cognitive state (i.e., percepts, thoughts, memories) from spatially and/or temporally distributed patterns of fMRI activity. Beginners and even intermediate users face a steep learning curve and uncertainty in using these complex techniques. Even expert users are hesitant to add new, more advanced techniques to their existing pipelines, and face significant software and hardware challenges in doing so. These difficulties continue, even though MVPA has been used successfully for almost two decades to answer fundamental questions in cognitive neuroscience.</p>
    <p>MVPA encompasses a wide range of analyses: from pattern classifiers that map between distributed brain patterns and cognitive states [<xref rid="pcbi.1007549.ref001" ref-type="bibr">1</xref>–<xref rid="pcbi.1007549.ref004" ref-type="bibr">4</xref>], to techniques that explore the similarity structure exploited by classifiers (e.g., representational similarity analysis, RSA; [<xref rid="pcbi.1007549.ref005" ref-type="bibr">5</xref>,<xref rid="pcbi.1007549.ref006" ref-type="bibr">6</xref>]). There are also related multivariate techniques for functional connectivity and functional alignment, including: full correlation matrix analysis (FCMA; [<xref rid="pcbi.1007549.ref007" ref-type="bibr">7</xref>]), inter-subject correlation (ISC; [<xref rid="pcbi.1007549.ref008" ref-type="bibr">8</xref>,<xref rid="pcbi.1007549.ref009" ref-type="bibr">9</xref>]), inter-subject functional connectivity (ISFC; [<xref rid="pcbi.1007549.ref010" ref-type="bibr">10</xref>]), shared response modeling (SRM; [<xref rid="pcbi.1007549.ref011" ref-type="bibr">11</xref>]), and event segmentation [<xref rid="pcbi.1007549.ref012" ref-type="bibr">12</xref>]. These analyses can be run after data collection is complete or in real-time for neurofeedback training or adaptive design optimization [<xref rid="pcbi.1007549.ref013" ref-type="bibr">13</xref>–<xref rid="pcbi.1007549.ref016" ref-type="bibr">16</xref>].</p>
    <p>There exist multiple open-source packages that implement MVPA and RSA techniques. Some of these packages require commercial software such as MATLAB with paid licenses and proprietary code (e.g., Princeton MVPA Toolbox, The Decoding Toolbox [<xref rid="pcbi.1007549.ref017" ref-type="bibr">17</xref>], and CoSMoMVPA [<xref rid="pcbi.1007549.ref018" ref-type="bibr">18</xref>]), while others are completely open-source (e.g., Nilearn [<xref rid="pcbi.1007549.ref019" ref-type="bibr">19</xref>] and PyMVPA [<xref rid="pcbi.1007549.ref020" ref-type="bibr">20</xref>,<xref rid="pcbi.1007549.ref021" ref-type="bibr">21</xref>]). Although all of these packages cover a broad range of MVPA and RSA techniques, they do not cover techniques such as FCMA, ISC, ISFC, SRM, and event segmentation. One barrier to increasing the accessibility of these techniques is that, in most cases, they were created as custom code within individual labs and are thus not part of other fMRI software analysis packages. To address this, we implemented and released them in an open-source Python package called <ext-link ext-link-type="uri" xlink:href="https://brainiak.org/">BrainIAK</ext-link>. The tutorials that are the focus of this article provide extensive background, code, and exercises, which serve as structured guidance for learning how to use these and other advanced fMRI analysis techniques. The tutorials also show how to use methods in other packages such as Nilearn and integrate them with the methods in BrainIAK.</p>
    <p>In a typical fMRI analysis pipeline, the data are first pre-processed, a general linear model (GLM) might be fit, and then MVPA or other more advanced analyses are performed. For pre-processing and GLM analysis of fMRI data, a number of tutorials and bootcamps are available to learn software packages such as AFNI, FSL, SPM, and fmriprep [<xref rid="pcbi.1007549.ref022" ref-type="bibr">22</xref>–<xref rid="pcbi.1007549.ref025" ref-type="bibr">25</xref>]; a recent publicly released course at <ext-link ext-link-type="uri" xlink:href="http://dartbrains.org/">http://dartbrains.org</ext-link> also nicely covers these topics. In contrast, for MVPA and more advanced analyses, fewer educational materials are available. We designed the present tutorials to make it easier for the novice user to learn these techniques. An expert user can use our materials to understand BrainIAK’s implementation of these techniques, to train other researchers, and to teach research methods classes.</p>
    <p>There are three main steps to learning and implementing BrainIAK methods: (1) learning to write code and scripts, (2) understanding machine learning algorithms and how to apply them to cognitive neuroscience data, and (3) executing jobs on high-performance compute clusters. We elaborate on each of these steps below.</p>
    <p>First, one needs to learn a programming language; for example, BrainIAK uses Python. This can present a significant challenge to a beginner as learning to program and how to apply these skills to scientific computing is a time-consuming process. Such skills have only recently been added to the curriculum in some psychology and neuroscience departments, and been included as components of hackathons and summer schools. As instructors tend to teach in the language they are most familiar with, different programming languages are often used to teach various techniques, making it difficult for users to switch flexibly between methods.</p>
    <p>Second, the analysis techniques in BrainIAK involve extensive use of machine learning algorithms that may be unfamiliar to cognitive neuroscientists. There are multiple tutorials on machine learning available (see examples on Scikit-learn <ext-link ext-link-type="uri" xlink:href="https://scikit-learn.org/stable/auto_examples/index.html">https://scikit-learn.org/stable/auto_examples/index.html</ext-link>); however, only a few cover the use of machine learning in cognitive neuroscience: for example, the documentation for <ext-link ext-link-type="uri" xlink:href="https://nilearn.github.io/user_guide.html">Nilearn</ext-link> [<xref rid="pcbi.1007549.ref019" ref-type="bibr">19</xref>], lectures from the <ext-link ext-link-type="uri" xlink:href="http://mindsummerschool.org/index.html">MIND</ext-link> summer school, lectures from the Organization for Human Brain Mapping <ext-link ext-link-type="uri" xlink:href="https://www.pathlms.com/ohbm/courses/8246/sections/12542">education section</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/ohbm">hackathons</ext-link>, and blogs such as <ext-link ext-link-type="uri" xlink:href="http://mvpa.blogspot.com/">MVPA Meanderings</ext-link>. For many of the cutting-edge techniques in BrainIAK, no tutorials exist (one notable exception is the volumetric searchlight technique; tutorials for this method are included in the PyMVPA [<xref rid="pcbi.1007549.ref020" ref-type="bibr">20</xref>,<xref rid="pcbi.1007549.ref021" ref-type="bibr">21</xref>] and Nilearn [<xref rid="pcbi.1007549.ref019" ref-type="bibr">19</xref>] packages) or they are taught only as a part of special workshops. Furthermore, the application of general-purpose machine learning algorithms in cognitive neuroscience needs to be done with care, as not all data are independent of each other in space or time; this has led to the insidious problem of circular inference or “double dipping” [<xref rid="pcbi.1007549.ref026" ref-type="bibr">26</xref>].</p>
    <p>Third, the execution of these programs on high-performance compute clusters is non-trivial even for advanced practitioners who are proficient at executing code on individual machines. Using clusters can accelerate analyses dramatically through parallelization, but sizing the memory needed and enabling parallel code execution for optimal run-times requires an understanding of how jobs are scheduled and processed in a cluster environment. It is a challenge to find training materials on how to run fMRI analyses on a compute cluster, although, resources are becoming increasingly available, for example, lectures on Neurohackademy (<ext-link ext-link-type="uri" xlink:href="https://neurohackademy.org/course_type/lectures/">https://neurohackademy.org/course_type/lectures/</ext-link>); and forums such as NeuroStars (<ext-link ext-link-type="uri" xlink:href="https://neurostars.org/">https://neurostars.org</ext-link>) for using fmriprep on clusters [<xref rid="pcbi.1007549.ref025" ref-type="bibr">25</xref>].</p>
    <p>We have created learning materials (herein referred to as tutorials) that address each of the above challenges, making it easier for novice users to learn MVPA and for expert users to learn more advanced BrainIAK analysis techniques, such as FCMA and SRM. To aid learning to code, the tutorials provide an interactive environment to read, write, and execute Python. Specifically, for novice users, a simple way to learn programming is to study small snippets of code with a clear description of what is being accomplished by the code. Our use of <ext-link ext-link-type="uri" xlink:href="https://jupyter-notebook.readthedocs.io/en/stable/notebook.html">Jupyter</ext-link> notebooks [<xref rid="pcbi.1007549.ref027" ref-type="bibr">27</xref>] allows for detailed explanations of the code with text and figures embedded in-line. The user can execute the code step-by-step and interact with data at each step using plotting functions. In order to ease users into the use of advanced analysis techniques, we first introduce them to a fully-working but simplified version of the code. After mastering this version, we encourage users to delve deeper and learn more about helper functions and input/output variables. Expert users, who may wish to examine the details of how the data are being processed, or modify the code to suit their needs, can readily do so using the open-source Python code contained in the Jupyter notebooks. For all users, we embed background material and references, prompts for further self-study, and problem set exercises to help them learn how to generate and adapt code. The exercises for each notebook focus on neuroscientific applications of the techniques being learned; thus, by working through the exercises, students learn how to use these techniques to answer meaningful neuroscientific questions (course instructors may contact us for more information).</p>
    <p>To help users learn how to apply machine learning algorithms to cognitive neuroscience data, we build on several open-source machine learning tools in Python. For data loading we use <ext-link ext-link-type="uri" xlink:href="https://nipy.org/nibabel/">Nibabel</ext-link> [<xref rid="pcbi.1007549.ref028" ref-type="bibr">28</xref>]; for data masking, normalization, dimensionality reduction, plotting, atlases, and functional connectivity we use <ext-link ext-link-type="uri" xlink:href="https://nilearn.github.io/user_guide.html">Nilearn</ext-link> [<xref rid="pcbi.1007549.ref019" ref-type="bibr">19</xref>]; and for machine learning libraries we use <ext-link ext-link-type="uri" xlink:href="https://scikit-learn.org/stable/">Scikit-learn</ext-link> [<xref rid="pcbi.1007549.ref029" ref-type="bibr">29</xref>]. We include detailed instructions and exercises on how to avoid problems of circular inference and double-dipping. We also use tools native to BrainIAK for applying cutting-edge machine learning to fMRI data, including parallelized searchlight analysis [<xref rid="pcbi.1007549.ref030" ref-type="bibr">30</xref>]. An important consideration is how to prepare the data in a suitable format. Publicly available datasets are often in a raw state and need to be pre-processed (e.g., motion correction, registration, and masking) before they can be used for advanced analyses. The pre-processing can take a significant amount of time and add to the burden on the learner. To circumvent this bottleneck, we supply fully pre-processed data with the tutorials, making it significantly easier for a novice user to get started and quickly perform a successful analysis.</p>
    <p>Having made it easy to access code and use machine learning algorithms, we embrace the third challenge: running the code efficiently using compute clusters. It can be difficult to take code that works on a laptop and modify it to efficiently leverage the resources of a cluster and scale performance to meet the demands of large datasets. This is a burden on the user and requires specialized expertise to write efficient, properly parallelized code. BrainIAK has built-in tools for making the most of clusters to scale analyses easily. In fact, the same code works seamlessly from a laptop (with a few cores) to clusters (with thousands of cores). For example, searchlight analysis (see [<xref rid="pcbi.1007549.ref031" ref-type="bibr">31</xref>]) involves running the same MVPA thousands of times at different points in the brain, which can be extremely slow on a laptop or desktop. BrainIAK includes a searchlight function that distributes these jobs on a cluster to run them in parallel. This function can be invoked using a few lines of code and runs seamlessly on any computing hardware. The tutorials give example code for cluster computing that can easily be extended to novel datasets.</p>
    <p>In addition to parallelizing the code, cluster environments can present other complications for learners. In particular, the interactive nature of working on a laptop or desktop is absent when working on a cluster, making troubleshooting difficult. Cluster environments also demand resource allocations up front (i.e., number of cores and amount of memory); increasing memory or extending time during program execution is not permitted. The tutorials use the SLURM scheduler [<xref rid="pcbi.1007549.ref032" ref-type="bibr">32</xref>] and provide instructions on how to determine the resources required to execute jobs and how to monitor running jobs.</p>
    <p>In summary, we present a set of tutorials created to enable users of all skill levels to learn and deploy advanced multivariate fMRI analysis techniques. In addition to covering the latest incarnation of MVPA [<xref rid="pcbi.1007549.ref001" ref-type="bibr">1</xref>],[<xref rid="pcbi.1007549.ref005" ref-type="bibr">5</xref>], we provide recommendations on optimizing classifiers and strategies to avoid double-dipping. We also cover a range of cutting-edge techniques available in BrainIAK, including searchlight analysis, FCMA, ISC, ISFC, SRM, real-time fMRI, and event segmentation using hidden Markov models. We have released these tutorials publicly and freely. The users can also apply these methods to publicly available datasets from the existing literature, leading to independent validation of the published results. We are hopeful that this will help increase reproducibility of future results more broadly: when tutorial users analyze their own data, they will have already become familiar with the tools necessary to share their code and data, leading to a cycle of improved data sharing and code validation.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>Design and implementation</title>
    <sec id="sec003">
      <title>Tutorials</title>
      <p>Our learning materials are built and integrated using freely available tools and packages. The tutorials are written in the Python programming language. They are presented as Jupyter notebooks with background, documentation, and figures for each section of the code. For data loading, masking, and writing files in NIFTI format, we use <ext-link ext-link-type="uri" xlink:href="https://nipy.org/nibabel/">Nibabel</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://nilearn.github.io/user_guide.html">Nilearn</ext-link>. A variety of functions useful for machine learning are called from <ext-link ext-link-type="uri" xlink:href="https://scikit-learn.org/stable/">Scikit-learn</ext-link>. Each notebook is paired with a publicly available dataset that is analyzed using the code (see <xref rid="pcbi.1007549.t001" ref-type="table">Table 1</xref>). These datasets have already been pre-processed using standard steps and parameters, allowing the user to focus on learning the analyses. We have compiled a condensed version of these datasets, reducing the number of subjects to ensure that the tutorials run quickly and have reasonable memory requirements [<xref rid="pcbi.1007549.ref033" ref-type="bibr">33</xref>]. The results from the analyses are plotted using <ext-link ext-link-type="uri" xlink:href="https://matplotlib.org/">Matplotlib</ext-link> [<xref rid="pcbi.1007549.ref034" ref-type="bibr">34</xref>] and <ext-link ext-link-type="uri" xlink:href="https://seaborn.pydata.org/">Seaborn</ext-link> [<xref rid="pcbi.1007549.ref035" ref-type="bibr">35</xref>]. For network connectivity diagrams, <ext-link ext-link-type="uri" xlink:href="https://networkx.github.io/documentation/networkx-2.3/index.html">Networkx</ext-link> [<xref rid="pcbi.1007549.ref036" ref-type="bibr">36</xref>] and <ext-link ext-link-type="uri" xlink:href="https://nxviz.readthedocs.io/en/latest/index.html">Nxviz</ext-link> were used. To load hdf5 files, the <ext-link ext-link-type="uri" xlink:href="https://deepdish.readthedocs.io/en/latest/index.html">Deepdish</ext-link> package was used. The <ext-link ext-link-type="uri" xlink:href="https://github.com/gorakhargosh/watchdog">Watchdog</ext-link> package was used to indicate when new files were created.</p>
      <table-wrap id="pcbi.1007549.t001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1007549.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>The datasets used in the tutorials.</title>
          <p>We are releasing these datasets under the Creative Commons Attribution 4.0 International License. Although some of these datasets are publicly available, we provide condensed versions of these datasets, along with masks, that are easier to use and may be downloaded from Zenodo (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2598755">https://doi.org/10.5281/zenodo.2598755</ext-link>). For quicker download speeds, the datasets may be downloaded from the Brainiak tutorials website (<ext-link ext-link-type="uri" xlink:href="https:/brainiak.org/tutorials">https:/brainiak.org/tutorials</ext-link>).</p>
        </caption>
        <alternatives>
          <graphic id="pcbi.1007549.t001g" xlink:href="pcbi.1007549.t001"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th align="center" rowspan="1" colspan="1">Datasets</th>
                <th align="center" rowspan="1" colspan="1">Source</th>
                <th align="center" rowspan="1" colspan="1">Used in tutorials</th>
                <th align="center" rowspan="1" colspan="1">Online archive of the dataset</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>1.</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Faces, places, and objects</td>
                <td align="center" rowspan="1" colspan="1">[<xref rid="pcbi.1007549.ref037" ref-type="bibr">37</xref>]</td>
                <td align="center" rowspan="1" colspan="1">1–5, 7</td>
                <td align="left" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds001926/versions/1.0.1">https://openneuro.org/datasets/ds001926/versions/1.0.1</ext-link><break/>Condensed version available on the BrainIAK tutorials website.</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>2.</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Ninety-six objects</td>
                <td align="center" rowspan="1" colspan="1">[<xref rid="pcbi.1007549.ref038" ref-type="bibr">38</xref>]</td>
                <td align="center" rowspan="1" colspan="1">6</td>
                <td align="left" rowspan="1" colspan="1">Not on OpenNeuro. Condensed version available on the BrainIAK tutorials website.</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>3.</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Faces and scenes</td>
                <td align="center" rowspan="1" colspan="1">[<xref rid="pcbi.1007549.ref039" ref-type="bibr">39</xref>]</td>
                <td align="center" rowspan="1" colspan="1">7, 9</td>
                <td align="left" rowspan="1" colspan="1">Not on OpenNeuro. Condensed version available on the BrainIAK tutorials website.</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>4.</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Lateralized attention</td>
                <td align="center" rowspan="1" colspan="1">[<xref rid="pcbi.1007549.ref040" ref-type="bibr">40</xref>]</td>
                <td align="center" rowspan="1" colspan="1">8</td>
                <td align="left" rowspan="1" colspan="1">Not on OpenNeuro. Condensed version available on the BrainIAK tutorials website.</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>5.</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Pieman story</td>
                <td align="center" rowspan="1" colspan="1">[<xref rid="pcbi.1007549.ref010" ref-type="bibr">10</xref>]</td>
                <td align="center" rowspan="1" colspan="1">10, 11</td>
                <td align="left" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://dataspace.princeton.edu/jspui/handle/88435/dsp015d86p269k">https://dataspace.princeton.edu/jspui/handle/88435/dsp015d86p269k</ext-link><break/>Condensed version available on the BrainIAK tutorials website.</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>6.</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Raiders movie</td>
                <td align="center" rowspan="1" colspan="1">[<xref rid="pcbi.1007549.ref041" ref-type="bibr">41</xref>]</td>
                <td align="center" rowspan="1" colspan="1">11</td>
                <td align="left" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://github.com/HaxbyLab/raiders_data">https://github.com/HaxbyLab/raiders_data</ext-link><break/>Condensed version available on the BrainIAK tutorials website.</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>7.</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Raiders images</td>
                <td align="center" rowspan="1" colspan="1">[<xref rid="pcbi.1007549.ref041" ref-type="bibr">41</xref>]</td>
                <td align="center" rowspan="1" colspan="1">11</td>
                <td align="left" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://github.com/HaxbyLab/raiders_data">https://github.com/HaxbyLab/raiders_data</ext-link><break/>Condensed version available on the BrainIAK tutorials website.</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>8.</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Sherlock movie</td>
                <td align="center" rowspan="1" colspan="1">[<xref rid="pcbi.1007549.ref042" ref-type="bibr">42</xref>]</td>
                <td align="center" rowspan="1" colspan="1">12</td>
                <td align="left" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds001132/versions/1.0.0">https://openneuro.org/datasets/ds001132/versions/1.0.0</ext-link><break/>Condensed version available on the BrainIAK tutorials website.</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec id="sec004">
      <title>BrainIAK</title>
      <p>BrainIAK is a software library for advanced fMRI analysis co-designed by cognitive neuroscientists and computer scientists. BrainIAK offers a Python interface and is mostly written in Python, but contains optimized code written in Cython and C++. Many of the methods in BrainIAK scale from a laptop to compute clusters using OpenMP [<xref rid="pcbi.1007549.ref043" ref-type="bibr">43</xref>] and MPI [<xref rid="pcbi.1007549.ref044" ref-type="bibr">44</xref>] parallel and distributed computing technologies. BrainIAK assumes that data have already been pre-processed with other pipelines and relies on other packages for plotting. The user is free to use any preprocessing pipeline (e.g., fmriprep, AFNI). Data are exchanged in standard NIFTI and NumPy formats with existing tools such as <ext-link ext-link-type="uri" xlink:href="https://nipy.org/nibabel/">Nibabel</ext-link> or <ext-link ext-link-type="uri" xlink:href="https://nilearn.github.io/user_guide.html">Nilearn</ext-link> and our tutorials show how to import data into Python structures and use BrainIAK. The functions in BrainIAK parse the data in a <italic>time</italic> x <italic>voxels</italic> format, with an exception being the searchlight function that takes in 4-D volumes. The BrainIAK package also serves as an ecosystem for users to contribute their own methods while avoiding duplication of methods found in other packages.</p>
    </sec>
    <sec id="sec005">
      <title>Hardware configurations</title>
      <p>We have provided detailed instructions on how to configure the tutorials on different computing platforms here: <ext-link ext-link-type="uri" xlink:href="http://brainiak.org/tutorials">https://brainiak.org/tutorials</ext-link>. Multiple installation or usage options are available using: Google Colaboratory for running through a web browser on the cloud, Docker for running on a Macintosh or Windows computer, and Conda for running on a Macintosh computer, Linux server, or high-performance compute cluster.</p>
      <p>We tested the tutorials on clusters using the SLURM scheduler. We provide scripts to launch Jupyter notebooks on clusters and connect to the tutorials through a web browser via an SSH tunnel. We also provide bash scripts for running the tutorials on these remote servers. For long-running jobs that need large amounts of resources on the cluster, we use Python scripts that are submitted to the cluster as batch jobs instead of the more interactive Jupyter notebooks. These scripts are also provided along with the tutorials.</p>
    </sec>
    <sec id="sec006">
      <title>Classroom deployment</title>
      <p>These notebooks were initially developed for research methods courses taught at an advanced undergraduate/graduate level at Yale and Princeton. Each notebook was intentionally designed to be a suitable length for a weekly problem set that would take students between three and twelve hours, depending on the skill level of the student and complexity of the topic. To implement these tutorials in a classroom setting, we configured cluster resources for the class and distributed and collected assigned notebooks using GitHub Classroom. Another feature of GitHub Classroom is that it keeps student responses private from other students and yet gives the instructors easy access.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="sec007">
    <title>Results</title>
    <p>Our goal was to create user-friendly educational materials (<ext-link ext-link-type="uri" xlink:href="https://brainiak.org/tutorials">https://brainiak.org/tutorials</ext-link>) that can be used by novice or expert practitioners to learn how to deploy advanced fMRI analyses in their research. The execution of the notebooks on a cluster is also made simple. If the requisite software and data are installed on the cluster, a user simply needs to connect to the cluster from their laptop/desktop computer, open a web browser, and access the Jupyter notebooks. The tutorials can also be run on the cloud for free via Google Colaboratory. Each tutorial notebook has an overarching theme of a scientific question relevant to cognitive neuroscience. The accompanying notebook exercises help the user understand the method and its applicability to the scientific question by requiring that they generate answers or code. The questions and exercises can be used to formally evaluate students enrolled in a for-credit course (course instructors may contact us for more information). These questions are posed in the context of a publicly available fMRI dataset. These datasets are distributed with the tutorials in a ready-to-use (pre-processed) state. The user is also encouraged to make novel contributions using the method that they learned in the tutorial, either by enhancing the method, creating a new visualization of the data, or even using the method on another dataset, e.g., from OpenNeuro (<ext-link ext-link-type="uri" xlink:href="http://openneuro.org/">http://openneuro.org</ext-link>) [<xref rid="pcbi.1007549.ref045" ref-type="bibr">45</xref>]. Once the user has acquired proficiency in executing the notebooks from a browser, we introduce running programs on clusters by submitting scripts as batch jobs.</p>
    <p>Each of the notebooks can be run independently. For the beginning and intermediate user, we recommend starting with the first notebook and working through 1–7. After this, the user can choose to focus on a particular method among notebooks 8–13. An advanced user already familiar with Python and machine learning can start with any notebook in the sequence. For those who are new to clusters but otherwise proficient at fMRI analysis, the searchlight notebook is a useful starting point. We describe the contents of each notebook (<ext-link ext-link-type="uri" xlink:href="https://brainiak.org/tutorials">https://brainiak.org/tutorials</ext-link>) in more detail below:</p>
    <sec id="sec008">
      <title>Tutorial notebooks</title>
      <list list-type="order">
        <list-item>
          <p><bold>Setup:</bold> An introductory notebook to help users learn how to work with Jupyter.</p>
        </list-item>
        <list-item>
          <p><bold>Data handling and normalization:</bold> Load fMRI datasets into a Python environment using <ext-link ext-link-type="uri" xlink:href="https://nilearn.github.io/user_guide.html">Nilearn</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://nipy.org/nibabel/">Nibabel</ext-link> packages. The importance of normalizing the data is shown via an exercise using a simulated dataset.</p>
        </list-item>
        <list-item>
          <p><bold>Classification:</bold> Once the data have been loaded and normalized, the BOLD signal is extracted with a shift to account for hemodynamic lag and classification is performed using a linear classifier. The importance of separating training and test data is emphasized and cross-validation is introduced. The pitfalls of double-dipping are highlighted and the leave-one-run-out approach is covered. A category localizer dataset is used to examine modular vs. distributed processing in the visual system.</p>
        </list-item>
        <list-item>
          <p><bold>Dimensionality reduction:</bold> Introduce principal component analysis (PCA), explore how to select the number of dimensions, and highlight the importance of using cross-validation to perform feature selection. Determine the smallest number of components yielding the “best” decoding accuracy. Show how other dimensionality reduction techniques can be substituted into this pipeline.</p>
        </list-item>
        <list-item>
          <p><bold>Classifier optimization:</bold> Use grid search and pipelines from <ext-link ext-link-type="uri" xlink:href="https://scikit-learn.org/stable/">Scikit-learn</ext-link> to tune hyperparameters and perform nested cross-validation. How to handle mild forms of double-dipping (e.g., “peeking” at unlabeled test data by including it in z-scoring) that are often unavoidable, by performing permutation tests with randomized labels.</p>
        </list-item>
        <list-item>
          <p><bold>Representational similarity analysis (RSA):</bold> Using pattern similarity and representational dissimilarity matrices to explore the neural representation of different categories of objects in a way that can be compared to behavioral judgments and computational models, and solve the identity of unlabeled “mystery” objects.</p>
        </list-item>
        <list-item>
          <p><bold>Searchlights:</bold> Explore where in the brain local areas contain multivariate information that discriminates between faces and scenes. Begins with a small mask to build proficiency and ends by running a whole-brain searchlight analysis. Demonstrates how to execute this computationally intensive analysis rapidly on a cluster using batch scripts and covers resource planning and monitoring of large batch jobs.</p>
        </list-item>
        <list-item>
          <p><bold>Seed-based functional connectivity:</bold> To explore how large-scale brain networks, not just individual regions, contribute to cognitive processing, examine the temporal correlation (functional connectivity) between regions. Shows how connectivity changes during an attention task and how to remove stimulus-evoked responses to isolate background connectivity.</p>
        </list-item>
        <list-item>
          <p><bold>Full correlation matrix analysis (FCMA):</bold> Rather than focus on connectivity with one or more seed regions of interest, calculate and analyze an unbiased measure of connectivity—the correlation of every voxel in the brain with every other voxel. Highlights differences between FCMA (which classifies based on connectivity) and MVPA (which classifies based on activity), including brain regions that are equally active for faces and scenes but are differentially connected.</p>
        </list-item>
        <list-item>
          <p><bold>Inter-subject connectivity (ISC):</bold> Examine what is common across people by measuring correlations over time in the activity of matching voxels in their brains in response to a common stimulus (e.g., story or movie). Measure functional connectivity across people by correlating non-matching voxels (e.g., between angular gyrus in one subject and hippocampus in another). Shows how these techniques can reveal stimulus-driven variance in the brain by comparing listening to intact vs. scrambled stories.</p>
        </list-item>
        <list-item>
          <p><bold>Shared response model (SRM):</bold> A common stimulus across subjects can be used to align subject brains functionally, rather than typical anatomical registration. SRM seeks to find shared variance in the fMRI data across subjects, in a reduced dimension feature space. This results in weights that map between voxels and features, allowing other data to be projected into the aligned space. SRM can also be viewed as a technique for isolating reliable stimulus-related responses by removing responses that are either noise or idiosyncratic subject responses. Shows the utility of this approach by improving time-segment matching in movie data and image classification with MVPA.</p>
        </list-item>
        <list-item>
          <p><bold>Event segmentation:</bold> Use hidden Markov models (HMMs) to identify a sequence of transitions between stable brain patterns in fMRI data. Illustrates how fitting HMMs to data from high-level brain regions (obtained during movie-watching) subdivides the time series into chunks that track events in the movie. Explores whether retrieving events from memory leads to similar neural transitions.</p>
        </list-item>
        <list-item>
          <p><bold>Real-time fMRI:</bold> Most fMRI studies involve collecting data and analyzing them days or weeks later. By analyzing data on the fly, real-time fMRI makes new kinds of experiments possible, such as neurofeedback training and adaptive designs. Demonstrates the use of an fMRI data simulator, which generates brain images at the rate of an fMRI study (every 1–2 s), and then address how to pre-process data online and how to complete MVPA or other advanced analyses incrementally, before the next brain image.</p>
        </list-item>
      </list>
    </sec>
    <sec id="sec009">
      <title>Cluster computing</title>
      <p>Analyses that require either a long run-time or large memory are best run in batch mode. The Jupyter notebooks for these jobs serve as a template and may be used as the starting point for a batch script. Once the contents of the notebook have been learned, the user is directed to execute batch scripts associated with the notebook on the cluster.</p>
      <p>Executing batch jobs on clusters is non-trivial as it involves allocating the correct memory utilization, number of tasks, and the time required. Given the non-interactive nature of most clusters, debugging performance issues can be challenging. In the Searchlight notebook we have provided step-by-step instructions for cluster execution. To make the transition to running on clusters easier, we provide recommendations such as running small samples of the analyses and extrapolating to make memory and time estimates for the analysis of the entire dataset. We also provide batch scripts with parameters that can be changed to fit the needs of the user. Finally, we provide some basic tips on how to monitor the status of batch jobs on the clusters.</p>
    </sec>
    <sec id="sec010">
      <title>Other resources</title>
      <p>To use the tutorials, a user will need to interact with multiple software tools. To make it easier for a new user to navigate these tools, we have created a website <ext-link ext-link-type="uri" xlink:href="https://github.com/brainiak/brainiak-tutorials/wiki/Resources">https://github.com/brainiak/brainiak-tutorials/wiki/Resources</ext-link>, where a new user can access tutorials and become familiar with Python, GitHub, and Unix. Furthermore, our goal for these tutorials was to cover advanced fMRI analysis and hence our tutorials do not cover pre-processing methods, General Linear Model analysis, or software deployment options (e.g., containers) in great detail. An exhaustive list covering multiple helpful tools and tutorials is available here: <ext-link ext-link-type="uri" xlink:href="https://github.com/ohbm/hackathon2019/blob/master/Tutorial_Resources.md">https://github.com/ohbm/hackathon2019/blob/master/Tutorial_Resources.md</ext-link>.</p>
    </sec>
    <sec id="sec011">
      <title>Availability and future directions</title>
      <p>These tutorials and their associated datasets can be accessed here: <ext-link ext-link-type="uri" xlink:href="https://brainiak.org/tutorials/">https://brainiak.org/tutorials</ext-link>. At the time of writing there are 13 notebooks available. As time permits, we intend to produce more tutorials as needs or new methods demand. The methods/tools that are available in BrainIAK but not covered in the tutorials are: Bayesian derived methods for RSA; Topographic Factor Analysis; and an fMRI Simulator. We welcome contributions to BrainIAK from the community, in the form of code and tutorials added via GitHub.</p>
    </sec>
  </sec>
</body>
<back>
  <ack>
    <p>We would like to thank the following people for help with many aspects of the tutorials: David Turner for help with high-performance computing; Benjamin Singer for help with software installations and data management; Grant Wallace for cloud configurations and testing; and Daniel Suo for website management. Several individuals contributed to specific tutorials, as listed in the contributions section for each tutorial; we especially thank Chris Baldassano for creating the initial HMM notebook and writing an example script to compute ISC, and Po-Hsuan (Cameron) Chen for providing initial code for the SRM notebook. We would also like to thank the students (at Yale and Princeton) and workshop and hackathon participants (at Yale, Princeton, and Virginia Tech) for their participation and feedback on these materials, Ed Clayton for organizing logistics for the workshops and hackathons, and Jonathan D. Cohen for overall project oversight. The author order for N.B.T.-B and K.A.N was determined by a coin flip.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1007549.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Norman</surname><given-names>KA</given-names></name>, <name><surname>Polyn</surname><given-names>SM</given-names></name>, <name><surname>Detre</surname><given-names>GJ</given-names></name>, <name><surname>Haxby</surname><given-names>JV</given-names></name>. <article-title>Beyond mind-reading: multi-voxel pattern analysis of fMRI data</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2006</year>;<volume>10</volume>: <fpage>424</fpage>–<lpage>430</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2006.07.005</pub-id><?supplied-pmid 16899397?><pub-id pub-id-type="pmid">16899397</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Chadwick</surname><given-names>MJ</given-names></name>, <name><surname>Bonnici</surname><given-names>HM</given-names></name>, <name><surname>Maguire</surname><given-names>EA</given-names></name>. <article-title>Decoding information in the human hippocampus: A user’s guide</article-title>. <source>Neuropsychologia</source>. <year>2012</year>;<volume>50</volume>: <fpage>3107</fpage>–<lpage>3121</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2012.07.007</pub-id><?supplied-pmid 22820344?><pub-id pub-id-type="pmid">22820344</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref003">
      <label>3</label>
      <mixed-citation publication-type="book"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name>, <name><surname>Kreiman</surname><given-names>G</given-names></name>. <chapter-title>Visual Population Codes: Toward a Common Multivariate Framework for Cell Recording and Functional Imaging</chapter-title><publisher-name>MIT Press</publisher-name>; <year>2012</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Kaplan</surname><given-names>JT</given-names></name>, <name><surname>Man</surname><given-names>K</given-names></name>, <name><surname>Greening</surname><given-names>SG</given-names></name>. <article-title>Multivariate cross-classification: applying machine learning techniques to characterize abstraction in neural representations</article-title>. <source>Front Hum Neurosci</source>. <year>2015</year>;<volume>9</volume><pub-id pub-id-type="doi">10.3389/fnhum.2015.00151</pub-id><?supplied-pmid 25859202?><pub-id pub-id-type="pmid">25859202</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name>, <name><surname>Mur</surname><given-names>M</given-names></name>, <name><surname>Bandettini</surname><given-names>P</given-names></name>. <article-title>Representational Similarity Analysis–Connecting the Branches of Systems Neuroscience</article-title>. <source>Front Syst Neurosci</source>. <year>2008</year>;<volume>2</volume><pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id><?supplied-pmid 19104670?><pub-id pub-id-type="pmid">19104670</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Nili</surname><given-names>H</given-names></name>, <name><surname>Wingfield</surname><given-names>C</given-names></name>, <name><surname>Walther</surname><given-names>A</given-names></name>, <name><surname>Su</surname><given-names>L</given-names></name>, <name><surname>Marslen-Wilson</surname><given-names>W</given-names></name>, <name><surname>Kriegeskorte</surname><given-names>N</given-names></name>. <article-title>A Toolbox for Representational Similarity Analysis</article-title>. <name><surname>Prlic</surname><given-names>A</given-names></name>, editor. <source>PLoS Computational Biology</source>. <year>2014</year>;<volume>10</volume>: <fpage>e1003553</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003553</pub-id><?supplied-pmid 24743308?><pub-id pub-id-type="pmid">24743308</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref007">
      <label>7</label>
      <mixed-citation publication-type="book"><name><surname>Wang</surname><given-names>Y</given-names></name>, <name><surname>Anderson</surname><given-names>MJ</given-names></name>, <name><surname>Cohen</surname><given-names>JD</given-names></name>, <name><surname>Heinecke</surname><given-names>A</given-names></name>, <name><surname>Li</surname><given-names>K</given-names></name>, <name><surname>Satish</surname><given-names>N</given-names></name>, <etal>et al</etal><source>Full correlation matrix analysis of fMRI data on Intel® Xeon Phi<sup>TM</sup> coprocessors</source>. <publisher-name>ACM Press</publisher-name>; <year>2015</year> pp. <fpage>1</fpage>–<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1145/2807591.2807631</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Hasson</surname><given-names>U</given-names></name>, <name><surname>Nir</surname><given-names>Y</given-names></name>, <name><surname>Levy</surname><given-names>I</given-names></name>, <name><surname>Fuhrmann</surname><given-names>G</given-names></name>, <name><surname>Malach</surname><given-names>R</given-names></name>. <article-title>Intersubject Synchronization of Cortical Activity During Natural Vision</article-title>. <source>Science</source>. <year>2004</year>;<volume>303</volume>: <fpage>1634</fpage>–<lpage>1640</lpage>. <pub-id pub-id-type="doi">10.1126/science.1089506</pub-id><?supplied-pmid 15016991?><pub-id pub-id-type="pmid">15016991</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Nastase</surname><given-names>SA</given-names></name>, <name><surname>Gazzola</surname><given-names>V</given-names></name>, <name><surname>Hasson</surname><given-names>U</given-names></name>, <name><surname>Keysers</surname><given-names>C</given-names></name>. <article-title>Measuring shared responses across subjects using intersubject correlation</article-title>. <source>Soc Cogn Affect Neurosci</source>. <year>2019</year>;<volume>14</volume>: <fpage>667</fpage>–<lpage>685</lpage>. <pub-id pub-id-type="doi">10.1093/scan/nsz037</pub-id><?supplied-pmid 31099394?><pub-id pub-id-type="pmid">31099394</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Simony</surname><given-names>E</given-names></name>, <name><surname>Honey</surname><given-names>CJ</given-names></name>, <name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Lositsky</surname><given-names>O</given-names></name>, <name><surname>Yeshurun</surname><given-names>Y</given-names></name>, <name><surname>Wiesel</surname><given-names>A</given-names></name>, <etal>et al</etal><article-title>Dynamic reconfiguration of the default mode network during narrative comprehension</article-title>. <source>Nature Communications</source>. <year>2016</year>;<volume>7</volume>: <fpage>12141</fpage><pub-id pub-id-type="doi">10.1038/ncomms12141</pub-id><?supplied-pmid 27424918?><pub-id pub-id-type="pmid">27424918</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref011">
      <label>11</label>
      <mixed-citation publication-type="book"><name><surname>Chen</surname><given-names>P-H</given-names></name>, <name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Yeshurun</surname><given-names>Y</given-names></name>, <name><surname>Hasson</surname><given-names>U</given-names></name>, <name><surname>Haxby</surname><given-names>J</given-names></name>, <name><surname>Ramadge</surname><given-names>PJ</given-names></name>. <chapter-title>A Reduced-Dimension fMRI Shared Response Model</chapter-title> In: <name><surname>Cortes</surname><given-names>C</given-names></name>, <name><surname>Lawrence</surname><given-names>ND</given-names></name>, <name><surname>Lee</surname><given-names>DD</given-names></name>, <name><surname>Sugiyama</surname><given-names>M</given-names></name>, <name><surname>Garnett</surname><given-names>R</given-names></name>, editors. <source>Advances in Neural Information Processing Systems 28</source>. <publisher-name>Curran Associates, Inc.</publisher-name>; <year>2015</year> pp. <fpage>460</fpage>–<lpage>468</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://papers.nips.cc/paper/5855-a-reduced-dimension-fmri-shared-response-model.pdf">http://papers.nips.cc/paper/5855-a-reduced-dimension-fmri-shared-response-model.pdf</ext-link></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Baldassano</surname><given-names>C</given-names></name>, <name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Zadbood</surname><given-names>A</given-names></name>, <name><surname>Pillow</surname><given-names>JW</given-names></name>, <name><surname>Hasson</surname><given-names>U</given-names></name>, <name><surname>Norman</surname><given-names>KA</given-names></name>. <article-title>Discovering Event Structure in Continuous Narrative Perception and Memory</article-title>. <source>Neuron</source>. <year>2017</year>;<volume>95</volume>: <fpage>709</fpage>–<lpage>721</lpage>.e5. <pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.041</pub-id><?supplied-pmid 28772125?><pub-id pub-id-type="pmid">28772125</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>deBettencourt</surname><given-names>MT</given-names></name>, <name><surname>Cohen</surname><given-names>JD</given-names></name>, <name><surname>Lee</surname><given-names>RF</given-names></name>, <name><surname>Norman</surname><given-names>KA</given-names></name>, <name><surname>Turk-Browne</surname><given-names>NB</given-names></name>. <article-title>Closed-loop training of attention with real-time brain imaging</article-title>. <source>Nature Neuroscience</source>. <year>2015</year>;<volume>18</volume>: <fpage>470</fpage>–<lpage>475</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3940</pub-id><?supplied-pmid 25664913?><pub-id pub-id-type="pmid">25664913</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref014">
      <label>14</label>
      <mixed-citation publication-type="other">Wang Y, Keller B, Capota M, Anderson MJ, Sundaram N, Cohen JD, et al. Real-time full correlation matrix analysis of fMRI data. 2016 IEEE International Conference on Big Data (Big Data). 2016. pp. 1242–1251. <pub-id pub-id-type="doi">10.1109/BigData.2016.7840728</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Sitaram</surname><given-names>R</given-names></name>, <name><surname>Ros</surname><given-names>T</given-names></name>, <name><surname>Stoeckel</surname><given-names>L</given-names></name>, <name><surname>Haller</surname><given-names>S</given-names></name>, <name><surname>Scharnowski</surname><given-names>F</given-names></name>, <name><surname>Lewis-Peacock</surname><given-names>J</given-names></name>, <etal>et al</etal><article-title>Closed-loop brain training: the science of neurofeedback</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2017</year>;<volume>18</volume>: <fpage>86</fpage>–<lpage>100</lpage>. <pub-id pub-id-type="doi">10.1038/nrn.2016.164</pub-id><?supplied-pmid 28003656?><pub-id pub-id-type="pmid">28003656</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Lorenz</surname><given-names>R</given-names></name>, <name><surname>Hampshire</surname><given-names>A</given-names></name>, <name><surname>Leech</surname><given-names>R</given-names></name>. <article-title>Neuroadaptive Bayesian Optimization and Hypothesis Testing</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2017</year>;<volume>21</volume>: <fpage>155</fpage>–<lpage>167</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2017.01.006</pub-id><?supplied-pmid 28236531?><pub-id pub-id-type="pmid">28236531</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Hebart</surname><given-names>MN</given-names></name>, <name><surname>Görgen</surname><given-names>K</given-names></name>, <name><surname>Haynes</surname><given-names>J-D</given-names></name>. <article-title>The Decoding Toolbox (TDT): a versatile software package for multivariate analyses of functional imaging data</article-title>. <source>Front Neuroinform</source>. <year>2015</year>;<volume>8</volume><pub-id pub-id-type="doi">10.3389/fninf.2014.00088</pub-id><?supplied-pmid 25610393?><pub-id pub-id-type="pmid">25610393</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Oosterhof</surname><given-names>NN</given-names></name>, <name><surname>Connolly</surname><given-names>AC</given-names></name>, <name><surname>Haxby</surname><given-names>JV</given-names></name>. <article-title>CoSMoMVPA: Multi-Modal Multivariate Pattern Analysis of Neuroimaging Data in Matlab/GNU Octave</article-title>. <source>Front Neuroinform</source>. <year>2016</year>;<volume>10</volume><pub-id pub-id-type="doi">10.3389/fninf.2016.00027</pub-id><?supplied-pmid 27499741?><pub-id pub-id-type="pmid">27499741</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Abraham</surname><given-names>A</given-names></name>, <name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Eickenberg</surname><given-names>M</given-names></name>, <name><surname>Gervais</surname><given-names>P</given-names></name>, <name><surname>Mueller</surname><given-names>A</given-names></name>, <name><surname>Kossaifi</surname><given-names>J</given-names></name>, <etal>et al</etal><source>Machine learning for neuroimaging with scikit-learn</source>. Front Neuroinform. <year>2014</year>;<fpage>8</fpage><pub-id pub-id-type="doi">10.3389/fninf.2014.00014</pub-id><?supplied-pmid 24600388?><pub-id pub-id-type="pmid">24600388</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Hanke</surname><given-names>M</given-names></name>, <name><surname>Halchenko</surname><given-names>YO</given-names></name>, <name><surname>Sederberg</surname><given-names>PB</given-names></name>, <name><surname>Hanson</surname><given-names>SJ</given-names></name>, <name><surname>Haxby</surname><given-names>JV</given-names></name>, <name><surname>Pollmann</surname><given-names>S</given-names></name>. <article-title>PyMVPA: a Python Toolbox for Multivariate Pattern Analysis of fMRI Data</article-title>. <source>Neuroinform</source>. <year>2009</year>;<volume>7</volume>: <fpage>37</fpage>–<lpage>53</lpage>. <pub-id pub-id-type="doi">10.1007/s12021-008-9041-y</pub-id><?supplied-pmid 19184561?><pub-id pub-id-type="pmid">19184561</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Hanke</surname><given-names>M</given-names></name>, <name><surname>Halchenko</surname><given-names>YO</given-names></name>, <name><surname>Sederberg</surname><given-names>PB</given-names></name>, <name><surname>Olivetti</surname><given-names>E</given-names></name>, <name><surname>Fründ</surname><given-names>I</given-names></name>, <name><surname>Rieger</surname><given-names>JW</given-names></name>, <etal>et al</etal><article-title>PyMVPA: a unifying approach to the analysis of neuroscientific data</article-title>. <source>Front Neuroinform</source>. <year>2009</year>;<volume>3</volume><pub-id pub-id-type="doi">10.3389/neuro.11.003.2009</pub-id><?supplied-pmid 19212459?><pub-id pub-id-type="pmid">19212459</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Cox</surname><given-names>RW</given-names></name>. <article-title>AFNI: Software for Analysis and Visualization of Functional Magnetic Resonance Neuroimages</article-title>. <source>Computers and Biomedical Research</source>. <year>1996</year>;<volume>29</volume>: <fpage>162</fpage>–<lpage>173</lpage>. <pub-id pub-id-type="doi">10.1006/cbmr.1996.0014</pub-id><?supplied-pmid 8812068?><pub-id pub-id-type="pmid">8812068</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Jenkinson</surname><given-names>M</given-names></name>, <name><surname>Beckmann</surname><given-names>CF</given-names></name>, <name><surname>Behrens</surname><given-names>TEJ</given-names></name>, <name><surname>Woolrich</surname><given-names>MW</given-names></name>, <name><surname>Smith</surname><given-names>SM</given-names></name>. <article-title>FSL</article-title>. <source>NeuroImage</source>. <year>2012</year>;<volume>62</volume>: <fpage>782</fpage>–<lpage>790</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.09.015</pub-id><?supplied-pmid 21979382?><pub-id pub-id-type="pmid">21979382</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref024">
      <label>24</label>
      <mixed-citation publication-type="book"><name><surname>Friston</surname><given-names>KJ</given-names></name>, <name><surname>Ashburner</surname><given-names>J</given-names></name>, <name><surname>Kiebel</surname><given-names>SJ</given-names></name>, <name><surname>Nichols</surname><given-names>TE</given-names></name>, <name><surname>Penny</surname><given-names>WD</given-names></name>, editors. <source>Statistical Parametric Mapping: The Analysis of Functional Brain Images</source>. <publisher-name>Academic Press</publisher-name>; <year>2007</year> Available: <ext-link ext-link-type="uri" xlink:href="http://store.elsevier.com/product.jsp?isbn=9780123725608">http://store.elsevier.com/product.jsp?isbn=9780123725608</ext-link></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Esteban</surname><given-names>O</given-names></name>, <name><surname>Markiewicz</surname><given-names>CJ</given-names></name>, <name><surname>Blair</surname><given-names>RW</given-names></name>, <name><surname>Moodie</surname><given-names>CA</given-names></name>, <name><surname>Isik</surname><given-names>AI</given-names></name>, <name><surname>Erramuzpe</surname><given-names>A</given-names></name>, <etal>et al</etal><article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title>. <source>Nature Methods</source>. <year>2019</year>;<volume>16</volume>: <fpage>111</fpage>–<lpage>116</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id><?supplied-pmid 30532080?><pub-id pub-id-type="pmid">30532080</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name>, <name><surname>Simmons</surname><given-names>WK</given-names></name>, <name><surname>Bellgowan</surname><given-names>PSF</given-names></name>, <name><surname>Baker</surname><given-names>CI</given-names></name>. <article-title>Circular analysis in systems neuroscience: the dangers of double dipping</article-title>. <source>Nature Neuroscience</source>. <year>2009</year>;<volume>12</volume>: <fpage>535</fpage>–<lpage>540</lpage>. <pub-id pub-id-type="doi">10.1038/nn.2303</pub-id><?supplied-pmid 19396166?><pub-id pub-id-type="pmid">19396166</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Kluyver</surname><given-names>T</given-names></name>, <name><surname>Ragan-Kelley</surname><given-names>B</given-names></name>, <name><surname>Pérez</surname><given-names>F</given-names></name>, <name><surname>Granger</surname><given-names>BE</given-names></name>, <name><surname>Bussonnier</surname><given-names>M</given-names></name>, <name><surname>Frederic</surname><given-names>J</given-names></name>, <etal>et al</etal><article-title>Jupyter Notebooks—a publishing format for reproducible computational workflows</article-title>. <source>In Positioning and Power in Academic Publishing: Players, Agents and Agendas</source>. <year>2016</year> pp. <fpage>87</fpage>–<lpage>90</lpage>. <pub-id pub-id-type="doi">10.3233/978-1-61499-649-1-87</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Brett</surname><given-names>M</given-names></name>, <name><surname>Hanke</surname><given-names>M</given-names></name>, <name><surname>Markiewicz</surname><given-names>C</given-names></name>, <name><surname>Côté</surname><given-names>M-A</given-names></name>, <name><surname>McCarthy</surname><given-names>P</given-names></name>, <name><surname>Cheng</surname><given-names>C</given-names></name>, <etal>et al</etal><article-title>nipy/nibabel: 2.3.1</article-title>. <source>Zenodo</source>; <year>2018</year><pub-id pub-id-type="doi">10.5281/zenodo.1464282</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Gramfort</surname><given-names>A</given-names></name>, <name><surname>Michel</surname><given-names>V</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <name><surname>Grisel</surname><given-names>O</given-names></name>, <etal>et al</etal><article-title>Scikit-learn: Machine Learning in Python</article-title>. <source>Journal of Machine Learning Research</source>. <year>2011</year>;<volume>12</volume>: <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Anderson</surname><given-names>MJ</given-names></name>, <name><surname>Capota</surname><given-names>M</given-names></name>, <name><surname>Turek</surname><given-names>JS</given-names></name>, <name><surname>Zhu</surname><given-names>X</given-names></name>, <name><surname>Willke</surname><given-names>TL</given-names></name>, <name><surname>Wang</surname><given-names>Y</given-names></name>, <etal>et al</etal><article-title>Enabling factor analysis on thousand-subject neuroimaging datasets</article-title>. IEEE; <year>2016</year> pp. <fpage>1151</fpage>–<lpage>1160</lpage>. <pub-id pub-id-type="doi">10.1109/BigData.2016.7840719</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name>, <name><surname>Goebel</surname><given-names>R</given-names></name>, <name><surname>Bandettini</surname><given-names>P</given-names></name>. <article-title>Information-based functional brain mapping</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>2006</year>;<volume>103</volume>: <fpage>3863</fpage>–<lpage>3868</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://www.pnas.org/content/103/10/3863.short">http://www.pnas.org/content/103/10/3863.short</ext-link><pub-id pub-id-type="doi">10.1073/pnas.0600244103</pub-id><?supplied-pmid 16537458?><pub-id pub-id-type="pmid">16537458</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref032">
      <label>32</label>
      <mixed-citation publication-type="book"><name><surname>Jette</surname><given-names>MA</given-names></name>, <name><surname>Yoo</surname><given-names>AB</given-names></name>, <name><surname>Grondona</surname><given-names>M</given-names></name>. <chapter-title>SLURM: Simple Linux Utility for Resource Management</chapter-title><source>In Lecture Notes in Computer Science: Proceedings of Job Scheduling Strategies for Parallel Processing (JSSPP) 2003</source>. <publisher-name>Springer-Verlag</publisher-name>; <year>2002</year> pp. <fpage>44</fpage>–<lpage>60</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Kumar</surname><given-names>M</given-names></name>, <name><surname>Ellis</surname><given-names>CT</given-names></name>, <name><surname>Lu</surname><given-names>Q</given-names></name>, <name><surname>Zhang</surname><given-names>H</given-names></name>, <name><surname>Ramadge</surname><given-names>PJ</given-names></name>, <name><surname>Turk-Browne</surname><given-names>NB</given-names></name>, <etal>et al</etal><article-title>BrainIAK Tutorials: Condensed Datasets</article-title>. <source>Zenodo</source>; <year>2019</year><pub-id pub-id-type="doi">10.5281/zenodo.2598755</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Droettboom</surname><given-names>M</given-names></name>, <name><surname>Caswell</surname><given-names>TA</given-names></name>, <name><surname>John</surname><given-names>Hunter</given-names></name>, <name><surname>Eric</surname><given-names>Firing</given-names></name>, <name><surname>Jens Hedegaard</surname><given-names>Nielsen</given-names></name>, <name><surname>Antony</surname><given-names>Lee</given-names></name>, <etal>et al</etal><article-title>matplotlib/matplotlib v2.2.2</article-title>. <source>Zenodo</source>; <year>2018</year><pub-id pub-id-type="doi">10.5281/zenodo.1202077</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Waskom</surname><given-names>M</given-names></name>, <name><surname>Botvinnik</surname><given-names>O</given-names></name>, <name><surname>O’Kane</surname><given-names>D</given-names></name>, <name><surname>Hobson</surname><given-names>P</given-names></name>, <name><surname>Ostblom</surname><given-names>J</given-names></name>, <name><surname>Lukauskas</surname><given-names>S</given-names></name>, <etal>et al</etal><article-title>mwaskom/seaborn: v0.9.0 (July 2018)</article-title>. <source>Zenodo</source>; <year>2018</year><pub-id pub-id-type="doi">10.5281/zenodo.1313201</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref036">
      <label>36</label>
      <mixed-citation publication-type="other">Hagberg AA, Schult DA, Swart PJ. Exploring Network Structure, Dynamics, and Function using NetworkX. In: Varoquaux G, Vaught T, Millman J, editors. Proceedings of the 7th Python in Science Conference. Pasadena, CA USA; 2008. pp. 11–15.</mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Kim</surname><given-names>G</given-names></name>, <name><surname>Norman</surname><given-names>KA</given-names></name>, <name><surname>Turk-Browne</surname><given-names>NB</given-names></name>. <article-title>Neural Differentiation of Incorrectly Predicted Memories</article-title>. <source>J Neurosci</source>. <year>2017</year>;<volume>37</volume>: <fpage>2022</fpage>–<lpage>2031</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3272-16.2017</pub-id><?supplied-pmid 28115478?><pub-id pub-id-type="pmid">28115478</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref038">
      <label>38</label>
      <mixed-citation publication-type="journal"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name>, <name><surname>Mur</surname><given-names>M</given-names></name>, <name><surname>Ruff</surname><given-names>DA</given-names></name>, <name><surname>Kiani</surname><given-names>R</given-names></name>, <name><surname>Bodurka</surname><given-names>J</given-names></name>, <name><surname>Esteky</surname><given-names>H</given-names></name>, <etal>et al</etal><article-title>Matching Categorical Object Representations in Inferior Temporal Cortex of Man and Monkey</article-title>. <source>Neuron</source>. <year>2008</year>;<volume>60</volume>: <fpage>1126</fpage>–<lpage>1141</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2008.10.043</pub-id><?supplied-pmid 19109916?><pub-id pub-id-type="pmid">19109916</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Turk-Browne</surname><given-names>NB</given-names></name>, <name><surname>Simon</surname><given-names>MG</given-names></name>, <name><surname>Sederberg</surname><given-names>PB</given-names></name>. <article-title>Scene Representations in Parahippocampal Cortex Depend on Temporal Context</article-title>. <source>J Neurosci</source>. <year>2012</year>;<volume>32</volume>: <fpage>7202</fpage>–<lpage>7207</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0942-12.2012</pub-id><?supplied-pmid 22623664?><pub-id pub-id-type="pmid">22623664</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>Hutchinson</surname><given-names>JB</given-names></name>, <name><surname>Pak</surname><given-names>SS</given-names></name>, <name><surname>Turk-Browne</surname><given-names>NB</given-names></name>. <article-title>Biased Competition during Long-term Memory Formation</article-title>. <source>J Cogn Neurosci</source>. <year>2016</year>;<volume>28</volume>: <fpage>187</fpage>–<lpage>197</lpage>. <pub-id pub-id-type="doi">10.1162/jocn_a_00889</pub-id><?supplied-pmid 26439270?><pub-id pub-id-type="pmid">26439270</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Haxby</surname><given-names>JV</given-names></name>, <name><surname>Guntupalli</surname><given-names>JS</given-names></name>, <name><surname>Connolly</surname><given-names>AC</given-names></name>, <name><surname>Halchenko</surname><given-names>YO</given-names></name>, <name><surname>Conroy</surname><given-names>BR</given-names></name>, <name><surname>Gobbini</surname><given-names>MI</given-names></name>, <etal>et al</etal><article-title>A common, high-dimensional model of the representational space in human ventral temporal cortex</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>72</volume>: <fpage>404</fpage>–<lpage>416</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2011.08.026</pub-id><?supplied-pmid 22017997?><pub-id pub-id-type="pmid">22017997</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref042">
      <label>42</label>
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Leong</surname><given-names>YC</given-names></name>, <name><surname>Honey</surname><given-names>CJ</given-names></name>, <name><surname>Yong</surname><given-names>CH</given-names></name>, <name><surname>Norman</surname><given-names>KA</given-names></name>, <name><surname>Hasson</surname><given-names>U</given-names></name>. <article-title>Shared memories reveal shared structure in neural activity across individuals</article-title>. <source>Nature Neuroscience</source>. <year>2017</year>;<volume>20</volume>: <fpage>115</fpage>–<lpage>125</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4450</pub-id><?supplied-pmid 27918531?><pub-id pub-id-type="pmid">27918531</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Dagum</surname><given-names>L</given-names></name>, <name><surname>Menon</surname><given-names>R</given-names></name>. <article-title>OpenMP: An Industry-Standard API for Shared-Memory Programming</article-title>. <source>IEEE Comput Sci Eng</source>. <year>1998</year>;<volume>5</volume>: <fpage>46</fpage>–<lpage>55</lpage>. <pub-id pub-id-type="doi">10.1109/99.660313</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref044">
      <label>44</label>
      <mixed-citation publication-type="book"><name><surname>Forum</surname><given-names>MP</given-names></name>. <source>MPI: A Message-Passing Interface Standard</source>. <publisher-loc>Knoxville, TN, USA</publisher-loc>: <publisher-name>University of Tennessee</publisher-name>; <year>1994</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1007549.ref045">
      <label>45</label>
      <mixed-citation publication-type="journal"><name><surname>Poldrack</surname><given-names>RA</given-names></name>, <name><surname>Barch</surname><given-names>DM</given-names></name>, <name><surname>Mitchell</surname><given-names>JP</given-names></name>, <name><surname>Wager</surname><given-names>TD</given-names></name>, <name><surname>Wagner</surname><given-names>AD</given-names></name>, <name><surname>Devlin</surname><given-names>JT</given-names></name>, <etal>et al</etal><article-title>Toward open sharing of task-based fMRI data: the OpenfMRI project</article-title>. <source>Frontiers in Neuroinformatics</source>. <year>2013</year>;<volume>7</volume><pub-id pub-id-type="doi">10.3389/fninf.2013.00012</pub-id><?supplied-pmid 23847528?><pub-id pub-id-type="pmid">23847528</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article id="pcbi.1007549.r001" article-type="aggregated-review-documents">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1007549.r001</article-id>
    <title-group>
      <article-title>Decision Letter 0</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Marinazzo</surname>
          <given-names>Daniele</given-names>
        </name>
        <role>Deputy Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2020 Daniele Marinazzo</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Daniele Marinazzo</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article id="rel-obj001" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1007549" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>0</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">26 Aug 2019</named-content>
    </p>
    <p>Dear Dr Kumar,</p>
    <p>Thank you very much for submitting your manuscript 'BrainIAK tutorials: user-friendly learning materials for advanced fMRI analysis' for review by PLOS Computational Biology. Your manuscript has been fully evaluated by the PLOS Computational Biology editorial team and in this case also by independent peer reviewers. </p>
    <p>Your paper describes a valuable contribution, and the examples are comprehensive. </p>
    <p>The reviewers have raised some important points concerning the implementation of the tutorials (in addtition to the feedback you already received by the community), and the inclusion of this set of tools in the panorama of a wider communitary effort.</p>
    <p>While your manuscript cannot be accepted in its present form, we are willing to consider a revised version in which the issues raised by the reviewers have been adequately addressed. We cannot, of course, promise publication at that time.</p>
    <p>Please note while forming your response, if your article is accepted, you may have the opportunity to make the peer review history publicly available. The record will include editor decision letters (with reviews) and your responses to reviewer comments. If eligible, we will contact you to opt in or out.</p>
    <p>Your revisions should address the specific points made by each reviewer. Please return the revised version within the next 60 days. If you anticipate any delay in its return, we ask that you let us know the expected resubmission date by email at <email>ploscompbiol@plos.org</email>. Revised manuscripts received beyond 60 days may require evaluation and peer review similar to that applied to newly submitted manuscripts.</p>
    <p>In addition, when you are ready to resubmit, please be prepared to provide the following:</p>
    <p>(1) A detailed list of your responses to the review comments and the changes you have made in the manuscript. We require a file of this nature before your manuscript is passed back to the editors.</p>
    <p>(2) A copy of your manuscript with the changes highlighted (encouraged). We encourage authors, if possible to show clearly where changes have been made to their manuscript e.g. by highlighting text.</p>
    <p>(3) A striking still image to accompany your article (optional). If the image is judged to be suitable by the editors, it may be featured on our website and might be chosen as the issue image for that month. These square, high-quality images should be accompanied by a short caption. Please note as well that there should be no copyright restrictions on the use of the image, so that it can be published under the Open-Access license and be subject only to appropriate attribution.</p>
    <p>Before you resubmit your manuscript, please consult our Submission Checklist to ensure your manuscript is formatted correctly for PLOS Computational Biology: <ext-link ext-link-type="uri" xlink:href="http://www.ploscompbiol.org/static/checklist.action">http://www.ploscompbiol.org/static/checklist.action</ext-link>. Some key points to remember are:</p>
    <p>- Figures uploaded separately as TIFF or EPS files (if you wish, your figures may remain in your main manuscript file in addition).</p>
    <p>- Supporting Information uploaded as separate files, titled Dataset, Figure, Table, Text, Protocol, Audio, or Video.</p>
    <p>- Funding information in the 'Financial Disclosure' box in the online system.</p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link ext-link-type="uri" xlink:href="https://pacev2.apexcovantage.com">https://pacev2.apexcovantage.com</ext-link> PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email us at <email>figures@plos.org</email>.</p>
    <p>To enhance the reproducibility of your results, we recommend that you deposit your laboratory protocols in protocols.io, where a protocol can be assigned its own identifier (DOI) such that it can be cited independently in the future. For instructions see <ext-link ext-link-type="uri" xlink:href="http://journals.plos.org/ploscompbiol/s/submission-guidelines#loc-materials-and-methods">here</ext-link>. </p>
    <p>We are sorry that we cannot be more positive about your manuscript at this stage, but if you have any concerns or questions, please do not hesitate to contact us.</p>
    <p>Sincerely,</p>
    <p>Daniele Marinazzo</p>
    <p>Deputy Editor</p>
    <p>PLOS Computational Biology</p>
    <p>Daniele Marinazzo</p>
    <p>Deputy Editor</p>
    <p>PLOS Computational Biology</p>
    <p>A link appears below if there are any accompanying review attachments. If you believe any reviews to be missing, please contact <email>ploscompbiol@plos.org</email> immediately:</p>
    <p>[LINK]</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <bold>Comments to the Authors:</bold>
    </p>
    <p>
      <bold>Please note here if the review is uploaded as an attachment.</bold>
    </p>
    <p>Reviewer #1: Review uploaded as attachment</p>
    <p>Reviewer #2: By drafting the described tutorials, the authors have provided a substantial, valuable contribution to the field. I do, however, have significant concerns about their framing of this contribution in the present manuscript. In particular, the authors fail to acknowledge related efforts across open neuroimaging. I hope that this review provides some constructive feedback as to where they could better link their efforts with those of other community members so that a reader might better understand the impact of the described tutorials.</p>
    <p>The full review is uploaded as an attachment.</p>
    <p>Reviewer #3: # Summary and general comments</p>
    <p>In this submission, Kumar and colleagues present a library called BrainIAK for machine learning in functional neuroimaging, and an accompanying set of tutorials.</p>
    <p>The tutorials are presented in the form of jupyter notebooks, and are accessible either locally through containers or online on the google collab platform.</p>
    <p>They also include instructions for deployment on high-performance infrastructure.</p>
    <p>The data used in the tutorial are freely available and specially prepared to be used as part of a training activity.</p>
    <p>As a strength, some of the material covered in the tutorials include inter-subject correlations and representational similarity analysis, two applications which are not well covered by currently available tutorials, to my knowledge. Overall, this new library and tutorials are remarkably comprehensive, and I believe will represent a very valuable resource for the community. My only major concern is that the authors did not properly position their work compared to other efforts.</p>
    <p># Minor comments</p>
    <p>* abstract: citing a specific list training and hackathons will become obsolete in a few months only. Maybe stay vague there.</p>
    <p>* intro claims several times the lack of existing education material. There is a huge amount of general-purpose tutorials for machine learning, most notably featuring the sklearn documentation. There are at least three extensive packages with many tutorials: nilearn, pyMVPA and <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4956688/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4956688/</ext-link>. The authors should briefly review these other resources and explain how BrainIAK adds to them (paragraph line 120). Which techniques are not currently covered by tutorials?</p>
    <p>* l. 211: would you have recommendations for resources to preprocess the data that would integrate well with BrainIAK? In particular, you may want to discuss if detailed instructions are available for importing minimally preprocessed data, such as the ones generated by fMRIprep.</p>
    <p>* no material is presented to demonstrate that the proposed material achieves the stated goals. Survey results from a workshop, for example, would add some support to the usefulness of the resources.</p>
    <p># Optional suggestions</p>
    <p>Below are two suggestions. I (as a reviewer) do not think it is necessary to implement these suggestions prior to publication. I am providing these suggestions in the hope the authors may find them useful and may choose to follow up on some of them.</p>
    <p>* BrainIAK should go through a proper code review, as a library. Consider a submission to the journal of open source software (JOSS) for the library component of BrainIAK.</p>
    <p>* I have not reviewed the tutorials themselves, but tried to evaluate if BrainIAK adds conceptually to existing software resources. As part of the NeuroLibre platform, a detailed technical review of the notebooks has been performed by two reviewers. I would encourage the authors to address these technical issues.</p>
    <p>**********</p>
    <p>
      <bold>Have all data underlying the figures and results presented in the manuscript been provided?</bold>
    </p>
    <p>Large-scale datasets should be made available via a public repository as described in the <italic>PLOS Computational Biology</italic>
<ext-link ext-link-type="uri" xlink:href="http://journals.plos.org/ploscompbiol/s/data-availability">data availability policy</ext-link>, and numerical data that underlies graphs or summary statistics should be provided in spreadsheet form as supporting information.</p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>Reviewer #3: Yes</p>
    <p>**********</p>
    <p>PLOS authors have the option to publish the peer review history of their article (<ext-link ext-link-type="uri" xlink:href="https://journals.plos.org/ploscompbiol/s/editorial-and-peer-review-process#loc-peer-review-history">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link ext-link-type="uri" xlink:href="https://www.plos.org/privacy-policy">Privacy Policy</ext-link>.</p>
    <p>Reviewer #1: Yes: Oscar Esteban</p>
    <p>Reviewer #2: No</p>
    <p>Reviewer #3: Yes: Pierre Bellec</p>
    <supplementary-material content-type="local-data" id="pcbi.1007549.s001">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">PCOMPBIOL-D-19-01130.pdf</named-content></p>
      </caption>
      <media xlink:href="pcbi.1007549.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1007549.s002">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">review-PCOMPBIOL-D-19-01130.pdf</named-content></p>
      </caption>
      <media xlink:href="pcbi.1007549.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article id="pcbi.1007549.r002" article-type="author-comment">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1007549.r002</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 0</article-title>
    </title-group>
    <related-article id="rel-obj002" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1007549" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">15 Oct 2019</named-content>
    </p>
    <supplementary-material content-type="local-data" id="pcbi.1007549.s003">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">Brainiak Tutorials Paper_response_letter_v3.pdf</named-content></p>
      </caption>
      <media xlink:href="pcbi.1007549.s003.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article id="pcbi.1007549.r003" article-type="aggregated-review-documents">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1007549.r003</article-id>
    <title-group>
      <article-title>Decision Letter 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Marinazzo</surname>
          <given-names>Daniele</given-names>
        </name>
        <role>Deputy Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2020 Daniele Marinazzo</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Daniele Marinazzo</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article id="rel-obj003" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1007549" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">17 Nov 2019</named-content>
    </p>
    <p>Dear Dr Kumar,</p>
    <p>We are pleased to inform you that your manuscript 'BrainIAK tutorials: user-friendly learning materials for advanced fMRI analysis' has been provisionally accepted for publication in PLOS Computational Biology. Please make sure to update the table and references as requested by reviewer 2.</p>
    <p>Before your manuscript can be formally accepted you will need to complete some formatting changes, which you will receive in a follow up email. Please be aware that it may take several days for you to receive this email; during this time no action is required by you. Once you have received these formatting requests, please note that your manuscript will not be scheduled for publication until you have made the required changes.</p>
    <p>In the meantime, please log into Editorial Manager at <ext-link ext-link-type="uri" xlink:href="https://www.editorialmanager.com/pcompbiol/">https://www.editorialmanager.com/pcompbiol/</ext-link>, click the "Update My Information" link at the top of the page, and update your user information to ensure an efficient production and billing process.</p>
    <p>One of the goals of PLOS is to make science accessible to educators and the public. PLOS staff issue occasional press releases and make early versions of PLOS Computational Biology articles available to science writers and journalists. PLOS staff also collaborate with Communication and Public Information Offices and would be happy to work with the relevant people at your institution or funding agency. If your institution or funding agency is interested in promoting your findings, please ask them to coordinate their releases with PLOS (contact <email>ploscompbiol@plos.org</email>).</p>
    <p>Thank you again for supporting Open Access publishing. We look forward to publishing your paper in PLOS Computational Biology.</p>
    <p>Sincerely,</p>
    <p>Daniele Marinazzo</p>
    <p>Deputy Editor</p>
    <p>PLOS Computational Biology</p>
    <p>Daniele Marinazzo</p>
    <p>Deputy Editor</p>
    <p>PLOS Computational Biology</p>
    <p>&lt;br \\&gt;</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <bold>Comments to the Authors: </bold>
    </p>
    <p>
      <bold>Please note here if the review is uploaded as an attachment.</bold>
    </p>
    <p>Reviewer #1: Please find my comments attached.</p>
    <p>Oscar Esteban.</p>
    <p>Reviewer #2: The authors have addressed my major concerns, and the revised manuscript significantly better situates these contributions in the context of the broader field. Several minor notes and clarifications:</p>
    <p>1. I am delighted that the authors are careful to cite supporting software, but I noticed that two technologies are missing from the references list: Jupyter Notebooks and OpenNeuro (formerly OpenfMRI). These citations are, respectively: </p>
    <p>Kluyver, T., Ragan-Kelley, B., Pérez, F., Granger, B.E., Bussonnier, M., Frederic, J., Kelley, K., Hamrick, J.B., Grout, J., Corlay, S., Ivanov, P., Avila, D., Abdalla, S., Willing, C., &amp; Jupyter development team (2016). Jupyter Notebooks - a publishing format for reproducible computational workflows. In Positioning and Power in Academic Publishing: Players, Agents and Agendas. doi: 10.3233/978-1-61499-649-1-87.</p>
    <p>and</p>
    <p>Poldrack, R.A., Barch, D.M., Mitchell, J.P., Wager, T.D., Wagner, A.D., Devlin, J.T., Cumba, C., Koyejo, O., and Milham, M.P. (2013). Toward open sharing of task-based fMRI data: the OpenfMRI project. Frontiers in Neuroinformatics, 7, 1–12.</p>
    <p>Could the authors please update the text to include these references?</p>
    <p>2. I appreciate the authors' clarification as to why Google drive links were included for the datasets. I was also pleased to see that the data used in the tutorials are now directly available in Zenodo, as this provides better long-term archiving. </p>
    <p>Would the authors be willing to update their caption for Table 1 to directly link to the Zenodo archive? This would ensure better long-term access to the exact data source used in the tutorials, as the authors point out that the versions available from e.g. OpenNeuro do not match those used in the lessons.</p>
    <p>Reviewer #3: Thanks for appropriately addressing all of my comments, and congratulations on a very valuable contribution.</p>
    <p>**********</p>
    <p>
      <bold>Have all data underlying the figures and results presented in the manuscript been provided?</bold>
    </p>
    <p> Large-scale datasets should be made available via a public repository as described in the <italic>PLOS Computational Biology</italic>
<ext-link ext-link-type="uri" xlink:href="http://journals.plos.org/ploscompbiol/s/data-availability">data availability policy</ext-link>, and numerical data that underlies graphs or summary statistics should be provided in spreadsheet form as supporting information.</p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>Reviewer #3: Yes</p>
    <p>**********</p>
    <p>PLOS authors have the option to publish the peer review history of their article (<ext-link ext-link-type="uri" xlink:href="https://journals.plos.org/ploscompbiol/s/editorial-and-peer-review-process#loc-peer-review-history">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>&lt;br \\&gt;</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p>&lt;br \\&gt;</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link ext-link-type="uri" xlink:href="https://www.plos.org/privacy-policy">Privacy Policy</ext-link>.</p>
    <p>Reviewer #1: Yes: Oscar Esteban</p>
    <p>Reviewer #2: No</p>
    <p>Reviewer #3: Yes: Pierre Bellec</p>
    <supplementary-material content-type="local-data" id="pcbi.1007549.s004">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">PCOMPBIOL-D-19-01130_R1.pdf</named-content></p>
      </caption>
      <media xlink:href="pcbi.1007549.s004.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article id="pcbi.1007549.r004" article-type="editor-report">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1007549.r004</article-id>
    <title-group>
      <article-title>Acceptance letter</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Marinazzo</surname>
          <given-names>Daniele</given-names>
        </name>
        <role>Deputy Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2020 Daniele Marinazzo</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Daniele Marinazzo</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article id="rel-obj004" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1007549" related-article-type="reviewed-article"/>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">9 Dec 2019</named-content>
    </p>
    <p>PCOMPBIOL-D-19-01130R1 </p>
    <p>BrainIAK tutorials: User-friendly learning materials for advanced fMRI analysis</p>
    <p>Dear Dr Kumar,</p>
    <p>I am pleased to inform you that your manuscript has been formally accepted for publication in PLOS Computational Biology. Your manuscript is now with our production department and you will be notified of the publication date in due course.</p>
    <p>The corresponding author will soon be receiving a typeset proof for review, to ensure errors have not been introduced during production. Please review the PDF proof of your manuscript carefully, as this is the last chance to correct any errors. Please note that major changes, or those which affect the scientific understanding of the work, will likely cause delays to the publication date of your manuscript. </p>
    <p>Soon after your final files are uploaded, unless you have opted out, the early version of your manuscript will be published online. The date of the early version will be your article's publication date. The final article will be published to the same URL, and all versions of the paper will be accessible to readers.</p>
    <p>Thank you again for supporting PLOS Computational Biology and open-access publishing. We are looking forward to publishing your work! </p>
    <p>With kind regards,</p>
    <p>Laura Mallard</p>
    <p>PLOS Computational Biology | Carlyle House, Carlyle Road, Cambridge CB4 3DN | United Kingdom <email>ploscompbiol@plos.org</email> | Phone +44 (0) 1223-442824 | <ext-link ext-link-type="uri" xlink:href="http://ploscompbiol.org">ploscompbiol.org</ext-link> | @PLOSCompBiol</p>
  </body>
</sub-article>
