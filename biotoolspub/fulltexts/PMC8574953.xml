<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Brief Bioinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Brief Bioinform</journal-id>
    <journal-id journal-id-type="publisher-id">bib</journal-id>
    <journal-title-group>
      <journal-title>Briefings in Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1467-5463</issn>
    <issn pub-type="epub">1477-4054</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8574953</article-id>
    <article-id pub-id-type="pmid">34160596</article-id>
    <article-id pub-id-type="doi">10.1093/bib/bbab228</article-id>
    <article-id pub-id-type="publisher-id">bbab228</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Problem Solving Protocol</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>LSTM-PHV: prediction of human-virus protein–protein interactions by LSTM with word2vec</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Tsukiyama</surname>
          <given-names>Sho</given-names>
        </name>
        <aff><institution>Department of Interdisciplinary Informatics in the Kyushu Institute of Technology</institution>, <country country="JP">Japan</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hasan</surname>
          <given-names>Md Mehedi</given-names>
        </name>
        <aff><institution>Tulane University</institution>, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fujii</surname>
          <given-names>Satoshi</given-names>
        </name>
        <aff><institution>Department of Bioscience and Bioinformatics in the Kyushu Institute of Technology</institution>, <country country="JP">Japan</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kurata</surname>
          <given-names>Hiroyuki</given-names>
        </name>
        <!--kurata@bio.kyutech.ac.jp-->
        <aff><institution>Department of Bioscience and Bioinformatics in the Kyushu Institute of Technology</institution>, <country country="JP">Japan</country></aff>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="cor1">Corresponding author: Hiroyuki Kurata, Department of Bioscience and Bioinformatics, Kyushu Institute of Technology, 680-4 Kawazu, Iizuka, Fukuoka 820-8502, Japan. E-mail: <email>kurata@bio.kyutech.ac.jp</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>11</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-06-23">
      <day>23</day>
      <month>6</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>23</day>
      <month>6</month>
      <year>2021</year>
    </pub-date>
    <volume>22</volume>
    <issue>6</issue>
    <elocation-id>bbab228</elocation-id>
    <history>
      <date date-type="received">
        <day>3</day>
        <month>3</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>27</day>
        <month>4</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>25</day>
        <month>5</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="bbab228.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>Viral infection involves a large number of protein–protein interactions (PPIs) between human and virus. The PPIs range from the initial binding of viral coat proteins to host membrane receptors to the hijacking of host transcription machinery. However, few interspecies PPIs have been identified, because experimental methods including mass spectrometry are time-consuming and expensive, and molecular dynamic simulation is limited only to the proteins whose 3D structures are solved. Sequence-based machine learning methods are expected to overcome these problems. We have first developed the LSTM model with word2vec to predict PPIs between human and virus, named LSTM-PHV, by using amino acid sequences alone. The LSTM-PHV effectively learnt the training data with a highly imbalanced ratio of positive to negative samples and achieved AUCs of 0.976 and 0.973 and accuracies of 0.984 and 0.985 on the training and independent datasets, respectively. In predicting PPIs between human and unknown or new virus, the LSTM-PHV learned greatly outperformed the existing state-of-the-art PPI predictors. Interestingly, learning of only sequence contexts as words is sufficient for PPI prediction. Use of uniform manifold approximation and projection demonstrated that the LSTM-PHV clearly distinguished the positive PPI samples from the negative ones. We presented the LSTM-PHV online web server and support data that are freely available at <ext-link xlink:href="http://kurata35.bio.kyutech.ac.jp/LSTM-PHV" ext-link-type="uri">http://kurata35.bio.kyutech.ac.jp/LSTM-PHV</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>LSTM</kwd>
      <kwd>word2vec</kwd>
      <kwd>human-virus protein–protein interaction</kwd>
      <kwd>deep learning</kwd>
      <kwd>SARS-CoV2</kwd>
    </kwd-group>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Japan Society for the Promotion of Science</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001691</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>19H04208</award-id>
        <award-id>19F19377</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Introduction</title>
    <p>Viral infections are one of the major causes of human health, as we can see from the current status of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) that raises a global pandemic. As of February 2021, more than 110 million people infected and nearly 2.4 million deaths have been reported worldwide for the coronavirus disease 2019 (COVID-19) disease [<xref rid="ref1" ref-type="bibr">1</xref>]. Viruses achieve their own life cycle and proliferate their clones by hijacking and utilizing the functions of their hosts. To carry out these processes, viruses interact with host proteins to control cell cycles and apoptosis and to transport their own genetic material into the host nucleus [<xref rid="ref2" ref-type="bibr">2</xref>, <xref rid="ref3" ref-type="bibr">3</xref>]. Therefore, it is important to identify human-virus protein–protein interactions (HV-PPIs) and to understand the mechanisms of viral infections and host immune responses to find new drug targets. However, compared to intraspecies PPIs, few interspecies PPIs have been identified. To identify the PPIs, experimental methods such as yeast-to-hybrid and mass spectrometry have been widely used [<xref rid="ref4" ref-type="bibr">4</xref>, <xref rid="ref5" ref-type="bibr">5</xref>], but they are time-consuming and laborious. For this reason, it is difficult to apply experimental methods for all protein pairs. Therefore, the computational approach is a preliminary treatment prior to the experimental method.</p>
    <p>The use of amino acid sequence information is promising in the prediction of PPIs because the experimental data of PPIs and sequence information of proteins are abundant. Machine learning (ML)-based approaches are very attractive [<xref rid="ref6" ref-type="bibr">6</xref>] that use the amino acid binary profiles [<xref rid="ref7" ref-type="bibr">7</xref>], evolutionary properties [<xref rid="ref8" ref-type="bibr">8</xref>], physicochemical properties [<xref rid="ref9" ref-type="bibr">9</xref>] and structural information [<xref rid="ref10" ref-type="bibr">10</xref>]. Zhou <italic toggle="yes">et al</italic>. [<xref rid="ref11" ref-type="bibr">11</xref>] integrated different encoding methods, such as relative frequency of amino acid triplets, frequency difference of amino acid triplets and amino acid composition to construct a SVM-based PPI predictor [<xref rid="ref11" ref-type="bibr">11</xref>]. Yang <italic toggle="yes">et al</italic>. [<xref rid="ref12" ref-type="bibr">12</xref>] have employed a position-specific scoring matrix (PSSM) to build a convolutional neural network (CNN) for PPI prediction. Recently, promising encoding schemes have been proposed to capture the sequence patterns of proteins, including the conjoint triad [<xref rid="ref13" ref-type="bibr">13</xref>], auto covariance [<xref rid="ref14" ref-type="bibr">14</xref>] and autocorrelation [<xref rid="ref15" ref-type="bibr">15</xref>].</p>
    <p>Human-virus PPIs involve not only the various properties of amino acid sequences but also the distributions of 20 amino acid residues in the context of whole protein sequences. While many predictors have focused on the former features, the latter context-based information is suggested to be effective in predicting HV-PPIs. To capture the context information of amino acid sequences as much as possible, word/document embedding techniques have recently been proposed. Yang <italic toggle="yes">et al</italic>. [<xref rid="ref16" ref-type="bibr">16</xref>] combined the doc2vec encoding schemes with a random forest method to predict PPIs.</p>
    <p>To utilize the amino acid sequence context as words effectively, we have proposed the long short-term memory (LSTM) model [<xref rid="ref17" ref-type="bibr">17</xref>] with the word2vec embedding method that predicts the PPIs between human and virus, named LSTM-PHV. To the best of our knowledge, this is the first application of the LSTM with the word2vec to sequence-based PPI prediction. Interestingly, use of the sequence context as words presented remarkably accurate prediction of the interactions between human and unknown virus proteins.</p>
  </sec>
  <sec id="sec2">
    <title>Materials and methods</title>
    <sec id="sec3">
      <title>Benchmark dataset construction</title>
      <p>The PPIs datasets were downloaded from the Host-Pathogen Interaction Database 3.0 (HPIDB 3.0) [<xref rid="ref18" ref-type="bibr">18</xref>]. The retrieved HV-PPIs were further selected in the following process. First, to ensure interactions with a certain level of confidence, the PPIs with an MI score of below 0.3 were removed. The MI score is the confidence score assigned to each PPI from IntAct [<xref rid="ref19" ref-type="bibr">19</xref>] and VirHostNet [<xref rid="ref20" ref-type="bibr">20</xref>]. Second, redundant PPIs were excluded by using CD-HIT with an identity threshold of 0.95 [<xref rid="ref21" ref-type="bibr">21</xref>]. Third, the PPIs that contained the proteins consisting of standard amino acids only and the proteins with a length of more than 30 residues and less than 1000 residues were selected. Finally, 22 383 PPIs from 5882 human and 996 virus proteins were considered as positive samples.</p>
      <p>To the best of our knowledge, there is no gold standard for generating negative samples. Many previous studies used a random sampling method. Pairs of the human and virus proteins that do not appear in the positive PPI dataset are randomly sampled as negative data. However, the random sampling method may incorrectly assign many positive samples to negative ones [<xref rid="ref9" ref-type="bibr">9</xref>, <xref rid="ref22" ref-type="bibr">22</xref>]. To address this problem, the dissimilarity negative sampling method was developed [<xref rid="ref9" ref-type="bibr">9</xref>], which used a sequence similarity-based method to explore the protein pairs that are unlikely to interact. We employed the dissimilarity-based negative sampling method as follows. We calculated the sequence similarities of all pairs of virus proteins in positive samples with the Needleman–Wunsch algorithm of BLOSUM30 and defined a similarity vector for each virus protein. Subsequently, we excluded the virus proteins showing lower sequence similarities than <inline-formula><tex-math id="M1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$Ts$\end{document}</tex-math></inline-formula> for more than half of the total virus proteins as outliers. <inline-formula><tex-math id="M2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$Ts$\end{document}</tex-math></inline-formula> was calculated by:<disp-formula id="deqn01"><label>(1)</label><tex-math id="M3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} {Ts}_i={fq}_i-1.5\times{ir}_i \end{equation*}\end{document}</tex-math></disp-formula>where <inline-formula><tex-math id="M4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${fq}_i$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${ir}_i$\end{document}</tex-math></inline-formula> are the first quartile and quartile range of the similarity scores for the <inline-formula><tex-math id="M6">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$i$\end{document}</tex-math></inline-formula>-th virus protein <inline-formula><tex-math id="M7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${V}_i$\end{document}</tex-math></inline-formula>, respectively. By setting the maximum and minimum values of the similarity scores to 0 and 1, respectively, the similarity score was normalized and converted into the distance.</p>
      <p>The human proteins that consisted of the standard amino acids and whose residue length was longer than 30 and shorter than 1000 were retrieved from the UniProtKB/Swiss-Prot database [<xref rid="ref23" ref-type="bibr">23</xref>]. Then, the human proteins that interacted with the virus proteins showing a distance from viral protein <inline-formula><tex-math id="M8">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${V}_i$\end{document}</tex-math></inline-formula> of less than distance threshold <italic toggle="yes">T</italic> were removed, considering that they were likely to interact with virus protein <inline-formula><tex-math id="M9">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${V}_i$\end{document}</tex-math></inline-formula>. The remaining pairs of the human and virus proteins were regarded as negative samples. According to the previous study [<xref rid="ref9" ref-type="bibr">9</xref>], the threshold <inline-formula><tex-math id="M10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$T$\end{document}</tex-math></inline-formula> was set to 0.8. We randomly sampled from the candidates so that the ratio of positive to negative samples was 1:10. The positive and negative samples were labeled 1 and 0, respectively. The resultant dataset was divided into training data and independent test data at a ratio of 8:2.</p>
    </sec>
    <sec id="sec4">
      <title>SARS-CoV-2 PPIs dataset construction</title>
      <p>We downloaded the datasets of SARS-CoV-2 from BioGRID (COVID-19 Coronavirus Project 4.3.195) [<xref rid="ref24" ref-type="bibr">24</xref>] and extracted the PPIs between human and SARS-CoV-2. We removed the PPIs having the proteins whose amino acid sequences were not registered in the UniProtKB database [<xref rid="ref23" ref-type="bibr">23</xref>]. We further removed the PPIs that contained nonstandard amino acids and the proteins with a length of fewer than 30 residues and more than 1000 residues. Finally, we obtained 7373 PPIs that consisted of 2943 human proteins and 11 SARS-CoV-2 proteins as the positive samples. The negative samples were generated by the dissimilarity negative sampling method. We randomly selected negative samples so that the ratio of positive to negative samples was 1:10. The resultant dataset was divided into training data and independent test data at a ratio of 8:2.</p>
    </sec>
    <sec id="sec5">
      <title>Nonviral pathogen PPIs dataset construction</title>
      <p>In order to investigate whether our model can be extended to pathogens other than viruses, we constructed the datasets of PPIs between human and nonviral pathogens. The PPIs having virus proteins were excluded from the PPI dataset of HPIDB. The PPIs were prepared in the same manner as the benchmark dataset construction mentioned above. Subsequently, 8412 PPIs consisting of 3317 human proteins and 3068 virus proteins were selected as positive data. The negative datasets were generated by the dissimilarity negative sampling method. We randomly selected negative samples so that the ratio of positive to negative samples was 1:10. The resultant dataset was divided into training data and independent test data at a ratio of 8:2.</p>
    </sec>
    <sec id="sec6">
      <title>Embedding of protein sequences by word2vec</title>
      <p>In the field of natural language processing, embedding methods such as word2vec [<xref rid="ref25" ref-type="bibr">25</xref>] and doc2vec [<xref rid="ref26" ref-type="bibr">26</xref>] were developed to obtain the distributed representation of words and documents, respectively. In word2vec, the weights in a neural network learn the context of words to provide the distributed representation that encodes different linguistic regularities and patterns [<xref rid="ref27" ref-type="bibr">27</xref>]. There are two methods for learning the context of words: Continuous Bag-of-Words Model (CBOW) and the Continuous Skip-Gram Model (Skip-Gram). CBOW predicts the current word based on the context, while Skip-Gram predicts the context from the current word. Skip-gram is more efficient with less training data, while CBOW learns faster and more frequent words. At present, computational biology used these methods [<xref rid="ref28" ref-type="bibr">28</xref>, <xref rid="ref29" ref-type="bibr">29</xref>].</p>
      <p>The amino acid sequences of human and virus proteins registered as positive and negative samples were encoded as matrixes using the word2vec method. The k-mers (k consecutive amino acids) in amino acid sequences were regarded as a single word (unit) and each amino acid sequence was represented by multiple k-mers. For example, given an amino acid sequence MAEDDPYL, the units of the 4-mers are MAED, AEDD, EDDP, DDPY and DPYL (<xref rid="f1" ref-type="fig">Figure 1</xref>). We trained a CBOW-based word2vec model to learn the appearance pattern of k-mers from the computational speed standpoint by using the genism of the python package [<xref rid="ref30" ref-type="bibr">30</xref>]. Here, k-mers and protein sequences correspond to words and sentences in natural language. Human and virus proteins in positive samples and nonredundant proteins in the UniProtKB/Swiss-Prot database [<xref rid="ref23" ref-type="bibr">23</xref>] were used to train the word2vec model. The nonredundant proteins were collected by applying CD-HIT to all proteins with an identity threshold of 0.9. The k-mers up to three neighbors of a specific k-mer are considered as the peripheral k-mers, and training was iterated 1000 times. The trained word2vec model produced 128-dimensional embedding vectors in each k-mer and they were concatenated to produce the embedding matrixes of proteins. Since 4-mer provided the largest AUC by 5-fold cross-validation in a previous study [<xref rid="ref16" ref-type="bibr">16</xref>], we set k to 4.</p>
      <fig position="float" id="f1">
        <label>
Figure 1
</label>
        <caption>
          <p>Embedding of amino acid sequences in a case of 4-mer. Amino acid sequences were represented by 4-mers and embedded as a matrix by training the word2vec model. The matrixes were generated by concatenating the vectors of 4-mers in a row.</p>
        </caption>
        <graphic xlink:href="bbab228f1" position="float"/>
      </fig>
    </sec>
    <sec id="sec7">
      <title>Construction of LSTM-PHV</title>
      <p>Neural networks such as CNN and recurrent neural network (RNN), in particular, are very powerful and have been applied to difficult problems such as speech recognition and visual object recognition [<xref rid="ref31" ref-type="bibr">31</xref>]. The RNN learns time or step dependencies in sequence data and enables training on variable-length data. The LSTM solves the gradient explosion and gradient disappearance problems of RNNs, enabling long-term time-dependent learning.</p>
      <p>The LSTM-PHV is composed of three sub-networks, as shown in <xref rid="f2" ref-type="fig">Figure 2</xref>. The two, upstream networks with the same structure transformed the human and virus proteins-embedding matrixes into two fixed-length vectors. The third network used their concatenated fixed-length vectors to predict the PPIs. They are referred to as ‘concatenated vectors’. The amino acid sequence column vectors in the embedding matrixes are inputted to each step of the LSTM units. The LSTM units were expanded in both the N- to C-terminus and the C- to N-terminus directions. The 64 × 2-dimensional vectors generated from one LSTM unit were concatenated in a row. The dimensions of the vectors generated through the three layers decreased in the order of 64, 32 and 1. In the first two layers, the rectified linear unit (ReLU) function with a dropout rate of 0.3 was used as an activation function. The scalar values generated from the third layer were lined up into a vector, which was provided to the softmax function. A fixed-length vector was generated by summarizing the weighted vectors in all the steps.</p>
      <fig position="float" id="f2">
        <label>
Figure 2
</label>
        <caption>
          <p>Network structure of LSTM-PHV. The human and virus protein matrices were transformed into the two fixed-length vectors by the two upstream neural networks with the LSTM, respectively. The networks were surrounded by blue and red lines. Feature vectors of each 4-mer in protein matrices were inputted into the LSTM unit at each step. Scalar values were generated by applying three fully connected layers to output from the LSTM unit at each step. The broadcasted scalar values and output from the LSTM unit were multiplied. The fixed-length vectors were produced by adding the multiplied vectors and concatenating the vectors in human and virus. Final outputs were obtained by four fully connected layers surrounded by the purple line.</p>
        </caption>
        <graphic xlink:href="bbab228f2" position="float"/>
      </fig>
      <p>The fixed-length vectors for the human and virus proteins were concatenated in line and propagated into the final network. The final network consists of three layers and an output layer. The dimensions of the generated vectors from each layer decreased in the order of 200, 100, 40 and 1. The ReLU function with a dropout rate of 0.3 was applied to the output of the three layers. To obtain a final output with a value between 0 and 1, the sigmoid function was used as an activation function at the output layer. The construction and learning of the neural networks were performed using the PyTorch [<xref rid="ref32" ref-type="bibr">32</xref>] of the python package.</p>
    </sec>
    <sec id="sec8">
      <title>Training of imbalanced data</title>
      <p>A 5-fold cross-validation was applied on the training dataset, while conserving the ratio of positive and negative samples at each subset. We set the learning rate to 0.001, used the rectified adam (RAdam) optimizer [<xref rid="ref33" ref-type="bibr">33</xref>] as the optimization function, and set a mini-batch learning size to 1024. To train the model on imbalanced data, we weighted a binary cross-entropy loss function in the manner reported by Cui <italic toggle="yes">et al</italic>. (2019) [<xref rid="ref34" ref-type="bibr">34</xref>]. The loss functions used are shown below.<disp-formula id="deqn02"><label>(2)</label><tex-math id="M11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} CE\left(p,y\right)=-\frac{1-\beta }{1-{\beta}^{n_y}}\left\{\left(y\times logx+\left(1-y\right)\times \log \left(1-x\right)\right)\right\}, \end{equation*}\end{document}</tex-math></disp-formula>where <inline-formula><tex-math id="M12">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$y$\end{document}</tex-math></inline-formula> is the correct label, <inline-formula><tex-math id="M13">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$x$\end{document}</tex-math></inline-formula> is the model-predicted probability of interaction, <inline-formula><tex-math id="M14">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${n}_y$\end{document}</tex-math></inline-formula> is the number of data whose label is <inline-formula><tex-math id="M15">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$y$\end{document}</tex-math></inline-formula> in the mini-batch and <inline-formula><tex-math id="M16">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\beta$\end{document}</tex-math></inline-formula> is the hyperparameter. <inline-formula><tex-math id="M17">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\beta$\end{document}</tex-math></inline-formula> was set to 0.99. To prevent overlearning, the training process was terminated when the maximum accuracy in the validation data was not updated for consecutive 20 epochs. To prevent the weight of the loss function from being 0, we set an approximately equal ratio of labels for all the mini-batches.</p>
      <fig position="float" id="f3">
        <label>
Figure 3
</label>
        <caption>
          <p>Performance of the LSTM-PHV via 5-fold cross-validation on the training dataset. The measures of the five subset models in 5-fold cross-validation were averaged.</p>
        </caption>
        <graphic xlink:href="bbab228f3" position="float"/>
      </fig>
      <fig position="float" id="f4">
        <label>
Figure 4
</label>
        <caption>
          <p>Performance comparison of LSTM-PHV with Yang’s RF model with doc2vec using our independent test. Thresholds at SP of 0.90, 0.95 and 0.99 in Yang’s study were used according to their suggestion.</p>
        </caption>
        <graphic xlink:href="bbab228f4" position="float"/>
      </fig>
    </sec>
    <sec id="sec9">
      <title>Measures</title>
      <p>To evaluate the prediction performance, seven statistics measures were used: sensitivity (SN; recall), specificity (SP), accuracy (ACC), Matthews correlation coefficient (MCC), positive predictive value (PPV), F1-score (F1), area under the curve (AUC) and area under the precision-recall curve (AUPRC). MCC, F1-score and AUPRC are effective in assessments of imbalanced data. The measures other than the AUC and AUPRC are given by:<disp-formula id="deqn03"><label>(3)</label><tex-math id="M18">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{SN}\ \left(\mathrm{recall}\right)=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}} \end{equation*}\end{document}</tex-math></disp-formula><disp-formula id="deqn04"><label>(4)</label><tex-math id="M19">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{SP}=\frac{\mathrm{TN}}{\mathrm{TN}+\mathrm{FP}} \end{equation*}\end{document}</tex-math></disp-formula><disp-formula id="deqn05"><label>(5)</label><tex-math id="M20">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{ACC}=\frac{\mathrm{TP}+\mathrm{TN}}{\mathrm{TP}+\mathrm{TN}+\mathrm{FP}+\mathrm{FN}} \end{equation*}\end{document}</tex-math></disp-formula><disp-formula id="deqn06"><label>(6)</label><tex-math id="M21">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{MCC}=\frac{\mathrm{TP}\times \mathrm{TN}-\mathrm{FP}\times \mathrm{FN}}{\sqrt{\left(\mathrm{TN}+\mathrm{FN}\right)\times \left(\mathrm{TP}+\mathrm{FP}\right)\times \left(\mathrm{TN}+\mathrm{FP}\right)\times \left(\mathrm{TP}+\mathrm{FN}\right)}} \end{equation*}\end{document}</tex-math></disp-formula><disp-formula id="deqn07"><label>(7)</label><tex-math id="M22">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{PPV}=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FP}} \end{equation*}\end{document}</tex-math></disp-formula><disp-formula id="deqn08"><label>(8)</label><tex-math id="M23">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{F}1=\frac{2\times \mathrm{precision}\times \mathrm{recall}}{\mathrm{precision}+\mathrm{recall}} \end{equation*}\end{document}</tex-math></disp-formula>where TP, FP, TN and FN are the numbers of the correctly predicted positive samples, incorrectly predicted positive samples, correctly predicted negative samples and incorrectly predicted negative samples, respectively. The threshold for a determination of whether protein pairs interact or not was set to a predicted probability of 0.5. AUC and AUPRC are the areas beneath the ROC curve and PR curve, respectively. These measures were calculated by the scikit-learn of the python package [<xref rid="ref35" ref-type="bibr">35</xref>].</p>
    </sec>
    <sec id="sec10">
      <title>Visualization of positive and negative samples</title>
      <p>To visualize the concatenated vectors, we reduced the dimensionality of the concatenated vector from 256 to 2 using uniform manifold approximation and projection (UMAP) [<xref rid="ref36" ref-type="bibr">36</xref>]. UMAP is the nonlinear dimensionality reduction approach [<xref rid="ref36" ref-type="bibr">36</xref>], which can preserve not only local patterns but also global patterns in low-dimensional space. We set the number of neighbors in the k-neighbor graph to 50, and set a minimum distance between points in the low-dimensional space to 0. The distances between any points were calculated by the Euclidean distance. The optimization was implemented up to 500 epochs with a learning rate of 1.0.</p>
      <fig position="float" id="f5">
        <label>
Figure 5
</label>
        <caption>
          <p>Prediction performance of LSTM-PHV with existing state-of-the-art predictors. We employed the four datasets that combine the four training data with two test data according to Zhou’s study. The four datasets containing human–virus interactions (TR1-TS1 and TR2-TS2) and multiple host–virus interactions (TR3-TS1 and TR4-TS2) were applied to LSTM-PHV. The performances of the Zhou’s model are from table 5 of their paper.</p>
        </caption>
        <graphic xlink:href="bbab228f5" position="float"/>
      </fig>
      <fig position="float" id="f6">
        <label>
Figure 6
</label>
        <caption>
          <p>Comparison of the dissimilarity negative sampling method with a random sampling method. A 5-fold cross-validation was applied to the training data generated by the dissimilarity negative sampling method and by a random sampling method. The bars and error bars indicate the mean and standard deviation of AUC and AUPRC in the five subset models.</p>
        </caption>
        <graphic xlink:href="bbab228f6" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec id="sec11">
    <title>Results and discussion</title>
    <sec id="sec12">
      <title>Predictive performance of LSTM-PHV</title>
      <p>We evaluated the predictive performance of LSTM-PHV via 5-fold cross-validation on the training dataset and test it on the independent dataset, as shown in <xref rid="f3" ref-type="fig">Figure 3</xref> and <xref rid="sup1" ref-type="supplementary-material">Table S1</xref>. Out of the five subset models, the model with the highest AUC was used to predict the independent dataset. The AUCs were 0.976 and 0.973 on the training and independent datasets, respectively; the ACCs were 0.984 and 0.985 on the training and independent datasets, respectively. The MCC, F1 and AUPRC also presented high scores on both the datasets. MCC has been used in many previous studies in bioinformatics as an evaluation measure for imbalance data [<xref rid="ref16" ref-type="bibr">16</xref>, <xref rid="ref37" ref-type="bibr">37</xref>, <xref rid="ref38" ref-type="bibr">38</xref>]. A high MCC indicated that the LSTM-PHV was able to effectively learn the imbalanced data. LSTM-PHV provided remarkable performance of PPI prediction.</p>
    </sec>
    <sec id="sec13">
      <title>Performance comparison with state-of-the-art existing machine learning models</title>
      <p>To characterize the performance of LSTM-PHV, we compared it with an RF model with Doc2vec, named Yang’s model [<xref rid="ref16" ref-type="bibr">16</xref>], on our independent test data, as shown in <xref rid="f4" ref-type="fig">Figure 4</xref> and <xref rid="sup1" ref-type="supplementary-material">Table S2</xref>. The source code and trained model were provided by Yang <italic toggle="yes">et al</italic>. with their recommended three threshold values. As in our case, Yang <italic toggle="yes">et al</italic>. built the imbalanced data that contained 10 times more negative samples than positive samples, while generating negative samples by the dissimilarity-based negative sampling method. The LSTM-PHV presented higher values than Yang’s model not only for AUC and ACC but also for MCC, F1-score and AUPRC (<xref rid="f4" ref-type="fig">Figure 4</xref>). The LSTM-PHV was able to learn the imbalanced data better than Yang’s model. Particularly, LSTM-PHV takes an advantage in the high MCC value, because learning of imbalanced data is not evitable. At present the number of known PPIs is very small compared to the total number of protein pairs. Thus, negative samples are typically produced much more than positive ones in the absence of golden standard of generating negative samples.</p>
      <p>The LSTM-PVM that combined LSTM with word2vec outperformed the latest state-of-the-art model of Yang’s RF model, probably because LSTM was able to efficiently capture the context of amino acid sequence patterns. Interestingly, we revealed that learning of only sequence contexts as words presented remarkably high performances without any biochemical properties.</p>
      <fig position="float" id="f7">
        <label>
Figure 7
</label>
        <caption>
          <p>UMAP map of the positive and negative samples of our benchmark dataset. (A) The concatenated vectors provided in the 5-fold cross-validation, which showed the highest value of AUC for all the five, were projected. (B) The concatenated vectors provided in the independent test were projected. The true positive, false positive, false negative and true negative samples were visualized.</p>
        </caption>
        <graphic xlink:href="bbab228f7" position="float"/>
      </fig>
      <p>To assess whether the LSTM-PHV is applicable to unknown virus species, we compared LSTM-PHV with a SVM model with commonly used encoding methods, named Zhou’s model [<xref rid="ref11" ref-type="bibr">11</xref>]. We employed Zhou’s dataset that consisted of the four training datasets: PPIs between human and any virus except Influenza A virus subtype H1N1 (H1N1) (TR1), PPIs between human and any virus except <italic toggle="yes">Ebola virus</italic> (TR2), PPIs between any host and any virus except H1N1 (TR3), PPIs between any host and any virus except <italic toggle="yes">Ebola virus</italic> (TR4) and two test datasets: PPIs between human and H1N1 virus (TS1) and PPIs between human and <italic toggle="yes">Ebola virus</italic> (TS2). In training the LSTM-PHV, we set a batch size to 256 and used the normal binary cross-entropy loss function, because Zhou’s datasets were much smaller than our dataset and it was balanced data. As shown in <xref rid="f5" ref-type="fig">Figure 5</xref> and <xref rid="sup1" ref-type="supplementary-material">Table S3</xref>, we compared the LSTM-PHV with Zhou’s SVM model on the four datasets. We trained the LSTM-PHV by the same datasets of TR1 and TR2 that do not include the PPIs between human and H1N1 and <italic toggle="yes">Ebola virus</italic>, respectively. Compared to Zhou’s model, the LSTM-PHV predicted TS1 and TS2 with high ACC and AUC. When the predictors were trained on multiple host protein-including TR3 and TR4, the LSTM-PHV also presented higher ACC and AUC to predict TS1 and TS2. The AUCs on the four datasets were significantly different between LSTM-PHV and Zhou’s model (two-sample <italic toggle="yes">t</italic>-test; <italic toggle="yes">P</italic> &lt; 0.05). LSTM-PHV learnt host and virus protein sequence contexts more efficiently than the SVM model.</p>
      <p>Very recently, Yang <italic toggle="yes">et al</italic>. [<xref rid="ref12" ref-type="bibr">12</xref>] have proposed a CNN-based PPI predictor with a PSSM. They generated the PSSM by applying PSI-BLAST to amino acid sequences, and then inputted the PSSM to a CNN as a feature matrix. CNNs take in an advantage in learning the features of noncontinuous data such as image data, while LSTMs (RNN-type models) effectively learn the long-term memory features. Our LSTM-PHV achieved high prediction performance of human-virus PPIs. Differing from Yang’s model, we used LSTM to intensively read the contexts of the whole amino acid sequences.</p>
    </sec>
    <sec id="sec14">
      <title>Prediction of SARS-CoV-2 and nonviral pathogens PPIs</title>
      <p>To demonstrate the applicability of LSTM-PHV to other species, we applied it to PPIs between human and SARS-CoV-2. A 5-fold cross-validation was performed on the training dataset. The subset model providing the highest AUC for all the five was employed as the final model and tested on the independent dataset. LSTM-PHV achieved AUCs of 0.955 and 0.956 in 5-fold cross-validation and independent test, respectively (<xref rid="sup1" ref-type="supplementary-material">Table S4</xref>). Our method was found available to prediction of the human and SARS-CoV-2 PPIs.</p>
      <p>Furthermore, to investigate whether LSTM-PHV can be extended to nonviral pathogens, we applied it to PPIs between human and nonviral pathogens. A 5-fold cross-validation was carried on the training dataset. The subset model providing the highest AUC for all the five was employed as the final model and tested on the independent dataset. LSTM-PHV achieved AUCs of 0.920 and 0.922 in 5-fold cross-validation and independent test, respectively (<xref rid="sup1" ref-type="supplementary-material">Table S5</xref>). These results demonstrated that LSTM-PHV can be extended to predict the PPIs between human and nonviral pathogens.</p>
    </sec>
    <sec id="sec15">
      <title>Superiority of dissimilarity negative sampling method</title>
      <p>To demonstrate the superiority of the dissimilarity negative sampling method, we compared it with a random negative sampling method, as shown in <xref rid="f6" ref-type="fig">Figure 6</xref> and <xref rid="sup1" ref-type="supplementary-material">Table S6</xref>. A 5-fold cross-validation and the independent test were used. The AUC and AUPRC in the dissimilarity negative sampling method were higher than those in the random sampling method. The AUCs and AUPRCs by the 5-fold cross-validation were significantly different (two-sample <italic toggle="yes">t</italic>-test; <italic toggle="yes">P</italic> &lt; 0.0001) between the two methods. These results suggest some of the randomly generated-negative samples impair the prediction as noisy data.</p>
    </sec>
    <sec id="sec16">
      <title>Visualization of positive and negative samples</title>
      <p>The two upstream neural networks with the LSTM generated the fixed-length vectors (<xref rid="f2" ref-type="fig">Figure 2</xref>). To examine how these neural networks extract PPI-related information, we drew the UMAP map of their concatenated vectors on the training and independent datasets of our benchmark dataset (<xref rid="f7" ref-type="fig">Figure 7</xref>). In addition, we made the t-SNE map of them (<xref rid="sup1" ref-type="supplementary-material">Figure S1</xref>). In both the UMAP and T-SNE maps, multiple clusters were generated, and positive samples were distinguished from negative samples within the clusters. The false negative and false positive samples were located between the true negative and true positive sample<strike>s</strike>. The numbers of the false negative and false positive samples were small. These results suggested that the upstream neural networks extract critical information responsible for predicting PPIs from the amino acid sequences of each protein. The UMAP accumulated the true positive samples more densely than t-SNE, which corresponded to the previous suggestion [<xref rid="ref39" ref-type="bibr">39</xref>] that UMAP preserves not only local structure but also the global structure. The LSTM-PHV showed almost similar distributions between the training and independent datasets in both the UMAP and t-SNE, demonstrating the robustness of LSTM-PHV to an independent dataset or to changes in datasets.</p>
    </sec>
    <sec id="sec17">
      <title>Webserver implementation</title>
      <p>We used apache (2.4.18), python (3.8.0) and flask (1.1.2) to build a web server application of LSTM-PHV at <ext-link xlink:href="http://kurata35.bio.kyutech.ac.jp/LSTM-PHV" ext-link-type="uri">http://kurata35.bio.kyutech.ac.jp/LSTM-PHV</ext-link>. The users can either input or upload the amino acid sequences of human and virus proteins in FASTA format to evaluate the PPIs with prediction scores. In addition, the attention weights and transformed vectors generated during prediction are provided. A threshold to determine whether the inputted proteins interact was set to 0.5. To facilitate the community, we provide the datasets used in the present study, which can be downloaded from our website. For other overviews, refer to the help of the website.</p>
    </sec>
  </sec>
  <sec id="sec18">
    <title>Conclusions</title>
    <p>To accurately predict PPIs between human and virus, we proposed the LSTM-PHV that combined LSTM with the word2vec embedding method by considering the whole sequence context of amino acid residues. The word2vec is able to preserve the information about patterns of the local amino acid residues. Interestingly, the method does not use any biochemical properties of amino acid residues, while existing models intensively used their biochemical properties. The LSTM further learns the amino acid patterns in the whole sequence contexts. The LSTM-PHV learnt highly imbalanced data and was able to accurately predict the interaction of a human protein to an unknown virus protein, compared to existing state-of-the-art models. Interestingly, it could be extended not only to the PPIs between SARS-CoV-2 and human but also to the PPIs between nonviral pathogens and human. On the other hand, our method requires more memory or computational cost compared to existing models, because the number of elements in the feature matrix increases with an increase in the length of the sequence. Use of the LSTM-PHV enhances the screening of drug targets that inhibit human-virus PPIs and definitely contributes to advances in remedies of infectious diseases including COVID-19.</p>
    <boxed-text id="box01" position="float">
      <sec id="sec20z">
        <title>Key Points</title>
        <list list-type="bullet">
          <list-item>
            <p>The LSTM-based model with word2vec (LSTM-PHV) efficiently learns highly imbalanced training data to accurately predict PPIs between human and virus.</p>
          </list-item>
          <list-item>
            <p>Learning of amino acid sequence contexts as words without any biochemical properties is sufficient for PPI prediction.</p>
          </list-item>
          <list-item>
            <p>UMAP visualizes that positive samples are clearly distinguished from negative samples.</p>
          </list-item>
          <list-item>
            <p>LSTM-PHV is applied to prediction of the human and SARS-CoV-2 PPIs and human and nonviral pathogens PPIs.</p>
          </list-item>
        </list>
      </sec>
    </boxed-text>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>LSTM-PVH_suppl_r12_bbab228</label>
      <media xlink:href="lstm-pvh_suppl_r12_bbab228.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec id="bbab228-ack">
    <title>Acknowledgement</title>
    <p>This work was supported by the Grant-in-Aid for Scientific Research (B) (19H04208) and partially supported by the Grant-in-Aid for JSPS Research Fellow (19F19377) from Japan Society for the Promotion of Science (JSPS).</p>
  </sec>
  <notes id="bio3">
    <p><bold>Sho Tsukiyama</bold> is a student of Department of Interdisciplinary Informatics in the Kyushu Institute of Technology, Japan. His main research interests include machine learning and computational biology.</p>
    <p><bold>Md Mehedi Hasan</bold> is currently a postdoctoral fellow at the Tulane University, USA. Before his current position, he worked as a Japan Society for the Promotion of Science international PD fellow in the Kyushu Institute of Technology, Japan. He also worked as a researcher at the Chinese University of Hong Kong. He received his PhD degree in bioinformatics from the China Agricultural University, Beijing, in 2016. His main research interests include protein structure prediction, machine learning, data mining, computational biology and functional genomics.</p>
    <p><bold>Satoshi Fujii</bold> is an assistant professor of Department of Bioscience and Bioinformatics in the Kyushu Institute of Technology, Japan. His research interests include machine learning, clinical data analysis and biomedical design.</p>
    <p><bold>Hiroyuki Kurata</bold> is a professor of Department of Bioscience and Bioinformatics in the Kyushu Institute of Technology, Japan. His research interests primarily focus on systems biology, synthetics biology, functional genomics, machine learning and their applications.</p>
  </notes>
  <ref-list id="bib1">
    <title>References</title>
    <ref id="ref1">
      <label>1.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><collab>World Health Organization</collab></person-group>. <source>Coronavirus disease (covid-19) situation dashboard</source>. <ext-link xlink:href="https://covid19.who.int/" ext-link-type="uri">https://covid19.who.int/</ext-link><comment>(21 February 2021, date last accessed)</comment>.</mixed-citation>
    </ref>
    <ref id="ref2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>S</given-names></string-name>, <string-name><surname>Fu</surname><given-names>C</given-names></string-name>, <string-name><surname>Lian</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Understanding human-virus protein-protein interactions using a human protein complex-based analysis framework</article-title>. <source>mSystems</source><year>2019</year>;<volume>4</volume>:<fpage>e00303</fpage>–<lpage>18</lpage>.<pub-id pub-id-type="pmid">30984872</pub-id></mixed-citation>
    </ref>
    <ref id="ref3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dyer</surname><given-names>MD</given-names></string-name>, <string-name><surname>Murali</surname><given-names>TM</given-names></string-name>, <string-name><surname>Sobral</surname><given-names>BW</given-names></string-name></person-group>. <article-title>The landscape of human proteins interacting with viruses and other pathogens</article-title>. <source>PLoS Pathog</source><year>2008</year>;<volume>4</volume>(<issue>2</issue>):<fpage>e32</fpage>.<pub-id pub-id-type="pmid">18282095</pub-id></mixed-citation>
    </ref>
    <ref id="ref4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shoemaker</surname><given-names>BA</given-names></string-name>, <string-name><surname>Panchenko</surname><given-names>AR</given-names></string-name></person-group>. <article-title>Deciphering protein-protein interactions. Part I. experimental techniques and databases</article-title>. <source>PLoS Comput Biol</source><year>2007</year>;<volume>3</volume>(<issue>3</issue>):<fpage>e42</fpage>–<lpage>2</lpage>.<pub-id pub-id-type="pmid">17397251</pub-id></mixed-citation>
    </ref>
    <ref id="ref5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ito</surname><given-names>T</given-names></string-name>, <string-name><surname>Chiba</surname><given-names>T</given-names></string-name>, <string-name><surname>Ozawa</surname><given-names>R</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A comprehensive two-hybrid analysis to explore the yeast protein interactome</article-title>. <source>Proc Natl Acad Sci</source><year>2001</year>;<volume>98</volume>(<issue>8</issue>):<fpage>4569</fpage>–<lpage>74</lpage>.<pub-id pub-id-type="pmid">11283351</pub-id></mixed-citation>
    </ref>
    <ref id="ref6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Khatun</surname><given-names>MS</given-names></string-name>, <string-name><surname>Shoombuatong</surname><given-names>W</given-names></string-name>, <string-name><surname>Hasan</surname><given-names>MM</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Evolution of sequence-based bioinformatics tools for protein-protein interaction prediction</article-title>. <source>Curr Genomics</source><year>2020</year>;<volume>21</volume>(<issue>6</issue>):<fpage>454</fpage>–<lpage>63</lpage>.<pub-id pub-id-type="pmid">33093807</pub-id></mixed-citation>
    </ref>
    <ref id="ref7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>YA</given-names></string-name>, <string-name><surname>You</surname><given-names>ZH</given-names></string-name>, <string-name><surname>Chen</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Sequence-based prediction of protein-protein interactions using weighted sparse representation model combined with global encoding</article-title>. <source>BMC Bioinformatics</source><year>2016</year>;<volume>17</volume>(<issue>1</issue>):<fpage>184</fpage>.<pub-id pub-id-type="pmid">27112932</pub-id></mixed-citation>
    </ref>
    <ref id="ref8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hamp</surname><given-names>T</given-names></string-name>, <string-name><surname>Rost</surname><given-names>B</given-names></string-name></person-group>. <article-title>Evolutionary profiles improve protein-protein interaction prediction from sequence</article-title>. <source>Bioinformatics</source><year>2015</year>;<volume>31</volume>(<issue>12</issue>):<fpage>1945</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">25657331</pub-id></mixed-citation>
    </ref>
    <ref id="ref9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eid</surname><given-names>FE</given-names></string-name>, <string-name><surname>ElHefnawi</surname><given-names>M</given-names></string-name>, <string-name><surname>Heath</surname><given-names>LS</given-names></string-name></person-group>. <article-title>DeNovo: virus-host sequence-based protein-protein interaction prediction</article-title>. <source>Bioinformatics</source><year>2016</year>;<volume>32</volume>:<fpage>1144</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">26677965</pub-id></mixed-citation>
    </ref>
    <ref id="ref10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Neuvirth</surname><given-names>H</given-names></string-name>, <string-name><surname>Raz</surname><given-names>R</given-names></string-name>, <string-name><surname>Schreiber</surname><given-names>G</given-names></string-name></person-group>. <article-title>ProMate: a structure based prediction program to identify the location of protein-protein binding sites</article-title>. <source>J Mol Biol</source><year>2004</year>;<volume>338</volume>:<fpage>181</fpage>–<lpage>99</lpage>.<pub-id pub-id-type="pmid">15050833</pub-id></mixed-citation>
    </ref>
    <ref id="ref11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author">Zhou X, Park B, Choi D, <etal>et al.</etal></person-group><article-title>A generalized approach to predicting protein-protein interactions between virus and host</article-title>. <source>BMC Genomics</source><year>2018</year>;<volume>19</volume>:<fpage>568</fpage>.<pub-id pub-id-type="pmid">30367586</pub-id></mixed-citation>
    </ref>
    <ref id="ref12">
      <label>12.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>X</given-names></string-name>, <string-name><surname>Yang</surname><given-names>S</given-names></string-name>, <string-name><surname>Lian</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Transfer learning via multi-scale convolutional neural layers for human-virus protein-protein interaction prediction</article-title>. <source>bioRxiv</source><year>2021</year>; 4314202021. doi: <pub-id pub-id-type="doi">10.1101/2021.02.16.431420</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author">Wang J, Zhang L, Jia L, <etal>et al.</etal></person-group><article-title>Protein-protein interactions prediction using a novel local conjoint triad descriptor of amino acid sequences</article-title>. <source>Int J Mol Sci</source><year>2017</year>;<volume>18</volume>:2373.</mixed-citation>
    </ref>
    <ref id="ref14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yu</surname><given-names>L</given-names></string-name>, <string-name><surname>Wen</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Using support vector machine combined with auto covariance to predict protein-protein interactions from protein sequences</article-title>. <source>Nucleic Acids Res</source><year>2008</year>;<volume>36</volume>(<issue>9</issue>):<fpage>3025</fpage>–<lpage>30</lpage>.<pub-id pub-id-type="pmid">18390576</pub-id></mixed-citation>
    </ref>
    <ref id="ref15">
      <label>15.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Khatun</surname><given-names>MS</given-names></string-name>, <string-name><surname>Hasan</surname><given-names>MM</given-names></string-name>, <string-name><surname>Mollah</surname><given-names>MNH</given-names></string-name><etal>et al.</etal></person-group><part-title>SIPMA: A Systematic Identification of Protein-Protein Interactions in Zea mays Using Autocorrelation Features in a Machine-Learning Framework</part-title>. In: <source>2018 IEEE 18th International Conference on Bioinformatics and Bioengineering (BIBE)</source>. Taichung, Taiwan: IEEE, <year>2018</year>, <fpage>122</fpage>–<lpage>5</lpage>.</mixed-citation>
    </ref>
    <ref id="ref16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>X</given-names></string-name>, <string-name><surname>Yang</surname><given-names>S</given-names></string-name>, <string-name><surname>Li</surname><given-names>Q</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Prediction of human-virus protein-protein interactions through a sequence embedding-based machine learning method</article-title>. <source>Comput Struct Biotechnol J</source><year>2020</year>;<volume>18</volume>:<fpage>153</fpage>–<lpage>61</lpage>.<pub-id pub-id-type="pmid">31969974</pub-id></mixed-citation>
    </ref>
    <ref id="ref17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hochreiter</surname><given-names>S</given-names></string-name>, <string-name><surname>Schmidhuber</surname><given-names>J</given-names></string-name></person-group>. <article-title>Long short-term memory</article-title>. <source>Neural Comput</source><year>1997</year>;<volume>9</volume>(<issue>8</issue>):<fpage>1735</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="ref18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ammari</surname><given-names>MG</given-names></string-name>, <string-name><surname>Gresham</surname><given-names>CR</given-names></string-name>, <string-name><surname>McCarthy</surname><given-names>FM</given-names></string-name>, <etal>et al.</etal></person-group><article-title>HPIDB 2.0: a curated database for host-pathogen interactions</article-title>. <source>Database (Oxford)</source><year>2016</year>;<volume>2016</volume>:<fpage>baw103</fpage>.<pub-id pub-id-type="pmid">27374121</pub-id></mixed-citation>
    </ref>
    <ref id="ref19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kerrien</surname><given-names>S</given-names></string-name>, <string-name><surname>Aranda</surname><given-names>B</given-names></string-name>, <string-name><surname>Breuza</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>The IntAct molecular interaction database in 2012</article-title>. <source>Nucleic Acids Res</source><year>2012</year>;<volume>40</volume>(<issue>D1</issue>):<fpage>D841</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">22121220</pub-id></mixed-citation>
    </ref>
    <ref id="ref20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guirimand</surname><given-names>T</given-names></string-name>, <string-name><surname>Delmotte</surname><given-names>S</given-names></string-name>, <string-name><surname>Navratil</surname><given-names>V</given-names></string-name></person-group>. <article-title>VirHostNet 2.0: surfing on the web of virus/host molecular interactions data</article-title>. <source>Nucleic Acids Res</source><year>2015</year>;<volume>43</volume>(<issue>D1</issue>):<fpage>D583</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">25392406</pub-id></mixed-citation>
    </ref>
    <ref id="ref21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fu</surname><given-names>L</given-names></string-name>, <string-name><surname>Niu</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CD-HIT: accelerated for clustering the next-generation sequencing data</article-title>. <source>Bioinformatics</source><year>2012</year>;<volume>28</volume>(<issue>23</issue>):<fpage>3150</fpage>–<lpage>2</lpage>.<pub-id pub-id-type="pmid">23060610</pub-id></mixed-citation>
    </ref>
    <ref id="ref22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dey</surname><given-names>L</given-names></string-name>, <string-name><surname>Chakraborty</surname><given-names>S</given-names></string-name>, <string-name><surname>Mukhopadhyay</surname><given-names>A</given-names></string-name></person-group>. <article-title>Machine learning techniques for sequence-based prediction of viral-host interactions between SARS-CoV-2 and human proteins</article-title>. <source>Biom J</source><year>2020</year>;<volume>43</volume>(<issue>5</issue>):<fpage>438</fpage>–<lpage>50</lpage>.</mixed-citation>
    </ref>
    <ref id="ref23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>The UniProt Consortium</collab></person-group>. <article-title>UniProt: the universal protein knowledgebase</article-title>. <source>Nucleic Acids Res</source><year>2017</year>;<volume>45</volume>(<issue>D1</issue>):<fpage>D158</fpage>–<lpage>69</lpage>.<pub-id pub-id-type="pmid">27899622</pub-id></mixed-citation>
    </ref>
    <ref id="ref24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stark</surname><given-names>C</given-names></string-name>, <string-name><surname>Breitkreutz</surname><given-names>B-J</given-names></string-name>, <string-name><surname>Reguly</surname><given-names>T</given-names></string-name>, <etal>et al.</etal></person-group><article-title>BioGRID: a general repository for interaction datasets</article-title>. <source>Nucleic Acids Res</source><year>2006</year>;<volume>34</volume>(<issue>90001</issue>):<fpage>D535</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">16381927</pub-id></mixed-citation>
    </ref>
    <ref id="ref25">
      <label>25.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Mikolov</surname><given-names>T</given-names></string-name>, <string-name><surname>Chen</surname><given-names>K</given-names></string-name>, <string-name><surname>Corrado</surname><given-names>G</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Efficient estimation of word representations in vector space</article-title>. <source>arXiv</source><year>2013</year>; <fpage>1301.3781</fpage>.</mixed-citation>
    </ref>
    <ref id="ref26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Le</surname><given-names>Q</given-names></string-name>, <string-name><surname>Mikolov</surname><given-names>T</given-names></string-name></person-group>. <article-title>Distributed representations of sentences and documents</article-title>. <source>International Conference on International Conference on Machine Learning</source><year>2014</year>;<volume>31</volume>:<fpage>1188</fpage>–<lpage>96</lpage>.</mixed-citation>
    </ref>
    <ref id="ref27">
      <label>27.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Mikolov</surname><given-names>T</given-names></string-name>, <string-name><surname>Sutskever</surname><given-names>I</given-names></string-name>, <string-name><surname>Chen</surname><given-names>K</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Distributed representations of words and phrases and their compositionality</article-title>. <year>2013</year><comment>arXiv:1310.4546</comment>; <comment>October 18, 2013</comment><comment>preprint: not peer reviewed</comment>.</mixed-citation>
    </ref>
    <ref id="ref28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hamid</surname><given-names>MN</given-names></string-name>, <string-name><surname>Friedberg</surname><given-names>I</given-names></string-name></person-group>. <article-title>Identifying antimicrobial peptides using word embedding with deep recurrent neural networks</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>(<issue>12</issue>):<fpage>2009</fpage>–<lpage>16</lpage>.<pub-id pub-id-type="pmid">30418485</pub-id></mixed-citation>
    </ref>
    <ref id="ref29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>C</given-names></string-name>, <string-name><surname>Gao</surname><given-names>R</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>PTPD: predicting therapeutic peptides by deep learning and word2vec</article-title>. <source>BMC Bioinformatics</source><year>2019</year>;<volume>20</volume>(<issue>1</issue>):<fpage>456</fpage>.<pub-id pub-id-type="pmid">31492094</pub-id></mixed-citation>
    </ref>
    <ref id="ref30">
      <label>30.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Řehůřek</surname><given-names>R</given-names></string-name>, <string-name><surname>Sojka</surname><given-names>P</given-names></string-name></person-group>. <part-title>Software Framework for Topic Modelling with Large Corpora</part-title>. In <source>Proceedings of LREC 2010 Workshop on New Challenges for NLP Frameworks</source>. Malta: University of Malta, <year>2010</year>, <fpage>45</fpage>–<lpage>50</lpage>.</mixed-citation>
    </ref>
    <ref id="ref31">
      <label>31.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Sutskever</surname><given-names>I</given-names></string-name>, <string-name><surname>Vinyals</surname><given-names>O</given-names></string-name>, <string-name><surname>Le</surname><given-names>QV</given-names></string-name></person-group>. <article-title>Sequence to sequence learning with neural networks</article-title>. <source>arXiv</source><year>2014</year>; <comment>1409.3215</comment>.</mixed-citation>
    </ref>
    <ref id="ref32">
      <label>32.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Paszke</surname><given-names>A</given-names></string-name>, <string-name><surname>Gross</surname><given-names>S</given-names></string-name>, <string-name><surname>Chintala</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><part-title>Automatic Differentiation in PyTorch</part-title>. In: <source>NIPS 2017 Workshop on Autodiff</source>, Long Beach, California, USA, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="ref33">
      <label>33.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>L</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>H</given-names></string-name>, <string-name><surname>He</surname><given-names>P</given-names></string-name>, <etal>et al.</etal></person-group><article-title>On the variance of the adaptive learning rate and beyond</article-title>. <source>arXiv</source><year>2019</year>; <comment>1908.03265</comment>.</mixed-citation>
    </ref>
    <ref id="ref34">
      <label>34.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author">Cui Y, Jia M, Lin T-Y, <etal>et al.</etal></person-group><article-title>Class-balanced loss based on effective number of samples</article-title>. <year>2019</year>, <comment>arXiv:1901.05555</comment>.</mixed-citation>
    </ref>
    <ref id="ref35">
      <label>35.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pedregosa</surname><given-names>F</given-names></string-name>, <string-name><surname>Varoquaux</surname><given-names>G</given-names></string-name>, <string-name><surname>Gramfort</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Scikitlearn: machine learning in python</article-title>. <source>J Mach Learn Res</source><year>2012</year>;<volume>12</volume>:<fpage>2825–30</fpage>.</mixed-citation>
    </ref>
    <ref id="ref36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McInnes</surname><given-names>L</given-names></string-name>, <string-name><surname>Healy</surname><given-names>J</given-names></string-name>, <string-name><surname>Saul</surname><given-names>N</given-names></string-name>, <etal>et al.</etal></person-group><article-title>UMAP: uniform manifold approximation and projection for dimension reduction</article-title>. <source>J. Open Source Softw</source><year>2018</year>;<volume>3</volume>:<fpage>861</fpage>.</mixed-citation>
    </ref>
    <ref id="ref37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>W</given-names></string-name>, <string-name><surname>Xu</surname><given-names>D</given-names></string-name></person-group>. <article-title>Imbalanced multi-label learning for identifying antimicrobial peptides and their functional types</article-title>. <source>Bioinformatics (Oxford, England)</source><year>2016</year>;<volume>32</volume>(<issue>24</issue>):<fpage>3745</fpage>–<lpage>52</lpage>.</mixed-citation>
    </ref>
    <ref id="ref38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Xiao</surname><given-names>X</given-names></string-name>, <string-name><surname>Qiu</surname><given-names>WR</given-names></string-name>, <etal>et al.</etal></person-group><article-title>iDNA-methyl: identifying DNA methylation sites via pseudo trinucleotide composition</article-title>. <source>Anal Biochem</source><year>2015</year>;<volume>474</volume>:<fpage>69</fpage>–<lpage>77</lpage>.<pub-id pub-id-type="pmid">25596338</pub-id></mixed-citation>
    </ref>
    <ref id="ref39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Becht</surname><given-names>E</given-names></string-name>, <string-name><surname>McInnes</surname><given-names>L</given-names></string-name>, <string-name><surname>Healy</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Dimensionality reduction for visualizing single-cell data using UMAP</article-title>. <source>Nat Biotechnol</source><year>2019</year>;<volume>37</volume>(<issue>1</issue>):<fpage>38</fpage>–<lpage>44</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
