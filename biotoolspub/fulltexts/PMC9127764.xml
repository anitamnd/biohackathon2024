<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Neurorobot</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Neurorobot</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Neurorobot.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Neurorobotics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1662-5218</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9127764</article-id>
    <article-id pub-id-type="doi">10.3389/fnbot.2022.886050</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Neuroscience</subject>
        <subj-group>
          <subject>Perspective</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>ROS-Neuro: An Open-Source Platform for Neurorobotics</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Tonin</surname>
          <given-names>Luca</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">
          <sup>*</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/345903/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Beraldo</surname>
          <given-names>Gloria</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/1573539/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tortora</surname>
          <given-names>Stefano</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/1011145/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Menegatti</surname>
          <given-names>Emanuele</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/451857/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>Intelligent Autonomous Systems Laboratory, Department of Information Engineering, University of Padova</institution>, <addr-line>Padua</addr-line>, <country>Italy</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Padova Neuroscience Center, University of Padova</institution>, <addr-line>Padua</addr-line>, <country>Italy</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Institute of Cognitive Sciences and Technologies, National Research Council</institution>, <addr-line>Rome</addr-line>, <country>Italy</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Florian Röhrbein, Technische Universität Chemnitz, Germany</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Onofrio Gigliotta, University of Naples Federico II, Italy; Eris Chinellato, Middlesex University, United Kingdom</p>
      </fn>
      <corresp id="c001">*Correspondence: Luca Tonin <email>luca.tonin@dei.unipd.it</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>10</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>16</volume>
    <elocation-id>886050</elocation-id>
    <history>
      <date date-type="received">
        <day>28</day>
        <month>2</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>07</day>
        <month>4</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2022 Tonin, Beraldo, Tortora and Menegatti.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Tonin, Beraldo, Tortora and Menegatti</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>The growing interest in neurorobotics has led to a proliferation of heterogeneous neurophysiological-based applications controlling a variety of robotic devices. Although recent years have seen great advances in this technology, the integration between human neural interfaces and robotics is still limited, making evident the necessity of creating a standardized research framework bridging the gap between neuroscience and robotics. This perspective paper presents Robot Operating System (ROS)-Neuro, an open-source framework for neurorobotic applications based on ROS. ROS-Neuro aims to facilitate the software distribution, the repeatability of the experimental results, and support the birth of a new community focused on neuro-driven robotics. In addition, the exploitation of Robot Operating System (ROS) infrastructure guarantees stability, reliability, and robustness, which represent fundamental aspects to enhance the translational impact of this technology. We suggest that ROS-Neuro might be the future development platform for the flourishing of a new generation of neurorobots to promote the rehabilitation, the inclusion, and the independence of people with disabilities in their everyday life.</p>
    </abstract>
    <kwd-group>
      <kwd>ROS</kwd>
      <kwd>ROS-Neuro</kwd>
      <kwd>neural interface</kwd>
      <kwd>brain-machine interface</kwd>
      <kwd>neurorobotics</kwd>
    </kwd-group>
    <counts>
      <fig-count count="1"/>
      <table-count count="1"/>
      <equation-count count="0"/>
      <ref-count count="34"/>
      <page-count count="7"/>
      <word-count count="4943"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>1. Introduction</title>
    <p>The last few years have seen a growing interest in the topic of neural human-machine interfaces as a novel—potentially groundbreaking—interaction modality between users and robotic devices. In these interfaces, neurophysiological signals are acquired in real-time [e.g., from electroencephalography (EEG) or from electromyography (EMG)], processed with minimum delay, and translated into commands for the external actuators. Based on this workflow, researchers have demonstrated the feasibility and the potentiality of this innovation, in particular for those people suffering from severe motor disabilities (Kennedy and Bakay, <xref rid="B19" ref-type="bibr">1998</xref>; Hochberg et al., <xref rid="B17" ref-type="bibr">2012</xref>; Aflalo et al., <xref rid="B1" ref-type="bibr">2015</xref>; Chaudhary et al., <xref rid="B12" ref-type="bibr">2016</xref>; Tonin and Millán, <xref rid="B33" ref-type="bibr">2021</xref>). For instance, the latest advances in the brain-machine interface (BMI) showed the possibility to exploit brain signals (acquired with invasive or non-invasive techniques) to control telepresence robots, powered wheelchairs, robotic arms, and upper/lower-limb exoskeletons (Iez et al., <xref rid="B18" ref-type="bibr">2010</xref>; Leeb et al., <xref rid="B20" ref-type="bibr">2013</xref>, <xref rid="B21" ref-type="bibr">2015</xref>; Liu et al., <xref rid="B22" ref-type="bibr">2017</xref>, <xref rid="B23" ref-type="bibr">2018</xref>; Edelman et al., <xref rid="B15" ref-type="bibr">2019</xref>). In parallel, systems relying on residual motor functions demonstrated that EMG signals can be re-interpreted and used to precisely drive robotic arms in amputees (Farrell and Weir, <xref rid="B16" ref-type="bibr">2008</xref>; Castellini et al., <xref rid="B11" ref-type="bibr">2009</xref>; Cipriani et al., <xref rid="B13" ref-type="bibr">2011</xref>; Borton et al., <xref rid="B9" ref-type="bibr">2013</xref>; Parajuli et al., <xref rid="B25" ref-type="bibr">2019</xref>), to initiate the walking pattern in lower-limb exoskeletons (Sylos-Labini et al., <xref rid="B30" ref-type="bibr">2014</xref>; De Luca et al., <xref rid="B14" ref-type="bibr">2019</xref>) or to support reaching and grasping tasks with upper-limb exoskeletons (Batzianoulis et al., <xref rid="B2" ref-type="bibr">2017</xref>, <xref rid="B3" ref-type="bibr">2018</xref>; Betti et al., <xref rid="B7" ref-type="bibr">2018</xref>).</p>
    <p>However, despite such an emerging and promising trend, the full potential of the field is still unrevealed. Among the multifaceted and multidisciplinary aspects belonging to the neurorobotics challenge, herein we propose an engineering perspective on the development of neural driven robotic devices. In this regard, we highlight three current drawbacks that are conceptually and technically narrowing the field: first, the community suffers from the lack of a common development platform to spread the latest advances, to consolidate prototypes, and to compare results among different research groups. Second, there has been an abundance of home-made solutions that inevitably led to a heterogeneity of technical approaches to the same problems and to an absence of standards, making the reuse of already developed and well-tested code problematic. Finally, recent research trends keep considering robotic devices as mere passive actuators of users' intentions by mostly neglecting the potential benefits of including robotic artificial intelligence in the decoding workflow. Furthermore, we speculate that the lack of technical tools (e.g., a common development ecosystem) might also conceptually affect the direction of the current neurorobotics research by slowing down the necessary integration between neural interfaces and robotics. It is worth mentioning that a variety of open-source platforms already exists in the neurorobotics field to acquire, process, and decode neurophysiological signals (e.g., LSL, BCI2000, OpenViBE, TOBI Common Implementation Platform, BioSig, BCILAB, BCI++, xBCI, BF++, PMW, and VETA Brunner et al., <xref rid="B10" ref-type="bibr">2012</xref>; Stegman et al., <xref rid="B29" ref-type="bibr">2020</xref>). Although each software has specific features and advantages, they only partially face all the aforementioned challenges. Furthermore, to the best of our knowledge, neither of them explicitly targets the integration of robotic platforms nor do they provide out-of-the-box solutions to directly interact with external devices.</p>
    <p>In the current scenario, we firmly believe in the urgency of a common and open-source research framework for the future development of the neurorobotic field. Hence, we spotlight Robot Operating System (ROS)-Neuro, the first middleware explicitly devised to treat the multidisciplinary facets of neurorobotics with the same level of importance, to promote a holistic approach to the field, and to foster the research of a new generation of neural driven robotic devices.</p>
  </sec>
  <sec id="s2">
    <title>2. ROS-Neuro middleware</title>
    <sec>
      <title>2.1. Overview</title>
      <p>ROS-Neuro has been designed to represent the first open-source neurorobotic middleware that places human neural interfaces and robotic systems at the same conceptual and implementation level. ROS-Neuro is an extension of ROS that for many years is considered the standard platform for robotics (Quigley et al., <xref rid="B28" ref-type="bibr">2009</xref>). One of the strengths of ROS is its modularity and the possibility for different research groups to develop stand-alone components all relying on the same standard communication infrastructure. A similar requirement is a cornerstone for the workflow of any closed-loop neural interface where—for instance—acquisition, processing, and decoding methods should run in parallel in order to provide a continuous/discrete control signal to drive the robotic device. ROS-Neuro not only exploits such modular design but also provides several standard interfaces to acquire neurophysiological signals from different commercial devices to process EEG and EMG signals with traditional methods and to classify data with common machine learning algorithms. As in the case of ROS, the aim of ROS-Neuro is to allow the development of neurorobotic applications among different research groups as well as the possibility to easily compare heterogeneous methodological approaches and to rely and evaluate solutions proposed by others. This is guaranteed by its multi-process architecture where several stand-alone executables can coexist and can communicate through the provided network infrastructure. Moreover, each of these processes can be easily exchanged between research groups with the only requirement of sharing the same interface. The concept of ROS-Neuro has been introduced for the first time in Beraldo et al. (<xref rid="B5" ref-type="bibr">2018b</xref>) and in the following years, authors implemented and carefully tested packages to acquire, record, process, and visualize EEG and EMG data (Tonin et al., <xref rid="B32" ref-type="bibr">2019</xref>; Beraldo et al., <xref rid="B6" ref-type="bibr">2020</xref>). The aim of this contribution is to present ROS-Neuro to the community by providing a description of its main features and potentialities.</p>
    </sec>
    <sec>
      <title>2.2. Abstraction, Modularity, and Parallel Architecture</title>
      <p>Robotic applications and human neural interfaces share several similarities in the technical and implementation workflow. As robotics is traditionally based on the interactions between perception and planning and action, neural interfaces rely on the acquisition, processing, and classification closed-loop where the human plays the twofold role of generating the input signals and monitoring (as well as adapting to) the results of the decoding. Tonin and Millán (<xref rid="B33" ref-type="bibr">2021</xref>). ROS-Neuro generalizes such an architecture by providing modules to gather neurophysiological signals (<monospace>rosneuro_acquisition</monospace> package), to record the acquired data (<monospace>rosneuro_recorder</monospace>), to process and decode it (<monospace>rosneuro_buffers</monospace>, <monospace>rosneuro_filters</monospace>, <monospace>rosneuro_processing</monospace>), and to finally infer the intention of the user (<monospace>rosneuro_decisionmaking</monospace>). As in the case of the packages available in the ROS ecosystem, these modules represent generic interfaces that neither depends on specific hardware devices nor on particular processing methods. For instance, <monospace>rosneuro_acquisition</monospace> package is designed to work with plugins that can support different EEG/EMG devices and that can be independently developed (and shared) by any research group according to their needs. However, it is worth mentioning that ROS-Neuro already provides plugins that interface with the most used commercial acquisition systems (e.g., g.Tec, BioSemi, ANTNeuro, Cognionics). Similarly, packages like <monospace>rosneuro_buffers</monospace> and <monospace>rosneuro_filters</monospace> implement widely commonly used methods to process neural data such as spatial filters, DC removal algorithms, and windowing that can be easily extended and integrated with custom solutions provided by researchers. <xref rid="T1" ref-type="table">Table 1</xref> lists the acquisition systems (hardware devices and software platforms) compatible with ROS-Neuro and the supported file formats to store the acquired data. Furthermore, the filters, buffers, and the application scope provided by ROS-Neuro are reported.</p>
      <table-wrap position="float" id="T1">
        <label>Table 1</label>
        <caption>
          <p>List of acquisition devices and platforms currently compatible with the <monospace>rosneuro_acquisition</monospace> package and the file formats supported by the <monospace>rosneuro_recorder</monospace>.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Hardware</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Company</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Driver</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Plugin</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Status</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" colspan="5" rowspan="1">
                <bold>rosneuro_acquisition</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">BioSemi ActiveTwo</td>
              <td valign="top" align="left" rowspan="1" colspan="1">BioSemi</td>
              <td valign="top" align="left" rowspan="1" colspan="1">free</td>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::EGDDevice</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">MindWave Headsets</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Neurosky</td>
              <td valign="top" align="left" rowspan="1" colspan="1">free</td>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::EGDDevice</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Untested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Bittium NeurOne</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Bittium</td>
              <td valign="top" align="left" rowspan="1" colspan="1">free</td>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::EGDDevice</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Untested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">g.USBamp</td>
              <td valign="top" align="left" rowspan="1" colspan="1">g.Tec</td>
              <td valign="top" align="left" rowspan="1" colspan="1">proprietary</td>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::EGDDevice</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">g.NEEDaccess</td>
              <td valign="top" align="left" rowspan="1" colspan="1">g.Tex</td>
              <td valign="top" align="left" rowspan="1" colspan="1">proprietary</td>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::EGDDevice</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Untested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">BitBrain EEG</td>
              <td valign="top" align="left" rowspan="1" colspan="1">BitBrain</td>
              <td valign="top" align="left" rowspan="1" colspan="1">proprietary</td>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::EGDDevice</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Untested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">DSI-24</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Wearable Sensing</td>
              <td valign="top" align="left" rowspan="1" colspan="1">proprietary</td>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::EGDDevice</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">CGX Quick-20</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Cognionics</td>
              <td valign="top" align="left" rowspan="1" colspan="1">proprietary</td>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::EGDDevice</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">eego sport and mylab</td>
              <td valign="top" align="left" rowspan="1" colspan="1">AntNeuro</td>
              <td valign="top" align="left" rowspan="1" colspan="1">proprietary</td>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::EGDDevice</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Ultracortex Mark IV</td>
              <td valign="top" align="left" rowspan="1" colspan="1">OpenBCI</td>
              <td valign="top" align="left" rowspan="1" colspan="1">free</td>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::LSLDevice</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">LabStreaming layer</td>
              <td valign="top" align="left" rowspan="1" colspan="1">/</td>
              <td valign="top" align="left" rowspan="1" colspan="1">free</td>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::LSLDevice</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Tobi Interface A</td>
              <td valign="top" align="left" rowspan="1" colspan="1">/</td>
              <td valign="top" align="left" rowspan="1" colspan="1">free</td>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::EGDDevice</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Untested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">General data format (GDF) file</td>
              <td valign="top" align="left" rowspan="1" colspan="1">/</td>
              <td valign="top" align="left" rowspan="1" colspan="1">free</td>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::EGDDevice</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">BioSemi data format (BDF) file</td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">/</td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">free</td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">rosneuro::EGDDevice</td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>File format</bold>
              </td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Company</bold>
              </td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Driver</bold>
              </td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1"/>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Status</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" colspan="4" rowspan="1">
                <bold>rosneuro_recorder</bold>
              </td>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">General data format (GDF)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">/</td>
              <td valign="top" align="left" rowspan="1" colspan="1">free</td>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">BioSemi data format (BDF)</td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">BioSemi</td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">free</td>
              <td style="border-bottom: thin solid #000000;" rowspan="1" colspan="1"/>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Filter</bold>
              </td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Type</bold>
              </td>
              <td style="border-bottom: thin solid #000000;" rowspan="1" colspan="1"/>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Class</bold>
              </td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Status</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" colspan="4" rowspan="1">
                <bold>rosneuro_filters</bold>
              </td>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">DC removal</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Temporal</td>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::Dc &lt; T&gt;</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Common Average Reference</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Spatial</td>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::Car &lt; T&gt;</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Laplacian derivation</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Spatial</td>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::Laplacian &lt; T&gt;</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Blackman</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Windowing</td>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::Blackman &lt; T&gt;</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Flattop</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Windowing</td>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::Flattop &lt; T&gt;</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Hamming</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Windowing</td>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">rosneuro::Hamming &lt; T&gt;</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">Hann</td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">Windowing</td>
              <td style="border-bottom: thin solid #000000;" rowspan="1" colspan="1"/>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">rosneuro::Hann &lt; T&gt;</td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Buffer</bold>
              </td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Type</bold>
              </td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1"/>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Class</bold>
              </td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Status</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" colspan="4" rowspan="1">
                <bold>rosneuro_buffers</bold>
              </td>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">RingBuffer</td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">FIFO</td>
              <td style="border-bottom: thin solid #000000;" rowspan="1" colspan="1"/>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">rosneuro::RingBuffer &lt; T&gt;</td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">Tested</td>
            </tr>
            <tr>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Application</bold>
              </td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Type</bold>
              </td>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1"/>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1"/>
              <td valign="top" align="left" style="border-bottom: thin solid #000000;" rowspan="1" colspan="1">
                <bold>Status</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>rosneuro_visualizer</bold>
              </td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">neuroviz</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Temporal scope</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Tested</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p><italic>The table also provides the filters and buffers available in the <monospace>rosneuro_filters</monospace> and <monospace>rosneuro_buffers</monospace> packages. It is worth noticing that both filters and buffers can be easily concatenated via configuration file [please refer to <monospace>FilterChain</monospace> in Robot Operating System (ROS)]. Finally, <monospace>neuroviz</monospace> application is listed—the electroencephalography (EEG)/electromyography (EMG) scope provided by the <monospace>rosneuro_visualizer</monospace> package. In the last column, Untested status means that the related hardware is technically supported by the plugin but it was not possible to test it</italic>.</p>
        </table-wrap-foot>
      </table-wrap>
      <p>Another feature of ROS-Neuro is the possibility to conveniently implement parallel pipelines with the minimum developing effort. This is of particular interest for many emerging aspects of hybrid neural interfaces. On the one hand, these interfaces are designed to simultaneously acquire, process, and fuse together heterogeneous neurophysiological signals from several sources [e.g., EEG, EMG, electrooculography (EOG)] in order to improve the robustness of the whole system (Müller-Putz et al., <xref rid="B24" ref-type="bibr">2011</xref>). On the other, they can rely on different processing workflows to decode concurrent tasks performed by the user. In both cases, ROS-Neuro already exploits the ROS optimized communication infrastructure and it can rely on built-in solutions to synchronize and align data streams from different processes (e.g., hardware-based trigger) (Bilucaglia et al., <xref rid="B8" ref-type="bibr">2020</xref>). This enormously facilitates the implementation of interfaces where—for instance—multiple acquisition processes are instantiated to simultaneously gather EEG and EMG signals (<xref rid="F1" ref-type="fig">Figure 1</xref>). Then, specific processing may be applied to EEG in order to decode the intention of the user to reach an object with a robotic arm or an upper-limb exoskeleton; at the same time, residual muscular activity may be exploited to distinguish the type of grasping. Furthermore, brain signals can be also analyzed in conjunction with environmental information in order to recognize potential erroneous actions performed by the neuroprosthesis.</p>
      <fig position="float" id="F1">
        <label>Figure 1</label>
        <caption>
          <p>A schematic representation of a hybrid, multi-process implementation of a neural interface with Robot Operating System (ROS)-Neuro. Two acquisition systems are used in parallel to acquire (and record) EEG and EMG data (blue and cyan boxes). An additional interface can be added to record the data stream from the LSL device (dashed cyan box). Data is made available in the <monospace>eeg/neurodata</monospace> and <monospace>emg/neurodata</monospace> communication channels as <monospace>NeuroFrame</monospace> messages to all the other modules. In the example, four different workflows work in parallel (green boxes) to detect resting state, motion intention, to monitor the behavior of the system from EEG signals, and to classify residual muscular activity from EMG data. An additional processing module can be added by exploiting the ROS-Neuro MATLAB interface (dashed green box). The output of the processing workflows is published as <monospace>NeuroPrediction</monospace> messages in the <monospace>prediction/*/raw</monospace>. A decision making module (purple box) reads the predicted outputs and generates a proper control signal for the robotic device. Such a signal can be also used to provide feedback to the user. In parallel, computer vision algorithms and ROS navigation packages (red and yellow boxes) not only take care of controlling the robot but also provide environmental information for the EEG workflows (red and blue arrows).</p>
        </caption>
        <graphic xlink:href="fnbot-16-886050-g0001" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.3. Standard Messages and Communication</title>
      <p>The rapid growth of the neurorobotics field, and in particular, of human neural interfaces has led to the heterogeneity of technical solutions. In this scenario, one of the main limitations of current developing frameworks is the custom approaches to sharing information between the different modules composing the closed-loop implementation of neural interfaces. Traditionally, each research group relies on its own data structures to represent neurophysiological data and custom-made network infrastructures to implement the communication between the several processing steps. Such a lack of a common approach strongly downplays the impact of the technology by limiting the possibility to share developing tools, to exploit solutions already implemented, and to replicate results achieved by different research groups.</p>
      <p>ROS-Neuro provides standard messages to exchange data structures between the modules usually implemented within neurorobotics applications. Moreover, messages are available to all modules by the ROS network infrastructure-based peer-to-peer communication mechanisms. Data acquired by the <monospace>rosneuro_acquisition</monospace> is streamed as <monospace>NeuroFrame</monospace> messages within the ecosystem (<xref rid="F1" ref-type="fig">Figure 1</xref>), where several modules can subscribe to the stream at the same time and concurrently process the messages in order to extract and decode heterogeneous features from neurophysiological signals. Similarly, the output of the decoder is translated into <monospace>NeuroPrediction</monospace> messages that can be exploited to directly control the robotic application or to be further processed. Furthermore, it is worth mentioning that ROS allows to quickly extend the interface of any message without the need for coding in order to handle specific, application-related requirements. As a consequence, ROS-Neuro not only offers the possibility to conveniently compare different methodological approaches even during closed-loop operations but also to effortlessly distribute implementation solutions among different research groups with the only requirement of providing the standard message interface.</p>
    </sec>
    <sec>
      <title>2.4. Robotic Devices</title>
      <p>The straightforward integration between neural interfaces and external actuators is the most evident advantage of ROS-Neuro middleware. Traditionally, the inclusion of robotic devices has been considered a pure technical challenge, and thus, a variety of home-made solutions has been adopted to deliver the output of the neural interface to the robot ecosystem. However, the drawback of this approach is twofold: first, from an engineering perspective, custom solutions are often not optimized and efficient with the consequence of an increased risk of technical faults. Second, the communication stream between neural interfaces and robotic devices is usually limited to a single uni-dimensional control signal. This definitely narrows the research on new human-machine interaction (HMI) modalities and the introduction of bidirectional communication with the robot to enhance the robustness and the reliability of the whole system. For instance, a robot's intelligence may provide information about the operational context to the neural interface in order to modulate the velocity of the decoder response, thus facilitating the control or preventing the delivery of an erroneous command according to the current situation. Thus, the level of autonomy of the neurorobotic device may be changed in the case, for example, a smart wheelchair crosses a narrow passage or a robotic hand attempts to grasp an unusual-shaped object (<xref rid="F1" ref-type="fig">Figure 1</xref>).</p>
      <p>By construction, ROS-Neuro explicitly provides such a common and bidirectional communication between the neural interface workflow and the robotic intelligence by exploiting the ROS ecosystem and the several packages already available in the ROS community. Furthermore, the reliability and robustness of the communication is guaranteed by the ROS network infrastructure by reducing the likelihood of technical shortcomings and malfunctions.</p>
    </sec>
  </sec>
  <sec id="s3">
    <title>3. Evaluation of ROS-Neuro: the Cybathlon Event</title>
    <p>ROS-Neuro has been evaluated by using different hardware devices (e.g., a variety of commercial EEG/EMG amplifiers and various robotic platforms Beraldo et al., <xref rid="B4" ref-type="bibr">2018a</xref>,<xref rid="B5" ref-type="bibr">b</xref>, <xref rid="B6" ref-type="bibr">2020</xref>; Tonin et al., <xref rid="B32" ref-type="bibr">2019</xref>) during several experiments. In all cases, ROS-Neuro demonstrated its flexibility, reliability, and robustness. However, the most critical stress test for ROS-Neuro has been the usage for the Cybathlon events (Wolf and Riener, <xref rid="B34" ref-type="bibr">2018</xref>). Cybathlon is the first neurorobotic championship where several international teams from all over the world competed in different disciplines: from races with lower and upper limb prostheses to races with wheelchairs and exoskeletons. The ultimate goal of Cybathlon is to foster the research and development of daily-life solutions for people with disabilities. In this context, one of the most challenging disciplines was the BCI Race<xref rid="fn0001" ref-type="fn"><sup>1</sup></xref> where pilots with a severe motor disability (i.e., inclusion criteria ASIA-C) exploited a non-invasive BMI to control an avatar on the screen during a virtual race. Authors participated in the Cybathlon BCI Series 2019 and the Cybathlon 2020 Global Edition with the WHi Team composed of researchers from the University of Padua (Italy). In these periods and in the related longitudinal training of the pilot, ROS-Neuro has been extensively used and tested. In both editions, the WHi Team won the gold medal by awarding the race records. Most importantly, ROS-Neuro was confirmed to be reliable and robust during the whole training and, especially, in the demanding conditions of the event. Neither technical faults nor difficulties or glitches during the interface with the official Cybathlon infrastructure (for connecting to the virtual race) have been reported. We speculate that the efficiency, the flexibility, and the performance of ROS-Neuro were one of the key reasons (among others) for the success of the WHi Team at the Cybathlon.</p>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>4. Discussion</title>
    <p>Recent evidence in literature highlighted the importance of reconsidering the current approach to neurorobotics in order to enhance the reliability of neural driven robotic devices, and thus, foster the translational impact and the daily usage of the technology (Perdikis et al., <xref rid="B27" ref-type="bibr">2018</xref>; Perdikis and Millán, <xref rid="B26" ref-type="bibr">2020</xref>; Tonin and Millán, <xref rid="B33" ref-type="bibr">2021</xref>). In particular, the research community started following a more holistic approach by investigating the mutual interactions between the actors of the system, i.e., the user, the decoder, and the robotic device. For instance, several studies have demonstrated the key role of mutual learning between user and decoder to facilitate the acquisition of BMI skills and enhance the reliability of BMI-driven devices (Perdikis and Millán, <xref rid="B26" ref-type="bibr">2020</xref>). Similarly, it has been shown that a neural interface explicitly designed to promote the interaction between user and robotic intelligence can support a more natural and efficient control of the device (Tonin et al., <xref rid="B31" ref-type="bibr">2020</xref>). In this scenario, we speculate that ROS-Neuro might offer the technical counterpart of this new research direction by not only allowing to develop the neural interface workflow and the robotic intelligence within the same ecosystem but also by guaranteeing high performance and strong robustness of the whole application.</p>
    <p>Although we previously pinpointed ROS-Neuro features with respect to the current platforms available in the community, it is worth mentioning that it should not be considered a direct competitor. Indeed, ROS-Neuro represents uniqueness in the neurorobotics field with the explicit aim of integrating neural interfaces and robotics by exploiting the advantages of both fields. Furthermore, current development frameworks to acquire neural signals can easily be included in the ROS-Neuro infrastructure, for instance, plugin to connect LSL is already implemented and available in the public repository to incorporate external information streams into the ROS-Neuro ecosystem.</p>
    <p>ROS-Neuro is distributed as an open-source project, and it is available on GitHub<xref rid="fn0002" ref-type="fn"><sup>2</sup></xref>. As in the case of ROS, the success of ROS-Neuro strictly depends on the creation of a wide community disseminating the latest developments and including the multidisciplinary needs of the different research groups. It is our opinion that ROS-Neuro represents the only way to achieve a robust and flexible ecosystem, to review and evaluate alternative approaches, and, finally, to boost neurorobotics technology. ROS-Neuro supports the development of packages in C++ and Python, and we acknowledge that this might hinder the approach to the platform, especially if researchers are used to working with GUI-based software (e.g., OpenVibe). For this reason, ROS-Neuro already provides a MATLAB interface (<monospace>rosneuro_matlab</monospace>) in order to facilitate the integration with toolboxes widely spread in the community and to mitigate the effort of those people not used to such programming languages. Nevertheless, we consider that this is a small price to pay in comparison with the advantages in terms of reliability, performance, and integration that ROS-Neuro can offer.</p>
    <p>Finally, the current version of ROS-Neuro is fully based on ROS 1 LTS (ROS Noetic Ninjemys)<xref rid="fn0003" ref-type="fn"><sup>3</sup></xref>, and thus, it works on Ubuntu Linux operating systems only. However, in a few years, the community started the development of ROS 2 that—among several changes—is the first multi-platform version of ROS (i.e., on Ubuntu Linux, MacOS, and Windows 10). The transition of ROS-Neuro from ROS 1 to ROS 2 has already been scheduled to expand the base of potential users of ROS-Neuro. Nevertheless, the effort to develop and maintain both versions can be demanding, and it would be beneficial to have the support of the whole community.</p>
    <p>In conclusion, we firmly believe that ROS-Neuro might be the future development platform for neurorobotics. Furthermore, as in the case of ROS, it might represent the starting point for the creation of a flourishing research community to foster the translational impact of neurorobotics technology.</p>
  </sec>
  <sec sec-type="data-availability" id="s5">
    <title>Data Availability Statement</title>
    <p>Publicly available code was reported in this study. This code can be found here: GitHub, <ext-link xlink:href="https://github.com/rosneuro" ext-link-type="uri">https://github.com/rosneuro</ext-link>.</p>
  </sec>
  <sec id="s6">
    <title>Author Contributions</title>
    <p>LT and EM conceived the idea of ROS-Neuro. All authors wrote, reviewed, and approved the final manuscript.</p>
  </sec>
  <sec sec-type="funding-information" id="s7">
    <title>Funding</title>
    <p>Part of this work was supported by MUR (Italian Minister for University and Research), under the initiative Departments of Excellence (Law 232/2016), and by the Department of Information Engineering, University of Padova, under the BrainGear project (TONI_BIRD2020_01).</p>
  </sec>
  <sec sec-type="COI-statement" id="conf1">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s8">
    <title>Publisher's Note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
</body>
<back>
  <ack>
    <p>We would like to thank Vassilli srl for sponsorship and hardware support to the WHi team participating in the Cybathlon competition.</p>
  </ack>
  <fn-group>
    <fn id="fn0001">
      <p>
        <sup>1</sup>
        <ext-link xlink:href="https://cybathlon.ethz.ch/en/event/disciplines/bci" ext-link-type="uri">https://cybathlon.ethz.ch/en/event/disciplines/bci</ext-link>
      </p>
    </fn>
    <fn id="fn0002">
      <p>
        <sup>2</sup>
        <ext-link xlink:href="https://github.com/rosneuro" ext-link-type="uri">https://github.com/rosneuro</ext-link>
      </p>
    </fn>
    <fn id="fn0003">
      <p>
        <sup>3</sup>
        <ext-link xlink:href="https://www.ros.org/" ext-link-type="uri">https://www.ros.org/</ext-link>
      </p>
    </fn>
  </fn-group>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aflalo</surname><given-names>T.</given-names></name><name><surname>Kellis</surname><given-names>S.</given-names></name><name><surname>Klaes</surname><given-names>C.</given-names></name><name><surname>Lee</surname><given-names>B.</given-names></name><name><surname>Shi</surname><given-names>Y.</given-names></name><name><surname>Pejsa</surname><given-names>K.</given-names></name><etal/></person-group>. (<year>2015</year>). <article-title>Decoding motor imagery from the posterior parietal cortex of a tetraplegic human</article-title>. <source>Science</source><volume>348</volume>, <fpage>906</fpage>–<lpage>910</lpage>. <pub-id pub-id-type="doi">10.1126/science.aaa5417</pub-id><?supplied-pmid 25999506?><pub-id pub-id-type="pmid">25999506</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Batzianoulis</surname><given-names>I.</given-names></name><name><surname>El-Khoury</surname><given-names>S.</given-names></name><name><surname>Pirondini</surname><given-names>E.</given-names></name><name><surname>Coscia</surname><given-names>M.</given-names></name><name><surname>Micera</surname><given-names>S.</given-names></name><name><surname>Billard</surname><given-names>A.</given-names></name></person-group> (<year>2017</year>). <article-title>Emg-based decoding of grasp gestures in reaching-to-grasping motions</article-title>. <source>Rob. Auton. Syst</source>. <volume>91</volume>, <fpage>59</fpage>–<lpage>70</lpage>. <pub-id pub-id-type="doi">10.1016/j.robot.2016.12.014</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Batzianoulis</surname><given-names>I.</given-names></name><name><surname>Krausz</surname><given-names>N. E.</given-names></name><name><surname>Simon</surname><given-names>A. M.</given-names></name><name><surname>Hargrove</surname><given-names>L.</given-names></name><name><surname>Billard</surname><given-names>A.</given-names></name></person-group> (<year>2018</year>). <article-title>Decoding the grasping intention from electromyography during reaching motions</article-title>. <source>J. Neuroeng. Rehabil</source>. <volume>15</volume>, <fpage>57</fpage>. <pub-id pub-id-type="doi">10.1186/s12984-018-0396-5</pub-id><?supplied-pmid 29940991?><pub-id pub-id-type="pmid">29940991</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Beraldo</surname><given-names>G.</given-names></name><name><surname>Antonello</surname><given-names>M.</given-names></name><name><surname>Cimolato</surname><given-names>A.</given-names></name><name><surname>Menegatti</surname><given-names>E.</given-names></name><name><surname>Tonin</surname><given-names>L.</given-names></name></person-group> (<year>2018a</year>). <article-title>“Brain-computer interface meets ROS: a robotic approach to mentally drive telepresence robots,”</article-title> in <source>2018 IEEE International Conference on Robotics and Automation (ICRA)</source> (<publisher-loc>Brisbane, QLD</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>4459</fpage>–<lpage>4464</lpage>.</mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Beraldo</surname><given-names>G.</given-names></name><name><surname>Castaman</surname><given-names>N.</given-names></name><name><surname>Bortoletto</surname><given-names>R.</given-names></name><name><surname>Pagello</surname><given-names>E.</given-names></name><name><surname>Milln</surname><given-names>J. d. R.</given-names></name><etal/></person-group>. (<year>2018b</year>). <article-title>“ROS-health: an open-source framework for neurorobotics,”</article-title> in <source>2018 IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots (SIMPAR)</source> (<publisher-loc>Brisbane, QLD</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>174</fpage>–<lpage>179</lpage>.</mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Beraldo</surname><given-names>G.</given-names></name><name><surname>Tortora</surname><given-names>S.</given-names></name><name><surname>Menegatti</surname><given-names>E.</given-names></name><name><surname>Tonin</surname><given-names>L.</given-names></name></person-group> (<year>2020</year>). <article-title>“ROS-Neuro: implementation of a closed-loop BMI based on motor imagery,”</article-title> in <source>2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)</source> (<publisher-loc>Toronto, ON</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>2031</fpage>–<lpage>2037</lpage>.</mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Betti</surname><given-names>S.</given-names></name><name><surname>Zani</surname><given-names>G.</given-names></name><name><surname>Guerra</surname><given-names>S.</given-names></name><name><surname>Castiello</surname><given-names>U.</given-names></name><name><surname>Sartori</surname><given-names>L.</given-names></name></person-group> (<year>2018</year>). <article-title>Reach-to-grasp movements: a multimodal techniques study</article-title>. <source>Front. Psychol</source>. <volume>9</volume>, <fpage>990</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2018.00990</pub-id><?supplied-pmid 29962993?><pub-id pub-id-type="pmid">29962993</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bilucaglia</surname><given-names>M.</given-names></name><name><surname>Masi</surname><given-names>R.</given-names></name><name><surname>Stanislao</surname><given-names>G. D.</given-names></name><name><surname>Laureanti</surname><given-names>R.</given-names></name><name><surname>Fici</surname><given-names>A.</given-names></name><name><surname>Circi</surname><given-names>R.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>ESB: a low-cost EEG synchronization box</article-title>. <source>HardwareX</source><volume>8</volume>:<fpage>e00125</fpage>. <pub-id pub-id-type="doi">10.1016/j.ohx.2020.e00125</pub-id><?supplied-pmid 35498268?><pub-id pub-id-type="pmid">35498268</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borton</surname><given-names>D.</given-names></name><name><surname>Micera</surname><given-names>S.</given-names></name><name><surname>Millán</surname><given-names>J.</given-names></name><name><surname>Courtine</surname><given-names>G.</given-names></name></person-group> (<year>2013</year>). <article-title>Personalized neuroprosthetics</article-title>. <source>Sci. Transl. Med</source>. <volume>5</volume>, <fpage>210rv2</fpage>. <pub-id pub-id-type="doi">10.1126/scitranslmed.3005968</pub-id><?supplied-pmid 24197737?><pub-id pub-id-type="pmid">24197737</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Brunner</surname><given-names>C.</given-names></name><name><surname>Andreoni</surname><given-names>G.</given-names></name><name><surname>Bianchi</surname><given-names>L.</given-names></name><name><surname>Blankertz</surname><given-names>B.</given-names></name><name><surname>Breitwieser</surname><given-names>C.</given-names></name><name><surname>Kanoh</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>“BCI software platforms,”</article-title> in <source>Towards Practical Brain-Computer Interfaces. Biological and Medical Physics, Biomedical Engineering</source>, eds B. Allison, S. Dunne, R. Leeb, R. Del, J. Millán, and A. Nijholt (<publisher-loc>Berlin; Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>). <pub-id pub-id-type="doi">10.1007/978-3-642-29746-5_16</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Castellini</surname><given-names>C.</given-names></name><name><surname>Gruppioni</surname><given-names>E.</given-names></name><name><surname>Davalli</surname><given-names>A.</given-names></name><name><surname>Sandini</surname><given-names>G.</given-names></name></person-group> (<year>2009</year>). <article-title>Fine detection of grasp force and posture by amputees via surface electromyography</article-title>. <source>J. Physiol. Paris</source>
<volume>103</volume>, <fpage>255</fpage>–<lpage>262</lpage>. <pub-id pub-id-type="doi">10.1016/j.jphysparis.2009.08.008</pub-id><?supplied-pmid 19665563?><pub-id pub-id-type="pmid">19665563</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaudhary</surname><given-names>U.</given-names></name><name><surname>Birbaumer</surname><given-names>N.</given-names></name><name><surname>Ramos-Murguialday</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>). <article-title>Brain-computer interfaces for communication and rehabilitation</article-title>. <source>Nat. Rev. Neurol</source>. <volume>12</volume>, <fpage>513</fpage>–<lpage>525</lpage>. <pub-id pub-id-type="doi">10.1038/nrneurol.2016.113</pub-id><?supplied-pmid 27539560?><pub-id pub-id-type="pmid">27539560</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cipriani</surname><given-names>C.</given-names></name><name><surname>Antfolk</surname><given-names>C.</given-names></name><name><surname>Controzzi</surname><given-names>M.</given-names></name><name><surname>Lundborg</surname><given-names>G.</given-names></name><name><surname>Rosen</surname><given-names>B.</given-names></name><name><surname>Carrozza</surname><given-names>M. C.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Online myoelectric control of a dexterous hand prosthesis by transradial amputees</article-title>. <source>IEEE Trans. Neural Syst. Rehabil. Eng</source>. <volume>19</volume>, <fpage>260</fpage>–<lpage>270</lpage>. <pub-id pub-id-type="doi">10.1109/TNSRE.2011.2108667</pub-id><?supplied-pmid 21292599?><pub-id pub-id-type="pmid">21292599</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Luca</surname><given-names>A.</given-names></name><name><surname>Bellitto</surname><given-names>A.</given-names></name><name><surname>Mandraccia</surname><given-names>S.</given-names></name><name><surname>Marchesi</surname><given-names>G.</given-names></name><name><surname>Pellegrino</surname><given-names>L.</given-names></name><name><surname>Coscia</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Exoskeleton for gait rehabilitation: effects of assistance, mechanical structure, and walking aids on muscle activations</article-title>. <source>Appl. Sci</source>. <volume>9</volume>, <fpage>2868</fpage>. <pub-id pub-id-type="doi">10.3390/app9142868</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edelman</surname><given-names>B. J.</given-names></name><name><surname>Meng</surname><given-names>J.</given-names></name><name><surname>Suma</surname><given-names>D.</given-names></name><name><surname>Zurn</surname><given-names>C.</given-names></name><name><surname>Nagarajan</surname><given-names>E.</given-names></name><name><surname>Baxter</surname><given-names>B. S.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Noninvasive neuroimaging enhances continuous neural tracking for robotic device control</article-title>. <source>Sci. Rob</source>. <volume>4</volume>, <fpage>eaaw6844</fpage>. <pub-id pub-id-type="doi">10.1126/scirobotics.aaw6844</pub-id><?supplied-pmid 31656937?><pub-id pub-id-type="pmid">31656937</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farrell</surname><given-names>T. R.</given-names></name><name><surname>Weir</surname><given-names>R. F.</given-names></name></person-group> (<year>2008</year>). <article-title>A comparison of the effects of electrode implantation and targeting on pattern classification accuracy for prosthesis control</article-title>. <source>IEEE Trans. Biomed. Eng</source>. <volume>55</volume>, <fpage>2198</fpage>–<lpage>2211</lpage>. <pub-id pub-id-type="doi">10.1109/TBME.2008.923917</pub-id><?supplied-pmid 18713689?><pub-id pub-id-type="pmid">18713689</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochberg</surname><given-names>L.</given-names></name><name><surname>Bacher</surname><given-names>D.</given-names></name><name><surname>Jarosiewicz</surname><given-names>B.</given-names></name><name><surname>Masse</surname><given-names>N.</given-names></name><name><surname>Simeral</surname><given-names>J.</given-names></name><name><surname>Vogel</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Reach and grasp by people with tetraplegia using a neurally controlled robotic arm</article-title>. <source>Nature</source><volume>485</volume>, <fpage>372</fpage>–<lpage>375</lpage>. <pub-id pub-id-type="doi">10.1038/nature11076</pub-id><?supplied-pmid 22596161?><pub-id pub-id-type="pmid">22596161</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iez</surname><given-names>E.</given-names></name><name><surname>Azor-n</surname><given-names>J. M.</given-names></name><name><surname>beda</surname><given-names>A.</given-names></name><name><surname>Ferrndez</surname><given-names>J. M.</given-names></name><name><surname>Fernndez</surname><given-names>E.</given-names></name></person-group> (<year>2010</year>). <article-title>Mental tasks-based brain robot interface</article-title>. <source>Rob. Auton. Syst</source>. <volume>58</volume>, <fpage>1238</fpage>–<lpage>1245</lpage>. <pub-id pub-id-type="doi">10.1016/j.robot.2010.08.007</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kennedy</surname><given-names>P.</given-names></name><name><surname>Bakay</surname><given-names>R.</given-names></name></person-group> (<year>1998</year>). <article-title>Restoration of neural output from a paralyzed patient by a direct brain connection</article-title>. <source>Neuroreport</source>
<volume>9</volume>, <fpage>1707</fpage>–<lpage>1711</lpage>. <pub-id pub-id-type="doi">10.1097/00001756-199806010-00007</pub-id><?supplied-pmid 9665587?><pub-id pub-id-type="pmid">9665587</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leeb</surname><given-names>R.</given-names></name><name><surname>Perdikis</surname><given-names>S.</given-names></name><name><surname>Tonin</surname><given-names>L.</given-names></name><name><surname>Biasiucci</surname><given-names>A.</given-names></name><name><surname>Tavella</surname><given-names>M.</given-names></name><name><surname>Creatura</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Transferring brain-computer interfaces beyond the laboratory: successful application control for motor-disabled users</article-title>. <source>Artif. Intell. Med</source>. <volume>59</volume>, <fpage>121</fpage>–<lpage>132</lpage>. <pub-id pub-id-type="doi">10.1016/j.artmed.2013.08.004</pub-id><?supplied-pmid 24119870?><pub-id pub-id-type="pmid">24119870</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leeb</surname><given-names>R.</given-names></name><name><surname>Tonin</surname><given-names>L.</given-names></name><name><surname>Rohm</surname><given-names>M.</given-names></name><name><surname>Desideri</surname><given-names>L.</given-names></name><name><surname>Carlson</surname><given-names>T.</given-names></name><name><surname>Millán</surname><given-names>J.</given-names></name></person-group> (<year>2015</year>). <article-title>Towards independence: a BCI telepresence robot for people with severe motor disabilities</article-title>. <source>Proc. IEEE</source>
<volume>103</volume>, <fpage>969</fpage>–<lpage>982</lpage>. <pub-id pub-id-type="doi">10.1109/JPROC.2015.2419736</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>D.</given-names></name><name><surname>Chen</surname><given-names>W.</given-names></name><name><surname>Lee</surname><given-names>K.</given-names></name><name><surname>Chavarriaga</surname><given-names>R.</given-names></name><name><surname>Bouri</surname><given-names>M.</given-names></name><name><surname>Pei</surname><given-names>Z.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>Brain-actuated gait trainer with visual and proprioceptive feedback</article-title>. <source>J. Neural Eng</source>. <volume>14</volume>, <fpage>056017</fpage>. <pub-id pub-id-type="doi">10.1088/1741-2552/aa7df9</pub-id><?supplied-pmid 28696340?><pub-id pub-id-type="pmid">28696340</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>D.</given-names></name><name><surname>Chen</surname><given-names>W.</given-names></name><name><surname>Lee</surname><given-names>K.</given-names></name><name><surname>Chavarriaga</surname><given-names>R.</given-names></name><name><surname>Iwane</surname><given-names>F.</given-names></name><name><surname>Bouri</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>EEG-based lower-limb movement onset decoding: continuous classification and asynchronous detection</article-title>. <source>IEEE Trans. Neural Syst. Rehabil. Eng</source>. <volume>26</volume>, <fpage>1626</fpage>–<lpage>1635</lpage>. <pub-id pub-id-type="doi">10.1109/TNSRE.2018.2855053</pub-id><?supplied-pmid 30004882?><pub-id pub-id-type="pmid">30004882</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Müller-Putz</surname><given-names>G.</given-names></name><name><surname>Breitwieser</surname><given-names>C.</given-names></name><name><surname>Cincotti</surname><given-names>F.</given-names></name><name><surname>Leeb</surname><given-names>R.</given-names></name><name><surname>Schreuder</surname><given-names>M.</given-names></name><name><surname>Leotta</surname><given-names>F.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Tools for Brain-Computer Interaction: a general concept for a hybrid bci</article-title>. <source>Front. Neuroinform</source>. <volume>5</volume>, <fpage>30</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2011.00030</pub-id><?supplied-pmid 22131973?><pub-id pub-id-type="pmid">22131973</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parajuli</surname><given-names>N.</given-names></name><name><surname>Sreenivasan</surname><given-names>N.</given-names></name><name><surname>Bifulco</surname><given-names>P.</given-names></name><name><surname>Cesarelli</surname><given-names>M.</given-names></name><name><surname>Savino</surname><given-names>S.</given-names></name><name><surname>Niola</surname><given-names>V.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Real-time EMG based pattern recognition control for hand prostheses: a review on existing methods, challenges and future implementation</article-title>. <source>Sensors</source><volume>19</volume>, <fpage>4596</fpage>. <pub-id pub-id-type="doi">10.3390/s19204596</pub-id><?supplied-pmid 31652616?><pub-id pub-id-type="pmid">31652616</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perdikis</surname><given-names>S.</given-names></name><name><surname>Millán</surname><given-names>J.</given-names></name></person-group> (<year>2020</year>). <article-title>Brain-machine interfaces: a tale of two learners</article-title>. <source>IEEE Syst. Man Cybern. Mag</source>. <volume>6</volume>, <fpage>12</fpage>–<lpage>19</lpage>. <pub-id pub-id-type="doi">10.1109/MSMC.2019.2958200</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perdikis</surname><given-names>S.</given-names></name><name><surname>Tonin</surname><given-names>L.</given-names></name><name><surname>Saeedi</surname><given-names>S.</given-names></name><name><surname>Schneider</surname><given-names>C.</given-names></name><name><surname>Millán</surname><given-names>J.</given-names></name></person-group> (<year>2018</year>). <article-title>The cybathlon BCI race: successful longitudinal mutual learning with two tetraplegic users</article-title>. <source>PLoS Biol</source>. <volume>16</volume>, <fpage>e2003787</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pbio.2003787</pub-id><?supplied-pmid 29746465?><pub-id pub-id-type="pmid">29746465</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Quigley</surname><given-names>M.</given-names></name><name><surname>Gerkey</surname><given-names>B.</given-names></name><name><surname>Conley</surname><given-names>K.</given-names></name><name><surname>Faust</surname><given-names>J.</given-names></name><name><surname>Foote</surname><given-names>T.</given-names></name><name><surname>Leibs</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2009</year>). <article-title>“ROS: an open-source Robot Operating System,”</article-title> in <source>ICRA workshop on Open Source Software, Vol. 3</source> (<publisher-loc>Kobe</publisher-loc>).</mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stegman</surname><given-names>P.</given-names></name><name><surname>Crawford</surname><given-names>C. S.</given-names></name><name><surname>Andujar</surname><given-names>M.</given-names></name><name><surname>Nijholt</surname><given-names>A.</given-names></name><name><surname>Gilbert</surname><given-names>J. E.</given-names></name></person-group> (<year>2020</year>). <article-title>Brain computer interface software: a review and discussion</article-title>. <source>IEEE Trans. Hum. Mach. Syst</source>. <volume>50</volume>, <fpage>101</fpage>–<lpage>115</lpage>. <pub-id pub-id-type="doi">10.1109/THMS.2020.2968411</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sylos-Labini</surname><given-names>F.</given-names></name><name><surname>La Scaleia</surname><given-names>V.</given-names></name><name><surname>d'Avella</surname><given-names>A.</given-names></name><name><surname>Pisotta</surname><given-names>I.</given-names></name><name><surname>Tamburella</surname><given-names>F.</given-names></name><name><surname>Scivoletto</surname><given-names>G.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>EMG patterns during assisted walking in the exoskeleton</article-title>. <source>Front. Hum. Neurosci</source>. <volume>8</volume>, <fpage>423</fpage>. <pub-id pub-id-type="doi">10.3389/fnhum.2014.00423</pub-id><?supplied-pmid 24982628?><pub-id pub-id-type="pmid">24982628</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tonin</surname><given-names>L.</given-names></name><name><surname>Bauer</surname><given-names>F.</given-names></name><name><surname>Millán</surname><given-names>J.</given-names></name></person-group> (<year>2020</year>). <article-title>The role of the control framework for continuous tele-operation of a BMI driven mobile robot</article-title>. <source>IEEE Trans. Rob</source>. <volume>36</volume>, <fpage>78</fpage>–<lpage>91</lpage>. <pub-id pub-id-type="doi">10.1109/TRO.2019.2943072</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tonin</surname><given-names>L.</given-names></name><name><surname>Beraldo</surname><given-names>G.</given-names></name><name><surname>Tortora</surname><given-names>S.</given-names></name><name><surname>Tagliapietra</surname><given-names>L.</given-names></name><name><surname>Milln</surname><given-names>J. d. R.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>ROS-“Neuro: a common middleware for BMI and robotics. the acquisition and recorder packages,”</article-title> in <source>2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)</source> (<publisher-loc>Bari</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>2767</fpage>–<lpage>2772</lpage>.</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tonin</surname><given-names>L.</given-names></name><name><surname>Millán</surname><given-names>J.</given-names></name></person-group> (<year>2021</year>). <article-title>Noninvasive brain-machine interfaces for robotic devices</article-title>. <source>Ann. Rev. Control Rob. Auton. Syst</source>. <volume>4</volume>, <fpage>191</fpage>–<lpage>214</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-control-012720-093904</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolf</surname><given-names>P.</given-names></name><name><surname>Riener</surname><given-names>R.</given-names></name></person-group> (<year>2018</year>). <article-title>Cybathlon: how to promote the development of assistive technologies</article-title>. <source>Sci. Rob</source>. <volume>3</volume>, <fpage>eaat7174</fpage>. <pub-id pub-id-type="doi">10.1126/scirobotics.aat7174</pub-id><?supplied-pmid 33141744?><pub-id pub-id-type="pmid">33141744</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
