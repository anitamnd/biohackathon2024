<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10032634</article-id>
    <article-id pub-id-type="pmid">36883697</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btad123</article-id>
    <article-id pub-id-type="publisher-id">btad123</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Systems Biology</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CFAGO: cross-fusion of network and attributes based on attention mechanism for protein function prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wu</surname>
          <given-names>Zhourun</given-names>
        </name>
        <aff><institution>School of Computer Science and Technology, Harbin Institute of Technology</institution>, Shenzhen, Guangdong 518055, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Guo</surname>
          <given-names>Mingyue</given-names>
        </name>
        <aff><institution>School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences</institution>, Beijing 101408, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jin</surname>
          <given-names>Xiaopeng</given-names>
        </name>
        <aff><institution>College of Big Data and Internet, Shenzhen Technology University</institution>, Shenzhen, Guangdong 518118, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-0483-303X</contrib-id>
        <name>
          <surname>Chen</surname>
          <given-names>Junjie</given-names>
        </name>
        <aff><institution>School of Computer Science and Technology, Harbin Institute of Technology</institution>, Shenzhen, Guangdong 518055, <country country="CN">China</country></aff>
        <xref rid="btad123-cor1" ref-type="corresp"/>
        <!--junjiechen@hit.edu.cn-->
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-3685-9469</contrib-id>
        <name>
          <surname>Liu</surname>
          <given-names>Bin</given-names>
        </name>
        <aff><institution>School of Computer Science and Technology, Harbin Institute of Technology</institution>, Shenzhen, Guangdong 518055, <country country="CN">China</country></aff>
        <aff><institution>School of Computer Science and Technology, Beijing Institute of Technology</institution>, Beijing 100081, <country country="CN">China</country></aff>
        <aff><institution>Advanced Research Institute of Multidisciplinary Science, Beijing Institute of Technology</institution>, Beijing 100081, <country country="CN">China</country></aff>
        <xref rid="btad123-cor1" ref-type="corresp"/>
        <!--bliu@bliulab.net-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btad123-cor1">Corresponding author. <email>junjiechen@hit.edu.cn</email> (J.C.); <email>bliu@bliulab.net</email> (B.L.)</corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-03-08">
      <day>08</day>
      <month>3</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>08</day>
      <month>3</month>
      <year>2023</year>
    </pub-date>
    <volume>39</volume>
    <issue>3</issue>
    <elocation-id>btad123</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>28</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>05</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>05</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>22</day>
        <month>3</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btad123.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Protein function annotation is fundamental to understanding biological mechanisms. The abundant genome-scale protein–protein interaction (PPI) networks, together with other protein biological attributes, provide rich information for annotating protein functions. As PPI networks and biological attributes describe protein functions from different perspectives, it is highly challenging to cross-fuse them for protein function prediction. Recently, several methods combine the PPI networks and protein attributes via the graph neural networks (GNNs). However, GNNs may inherit or even magnify the bias caused by noisy edges in PPI networks. Besides, GNNs with stacking of many layers may cause the over-smoothing problem of node representations.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We develop a novel protein function prediction method, CFAGO, to integrate single-species PPI networks and protein biological attributes via a multi-head attention mechanism. CFAGO is first pre-trained with an encoder–decoder architecture to capture the universal protein representation of the two sources. It is then fine-tuned to learn more effective protein representations for protein function prediction. Benchmark experiments on human and mouse datasets show CFAGO outperforms state-of-the-art single-species network-based methods by at least 7.59%, 6.90%, 11.68% in terms of m-AUPR, M-AUPR, and Fmax, respectively, demonstrating cross-fusion by multi-head attention mechanism can greatly improve the protein function prediction. We further evaluate the quality of captured protein representations in terms of Davies Bouldin Score, whose results show that cross-fused protein representations by multi-head attention mechanism are at least 2.7% better than that of original and concatenated representations. We believe CFAGO is an effective tool for protein function prediction.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The source code of CFAGO and experiments data are available at: <ext-link xlink:href="http://bliulab.net/CFAGO/" ext-link-type="uri">http://bliulab.net/CFAGO/</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>62102118</award-id>
        <award-id>62271049</award-id>
        <award-id>U22A2039</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Educational Commission of Guangdong Province of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2021KQNCX274</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Shenzhen Colleges and Universities Stable Support Program</institution>
          </institution-wrap>
        </funding-source>
        <award-id>GXWD20220811170504001</award-id>
        <award-id>20220715183602001</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Annotating protein functions is the key for unveiling the mechanism of disease, bringing great benefits for biomedical and pharmaceutical (<xref rid="btad123-B41" ref-type="bibr">Radivojac et al. 2013</xref>). Currently, protein functions are standardized by Gene Ontology (GO) (<xref rid="btad123-B1" ref-type="bibr">Ashburner et al. 2000</xref>; <xref rid="btad123-B750" ref-type="bibr">Carbon et al. 2021</xref>), which covers three aspects: biological process ontology (BPO), molecular function ontology (MFO), and cellular component ontology (CCO). Because biochemical experiments are expensive and time-consuming, it is impractical to experimentally annotate protein functions in large scale. In fact, only about 0.25% of known proteins have been experimentally annotated their functions (<xref rid="btad123-B47" ref-type="bibr">UniProt 2021</xref>). Therefore, to fill the huge vacancy of protein function annotation, developing effective and accurate computational protein function prediction methods is of great importance (<xref rid="btad123-B41" ref-type="bibr">Radivojac et al. 2013</xref>; <xref rid="btad123-B21" ref-type="bibr">Jiang et al. 2016</xref>; <xref rid="btad123-B55" ref-type="bibr">Zhou et al. 2019</xref>).</p>
    <p>In the past decades, a lot of computational protein function prediction methods have been developed (<xref rid="btad123-B12" ref-type="bibr">Friedberg 2006</xref>; <xref rid="btad123-B30" ref-type="bibr">Lee et al. 2007</xref>; <xref rid="btad123-B42" ref-type="bibr">Rentzsch and Orengo 2009</xref>; <xref rid="btad123-B23" ref-type="bibr">Kihara 2016</xref>). Depending on their paradigms of feature extraction, these methods can be divided into four categories: sequence-based methods, structure-based methods, protein–protein interaction (PPI) network-based methods, and multi-source-based methods. As high sequence identity implies a similar function (<xref rid="btad123-B24" ref-type="bibr">Kimura and Ohta 1974</xref>; <xref rid="btad123-B32" ref-type="bibr">Lord et al. 2003</xref>), sequence-based methods infer protein functions by retrieving similar sequences (<xref rid="btad123-B7" ref-type="bibr">Cozzetto et al. 2013</xref>; <xref rid="btad123-B41" ref-type="bibr">Radivojac et al. 2013</xref>; <xref rid="btad123-B17" ref-type="bibr">Gong et al. 2016</xref>; <xref rid="btad123-B52" ref-type="bibr">You et al. 2018</xref>; <xref rid="btad123-B36" ref-type="bibr">Makrodimitris et al. 2019</xref>; <xref rid="btad123-B25" ref-type="bibr">Kulmanov and Hoehndorf 2020</xref>; <xref rid="btad123-B51" ref-type="bibr">Villegas-Morcillo et al. 2021</xref>; <xref rid="btad123-B26" ref-type="bibr">Kulmanov and Hoehndorf 2022</xref>). However, many proteins are similar in function, but not in sequence, so sequence-only-based methods are unable to predict functions for proteins with low sequence similarity. Protein structure determines its function, and proteins with similar structures usually share similar functions even when their sequence similarities are very low (<xref rid="btad123-B4" ref-type="bibr">Brenner et al. 1996</xref>; <xref rid="btad123-B20" ref-type="bibr">Holm and Sander 1996</xref>; <xref rid="btad123-B44" ref-type="bibr">Rost 1999</xref>). Therefore, structure-based methods detect the structure similarity between proteins to determine the functions of target proteins (<xref rid="btad123-B19" ref-type="bibr">Holm and Sander 1995</xref>; <xref rid="btad123-B14" ref-type="bibr">Gibrat et al. 1996</xref>; <xref rid="btad123-B29" ref-type="bibr">Laskowski et al. 2005</xref>). However, it is expensive to determine protein structures, and the amount of protein structure data is small. Although AlphaFold2 (<xref rid="btad123-B22" ref-type="bibr">Jumper et al. 2021</xref>) can predict protein structures from sequences, it has a limitation on the prediction of protein multi-chain structure that is the true structure for most proteins in living cells (<xref rid="btad123-B49" ref-type="bibr">Varadi et al. 2022</xref>). These facts limit the application of structure-based methods. On the other hand, as high-throughput techniques can screen PPIs in genome scale, predicting protein functions from PPI networks is desirable. PPI network-based methods assume similar functions usually shared by proteins with interaction (<xref rid="btad123-B45" ref-type="bibr">Sharan et al. 2007</xref>) or proteins with similar topological roles in PPI networks (<xref rid="btad123-B37" ref-type="bibr">Milenkovic and Przulj 2008</xref>). They predict protein functions either by label propagation among network nodes (<xref rid="btad123-B40" ref-type="bibr">Mostafavi et al. 2008</xref>; <xref rid="btad123-B39" ref-type="bibr">Mostafavi and Morris 2010</xref>) or by graph embedding of PPI network (<xref rid="btad123-B6" ref-type="bibr">Cho et al. 2016</xref>; <xref rid="btad123-B15" ref-type="bibr">Gligorijevic et al. 2018</xref>). However, high-throughput PPI data are incomplete and noisy due to the technical bias (<xref rid="btad123-B10" ref-type="bibr">De Las Rivas and Fontanillo 2010</xref>; <xref rid="btad123-B34" ref-type="bibr">Luck et al. 2020</xref>). Therefore, PPI networks alone cannot compactly describe protein functions. Protein information from multiple sources is complementary, such as PPI network and sequence (<xref rid="btad123-B27" ref-type="bibr">Kulmanov et al. 2018</xref>; <xref rid="btad123-B3" ref-type="bibr">Barot et al. 2021</xref>; <xref rid="btad123-B53" ref-type="bibr">You et al. 2021</xref>), in addition to subcellular location (<xref rid="btad123-B11" ref-type="bibr">Fan et al. 2020</xref>), text and sequence (<xref rid="btad123-B54" ref-type="bibr">You et al. 2018</xref>), structure and sequence (<xref rid="btad123-B16" ref-type="bibr">Gligorijevic et al. 2021</xref>; <xref rid="btad123-B28" ref-type="bibr">Lai and Xu 2022</xref>), etc. The last three Critical Assessment of Functional Annotation (CAFA) challenges have shown that the combination of different information indeed achieved the best performance on protein function prediction (<xref rid="btad123-B41" ref-type="bibr">Radivojac et al. 2013</xref>; <xref rid="btad123-B21" ref-type="bibr">Jiang et al. 2016</xref>; <xref rid="btad123-B55" ref-type="bibr">Zhou et al. 2019</xref>).</p>
    <p>There are two main ways to combine protein information from multiple sources. The intuitive and simple way is concatenation, which directly concatenates the representations of multiple sources as the input of classifiers (<xref rid="btad123-B27" ref-type="bibr">Kulmanov et al. 2018</xref>). However, the concatenation fails to remove the effect of noise information from various sources. The widely used way is the graph neural networks (GNNs), which take the PPI network as graph and other information as node attribute features (<xref rid="btad123-B11" ref-type="bibr">Fan et al. 2020</xref>; <xref rid="btad123-B53" ref-type="bibr">You et al. 2021</xref>). But the message-passing mechanism of GNNs may inherit or even magnify the noise effect in networks (<xref rid="btad123-B8" ref-type="bibr">Dai and Wang 2021</xref>). Besides, GNNs with deep layers may cause the over-smoothing problem that all nodes tend to learn the same representation (<xref rid="btad123-B31" ref-type="bibr">Li et al. 2018</xref>; <xref rid="btad123-B5" ref-type="bibr">Cai and Wang 2020)</xref>. Thus, it is urgent to propose a new method to integrate PPI network and other protein attributes into a more powerful representation.</p>
    <p>In this study, we propose a new method called CFAGO to cross-fuse single-species PPI network and protein biological attributes via a multi-head attention mechanism. CFAGO contains a pre-training step and a fine-tuning step, and both of them use the multi-head attention mechanism to focus on important information. The pre-training step consists of an autoencoder, which can cross-fuse the effective information while ignoring the noise in the sources. The fine-tuning step learns more distinguishing protein representations for protein function annotation. The experimental results on human and mouse datasets show that CFAGO outperforms state-of-the-art single-species network-based protein function prediction methods, including pure PPI network-based methods and GNN-based fusion methods. Both the ablation study and protein representation visualization show the multi-head attention mechanism has an important contribution to fuse features of PPI network and other sources for single-species protein function prediction.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>We conduct experiments on two species: <italic toggle="yes">Homo sapiens</italic> (human) and <italic toggle="yes">Mus musculus</italic> (mouse). The PPI data and protein sequence data are retrieved from the STRING (v11.5) database (<xref rid="btad123-B46" ref-type="bibr">Szklarczyk et al. 2021</xref>). In particular, we use the ‘combined’ type PPI data, which includes all of the ‘experimental’, ‘coexpression’, ‘coocurrence’, ‘neighborhood’, ‘fusion’, ‘database’, and ‘textmining’ types of PPI data. The protein function annotation data are retrieved from Gene Ontology Resource (<ext-link xlink:href="http://geneontology.org" ext-link-type="uri">http://geneontology.org</ext-link>) (version 2022-01-13 release) (<xref rid="btad123-B1" ref-type="bibr">Ashburner et al. 2000</xref>; <xref rid="btad123-B750" ref-type="bibr">Carbon et al. 2021</xref>). Protein subcellular location and protein domain data are retrieved from the UniProt database (v3.5.175) (<xref rid="btad123-B47" ref-type="bibr">UniProt 2021</xref>). Specifically, the protein domain from the pfam database (<xref rid="btad123-B38" ref-type="bibr">Mistry et al. 2021</xref>) is used.</p>
      <p>Following the standard CAFA protocol (<xref rid="btad123-B41" ref-type="bibr">Radivojac et al. 2013</xref>; <xref rid="btad123-B21" ref-type="bibr">Jiang et al. 2016</xref>; <xref rid="btad123-B55" ref-type="bibr">Zhou et al. 2019</xref>), we extract experimental annotations of protein functions with evidence ‘IDA’, ‘IPI’, ‘EXP’, ‘IGI’, ‘IMP’, ‘IEP’, ‘IC’, or ‘TA’, and use two time points: <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> (1 January 2018), <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> (31 December 2020), to divide annotated proteins into training, validation, and testing sets. Concretely, the training set consists of proteins that have been annotated no later than <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, validation set consists of proteins that only have been annotated in <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:math></inline-formula>, testing set consists of proteins that only have been annotated after <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. We only use GO terms that have at least 10, 5, and 1 training, validation, and testing proteins, respectively. Furthermore, to reduce the effect of the dependence relationship between GO terms, we remove those GO terms annotating more than 5% of the species’ PPI network proteins, following a previous study (<xref rid="btad123-B3" ref-type="bibr">Barot et al. 2021</xref>). The statistics of GO terms, training, validation, and testing sets used in this study is shown in <xref rid="btad123-T1" ref-type="table">Table 1</xref>.</p>
      <table-wrap position="float" id="btad123-T1">
        <label>Table 1.</label>
        <caption>
          <p>Data statistics considered for each organism and Gene Ontology branch</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Species</th>
              <th rowspan="1" colspan="1">Statistics</th>
              <th rowspan="1" colspan="1">BPO</th>
              <th rowspan="1" colspan="1">MFO</th>
              <th rowspan="1" colspan="1">CCO</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="4" colspan="1">Human</td>
              <td rowspan="1" colspan="1">#GO terms</td>
              <td rowspan="1" colspan="1">45</td>
              <td rowspan="1" colspan="1">38</td>
              <td rowspan="1" colspan="1">35</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">#training proteins</td>
              <td rowspan="1" colspan="1">3197</td>
              <td rowspan="1" colspan="1">2747</td>
              <td rowspan="1" colspan="1">5263</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">#validation proteins</td>
              <td rowspan="1" colspan="1">304</td>
              <td rowspan="1" colspan="1">503</td>
              <td rowspan="1" colspan="1">577</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">#testing proteins</td>
              <td rowspan="1" colspan="1">182</td>
              <td rowspan="1" colspan="1">719</td>
              <td rowspan="1" colspan="1">119</td>
            </tr>
            <tr>
              <td rowspan="4" colspan="1">Mouse</td>
              <td rowspan="1" colspan="1">#GO terms</td>
              <td rowspan="1" colspan="1">42</td>
              <td rowspan="1" colspan="1">17</td>
              <td rowspan="1" colspan="1">37</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">#training proteins</td>
              <td rowspan="1" colspan="1">2714</td>
              <td rowspan="1" colspan="1">1185</td>
              <td rowspan="1" colspan="1">4014</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">#validation proteins</td>
              <td rowspan="1" colspan="1">336</td>
              <td rowspan="1" colspan="1">232</td>
              <td rowspan="1" colspan="1">694</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">#testing proteins</td>
              <td rowspan="1" colspan="1">155</td>
              <td rowspan="1" colspan="1">126</td>
              <td rowspan="1" colspan="1">147</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>2.2 Method</title>
      <p>CFAGO introduces multi-head attention layers to cross-fuse protein information from different sources in two steps (<xref rid="btad123-F1" ref-type="fig">Fig. 1</xref>). The first step is the pre-training, which is an encoder–decoder model that learns protein hidden embedding vectors by reconstructing original source features. The second step is fine-tuning, which combines the pre-trained encoder with a two-layer fully-connected neural network to predict protein functions.</p>
      <fig position="float" id="btad123-F1">
        <label>Figure 1</label>
        <caption>
          <p>The flowchart of CFAGO. (a) Architecture of encoder–decoder for CFAGO pre-training step, where MLP stands for multilayer perceptron. (b) Architecture of CFAGO fine-tuning step. (c) Multi-head attention layer of Encoder and Decoder. (d) Scaled Dot-Product Attention of Multi-head attention layer.</p>
        </caption>
        <graphic xlink:href="btad123f1" position="float"/>
      </fig>
      <sec>
        <title>2.2.1 PPI network structure and node attribute representations</title>
        <p>For a protein, we use its first-order neighborhood of the PPI network to represent its network structure. Specifically, we first convert the PPI network into a weighted adjacency matrix, in which elements are weights of edges, then normalize elements to range <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>0,1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> by min-max normalization. A column vector of the normalized adjacency matrix is a protein representation that contains normalized weights to its first-order neighborhoods.</p>
        <p>For the protein attributes, we select the widely used protein domain and subcellular location information. Protein attributes are represented as binary vectors by bag-of-words encoding, which assigns 1 to an element in the binary vector if the protein is annotated with the corresponding domain or subcellular location. We filter out protein domain terms that appear less than 6 times in the dataset, following a previous study (<xref rid="btad123-B11" ref-type="bibr">Fan et al. 2020</xref>). Without prior knowledge of different attributes and GO aspects, we concatenate the two attribute vectors as the protein attribute vector representation for all GO aspects.</p>
      </sec>
      <sec>
        <title>2.2.2 Multi-head attention layer</title>
        <p>Here we define the multi-head attention layer following a previous study (<xref rid="btad123-B50" ref-type="bibr">Vaswani et al. 2017</xref>). The multi-head attention layer consists of multi-head attention, residual connection, normalization, and position-wise feed-forward networks. The core of multi-head attention is the Scaled Dot-Product Attention (<xref rid="btad123-B50" ref-type="bibr">Vaswani et al. 2017</xref>):
where <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi mathvariant="bold">Q</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">K</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">V</mml:mi></mml:math></inline-formula> are the query matrix, key matrix, and value matrix, respectively, and <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the dimension size of key matrix. The multi-head attention is defined as (<xref rid="btad123-B50" ref-type="bibr">Vaswani et al. 2017</xref>):
where <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mi>n</mml:mi></mml:math></inline-formula> is the number of heads, <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="italic">head</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is defined as:
where <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula> are projection weight parameter matrices. Here <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mi>d</mml:mi></mml:math></inline-formula> is the dimension size of hidden embedding vectors, and <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mo>/</mml:mo><mml:mi>n</mml:mi></mml:math></inline-formula>.</p>
        <disp-formula id="E1">
          <label>(1)</label>
          <mml:math id="M1" display="block" overflow="scroll">
            <mml:mi mathvariant="normal">Attention</mml:mi>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:mi mathvariant="bold">Q</mml:mi>
                <mml:mo>,</mml:mo>
                <mml:mi mathvariant="bold">K</mml:mi>
                <mml:mo>,</mml:mo>
                <mml:mi mathvariant="bold">V</mml:mi>
              </mml:mrow>
            </mml:mfenced>
            <mml:mo>=</mml:mo>
            <mml:mi mathvariant="normal">softmax</mml:mi>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi mathvariant="bold">Q</mml:mi>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">K</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>T</mml:mi>
                      </mml:mrow>
                    </mml:msup>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msqrt>
                      <mml:msub>
                        <mml:mrow>
                          <mml:mi>d</mml:mi>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>k</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                    </mml:msqrt>
                  </mml:mrow>
                </mml:mfrac>
              </mml:mrow>
            </mml:mfenced>
            <mml:mi mathvariant="bold">V</mml:mi>
          </mml:math>
        </disp-formula>
        <disp-formula id="E2">
          <label>(2)</label>
          <mml:math id="M2" display="block" overflow="scroll">
            <mml:mi mathvariant="normal">MultiHead</mml:mi>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:mi mathvariant="bold">Q</mml:mi>
                <mml:mo>,</mml:mo>
                <mml:mi mathvariant="bold">K</mml:mi>
                <mml:mo>,</mml:mo>
                <mml:mi mathvariant="bold">V</mml:mi>
              </mml:mrow>
            </mml:mfenced>
            <mml:mo>=</mml:mo>
            <mml:mi mathvariant="normal">Concat</mml:mi>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi mathvariant="italic">head</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>,</mml:mo>
                <mml:mo>…</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi mathvariant="italic">head</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>n</mml:mi>
                  </mml:mrow>
                </mml:msub>
              </mml:mrow>
            </mml:mfenced>
            <mml:msup>
              <mml:mrow>
                <mml:mi mathvariant="bold">W</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="normal">O</mml:mi>
              </mml:mrow>
            </mml:msup>
          </mml:math>
        </disp-formula>
        <disp-formula id="E3">
          <label>(3)</label>
          <mml:math id="M3" display="block" overflow="scroll">
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="italic">head</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>j</mml:mi>
              </mml:mrow>
            </mml:msub>
            <mml:mo>=</mml:mo>
            <mml:mi mathvariant="normal">Attention</mml:mi>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:mi mathvariant="bold">Q</mml:mi>
                <mml:msubsup>
                  <mml:mrow>
                    <mml:mi mathvariant="bold">W</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>j</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>Q</mml:mi>
                  </mml:mrow>
                </mml:msubsup>
                <mml:mo>,</mml:mo>
                <mml:mi mathvariant="bold">K</mml:mi>
                <mml:msubsup>
                  <mml:mrow>
                    <mml:mi mathvariant="bold">W</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>j</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>K</mml:mi>
                  </mml:mrow>
                </mml:msubsup>
                <mml:mo>,</mml:mo>
                <mml:mi mathvariant="bold">V</mml:mi>
                <mml:msubsup>
                  <mml:mrow>
                    <mml:mi mathvariant="bold">W</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>j</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>V</mml:mi>
                  </mml:mrow>
                </mml:msubsup>
              </mml:mrow>
            </mml:mfenced>
          </mml:math>
        </disp-formula>
        <p>The feed-forward network consists of two fully connected layers with a nonlinear activation function (<xref rid="btad123-B50" ref-type="bibr">Vaswani et al. 2017</xref>):
where <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mi>f</mml:mi></mml:math></inline-formula> is the nonlinear activation function, <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> are the weight parameter matrices of feed-forward network, <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the output dimension size of the first linear layer, <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> are bias parameter vectors.</p>
        <disp-formula id="E4">
          <label>(4)</label>
          <mml:math id="M4" display="block" overflow="scroll">
            <mml:mi mathvariant="normal">FFN</mml:mi>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:mi mathvariant="bold-italic">h</mml:mi>
              </mml:mrow>
            </mml:mfenced>
            <mml:mo>=</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="bold">W</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mn>2</mml:mn>
              </mml:mrow>
            </mml:msub>
            <mml:mi>f</mml:mi>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi mathvariant="bold">W</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msub>
                <mml:mi mathvariant="bold-italic">h</mml:mi>
                <mml:mo>+</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi mathvariant="bold-italic">b</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msub>
              </mml:mrow>
            </mml:mfenced>
            <mml:mo>+</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="bold-italic">b</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mn>2</mml:mn>
              </mml:mrow>
            </mml:msub>
          </mml:math>
        </disp-formula>
      </sec>
      <sec>
        <title>2.2.3 Pre-training with a self-supervised encoder–decoder</title>
        <p>The pre-training step uses an encoder–decoder model to cross-fuse information from two sources. For protein <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula>, its two original source features are represented as <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:math></inline-formula>, where <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mi>d</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the feature dimension of source <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mi>m</mml:mi></mml:math></inline-formula>.</p>
        <p><bold>Encoder:</bold> the encoder has two parallel multilayer perceptrons (MLPs), each for a source feature, and <italic toggle="yes">L</italic> multi-head attention layers. As original features of different sources may be sparse and differ in dimension, the original feature vector of protein <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula> from source <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mi>m</mml:mi></mml:math></inline-formula>, <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula>, is projected to a common vector with <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mi>d</mml:mi></mml:math></inline-formula> dimensions by a two-layer MLP, which is defined as:
where <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mi>f</mml:mi></mml:math></inline-formula> is the nonlinear activation function, <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mi mathvariant="normal">LN</mml:mi></mml:math></inline-formula> is the layer normalization function (<xref rid="btad123-B2" ref-type="bibr">Ba et al. 2016</xref>), <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>)</mml:mo><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> are the weight matrices, <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>and <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> are the bias vectors, <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the size of the MLP hidden layer. Then, the projected vectors of two sources are cross-fused by multi-head attention layers to generate protein-hidden embedding vectors.</p>
        <disp-formula id="E5">
          <label>(5)</label>
          <mml:math id="M5" display="block" overflow="scroll">
            <mml:mi mathvariant="normal">MLP</mml:mi>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:mi mathvariant="bold">x</mml:mi>
              </mml:mrow>
            </mml:mfenced>
            <mml:mo>=</mml:mo>
            <mml:mi>f</mml:mi>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:mi mathvariant="normal">LN</mml:mi>
                <mml:mfenced open="(" close=")" separators="|">
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">W</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mi>f</mml:mi>
                    <mml:mfenced open="(" close=")" separators="|">
                      <mml:mrow>
                        <mml:mi mathvariant="normal">LN</mml:mi>
                        <mml:mfenced open="(" close=")" separators="|">
                          <mml:mrow>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mi mathvariant="bold">W</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mn>1</mml:mn>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mi mathvariant="bold">x</mml:mi>
                            <mml:mo>+</mml:mo>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mi mathvariant="bold">b</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mn>1</mml:mn>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mrow>
                        </mml:mfenced>
                      </mml:mrow>
                    </mml:mfenced>
                  </mml:mrow>
                </mml:mfenced>
                <mml:mo>+</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi mathvariant="bold">b</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>2</mml:mn>
                  </mml:mrow>
                </mml:msub>
              </mml:mrow>
            </mml:mfenced>
          </mml:math>
        </disp-formula>
        <p><bold>Decoder:</bold> the structure of the decoder is symmetric to the encoder. The decoder first feeds the hidden embedding vectors into <italic toggle="yes">L</italic> multi-head attention layers. Then for protein <italic toggle="yes">i</italic>, the feature vector of source <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mi>m</mml:mi></mml:math></inline-formula> is reconstructed by an MLP whose structure is symmetric to the corresponding MLP in encoder, denoting as <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mi mathvariant="bold"> </mml:mi><mml:msubsup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula>. In decoder, the sigmoid function is used as the activation function of the output layer of MLPs.</p>
        <p>The aim of the encoder–decoder is to minimize the sample-wise binary cross-entropy loss between original and reconstructed source features:
where <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mi>N</mml:mi></mml:math></inline-formula> is the number of total proteins in PPI network, <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> are the <italic toggle="yes">j</italic>th dimension value of <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula>, respectively, <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mi mathvariant="normal">Θ</mml:mi></mml:math></inline-formula> is the set of all parameters in the pre-training step.</p>
        <disp-formula id="E6">
          <label>(6)</label>
          <mml:math id="M6" display="block" overflow="scroll">
            <mml:mi mathvariant="italic">loss</mml:mi>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:mi mathvariant="normal">Θ</mml:mi>
              </mml:mrow>
            </mml:mfenced>
            <mml:mo>=</mml:mo>
            <mml:mfrac>
              <mml:mrow>
                <mml:mn>1</mml:mn>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>N</mml:mi>
              </mml:mrow>
            </mml:mfrac>
            <mml:mrow>
              <mml:munderover>
                <mml:mo stretchy="false">∑</mml:mo>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>N</mml:mi>
                </mml:mrow>
              </mml:munderover>
              <mml:mrow>
                <mml:mrow>
                  <mml:munderover>
                    <mml:mo stretchy="false">∑</mml:mo>
                    <mml:mrow>
                      <mml:mi>m</mml:mi>
                      <mml:mo>=</mml:mo>
                      <mml:mn>1</mml:mn>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mn>2</mml:mn>
                    </mml:mrow>
                  </mml:munderover>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:munderover>
                        <mml:mo stretchy="false">∑</mml:mo>
                        <mml:mrow>
                          <mml:mi>j</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>d</mml:mi>
                          <mml:mfenced open="(" close=")" separators="|">
                            <mml:mrow>
                              <mml:mi>m</mml:mi>
                            </mml:mrow>
                          </mml:mfenced>
                        </mml:mrow>
                      </mml:munderover>
                      <mml:mrow>
                        <mml:mo>-</mml:mo>
                        <mml:mfenced open="[" close="]" separators="|">
                          <mml:mrow>
                            <mml:msubsup>
                              <mml:mrow>
                                <mml:mi>x</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>j</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mfenced open="(" close=")" separators="|">
                                  <mml:mrow>
                                    <mml:mi>m</mml:mi>
                                  </mml:mrow>
                                </mml:mfenced>
                              </mml:mrow>
                            </mml:msubsup>
                            <mml:mrow>
                              <mml:mrow>
                                <mml:mi mathvariant="normal">log</mml:mi>
                              </mml:mrow>
                              <mml:mo> </mml:mo>
                              <mml:mo>⁡</mml:mo>
                              <mml:mrow>
                                <mml:msubsup>
                                  <mml:mrow>
                                    <mml:mrow>
                                      <mml:mover accent="true">
                                        <mml:mrow>
                                          <mml:mi>x</mml:mi>
                                        </mml:mrow>
                                        <mml:mo>^</mml:mo>
                                      </mml:mover>
                                    </mml:mrow>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mi>i</mml:mi>
                                    <mml:mi>j</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mfenced open="(" close=")" separators="|">
                                      <mml:mrow>
                                        <mml:mi>m</mml:mi>
                                      </mml:mrow>
                                    </mml:mfenced>
                                  </mml:mrow>
                                </mml:msubsup>
                              </mml:mrow>
                            </mml:mrow>
                            <mml:mo>+</mml:mo>
                            <mml:mfenced open="(" close=")" separators="|">
                              <mml:mrow>
                                <mml:mn>1</mml:mn>
                                <mml:mo>-</mml:mo>
                                <mml:msubsup>
                                  <mml:mrow>
                                    <mml:mi>x</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mi>i</mml:mi>
                                    <mml:mi>j</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mfenced open="(" close=")" separators="|">
                                      <mml:mrow>
                                        <mml:mi>m</mml:mi>
                                      </mml:mrow>
                                    </mml:mfenced>
                                  </mml:mrow>
                                </mml:msubsup>
                              </mml:mrow>
                            </mml:mfenced>
                            <mml:mrow>
                              <mml:mrow>
                                <mml:mi mathvariant="normal">log</mml:mi>
                              </mml:mrow>
                              <mml:mo>⁡</mml:mo>
                              <mml:mrow>
                                <mml:mfenced open="(" close=")" separators="|">
                                  <mml:mrow>
                                    <mml:mn>1</mml:mn>
                                    <mml:mo>-</mml:mo>
                                    <mml:msubsup>
                                      <mml:mrow>
                                        <mml:mrow>
                                          <mml:mover accent="true">
                                            <mml:mrow>
                                              <mml:mi>x</mml:mi>
                                            </mml:mrow>
                                            <mml:mo>^</mml:mo>
                                          </mml:mover>
                                        </mml:mrow>
                                      </mml:mrow>
                                      <mml:mrow>
                                        <mml:mi>i</mml:mi>
                                        <mml:mi>j</mml:mi>
                                      </mml:mrow>
                                      <mml:mrow>
                                        <mml:mfenced open="(" close=")" separators="|">
                                          <mml:mrow>
                                            <mml:mi>m</mml:mi>
                                          </mml:mrow>
                                        </mml:mfenced>
                                      </mml:mrow>
                                    </mml:msubsup>
                                  </mml:mrow>
                                </mml:mfenced>
                              </mml:mrow>
                            </mml:mrow>
                          </mml:mrow>
                        </mml:mfenced>
                      </mml:mrow>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
          </mml:math>
        </disp-formula>
      </sec>
      <sec>
        <title>2.2.4 Fine-tuning for protein function prediction</title>
        <p>In this study, protein function prediction is modeled as a multi-label task. We extract the pre-trained encoder and attach it with a predictor, which is a two-layer perceptron, to predict protein labels. Let the number of target GO terms to be <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mi>K</mml:mi></mml:math></inline-formula>. The predictor takes the concatenation of the embedding vectors, denoting as <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula>, of the two sources generated by the encoder as input, and output a <italic toggle="yes">K</italic>-dimension score vector for GO terms Formally, the prediction score vector <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> of protein <italic toggle="yes">i</italic> is defined as:
where <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:math></inline-formula> is concatenation operator, and <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mo>σ</mml:mo></mml:math></inline-formula> is the sigmoid function, <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the size of the predictor’s hidden layer, <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> are the weight matrices of predictor’s hidden and output layers, respectively. <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> are the bias vectors of predictor’s hidden and output layers, respectively.</p>
        <disp-formula id="E7">
          <label>(7)</label>
          <mml:math id="M7" display="block" overflow="scroll">
            <mml:msup>
              <mml:mrow>
                <mml:mfenced open="[" close="]" separators="|">
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>p</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>,</mml:mo>
                    <mml:mo>…</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>p</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mi>K</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:mfenced>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>T</mml:mi>
              </mml:mrow>
            </mml:msup>
            <mml:mo>=</mml:mo>
            <mml:mo>σ</mml:mo>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi mathvariant="bold">W</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>o</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>σ</mml:mo>
                <mml:mfenced open="(" close=")" separators="|">
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">W</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>h</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mfenced open="(" close=")" separators="|">
                      <mml:mrow>
                        <mml:mfenced open="‖" close="" separators="|">
                          <mml:mrow>
                            <mml:msubsup>
                              <mml:mrow>
                                <mml:mi mathvariant="bold-italic">h</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mfenced open="(" close=")" separators="|">
                                  <mml:mrow>
                                    <mml:mi>m</mml:mi>
                                  </mml:mrow>
                                </mml:mfenced>
                              </mml:mrow>
                            </mml:msubsup>
                          </mml:mrow>
                        </mml:mfenced>
                      </mml:mrow>
                    </mml:mfenced>
                    <mml:mo>+</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">b</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>h</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:mfenced>
                <mml:mo>+</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi mathvariant="bold">b</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>o</mml:mi>
                  </mml:mrow>
                </mml:msub>
              </mml:mrow>
            </mml:mfenced>
          </mml:math>
        </disp-formula>
        <p>For GO terms, negative proteins are much more than positive proteins in training set. Therefore, we use the asymmetric loss (<xref rid="btad123-B43" ref-type="bibr">Ridnik et al. 2021</xref>) as the prediction loss:
where <inline-formula id="IE58"><mml:math id="IM58" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mn>0,1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> and <inline-formula id="IE59"><mml:math id="IM59" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>0,1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> are the true label and predicted score of protein <inline-formula id="IE60"><mml:math id="IM60" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula> in terms of GO term <inline-formula id="IE61"><mml:math id="IM61" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula>, <inline-formula id="IE62"><mml:math id="IM62" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mo>γ</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula>, and <inline-formula id="IE63"><mml:math id="IM63" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mo>γ</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> are the positive and negative focusing parameters, respectively, <inline-formula id="IE64"><mml:math id="IM64" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">train</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the number of proteins in training set, <inline-formula id="IE65"><mml:math id="IM65" display="inline" overflow="scroll"><mml:mi mathvariant="normal">Φ</mml:mi></mml:math></inline-formula> is the set of all parameters in the fine-tuning step. In this study we set <inline-formula id="IE66"><mml:math id="IM66" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mo>γ</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula> and <inline-formula id="IE67"><mml:math id="IM67" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mo>γ</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula>.</p>
        <disp-formula id="E8">
          <label>(8)</label>
          <mml:math id="M8" display="block" overflow="scroll">
            <mml:mi mathvariant="italic">ASL</mml:mi>
            <mml:mfenced open="(" close=")" separators="|">
              <mml:mrow>
                <mml:mi mathvariant="normal">Φ</mml:mi>
              </mml:mrow>
            </mml:mfenced>
            <mml:mo>=</mml:mo>
            <mml:mfrac>
              <mml:mrow>
                <mml:mn>1</mml:mn>
              </mml:mrow>
              <mml:mrow>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>N</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi mathvariant="italic">train</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mi>K</mml:mi>
              </mml:mrow>
            </mml:mfrac>
            <mml:mrow>
              <mml:munderover>
                <mml:mo stretchy="false">∑</mml:mo>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi>N</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="italic">train</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:munderover>
              <mml:mrow>
                <mml:mrow>
                  <mml:munderover>
                    <mml:mo stretchy="false">∑</mml:mo>
                    <mml:mrow>
                      <mml:mi>k</mml:mi>
                      <mml:mo>=</mml:mo>
                      <mml:mn>1</mml:mn>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>K</mml:mi>
                    </mml:mrow>
                  </mml:munderover>
                  <mml:mrow>
                    <mml:mo>-</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>y</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mi>k</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mfenced open="(" close=")" separators="|">
                          <mml:mrow>
                            <mml:mn>1</mml:mn>
                            <mml:mo>-</mml:mo>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mi>p</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>k</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mrow>
                        </mml:mfenced>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mo>γ</mml:mo>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mo>+</mml:mo>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msup>
                    <mml:mrow>
                      <mml:mrow>
                        <mml:mi mathvariant="normal">log</mml:mi>
                      </mml:mrow>
                      <mml:mo>⁡</mml:mo>
                      <mml:mrow>
                        <mml:mfenced open="(" close=")" separators="|">
                          <mml:mrow>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mi>p</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>k</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mrow>
                        </mml:mfenced>
                      </mml:mrow>
                    </mml:mrow>
                    <mml:mo>-</mml:mo>
                    <mml:mfenced open="(" close=")" separators="|">
                      <mml:mrow>
                        <mml:mn>1</mml:mn>
                        <mml:mo>-</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>y</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>i</mml:mi>
                            <mml:mi>k</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:mfenced>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mfenced open="(" close=")" separators="|">
                          <mml:mrow>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mi>p</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>k</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mrow>
                        </mml:mfenced>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mo>γ</mml:mo>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mo>-</mml:mo>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msup>
                    <mml:mrow>
                      <mml:mrow>
                        <mml:mi mathvariant="normal">log</mml:mi>
                      </mml:mrow>
                      <mml:mo>⁡</mml:mo>
                      <mml:mrow>
                        <mml:mfenced open="(" close=")" separators="|">
                          <mml:mrow>
                            <mml:mn>1</mml:mn>
                            <mml:mo>-</mml:mo>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mi>p</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>k</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mrow>
                        </mml:mfenced>
                      </mml:mrow>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
          </mml:math>
        </disp-formula>
      </sec>
    </sec>
    <sec>
      <title>2.3 Evaluation metrics</title>
      <p>In this study, we use five metrics to evaluate prediction performance, including two types of area under the precision–recall curve (AUPR), e.g. micro-averaged AUPR (m-AUPR) and Macro-averaged AUPR (M-AUPR), F1-score (F1), accuracy (ACC), and F-max score (Fmax). The first three metrics are function-centric measures that evaluate proteins annotated to each GO term, while the last two metrics are protein-centric measures that evaluate GO terms annotated to each protein.The m-AUPR, M-AUPR, F1, and ACC are widely used to evaluate protein function prediction (<xref rid="btad123-B40" ref-type="bibr">Mostafavi et al. 2008</xref>; <xref rid="btad123-B6" ref-type="bibr">Cho et al. 2016</xref>; <xref rid="btad123-B15" ref-type="bibr">Gligorijevic et al. 2018</xref>; <xref rid="btad123-B3" ref-type="bibr">Barot et al. 2021</xref>). Specifically, m-AUPR is the AUPR across the vectorized results of true label and prediction matrices, M-AUPR is the average of AUPRs of all GO terms. F1 is computed by taking the top three prediction scores for each protein, then constructing a two-by-two confusion matrix for each GO term, and calculating the harmonic mean of precision and recall on the summed-up confusion matrix of all GO terms. Accuracy is the proportion of proteins that the predicted GO terms are exactly the same as the true GO terms, using 0.5 as the predicted threshold. Fmax is used for the CAFA challenging (<xref rid="btad123-B41" ref-type="bibr">Radivojac et al. 2013</xref>; <xref rid="btad123-B21" ref-type="bibr">Jiang et al. 2016</xref>; <xref rid="btad123-B55" ref-type="bibr">Zhou et al. 2019</xref>) and many protein function prediction studies (<xref rid="btad123-B25" ref-type="bibr">Kulmanov and Hoehndorf 2020</xref>; <xref rid="btad123-B3" ref-type="bibr">Barot et al. 2021</xref>; <xref rid="btad123-B16" ref-type="bibr">Gligorijevic et al. 2021</xref>; <xref rid="btad123-B53" ref-type="bibr">You et al. 2021</xref>; <xref rid="btad123-B28" ref-type="bibr">Lai and Xu 2022</xref>), which is defined as following:
where <inline-formula id="IE68"><mml:math id="IM68" display="inline" overflow="scroll"><mml:mo>τ</mml:mo></mml:math></inline-formula> is the threshold value, <inline-formula id="IE69"><mml:math id="IM69" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mo>τ</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> and <inline-formula id="IE70"><mml:math id="IM70" display="inline" overflow="scroll"><mml:mi>r</mml:mi><mml:mi>c</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mo>τ</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> are the precision and recall in terms of <inline-formula id="IE71"><mml:math id="IM71" display="inline" overflow="scroll"><mml:mo>τ</mml:mo></mml:math></inline-formula>, respectively, which are defined as:
where <inline-formula id="IE72"><mml:math id="IM72" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">I</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mo>·</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> is the indicator function, <inline-formula id="IE73"><mml:math id="IM73" display="inline" overflow="scroll"><mml:mi>q</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mo>τ</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> is the number of proteins whose max predicted score is not less than <inline-formula id="IE74"><mml:math id="IM74" display="inline" overflow="scroll"><mml:mo>τ</mml:mo></mml:math></inline-formula>, <inline-formula id="IE75"><mml:math id="IM75" display="inline" overflow="scroll"><mml:mi>g</mml:mi></mml:math></inline-formula> is the number of target proteins.</p>
      <disp-formula id="E9">
        <label>(9)</label>
        <mml:math id="M9" display="block" overflow="scroll">
          <mml:mi mathvariant="normal">Fmax</mml:mi>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mrow>
              <mml:munder>
                <mml:mrow>
                  <mml:mi mathvariant="normal">max</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>τ</mml:mo>
                </mml:mrow>
              </mml:munder>
            </mml:mrow>
            <mml:mo>⁡</mml:mo>
            <mml:mrow>
              <mml:mfenced open="{" close="}" separators="|">
                <mml:mrow>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mn>2</mml:mn>
                      <mml:mo>×</mml:mo>
                      <mml:mi>p</mml:mi>
                      <mml:mi>r</mml:mi>
                      <mml:mfenced open="(" close=")" separators="|">
                        <mml:mrow>
                          <mml:mo>τ</mml:mo>
                        </mml:mrow>
                      </mml:mfenced>
                      <mml:mo>×</mml:mo>
                      <mml:mi>r</mml:mi>
                      <mml:mi>c</mml:mi>
                      <mml:mfenced open="(" close=")" separators="|">
                        <mml:mrow>
                          <mml:mo>τ</mml:mo>
                        </mml:mrow>
                      </mml:mfenced>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>p</mml:mi>
                      <mml:mi>r</mml:mi>
                      <mml:mfenced open="(" close=")" separators="|">
                        <mml:mrow>
                          <mml:mo>τ</mml:mo>
                        </mml:mrow>
                      </mml:mfenced>
                      <mml:mo>+</mml:mo>
                      <mml:mi>r</mml:mi>
                      <mml:mi>c</mml:mi>
                      <mml:mfenced open="(" close=")" separators="|">
                        <mml:mrow>
                          <mml:mo>τ</mml:mo>
                        </mml:mrow>
                      </mml:mfenced>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:mfenced>
            </mml:mrow>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula id="E10">
        <label>(10)</label>
        <mml:math id="M10" display="block" overflow="scroll">
          <mml:mfenced open="{" close="" separators="|">
            <mml:mrow>
              <mml:mtable>
                <mml:mtr>
                  <mml:mtd>
                    <mml:mrow>
                      <mml:maligngroup/>
                      <mml:mi>p</mml:mi>
                      <mml:mi>r</mml:mi>
                      <mml:mfenced open="(" close=")" separators="|">
                        <mml:mrow>
                          <mml:mo>τ</mml:mo>
                        </mml:mrow>
                      </mml:mfenced>
                      <mml:mo>=</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>q</mml:mi>
                          <mml:mfenced open="(" close=")" separators="|">
                            <mml:mrow>
                              <mml:mo>τ</mml:mo>
                            </mml:mrow>
                          </mml:mfenced>
                        </mml:mrow>
                      </mml:mfrac>
                      <mml:mrow>
                        <mml:munderover>
                          <mml:mo stretchy="false">∑</mml:mo>
                          <mml:mrow>
                            <mml:mi>i</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>q</mml:mi>
                            <mml:mfenced open="(" close=")" separators="|">
                              <mml:mrow>
                                <mml:mo>τ</mml:mo>
                              </mml:mrow>
                            </mml:mfenced>
                          </mml:mrow>
                        </mml:munderover>
                        <mml:mrow>
                          <mml:mfrac>
                            <mml:mrow>
                              <mml:mrow>
                                <mml:munder>
                                  <mml:mo stretchy="false">∑</mml:mo>
                                  <mml:mrow>
                                    <mml:mi>k</mml:mi>
                                  </mml:mrow>
                                </mml:munder>
                                <mml:mrow>
                                  <mml:mi mathvariant="double-struck">I</mml:mi>
                                  <mml:mfenced open="(" close=")" separators="|">
                                    <mml:mrow>
                                      <mml:msub>
                                        <mml:mrow>
                                          <mml:mi>p</mml:mi>
                                        </mml:mrow>
                                        <mml:mrow>
                                          <mml:mi>i</mml:mi>
                                          <mml:mi>k</mml:mi>
                                        </mml:mrow>
                                      </mml:msub>
                                      <mml:mo>≥</mml:mo>
                                      <mml:mo>τ</mml:mo>
                                      <mml:mo>∧</mml:mo>
                                      <mml:msub>
                                        <mml:mrow>
                                          <mml:mi>y</mml:mi>
                                        </mml:mrow>
                                        <mml:mrow>
                                          <mml:mi>i</mml:mi>
                                          <mml:mi>k</mml:mi>
                                        </mml:mrow>
                                      </mml:msub>
                                      <mml:mo>≡</mml:mo>
                                      <mml:mn>1</mml:mn>
                                    </mml:mrow>
                                  </mml:mfenced>
                                </mml:mrow>
                              </mml:mrow>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:mrow>
                                <mml:munder>
                                  <mml:mo stretchy="false">∑</mml:mo>
                                  <mml:mrow>
                                    <mml:mi>k</mml:mi>
                                  </mml:mrow>
                                </mml:munder>
                                <mml:mrow>
                                  <mml:mi mathvariant="double-struck">I</mml:mi>
                                  <mml:mfenced open="(" close=")" separators="|">
                                    <mml:mrow>
                                      <mml:msub>
                                        <mml:mrow>
                                          <mml:mi>p</mml:mi>
                                        </mml:mrow>
                                        <mml:mrow>
                                          <mml:mi>i</mml:mi>
                                          <mml:mi>k</mml:mi>
                                        </mml:mrow>
                                      </mml:msub>
                                      <mml:mo>≥</mml:mo>
                                      <mml:mo>τ</mml:mo>
                                    </mml:mrow>
                                  </mml:mfenced>
                                </mml:mrow>
                              </mml:mrow>
                            </mml:mrow>
                          </mml:mfrac>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:mrow>
                  </mml:mtd>
                </mml:mtr>
                <mml:mtr>
                  <mml:mtd>
                    <mml:mrow>
                      <mml:maligngroup/>
                      <mml:mi>r</mml:mi>
                      <mml:mi>c</mml:mi>
                      <mml:mfenced open="(" close=")" separators="|">
                        <mml:mrow>
                          <mml:mo>τ</mml:mo>
                        </mml:mrow>
                      </mml:mfenced>
                      <mml:mo>=</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>g</mml:mi>
                        </mml:mrow>
                      </mml:mfrac>
                      <mml:mrow>
                        <mml:munderover>
                          <mml:mo stretchy="false">∑</mml:mo>
                          <mml:mrow>
                            <mml:mi>i</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>g</mml:mi>
                          </mml:mrow>
                        </mml:munderover>
                        <mml:mrow>
                          <mml:mfrac>
                            <mml:mrow>
                              <mml:mrow>
                                <mml:munder>
                                  <mml:mo stretchy="false">∑</mml:mo>
                                  <mml:mrow>
                                    <mml:mi>k</mml:mi>
                                  </mml:mrow>
                                </mml:munder>
                                <mml:mrow>
                                  <mml:mi mathvariant="double-struck">I</mml:mi>
                                  <mml:mfenced open="(" close=")" separators="|">
                                    <mml:mrow>
                                      <mml:msub>
                                        <mml:mrow>
                                          <mml:mi>p</mml:mi>
                                        </mml:mrow>
                                        <mml:mrow>
                                          <mml:mi>i</mml:mi>
                                          <mml:mi>k</mml:mi>
                                        </mml:mrow>
                                      </mml:msub>
                                      <mml:mo>≥</mml:mo>
                                      <mml:mo>τ</mml:mo>
                                      <mml:mo>∧</mml:mo>
                                      <mml:msub>
                                        <mml:mrow>
                                          <mml:mi>y</mml:mi>
                                        </mml:mrow>
                                        <mml:mrow>
                                          <mml:mi>i</mml:mi>
                                          <mml:mi>k</mml:mi>
                                        </mml:mrow>
                                      </mml:msub>
                                      <mml:mo>≡</mml:mo>
                                      <mml:mn>1</mml:mn>
                                    </mml:mrow>
                                  </mml:mfenced>
                                </mml:mrow>
                              </mml:mrow>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:mrow>
                                <mml:munder>
                                  <mml:mo stretchy="false">∑</mml:mo>
                                  <mml:mrow>
                                    <mml:mi>k</mml:mi>
                                  </mml:mrow>
                                </mml:munder>
                                <mml:mrow>
                                  <mml:mi mathvariant="double-struck">I</mml:mi>
                                  <mml:mfenced open="(" close=")" separators="|">
                                    <mml:mrow>
                                      <mml:msub>
                                        <mml:mrow>
                                          <mml:mi>y</mml:mi>
                                        </mml:mrow>
                                        <mml:mrow>
                                          <mml:mi>i</mml:mi>
                                          <mml:mi>k</mml:mi>
                                        </mml:mrow>
                                      </mml:msub>
                                      <mml:mo>≡</mml:mo>
                                      <mml:mn>1</mml:mn>
                                    </mml:mrow>
                                  </mml:mfenced>
                                </mml:mrow>
                              </mml:mrow>
                            </mml:mrow>
                          </mml:mfrac>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:mrow>
                  </mml:mtd>
                </mml:mtr>
              </mml:mtable>
            </mml:mrow>
          </mml:mfenced>
        </mml:math>
      </disp-formula>
      <p>In addition, we use the Davies Bouldin Score (<xref rid="btad123-B9" ref-type="bibr">Davies and Bouldin 1979</xref>) to evaluate the goodness of feature representations. Lower Davies Bouldin Score means proteins with same functions are clustered together better.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Experiments</title>
    <sec>
      <title>3.1 Experimental setup</title>
      <p>We evaluate CFAGO on the three GO aspects: BPO, MFO, and CCO separately. We use the same empirical hyperparameter set for both species and all of the three GO aspects, and merge the validation and training sets for each aspect to train our model. Specifically, the batch size is 32 for both of pre-training and fine-tuning steps, the encoder MLP hidden dimension size <inline-formula id="IE76"><mml:math id="IM76" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1024</mml:mn></mml:math></inline-formula>, hidden embedding vector dimension size <inline-formula id="IE77"><mml:math id="IM77" display="inline" overflow="scroll"><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>512</mml:mn></mml:math></inline-formula>, the number of multi-head attention layers <inline-formula id="IE78"><mml:math id="IM78" display="inline" overflow="scroll"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:math></inline-formula>, feed-forward network hidden dimension <inline-formula id="IE79"><mml:math id="IM79" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2048</mml:mn></mml:math></inline-formula>, number of attention heads <inline-formula id="IE80"><mml:math id="IM80" display="inline" overflow="scroll"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:math></inline-formula>, predictor hidden layer dimension <inline-formula id="IE81"><mml:math id="IM81" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>256</mml:mn></mml:math></inline-formula>, normalization function is set as the layer normalization (<xref rid="btad123-B2" ref-type="bibr">Ba et al. 2016</xref>). We use the Gaussian Error Linear Unit (<xref rid="btad123-B18" ref-type="bibr">Hendrycks and Gimpel 2016</xref>) as the nonlinear activation in all hidden layers in encoder and decoder, followed by a dropout layer. In predictor, the dropout rate is set as 0.3, while in encoder and decoder, the dropout rate is set as 0.1. The pre-training step is trained with 5000 epochs, learning rate of 1e-5 for the first 2500 epochs and 1e-6 for the remaining epochs. The fine-tuning step is trained with 100 epochs. In the first 50 epochs, we freeze the pre-trained encoder, and set the learning rate of 1e-4 for predictor. In the last 50 epochs, we set the learning rate of 1e-6 for the encoder, and set the learning rate of 1e-5 for predictor. The optimizer is AdamW (<xref rid="btad123-B33" ref-type="bibr">Loshchilov and Hutter 2019</xref>).</p>
      <p>Here, we compare CFAGO with eight state-of-the-art PPI network-based methods, including two baseline methods, four network integrate methods, and two GNN-based methods. The baseline methods include the Naïve and BLAST methods of CAFA (<xref rid="btad123-B41" ref-type="bibr">Radivojac et al. 2013</xref>). The network integrate methods include deepNF (<xref rid="btad123-B15" ref-type="bibr">Gligorijevic et al. 2018</xref>), Mashup (<xref rid="btad123-B6" ref-type="bibr">Cho et al. 2016</xref>), GeneMANIA (<xref rid="btad123-B40" ref-type="bibr">Mostafavi et al. 2008</xref>), and NetQuilt (<xref rid="btad123-B3" ref-type="bibr">Barot et al. 2021</xref>). The deepNF, Mashup, and GeneMANIA integrate multiple types of single-species PPI networks into a single kernel or compact low-dimensional representations, while NetQuilt globally aligns different species’ PPI networks into a meta-network profile. The GNN-based methods include Graph2GO (<xref rid="btad123-B11" ref-type="bibr">Fan et al. 2020</xref>) and DeepGraphGO (<xref rid="btad123-B53" ref-type="bibr">You et al. 2021</xref>). Since this study focuses on the information cross-fusion from multi-sources of single species, all of the competing methods are fitted on single species datasets by hyperparameters reported on their papers. Besides, their features are generated by using their feature-generating tools or procedures. Because GeneMANIA, Mashup, deepNF, and Graph2GO did not conduct experiments on mouse, we use their reported structure and hyperparameters for human to evaluate their performance on both species. For Graph2GO, the validation and training sets of each aspect are merged to train the model. All of the results are averaged by five random repeats.</p>
    </sec>
    <sec>
      <title>3.2 CFAGO outperforms competing methods</title>
      <p><xref rid="btad123-F2" ref-type="fig">Figure 2</xref> shows the performance of different methods on testing datasets of human and mouse for the three GO aspects. It is clear that CFAGO outperforms all of the competing methods in terms of m-AUPR, M-AUPR, and Fmax measures. Specifically, in terms of m-AUPR, CFAGO achieves (7.59%, 37.58%), (78.65%, 43.69%), and (89.89%, 85.91%) higher than that of competing methods on (human, mouse) datasets for BPO, MFO, and CCO, respectively. CFAGO achieves (6.90%, 45.86%), (16.10%, 13.45%), and (38.01%, 47.65%) higher in terms of M-AUPR, and (11.68%, 31.88%), (26.47%, 22.01%), and (23.57%, 34.30%) higher in terms of Fmax than that of competing methods on (human, mouse) datasets for BPO, MFO, and CCO, respectively.</p>
      <fig position="float" id="btad123-F2">
        <label>Figure 2</label>
        <caption>
          <p>Performance comparison of CFAGO with competing methods. CFAGO achieves better or comparable performance compared to the competing methods in terms of all measurements. The blank gaps on the ACC and Fmax measurements mean the value of corresponding methods are 0. Methods labelled with an asterisk are multi-species methods but have been trained as single-species methods in the comparisons.</p>
        </caption>
        <graphic xlink:href="btad123f2" position="float"/>
      </fig>
      <p>For the F1 measurement, CFAGO also outperforms the competing methods, only except on mouse MFO where BLAST and Graph2GO achieve better performance. This is not surprising, because several studies have pointed out that MFO is highly correlated with sequence information (<xref rid="btad123-B32" ref-type="bibr">Lord et al. 2003</xref>; <xref rid="btad123-B11" ref-type="bibr">Fan et al. 2020</xref>), and Graph2GO has the additional information from protein sequence similarity networks, in addition to PPI networks. For the ACC measurement, CFAGO outperforms competing methods on half of tasks. For the worst case of CFAGO, it has comparable performance with Graph2GO on human MFO, mouse BPO, and MFO, while outperforming other seven competing methods. We also noticed that the frequencies of individual labels on all datasets except on mouse BPO are much lower than 0.5 in the training dataset. Since Naïve uses the frequency of each label on the training dataset as the prediction score for every test protein, it achieves a value of 0 in terms of the ACC measurement on the corresponding datasets. Besides, as training proteins cover less than 30% of total proteins in the PPI network, GeneMANIA cannot effectively propagate labels from training proteins to test proteins, and Mashup is unable to learn protein compact low-dimensional via matrix factorization, leading them achieve a value of 0 in terms of ACC and Fmax on several tasks.</p>
      <p>We further investigate the AUPR performance of CFAGO in individual GO terms. The results in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S1–S6</xref> show that the performance of linked GO terms is not correlated. These results are expected. The first reason is that proteins are annotated to the most granular term (<xref rid="btad123-B1" ref-type="bibr">Ashburner et al. 2000</xref>), the second reason is that we remove those annotating more than 5% of proteins in the PPI network to reduce the effect of the dependence relationship between GO terms.</p>
      <p>Such outstanding results of CFAGO demonstrate the feature cross-fusion via multi-head attention mechanism has obvious advantages compared with pure PPI network-based methods and the multi-source combining method based on GNN.</p>
    </sec>
    <sec>
      <title>3.3 Attention mechanism learns more distinguishing representation via cross-fusing information from multiple sources</title>
      <p>To quantitatively evaluate the effectiveness of cross-fusion by attention mechanism and pre-training, we compare the distinguishing power of protein representations by Davies Bouldin Score (<xref rid="btad123-B9" ref-type="bibr">Davies and Bouldin 1979</xref>).</p>
      <p>We compare four types of protein representations, including the original PPI network representation, original attribute representation, and hidden embedding representations learned by CFAGO with and without attention mechanism. The structure of CFAGO without multi-head attention mechanism is shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S7</xref>. The GO term sets are used as the protein cluster labels, that is, two proteins with exactly the same GO term set are considered to be in the same cluster. The results on the union of training and validation set are listed in <xref rid="btad123-T2" ref-type="table">Table 2</xref>, which shows that the hidden embedding representations learned by full CFAGO model achieve the best performance. Specifically, its Davies Bouldin Score is (6.15%, 8.39%), (8.02%, 5.51%), and (6.30%, 7.63%) lower than that of comparison representations on (human, mouse) datasets for BPO, MFO, and CCO, respectively. These results indicate that cross-fusion of CFAGO can effectively fuse protein features from multiple sources to generate better protein representation for function prediction.</p>
      <table-wrap position="float" id="btad123-T2">
        <label>Table 2</label>
        <caption>
          <p>Davies Bouldin Score comparison of different protein feature represents</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1">Representation</th>
              <th colspan="3" align="center" rowspan="1">Human<hr/></th>
              <th colspan="3" align="center" rowspan="1">Mouse<hr/></th>
            </tr>
            <tr>
              <th align="center" rowspan="1" colspan="1">BPO</th>
              <th align="center" rowspan="1" colspan="1">MFO</th>
              <th align="center" rowspan="1" colspan="1">CCO</th>
              <th align="center" rowspan="1" colspan="1">BPO</th>
              <th align="center" rowspan="1" colspan="1">MFO</th>
              <th align="center" rowspan="1" colspan="1">CCO</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">o_PPI<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">1.855</td>
              <td rowspan="1" colspan="1">2.250</td>
              <td rowspan="1" colspan="1">2.243</td>
              <td rowspan="1" colspan="1">1.991</td>
              <td rowspan="1" colspan="1">3.133</td>
              <td rowspan="1" colspan="1">2.204</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">o_attribute<xref rid="tblfn3" ref-type="table-fn"><sup>b</sup></xref></td>
              <td rowspan="1" colspan="1">2.128</td>
              <td rowspan="1" colspan="1">2.387</td>
              <td rowspan="1" colspan="1">2.128</td>
              <td rowspan="1" colspan="1">2.209</td>
              <td rowspan="1" colspan="1">3.349</td>
              <td rowspan="1" colspan="1">2.122</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">c_embedding<xref rid="tblfn4" ref-type="table-fn"><sup>c</sup></xref></td>
              <td rowspan="1" colspan="1">1.884</td>
              <td rowspan="1" colspan="1">2.183</td>
              <td rowspan="1" colspan="1">2.201</td>
              <td rowspan="1" colspan="1">1.943</td>
              <td rowspan="1" colspan="1">2.924</td>
              <td rowspan="1" colspan="1">2.179</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">cf_embedding<xref rid="tblfn5" ref-type="table-fn"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">
                <bold>1.741</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>2.008</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>1.994</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>1.780</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>2.763</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>1.960</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic toggle="yes">Note:</italic> Smaller Davies Bouldin Score value means the cluster of protein representations are more clearly separated.</p>
          </fn>
          <fn id="tblfn2">
            <label>a</label>
            <p>The original PPI network structure feature.</p>
          </fn>
          <fn id="tblfn3">
            <label>b</label>
            <p>The original attribute feature.</p>
          </fn>
          <fn id="tblfn4">
            <label>c</label>
            <p>The concatenation of hidden embedding vectors output by CFAGO without attention mechanism.</p>
          </fn>
          <fn id="tblfn5">
            <label>d</label>
            <p>The concatenation of hidden embedding vectors output by CFAGO.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>In addition, we visualize the distribution of above protein representations on human and mouse datasets for the three aspects of GO via t-Distributed Stochastic Neighbor Embedding (<xref rid="btad123-B48" ref-type="bibr">van der Maaten and Hinton 2008</xref>) by assigning a unique color for each cluster label (GO term set), as shown in <xref rid="btad123-F3" ref-type="fig">Fig. 3</xref>. It is clear that the distribution of original PPI network structure and attribute features are different, indicating they are complementary for annotating protein function. The original PPI network structure feature shows a relatively clear distribution, while the original attribute feature isolates proteins into a ring part and a nucleus part that each of which shows more vague cluster segmentation.</p>
      <fig position="float" id="btad123-F3">
        <label>Figure 3</label>
        <caption>
          <p>Visualization of different feature representations on human and mouse dataset in terms of the BPO, MFO, and CCO, respectively. o_PPI is the original PPI network structure feature, o_attribute is the original biological attribute feature, cf_embedding and c_embedding is the concatenation of hidden embedding vectors output by CFAGO, with and without attention mechanism, respectively.</p>
        </caption>
        <graphic xlink:href="btad123f3" position="float"/>
      </fig>
      <p>The representation learned by CFAGO without cross-fusion mixes up the shape of distribution of original PPI network structure and original attribute, showing an edge that is similar to the ring part in the distribution of original attribute. The hidden embedding representation learned by full CFAGO model shows a much better cluster segmentation than compared representations. These results show that the features from two sources are indeed cross-fused by multi-head attention mechanism.</p>
    </sec>
    <sec>
      <title>3.4 The contribution of self-supervised pre-training and multi-head attention mechanism</title>
      <p>Here we conduct ablation experiments to study the contribution of self-supervised pre-training and attention mechanism to performance improvement (<xref rid="btad123-F4" ref-type="fig">Fig. 4</xref>). <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S7</xref> shows the CFAGO model that removed multi-head attention mechanism. We only use the m-AUPR, M-AUPR, and Fmax measures, as F1 and ACC measures depend on special thresholds.</p>
      <fig position="float" id="btad123-F4">
        <label>Figure 4</label>
        <caption>
          <p>Ablation studies of self-supervised pre-training and multi-head attention mechanism, the meaning of different colors is shown on top of the graph. m-AUPR, M-AUPR, and Fmax are performance measurements.</p>
        </caption>
        <graphic xlink:href="btad123f4" position="float"/>
      </fig>
      <p>We observe that the performance drops significantly if not applying self-supervised pre-training. The reason is that the CFAGO model contains a huge amount of parameters. As there are only several thousands of training proteins, the CFAGO model is over-fitted without applying pre-training. For the multi-head attention mechanism, the performance of CFAGO drops clearly without it, except on Fmax measure of mouse MFO. The reason is that there are only 1185 mouse MFO training proteins, therefore adding the attention mechanism makes the CFAGO model overfitted, leading the performance drops down. Overall, these results also demonstrate the feature cross-fusion via multi-head attention mechanism has obvious advantages compared with concatenation of features.</p>
    </sec>
    <sec>
      <title>3.5 Contribution of different features</title>
      <p>Here, we analyze the contribution of different features for the three GO aspects. We test five feature conditions: protein domain feature only, protein subcellular location feature only, concatenation of protein domain and subcellular location features, PPI network structure feature only, and combination of all features. <xref rid="btad123-F5" ref-type="fig">Figure 5</xref> shows the results. For BPO task, combining all of the features shows the best performance, and the PPI network structure feature contributes the most for improving prediction performance. For MFO task, combining all of the features shows the best performance, except on Fmax measure of mouse MFO. The PPI network structure feature contributes the most on human, while the combination of protein domain and subcellular location feature contributes the most on mouse. For CCO task, using the protein subcellular location feature only shows the best performance. By combining protein domain feature, the performance drops a bit, by combining PPI network structure feature, the performance drops significantly.</p>
      <fig position="float" id="btad123-F5">
        <label>Figure 5</label>
        <caption>
          <p>Performance comparison of different feature combinations. The meaning of different color is shown on top of the graph. m-AUPR, M-AUPR, and Fmax are performance measurements.</p>
        </caption>
        <graphic xlink:href="btad123f5" position="float"/>
      </fig>
      <p>The reduced performance in terms of Fmax on mouse MFO is caused by the noise in protein attribute data, and insufficient number of training proteins. Protein domains came from the pfam (<xref rid="btad123-B38" ref-type="bibr">Mistry et al. 2021</xref>) database that contains unverified domains (<xref rid="btad123-B38" ref-type="bibr">Mistry et al. 2021</xref>), and the subcellular location data came from the UniProt database (<xref rid="btad123-B47" ref-type="bibr">UniProt 2021</xref>) that contains unreviewed records (<xref rid="btad123-B35" ref-type="bibr">MacDougall et al. 2020</xref>). Therefore the protein domain and subcellular location features contain noise. The reduced performance on CCO is caused by the noise in both protein attribute data and PPI data. The PPI data are produced by high-throughput techniques which contain inherent bias noise or predicted computationally (<xref rid="btad123-B46" ref-type="bibr">Szklarczyk et al. 2021</xref>). Besides, in the STRING database, the ratio of PPIs derived from ‘textmining’ in human dataset is 27.75%, and the ratio in mouse dataset is 19.28%. Since this kind of PPIs is predicted from scientific literature, they likely connect proteins from different subcellular locations (<xref rid="btad123-B46" ref-type="bibr">Szklarczyk et al. 2021</xref>). Therefore, the PPIs derived from ‘textmining’ became noise for CCO prediction.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>In this study, we propose CFAGO, an attention mechanism-based neural network model, for protein function prediction. It cross-fuses the information from multiple sources of single species using an attention mechanism to learn more effective protein representations. Specifically, CFAGO is the first pre-trained via an encoder–decoder architecture to learn the universal protein representations and then fine-tuned to further improve protein function prediction. We show that CFAGO outperforms state-of-the-art single-species network-based protein function prediction methods in both human and mouse organisms. CFAGO would be an effective tool for understanding disease mechanisms or finding drug targets.</p>
    <p>Several studies (<xref rid="btad123-B3" ref-type="bibr">Barot et al. 2021</xref>; <xref rid="btad123-B53" ref-type="bibr">You et al. 2021</xref>) have shown that integrating PPI networks of multiple species can further improve the accuracy of protein function prediction. In future work, we will try more types of protein attributes such as sequence features, and explore effective ways that can use full homology information to integrate PPI networks of multi-species for protein function prediction.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btad123_Supplementary_Data</label>
      <media xlink:href="btad123_supplementary_data.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors are very much indebted to the anonymous reviewers, whose constructive comments are very helpful for strengthening the presentation of this article.</p>
    <sec>
      <title>Supplementary data</title>
      <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
    </sec>
  </ack>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the National Natural Science Foundation of China (Grant No. 62102118, 62271049, and U22A2039), Project of Educational Commission of Guangdong Province of China (Grant No. 2021KQNCX274), the Shenzhen Colleges and Universities Stable Support Program (Grant No. GXWD20220811170504001 and 20220715183602001).</p>
    <p>Conflict of interest: None declared.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btad123-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ashburner</surname><given-names>M</given-names></string-name>, <string-name><surname>Ball</surname><given-names>CA</given-names></string-name>, <string-name><surname>Blake</surname><given-names>JA</given-names></string-name></person-group><etal>et al</etal><article-title>Gene ontology: tool for the unification of biology. The gene ontology consortium</article-title>. <source>Nat Genet</source><year>2000</year>;<volume>25</volume>:<fpage>25</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">10802651</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ba</surname><given-names>JL</given-names></string-name>, <string-name><surname>Kiros</surname><given-names>JR</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>GE.</given-names></string-name></person-group> Layer Normalization. <year>2016</year>. <pub-id pub-id-type="doi">10.48550/ARXIV.1607.06450</pub-id>.</mixed-citation>
    </ref>
    <ref id="btad123-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barot</surname><given-names>M, Gligorijević V, Cho K</given-names></string-name></person-group><etal>et al</etal><article-title>NetQuilt: deep multispecies network-based protein function prediction using homology-informed network similarity</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>2414</fpage>–<lpage>2422</lpage>.<pub-id pub-id-type="pmid">33576802</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brenner</surname><given-names>SE</given-names></string-name>, <string-name><surname>Chothia</surname><given-names>C</given-names></string-name>, <string-name><surname>Hubbard</surname><given-names>TJ</given-names></string-name></person-group><etal>et al</etal><article-title>Understanding protein structure: using scop for fold interpretation</article-title>. <source>Methods Enzymol</source><year>1996</year>;<volume>266</volume>:<fpage>635</fpage>–<lpage>43</lpage>.<pub-id pub-id-type="pmid">8743710</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cai</surname><given-names>C</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y.</given-names></string-name></person-group><article-title>A note on over-smoothing for graph neural networks</article-title>. <source>CoRR</source><year>2020</year>;abs/2006.13318</mixed-citation>
    </ref>
    <ref id="btad123-B750">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carbon</surname><given-names>S</given-names></string-name>, <string-name><surname>Douglass</surname><given-names>E</given-names></string-name>, <string-name><surname>Good</surname><given-names>BM</given-names></string-name></person-group><etal>et al</etal><article-title>The Gene Ontology Consortium et al. The gene ontology resource: enriching a GOld mine</article-title>. <source>Nucleic Acids Res</source><year>2021</year>;<volume>49</volume>:<fpage>D325</fpage>–<lpage>D334</lpage>.<pub-id pub-id-type="pmid">33290552</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cho</surname><given-names>H</given-names></string-name>, <string-name><surname>Berger</surname><given-names>B</given-names></string-name>, <string-name><surname>Peng</surname><given-names>J.</given-names></string-name></person-group><article-title>Compact integration of multi-network topology for functional analysis of genes</article-title>. <source>Cell Syst</source><year>2016</year>;<volume>3</volume>:<fpage>540</fpage>–<lpage>8</lpage>. e545.<pub-id pub-id-type="pmid">27889536</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cozzetto</surname><given-names>D</given-names></string-name>, <string-name><surname>Buchan</surname><given-names>DWA</given-names></string-name>, <string-name><surname>Bryson</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal><article-title>Protein function prediction by massive integration of evolutionary analyses and multiple data sources</article-title>. <source>BMC Bioinform</source><year>2013</year>;<volume>14 Suppl 3</volume>:<fpage>S1</fpage>.</mixed-citation>
    </ref>
    <ref id="btad123-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Dai</surname><given-names>E</given-names></string-name>, <string-name><surname>Wang</surname><given-names>S.</given-names></string-name></person-group> Say no to the discrimination: learning fair graph neural networks with limited sensitive attribute information. In: <italic toggle="yes">Proceedings of the 14th ACM International Conference on Web Search and Data Mining</italic>, <year>2021</year>. pp. <fpage>680</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="btad123-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Davies</surname><given-names>DL</given-names></string-name>, <string-name><surname>Bouldin</surname><given-names>DW.</given-names></string-name></person-group><article-title>A cluster separation measure</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source><year>1979</year>;<volume>1</volume>:<fpage>224</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">21868852</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>De Las Rivas</surname><given-names>J</given-names></string-name>, <string-name><surname>Fontanillo</surname><given-names>C.</given-names></string-name></person-group><article-title>Protein-protein interactions essentials: key concepts to building and analyzing interactome networks</article-title>. <source>PLoS Comput Biol</source><year>2010</year>;<volume>6</volume>:<fpage>e1000807</fpage>.<pub-id pub-id-type="pmid">20589078</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fan</surname><given-names>K</given-names></string-name>, <string-name><surname>Guan</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y.</given-names></string-name></person-group><article-title>Graph2GO: a multi-modal attributed network embedding method for inferring protein functions</article-title>. <source>Gigascience</source><year>2020</year>;<volume>9</volume>:giaa081.</mixed-citation>
    </ref>
    <ref id="btad123-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friedberg</surname><given-names>I.</given-names></string-name></person-group><article-title>Automated protein function prediction–the genomic challenge</article-title>. <source>Brief Bioinform</source><year>2006</year>;<volume>7</volume>:<fpage>225</fpage>–<lpage>42</lpage>.<pub-id pub-id-type="pmid">16772267</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carbon</surname><given-names>S</given-names></string-name>, <string-name><surname>Douglass</surname><given-names>E</given-names></string-name>, <string-name><surname>Good</surname><given-names>BM</given-names></string-name></person-group>, <collab>The Gene Ontology Consortium</collab><etal>et al</etal><article-title>The gene ontology resource: enriching a GOld mine</article-title>. <source>Nucleic Acids Res</source><year>2021</year>;<volume>49</volume>:<fpage>D325</fpage>–<lpage>D334</lpage>.<pub-id pub-id-type="pmid">33290552</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gibrat</surname><given-names>JF</given-names></string-name>, <string-name><surname>Madej</surname><given-names>T</given-names></string-name>, <string-name><surname>Bryant</surname><given-names>SH.</given-names></string-name></person-group><article-title>Surprising similarities in structure comparison</article-title>. <source>Curr Opin Struct Biol</source><year>1996</year>;<volume>6</volume>:<fpage>377</fpage>–<lpage>85</lpage>.<pub-id pub-id-type="pmid">8804824</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gligorijevic</surname><given-names>V</given-names></string-name>, <string-name><surname>Barot</surname><given-names>M</given-names></string-name>, <string-name><surname>Bonneau</surname><given-names>R.</given-names></string-name></person-group><article-title>deepNF: deep network fusion for protein function prediction</article-title>. <source>Bioinformatics</source><year>2018</year>;<volume>34</volume>:<fpage>3873</fpage>–<lpage>81</lpage>.<pub-id pub-id-type="pmid">29868758</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gligorijevic</surname><given-names>V</given-names></string-name></person-group><etal>et al</etal><article-title>Structure-based protein function prediction using graph convolutional networks</article-title>. <source>Nat Commun</source><year>2021</year>;<volume>12</volume>:<fpage>3168</fpage>.<pub-id pub-id-type="pmid">34039967</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gong</surname><given-names>Q</given-names></string-name>, <string-name><surname>Ning</surname><given-names>W</given-names></string-name>, <string-name><surname>Tian</surname><given-names>W.</given-names></string-name></person-group><article-title>GoFDR: a sequence alignment based method for predicting protein functions</article-title>. <source>Methods</source><year>2016</year>;<volume>93</volume>:<fpage>3</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">26277418</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B18">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Hendrycks</surname><given-names>D</given-names></string-name>, <string-name><surname>Gimpel</surname><given-names>K.</given-names></string-name></person-group> Gaussian error linear units (gelus). <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="btad123-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holm</surname><given-names>L</given-names></string-name>, <string-name><surname>Sander</surname><given-names>C.</given-names></string-name></person-group><article-title>Dali: a network tool for protein structure comparison</article-title>. <source>Trends Biochem Sci</source><year>1995</year>;<volume>20</volume>:<fpage>478</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">8578593</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holm</surname><given-names>L</given-names></string-name>, <string-name><surname>Sander</surname><given-names>C.</given-names></string-name></person-group><article-title>Mapping the protein universe</article-title>. <source>Science</source><year>1996</year>;<volume>273</volume>:<fpage>595</fpage>–<lpage>603</lpage>.<pub-id pub-id-type="pmid">8662544</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Oron</surname><given-names>TR</given-names></string-name>, <string-name><surname>Clark</surname><given-names>WT</given-names></string-name></person-group><etal>et al</etal><article-title>An expanded evaluation of protein function prediction methods shows an improvement in accuracy</article-title>. <source>Genome Biol</source><year>2016</year>;<volume>17</volume>:<fpage>1</fpage>–<lpage>19</lpage>.<pub-id pub-id-type="pmid">26753840</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jumper</surname><given-names>J</given-names></string-name>, <string-name><surname>Evans</surname><given-names>R</given-names></string-name>, <string-name><surname>Pritzel</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source>Nature</source><year>2021</year>;<volume>596</volume>:<fpage>583</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kihara</surname><given-names>D.</given-names></string-name></person-group><article-title>Computational protein function predictions</article-title>. <source>Methods</source><year>2016</year>;<volume>93</volume>:<fpage>1</fpage>–<lpage>2</lpage>.<pub-id pub-id-type="pmid">26778120</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kimura</surname><given-names>M</given-names></string-name>, <string-name><surname>Ohta</surname><given-names>T.</given-names></string-name></person-group><article-title>On some principles governing molecular evolution</article-title>. <source>Proc Natl Acad Sci USA</source><year>1974</year>;<volume>71</volume>:<fpage>2848</fpage>–<lpage>52</lpage>.<pub-id pub-id-type="pmid">4527913</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kulmanov</surname><given-names>M</given-names></string-name>, <string-name><surname>Hoehndorf</surname><given-names>R.</given-names></string-name></person-group><article-title>DeepGOPlus: improved protein function prediction from sequence</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>422</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">31350877</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kulmanov</surname><given-names>M</given-names></string-name>, <string-name><surname>Hoehndorf</surname><given-names>R.</given-names></string-name></person-group><article-title>DeepGOZero: improving protein function prediction from sequence and zero-shot learning based on ontology axioms</article-title>. <source>Bioinformatics</source><year>2022</year>;<volume>38</volume>:<fpage>i238</fpage>–<lpage>i245</lpage>.<pub-id pub-id-type="pmid">35758802</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kulmanov</surname><given-names>M</given-names></string-name>, <string-name><surname>Khan</surname><given-names>MA</given-names></string-name>, <string-name><surname>Hoehndorf</surname><given-names>R</given-names></string-name></person-group><etal>et al</etal><article-title>DeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier</article-title>. <source>Bioinformatics</source><year>2018</year>;<volume>34</volume>:<fpage>660</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">29028931</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lai</surname><given-names>B</given-names></string-name>, <string-name><surname>Xu</surname><given-names>J.</given-names></string-name></person-group><article-title>Accurate protein function prediction via graph attention networks with predicted structure information</article-title>. Brief Bioinform 2022;23:bbab502.</mixed-citation>
    </ref>
    <ref id="btad123-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Laskowski</surname><given-names>RA</given-names></string-name>, <string-name><surname>Watson</surname><given-names>JD</given-names></string-name>, <string-name><surname>Thornton</surname><given-names>JM.</given-names></string-name></person-group><article-title>Protein function prediction using local 3D templates</article-title>. <source>J Mol Biol</source><year>2005</year>;<volume>351</volume>:<fpage>614</fpage>–<lpage>26</lpage>.<pub-id pub-id-type="pmid">16019027</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>D</given-names></string-name>, <string-name><surname>Redfern</surname><given-names>O</given-names></string-name>, <string-name><surname>Orengo</surname><given-names>C.</given-names></string-name></person-group><article-title>Predicting protein function from sequence and structure</article-title>. <source>Nat Rev Mol Cell Biol</source><year>2007</year>;<volume>8</volume>:<fpage>995</fpage>–<lpage>1005</lpage>.<pub-id pub-id-type="pmid">18037900</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B31">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Q</given-names></string-name>, <string-name><surname>Han</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wu</surname><given-names>X-M.</given-names></string-name></person-group> Deeper insights into graph convolutional networks for semi-supervised learning. <italic toggle="yes">CoRR</italic><year>2018</year>;abs/1801.07606.</mixed-citation>
    </ref>
    <ref id="btad123-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lord</surname><given-names>PW</given-names></string-name>, <string-name><surname>Stevens</surname><given-names>RD</given-names></string-name>, <string-name><surname>Brass</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Investigating semantic similarity measures across the gene ontology: the relationship between sequence and annotation</article-title>. <source>Bioinformatics</source><year>2003</year>;<volume>19</volume>:<fpage>1275</fpage>–<lpage>83</lpage>.<pub-id pub-id-type="pmid">12835272</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B33">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Loshchilov</surname><given-names>I</given-names></string-name>, <string-name><surname>Hutter</surname><given-names>F.</given-names></string-name></person-group> Decoupled weight decay regularization. In: <italic toggle="yes">7th International Conference on Learning Representations</italic>. New Orleans, LA, USA: OpenReview.net, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="btad123-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luck</surname><given-names>K</given-names></string-name>, <string-name><surname>Kim</surname><given-names>D-K</given-names></string-name>, <string-name><surname>Lambourne</surname><given-names>L</given-names></string-name></person-group><etal>et al</etal><article-title>A reference map of the human binary protein interactome</article-title>. <source>Nature</source><year>2020</year>;<volume>580</volume>:<fpage>402</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">32296183</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>MacDougall</surname><given-names>A</given-names></string-name>, <string-name><surname>Volynkin</surname><given-names>V</given-names></string-name>, <string-name><surname>Saidi</surname><given-names>R</given-names></string-name></person-group>, <collab>UniProt Consortium</collab><etal>et al</etal><article-title>UniRule: a unified rule resource for automatic annotation in the UniProt Knowledgebase</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>4643</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">32399560</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Makrodimitris</surname><given-names>S</given-names></string-name>, <string-name><surname>van Ham</surname><given-names>R</given-names></string-name>, <string-name><surname>Reinders</surname><given-names>MJT.</given-names></string-name></person-group><article-title>Improving protein function prediction using protein sequence and GO-term similarities</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>1116</fpage>–<lpage>24</lpage>.<pub-id pub-id-type="pmid">30169569</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Milenkovic</surname><given-names>T</given-names></string-name>, <string-name><surname>Przulj</surname><given-names>N.</given-names></string-name></person-group><article-title>Uncovering biological network function via graphlet degree signatures</article-title>. <source>Cancer Inform</source><year>2008</year>;<volume>6</volume>:<fpage>CIN.S680</fpage>–<lpage>273</lpage>.</mixed-citation>
    </ref>
    <ref id="btad123-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mistry</surname><given-names>J</given-names></string-name>, <string-name><surname>Chuguransky</surname><given-names>S</given-names></string-name>, <string-name><surname>Williams</surname><given-names>L</given-names></string-name></person-group><etal>et al</etal><article-title>Pfam: the protein families database in 2021</article-title>. <source>Nucleic Acids Res</source><year>2021</year>;<volume>49</volume>:<fpage>D412</fpage>–<lpage>19</lpage>.<pub-id pub-id-type="pmid">33125078</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mostafavi</surname><given-names>S</given-names></string-name>, <string-name><surname>Morris</surname><given-names>Q.</given-names></string-name></person-group><article-title>Fast integration of heterogeneous data sources for predicting gene function with limited annotation</article-title>. <source>Bioinformatics</source><year>2010</year>;<volume>26</volume>:<fpage>1759</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">20507895</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mostafavi</surname><given-names>S</given-names></string-name>, <string-name><surname>Ray</surname><given-names>D</given-names></string-name>, <string-name><surname>Warde-Farley</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>GeneMANIA: a real-time multiple association network integration algorithm for predicting gene function</article-title>. <source>Genome Biol</source><year>2008</year>;<volume>9 Suppl 1</volume>:<fpage>S4</fpage>.</mixed-citation>
    </ref>
    <ref id="btad123-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Radivojac</surname><given-names>P</given-names></string-name>, <string-name><surname>Clark</surname><given-names>WT</given-names></string-name>, <string-name><surname>Oron</surname><given-names>TR</given-names></string-name></person-group><etal>et al</etal><article-title>A large-scale evaluation of computational protein function prediction</article-title>. <source>Nat Methods</source><year>2013</year>;<volume>10</volume>:<fpage>221</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">23353650</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rentzsch</surname><given-names>R</given-names></string-name>, <string-name><surname>Orengo</surname><given-names>CA.</given-names></string-name></person-group><article-title>Protein function prediction–the power of multiplicity</article-title>. <source>Trends Biotechnol</source><year>2009</year>;<volume>27</volume>:<fpage>210</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">19251332</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B43">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ridnik</surname><given-names>T</given-names></string-name></person-group><etal>et al</etal> Asymmetric loss for multi-label classification. In: <italic toggle="yes">2021 IEEE/CVF International Conference on Computer Vision (ICCV</italic>), <year>2021</year>, pp. <fpage>82</fpage>–<lpage>91</lpage>.</mixed-citation>
    </ref>
    <ref id="btad123-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rost</surname><given-names>B.</given-names></string-name></person-group><article-title>Twilight zone of protein sequence alignments</article-title>. <source>Protein Eng</source><year>1999</year>;<volume>12</volume>:<fpage>85</fpage>–<lpage>94</lpage>.<pub-id pub-id-type="pmid">10195279</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sharan</surname><given-names>R</given-names></string-name>, <string-name><surname>Ulitsky</surname><given-names>I</given-names></string-name>, <string-name><surname>Shamir</surname><given-names>R.</given-names></string-name></person-group><article-title>Network-based prediction of protein function</article-title>. <source>Mol Syst Biol</source><year>2007</year>;<volume>3</volume>:<fpage>88</fpage>.<pub-id pub-id-type="pmid">17353930</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Szklarczyk</surname><given-names>D</given-names></string-name>, <string-name><surname>Gable</surname><given-names>AL</given-names></string-name>, <string-name><surname>Nastou</surname><given-names>KC</given-names></string-name></person-group><etal>et al</etal><article-title>The STRING database in 2021: customizable protein-protein networks, and functional characterization of user-uploaded gene/measurement sets</article-title>. <source>Nucleic Acids Res</source><year>2021</year>;<volume>49</volume>:<fpage>D605</fpage>–<lpage>12</lpage>.<pub-id pub-id-type="pmid">33237311</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>UniProt</surname><given-names>C.</given-names></string-name></person-group><article-title>UniProt: the universal protein knowledgebase in 2021</article-title>. <source>Nucleic Acids Res</source><year>2021</year>;<volume>49</volume>:<fpage>D480</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">33237286</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van der Maaten</surname><given-names>L</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>G.</given-names></string-name></person-group><article-title>Visualizing data using t-SNE</article-title>. <source>J Mach Learn Res</source><year>2008</year>;<volume>9</volume>:<fpage>2579</fpage>–<lpage>605</lpage>.</mixed-citation>
    </ref>
    <ref id="btad123-B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Varadi</surname><given-names>M</given-names></string-name>, <string-name><surname>Anyango</surname><given-names>S</given-names></string-name>, <string-name><surname>Deshpande</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>AlphaFold Protein Structure Database: massively expanding the structural coverage of protein-sequence space with high-accuracy models</article-title>. <source>Nucleic Acids Res</source><year>2022</year>;<volume>50</volume>:<fpage>D439</fpage>–<lpage>44</lpage>.<pub-id pub-id-type="pmid">34791371</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vaswani</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Attention is all you need</article-title>. <source>Adv Neur In</source><year>2017</year>;<volume>30</volume>:<fpage>6000</fpage>–<lpage>6010</lpage>.</mixed-citation>
    </ref>
    <ref id="btad123-B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Villegas-Morcillo</surname><given-names>A</given-names></string-name>, <string-name><surname>Makrodimitris</surname><given-names>S</given-names></string-name>, <string-name><surname>van Ham</surname><given-names>RCHJ</given-names></string-name></person-group><etal>et al</etal><article-title>Unsupervised protein embeddings outperform hand-crafted sequence and structure features at predicting molecular function</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>162</fpage>–<lpage>70</lpage>.<pub-id pub-id-type="pmid">32797179</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>You</surname><given-names>R</given-names></string-name>, <string-name><surname>Huang</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>S.</given-names></string-name></person-group><article-title>DeepText2GO: improving large-scale protein function prediction with deep semantic text representation</article-title>. <source>Methods</source><year>2018</year>;<volume>145</volume>:<fpage>82</fpage>–<lpage>90</lpage>.<pub-id pub-id-type="pmid">29883746</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>You</surname><given-names>R</given-names></string-name>, <string-name><surname>Yao</surname><given-names>S</given-names></string-name>, <string-name><surname>Mamitsuka</surname><given-names>H</given-names></string-name></person-group><etal>et al</etal><article-title>DeepGraphGO: graph neural network for large-scale, multispecies protein function prediction</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>i262</fpage>–<lpage>71</lpage>.<pub-id pub-id-type="pmid">34252926</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>You</surname><given-names>R</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Xiong</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>GOLabeler: improving sequence-based large-scale protein function prediction by learning to rank</article-title>. <source>Bioinformatics</source><year>2018</year>;<volume>34</volume>:<fpage>2465</fpage>–<lpage>73</lpage>.<pub-id pub-id-type="pmid">29522145</pub-id></mixed-citation>
    </ref>
    <ref id="btad123-B55">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>N</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Bergquist</surname><given-names>TR</given-names></string-name></person-group><etal>et al</etal><article-title>The CAFA challenge reports improved protein function prediction and new functional annotations for hundreds of genes through experimental screens</article-title>. <source>Genome Biol</source><year>2019</year>;<volume>20</volume>:<fpage>1</fpage>–<lpage>23</lpage>.<pub-id pub-id-type="pmid">30606230</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
