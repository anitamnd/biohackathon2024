<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9947927</article-id>
    <article-id pub-id-type="pmid">36413068</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac727</article-id>
    <article-id pub-id-type="publisher-id">btac727</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Bioimage Informatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>PScL-2LSAESM: bioimage-based prediction of protein subcellular localization by integrating heterogeneous features with the two-level SAE-SM and mean ensemble method</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Ullah</surname>
          <given-names>Matee</given-names>
        </name>
        <aff><institution>School of Computer Science and Engineering, Nanjing University of Science and Technology</institution>, Nanjing 210094, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hadi</surname>
          <given-names>Fazal</given-names>
        </name>
        <aff><institution>School of Computer Science and Engineering, Nanjing University of Science and Technology</institution>, Nanjing 210094, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-8031-9086</contrib-id>
        <name>
          <surname>Song</surname>
          <given-names>Jiangning</given-names>
        </name>
        <aff><institution>Department of Biochemistry and Molecular Biology, Monash Biomedicine Discovery Institute, Monash University</institution>, Melbourne, VIC 3800, <country country="AU">Australia</country></aff>
        <aff><institution>Monash Data Futures Institute, Monash University</institution>, Melbourne, VIC 3800, <country country="AU">Australia</country></aff>
        <xref rid="btac727-cor1" ref-type="corresp"/>
        <!--jiangning.song@monash.edu-->
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-6786-8053</contrib-id>
        <name>
          <surname>Yu</surname>
          <given-names>Dong-Jun</given-names>
        </name>
        <aff><institution>School of Computer Science and Engineering, Nanjing University of Science and Technology</institution>, Nanjing 210094, <country country="CN">China</country></aff>
        <xref rid="btac727-cor1" ref-type="corresp"/>
        <!--njyudj@njust.edu.cn-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Peng</surname>
          <given-names>Hanchuan</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btac727-cor1">To whom correspondence should be addressed. Email: <email>jiangning.song@monash.edu</email> or <email>njyudj@njust.edu.cn</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-11-22">
      <day>22</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>22</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <volume>39</volume>
    <issue>1</issue>
    <elocation-id>btac727</elocation-id>
    <history>
      <date date-type="received">
        <day>13</day>
        <month>9</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>02</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>07</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>02</day>
        <month>12</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac727.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Over the past decades, a variety of <italic toggle="yes">in silico</italic> methods have been developed to predict protein subcellular localization within cells. However, a common and major challenge in the design and development of such methods is how to effectively utilize the heterogeneous feature sets extracted from bioimages. In this regards, limited efforts have been undertaken.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We propose a new two-level stacked autoencoder network (termed 2L-SAE-SM) to improve its performance by integrating the heterogeneous feature sets. In particular, in the first level of 2L-SAE-SM, each optimal heterogeneous feature set is fed to train our designed stacked autoencoder network (SAE-SM). All the trained SAE-SMs in the first level can output the decision sets based on their respective optimal heterogeneous feature sets, known as ‘intermediate decision’ sets. Such intermediate decision sets are then ensembled using the mean ensemble method to generate the ‘intermediate feature’ set for the second-level SAE-SM. Using the proposed framework, we further develop a novel predictor, referred to as PScL-2LSAESM, to characterize image-based protein subcellular localization. Extensive benchmarking experiments on the latest benchmark training and independent test datasets collected from the human protein atlas databank demonstrate the effectiveness of the proposed 2L-SAE-SM framework for the integration of heterogeneous feature sets. Moreover, performance comparison of the proposed PScL-2LSAESM with current state-of-the-art methods further illustrates that PScL-2LSAESM clearly outperforms the existing state-of-the-art methods for the task of protein subcellular localization.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p><ext-link xlink:href="https://github.com/csbio-njust-edu/PScL-2LSAESM" ext-link-type="uri">https://github.com/csbio-njust-edu/PScL-2LSAESM</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>62072243</award-id>
        <award-id>61772273</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Natural Science Foundation of Jiangsu</institution>
          </institution-wrap>
        </funding-source>
        <award-id>BK20201304</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Fundamental Research Funds for the Central Universities</institution>
            <institution-id institution-id-type="DOI">10.13039/501100012226</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>30918011104</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Health and Medical Research Council of Australia</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NHMRC</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000925</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>1144652</award-id>
        <award-id>1127948</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Australian Research Council</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000923</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>LP110200333</award-id>
        <award-id>DP120104460</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of Allergy and Infectious Diseases of the National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01 AI111965</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Major and Seed Inter-Disciplinary Research</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Monash University</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001779</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NIH</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>The knowledge regarding the precise subcellular location of a protein is crucial for the determination of its function and involved biological processes (<xref rid="btac727-B6" ref-type="bibr">Dallago <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac727-B49" ref-type="bibr">Zhou <italic toggle="yes">et al.</italic>, 2017</xref>). Location proteomics is concerned with the large-scale study of protein localization inside a cell (<xref rid="btac727-B19" ref-type="bibr">Murphy, 2005</xref>; <xref rid="btac727-B21" ref-type="bibr">Newberg <italic toggle="yes">et al.</italic>, 2009</xref>). In location proteomics, various methods are used to analyze and predict protein subcellular localization such as wet-lab experiments or computational methods. Determining the protein subcellular localization via wet-lab experiments is often time-consuming and labor-intensive. Due to the importance of subcellular location of proteins and as a useful alternative to facilitate experimental characterization of protein subcellular localization, automatic computational methods are attracting a great deal of interest in recent years, representing the main focus in location proteomics.</p>
    <p>Over the past decades, a great variety of computational methods have emerged for characterization of protein subcellular localization from diverse protein data sources, including amino acid sequences or bioimages. Based on the data sources, these methods can be generally categorized into either one-dimensional sequence-based or two-dimensional (2D) image-based methods which can be further grouped into single-label or multi-label methods (<xref rid="btac727-B3" ref-type="bibr">Cheng <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac727-B12" ref-type="bibr">Hu <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac727-B25" ref-type="bibr">Özsarı <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac727-B42" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2018</xref>, <xref rid="btac727-B43" ref-type="bibr">2020</xref>; <xref rid="btac727-B44" ref-type="bibr">Xue <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac727-B45" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btac727-B47" ref-type="bibr">Yu <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac727-B48" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2021</xref>). In the case of sequence-based methods, they can effectively determine the location of the protein (<xref rid="btac727-B4" ref-type="bibr">Chou and Shen, 2008</xref>; <xref rid="btac727-B8" ref-type="bibr">Guo <italic toggle="yes">et al.</italic>, 2016</xref>) and protein properties (<xref rid="btac727-B14" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac727-B15" ref-type="bibr">Liu, 2019</xref>; <xref rid="btac727-B17" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac727-B18" ref-type="bibr">Luo <italic toggle="yes">et al.</italic>, 2019</xref>). However, as amino acid sequences do not change whenever the translocation takes place, this will make them unfit for the detection of subcellular translocation of proteins. In this regard, the image-based methods can serve as an alternative complementary to the sequence-based methods because they can unravel the crucial information regarding the spatial distribution of proteins across the normal and cancerous tissues, as well as their location changes in various tissues. Therefore, development of 2D image-based computational methods to facilitate the identification of protein subcellular localization has become an increasingly important problem in bioinformatics and computational biology (<xref rid="btac727-B26" ref-type="bibr">Peng <italic toggle="yes">et al.</italic>, 2012</xref>).</p>
    <p>During the development of image-based computational methods for analyzing protein subcellular localization, considerable challenges often exist for statistical and machine learning models, especially related to feature extraction, feature selection (FS), feature integration and classification. For example, DNA distribution and Haralick texture features, which belong to subcellular location features (SLFs) (<xref rid="btac727-B1" ref-type="bibr">Boland and Murphy, 2001</xref>), are frequently utilized to represent and encode the global information from the bioimages. In addition, a variety of local features such as local binary pattern (LBP) (<xref rid="btac727-B24" ref-type="bibr">Ojala <italic toggle="yes">et al.</italic>, 2002</xref>), completed local binary pattern (CLBP) (<xref rid="btac727-B9" ref-type="bibr">Guo <italic toggle="yes">et al.</italic>, 2010</xref>), local ternary pattern (<xref rid="btac727-B34" ref-type="bibr">Tan and Triggs, 2007</xref>), local quinary pattern (<xref rid="btac727-B20" ref-type="bibr">Nanni <italic toggle="yes">et al.</italic>, 2010</xref>), rotation invariant co-occurrence among adjacent local binary patterns (RICLBP) (<xref rid="btac727-B23" ref-type="bibr">Nosaka <italic toggle="yes">et al.</italic>, 2013</xref>) and locally encoded transform feature histogram (LETRIST) (<xref rid="btac727-B32" ref-type="bibr">Song <italic toggle="yes">et al.</italic>, 2018</xref>) are utilized to extract the local micropatterns from images. Current studies have shown that extracting both global and local features can help improve the predictive capabilities of the developed methods (<xref rid="btac727-B40" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2013</xref>, <xref rid="btac727-B41" ref-type="bibr">2016</xref>; <xref rid="btac727-B46" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2019</xref>). Similarly, at the FS stage, a number of studies have proposed different FS algorithms to effectively select the optimal features from the extracted features (<xref rid="btac727-B16" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac727-B22" ref-type="bibr">Newberg and Murphy, 2008</xref>; <xref rid="btac727-B30" ref-type="bibr">Shao <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac727-B37" ref-type="bibr">Ullah <italic toggle="yes">et al.</italic>, 2021</xref>). Among such FS algorithms, the stepwise discriminant analysis (SDA) algorithm (<xref rid="btac727-B13" ref-type="bibr">Klecka, 1980</xref>) has been widely adopted and shown to be effective for FS.</p>
    <p>Use of multiple heterogeneous features is a common step during the development of automated models as it remains a challenging task to represent the global and local features from images based on single traditional handcrafted feature sets. As such, the difficulty in feature integration arises when multiple features are used to represent the protein image. One useful way to utilize multiple feature sets is to simply concatenate all the feature sets in a simple serial fashion. Many protein subcellular localization prediction methods have utilized this simple serial integration strategy to integrate all the feature sets and subsequently develop a predictor (<xref rid="btac727-B33" ref-type="bibr">Tahir <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btac727-B38" ref-type="bibr">Ullah <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac727-B41" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2016</xref>, <xref rid="btac727-B42" ref-type="bibr">2018</xref>). More recently, several studies have investigated new techniques other than simple serial integration (<xref rid="btac727-B29" ref-type="bibr">Shao <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btac727-B39" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2022</xref>). However, less attention is being paid to integrating multiple feature sets and accordingly, there still remains significant challenges as to how these multiple feature sets can be efficiently integrated.</p>
    <p>From the algorithmic perspective, a number of different classification models have been developed to predict protein subcellular localization. For example, support vector machine (<xref rid="btac727-B5" ref-type="bibr">Cortes and Vapnik, 1995</xref>), error correcting output coding (<xref rid="btac727-B7" ref-type="bibr">Dietterich and Bakiri, 1994</xref>), discriminant error correcting output coding (<xref rid="btac727-B27" ref-type="bibr">Pujol <italic toggle="yes">et al.</italic>, 2006</xref>), random forest (RF) (<xref rid="btac727-B2" ref-type="bibr">Breiman, 2001</xref>) and deep learning-based models (<xref rid="btac727-B10" ref-type="bibr">Hinton <italic toggle="yes">et al.</italic>, 2006</xref>; <xref rid="btac727-B11" ref-type="bibr">Hochreiter and Schmidhuber, 1997</xref>; <xref rid="btac727-B31" ref-type="bibr">Simonyan and Zisserman, 2015</xref>) have been utilized efficiently. Despite the extensive efforts being undertaken, currently available computational approaches continue to have insufficient and limited performance of protein subcellular localization. This is particularly the case in terms of the overall success rate and as a consequence, there remains an exigent need to develop novel and high-performance predictors.</p>
    <p>Motivated by the issues mentioned above, in this study, we make the following contributions in order to improve the predictive performance of protein subcellular localization: first, to ensure that the dataset is up to date and no mistakenly labeled data are included, we collect the high-quality datasets from the latest version of human protein atlas (HPA) databank (<xref rid="btac727-B36" ref-type="bibr">Uhlén <italic toggle="yes">et al.</italic>, 2015</xref>) as the collection of the latest datasets is highly desirable for the development of accurate predictors; Second, we design and develop a new classifier called the stacked autoencoder-SoftMax (SAE-SM) network; Third, using the designed SAE-SM, we further develop a two-level SAE-SM (2L-SAE-SM) framework based on the integration of multiple feature sets, and fourth, based on 2L-SAE-SM, we implement a bioimage-based protein subcellular localization predictor termed PScL-2LSAESM. Benchmarking results on the stringent 10-fold cross-validation using the benchmark training dataset and the independent test using the independent test dataset illustrate the effectiveness of the proposed framework.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Benchmark datasets</title>
      <p>The benchmark image datasets used in this study were collected from the publicly available Tissue Atlas of the HPA database (version 21, <ext-link xlink:href="http://proteinatlas.org" ext-link-type="uri">http://proteinatlas.org</ext-link>) (<xref rid="btac727-B35" ref-type="bibr">Uhlen <italic toggle="yes">et al.</italic>, 2010</xref>; <xref rid="btac727-B36" ref-type="bibr">Uhlén <italic toggle="yes">et al.</italic>, 2015</xref>). The same criteria (i.e. reliability and validation scores) as <xref rid="btac727-B37" ref-type="bibr">Ullah <italic toggle="yes">et al.</italic> (2021)</xref> were considered during the collection of protein entries in our datasets. The immunohistochemistry (IHC)-based brightfield microscopic images of these proteins were collected in this study. All the images belong to normal human tissues; according to the annotations in HPA, each IHC image in the benchmark datasets was labeled as one of the seven major subcellular location classes including cytoplasm (Cytopl.), endoplasmic reticulum (ER), Golgi apparatus (Gol.), mitochondrion (Mito.), lysosome (Lyso.), nucleus (Nucl.) and vesicles (Vesi.).</p>
      <p>The benchmark training dataset, referred to as PScL2708, encompasses 2708 IHC images belonging to 23 different proteins. The subcellular location classes including cytoplasm, endoplasmic reticulum, Golgi apparatus, mitochondrion, lysosome, nucleus and vesicles contain 4, 3, 3, 3, 2, 4 and 4 different proteins, respectively. Similarly, we also collected the independent test dataset called PScL227 in our study. PScL227 has 227 IHC images belonging to seven distinguished proteins. Each protein belongs to one subcellular location class. <xref rid="btac727-T1" ref-type="table">Table 1</xref> summarizes the statistical distribution of the images across each subcellular location class for both the PScL2708 and PScL227 datasets.</p>
      <table-wrap position="float" id="btac727-T1">
        <label>Table 1.</label>
        <caption>
          <p>Statistical distribution of the images across each subcellular location class</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1">Dataset</th>
              <th colspan="7" align="center" rowspan="1">Subcellular location<hr/></th>
              <th rowspan="2" colspan="1">Total</th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">Cytopl.</th>
              <th rowspan="1" colspan="1">ER</th>
              <th rowspan="1" colspan="1">Gol.</th>
              <th rowspan="1" colspan="1">Lyso.</th>
              <th rowspan="1" colspan="1">Mito.</th>
              <th rowspan="1" colspan="1">Nucl.</th>
              <th rowspan="1" colspan="1">Vesi</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">PScL2708</td>
              <td rowspan="1" colspan="1">483</td>
              <td rowspan="1" colspan="1">310</td>
              <td rowspan="1" colspan="1">345</td>
              <td rowspan="1" colspan="1">224</td>
              <td rowspan="1" colspan="1">374</td>
              <td rowspan="1" colspan="1">472</td>
              <td rowspan="1" colspan="1">500</td>
              <td rowspan="1" colspan="1">2708</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PScL227</td>
              <td rowspan="1" colspan="1">34</td>
              <td rowspan="1" colspan="1">36</td>
              <td rowspan="1" colspan="1">27</td>
              <td rowspan="1" colspan="1">36</td>
              <td rowspan="1" colspan="1">30</td>
              <td rowspan="1" colspan="1">34</td>
              <td rowspan="1" colspan="1">30</td>
              <td rowspan="1" colspan="1">227</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>2.2 Image separation and feature extraction</title>
      <p>All IHC bioimages in the HPA database are the mixture of DNA and protein stains. As we were interested in the subcellular localizations of proteins only, therefore, we first used the linear spectral separation (LIN) method (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Text S1</xref> for details regarding the linear spectral separation) to separate each original IHC image into DNA and protein channels. Next, heterogeneous features extracted from multiple aspects might reveal hidden information from protein image samples, which is useful for predicting protein subcellular localization. Therefore, we extracted various global and local heterogeneous features considering that the global and local features are expected to extract complementary information from protein images (<xref rid="btac727-B45" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2014</xref>).</p>
      <p>In our study, we extracted five types of heterogeneous feature sets from each IHC image. These included SLFs, LBP, CLBP, LETRIST and RICLBP with the dimensionalities of 840, 256, 906, 413 and 408, respectively. Previous studies have shown these features to be very effective in this field (<xref rid="btac727-B37" ref-type="bibr">Ullah <italic toggle="yes">et al.</italic>, 2021</xref>, <xref rid="btac727-B38" ref-type="bibr">2022</xref>; <xref rid="btac727-B41" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2016</xref>). SLFs are the global features which includes 4-dimensional DNA distribution and 836-dimensional Haralick texture features (<xref rid="btac727-B1" ref-type="bibr">Boland and Murphy, 2001</xref>; <xref rid="btac727-B38" ref-type="bibr">Ullah <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac727-B40" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2013</xref>). SLFs are very useful for extracting the global texture information from images (<xref rid="btac727-B1" ref-type="bibr">Boland and Murphy, 2001</xref>). The corresponding LBP features were extracted to characterize the local texture structure and detect micropatterns such as spots, edges and flat areas. In addition, CLBP and RICLBP features were also extracted to ensure the rotation invariance and information neglected by LBP. Similarly, LETRIST features were extracted because they could explicitly encode the joint information within the IHC image across the feature and scale spaces. For the sake of convenience, we termed LETRIST as LET in this study. A detailed description of SLFs, LBP, CLBP, LET and RICLBP is provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Text S2</xref>. In the current study, we accordingly named these five extracted heterogeneous feature sets as SLFs-Raw, LBP-Raw, CLBP-Raw, LET-Raw and RICLBP-raw, respectively.</p>
    </sec>
    <sec>
      <title>2.3 Feature selection</title>
      <p>In our study, all the five extracted heterogeneous features (i.e. SLFs-Raw, LBP-Raw, CLBP-Raw, LET-Raw and RICLBP-raw) have high dimensionalities and as such, there might exist irrelevant, redundant and noisy information which may either cause overfitting or underfitting. In order to avoid dimension explosion and remove feature redundancy, the original extracted features need to be reduced by some FS algorithms. A series of studies utilized various FS algorithms during the analysis of protein subcellular localization; however, among all these algorithms, the SDA has proven to be more effective. Therefore, in this study, we also employed the SDA algorithm on each feature set.</p>
      <p>For a given training dataset <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the <italic toggle="yes">j</italic>-th image sample, <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is its corresponding label and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mi>N</mml:mi></mml:math></inline-formula> is the total number of features, let <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> be the <italic toggle="yes">t</italic>-th <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> heterogeneous feature set extracted from <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi>X</mml:mi></mml:math></inline-formula>, where <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the feature vector extracted from the <italic toggle="yes">j</italic>-th image sample for the <italic toggle="yes">t-</italic>th heterogeneous feature set. Suppose that for each feature vector <italic toggle="yes">j</italic> (i.e. <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>) in the <italic toggle="yes">t</italic>-th heterogeneous feature set <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> be its <italic toggle="yes">j</italic>-th data pair representing the <italic toggle="yes">j</italic>-th image sample of <italic toggle="yes">X</italic>, where <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is the optimal feature vector for the <italic toggle="yes">t</italic>-th optimal heterogeneous feature set, <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is the dimension of the optimal feature vector. For <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mi>N</mml:mi></mml:math></inline-formula>number of features, a corresponding <italic toggle="yes">t</italic>-th optimal heterogeneous feature set, denoted as <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> can be generated.</p>
      <p>For <italic toggle="yes">T</italic> heterogeneous feature sets <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">i</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">e</mml:mi><mml:mo>.</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula><inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, a total of <italic toggle="yes">T</italic> optimal heterogeneous feature sets <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">i</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">e</mml:mi><mml:mo>.</mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mo>,</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>T</mml:mi><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">opt</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> can be selected. For more theoretical and mathematical details of SDA algorithms, please refer to the <xref rid="sup1" ref-type="supplementary-material">Supplementary Text S3</xref>.</p>
      <p>In our study, we represent the optimal heterogeneous feature set of SLFs-Raw as SLFs-optimal, LBP-Raw as LBP-Optimal, CLBP-Raw as CLBP-Optimal, LET-Raw as LET-Optimal and RICLBP-raw as RICLBP-Optimal, respectively.</p>
    </sec>
    <sec>
      <title>2.4 Stacked autoencoder</title>
      <p>A single autoencoder (AE) (<xref rid="btac727-B28" ref-type="bibr">Rumelhart <italic toggle="yes">et al.</italic>, 1986</xref>) consists of an input layer, a hidden layer and an output layer (for details about autoencoder, please refer to the <xref rid="sup1" ref-type="supplementary-material">Supplementary Text S4</xref>). In order to construct a stacked autoencoder (SAE), multiple AEs are stacked on top of each other. In other words, an SAE is a neural network consisting of multiple layers of AEs where the activation output features of the <italic toggle="yes">k</italic>-th hidden layer of AE are sent as an input to the (<italic toggle="yes">k </italic>+<italic toggle="yes"> </italic>1)-th hidden layer of AE. In cases where an SAE is used as a classifier, a classification layer must be added as the top layer to compute and output the probabilities of the classes. The purpose of stacking multiple AEs is to boost the performance of the model.</p>
      <p>In the current study, we used two encoders and the SoftMax (SM) activation function as a classification layer to construct our stacked autoencoder network, referred to as SAE-SM as shown in <xref rid="btac727-F1" ref-type="fig">Figure 1</xref>. Given the input <inline-formula id="IE19"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mi>x</mml:mi></mml:math></inline-formula> (Input Layer), the first encoder (Encoder 1) produces first hidden layer activation output features <inline-formula id="IE20"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> (Features 1). The activation output features <inline-formula id="IE21"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>will be then fed to the second encoder (i.e. Encoder 2) generating the second hidden layer activation output features <inline-formula id="IE22"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> (i.e. Features 2). The activation output features <inline-formula id="IE23"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are finally fed to the SM classifier layer (SoftMax Classifier) to output the corresponding class probabilities. Each hidden layer size and hyperparameters are provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Text S5</xref>. In the hidden layers, we used the sigmoid activation function and also imposed the sparsity constraint on hidden units. Two training phases are involved during the training of our SAE-SM: (i) layer-by-layer pre-training which uses the unsupervised learning method and (ii) fine-tuning which uses the supervised back propagation (BP) method. For example, once the first AE is pre-trained based on the input <inline-formula id="IE24"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mi>x</mml:mi></mml:math></inline-formula>, the output (<inline-formula id="IE25"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) of the first AE can then be input to the next AE. This procedure continues until the pre-training is accomplished (i.e. layer-by-layer pre-training). Finally, the pre-trained SAE-SM is fine-tuned using the BP algorithm (i.e. fine-tuning).</p>
      <fig position="float" id="btac727-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Illustration of the SAE-SM-model architecture</p>
        </caption>
        <graphic xlink:href="btac727f1" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.5 Proposed 2L-SAE-SM</title>
      <p>In order to effectively integrate multiple feature sets, we propose the 2L-SAE-SM framework. <xref rid="btac727-F2" ref-type="fig">Figure 2</xref> illustrates its architecture. As can be seen, 2L-SAE-SM is a two-level model where in the first level, <inline-formula id="IE26"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mi>T</mml:mi></mml:math></inline-formula> number of SAE-SMs, denoted as SAE-SM<sub><italic toggle="yes">1</italic></sub>, SAE-SM<sub><italic toggle="yes">2</italic></sub>, …, SAE-SM<sub><italic toggle="yes">T</italic></sub><sub>-1</sub>, SAE-SM<sub><italic toggle="yes">T</italic></sub>, are trained on the <inline-formula id="IE27"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mi>T</mml:mi></mml:math></inline-formula> optimal heterogeneous feature sets selected from the <inline-formula id="IE28"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mi>T</mml:mi></mml:math></inline-formula> raw heterogeneous feature sets via the SDA algorithm detailed in the Section 2.3 to further learn the hidden information from the corresponding optimal heterogeneous feature set. The Mean Ensemble (ME) method is applied in the middle of two levels to ensemble the outputs of the trained first-level SAE-SMs, whose output would be fed into the second-level SAE-SM<sub><italic toggle="yes">ME</italic></sub> for making the prediction.</p>
      <fig position="float" id="btac727-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>The architecture of the proposed 2L-SAE-SM model for integrating heterogeneous feature sets</p>
        </caption>
        <graphic xlink:href="btac727f2" position="float"/>
      </fig>
      <p>Next, we describe the ME in detail below:</p>
      <p>Let <inline-formula id="IE29"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> be the <inline-formula id="IE30"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mi>T</mml:mi></mml:math></inline-formula> ‘intermediate decision’ sets, where <inline-formula id="IE31"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denotes the <italic toggle="yes">t</italic>-th ‘intermediate decision’ set. Then the ME can be represented as:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE32"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> denotes the ‘intermediate feature’ set.</p>
      <p>A major challenge is how to train a 2L-SAE-SM on a given training dataset. In order to efficiently handle this issue, <xref rid="sup1" ref-type="supplementary-material">Supplementary Text S6</xref> provides a detailed description of the training procedures of 2L-SAE-SM.</p>
      <p>Based on the 2L-SAE-SM framework, we developed a novel predictor PScL-2LSAESM to characterize image-based protein subcellular localization. An overview of the working flow of the proposed PScL-2LSAESM is illustrated in <xref rid="btac727-F3" ref-type="fig">Figure 3</xref>. Each major stage of the PScL-2LSAESM is described in <xref rid="sup1" ref-type="supplementary-material">Supplementary Text S7</xref> and the system configuration settings are discussed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Text S8</xref>.</p>
      <fig position="float" id="btac727-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Illustration of the architecture of the proposed PScL-2LSAESM model</p>
        </caption>
        <graphic xlink:href="btac727f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.6 Evaluation indices</title>
      <p>In this study, five commonly used performance indices specially designed for evaluating the performance of multiclass learning are employed. These included the overall accuracy (OA), Macroaverage Precision (Prec<sub>M</sub>), Macroaverage Recall (Rec<sub>M</sub>), Macroaverage F1-Score (F1-Score<sub>M</sub>) and Matthews’ Correlation Coefficient (MCC). In addition to these indices, the mean of the area under the receiver-operating characteristic (ROC) curves (AUC) denoted as meanAUC, the mean of area under precision-recall (PR) curves (AUPR) denoted as meanAUPR and the standard deviation of AUC and AUPR denoted as stdAUC and stdAUPR, respectively, are also used as the other four evaluation indices. All the performance evaluation indices are described in detail in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Text S9</xref>.</p>
      <p>Stringent <italic toggle="yes">k</italic>-fold cross-validation and independent validation tests are conducted to evaluate the performance of the proposed model. When performing <italic toggle="yes">k</italic>-fold cross-validation, the value of <italic toggle="yes">k</italic> was set to 10. It is noteworthy that when evaluating the performance of the model via stringent <italic toggle="yes">k</italic>-fold cross-validation, the features were selected independently in each fold of the train dataset to avoid biased evaluation of the model performance.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Performance comparison of the extracted heterogeneous feature sets</title>
      <p>In this section, we examined the discriminative capabilities of SLFs-Raw, LBP-Raw, CLBP-Raw, RICLBP-Raw and LET-Raw heterogeneous feature sets. The performance of each heterogeneous feature set was evaluated by performing 10-fold cross-validation on the benchmark training dataset PScL2708 with our designed SAE-SM classifier. The performance comparison of all the five heterogeneous feature sets in terms of OA, Rec<sub>M</sub>, Prec<sub>M</sub>, F1-Score<sub>M</sub> and MCC is provided in <xref rid="btac727-T2" ref-type="table">Table 2</xref>.</p>
      <table-wrap position="float" id="btac727-T2">
        <label>Table 2.</label>
        <caption>
          <p>Performance comparison of the raw feature sets on 10-fold cross-validation using the benchmark training dataset PScL2708</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Feature set</th>
              <th rowspan="1" colspan="1">OA (%)</th>
              <th rowspan="1" colspan="1">Rec<sub>M</sub> (%)</th>
              <th rowspan="1" colspan="1">Prec<sub>M</sub> (%)</th>
              <th rowspan="1" colspan="1">F1-Score<sub>M</sub></th>
              <th rowspan="1" colspan="1">MCC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SLFs-Raw</td>
              <td rowspan="1" colspan="1">67.54</td>
              <td rowspan="1" colspan="1">65.90</td>
              <td rowspan="1" colspan="1">66.66</td>
              <td rowspan="1" colspan="1">0.6622</td>
              <td rowspan="1" colspan="1">0.6168</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">LBP-Raw</td>
              <td rowspan="1" colspan="1">80.90</td>
              <td rowspan="1" colspan="1">79.54</td>
              <td rowspan="1" colspan="1">80.07</td>
              <td rowspan="1" colspan="1">0.7977</td>
              <td rowspan="1" colspan="1">0.7748</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CLBP-Raw</td>
              <td rowspan="1" colspan="1">81.83</td>
              <td rowspan="1" colspan="1">80.66</td>
              <td rowspan="1" colspan="1">81.06</td>
              <td rowspan="1" colspan="1">0.8084</td>
              <td rowspan="1" colspan="1">0.7857</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RICLBP-Raw</td>
              <td rowspan="1" colspan="1">78.84</td>
              <td rowspan="1" colspan="1">77.69</td>
              <td rowspan="1" colspan="1">77.93</td>
              <td rowspan="1" colspan="1">0.7775</td>
              <td rowspan="1" colspan="1">0.7506</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">LET-Raw</td>
              <td rowspan="1" colspan="1">77.80</td>
              <td rowspan="1" colspan="1">76.42</td>
              <td rowspan="1" colspan="1">76.88</td>
              <td rowspan="1" colspan="1">0.7662</td>
              <td rowspan="1" colspan="1">0.7382</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>Several observations can be derived from <xref rid="btac727-T2" ref-type="table">Table 2</xref>: first, among all the heterogeneous feature sets, the CLBP-Raw heterogeneous feature set served as the best performer in terms of all the evaluation metrics, suggesting the superiority of CLBP-Raw over the other four heterogonous feature sets. For example, CLBP-Raw achieved the F1-Score<sub>M</sub> = 0.8084 and MCC = 0.7857, which were 14.62% and 16.89%, 1.07% and 1.09%, 3.09% and 3.51%, and 4.22% and 4.75% higher than SLFs-Raw, LBP-Raw, RICLBP-Raw and LET-Raw, respectively. Upon closer inspection of the other four heterogeneous feature sets, we found that the LBP-Raw and RICLBP-Raw achieved the second and third best performance, respectively; Second, the performance of SLFs-Raw was not satisfactory. A possible reason is that the extracted raw heterogeneous feature sets might have redundant and noisy information which can result in the decreased predictive capabilities of the model; Third, keeping in mind that all the extracted raw heterogeneous feature sets may have redundant and noisy information, the performance results in <xref rid="btac727-T2" ref-type="table">Table 2</xref> suggest that all the five heterogeneous feature sets examined in this study can be effectively used to predict protein subcellular localization.</p>
    </sec>
    <sec>
      <title>3.2 Performance comparison of optimal heterogeneous feature sets</title>
      <p>As described in the Section 2.3, we fed each of the five extracted heterogeneous feature sets (i.e. SLFs-Raw, LBP-Raw, CLBP-Raw, RICLBP-Raw and LET-Raw) into the SDA FS algorithm and obtained its corresponding optimal heterogeneous feature set. Next, to investigate the discriminative capability of each optimal heterogeneous feature set, we performed 10-fold cross-validation on PScL2708 with SAE-SM as the classifier. <xref rid="btac727-T3" ref-type="table">Table 3</xref> provides the performance results of all the five selected optimal heterogeneous feature sets (i.e. SLFs-Optimal, LBP-Optimal, CLBP-Optimal, RICLBP-Optimal and LET-Optimal) in terms of OA, Rec<sub>M</sub>, Prec<sub>M</sub>, F1-Score<sub>M</sub> and MCC.</p>
      <table-wrap position="float" id="btac727-T3">
        <label>Table 3.</label>
        <caption>
          <p>Performance comparison of the optimal feature sets on 10-fold cross-validation using the benchmark training dataset PScL2708</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Feature set</th>
              <th rowspan="1" colspan="1">OA (%)</th>
              <th rowspan="1" colspan="1">Rec<sub>M</sub> (%)</th>
              <th rowspan="1" colspan="1">Prec<sub>M</sub> (%)</th>
              <th rowspan="1" colspan="1">F1-Score<sub>M</sub></th>
              <th rowspan="1" colspan="1">MCC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SLFs-Optimal</td>
              <td rowspan="1" colspan="1">77.62</td>
              <td rowspan="1" colspan="1">76.72</td>
              <td rowspan="1" colspan="1">76.51</td>
              <td rowspan="1" colspan="1">0.7660</td>
              <td rowspan="1" colspan="1">0.7363</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">LBP-Optimal</td>
              <td rowspan="1" colspan="1">83.19</td>
              <td rowspan="1" colspan="1">82.23</td>
              <td rowspan="1" colspan="1">82.11</td>
              <td rowspan="1" colspan="1">0.8215</td>
              <td rowspan="1" colspan="1">0.8020</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CLBP-Optimal</td>
              <td rowspan="1" colspan="1">84.08</td>
              <td rowspan="1" colspan="1">82.83</td>
              <td rowspan="1" colspan="1">83.02</td>
              <td rowspan="1" colspan="1">0.8292</td>
              <td rowspan="1" colspan="1">0.8123</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RICLBP-Optimal</td>
              <td rowspan="1" colspan="1">79.91</td>
              <td rowspan="1" colspan="1">79.14</td>
              <td rowspan="1" colspan="1">79.89</td>
              <td rowspan="1" colspan="1">0.7940</td>
              <td rowspan="1" colspan="1">0.7631</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">LET-Optimal</td>
              <td rowspan="1" colspan="1">80.35</td>
              <td rowspan="1" colspan="1">79.26</td>
              <td rowspan="1" colspan="1">79.39</td>
              <td rowspan="1" colspan="1">0.7932</td>
              <td rowspan="1" colspan="1">0.7683</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>From <xref rid="btac727-T3" ref-type="table">Table 3</xref>, it can be observed that use of the SDA FS algorithm indeed helped improve the predictive performance of protein subcellular localization. Particularly, for each of the optimal heterogeneous feature sets, all the evaluation metrics (i.e. OA, Rec<sub>M</sub>, Prec<sub>M</sub>, F1-Score<sub>M</sub> and MCC) were improved compared with the raw heterogeneous feature sets. Moreover, among all the extracted raw and optimal heterogeneous feature sets, CLBP-Optimal consistently achieved the maximal performance of OA, Rec<sub>M</sub>, Prec<sub>M</sub>, F1-Score<sub>M</sub> and MCC, which were 84.08%, 82.83%, 83.02%, 0.8292 and 0.8123, respectively. For a fair comparison, <xref rid="btac727-F4" ref-type="fig">Figure 4A–C</xref> show the bar-graph representations of the OA, F1-Score<sub>M</sub> and MCC values of the raw and optimal heterogeneous feature sets. We can see that SAE-SM trained using the optimal heterogeneous feature sets consistently achieved a better performance than its counterpart trained using the raw heterogeneous feature sets. More specifically, from <xref rid="btac727-F4" ref-type="fig">Figure 4A</xref>, it can be seen that the predictive performance of the SAE-SM in term of OA on SLFs-Optimal, LBP-Optimal, CLBP-Optimal, RICLBP-Optimal and LET-Optimal was improved by 10.07%, 2.29%, 2.25%, 1.07% and 2.55%, respectively, in comparison to that of the SAE-SM achieved on SLFs-Raw, LBP-Raw, CLBP-Raw, RICLBP-Raw and LET-Raw. Similarly, as shown in <xref rid="btac727-F4" ref-type="fig">Figure 4B and C</xref>, the F1-Score<sub>M</sub> and MCC values were also improved based on the optimal heterogeneous feature sets.</p>
      <fig position="float" id="btac727-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Performance comparison between the raw and optimal heterogeneous feature sets. Panels (<bold>A–C</bold>) display the performance comparisons in terms of OA, F1-ScoreM and MCC, respectively</p>
        </caption>
        <graphic xlink:href="btac727f4" position="float"/>
      </fig>
      <p>In summary, the results in <xref rid="btac727-T3" ref-type="table">Table 3</xref> and <xref rid="btac727-F4" ref-type="fig">Figure 4A–C</xref> clearly demonstrate that utilizing the optimal heterogeneous feature sets consistently improved the predictive performance of our proposed SAE-SM method. Therefore, in the following sections, instead of utilizing the raw heterogeneous feature sets, we used SLFs-Optimal, LBP-Optimal, CLBP-Optimal, RICLBP-Optimal and LET-Optimal as our five optimal heterogeneous feature sets to construct our model.</p>
    </sec>
    <sec>
      <title>3.3 Integrating feature sets via 2L-SAE-SM to improve the prediction performance</title>
      <p><xref rid="sup1" ref-type="supplementary-material">Supplementary Text S10</xref> provides the performance comparison of different classifiers based on serial integration of the optimal heterogeneous feature sets. In this section, we seek to examine the effectiveness of the proposed 2L-SAE-SM method and investigate whether integrating all the optimal heterogeneous feature sets with 2L-SAE-SM can be even more effective than the direct serial integration for predicting protein subcellular localization. To address this, we performed experiments on the PScL2708 using 10-fold cross-validation and the performance comparisons between the best optimal heterogeneous feature set, the serially integrated feature set and the feature set integrated by 2L-SAE-SM are provided in <xref rid="btac727-T4" ref-type="table">Table 4</xref>.</p>
      <table-wrap position="float" id="btac727-T4">
        <label>Table 4.</label>
        <caption>
          <p>Performance comparison between the best optimal features, features integrated serially and by 2L-SAE-SM on 10-fold cross-validation using the benchmark training dataset PScL2708</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Method</th>
              <th rowspan="1" colspan="1">OA (%)</th>
              <th rowspan="1" colspan="1">Rec<sub>M</sub> (%)</th>
              <th rowspan="1" colspan="1">Prec<sub>M</sub> (%)</th>
              <th rowspan="1" colspan="1">F1-Score<sub>M</sub></th>
              <th rowspan="1" colspan="1">MCC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">CLBP-Optimal+SAE-SM</td>
              <td rowspan="1" colspan="1">84.08</td>
              <td rowspan="1" colspan="1">82.83</td>
              <td rowspan="1" colspan="1">83.02</td>
              <td rowspan="1" colspan="1">0.8292</td>
              <td rowspan="1" colspan="1">0.8123</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Serial+SAE-SM</td>
              <td rowspan="1" colspan="1">87.18</td>
              <td rowspan="1" colspan="1">86.52</td>
              <td rowspan="1" colspan="1">86.56</td>
              <td rowspan="1" colspan="1">0.8653</td>
              <td rowspan="1" colspan="1">0.8489</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Features integrated by 2L-SAE-SM</td>
              <td rowspan="1" colspan="1">90.25</td>
              <td rowspan="1" colspan="1">89.31</td>
              <td rowspan="1" colspan="1">89.84</td>
              <td rowspan="1" colspan="1">0.8953</td>
              <td rowspan="1" colspan="1">0.8851</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>From <xref rid="btac727-T4" ref-type="table">Table 4</xref>, we can readily observe that the optimal heterogeneous feature sets integrated by 2L-SAE-SM drastically improved the performance. Compared with the feature set obtained by direct serial integration, the feature set integrated by 2L-SAE-SM achieved 3.07%, 3% and 3.62% improvements OA, F1-Score<sub>M</sub> and MCC, respectively. Similarly, by comparing with the CLBP-Optimal feature set, the feature set integrated by 2L-SAE-SM showed improvements of 6.17%, 6.61% and 7.28% in OA, F1-Score<sub>M</sub> and MCC, respectively. Additionally, the feature set integrated by 2L-SAE-SM also consistently performed well in terms of Rec<sub>M</sub> and Prec<sub>M</sub>.</p>
      <p>In order to verify the efficacy of the proposed 2L-SAE-SM, we compared the performance of these three feature sets in terms of ROC and PR curves in <xref rid="btac727-F5" ref-type="fig">Figures 5A–C</xref> and <xref rid="btac727-F6" ref-type="fig">6A–C</xref>. In particular, <xref rid="btac727-F5" ref-type="fig">Figures 5A</xref> and <xref rid="btac727-F6" ref-type="fig">6A</xref>, <xref rid="btac727-F5" ref-type="fig">5B</xref> and <xref rid="btac727-F6" ref-type="fig">6B</xref> and <xref rid="btac727-F5" ref-type="fig">5C</xref> and <xref rid="btac727-F6" ref-type="fig">6C</xref> show the ROC and PR curves for the CLBP-Optimal feature set, the serially integrated feature set and the feature set integrated by 2L-SAE-SM, respectively. Compared with the CLBP-Optimal and serially integrated feature sets, the feature set integrated by 2L-SAE-SM consistently achieved better performance by improving the ROC curve and AUC value for each individual class as shown in <xref rid="btac727-F5" ref-type="fig">Figure 5A–C</xref>. In terms of meanAUC, feature set integrated by 2L-SAE-SM achieved the meanAUC of 0.9906 and stdAUC of 0.0033 which was improved by 1.56% and 0.49% in comparison to the meanAUCs of 0.9750 and 0.9857 achieved by CLBP-Optimal and serially integrated feature sets, respectively. In addition, the feature set integrated by 2L-SAE-SM achieved the stdAUC of 0.0033 which was decreased by 0.77% and 0.15% in compassion to the stdAUCs of 0.0110 and 0.0048 achieved by CLBP-Optimal and serially integrated feature sets, respectively. Similarly, from <xref rid="btac727-F6" ref-type="fig">Figure 6A–C</xref>, the feature set integrated by 2L-SAE-SM achieved improvements in terms PR curve of AUPR value for each individual class. Considering the meanAUPR and stdAUPR, the feature set integrated by 2L-SAE-SM achieved the meanAUPR and stdAUPR of 0.9608 and 0.0171, respectively, which is clearly better than the meanAUPR and stdAUPR of 0.8923 and 0.0518 achieved by CLBP-Optimal feature set and the meanAUC and stdAUPR of 0.9326 and 0.0273 achieved by serially integrated feature set. Altogether, the results and performance comparisons in terms of all evaluation indices in <xref rid="btac727-T4" ref-type="table">Table 4</xref>, <xref rid="btac727-F5" ref-type="fig">Figures 5A–C</xref> and <xref rid="btac727-F6" ref-type="fig">6A–C</xref> prove that integrating all the optimal feature sets by 2L-SAE-SM can indeed improve the prediction accuracy for protein subcellular localization.</p>
      <fig position="float" id="btac727-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>ROC curves of the optimal heterogeneous features and features integrated serially and by 2L-SAE-SM. Panel (<bold>A</bold>) shows the ROC curves for the CLBP-Optimal feature set, panel (<bold>B</bold>) shows the ROC curves for the serially integrated feature set and panel (<bold>C</bold>) shows the ROC curves</p>
        </caption>
        <graphic xlink:href="btac727f5" position="float"/>
      </fig>
      <fig position="float" id="btac727-F6">
        <label>Fig. 6.</label>
        <caption>
          <p>PR curves for optimal heterogeneous feature, features integrated serially and by 2L-SAE-SM. Panel (<bold>A</bold>) shows the PR curves for the CLBP-Optimal feature set, panel (<bold>B</bold>) shows the PR curves for the serially integrated feature set and panel (<bold>C</bold>) shows the PR curves for the feature set integrated by 2L-SAE-SM</p>
        </caption>
        <graphic xlink:href="btac727f6" position="float"/>
      </fig>
      <p>Based upon the proposed 2L-SAE-SM, we developed a new computational method termed PScL-2LSAESM for the prediction of protein subcellular localization.</p>
    </sec>
    <sec>
      <title>3.4 Performance comparison with the other existing methods</title>
      <p>In this section, to further illustrate the predictive power of PScL-2LSAESM, we performed experiments and compared its performance with that of the other existing protein subcellular localization predictors including PScL-DDCFPred (<xref rid="btac727-B38" ref-type="bibr">Ullah <italic toggle="yes">et al.</italic>, 2022</xref>), PScL-HDeep (<xref rid="btac727-B37" ref-type="bibr">Ullah <italic toggle="yes">et al.</italic>, 2021</xref>), SAE-RF (<xref rid="btac727-B16" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2020</xref>), SC-PSorter (<xref rid="btac727-B29" ref-type="bibr">Shao <italic toggle="yes">et al.</italic>, 2016</xref>) as well as the method proposed by <xref rid="btac727-B45" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> (2014)</xref>.</p>
      <sec>
        <title>3.4.1 Performance comparison on 10-fold cross-validation test</title>
        <p>In this section, we further compared the proposed PScL-2LSAESM with the other existing predictors by conducting 10-fold cross-validation test on the PScL2708 dataset. To show the predictive capability, we first compared PScL-2LSAESM with the most recently published PScL-DDCFPred predictor. <xref rid="btac727-T5" ref-type="table">Table 5</xref> and <xref rid="btac727-F7" ref-type="fig">Figure 7A–D</xref> show the experimental results of the two predictors.</p>
        <fig position="float" id="btac727-F7">
          <label>Fig. 7.</label>
          <caption>
            <p>Performance comparisons between PScL-DDCFPred and the proposed PScL-2LSAESM method. Panels (<bold>A</bold>) and (<bold>B</bold>) show the ROC Curves, while (<bold>C</bold>) and (<bold>D</bold>) show the PR curves of PScL-DDCFPred and PScL-2LSAESM, respectively</p>
          </caption>
          <graphic xlink:href="btac727f7" position="float"/>
        </fig>
        <table-wrap position="float" id="btac727-T5">
          <label>Table 5.</label>
          <caption>
            <p>Performance comparison between PScL-2LSAESM and PScL-DDCFPred on 10-fold cross-validation using the benchmark training dataset PScL2708</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Method</th>
                <th rowspan="1" colspan="1">OA (%)</th>
                <th rowspan="1" colspan="1">Rec<sub>M</sub> (%)</th>
                <th rowspan="1" colspan="1">Prec<sub>M</sub> (%)</th>
                <th rowspan="1" colspan="1">F1-Score<sub>M</sub></th>
                <th rowspan="1" colspan="1">MCC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">PScL-DDCFPred<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">88.40</td>
                <td rowspan="1" colspan="1">88.38</td>
                <td rowspan="1" colspan="1">88.54</td>
                <td rowspan="1" colspan="1">0.8839</td>
                <td rowspan="1" colspan="1">0.8609</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PScL-2LSAESM</td>
                <td rowspan="1" colspan="1">90.25</td>
                <td rowspan="1" colspan="1">89.31</td>
                <td rowspan="1" colspan="1">89.84</td>
                <td rowspan="1" colspan="1">0.8953</td>
                <td rowspan="1" colspan="1">0.8851</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <label>a</label>
              <p>Results were calculated using the source code and data of PScL-DDCFPred.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>From <xref rid="btac727-T5" ref-type="table">Table 5</xref> and <xref rid="btac727-F7" ref-type="fig">Figure 7A–D</xref>, we conclude that the proposed PScL-2LSAESM outperformed the recently published PScL-DDCFPred. In particular, PScL-2LSAESM achieved the OA, F1-Score<sub>M</sub> and MCC of 90.25%, 0.8953 and 0.8851, respectively, which were improved by 1.85%, 1.14% and 2.24% compared with the OA, F1-Score<sub>M</sub> and MCC of the PScL-DDCFPred predictor, respectively. In addition, the Rec<sub>M</sub> and Prec<sub>M</sub> of the PScL-2LSAESM were consistently improved as well.</p>
        <p>Further, upon close inspection of <xref rid="btac727-F7" ref-type="fig">Figure 7A and C</xref> which show the ROC and PR curves of PScL-DDCFPred and <xref rid="btac727-F7" ref-type="fig">Figure 7B and D</xref> which show the ROC and PR curves of PScL-2LSAESM, respectively, we can see that the performance of the proposed PScL-2LSAESM was also clearly improved in terms of both ROC and PR curves. As shown in <xref rid="btac727-F7" ref-type="fig">Figure 7B</xref>, the AUC values achieved by PScL-2LSAESM were consistently improved across all the subcellular localization classes compared with those of PScL-DDCFPred shown in <xref rid="btac727-F7" ref-type="fig">Figure 7A</xref>. Similarly, upon a closer look at the results in <xref rid="btac727-F7" ref-type="fig">Figure 7D</xref>, we can see that the proposed PScL-2LSAESM also achieved better AUPR curve values for the majority of the subcellular localization classes in comparison to the results in <xref rid="btac727-F7" ref-type="fig">Figure 7C</xref> for PScL-DDCFPred. In addition, the meanAUC and meanAUPR values of the recently published PScL-DDCFPred were 0.9821 and 0.9417, respectively, while the meanAUC and meanAUPR values of the proposed PScL-2LSAESM were 0.9906 and 0.9608, respectively, the latter of which was clearly improved. Moroever, PScL-DDCFPred attained the stdAUC and stdAUPR values of 0.0037 and 0.0144, while the proposed PScL-2LSAESM method attained the stdAUC and stdAUPR of 0.0033 and 0.0171. Although the stdAUPR value of the proposed PScL-2LSAESM was not improved compared with PScL-DDCFPred, it achieved a competitive performance. In summary, the performance improvements in terms of all the other evaluation indices including OA, Rec<sub>M</sub>, Prec<sub>M</sub>, F1-Socre<sub>M</sub>, MCC, ROC curves and its AUC, meanAUC and stdAUC values, PR curves and its AUPR, meanAUPR values suggest the superiority of the proposed PScL-2LSAESM method over the previously developed PScL-DDCFPred method.</p>
        <p>Next, we benchmarked the predictive capability of the proposed PScL-2LSAESM against that of PScL-HDeep, SAE-RF, SC-PSorter and Yang <italic toggle="yes">et al.’s</italic> method in <xref rid="btac727-T6" ref-type="table">Table 6</xref> in terms of OA, meanAUC and stdAUC. We can see that PScL-2LSAESM consistently achieved a better performance with an improvement of about 4.3–12.63% and 0.88–2.45% in OA and meanAUC, respectively, than the OA and meanAUC values of the other existing predictors. Similarly, the stdAUC of the PScL-2LSAESM was also the lowest.</p>
        <table-wrap position="float" id="btac727-T6">
          <label>Table 6.</label>
          <caption>
            <p>Performance comparison of PScL-2LSAESM and the other existing methods on 10-fold cross-validation using the benchmark training dataset PScL2708</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Method</th>
                <th rowspan="1" colspan="1">OA (%)</th>
                <th rowspan="1" colspan="1">meanAUC</th>
                <th rowspan="1" colspan="1">stdAUC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">Yang <italic toggle="yes">et al.</italic><xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">77.62</td>
                <td rowspan="1" colspan="1">0.9661</td>
                <td rowspan="1" colspan="1">0.0229</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">SC-PSorter<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">80.45</td>
                <td rowspan="1" colspan="1">0.9702</td>
                <td rowspan="1" colspan="1">0.0193</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">SAE-RF<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">81.76</td>
                <td rowspan="1" colspan="1">0.9715</td>
                <td rowspan="1" colspan="1">0.0185</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PScL-HDeep<xref rid="tblfn3" ref-type="table-fn"><sup>b</sup></xref></td>
                <td rowspan="1" colspan="1">85.95</td>
                <td rowspan="1" colspan="1">0.9818</td>
                <td rowspan="1" colspan="1">0.0046</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PScL-2LSAESM</td>
                <td rowspan="1" colspan="1">90.25</td>
                <td rowspan="1" colspan="1">0.9906</td>
                <td rowspan="1" colspan="1">0.0033</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn2">
              <label>a</label>
              <p>Data excerpted from <xref rid="btac727-B16" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2020)</xref>.</p>
            </fn>
            <fn id="tblfn3">
              <label>b</label>
              <p>Data excerpted from <xref rid="btac727-B37" ref-type="bibr">Ullah <italic toggle="yes">et al.</italic> (2021)</xref>.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>In conclusion, the benchmarking results on the PScL2708 dataset confirmed that the proposed PScL-2LSAESM method achieved the best performance for the prediction of single-label multiclass protein subcellular localization.</p>
      </sec>
      <sec>
        <title>3.4.2 Performance comparison on the independent test</title>
        <p>In this section, we performed independent test to further assess the generalization capability of the proposed PScL-2LSAESM. For this purpose, we first trained PScL-2LSAESM on the PScL2708 dataset and then tested the performance of the trained PScL-2LSAESM model on the independent PScL227 dataset. Next, we compared the performance of PScL-2LSAESM with that of the recently published PScL-DDCFPred in terms of OA, Rec<sub>M</sub>, Prec<sub>M</sub>, F1-Score<sub>M</sub> and MCC. The performance results are provided in <xref rid="btac727-T7" ref-type="table">Table 7</xref>.</p>
        <table-wrap position="float" id="btac727-T7">
          <label>Table 7.</label>
          <caption>
            <p>Performance comparison between PScL-2LSAESM and PScL-DDCFPred on the independent test dataset PScL227</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Method</th>
                <th rowspan="1" colspan="1">OA (%)</th>
                <th rowspan="1" colspan="1">Rec<sub>M</sub> (%)</th>
                <th rowspan="1" colspan="1">Prec<sub>M</sub> (%)</th>
                <th rowspan="1" colspan="1">F1-Score<sub>M</sub></th>
                <th rowspan="1" colspan="1">MCC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">PScL-DDCFPred<xref rid="tblfn4" ref-type="table-fn"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">72.28</td>
                <td rowspan="1" colspan="1">72.30</td>
                <td rowspan="1" colspan="1">74.41</td>
                <td rowspan="1" colspan="1">0.7270</td>
                <td rowspan="1" colspan="1">0.6694</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PScL-2LSAESM</td>
                <td rowspan="1" colspan="1">74.88</td>
                <td rowspan="1" colspan="1">74.94</td>
                <td rowspan="1" colspan="1">75.48</td>
                <td rowspan="1" colspan="1">0.7471</td>
                <td rowspan="1" colspan="1">0.7085</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn4">
              <label>a</label>
              <p>Data excerpted from <xref rid="btac727-B38" ref-type="bibr">Ullah <italic toggle="yes">et al.</italic> (2022)</xref>.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>From <xref rid="btac727-T7" ref-type="table">Table 7</xref>, we can see that the proposed PScL-2LSAESM method achieved an improved performance than PScL-DDCFPred in terms of all the evaluation indices. For example, PScL-2LSAESM achieved the OA, F1-Score<sub>M</sub> and MCC of 74.88%, 0.7471 and 0.7085, respectively, which were 2.6%, 2.01% and 3.91% higher than the OA, F1-Score<sub>M</sub> and MCC values of PScL-DDCFPred, respectively. These results highlight that PScL-2LSAESM outperformed PScL-DDCFPred and provided a better generalization capability.</p>
        <p>To further illustrate the generalization capability of PScL-2LSAESM, we provide the performance comparison of the proposed PScL-2LSAESM, PScL-HDeep, SAE-RF, SC-PSorter and Yang <italic toggle="yes">et al.’s</italic> method in terms of OA in <xref rid="btac727-F8" ref-type="fig">Figure 8</xref>. Note that parts of the results in <xref rid="btac727-F8" ref-type="fig">Figure 8</xref> were excerpted from the previous works of <xref rid="btac727-B16" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2020)</xref> and <xref rid="btac727-B37" ref-type="bibr">Ullah <italic toggle="yes">et al.</italic> (2021)</xref>. We can see that PScL-2LSAESM attained the OA of 74.88% which was 11.9%, 8.76%, 7.73% and 3.86% higher than that of Yang <italic toggle="yes">et al.’s</italic> method, SC-PSorter, SAE-RF and PScL-HDeep, respectively. From <xref rid="btac727-F8" ref-type="fig">Figure 8</xref>, we conclude that PScL-2LSAESM has the best generalization capability compared with the other compared methods.</p>
        <fig position="float" id="btac727-F8">
          <label>Fig. 8.</label>
          <caption>
            <p>Performance comparison between PScL-2LSAESM and the existing predictors on the independent test dataset</p>
          </caption>
          <graphic xlink:href="btac727f8" position="float"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>In this study, we have proposed a new computational method termed PScL-2LSAESM to effectively improve the bioimage-based prediction of human protein subcellular localization in human tissues. Specifically, a 2L-SAE-SM system was developed to integrate multiple heterogeneous feature sets into PScL-2LSAESM. For this purpose, we first designed a stacked based autoencoder with the SoftMax as the classifier layer, referred to as SAE-SM. Using SAE-SM, we implemented a two-level SAE-SM (2L-SAE-SM) where in the first level, each of the optimal heterogeneous feature sets (i.e. SLFs-Optimal, LBP-Optimal, CLBP-Optimal, LET-Optimal and RICLBP-Optimal) was fed into a single SAE-SM and then output the decision level set termed the ‘intermediate decision’ set. All the produced intermediate decision sets were then integrated using the ME method in the 2L-SAE-SM as the ‘intermediate feature’ set and then sent to the second-level SAE-SM. Both stringent 10-fold cross-validation test on the newly collected benchmark training dataset PScL2708 and independent test on the newly collected independent test dataset PScL227 have demonstrated the effectiveness of the proposed 2L-SAE-SM method for heterogeneous feature set integration. Extensive benchmarking experiments have also shown that the proposed PScL-2LSAESM predictor clearly outperformed the other existing single-label multiclass protein subcellular localization prediction methods. We expect that the proposed predictor can be explored as a useful method to facilitate the characterization of single-label multiclass protein subcellular localizations. In the future work, we plan to develop improved strategies to improve the performance of the proposed framework through the integration of multiple data sources such as protein amino acid sequences, protein images and protein-protein interaction networks.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac727_Supplementary_Data</label>
      <media xlink:href="btac727_supplementary_data.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the National Natural Science Foundation of China (62072243 and 61772273), the Natural Science Foundation of Jiangsu (BK20201304), the Fundamental Research Funds for the Central Universities (30918011104), the National Health and Medical Research Council of Australia (NHMRC) (1144652 and 1127948), the Australian Research Council (ARC) (LP110200333 and DP120104460), the National Institute of Allergy and Infectious Diseases of the National Institutes of Health (R01 AI111965) and Major and Seed Inter-Disciplinary Research (IDR) projects awarded by Monash University.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: The authors declare no conflict of interest.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>All the data and source codes used in this study are freely available at <ext-link xlink:href="https://github.com/csbio-njust-edu/PScL-2LSAESM" ext-link-type="uri">https://github.com/csbio-njust-edu/PScL-2LSAESM</ext-link>.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac727-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Boland</surname><given-names>M.V.</given-names></string-name>, <string-name><surname>Murphy</surname><given-names>R.F.</given-names></string-name></person-group> (<year>2001</year>) <article-title>A neural network classifier capable of recognizing the patterns of all major subcellular structures in fluorescence microscope images of HeLa cells</article-title>. <source>Bioinformatics</source>, <volume>17</volume>, <fpage>1213</fpage>–<lpage>1223</lpage>.<pub-id pub-id-type="pmid">11751230</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Breiman</surname><given-names>L.</given-names></string-name></person-group> (<year>2001</year>) <article-title>Random forests</article-title>. <source>Mach. Learn</source>., <volume>45</volume>, <fpage>5</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheng</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>pLoc-mHum: predict subcellular localization of multi-location human proteins via general PseAAC to winnow out the crucial GO information</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>1448</fpage>–<lpage>1456</lpage>.<pub-id pub-id-type="pmid">29106451</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chou</surname><given-names>K.-C.</given-names></string-name>, <string-name><surname>Shen</surname><given-names>H.-B.</given-names></string-name></person-group> (<year>2008</year>) <article-title>Cell-PLoc: a package of web servers for predicting subcellular localization of proteins in various organisms</article-title>. <source>Nat. Protoc</source>., <volume>3</volume>, <fpage>153</fpage>–<lpage>162</lpage>.<pub-id pub-id-type="pmid">18274516</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cortes</surname><given-names>C.</given-names></string-name>, <string-name><surname>Vapnik</surname><given-names>V.</given-names></string-name></person-group> (<year>1995</year>) <article-title>Support-vector networks</article-title>. <source>Mach. Learn</source>., <volume>20</volume>, <fpage>273</fpage>–<lpage>297</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dallago</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>CellMap visualizes protein-protein interactions and subcellular localization</article-title>. <source>F1000Res</source>., <volume>6</volume>, <fpage>1824</fpage>.<pub-id pub-id-type="pmid">29497493</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dietterich</surname><given-names>T.G.</given-names></string-name>, <string-name><surname>Bakiri</surname><given-names>G.</given-names></string-name></person-group> (<year>1994</year>) <article-title>Solving multiclass learning problems via error-correcting output codes</article-title>. <source>J. Artif. Intell. Res</source>., <volume>2</volume>, <fpage>263</fpage>–<lpage>286</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>Human protein subcellular localization with integrated source and multi-label ensemble classifier</article-title>. <source>Sci. Rep</source>., <volume>6</volume>, <fpage>28087</fpage>.<pub-id pub-id-type="pmid">27323846</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname><given-names>Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2010</year>) <article-title>A completed modeling of local binary pattern operator for texture classification</article-title>. <source>IEEE Trans. Image Process</source>., <volume>19</volume>, <fpage>1657</fpage>–<lpage>1663</lpage>.<pub-id pub-id-type="pmid">20215079</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hinton</surname><given-names>G.E.</given-names></string-name></person-group><etal>et al</etal> (<year>2006</year>) <article-title>A fast learning algorithm for deep belief nets</article-title>. <source>Neural Comput</source>., <volume>18</volume>, <fpage>1527</fpage>–<lpage>1554</lpage>.<pub-id pub-id-type="pmid">16764513</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hochreiter</surname><given-names>S.</given-names></string-name>, <string-name><surname>Schmidhuber</surname><given-names>J.</given-names></string-name></person-group> (<year>1997</year>) <article-title>Long short-term memory</article-title>. <source>Neural Comput</source>., <volume>9</volume>, <fpage>1735</fpage>–<lpage>1780</lpage>.<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hu</surname><given-names>J.-X.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Incorporating label correlations into deep neural networks to classify protein subcellular location patterns in immunohistochemistry images</article-title>. <source>Proteins</source>, <volume>90</volume>, <fpage>493</fpage>–<lpage>503</lpage>.<pub-id pub-id-type="pmid">34546597</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B13">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Klecka</surname><given-names>W.R.</given-names></string-name></person-group> (<year>1980</year>) <source>Discriminant analysis</source>. <publisher-name>SAGE Publications, Inc</publisher-name>, <publisher-loc>Thousands Oaks, CA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btac727-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>H.-L.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>BioSeq-BLM: a platform for analyzing DNA, RNA and protein sequences based on biological language models</article-title>. <source>Nucleic Acids Res</source>., <volume>49</volume>, <fpage>e129</fpage>.<pub-id pub-id-type="pmid">34581805</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>B.</given-names></string-name></person-group> (<year>2019</year>) <article-title>BioSeq-Analysis: a platform for DNA, RNA and protein sequence analysis based on machine learning approaches</article-title>. <source>Brief. Bioinform</source>., <volume>20</volume>, <fpage>1280</fpage>–<lpage>1294</lpage>.<pub-id pub-id-type="pmid">29272359</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>G.H.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Bioimage-based prediction of protein subcellular location in human tissue with ensemble features and deep networks</article-title>. <source>IEEE/ACM Trans. Comput. Biol. Bioinformatics</source>, <volume>17</volume>, <fpage>1966</fpage>–<lpage>1980</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>PTM-ssMP: a web server for predicting different types of post-translational modification sites using novel site-specific modification profile</article-title>. <source>Int. J. Biol. Sci</source>., <volume>14</volume>, <fpage>946</fpage>–<lpage>956</lpage>.<pub-id pub-id-type="pmid">29989096</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luo</surname><given-names>F.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>DeepPhos: prediction of protein phosphorylation sites with deep learning</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>2766</fpage>–<lpage>2773</lpage>.<pub-id pub-id-type="pmid">30601936</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murphy</surname><given-names>R.F.</given-names></string-name></person-group> (<year>2005</year>) <article-title>Location proteomics: a systems approach to subcellular location</article-title>. <source>Biochem. Soc. Trans</source>., <volume>33</volume>, <fpage>535</fpage>–<lpage>538</lpage>.<pub-id pub-id-type="pmid">15916558</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nanni</surname><given-names>L.</given-names></string-name></person-group><etal>et al</etal> (<year>2010</year>) <article-title>Local binary patterns variants as texture descriptors for medical image analysis</article-title>. <source>Artif. Intell. Med</source>., <volume>49</volume>, <fpage>117</fpage>–<lpage>125</lpage>.<pub-id pub-id-type="pmid">20338737</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Newberg</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2009</year>) <article-title>Location proteomics: systematic determination of protein subcellular location</article-title>. <source>Methods Mol. Biol</source>., <volume>500</volume>, <fpage>313</fpage>–<lpage>332</lpage>.<pub-id pub-id-type="pmid">19399439</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Newberg</surname><given-names>J.</given-names></string-name>, <string-name><surname>Murphy</surname><given-names>R.F.</given-names></string-name></person-group> (<year>2008</year>) <article-title>A framework for the automated analysis of subcellular patterns in human protein atlas images</article-title>. <source>J. Proteome Res</source>., <volume>7</volume>, <fpage>2300</fpage>–<lpage>2308</lpage>.<pub-id pub-id-type="pmid">18435555</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B23">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Nosaka</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <part-title>Rotation invariant co-occurrence among adjacent LBPs</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Park</surname><given-names>J.-I.</given-names></string-name>, <string-name><surname>Kim</surname><given-names>J.</given-names></string-name></person-group> (eds.) <source>Computer Vision—ACCV 2012 Workshops</source>. <publisher-name>Springer</publisher-name>, <publisher-loc>Berlin, Heidelberg</publisher-loc>, pp. <fpage>15</fpage>–<lpage>25</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ojala</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2002</year>) <article-title>Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell</source>., <volume>24</volume>, <fpage>971</fpage>–<lpage>987</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Özsarı</surname><given-names>G.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>SLPred: a multi-view subcellular localization prediction tool for multi-location human proteins</article-title>. <source>Bioinformatics</source>, <volume>38</volume>, <fpage>4226</fpage>–<lpage>4229</lpage>.<pub-id pub-id-type="pmid">35801913</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peng</surname><given-names>H.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>Bioimage informatics: a new category in bioinformatics</article-title>. <source>Bioinformatics</source>, <volume>28</volume>, <fpage>1057</fpage>.<pub-id pub-id-type="pmid">22399678</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pujol</surname><given-names>O.</given-names></string-name></person-group><etal>et al</etal> (<year>2006</year>) <article-title>Discriminant ECOC: a heuristic method for application dependent design of error correcting output codes</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell</source>., <volume>28</volume>, <fpage>1007</fpage>–<lpage>1012</lpage>.<pub-id pub-id-type="pmid">16724594</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B28">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Rumelhart</surname><given-names>D.E.</given-names></string-name></person-group><etal>et al</etal> (<year>1986</year>) <part-title>Learning internal representations by error propagation</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Rumelhart</surname><given-names>D.E.</given-names></string-name>, <string-name><surname>McClelland</surname><given-names>J.L.</given-names></string-name></person-group> (eds.) <source>Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 1: Foundations</source>. <publisher-name>MIT Press</publisher-name>, <publisher-loc>Cambridge, MA</publisher-loc>, pp. <fpage>318</fpage>–<lpage>362</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shao</surname><given-names>W.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>Human cell structure-driven model construction for predicting protein subcellular location from biological images</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>114</fpage>–<lpage>121</lpage>.<pub-id pub-id-type="pmid">26363175</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shao</surname><given-names>W.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>An organelle correlation-guided feature selection approach for classifying multi-label subcellular bio-images</article-title>. <source>IEEE/ACM Trans. Comput. Biol. Bioinformatics</source>, <volume>15</volume>, <fpage>828</fpage>–<lpage>838</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B31">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Simonyan</surname><given-names>K.</given-names></string-name>, <string-name><surname>Zisserman</surname><given-names>A.</given-names></string-name></person-group> (<year>2015</year>) Very deep convolutional networks for large-scale image recognition. In: <italic toggle="yes">3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA</italic>.</mixed-citation>
    </ref>
    <ref id="btac727-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>LETRIST: locally encoded transform feature histogram for rotation-invariant texture classification</article-title>. <source>IEEE Trans. Circuits Syst. Video Technol</source>., <volume>28</volume>, <fpage>1565</fpage>–<lpage>1579</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tahir</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <article-title>Subcellular localization using fluorescence imagery: utilizing ensemble classification with diverse feature extraction strategies and data balancing</article-title>. <source>Appl. Soft Comput</source>., <volume>13</volume>, <fpage>4231</fpage>–<lpage>4243</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B34">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Tan</surname><given-names>X.</given-names></string-name>, <string-name><surname>Triggs</surname><given-names>B.</given-names></string-name></person-group> (<year>2007</year>) <part-title>Enhanced local texture feature sets for face recognition under difficult lighting conditions</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Zhou</surname><given-names>S.K.</given-names></string-name></person-group> (ed.) <source>Analysis and Modeling of Faces and Gestures</source>. <publisher-name>Springer Berlin Heidelberg</publisher-name>, <publisher-loc>Berlin, Heidelberg</publisher-loc>, pp. <fpage>168</fpage>–<lpage>182</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Uhlen</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2010</year>) <article-title>Towards a knowledge-based human protein atlas</article-title>. <source>Nat. Biotechnol</source>., <volume>28</volume>, <fpage>1248</fpage>–<lpage>1250</lpage>.<pub-id pub-id-type="pmid">21139605</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Uhlén</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) <article-title>Tissue-based map of the human proteome</article-title>. <source>Science</source>, <volume>347</volume>, <fpage>1260419</fpage>.<pub-id pub-id-type="pmid">25613900</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ullah</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>PScL-HDeep: image-based prediction of protein subcellular location in human tissue using ensemble learning of handcrafted and deep learned features with two-layer feature selection</article-title>. <source>Brief. Bioinform</source>., <volume>22</volume>, <fpage>bbab278</fpage>.<pub-id pub-id-type="pmid">34337652</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ullah</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>PScL-DDCFPred: an ensemble deep learning-based approach for characterizing multiclass subcellular localization of human proteins from bioimage data</article-title>. <source>Bioinformatics</source>, <volume>38</volume>, <fpage>4019</fpage>–<lpage>4026</lpage>.<pub-id pub-id-type="pmid">35771606</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>G.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Learning protein subcellular localization multi-view patterns from heterogeneous data of imaging, sequence and networks</article-title>. <source>Brief. Bioinform</source>., <volume>23</volume>, <fpage>bbab539</fpage>.<pub-id pub-id-type="pmid">35018423</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>Y.-Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <article-title>An image-based multi-label human protein subcellular localization predictor (iLocator) reveals protein mislocalizations in cancer tissues</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>2032</fpage>–<lpage>2040</lpage>.<pub-id pub-id-type="pmid">23740749</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>Y.-Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>Incorporating organelle correlations into semi-supervised learning for protein subcellular localization prediction</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>2184</fpage>–<lpage>2192</lpage>.<pub-id pub-id-type="pmid">27153655</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>Y.-Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Bioimage-based protein subcellular location prediction: a comprehensive review</article-title>. <source>Front. Comput. Sci</source>., <volume>12</volume>, <fpage>26</fpage>–<lpage>39</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>Y.-Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Learning complex subcellular distribution patterns of proteins via analysis of immunohistochemistry images</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>1908</fpage>–<lpage>1914</lpage>.<pub-id pub-id-type="pmid">31722369</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xue</surname><given-names>Z.-Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Automated classification of protein subcellular localization in immunohistochemistry images to reveal biomarkers in colon cancer</article-title>. <source>BMC Bioinformatics</source>, <volume>21</volume>, <fpage>398</fpage>.<pub-id pub-id-type="pmid">32907537</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>F.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) <article-title>Image-based classification of protein subcellular location patterns in human reproductive tissue by ensemble learning global and local features</article-title>. <source>Neurocomputing</source>, <volume>131</volume>, <fpage>113</fpage>–<lpage>123</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>F.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>MIC_locator: a novel image-based protein subcellular location multi-label prediction model based on multi-scale monogenic signal representation and intensity encoding strategy</article-title>. <source>BMC Bioinformatics</source>, <volume>20</volume>, <fpage>522</fpage>.<pub-id pub-id-type="pmid">31655541</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname><given-names>B.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>SubMito-XGBoost: predicting protein submitochondrial localization by fusing multiple feature information and eXtreme gradient boosting</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>1074</fpage>–<lpage>1081</lpage>.</mixed-citation>
    </ref>
    <ref id="btac727-B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Q.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Accurate prediction of multi-label protein subcellular localization through multi-view feature learning with RBRL classifier</article-title>. <source>Brief. Bioinform</source>, <volume>22</volume>, <fpage>bbab012</fpage>.<pub-id pub-id-type="pmid">33537726</pub-id></mixed-citation>
    </ref>
    <ref id="btac727-B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>H.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Hum-mPLoc 3.0: prediction enhancement of human protein subcellular localization through modeling the hidden correlations of gene ontology and functional domain features</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>843</fpage>–<lpage>853</lpage>.<pub-id pub-id-type="pmid">27993784</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
