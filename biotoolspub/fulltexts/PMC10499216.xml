<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLOS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10499216</article-id>
    <article-id pub-id-type="pmid">37651442</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011435</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-23-00388</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Molecular Biology</subject>
          <subj-group>
            <subject>Macromolecular Structure Analysis</subject>
            <subj-group>
              <subject>Protein Structure</subject>
              <subj-group>
                <subject>Protein Structure Prediction</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Protein Structure</subject>
              <subj-group>
                <subject>Protein Structure Prediction</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Neural Networks</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Neural Networks</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Molecular Biology</subject>
          <subj-group>
            <subject>Macromolecular Structure Analysis</subject>
            <subj-group>
              <subject>Protein Structure</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Protein Structure</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Chemistry</subject>
          <subj-group>
            <subject>Polymer Chemistry</subject>
            <subj-group>
              <subject>Monomers</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Mathematical Functions</subject>
            <subj-group>
              <subject>Convolution</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Statistical Methods</subject>
            <subj-group>
              <subject>Forecasting</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical Methods</subject>
              <subj-group>
                <subject>Forecasting</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Neural Networks</subject>
          <subj-group>
            <subject>Recurrent Neural Networks</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Neural Networks</subject>
            <subj-group>
              <subject>Recurrent Neural Networks</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Physics</subject>
          <subj-group>
            <subject>Classical Mechanics</subject>
            <subj-group>
              <subject>Reflection</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>E(3) equivariant graph neural networks for robust and accurate protein-protein interaction site prediction</article-title>
      <alt-title alt-title-type="running-head">E(3) equivariant graph neural networks for protein-protein interaction site prediction</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Roche</surname>
          <given-names>Rahmatullah</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Moussad</surname>
          <given-names>Bernard</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shuvo</surname>
          <given-names>Md Hossain</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9630-0141</contrib-id>
        <name>
          <surname>Bhattacharya</surname>
          <given-names>Debswapna</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="cor001" ref-type="corresp">*</xref>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <addr-line>Department of Computer Science, Virginia Tech, Blacksburg, Virginia, United States of America</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Li</surname>
          <given-names>Jinyan</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>University of Technology Sydney, AUSTRALIA</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>dbhattacharya@vt.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>31</day>
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <volume>19</volume>
    <issue>8</issue>
    <elocation-id>e1011435</elocation-id>
    <history>
      <date date-type="received">
        <day>10</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>15</day>
        <month>8</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 Roche et al</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Roche et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1011435.pdf"/>
    <abstract>
      <p>Artificial intelligence-powered protein structure prediction methods have led to a paradigm-shift in computational structural biology, yet contemporary approaches for predicting the interfacial residues (i.e., sites) of protein-protein interaction (PPI) still rely on experimental structures. Recent studies have demonstrated benefits of employing graph convolution for PPI site prediction, but ignore symmetries naturally occurring in 3-dimensional space and act only on experimental coordinates. Here we present EquiPPIS, an E(3) equivariant graph neural network approach for PPI site prediction. EquiPPIS employs symmetry-aware graph convolutions that transform equivariantly with translation, rotation, and reflection in 3D space, providing richer representations for molecular data compared to invariant convolutions. EquiPPIS substantially outperforms state-of-the-art approaches based on the same experimental input, and exhibits remarkable robustness by attaining better accuracy with predicted structural models from AlphaFold2 than what existing methods can achieve even with experimental structures. Freely available at <ext-link xlink:href="https://github.com/Bhattacharya-Lab/EquiPPIS" ext-link-type="uri">https://github.com/Bhattacharya-Lab/EquiPPIS</ext-link>, EquiPPIS enables accurate PPI site prediction at scale.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>Predicting how proteins interact and characterizing the interacting residues at the protein-protein interaction interface (i.e., sites) is of central importance to understanding various biological processes actuated by protein-protein interactions (PPI). Despite the remarkable recent progress in protein structure prediction driven by artificial intelligence, existing approaches for PPI site prediction still rely on experimental input. This paper presents an E(3) equivariant graph neural network approach for PPI site prediction that takes into account symmetries naturally occurring in 3-dimensional space and transforms equivariantly with translation, rotation, and reflection. Rigorous experimental validation shows that our method attains substantially improved accuracy and robustness over the existing approaches. Moving beyond what is currently possible with only experimental input, our method enables large-scale PPI site prediction using predicted structural models from AlphaFold2 without compromising on accuracy. An open-source software implementation of EquiPPIS, licensed under the GNU General Public License v3, is freely available at <ext-link xlink:href="https://github.com/Bhattacharya-Lab/EquiPPIS" ext-link-type="uri">https://github.com/Bhattacharya-Lab/EquiPPIS</ext-link>.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000057</institution-id>
            <institution>National Institute of General Medical Sciences</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R35GM138146</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9630-0141</contrib-id>
          <name>
            <surname>Bhattacharya</surname>
            <given-names>Debswapna</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000001</institution-id>
            <institution>National Science Foundation</institution>
          </institution-wrap>
        </funding-source>
        <award-id>DBI2208679</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9630-0141</contrib-id>
          <name>
            <surname>Bhattacharya</surname>
            <given-names>Debswapna</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>This work was partially supported by the National Institute of General Medical Sciences (R35GM138146 to D.B.) and the National Science Foundation (DBI2208679 to D.B.). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="3"/>
      <page-count count="19"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>PLOS Publication Stage</meta-name>
        <meta-value>vor-update-to-uncorrected-proof</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>Publication Update</meta-name>
        <meta-value>2023-09-13</meta-value>
      </custom-meta>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>Data availability: The raw data used in this study, including the datasets for train, test and validation are collected from publicly available sources and freely available at <ext-link xlink:href="https://github.com/biomed-AI/GraphPPIS" ext-link-type="uri">https://github.com/biomed-AI/GraphPPIS</ext-link>. Code availability: An open-source software implementation of EquiPPIS, licensed under the GNU General Public License v3, is freely available at <ext-link xlink:href="https://github.com/Bhattacharya-Lab/EquiPPIS" ext-link-type="uri">https://github.com/Bhattacharya-Lab/EquiPPIS</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>Data availability: The raw data used in this study, including the datasets for train, test and validation are collected from publicly available sources and freely available at <ext-link xlink:href="https://github.com/biomed-AI/GraphPPIS" ext-link-type="uri">https://github.com/biomed-AI/GraphPPIS</ext-link>. Code availability: An open-source software implementation of EquiPPIS, licensed under the GNU General Public License v3, is freely available at <ext-link xlink:href="https://github.com/Bhattacharya-Lab/EquiPPIS" ext-link-type="uri">https://github.com/Bhattacharya-Lab/EquiPPIS</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Protein-protein interactions (PPI) underpin numerous biological processes [<xref rid="pcbi.1011435.ref001" ref-type="bibr">1</xref>, <xref rid="pcbi.1011435.ref002" ref-type="bibr">2</xref>]. Despite their importance, experimental characterization of PPI remains challenging due to the costly and time-consuming nature of the experimental assays [<xref rid="pcbi.1011435.ref003" ref-type="bibr">3</xref>]. Computational methods offer a cheaper and high-throughput alternative by predicting the bound complex structures of interacting proteins from the sequences and/or the unbound structures of individual protein chains. A closely related problem—and the one addressed in this study—is the prediction of the PPI sites, which are the interfacial residues of the interacting protein chains.</p>
    <p>Accurately predicting the interface of interacting proteins and the identification of the PPI sites remain challenging even after decades of research [<xref rid="pcbi.1011435.ref004" ref-type="bibr">4</xref>–<xref rid="pcbi.1011435.ref006" ref-type="bibr">6</xref>]. Various methods have been proposed, but with limited success. Partner-independent PPI site prediction [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>–<xref rid="pcbi.1011435.ref012" ref-type="bibr">12</xref>], which involves the prediction of putative interaction sites based only upon the surface of an isolated protein, without any knowledge of the partner or complex, is even more challenging compared to partner-aware PPI site prediction [<xref rid="pcbi.1011435.ref013" ref-type="bibr">13</xref>–<xref rid="pcbi.1011435.ref017" ref-type="bibr">17</xref>] due to the absence of any information about the partner protein and auxiliary information on the complex interfaces. In this work, we focus on partner-independent PPI site prediction.</p>
    <p>Predicting how proteins interact, and in particular, predicting the PPI sites, has a long history [<xref rid="pcbi.1011435.ref012" ref-type="bibr">12</xref>, <xref rid="pcbi.1011435.ref015" ref-type="bibr">15</xref>, <xref rid="pcbi.1011435.ref018" ref-type="bibr">18</xref>–<xref rid="pcbi.1011435.ref025" ref-type="bibr">25</xref>]. While initial models focused on feature engineering with machine learning [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>, <xref rid="pcbi.1011435.ref019" ref-type="bibr">19</xref>, <xref rid="pcbi.1011435.ref026" ref-type="bibr">26</xref>, <xref rid="pcbi.1011435.ref027" ref-type="bibr">27</xref>], subsequent work sought to capture more complex patterns using deep learning [<xref rid="pcbi.1011435.ref008" ref-type="bibr">8</xref>, <xref rid="pcbi.1011435.ref010" ref-type="bibr">10</xref>, <xref rid="pcbi.1011435.ref013" ref-type="bibr">13</xref>, <xref rid="pcbi.1011435.ref014" ref-type="bibr">14</xref>, <xref rid="pcbi.1011435.ref017" ref-type="bibr">17</xref>]. The vast majority of the existing methods rely on readily available protein sequence information, but their predictive accuracies are often quite limited [<xref rid="pcbi.1011435.ref028" ref-type="bibr">28</xref>]. Structure-based methods that integrate known structural information from the Protein Data Bank (PDB [<xref rid="pcbi.1011435.ref029" ref-type="bibr">29</xref>]) are usually more accurate. However, these approaches are limited by the paucity of experimentally solved protein structures in the PDB. In the 14th edition of the Critical Assessment of Structure Prediction (CASP14) experiment, AlphaFold2 [<xref rid="pcbi.1011435.ref030" ref-type="bibr">30</xref>] attained an unprecedented performance level, enabling highly accurate prediction of single-chain protein structural models at proteome-wide scale [<xref rid="pcbi.1011435.ref031" ref-type="bibr">31</xref>, <xref rid="pcbi.1011435.ref032" ref-type="bibr">32</xref>]. Given the recent progress, a natural question arises: can we leverage the predicted structural information by AlphaFold2 for accurate partner-independent PPI site prediction at scale?</p>
    <p>In the recent past, representation learning with graph structured data has been prevailing in different applications. In particular, graph neural networks (GNNs) have surged as the major choice for deep graph learning [<xref rid="pcbi.1011435.ref033" ref-type="bibr">33</xref>–<xref rid="pcbi.1011435.ref035" ref-type="bibr">35</xref>]. GNNs are permutation equivariant networks that operate on graph structured data, with numerous applications ranging from dynamical systems to conformational energy estimation [<xref rid="pcbi.1011435.ref036" ref-type="bibr">36</xref>, <xref rid="pcbi.1011435.ref037" ref-type="bibr">37</xref>]. However, off-the-shelf GNNs do not take into account symmetries naturally occurring in 3-dimensional space. That is, they ignore the effects of invariance and equivariance with respect to the E(3) symmetry group, i.e., the group of rotations, reflections, and translations in 3D space. The recent E(n) equivariant graph neural networks [<xref rid="pcbi.1011435.ref038" ref-type="bibr">38</xref>] address this problem by being translation, rotation, and reflection equivariant in 3D space that can be scaled to higher dimensional spaces (E(n)), while preserving permutation equivariance. SE(3) equivariant neural networks [<xref rid="pcbi.1011435.ref039" ref-type="bibr">39</xref>] are another recent graph-based models that can deal with the absolute coordinate systems in 3D space, but SE(3) equivariant models do not commute with reflections of the input. E(3) equivariant neural networks, on the other hand, transform equivariantly with translation, rotation and reflections, which make them suitable for molecular data where chirality of the molecules is often important, such as proteins, particularly when predicted protein structures are used as input that may contain mirror images. As such, E(3) equivariant graph neural networks offer an elegant choice for partner-independent PPI site prediction, where the input consists of a 3D structure of an isolated protein, known to be involved in PPIs, but where the structure of the partner or complex is not known. Being designed from geometric first-principles, symmetry-aware models such as E(3) equivariant graph neural networks are highly suitable for 3D molecular data, providing richer representation while avoiding expensive data augmentation strategies.</p>
    <p>The contribution of the present work is the introduction of a symmetry-aware PPI site prediction method, EquiPPIS, built on E(3) equivariant graph neural networks that yields state-of-the-art accuracy by substantially outperforming existing approaches based on the same experimental input. What is more striking is that EquiPPIS attains better accuracy with AlphaFold2-predicted structural models as input than what existing methods can achieve even with experimental input. We directly verify that the performance gains are connected to the unique E(3) equivariant architecture of EquiPPIS. The robustness and performance resilience of our method enable large-scale PPI site prediction without compromising on accuracy.</p>
  </sec>
  <sec sec-type="results" id="sec002">
    <title>Results</title>
    <p>Overview of the E(3) equivariant graph neural network architecture for protein–protein interaction site prediction</p>
    <p><bold><xref rid="pcbi.1011435.g001" ref-type="fig">Fig 1</xref></bold> illustrates our E(3) equivariant graph neural network model for partner-independent PPI site prediction. Different from the recent structure-aware graph learning approaches for PPI site prediction [<xref rid="pcbi.1011435.ref010" ref-type="bibr">10</xref>] that only exploit pairwise distances between all residue pairs (i.e., distance maps) as the spatial information, our E(3) equivariant graph neural network model directly leverages the C<sub>α</sub> coordinates extracted from the input monomer together with sequence- and structure-based node and edge features. By using an E(3) equivariant architecture, our symmetry-aware model can learn to preserve the known transformation properties of 3D coordinates under translation, rotation, and reflection, improving PPI site prediction. The EquiPPIS method consists of three major modules. The first module (<bold><xref rid="pcbi.1011435.g001" ref-type="fig">Fig 1A</xref></bold>) converts the input protein monomer into an undirected graph <inline-formula id="pcbi.1011435.e001"><alternatives><graphic xlink:href="pcbi.1011435.e001.jpg" id="pcbi.1011435.e001g" position="anchor"/><mml:math id="M1" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, with <inline-formula id="pcbi.1011435.e002"><alternatives><graphic xlink:href="pcbi.1011435.e002.jpg" id="pcbi.1011435.e002g" position="anchor"/><mml:math id="M2" display="inline" overflow="scroll"><mml:mi mathvariant="script">V</mml:mi></mml:math></alternatives></inline-formula> denoting the residues (nodes) and ℰ denoting the interaction between nonsequential residue pairs according to their pairwise spatial proximity (edges). The spatial proximity between nonsequential residue pairs (i.e., having sequence separation greater or equal to 6) is determined by calculating the Euclidean distances between the C<sub>α</sub> atom of all residue pairs and then setting a cutoff distance of 14Å to obtain the interacting pairs, determined through ablation experiments using an independent validation set. The sequence- and structure-based node and edge features (see the <xref rid="sec012" ref-type="sec">Methods</xref> section) are then fed into the second module together with the C<sub>α</sub> coordinates extracted from the input monomer. The second module (<bold><xref rid="pcbi.1011435.g001" ref-type="fig">Fig 1B</xref></bold>) is a deep E(3) equivariant graph neural network that conducts a series of transformations of its input through a stack of equivariant graph convolution layer (EGCL) [<xref rid="pcbi.1011435.ref038" ref-type="bibr">38</xref>], each updating the coordinate and node embeddings using the edge information and the coordinate and node embeddings from the previous layer. Finally, a sigmoidal function is applied to the last EGCL node embedding to predict the probability of every residue in the input monomer to be a PPI site, thereby converting the PPI site prediction into a graph node classification task (<bold><xref rid="pcbi.1011435.g001" ref-type="fig">Fig 1C</xref></bold>).</p>
    <fig position="float" id="pcbi.1011435.g001">
      <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.g001</object-id>
      <label>Fig 1</label>
      <caption>
        <title>Illustration of the EquiPPIS method for protein–protein interaction site prediction.</title>
        <p>(<bold>a</bold>) The input protein monomer is converted into an undirected graph. (<bold>b</bold>) Equivariant graph convolutions are then employed on the input graph. (<bold>c</bold>) PPI sites are finally predicted as a graph node classification task.</p>
      </caption>
      <graphic xlink:href="pcbi.1011435.g001" position="float"/>
    </fig>
    <sec id="sec003">
      <title>Experiments</title>
      <p>For training and performance evaluation, we use a combination of three widely used and publicly available benchmark datasets: Dset_186 [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>], Dset_72 [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>], and Dset_164 [<xref rid="pcbi.1011435.ref040" ref-type="bibr">40</xref>], named by the number of proteins in the datasets. We follow the same train and test splits from the recent PPI site prediction method GraphPPIS [<xref rid="pcbi.1011435.ref010" ref-type="bibr">10</xref>], which combines the aforementioned three datasets and subsequently removes redundancy, resulting in 335 targets as the training set (Train_335) and 60 targets as the test set (Test_60). Details of our training procedure are provided in the Methods section. We evaluate our proposed method on a diverse series of challenging test scenarios using standard performance evaluation metrics including accuracy, precision, recall, F1-score (F1), Matthews correlation coefficient (MCC), area under the receiver operating characteristic curve (ROC-AUC), and area under the precision-recall curve (PR-AUC). First, we demonstrate that EquiPPIS improves upon state-of-the-art accuracy on Test_60 dataset by comparing it directly against a wide variety of existing approaches including PSIVER [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>] (based on Naïve Bayes), ProNA2020 [<xref rid="pcbi.1011435.ref041" ref-type="bibr">41</xref>] (based on neural network), SCRIBER [<xref rid="pcbi.1011435.ref042" ref-type="bibr">42</xref>] (based on two layers of logistic regression), DLPred [<xref rid="pcbi.1011435.ref043" ref-type="bibr">43</xref>] (based on long short-term memory), DELPHI [<xref rid="pcbi.1011435.ref009" ref-type="bibr">9</xref>] (based on an ensemble of convolutional and recurrent neural networks), DeepPPISP [<xref rid="pcbi.1011435.ref008" ref-type="bibr">8</xref>] (based on convolutional neural network), SPPIDER [<xref rid="pcbi.1011435.ref011" ref-type="bibr">11</xref>] (based on support vector machine, neural network, and linear discriminant analysis), MaSIF-site [<xref rid="pcbi.1011435.ref044" ref-type="bibr">44</xref>] (based on geometric deep learning), and GraphPPIS (based on deep graph convolutional network). Among the competing methods, PSIVER, ProNA2020, SCRIBER, DLPred, and DELPHI are purely sequence-based methods; whereas DeepPPIS, SPPIDER, MaSIF-site, GraphPPIS, and our new method EquiPPIS additionally integrate structural information. Next, we examine the reasons for such high performance attained by EquiPPIS and verify that it is indeed connected to the equivariant nature of the model used. To broaden the applicability of our method beyond predicting PPI sites based only on experimentally-solved input monomers extracted from the bound complex structures, we explore a number of extensions including using unbound experimental structures and computationally predicted structural models as input. Specifically, using a subset of 31 proteins from the Test_60 dataset with known unbound monomeric structures in the PDB as an additional unbound test set (hereafter called UBtest_31), we show that EquiPPIS exhibits remarkable robustness and performance resilience compared to the existing approaches. Furthermore, by replacing the experimental input monomers with AlphaFold2 predicted structural models for the Test_60 dataset, we demonstrate that EquiPPIS attains state-of-the-art accuracy, which is better than what the top performing competing method can achieve even with experimental structures. The superior performance of EquiPPIS even when using predicted structural models as input dramatically enhances the scalability of partner-independent PPI site prediction without compromising on accuracy. Finally, we examine the relative importance of each feature we adopted by conducting feature ablation experiments using an independent validation set consisting of 42 targets (hereafter called Validation_42) collected from the Test_315 dataset of the published work of GraphPPIS after filtering out proteins with &gt;25% pairwise sequence identity with our test sets. We also use this validation set for hyperparameter selection.</p>
    </sec>
    <sec id="sec004">
      <title>Test set performance</title>
      <p>We compare EquiPPIS with five sequence-based (PSIVER, ProNA2020, SCRIBER, DLPred and DELPHI) and four structure-based (DeepPPISP, SPPIDER, MaSIF-site, and GraphPPIS) predictors on the Test_60 set. As shown in <bold><xref rid="pcbi.1011435.t001" ref-type="table">Table 1</xref></bold>, in addition to outperforming the sequence-based methods (PR-AUC ranging from 0.190 to 0.319) by a large margin, EquiPPIS significantly improves upon state-of-the-art accuracy by outperforming the structure-based methods. Remarkably, EquiPPIS is the only method attaining ROC-AUC of more than 0.8, which is noticeably better than the closest competing method GraphPPIS. Interestingly, the published work of GraphPPIS sets the goal of achieving ROC-AUC of 0.8 as a motivation for future work, while acknowledging it as one of the current impediments. In summary, EquiPPIS is a leap forward for partner independent PPI site prediction.</p>
      <table-wrap position="float" id="pcbi.1011435.t001">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>PPI site prediction performance on the Test_60 dataset for various methods.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1011435.t001" id="pcbi.1011435.t001g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" style="background-color:#F2F2F2" rowspan="1" colspan="1">Method</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Accuracy</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Precision</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Recall</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">F1</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">MCC</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">ROC-AUC</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">PR-AUC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">PSIVER</td>
                <td align="center" rowspan="1" colspan="1">0.561</td>
                <td align="center" rowspan="1" colspan="1">0.188</td>
                <td align="center" rowspan="1" colspan="1">0.534</td>
                <td align="center" rowspan="1" colspan="1">0.278</td>
                <td align="center" rowspan="1" colspan="1">0.074</td>
                <td align="center" rowspan="1" colspan="1">0.573</td>
                <td align="center" rowspan="1" colspan="1">0.190</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">ProNA2020</td>
                <td align="center" rowspan="1" colspan="1">0.738</td>
                <td align="center" rowspan="1" colspan="1">0.275</td>
                <td align="center" rowspan="1" colspan="1">0.402</td>
                <td align="center" rowspan="1" colspan="1">0.326</td>
                <td align="center" rowspan="1" colspan="1">0.176</td>
                <td align="center" rowspan="1" colspan="1">N/A</td>
                <td align="center" rowspan="1" colspan="1">N/A</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">SCRIBER</td>
                <td align="center" rowspan="1" colspan="1">0.667</td>
                <td align="center" rowspan="1" colspan="1">0.253</td>
                <td align="center" rowspan="1" colspan="1">0.568</td>
                <td align="center" rowspan="1" colspan="1">0.350</td>
                <td align="center" rowspan="1" colspan="1">0.193</td>
                <td align="center" rowspan="1" colspan="1">0.665</td>
                <td align="center" rowspan="1" colspan="1">0.278</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">DLPred</td>
                <td align="center" rowspan="1" colspan="1">0.682</td>
                <td align="center" rowspan="1" colspan="1">0.264</td>
                <td align="center" rowspan="1" colspan="1">0.565</td>
                <td align="center" rowspan="1" colspan="1">0.360</td>
                <td align="center" rowspan="1" colspan="1">0.208</td>
                <td align="center" rowspan="1" colspan="1">0.677</td>
                <td align="center" rowspan="1" colspan="1">0.294</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">DELPHI</td>
                <td align="center" rowspan="1" colspan="1">0.697</td>
                <td align="center" rowspan="1" colspan="1">0.276</td>
                <td align="center" rowspan="1" colspan="1">0.568</td>
                <td align="center" rowspan="1" colspan="1">0.372</td>
                <td align="center" rowspan="1" colspan="1">0.225</td>
                <td align="center" rowspan="1" colspan="1">0.699</td>
                <td align="center" rowspan="1" colspan="1">0.319</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">DeepPPISP</td>
                <td align="center" rowspan="1" colspan="1">0.657</td>
                <td align="center" rowspan="1" colspan="1">0.243</td>
                <td align="center" rowspan="1" colspan="1">0.539</td>
                <td align="center" rowspan="1" colspan="1">0.335</td>
                <td align="center" rowspan="1" colspan="1">0.167</td>
                <td align="center" rowspan="1" colspan="1">0.653</td>
                <td align="center" rowspan="1" colspan="1">0.276</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">SPPIDER</td>
                <td align="center" rowspan="1" colspan="1">0.752</td>
                <td align="center" rowspan="1" colspan="1">0.331</td>
                <td align="center" rowspan="1" colspan="1">0.557</td>
                <td align="center" rowspan="1" colspan="1">0.415</td>
                <td align="center" rowspan="1" colspan="1">0.285</td>
                <td align="center" rowspan="1" colspan="1">0.755</td>
                <td align="center" rowspan="1" colspan="1">0.373</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">MaSIF-site</td>
                <td align="center" rowspan="1" colspan="1">0.780</td>
                <td align="center" rowspan="1" colspan="1">0.370</td>
                <td align="center" rowspan="1" colspan="1">0.561</td>
                <td align="center" rowspan="1" colspan="1">0.446</td>
                <td align="center" rowspan="1" colspan="1">0.326</td>
                <td align="center" rowspan="1" colspan="1">0.775</td>
                <td align="center" rowspan="1" colspan="1">0.439</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraphPPIS</td>
                <td align="center" rowspan="1" colspan="1">0.776</td>
                <td align="center" rowspan="1" colspan="1">0.368</td>
                <td align="center" rowspan="1" colspan="1">0.584</td>
                <td align="center" rowspan="1" colspan="1">0.451</td>
                <td align="center" rowspan="1" colspan="1">0.333</td>
                <td align="center" rowspan="1" colspan="1">0.786</td>
                <td align="center" rowspan="1" colspan="1">0.429</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">EquiPPIS</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.787</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.389</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.615</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.477</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.366</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.805</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.467</bold>
                </td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t001fn001">
            <p>Note: Except EquiPPS, results for the other methods are obtained directly from the published work of GraphPPIS; values in bold represent the best performance.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p><bold><xref rid="pcbi.1011435.g002" ref-type="fig">Fig 2</xref></bold> presents two representative examples from the Test_60 dataset comparing the PPI site predictions using EquiPPIS and GraphPPIS. For the first example of a sugar binding protein of Trichosanthes kirilowii (PDB ID: 1GGP, chain A) having length 234 (<bold><xref rid="pcbi.1011435.g002" ref-type="fig">Fig 2A</xref></bold>), EquiPPIS correctly predicts majority of the observed PPI sites, attaining Precision, Recall, F1, and MCC of 0.8, 0.545, 0.649, and 0.601, respectively; whereas GraphPPIS fails to predict any correct PPI sites with Precision, Recall, F1 and MCC of 0, 0, 0, -0.185, respectively. The second example is a Hydrolase inhibitor of Triticum aestivum in complex with Bacillus subtilis (PDB ID: 2B42, chain A) having length 364 (<bold><xref rid="pcbi.1011435.g002" ref-type="fig">Fig 2B</xref></bold>), where GraphPPIS predicts many false positive PPI sites, resulting in low Precision, Recall, F1 and MCC of 0.105, 0.231, 0.144, and -0.004, respectively. EquiPPIS on the other hand attains reasonably accurate predictive performance having Precision, Recall, F1, and MCC of 0.595, 0.564, 0.579, and 0.53, respectively. In both cases, EquiPPIS predictions are strikingly similar to the experimentally observed PPI sites.</p>
      <fig position="float" id="pcbi.1011435.g002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>GraphPPIS and EquiPPIS predictions compared to the experimental observation.</title>
          <p>(<bold>a</bold>) Sugar binding protein of Trichosanthes kirilowii. (<bold>b</bold>) Hydrolase inhibitor of Triticum aestivum in complex with Bacillus subtilis. The regions highlighted in green represent PPI sites.</p>
        </caption>
        <graphic xlink:href="pcbi.1011435.g002" position="float"/>
      </fig>
    </sec>
    <sec id="sec005">
      <title>Analyzing the importance of equivariance</title>
      <p>In the above experiments, EquiPPIS exhibits significantly improved performance. In order to gain insight into the reasons behind such high performance and verify that it is connected to the equivariant nature of the model, we perform a series of experiments by gradually isolating the effect of the equivariant graph convolutions used in EquiPPIS. In particular, we train several baseline models and compare them head-to-head with the full-fledged version of EquiPPIS. First, we train a baseline network by turning off the coordinate updates of the equivariant graph convolution layers, thus making it an invariant network (hereafter called ‘EquiPPIS invariant’). Since the full-fledged version of EquiPPIS employs attention operations for aggregated embedding as part of the equivariant message passing, we train another baseline network where attention operation is turned off during equivariant message passing, resulting in an equivariant network but without attention (hereafter called ‘EquiPPIS w/o attention’). Additionally, we train two off-the-shelf GNNs for PPI site prediction: graph convolution network (GCN) [<xref rid="pcbi.1011435.ref035" ref-type="bibr">35</xref>] and graph attention network (GAT) [<xref rid="pcbi.1011435.ref045" ref-type="bibr">45</xref>]. All baseline networks are trained on the same Train_335 dataset using the same set of input features and hyperparameters as the full-fledged version of EquiPPIS (see the <xref rid="sec012" ref-type="sec">Methods</xref> section). <bold><xref rid="pcbi.1011435.g003" ref-type="fig">Fig 3A to 3D</xref></bold> show the performance of EquiPPIS compared to the baseline networks on the Test_60 set. The results demonstrate that the full-fledged version of EquiPPIS outperforms all baseline models. For example, we observe that the full-fledged version of EquiPPIS attains an ROC-AUC of more than 0.8, which is the best accuracy compared to all baseline models. The ‘EquiPPIS invariant’ baseline, however, falls short of achieving an ROC-AUC of 0.8, suggesting that it is the equivariant nature of EquiPPIS that is responsible for the accuracy gain. Turning off the attention operation as done in the ‘EquiPPIS w/o attention’ baseline leads to an accuracy decline (an ROC-AUC of 0.8) compared to the full-fledged version of EquiPPIS, but still better than the invariant network. That is, attention operation during equivariant message passing contributes to an improvement in accuracy. It is worth noting that despite the accuracy drop from the full-fledged version of EquiPPIS, both ‘EquiPPIS invariant’ and ‘EquiPPIS w/o attention’ baselines outperform GraphPPIS. On the other hand, off-the-shelf GCN- and GAT-based baselines exhibit much lower accuracies compared to GraphPPIS, let alone EquiPPIS. Overall, the results underscore the importance of equivariance in particular and symmetry-aware nature of the new EquiPPIS model in general for improved predictive accuracy.</p>
      <fig position="float" id="pcbi.1011435.g003">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <p>Performance analysis on Test_60 set (<bold>a</bold>-<bold>d</bold>) and on UBtest_31 set (<bold>e</bold>-<bold>f</bold>). (<bold>a</bold>) MCC, (<bold>b</bold>) ROC-AUC, (<bold>c</bold>) F1, and (<bold>d</bold>) PR-AUC of EquiPPIS on Test_60 set compared to the baseline models ‘EquiPPIS invariant’, ‘EquiPPIS w/o attention’, graph convolution network (GCN), and graph attention network (GAT). (<bold>e</bold>) MCC and (<bold>f</bold>) PR-AUC of EquiPPIS on UBtest_31 set compared to other structure- based methods GraphPPIS, MaSIF-site, SPPIDER, and DeepPPISP.</p>
        </caption>
        <graphic xlink:href="pcbi.1011435.g003" position="float"/>
      </fig>
      <p>In addition to prediction accuracy, robustness of model is another key aspect to consider. While experimentally-solved bound complex structures are used during EquiPPIS training, protein–protein binding often leads to conformational changes by “induced fit” mechanism (binding first) or “conformational selection” (conformational change first) [<xref rid="pcbi.1011435.ref046" ref-type="bibr">46</xref>]. To evaluate the robustness of EquiPPIS and the effect of conformational changes, we examine the impact on the accuracy when unbound structures are used during prediction instead of their bound states for EquiPPIS as well as the other structure-based PPI site predictors (DeepPPISP, SPPIDER, MaSIF-site, and GraphPPIS) using the unbound test set (UBtest_31) of 31 proteins. As shown in <bold><xref rid="pcbi.1011435.g003" ref-type="fig">Fig 3E and 3F</xref></bold>, EquiPPIS outperforms all other methods by a large margin, while having the least impact on accuracy when unbound structures are used during prediction. For example, the closest competing methods MaSIF-site and GraphPPIS suffer from significant accuracy drop both in terms of MCC (35%, and 14.6% drop, respectively) and PR-AUC (24.7%, and 18.2% drop, respectively), whereas EquiPPIS experiences only 4.6%, and 5.5% drop in MCC and PR-AUC, respectively. What is most striking is that the accuracy gap between EquiPPIS and the competing methods is so large that EquiPPIS using unbound structures attains much better accuracy even when the competing methods are using the bound structures. That is, EquiPPIS exhibits remarkable robustness and performance resilience compared to existing approaches.</p>
    </sec>
    <sec id="sec006">
      <title>Beyond experimental input: state-of-the-art performance with AlphaFold2</title>
      <p>EquiPPIS achieves state-of-the-art accuracy with experimental structures as input in both bound and unbound states. A natural question to ask is can we achieve similar predictive accuracy when computationally predicted structural models are used as input instead of experimental structures? Given the exceptional performance of AlphaFold2 in the CASP14 experiment and the open availability of the AlphaFold2 protocol, it is now possible to predict single-chain protein structural models from the amino acid sequence with high degree of accuracy. In principle, a robust method such as EquiPPIS should be able to generalize when predicted structural models are used without significant drop in accuracy, thereby broadening its applicability beyond experimental input. Motivated by the prospect, we examine the impact on the accuracy by replacing the experimental input with AlphaFold2 predicted structural models for the Test_60 dataset. <bold><xref rid="pcbi.1011435.t002" ref-type="table">Table 2</xref></bold> shows the performance of EquiPPIS compared to the closest competing method GraphPPIS. Remarkably, EquiPPIS using AlphaFold2-predicted structural models attains better accuracy (PR-AUC = 0.451) than GraphPPIS using experimental structures (PR-AUC = 0.429), let alone GraphPPIS using predicted structural models (PR-AUC = 0.399). While there is a performance decline for both methods when switching from experimental input to prediction, the performance drop for EquiPPIS is lower (ΔPR-AUC = 0.016) than that of GraphPPIS (ΔPR-AUC = 0.03). The results demonstrate the generalizability of EquiPPIS, thus opening the possibility of large-scale PPI site prediction by utilizing high-throughput computational prediction without compromising on accuracy.</p>
      <table-wrap position="float" id="pcbi.1011435.t002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Performance comparison between EquiPPIS and GraphPPIS with experimental input and AlphaFold2 predicted structural models for the Test_60 dataset.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1011435.t002" id="pcbi.1011435.t002g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Method</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Input type</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Accuracy</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Precision</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Recall</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">F1</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">MCC</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">ROC-AUC</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">PR-AUC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="2" colspan="1">EquiPPIS</td>
                <td align="center" rowspan="1" colspan="1">Experimental</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.787</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.389</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.615</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.477</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.366</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.805</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.467</bold>
                </td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">AlphaFold2</td>
                <td align="center" rowspan="1" colspan="1">0.780</td>
                <td align="center" rowspan="1" colspan="1">0.379</td>
                <td align="center" rowspan="1" colspan="1">0.615</td>
                <td align="center" rowspan="1" colspan="1">0.469</td>
                <td align="center" rowspan="1" colspan="1">0.356</td>
                <td align="center" rowspan="1" colspan="1">0.795</td>
                <td align="center" rowspan="1" colspan="1">0.451</td>
              </tr>
              <tr>
                <td align="center" rowspan="2" colspan="1">GraphPPIS</td>
                <td align="center" rowspan="1" colspan="1">Experimental<xref rid="t002fn001" ref-type="table-fn">*</xref></td>
                <td align="center" rowspan="1" colspan="1">0.776</td>
                <td align="center" rowspan="1" colspan="1">0.368</td>
                <td align="center" rowspan="1" colspan="1">0.584</td>
                <td align="center" rowspan="1" colspan="1">0.451</td>
                <td align="center" rowspan="1" colspan="1">0.333</td>
                <td align="center" rowspan="1" colspan="1">0.786</td>
                <td align="center" rowspan="1" colspan="1">0.429</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">AlphaFold2</td>
                <td align="center" rowspan="1" colspan="1">0.767</td>
                <td align="center" rowspan="1" colspan="1">0.357</td>
                <td align="center" rowspan="1" colspan="1">0.590</td>
                <td align="center" rowspan="1" colspan="1">0.445</td>
                <td align="center" rowspan="1" colspan="1">0.324</td>
                <td align="center" rowspan="1" colspan="1">0.772</td>
                <td align="center" rowspan="1" colspan="1">0.399</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t002fn001">
            <p>* Results obtained directly from the published work of GraphPPIS; values in bold represent the best performance.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="sec007">
      <title>Significance test</title>
      <p>To investigate if our performance improvement is significant or due to chance, we perform significance tests, following the procedures of previous studies [<xref rid="pcbi.1011435.ref047" ref-type="bibr">47</xref>–<xref rid="pcbi.1011435.ref049" ref-type="bibr">49</xref>]. Specifically, we randomly sample 70% of the test set (Test_60), and calculate the F1, MCC, ROC-AUC, and PR-AUC scores of EquiPPIS and the closest competing method GraphPPIS with both experimental and AlphaFold2 predicted structures, where the same structures are used as inputs to both the prediction methods. We repeat this 10 times and obtain 10 pairs of scores. If the measurement is normal, which is determined through Anderson-Darling test [<xref rid="pcbi.1011435.ref050" ref-type="bibr">50</xref>], then paired t-test is used to calculate significance of the measurement. If the measurement is not normal, then we use Wilcoxon rank sum test [<xref rid="pcbi.1011435.ref051" ref-type="bibr">51</xref>]. As reported in <bold><xref rid="pcbi.1011435.t003" ref-type="table">Table 3</xref>,</bold> EquiPPIS is statistically significantly better than GraphPPIS on both experimental and predicted structures at 95% confidence level with p-values &lt; 0.05 for all four metrics.</p>
      <table-wrap position="float" id="pcbi.1011435.t003">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.t003</object-id>
        <label>Table 3</label>
        <caption>
          <title>Significance test between EquiPPIS and GraphPPIS using experimental and AlphaFold2 predicted structures.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1011435.t003" id="pcbi.1011435.t003g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" style="background-color:#F2F2F2" rowspan="1" colspan="1">Input type</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Method</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">F1</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">MCC</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">ROC-AUC</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">PR-AUC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="3" colspan="1"><break/>Experimental</td>
                <td align="center" rowspan="1" colspan="1">EquiPPIS</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.4793</bold><break/>±<break/>0.000302678</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.3664</bold><break/>±<break/>0.000287822</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.8032</bold><break/>±<break/>9.50667E-05</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.4684</bold><break/>±<break/>0.000536933</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">GraphPPIS</td>
                <td align="center" rowspan="1" colspan="1">0.4539<break/>±<break/>0.0004801</td>
                <td align="center" rowspan="1" colspan="1">0.3334<break/>±<break/>0.000352489</td>
                <td align="center" rowspan="1" colspan="1">0.7818<break/>±<break/>0.000117733</td>
                <td align="center" rowspan="1" colspan="1">0.4395<break/>±<break/>0.000764056</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <italic toggle="yes">p-value</italic>
                </td>
                <td align="center" rowspan="1" colspan="1">3.18683E-05</td>
                <td align="center" rowspan="1" colspan="1">2.41981E-05</td>
                <td align="center" rowspan="1" colspan="1">3.97085E-05</td>
                <td align="center" rowspan="1" colspan="1">0.000373678</td>
              </tr>
              <tr>
                <td align="left" rowspan="3" colspan="1"><break/>AlphaFold2</td>
                <td align="center" rowspan="1" colspan="1">EquiPPIS</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.4712</bold><break/>±<break/>0.000345067</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.356</bold><break/>±<break/>0.000401778</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.7912</bold><break/>±<break/>0.000189733</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.4516</bold><break/>±<break/>0.0008396</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">GraphPPIS</td>
                <td align="center" rowspan="1" colspan="1">0.4434<break/>±<break/>0.000515378</td>
                <td align="center" rowspan="1" colspan="1">0.3199<break/>±<break/>0.000447433</td>
                <td align="center" rowspan="1" colspan="1">0.7667<break/>±<break/>0.000159567</td>
                <td align="center" rowspan="1" colspan="1">0.3956<break/>±<break/>0.0007036</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <italic toggle="yes">p-value</italic>
                </td>
                <td align="center" rowspan="1" colspan="1">7.71066E-06</td>
                <td align="center" rowspan="1" colspan="1">0.002827272</td>
                <td align="center" rowspan="1" colspan="1">0.001939728</td>
                <td align="center" rowspan="1" colspan="1">9.92622E-08</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t003fn001">
            <p>* For all four metrics, the two numbers reported are mean and variance respectively; values in bold represent the best performance in terms of mean.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="sec008">
      <title>Impact of secondary structure content on prediction accuracy</title>
      <p>To examine the impact of physical characteristics of the input structures on the prediction accuracy of EquiPPIS, we analyze the secondary structure content of the proteins for the Test_60 set. The targets are divided into three groups: (1) helices (referred to as ’Primarily helix’), (2) beta strands (referred to as ’Primarily beta’), and (3) mixture of helices and beta strands (referred to as ’Mix’). We calculate the ROC-AUC scores for each group and compare them with the results obtained from the full set. <bold><xref rid="pcbi.1011435.s001" ref-type="supplementary-material">S1 Fig</xref></bold> presents a comparison of our prediction accuracy in terms of ROC-AUC scores across the groups with different physical characteristics based on secondary structure. EquiPPIS achieves a higher ROC-AUC of 0.855 in the ’Primarily helix’ group compared to the full set’s ROC-AUC of 0.805. However, in the ’Primarily beta’ group, EquiPPIS attains a somewhat lower ROC-AUC of 0.783. As for the ’Mix’ group, EquiPPIS achieves the ROC-AUC of 0.799, which is comparable to that obtained on the full set. The results demonstrate that secondary structure content has a minor impact on the prediction accuracy with primarily helical proteins yielding the best performance, whereas there is still room for improvement for the proteins that are primarily made of beta strands.</p>
    </sec>
    <sec id="sec009">
      <title>Running time analysis</title>
      <p>We analyze the running time of EquiPPIS and the closest competing method GraphPPIS for all targets in the Test_60 set on the same Linux machine with identical hardware environment. <bold><xref rid="pcbi.1011435.g004" ref-type="fig">Fig 4</xref></bold> presents a target-wise running time comparison between EquiPPIS and GraphPPIS. Not surprisingly, free from time-consuming MSA-searching, EquiPPIS demonstrates noticeably lower running time compared to GraphPPIS. Overall, EquiPPIS is considerably efficient in terms of the running time.</p>
      <fig position="float" id="pcbi.1011435.g004">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>The running time of EquiPPIS and GraphPPIS on Test_60 set.</title>
          <p>For each target, input protein length versus runtime (in seconds) of EquiPPIS (blue) and GraphPPIS (red) are shown.</p>
        </caption>
        <graphic xlink:href="pcbi.1011435.g004" position="float"/>
      </fig>
    </sec>
    <sec id="sec010">
      <title>Ablation studies and choice of hyperparameters</title>
      <p>To examine the relative importance of the features adopted in EquiPPIS, we conduct feature ablation experiments by gradually isolating the contribution of individual feature or groups of features during model training and evaluating the accuracy on the independent validation set Validation_42. <bold><xref rid="pcbi.1011435.g005" ref-type="fig">Fig 5A</xref></bold> shows the accuracy decline measured in terms of ΔPR-AUC and ΔROC-AUC when various features are isolated from the full-fledged version of EquiPPIS. The results demonstrate that all features contribute to the overall accuracy achieved by EquiPPIS. For example, we notice accuracy decline when we isolate the sequence-based features one by one including amino acid residue type (No AA), position specific scoring matrix (No PSSM), and protein language model ESM2 (No ESM2). Not surprisingly, the evolutionarily feature PSSM and protein language model-based ESM2 feature contribute more than just the residue type features. We notice a significant performance drop when all three sequence-based features are isolated (No seq). Similarly, we notice consistent accuracy decline when we discard the structure-based features individually including secondary structure (No ss), relative solvent accessibility (No rsa), local geometry (No local geom), residue orientation (No orient), contact count (No contact count) as well as relative residue positioning and residue virtual surface area (No res pos + area). Because we use multi-level discretization of secondary structure (e.g., 3-state and 8-state) and relative solvent accessibility (e.g., 2-state and 8-state) as well as backbone torsion angles, which are closely related to the secondary structure, we conduct feature ablation experiments by discarding the 8-state secondary structure, 8- state relative solvent accessibility, and backbone torsion angles. The resulting model (No multi-level) shows accuracy decline compared to the full-fledged version of EquiPPIS, indicating the effectiveness of combining multi-granular information. Finally, we also notice an accuracy drop when we isolate the edge feature (No edge) that takes into account the contributions of sequence separation and spatial interaction.</p>
      <fig position="float" id="pcbi.1011435.g005">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <title>Ablation studies and hyperparameter selection.</title>
          <p>(<bold>a</bold>) Validation set accuracy decline after feature ablation. Dark and light blue bars indicate the PR-AUC decline (ΔPR-AUC) and the ROC-AUC decline (ΔROC-AUC), respectively. Validation set accuracy in terms of MCC and F1 for various choices of hyperparameters including (<bold>b</bold>, <bold>c</bold>) distance cutoff, (<bold>d</bold>, <bold>e</bold>) number of layers, and (<bold>f</bold>, <bold>g</bold>) hidden dimension. The selected hyperparameters yielding the best accuracy are highlighted in darker shade.</p>
        </caption>
        <graphic xlink:href="pcbi.1011435.g005" position="float"/>
      </fig>
      <p>We also use the Validation_42 set to select the hyperparameters. Based on the results of the grid search as shown in <bold><xref rid="pcbi.1011435.g005" ref-type="fig">Fig 5B to 5G</xref></bold>, we select a 10-layer EGCL framework with 256 hidden units and the cutoff distance used to obtain the interacting residue pairs is set to 14Å. We use the hyperparameters selected in the independent validation set during training and testing.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec011">
    <title>Discussion</title>
    <p>This work introduces EquiPPIS, a symmetry-aware deep graph learning model for protein–protein interaction site prediction based on E(3) equivariant graph neural networks. We demonstrate that EquiPPIS outperforms existing methods and despite being trained on experimental structures, it generalizes extremely well to predicted structural models from AlphaFold2 to the extent that EquiPPIS attains better accuracy with predicted structural models than what existing approaches can achieve even with experimental structures. Through controlled experiments, we verify the importance of equivariance as one of the major driving forces behind the improved performance. In addition to questions around the effect of equivariance on accuracy, our ablation study on an independent validation set confirms the contribution of various features adopted in EquiPPIS. Our study leads to a series of interesting questions to consider: of particular interest is the possibility of broadening the applicability of our method beyond experimental input for large-scale PPI site predictions with high accuracy by utilizing rapid computational prediction. In this regard, considering the diversity of the predictive modeling ensemble and accounting for the conformational states of the interacting proteins having multi-state conformational dynamics may help broaden the horizon of computational PPI site prediction. Further, a promising direction for future work is to investigate the potential benefits of explicitly including multiple sequence alignment (MSA) information and measure the extent to which it may influence the accuracy. While an MSA-free method such as EquiPPIS offers some unique advantages by being broadly applicable even for proteins that do not have homologous sequences in the current sequence databases and bypasses the computational overhead of MSA searching, MSA may still provide a rich source of additional information for further improving the accuracy of PPI site prediction that might be worth exploring. Finally, while we find that EquiPPIS exhibits excellent predictive accuracy and remarkable robustness, an open challenge that remains is the interpretability of our deep learning model. The evolutionary and functional significance of the residues predicted to be in PPI site by means of the latent representation underlying the neural architecture of EquiPPIS still need to be systematically explored. We expect our proposed method can be easily extended to other biomolecular interaction site prediction tasks, including predicting protein-binding sites with other molecules, such as DNA, RNA and small ligands, as well as predicting gene-gene interaction and gene-networks with improved accuracy and robustness.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec012">
    <title>Materials and Methods</title>
    <p>Graph representation and featurization.</p>
    <sec id="sec013">
      <title>Graph representation</title>
      <p>We represent the input protein monomer as a graph <inline-formula id="pcbi.1011435.e003"><alternatives><graphic xlink:href="pcbi.1011435.e003.jpg" id="pcbi.1011435.e003g" position="anchor"/><mml:math id="M3" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, in which a node <inline-formula id="pcbi.1011435.e004"><alternatives><graphic xlink:href="pcbi.1011435.e004.jpg" id="pcbi.1011435.e004g" position="anchor"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">V</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> represents a residue and an edge <italic toggle="yes">e</italic>∈ ℰ represents an interacting residue pair. We consider two residues to be interacting if their C<sub>α</sub> Euclidean distance is no more than 14Å. The cutoff 14Å is chosen on an independent validation set as presented in <bold><xref rid="pcbi.1011435.g005" ref-type="fig">Fig 5</xref></bold>. To focus on longer-rage interactions, we only consider interacting residue pairs having a minimum sequence separation of 6.</p>
    </sec>
    <sec id="sec014">
      <title>Node features</title>
      <p>We use three types of sequence-based node features: (1) one-hot encoding of the residue (i.e., a binary vector of 20 entries indicating its amino acid type), resulting in L×20 feature set, where L is the length of the input monomer; (2) position specific scoring matrix (PSSM) obtained by running PSI-BLAST [<xref rid="pcbi.1011435.ref052" ref-type="bibr">52</xref>] to obtain L×20 feature set by considering the first 20 columns from the PSSM and normalizing the values by applying a sigmoidal function; and (3) features from ESM2 [<xref rid="pcbi.1011435.ref053" ref-type="bibr">53</xref>], which is a recent protein language model trained on 15 billion parameters, leading to L×33 feature set, after normalizing the values using sigmoidal function.</p>
      <p>Additionally, we extract a total of L×45 structure-based node features from the structure of the input monomer by either calculating various structural information directly from the 3D coordinates or by running the DSSP [<xref rid="pcbi.1011435.ref054" ref-type="bibr">54</xref>] program. We describe them below.</p>
      <sec id="sec015">
        <title>Secondary structure and relative solvent accessibility</title>
        <p>We use one-hot encoding of both 3-state and 8-state secondary structures (SS), leading to L×3 and L×8 feature sets, respectively. Additionally, we use one-hot encoding of 2-state relative solvent accessibility (RSA) by adopting an RSA cutoff of 50 (L×2 feature set), and use finer-grained RSA binning by discretizing into 8 bins as 0–30, 30–60, 60–90, 90–120, 120–150, 150–180, 180–210, and &gt;210, represented by one-hot encoding (L×8 feature set). The rationale of using multiple discretization of SS (e.g., 3-state and 8-state) and RSA (e.g., 2-state and 8-state) is to combine multi-level information, and ablation studies guiding these decisions are presented in <bold><xref rid="pcbi.1011435.g005" ref-type="fig">Fig 5</xref></bold>.</p>
      </sec>
      <sec id="sec016">
        <title>Local geometry</title>
        <p>We use a total of L×11 feature set from the local geometries by calculating various planar and torsion angles of the polypeptide chain, including (1) the cosine angle between the consecutive residues of the C = O bond; (2) sine and cosine of the virtual bond and torsion angles formed between the consecutive C<sub>α</sub> atoms; (3) normalized values of the backbone torsion angles.</p>
      </sec>
      <sec id="sec017">
        <title>Relative residue positioning</title>
        <p>To capture the relative positional information for each residue, we extract two types of features: (1) for i<sup>th</sup> residue, we use the inverse of i to capture the relative sequence position (L×1 feature set); and (2) we use the inverse of the Euclidean distance from the centroid of the input protein monomer to the C<sub>α</sub> atom of the i<sup>th</sup> residue to capture the spatial positioning of a residue relative to the overall structure (L×1 feature set).</p>
      </sec>
      <sec id="sec018">
        <title>Residue orientation</title>
        <p>To define the orientation of each amino acid residue, we adopted features from a recent work [<xref rid="pcbi.1011435.ref055" ref-type="bibr">55</xref>] including (1) the forward and reverse unit vectors in the directions of C<sub>α</sub><sup>(i+1)</sup> − C<sub>α</sub><sup>i</sup> and C<sub>α</sub><sup>(i−1)</sup> − C<sub>α</sub><sup>i</sup>, respectively (L×6 feature set); and (2) the unit vector in the imputed direction of C<sub>β</sub><sup>i</sup> − C<sub>α</sub><sup>i</sup>, computed by assuming tetrahedral geometries and normalization (L×3 feature set).</p>
      </sec>
      <sec id="sec019">
        <title>Residue virtual surface area</title>
        <p>An amino acid residue can be perceived as a virtual convex hull constructed by its atoms. We calculate the virtual surface area of the convex hull and use its inverse as a feature (L×1 feature set).</p>
      </sec>
      <sec id="sec020">
        <title>Contact count</title>
        <p>If the Euclidean distance between the C<sub>β</sub> atoms of a residue pair is within a cutoff of 8Å, the two residues can be considered to be in contact. We calculate the contact-count by calculating the number of spatial neighbors of a given residue (i.e., residues which are in contact) and use the normalized number of contact count per residue as a feature (L×1 feature set).</p>
        <p>The sequence-based amino acid (L×20 feature set), PSSM (L×20 feature set), and ESM2 (L×33 feature set) features are concatenated with the structure-based node features (L×45 feature set), leading to a total of L×118 features, which serves as an input to our E(3) equivariant graph neural network model (<bold><xref rid="pcbi.1011435.s002" ref-type="supplementary-material">S2 Fig</xref></bold>).</p>
      </sec>
    </sec>
    <sec id="sec021">
      <title>Edge features</title>
      <p>As the edge feature for the graph <inline-formula id="pcbi.1011435.e005"><alternatives><graphic xlink:href="pcbi.1011435.e005.jpg" id="pcbi.1011435.e005g" position="anchor"/><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, we calculate the ratio of the logarithmic sequential separation of two residues (i.e., logarithm of the absolute difference between the two residue indices) corresponding to two nodes in the graph and the Euclidean distance between them, defined as:
<disp-formula id="pcbi.1011435.e006"><alternatives><graphic xlink:href="pcbi.1011435.e006.jpg" id="pcbi.1011435.e006g" position="anchor"/><mml:math id="M6" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">log</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
Here, the numerator captures how the two residues are separated in the primary sequence while the denominator captures their spatial interactions.</p>
    </sec>
    <sec id="sec022">
      <title>Network architecture</title>
      <p>We formulate the PPI site prediction into a graph node classification task and predict the probability of every residue in the input monomer to be a PPI site using a deep E(3) equivariant graph neural network. The network architecture consists of a stack of equivariant graph convolution layer (EGCL) [<xref rid="pcbi.1011435.ref038" ref-type="bibr">38</xref>], performing a series of transformations of its input by updating the coordinate and node embeddings using the edge information and the coordinate and node embeddings from the previous layer. The EGCL operation attains equivariance primarily by changing the standard message passing (<inline-formula id="pcbi.1011435.e007"><alternatives><graphic xlink:href="pcbi.1011435.e007.jpg" id="pcbi.1011435.e007g" position="anchor"/><mml:math id="M7" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> [<xref rid="pcbi.1011435.ref056" ref-type="bibr">56</xref>] to equivariant message passing and by introducing coordinate updates in the graph neural network, as follows:
<disp-formula id="pcbi.1011435.e008"><alternatives><graphic xlink:href="pcbi.1011435.e008.jpg" id="pcbi.1011435.e008g" position="anchor"/><mml:math id="M8" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e009"><alternatives><graphic xlink:href="pcbi.1011435.e009.jpg" id="pcbi.1011435.e009g" position="anchor"/><mml:math id="M9" display="block" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi><mml:mo>≠</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives></disp-formula>
where <bold><italic toggle="yes">a</italic></bold><sub><bold><italic toggle="yes">ij</italic></bold></sub> denotes edge features; <inline-formula id="pcbi.1011435.e010"><alternatives><graphic xlink:href="pcbi.1011435.e010.jpg" id="pcbi.1011435.e010g" position="anchor"/><mml:math id="M10" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1011435.e011"><alternatives><graphic xlink:href="pcbi.1011435.e011.jpg" id="pcbi.1011435.e011g" position="anchor"/><mml:math id="M11" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> are node embeddings at layer <bold><italic toggle="yes">l</italic></bold> for nodes <bold><italic toggle="yes">i</italic></bold> and <bold><italic toggle="yes">j</italic></bold>, respectively; <bold><italic toggle="yes">ϕ</italic></bold><sub><bold><italic toggle="yes">e</italic></bold></sub>, <bold><italic toggle="yes">ϕ</italic></bold><sub><bold><italic toggle="yes">h</italic></bold></sub>, and <bold><italic toggle="yes">ϕ</italic></bold><sub><bold><italic toggle="yes">x</italic></bold></sub> are multilayer perceptrons (MLP) for edge, node, and coordinate operations, respectively. Equivariant message passing for an edge (<bold><italic toggle="yes">i</italic>, <italic toggle="yes">j</italic></bold>) is attained by considering the squared distance between node <bold><italic toggle="yes">i</italic></bold> and <bold><italic toggle="yes">j</italic></bold>: <inline-formula id="pcbi.1011435.e012"><alternatives><graphic xlink:href="pcbi.1011435.e012.jpg" id="pcbi.1011435.e012g" position="anchor"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> in the edge operation. The coordinate update for node <bold><italic toggle="yes">i</italic></bold> is obtained by the weighted sum of coordinate embedding difference from the previous layer, normalizing with a factor <bold><italic toggle="yes">C</italic></bold> = 1/(<bold><italic toggle="yes">M</italic></bold>−1), where <bold><italic toggle="yes">M</italic></bold> is the number of nodes in the graph. The weights for the sum are generated through the multilayer perceptron (MLP) of coordinate operation applied on the equivariant message passing (<bold><italic toggle="yes">m</italic></bold><sub><bold><italic toggle="yes">ij</italic></bold></sub>) for each edge (<bold><italic toggle="yes">i</italic></bold>, <bold><italic toggle="yes">j</italic></bold>).</p>
      <p>Unlike off-the-shelf graph neural networks that aggregate messages only from the neighboring nodes, equivariant graph neural networks aggregate messages from the whole graph. Additionally, an attention embedding (<bold><italic toggle="yes">m</italic></bold><sub><bold><italic toggle="yes">a</italic></bold></sub>) can be employed through an attention operation (<bold><italic toggle="yes">ϕ</italic></bold><sub><bold><italic toggle="yes">a</italic></bold></sub>), which is a linear transformation on the aggregated message embedding (<bold><italic toggle="yes">m</italic></bold><sub><bold><italic toggle="yes">i</italic></bold></sub>), followed by a sigmoidal non-linear transformation. The ‘attended’ aggregated message embedding is subsequently obtained through a scalar multiplication with the attention embedding. The node embedding is updated by applying an MLP (<bold><italic toggle="yes">ϕ</italic></bold><sub><bold><italic toggle="yes">h</italic></bold></sub>) on the aggregated message and the node embeddings of the previous layer, as follows:
<disp-formula id="pcbi.1011435.e013"><alternatives><graphic xlink:href="pcbi.1011435.e013.jpg" id="pcbi.1011435.e013g" position="anchor"/><mml:math id="M13" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi><mml:mo>≠</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e014"><alternatives><graphic xlink:href="pcbi.1011435.e014.jpg" id="pcbi.1011435.e014g" position="anchor"/><mml:math id="M14" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>×</mml:mo><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e015"><alternatives><graphic xlink:href="pcbi.1011435.e015.jpg" id="pcbi.1011435.e015g" position="anchor"/><mml:math id="M15" display="block" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives></disp-formula>
Finally, A linear transformation (<bold><italic toggle="yes">ϕ</italic></bold><sub>0</sub>) is applied to squeeze the hidden dimension (<inline-formula id="pcbi.1011435.e016"><alternatives><graphic xlink:href="pcbi.1011435.e016.jpg" id="pcbi.1011435.e016g" position="anchor"/><mml:math id="M16" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">L</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) of the last EGCL, followed by a sigmoidal function to obtain the node-level classification (<bold><italic toggle="yes">p</italic></bold><sub><italic toggle="yes">i</italic></sub>) for PPI site prediction:
<disp-formula id="pcbi.1011435.e017"><alternatives><graphic xlink:href="pcbi.1011435.e017.jpg" id="pcbi.1011435.e017g" position="anchor"/><mml:math id="M17" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">L</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e018"><alternatives><graphic xlink:href="pcbi.1011435.e018.jpg" id="pcbi.1011435.e018g" position="anchor"/><mml:math id="M18" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
The network architecture of EquiPPIS consists of 10 layers of EGCL with a hidden dimension of 256, where the hyperparameters are chosen on an independent validation set, and empirical results guiding these decisions are presented in <bold><xref rid="pcbi.1011435.g005" ref-type="fig">Fig 5</xref></bold>. EquiPPIS is implemented on Pytorch 1.12.0 [<xref rid="pcbi.1011435.ref057" ref-type="bibr">57</xref>] and Deep Graph Library (DGL) 0.9.0 [<xref rid="pcbi.1011435.ref058" ref-type="bibr">58</xref>]. We use binary cross entropy loss function between the node-level prediction and the ground truth, and we utilize cosine annealing scheduler from SGDR [<xref rid="pcbi.1011435.ref059" ref-type="bibr">59</xref>], ADAM optimizer [<xref rid="pcbi.1011435.ref060" ref-type="bibr">60</xref>] with a learning rate of 1e-4, and weight decay of 1e-16. The training process consists of at most 50 epochs on an NVIDIA A40 GPU. In addition to the full-fledged version of EquiPPIS, we train several baseline models on the same Train_335 dataset using the same set of input features and hyperparameters including off-the-shelf graph convolution network (GCN) [<xref rid="pcbi.1011435.ref035" ref-type="bibr">35</xref>] and graph attention network (GAT) [<xref rid="pcbi.1011435.ref045" ref-type="bibr">45</xref>], both implemented using the DGL [<xref rid="pcbi.1011435.ref058" ref-type="bibr">58</xref>], as well as two variants of EquiPPIS: (1) ‘EquiPPIS invariant’, an invariant network with the coordinate updates of the equivariant graph convolution layers turned off; and (2) ‘EquiPPIS w/o attention’, an equivariant network with the attention operation turned off during equivariant message passing.</p>
    </sec>
    <sec id="sec023">
      <title>Datasets, benchmarking, and performance evaluation</title>
      <p>We use a combination of three widely used and publicly available benchmark datasets: Dset_186 [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>], Dset_72 [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>], and Dset_164 [<xref rid="pcbi.1011435.ref040" ref-type="bibr">40</xref>]. Dset_72 is created based on protein-protein benchmark version 3.0 [<xref rid="pcbi.1011435.ref061" ref-type="bibr">61</xref>], Dset_186 is constructed through a six-step filtering process which involves the exclusion of structures containing over 30% missing residues, identical UniprotKB/Swiss-Prot accessions, interface polarity and buried surface accessibility below specific thresholds, as well as oligomeric structures, transmembrane, and redundant protein structures, where 186 targets are collected from known protein complexes, and Dset_164 consists of 164 targets obtained from known heterodimers. While Dset_186, Dset_72, and Dset_164 are non-redundant data sets independently, the combined dataset is further reduced to 395 targets by filtering out redundant chains among the datasets. Following the same train-test split as GraphPPIS [<xref rid="pcbi.1011435.ref010" ref-type="bibr">10</xref>], we use a train set (Train_335) having 10,374 and 55,992 interacting and noninteracting residues, respectively; and a test set (Test_60) having 2,075 and 11,069 interacting and noninteracting residues, respectively. In the Train_335 set, the average length of protein is ~198 residues ranging from 44 to 869 residues. In the Test_60 set, the average length of protein is ~219 residues ranging from 52 to 766 residues, with no homodimeric protein-protein interaction present within this set. To assess the robustness of EquiPPIS and examine the effect of conformational changes on its performance, we analyze a subset of 31 proteins from the Test_60 set with known unbound monomeric conformations. This additional unbound test set (UBtest_31) having 841 and 5813 interacting and non-interacting residues, respectively, is adopted from the published work on GraphPPIS. Additionally, we adopt a dataset named Test_315 from the published work on GraphPPIS consisting of newly solved protein complexes that are non-redundant to the train set. We filter out 42 targets from the Test_315 set by discarding protein chains having more than 25% pairwise sequence identity with our test set and create an independent validation set (Validation_42) to perform feature ablation and hyperparameter selection.</p>
      <p>During prediction, we use both experimentally-solved structures as well as on AlphaFold2-predicted structural models as input. We run AlphaFold2 with default parameter settings by locally installing the officially released version [<xref rid="pcbi.1011435.ref030" ref-type="bibr">30</xref>] to generate five predicted structural models and then select the model with the highest pLDDT confidence score. For target 4cdgA that failed during the MSA generation stage of the AlphaFold2 pipeline, we run Colabfold [<xref rid="pcbi.1011435.ref062" ref-type="bibr">62</xref>] that uses MMSeqs2 [<xref rid="pcbi.1011435.ref063" ref-type="bibr">63</xref>] for MSA generation and subsequently employs AlphaFold2 protocol for structure prediction.</p>
      <p>EquiPPIS is compared against both sequence-based (PSIVER [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>], ProNA2020 [<xref rid="pcbi.1011435.ref041" ref-type="bibr">41</xref>], SCRIBER [<xref rid="pcbi.1011435.ref042" ref-type="bibr">42</xref>], DLPred [<xref rid="pcbi.1011435.ref043" ref-type="bibr">43</xref>], and DELPHI [<xref rid="pcbi.1011435.ref009" ref-type="bibr">9</xref>]) and structure-aware (DeepPPIS [<xref rid="pcbi.1011435.ref008" ref-type="bibr">8</xref>], SPPIDER [<xref rid="pcbi.1011435.ref011" ref-type="bibr">11</xref>], MaSIF-site [<xref rid="pcbi.1011435.ref044" ref-type="bibr">44</xref>], and GraphPPIS [<xref rid="pcbi.1011435.ref010" ref-type="bibr">10</xref>]) PPI site prediction methods. PSIVER employs a Naïve Bayes classifier along with kernel density estimation by utilizing sequence-based features. ProNA2020 combines homology modeling with a neural network for residue-level PPI site prediction. SCRIBER employs two layers of logistic regression, where the first layer utilizes sequence-based features while the second layer combines the output from the first layer for the final prediction. DLPred employs a simplified long-short-term memory model for PPI site prediction. DELPHI uses an ensemble of convolutional and recurrent neural networks architectures with a large feature set. DeepPPISP combines local contextual features with global features and employs convolutional neural networks to predict PPI sites. SPPIDER leverages support vector machine, neural network, and linear discriminant analysis with an extensive feature search and extraction process. MaSIF-site predicts PPI sites by learning protein structural fingerprints through geometric deep learning. GraphPPIS employs structure-aware deep residual neural networks for PPI site prediction.</p>
      <p>For benchmarking and performance assessment, we use standard performance evaluation metrics including accuracy, precision, recall, F1-score (F1), and Matthews correlation coefficient (MCC), defined as:
<disp-formula id="pcbi.1011435.e019"><alternatives><graphic xlink:href="pcbi.1011435.e019.jpg" id="pcbi.1011435.e019g" position="anchor"/><mml:math id="M19" display="block" overflow="scroll"><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e020"><alternatives><graphic xlink:href="pcbi.1011435.e020.jpg" id="pcbi.1011435.e020g" position="anchor"/><mml:math id="M20" display="block" overflow="scroll"><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e021"><alternatives><graphic xlink:href="pcbi.1011435.e021.jpg" id="pcbi.1011435.e021g" position="anchor"/><mml:math id="M21" display="block" overflow="scroll"><mml:mi mathvariant="bold-italic">R</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e022"><alternatives><graphic xlink:href="pcbi.1011435.e022.jpg" id="pcbi.1011435.e022g" position="anchor"/><mml:math id="M22" display="block" overflow="scroll"><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="bold-italic">R</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">R</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e023"><alternatives><graphic xlink:href="pcbi.1011435.e023.jpg" id="pcbi.1011435.e023g" position="anchor"/><mml:math id="M23" display="block" overflow="scroll"><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:msqrt></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
where, TP denotes the number of true PPI site residues that are correctly predicted, FP denotes the number of non-PPI site residues that are incorrectly predicted to be in PPI sites, TN denotes the number of non-PPI site residues that are correctly predicted, and FN denotes the number of PPI site residues that are incorrectly predicted as non-PPI site. We additionally use area under the receiver operating characteristic curve (ROC-AUC) and area under the precision-recall curve (PR-AUC) for performance evaluation.</p>
    </sec>
  </sec>
  <sec id="sec024" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pcbi.1011435.s001" position="float" content-type="local-data">
      <label>S1 Fig</label>
      <caption>
        <title>Impact of secondary structure content on prediction accuracy.</title>
        <p>ROC-AUC scores achieved by EquiPPIS grouped by secondary structure content (’Primarily helix’, ’Primarily beta’, and ’Mix’) as well as the overall ROC-AUC (’All’) in the Test_60 set.</p>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pcbi.1011435.s001.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011435.s002" position="float" content-type="local-data">
      <label>S2 Fig</label>
      <caption>
        <title>Input node feature generation.</title>
        <p>The sequence-based amino acid (L×20 feature set), PSSM (L×20 feature set), and ESM2 (L×33 feature set) features are concatenated with the structure-based node features (L×45 feature set), leading to a total of L×118 features, which serves as an input to the E(3) equivariant graph neural networks.</p>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pcbi.1011435.s002.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1011435.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Jones</surname><given-names>S</given-names></name>, <name><surname>Thornton</surname><given-names>JM</given-names></name>. <article-title>Principles of protein-protein interactions</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>1996</year>;<volume>93</volume>(<issue>1</issue>):<fpage>13</fpage>–<lpage>20</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.93.1.13</pub-id><?supplied-pmid 8552589?><pub-id pub-id-type="pmid">8552589</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Sharan</surname><given-names>R</given-names></name>, <name><surname>Suthram</surname><given-names>S</given-names></name>, <name><surname>Kelley</surname><given-names>RM</given-names></name>, <name><surname>Kuhn</surname><given-names>T</given-names></name>, <name><surname>McCuine</surname><given-names>S</given-names></name>, <name><surname>Uetz</surname><given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Conserved patterns of protein interaction in multiple species</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2005</year>;<volume>102</volume>(<issue>6</issue>):<fpage>1974</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.0409522102</pub-id><?supplied-pmid 15687504?><pub-id pub-id-type="pmid">15687504</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Shoemaker</surname><given-names>BA</given-names></name>, <name><surname>Panchenko</surname><given-names>AR</given-names></name>. <article-title>Deciphering protein–protein interactions</article-title>. <source>Part I. Experimental techniques and databases. PLoS computational biology</source>. <year>2007</year>;<volume>3</volume>(<issue>3</issue>):<fpage>e42</fpage>.<pub-id pub-id-type="pmid">17397251</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Keskin</surname><given-names>O</given-names></name>, <name><surname>Gursoy</surname><given-names>A</given-names></name>, <name><surname>Ma</surname><given-names>B</given-names></name>, <name><surname>Nussinov</surname><given-names>R</given-names></name>. <article-title>Principles of protein− protein interactions: what are the preferred ways for proteins to interact?</article-title><source>Chemical reviews</source>. <year>2008</year>;<volume>108</volume>(<issue>4</issue>):<fpage>1225</fpage>–<lpage>44</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1021/cr040409x</pub-id><?supplied-pmid 18355092?><pub-id pub-id-type="pmid">18355092</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Nooren</surname><given-names>IM</given-names></name>, <name><surname>Thornton</surname><given-names>JM</given-names></name>. <article-title>Diversity of protein–protein interactions</article-title>. <source>The EMBO journal</source>. <year>2003</year>;<volume>22</volume>(<issue>14</issue>):<fpage>3486</fpage>–<lpage>92</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/emboj/cdg359</pub-id><?supplied-pmid 12853464?><pub-id pub-id-type="pmid">12853464</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Chatrabgoun</surname><given-names>O</given-names></name>, <name><surname>Daneshkhah</surname><given-names>A</given-names></name>, <name><surname>Esmaeilbeigi</surname><given-names>M</given-names></name>, <name><surname>Safa</surname><given-names>NS</given-names></name>, <name><surname>Alenezi</surname><given-names>AH</given-names></name>, <name><surname>Rahman</surname><given-names>A</given-names></name>. <article-title>Predicting Primary Sequence-Based Protein-Protein Interactions Using a Mercer Series Representation of Nonlinear Support Vector Machine.</article-title><source>IEEE Access.</source><year>2022</year>;<volume>10</volume>:<fpage>124345</fpage>–<lpage>54</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Murakami</surname><given-names>Y</given-names></name>, <name><surname>Mizuguchi</surname><given-names>K</given-names></name>. <article-title>Applying the Naïve Bayes classifier with kernel density estimation to the prediction of protein–protein interaction sites</article-title>. <source>Bioinformatics</source>. <year>2010</year>;<volume>26</volume>(<issue>15</issue>):<fpage>1841</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">20529890</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Zeng</surname><given-names>M</given-names></name>, <name><surname>Zhang</surname><given-names>F</given-names></name>, <name><surname>Wu</surname><given-names>F-X</given-names></name>, <name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Wang</surname><given-names>J</given-names></name>, <name><surname>Li</surname><given-names>M</given-names></name>. <article-title>Protein–protein interaction site prediction through combining local and global features with deep neural networks</article-title>. <source>Bioinformatics</source>. <year>2020</year>;<volume>36</volume>(<issue>4</issue>):<fpage>1114</fpage>–<lpage>20</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz699</pub-id><?supplied-pmid 31593229?><pub-id pub-id-type="pmid">31593229</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Golding</surname><given-names>GB</given-names></name>, <name><surname>Ilie</surname><given-names>L</given-names></name>. <article-title>DELPHI: accurate deep ensemble model for protein interaction sites prediction</article-title>. <source>Bioinformatics</source>. <year>2021</year>;<volume>37</volume>(<issue>7</issue>):<fpage>896</fpage>–<lpage>904</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btaa750</pub-id><?supplied-pmid 32840562?><pub-id pub-id-type="pmid">32840562</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Yuan</surname><given-names>Q</given-names></name>, <name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Zhao</surname><given-names>H</given-names></name>, <name><surname>Zhou</surname><given-names>Y</given-names></name>, <name><surname>Yang</surname><given-names>Y</given-names></name>. <article-title>Structure-aware protein–protein interaction site prediction using deep graph convolutional network</article-title>. <source>Bioinformatics</source>. <year>2022</year>;<volume>38</volume>(<issue>1</issue>):<fpage>125</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Porollo</surname><given-names>A</given-names></name>, <name><surname>Meller</surname><given-names>J</given-names></name>. <article-title>Prediction-based fingerprints of protein–protein interactions.</article-title><source>Proteins: Structure, Function, and Bioinformatics.</source><year>2007</year>;<volume>66</volume>(<issue>3</issue>):<fpage>630</fpage>–<lpage>45</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/prot.21248</pub-id><?supplied-pmid 17152079?><pub-id pub-id-type="pmid">17152079</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>M-H</given-names></name>, <name><surname>Lin</surname><given-names>L</given-names></name>, <name><surname>Wang</surname><given-names>X-L</given-names></name>, <name><surname>Liu</surname><given-names>T</given-names></name>. <article-title>Protein–protein interaction site prediction based on conditional random fields</article-title>. <source>Bioinformatics</source>. <year>2007</year>;<volume>23</volume>(<issue>5</issue>):<fpage>597</fpage>–<lpage>604</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btl660</pub-id><?supplied-pmid 17234636?><pub-id pub-id-type="pmid">17234636</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Fout</surname><given-names>A</given-names></name>, <name><surname>Byrd</surname><given-names>J</given-names></name>, <name><surname>Shariat</surname><given-names>B</given-names></name>, <name><surname>Ben-Hur</surname><given-names>A</given-names></name>. <article-title>Protein interface prediction using graph convolutional networks</article-title>. <source>Advances in neural information processing systems</source>. <year>2017</year>;<fpage>30</fpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Townshend</surname><given-names>R</given-names></name>, <name><surname>Bedi</surname><given-names>R</given-names></name>, <name><surname>Suriana</surname><given-names>P</given-names></name>, <name><surname>Dror</surname><given-names>R</given-names></name>. <article-title>End-to-end learning on 3d protein structure for interface prediction</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2019</year>;<fpage>32</fpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Afsar Minhas FuA</surname><given-names>Geiss BJ</given-names></name>, <article-title>Ben-Hur A. PAIRpred: partner-specific prediction of interacting residues from sequence and structure.</article-title><source>Proteins: Structure, Function, and Bioinformatics.</source><year>2014</year>;<volume>82</volume>(<issue>7</issue>):<fpage>1142</fpage>–<lpage>55</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Sanchez-Garcia</surname><given-names>R</given-names></name>, <name><surname>Sorzano</surname><given-names>COS</given-names></name>, <name><surname>Carazo</surname><given-names>JM</given-names></name>, <name><surname>Segura</surname><given-names>J</given-names></name>. <article-title>BIPSPI: a method for the prediction of partner-specific protein–protein interfaces</article-title>. <source>Bioinformatics</source>. <year>2019</year>;<volume>35</volume>(<issue>3</issue>):<fpage>470</fpage>–<lpage>7</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/bty647</pub-id><?supplied-pmid 30020406?><pub-id pub-id-type="pmid">30020406</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Dai</surname><given-names>B</given-names></name>, <name><surname>Bailey-Kellogg</surname><given-names>C</given-names></name>. <article-title>Protein interaction interface region prediction by geometric deep learning</article-title>. <source>Bioinformatics</source>. <year>2021</year>;<volume>37</volume>(<issue>17</issue>):<fpage>2580</fpage>–<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btab154</pub-id><?supplied-pmid 33693581?><pub-id pub-id-type="pmid">33693581</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>N</given-names></name>, <name><surname>Sun</surname><given-names>Z</given-names></name>, <name><surname>Jiang</surname><given-names>F</given-names></name>. <article-title>Prediction of protein-protein binding site by using core interface residue and support vector machine</article-title>. <source>BMC bioinformatics</source>. <year>2008</year>;<volume>9</volume>:<fpage>1</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">18173834</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Northey</surname><given-names>TC</given-names></name>, <name><surname>Barešić</surname><given-names>A</given-names></name>, <name><surname>Martin</surname><given-names>AC</given-names></name>. <article-title>IntPred: a structure-based predictor of protein–protein interaction sites</article-title>. <source>Bioinformatics</source>. <year>2018</year>;<volume>34</volume>(<issue>2</issue>):<fpage>223</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btx585</pub-id><?supplied-pmid 28968673?><pub-id pub-id-type="pmid">28968673</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Hou</surname><given-names>Q</given-names></name>, <name><surname>De Geest</surname><given-names>PF</given-names></name>, <name><surname>Vranken</surname><given-names>WF</given-names></name>, <name><surname>Heringa</surname><given-names>J</given-names></name>, <name><surname>Feenstra</surname><given-names>KA</given-names></name>. <article-title>Seeing the trees through the forest: sequence-based homo-and heteromeric protein-protein interaction sites prediction using random forest</article-title>. <source>Bioinformatics</source>. <year>2017</year>;<volume>33</volume>(<issue>10</issue>):<fpage>1479</fpage>–<lpage>87</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btx005</pub-id><?supplied-pmid 28073761?><pub-id pub-id-type="pmid">28073761</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Sriwastava</surname><given-names>BK</given-names></name>, <name><surname>Basu</surname><given-names>S</given-names></name>, <name><surname>Maulik</surname><given-names>U</given-names></name>. <article-title>Protein–protein interaction site prediction in Homo sapiens and E. coli using an interaction-affinity based membership function in fuzzy SVM</article-title>. <source>Journal of biosciences</source>. <year>2015</year>;<volume>40</volume>:<fpage>809</fpage>–<lpage>18</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s12038-015-9564-y</pub-id><?supplied-pmid 26564981?><pub-id pub-id-type="pmid">26564981</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>X</given-names></name>, <name><surname>Chen</surname><given-names>Xw</given-names></name>. <article-title>Heterogeneous data integration by tree-augmented naïve B ayes for protein–protein interactions prediction</article-title>. <source>Proteomics</source>. <year>2013</year>;<volume>13</volume>(<issue>2</issue>):<fpage>261</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">23112070</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Fariselli</surname><given-names>P</given-names></name>, <name><surname>Pazos</surname><given-names>F</given-names></name>, <name><surname>Valencia</surname><given-names>A</given-names></name>, <name><surname>Casadio</surname><given-names>R</given-names></name>. <article-title>Prediction of protein–protein interaction sites in heterocomplexes with neural networks</article-title>. <source>European Journal of Biochemistry</source>. <year>2002</year>;<volume>269</volume>(<issue>5</issue>):<fpage>1356</fpage>–<lpage>61</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1046/j.1432-1033.2002.02767.x</pub-id><?supplied-pmid 11874449?><pub-id pub-id-type="pmid">11874449</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>H</given-names></name>, <name><surname>Zhou</surname><given-names>HX</given-names></name>. <article-title>Prediction of interface residues in protein–protein complexes by a consensus neural network method: test against NMR data.</article-title><source>Proteins: Structure, Function, and Bioinformatics.</source><year>2005</year>;<volume>61</volume>(<issue>1</issue>):<fpage>21</fpage>–<lpage>35</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/prot.20514</pub-id><?supplied-pmid 16080151?><pub-id pub-id-type="pmid">16080151</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Liang</surname><given-names>S</given-names></name>, <name><surname>Zhang</surname><given-names>C</given-names></name>, <name><surname>Liu</surname><given-names>S</given-names></name>, <name><surname>Zhou</surname><given-names>Y</given-names></name>. <article-title>Protein binding site prediction using an empirical scoring function</article-title>. <source>Nucleic acids research</source>. <year>2006</year>;<volume>34</volume>(<issue>13</issue>):<fpage>3698</fpage>–<lpage>707</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkl454</pub-id><?supplied-pmid 16893954?><pub-id pub-id-type="pmid">16893954</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Deng</surname><given-names>A</given-names></name>, <name><surname>Zhang</surname><given-names>H</given-names></name>, <name><surname>Wang</surname><given-names>W</given-names></name>, <name><surname>Zhang</surname><given-names>J</given-names></name>, <name><surname>Fan</surname><given-names>D</given-names></name>, <name><surname>Chen</surname><given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Developing computational model to predict protein-protein interaction sites based on the XGBoost algorithm</article-title>. <source>International journal of molecular sciences</source>. <year>2020</year>;<volume>21</volume>(<issue>7</issue>):<fpage>2274</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/ijms21072274</pub-id><?supplied-pmid 32218345?><pub-id pub-id-type="pmid">32218345</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>Z-S</given-names></name>, <name><surname>Han</surname><given-names>K</given-names></name>, <name><surname>Yang</surname><given-names>J-Y</given-names></name>, <name><surname>Shen</surname><given-names>H-B</given-names></name>, <name><surname>Yu</surname><given-names>D-J</given-names></name>. <article-title>Protein–protein interaction sites prediction by ensembling SVM and sample-weighted random forests.</article-title><source>Neurocomputing</source>. <year>2016</year>;<volume>193</volume>:<fpage>201</fpage>–<lpage>12</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>J</given-names></name>, <name><surname>Kurgan</surname><given-names>L</given-names></name>. <article-title>Review and comparative assessment of sequence-based predictors of protein-binding residues</article-title>. <source>Briefings in bioinformatics</source>. <year>2018</year>;<volume>19</volume>(<issue>5</issue>):<fpage>821</fpage>–<lpage>37</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/bbx022</pub-id><?supplied-pmid 28334258?><pub-id pub-id-type="pmid">28334258</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Berman</surname><given-names>HM</given-names></name>, <name><surname>Westbrook</surname><given-names>J</given-names></name>, <name><surname>Feng</surname><given-names>Z</given-names></name>, <name><surname>Gilliland</surname><given-names>G</given-names></name>, <name><surname>Bhat</surname><given-names>TN</given-names></name>, <name><surname>Weissig</surname><given-names>H</given-names></name>, <etal>et al</etal>. <article-title>The protein data bank</article-title>. <source>Nucleic acids research</source>. <year>2000</year>;<volume>28</volume>(<issue>1</issue>):<fpage>235</fpage>–<lpage>42</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/28.1.235</pub-id><?supplied-pmid 10592235?><pub-id pub-id-type="pmid">10592235</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Jumper</surname><given-names>J</given-names></name>, <name><surname>Evans</surname><given-names>R</given-names></name>, <name><surname>Pritzel</surname><given-names>A</given-names></name>, <name><surname>Green</surname><given-names>T</given-names></name>, <name><surname>Figurnov</surname><given-names>M</given-names></name>, <name><surname>Ronneberger</surname><given-names>O</given-names></name>, <etal>et al</etal>. <article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source>Nature</source>. <year>2021</year>;<volume>596</volume>(<issue>7873</issue>):<fpage>583</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41586-021-03819-2</pub-id><?supplied-pmid 34265844?><pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Tunyasuvunakool</surname><given-names>K</given-names></name>, <name><surname>Adler</surname><given-names>J</given-names></name>, <name><surname>Wu</surname><given-names>Z</given-names></name>, <name><surname>Green</surname><given-names>T</given-names></name>, <name><surname>Zielinski</surname><given-names>M</given-names></name>, <name><surname>Žídek</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Highly accurate protein structure prediction for the human proteome</article-title>. <source>Nature</source>. <year>2021</year>;<volume>596</volume>(<issue>7873</issue>):<fpage>590</fpage>–<lpage>6</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41586-021-03828-1</pub-id><?supplied-pmid 34293799?><pub-id pub-id-type="pmid">34293799</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Varadi</surname><given-names>M</given-names></name>, <name><surname>Anyango</surname><given-names>S</given-names></name>, <name><surname>Deshpande</surname><given-names>M</given-names></name>, <name><surname>Nair</surname><given-names>S</given-names></name>, <name><surname>Natassia</surname><given-names>C</given-names></name>, <name><surname>Yordanova</surname><given-names>G</given-names></name>, <etal>et al</etal>. <article-title>AlphaFold Protein Structure Database: massively expanding the structural coverage of protein-sequence space with high-accuracy models</article-title>. <source>Nucleic Acids Research</source>. <year>2022</year>;<volume>50</volume>(<issue>D1</issue>):<fpage>D439</fpage>–<lpage>D44</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkab1061</pub-id><?supplied-pmid 34791371?><pub-id pub-id-type="pmid">34791371</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Bruna</surname><given-names>J</given-names></name>, <name><surname>Zaremba</surname><given-names>W</given-names></name>, <name><surname>Szlam</surname><given-names>A</given-names></name>, <name><surname>LeCun</surname><given-names>Y</given-names></name>. <article-title>Spectral networks and locally connected networks on graphs.</article-title><source>arXiv preprint arXiv:13126203.</source><year>2013</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Defferrard</surname><given-names>M</given-names></name>, <name><surname>Bresson</surname><given-names>X</given-names></name>, <name><surname>Vandergheynst</surname><given-names>P</given-names></name>. <article-title>Convolutional neural networks on graphs with fast localized spectral filtering</article-title>. <source>Advances in neural information processing systems</source>. <year>2016</year>;<fpage>29</fpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Kipf</surname><given-names>TN</given-names></name>, <name><surname>Welling</surname><given-names>M</given-names></name>. <article-title>Semi-supervised classification with graph convolutional networks.</article-title><source>arXiv preprint arXiv:160902907.</source><year>2016</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Weiler</surname><given-names>M</given-names></name>, <name><surname>Cesa</surname><given-names>G</given-names></name>. <article-title>General e (2)-equivariant steerable cnns.</article-title><source>Advances in Neural Information Processing Systems</source>. <year>2019</year>;<fpage>32</fpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Rezende</surname><given-names>DJ</given-names></name>, <name><surname>Racanière</surname><given-names>S</given-names></name>, <name><surname>Higgins</surname><given-names>I</given-names></name>, <name><surname>Toth</surname><given-names>P</given-names></name>. <article-title>Equivariant hamiltonian flows.</article-title><source>arXiv preprint arXiv:190913739</source>. <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref038">
      <label>38</label>
      <mixed-citation publication-type="journal"><name><surname>Satorras</surname><given-names>VcG</given-names></name>, <name><surname>Hoogeboom</surname><given-names>E</given-names></name>, <name><surname>Welling</surname><given-names>M</given-names></name>. <article-title>E(n) Equivariant Graph Neural Networks.</article-title> In: <name><surname>Marina</surname><given-names>M</given-names></name>, <name><surname>Tong</surname><given-names>Z</given-names></name>, editors. Proceedings of the 38th <source>International Conference on Machine Learning; Proceedings of Machine Learning Research: PMLR</source>; <year>2021</year>. p. <fpage>9323</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Thomas</surname><given-names>N</given-names></name>, <name><surname>Smidt</surname><given-names>T</given-names></name>, <name><surname>Kearnes</surname><given-names>S</given-names></name>, <name><surname>Yang</surname><given-names>L</given-names></name>, <name><surname>Li</surname><given-names>L</given-names></name>, <name><surname>Kohlhoff</surname><given-names>K</given-names></name>, <etal>et al</etal>. <article-title>Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds.</article-title><source>arXiv preprint arXiv:180208219.</source><year>2018</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>Dhole</surname><given-names>K</given-names></name>, <name><surname>Singh</surname><given-names>G</given-names></name>, <name><surname>Pai</surname><given-names>PP</given-names></name>, <name><surname>Mondal</surname><given-names>S</given-names></name>. <article-title>Sequence-based prediction of protein–protein interaction sites with L1-logreg classifier</article-title>. <source>Journal of Theoretical Biology</source>. <year>2014</year>;<volume>348</volume>:<fpage>47</fpage>–<lpage>54</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jtbi.2014.01.028</pub-id><?supplied-pmid 24486250?><pub-id pub-id-type="pmid">24486250</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Qiu</surname><given-names>J</given-names></name>, <name><surname>Bernhofer</surname><given-names>M</given-names></name>, <name><surname>Heinzinger</surname><given-names>M</given-names></name>, <name><surname>Kemper</surname><given-names>S</given-names></name>, <name><surname>Norambuena</surname><given-names>T</given-names></name>, <name><surname>Melo</surname><given-names>F</given-names></name>, <etal>et al</etal>. <article-title>ProNA2020 predicts protein–DNA, protein–RNA, and protein–protein binding proteins and residues from sequence</article-title>. <source>Journal of Molecular Biology</source>. <year>2020</year>;<volume>432</volume>(<issue>7</issue>):<fpage>2428</fpage>–<lpage>43</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jmb.2020.02.026</pub-id><?supplied-pmid 32142788?><pub-id pub-id-type="pmid">32142788</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref042">
      <label>42</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>J</given-names></name>, <name><surname>Kurgan</surname><given-names>L</given-names></name>. <article-title>SCRIBER: accurate and partner type-specific prediction of protein-binding residues from proteins sequences</article-title>. <source>Bioinformatics</source>. <year>2019</year>;<volume>35</volume>(<issue>14</issue>):<fpage>i343</fpage>–<lpage>i53</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz324</pub-id><?supplied-pmid 31510679?><pub-id pub-id-type="pmid">31510679</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>B</given-names></name>, <name><surname>Li</surname><given-names>J</given-names></name>, <name><surname>Quan</surname><given-names>L</given-names></name>, <name><surname>Chen</surname><given-names>Y</given-names></name>, <name><surname>Lü</surname><given-names>Q</given-names></name>. <article-title>Sequence-based prediction of protein-protein interaction sites by simplified long short-term memory network.</article-title><source>Neurocomputing</source>. <year>2019</year>;<volume>357</volume>:<fpage>86</fpage>–<lpage>100</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neucom.2019.05.013</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref044">
      <label>44</label>
      <mixed-citation publication-type="journal"><name><surname>Gainza</surname><given-names>P</given-names></name>, <name><surname>Sverrisson</surname><given-names>F</given-names></name>, <name><surname>Monti</surname><given-names>F</given-names></name>, <name><surname>Rodolà</surname><given-names>E</given-names></name>, <name><surname>Boscaini</surname><given-names>D</given-names></name>, <name><surname>Bronstein</surname><given-names>MM</given-names></name>, <etal>et al</etal>. <article-title>Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning</article-title>. <source>Nature Methods</source>. <year>2020</year>;<volume>17</volume>(<issue>2</issue>):<fpage>184</fpage>–<lpage>92</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41592-019-0666-6</pub-id><?supplied-pmid 31819266?><pub-id pub-id-type="pmid">31819266</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref045">
      <label>45</label>
      <mixed-citation publication-type="journal"><name><surname>Veličković</surname><given-names>P</given-names></name>, <name><surname>Cucurull</surname><given-names>G</given-names></name>, <name><surname>Casanova</surname><given-names>A</given-names></name>, <name><surname>Romero</surname><given-names>A</given-names></name>, <name><surname>Lio</surname><given-names>P</given-names></name>, <name><surname>Bengio</surname><given-names>Y</given-names></name>. <article-title>Graph attention networks.</article-title><source>arXiv preprint arXiv:171010903</source>. <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref046">
      <label>46</label>
      <mixed-citation publication-type="journal"><name><surname>Hammes</surname><given-names>GG</given-names></name>, <name><surname>Chang</surname><given-names>Y-C</given-names></name>, <name><surname>Oas</surname><given-names>TG</given-names></name>. <article-title>Conformational selection or induced fit: A flux description of reaction mechanism</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2009</year>;<volume>106</volume>(<issue>33</issue>):<fpage>13737</fpage>–<lpage>41</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.0907195106</pub-id><?supplied-pmid 19666553?><pub-id pub-id-type="pmid">19666553</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref047">
      <label>47</label>
      <mixed-citation publication-type="journal"><name><surname>Peng</surname><given-names>Z</given-names></name>, <name><surname>Kurgan</surname><given-names>L</given-names></name>. <article-title>High-throughput prediction of RNA, DNA and protein binding regions mediated by intrinsic disorder</article-title>. <source>Nucleic acids research</source>. <year>2015</year>;<volume>43</volume>(<issue>18</issue>):<fpage>e121</fpage>–<lpage>e</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkv585</pub-id><?supplied-pmid 26109352?><pub-id pub-id-type="pmid">26109352</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref048">
      <label>48</label>
      <mixed-citation publication-type="journal"><name><surname>Xia</surname><given-names>Y</given-names></name>, <name><surname>Xia</surname><given-names>C-Q</given-names></name>, <name><surname>Pan</surname><given-names>X</given-names></name>, <name><surname>Shen</surname><given-names>H-B</given-names></name>. <article-title>GraphBind: protein structural context embedded rules learned by hierarchical graph neural networks for recognizing nucleic-acid-binding residues</article-title>. <source>Nucleic acids research</source>. <year>2021</year>;<volume>49</volume>(<issue>9</issue>):<fpage>e51</fpage>–<lpage>e</lpage>.<pub-id pub-id-type="pmid">33577689</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref049">
      <label>49</label>
      <mixed-citation publication-type="journal"><name><surname>Yuan</surname><given-names>Q</given-names></name>, <name><surname>Chen</surname><given-names>S</given-names></name>, <name><surname>Rao</surname><given-names>J</given-names></name>, <name><surname>Zheng</surname><given-names>S</given-names></name>, <name><surname>Zhao</surname><given-names>H</given-names></name>, <name><surname>Yang</surname><given-names>Y</given-names></name>. <article-title>AlphaFold2-aware protein–DNA binding site prediction using graph transformer</article-title>. <source>Briefings in Bioinformatics</source>. <year>2022</year>;<volume>23</volume>(<issue>2</issue>):<fpage>bbab564</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/bbab564</pub-id><?supplied-pmid 35039821?><pub-id pub-id-type="pmid">35039821</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref050">
      <label>50</label>
      <mixed-citation publication-type="journal"><name><surname>Anderson</surname><given-names>TW</given-names></name>, <name><surname>Darling</surname><given-names>DA</given-names></name>. <article-title>Asymptotic theory of certain" goodness of fit" criteria based on stochastic processes.</article-title><source>The annals of mathematical statistics</source>. <year>1952</year>:<fpage>193</fpage>–<lpage>212</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref051">
      <label>51</label>
      <mixed-citation publication-type="book"><name><surname>Wilcoxon</surname><given-names>F.</given-names></name><part-title>Individual comparisons by ranking methods</part-title>. In: <name><surname>Kotz</surname><given-names>S</given-names></name>, <name><surname>Johnson</surname><given-names>NL</given-names></name>, editors. <source>Breakthroughs in Statistics: Methodology and Distribution</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer New York</publisher-name>; <year>1992</year>. p. <fpage>196</fpage>–<lpage>202</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref052">
      <label>52</label>
      <mixed-citation publication-type="journal"><name><surname>Altschul</surname><given-names>SF</given-names></name>, <name><surname>Madden</surname><given-names>TL</given-names></name>, <name><surname>Schäffer</surname><given-names>AA</given-names></name>, <name><surname>Zhang</surname><given-names>J</given-names></name>, <name><surname>Zhang</surname><given-names>Z</given-names></name>, <name><surname>Miller</surname><given-names>W</given-names></name>, <etal>et al</etal>. <article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>. <source>Nucleic Acids Research</source>. <year>1997</year>;<volume>25</volume>(<issue>17</issue>):<fpage>3389</fpage>–<lpage>402</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/25.17.3389</pub-id><?supplied-pmid 9254694?><pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref053">
      <label>53</label>
      <mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>Z</given-names></name>, <name><surname>Akin</surname><given-names>H</given-names></name>, <name><surname>Rao</surname><given-names>R</given-names></name>, <name><surname>Hie</surname><given-names>B</given-names></name>, <name><surname>Zhu</surname><given-names>Z</given-names></name>, <name><surname>Lu</surname><given-names>W</given-names></name>, <etal>et al</etal>. <article-title>Evolutionary-scale prediction of atomic-level protein structure with a language model</article-title>. <source>Science</source>. <year>2023</year>;<volume>379</volume>(<issue>6637</issue>):<fpage>1123</fpage>–<lpage>30</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1126/science.ade2574</pub-id><?supplied-pmid 36927031?><pub-id pub-id-type="pmid">36927031</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref054">
      <label>54</label>
      <mixed-citation publication-type="journal"><name><surname>Kabsch</surname><given-names>W</given-names></name>, <name><surname>Sander</surname><given-names>C</given-names></name>. <article-title>Dictionary of protein secondary structure: Pattern recognition of hydrogen-bonded and geometrical features</article-title>. <source>Biopolymers</source>. <year>1983</year>;<volume>22</volume>(<issue>12</issue>):<fpage>2577</fpage>–<lpage>637</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/bip.360221211</pub-id><?supplied-pmid 6667333?><pub-id pub-id-type="pmid">6667333</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref055">
      <label>55</label>
      <mixed-citation publication-type="journal"><name><surname>Jing</surname><given-names>B</given-names></name>, <name><surname>Eismann</surname><given-names>S</given-names></name>, <name><surname>Suriana</surname><given-names>P</given-names></name>, <name><surname>Townshend</surname><given-names>RJ</given-names></name>, <name><surname>Dror</surname><given-names>R</given-names></name>. <article-title>Learning from protein structure with geometric vector perceptrons</article-title>. <source>arXiv preprint arXiv:200901411</source>. <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref056">
      <label>56</label>
      <mixed-citation publication-type="journal"><name><surname>Gilmer</surname><given-names>J</given-names></name>, <name><surname>Schoenholz</surname><given-names>SS</given-names></name>, <name><surname>Riley</surname><given-names>PF</given-names></name>, <name><surname>Vinyals</surname><given-names>O</given-names></name>, <name><surname>Dahl</surname><given-names>GE</given-names></name>, <article-title>editors. Neural message passing for quantum chemistry</article-title>. <source>International conference on machine learning</source>; <year>2017</year>: PMLR.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref057">
      <label>57</label>
      <mixed-citation publication-type="journal"><name><surname>Paszke</surname><given-names>A</given-names></name>, <name><surname>Gross</surname><given-names>S</given-names></name>, <name><surname>Massa</surname><given-names>F</given-names></name>, <name><surname>Lerer</surname><given-names>A</given-names></name>, <name><surname>Bradbury</surname><given-names>J</given-names></name>, <name><surname>Chanan</surname><given-names>G</given-names></name>, <etal>et al</etal>. <article-title>Pytorch: An imperative style, high-performance deep learning library</article-title>. <source>Advances in neural information processing systems</source>. <year>2019</year>;<fpage>32</fpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref058">
      <label>58</label>
      <mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>M</given-names></name>, <name><surname>Zheng</surname><given-names>D</given-names></name>, <name><surname>Ye</surname><given-names>Z</given-names></name>, <name><surname>Gan</surname><given-names>Q</given-names></name>, <name><surname>Li</surname><given-names>M</given-names></name>, <name><surname>Song</surname><given-names>X</given-names></name>, <etal>et al</etal>. <article-title>Deep graph library: A graph-centric, highly-performant package for graph neural networks.</article-title><source>arXiv preprint arXiv:190901315.</source><year>2019</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref059">
      <label>59</label>
      <mixed-citation publication-type="journal"><name><surname>Loshchilov</surname><given-names>I</given-names></name>, <name><surname>Hutter</surname><given-names>F</given-names></name>. <article-title>Sgdr: Stochastic gradient descent with warm restarts.</article-title><source>arXiv preprint arXiv:160803983.</source><year>2016</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref060">
      <label>60</label>
      <mixed-citation publication-type="journal"><name><surname>Kingma</surname><given-names>DP</given-names></name>, <name><surname>Ba</surname><given-names>J</given-names></name>. <article-title>Adam: A method for stochastic optimization.</article-title><source>arXiv preprint arXiv:14126980.</source><year>2014</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref061">
      <label>61</label>
      <mixed-citation publication-type="journal"><name><surname>Hwang</surname><given-names>H</given-names></name>, <name><surname>Pierce</surname><given-names>B</given-names></name>, <name><surname>Mintseris</surname><given-names>J</given-names></name>, <name><surname>Janin</surname><given-names>J</given-names></name>, <name><surname>Weng</surname><given-names>Z</given-names></name>. <article-title>Protein–protein docking benchmark version 3.0.</article-title><source>Proteins: Structure, Function, and Bioinformatics.</source><year>2008</year>;<volume>73</volume>(<issue>3</issue>):<fpage>705</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/prot.22106</pub-id><?supplied-pmid 18491384?><pub-id pub-id-type="pmid">18491384</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref062">
      <label>62</label>
      <mixed-citation publication-type="journal"><name><surname>Mirdita</surname><given-names>M</given-names></name>, <name><surname>Schütze</surname><given-names>K</given-names></name>, <name><surname>Moriwaki</surname><given-names>Y</given-names></name>, <name><surname>Heo</surname><given-names>L</given-names></name>, <name><surname>Ovchinnikov</surname><given-names>S</given-names></name>, <name><surname>Steinegger</surname><given-names>M</given-names></name>. <article-title>ColabFold: making protein folding accessible to all</article-title>. <source>Nature Methods</source>. <year>2022</year>;<volume>19</volume>(<issue>6</issue>):<fpage>679</fpage>–<lpage>82</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41592-022-01488-1</pub-id><?supplied-pmid 35637307?><pub-id pub-id-type="pmid">35637307</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref063">
      <label>63</label>
      <mixed-citation publication-type="journal"><name><surname>Steinegger</surname><given-names>M</given-names></name>, <name><surname>Söding</surname><given-names>J</given-names></name>. <article-title>MMseqs2 enables sensitive protein sequence searching for the analysis of massive data sets</article-title>. <source>Nature Biotechnology</source>. <year>2017</year>;<volume>35</volume>(<issue>11</issue>):<fpage>1026</fpage>–<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nbt.3988</pub-id><?supplied-pmid 29035372?><pub-id pub-id-type="pmid">29035372</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLOS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10499216</article-id>
    <article-id pub-id-type="pmid">37651442</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011435</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-23-00388</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Molecular Biology</subject>
          <subj-group>
            <subject>Macromolecular Structure Analysis</subject>
            <subj-group>
              <subject>Protein Structure</subject>
              <subj-group>
                <subject>Protein Structure Prediction</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Protein Structure</subject>
              <subj-group>
                <subject>Protein Structure Prediction</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Neural Networks</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Neural Networks</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Molecular Biology</subject>
          <subj-group>
            <subject>Macromolecular Structure Analysis</subject>
            <subj-group>
              <subject>Protein Structure</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Protein Structure</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Chemistry</subject>
          <subj-group>
            <subject>Polymer Chemistry</subject>
            <subj-group>
              <subject>Monomers</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Mathematical Functions</subject>
            <subj-group>
              <subject>Convolution</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Statistical Methods</subject>
            <subj-group>
              <subject>Forecasting</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical Methods</subject>
              <subj-group>
                <subject>Forecasting</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Neural Networks</subject>
          <subj-group>
            <subject>Recurrent Neural Networks</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Neural Networks</subject>
            <subj-group>
              <subject>Recurrent Neural Networks</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Physics</subject>
          <subj-group>
            <subject>Classical Mechanics</subject>
            <subj-group>
              <subject>Reflection</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>E(3) equivariant graph neural networks for robust and accurate protein-protein interaction site prediction</article-title>
      <alt-title alt-title-type="running-head">E(3) equivariant graph neural networks for protein-protein interaction site prediction</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Roche</surname>
          <given-names>Rahmatullah</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Moussad</surname>
          <given-names>Bernard</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shuvo</surname>
          <given-names>Md Hossain</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9630-0141</contrib-id>
        <name>
          <surname>Bhattacharya</surname>
          <given-names>Debswapna</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="cor001" ref-type="corresp">*</xref>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <addr-line>Department of Computer Science, Virginia Tech, Blacksburg, Virginia, United States of America</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Li</surname>
          <given-names>Jinyan</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>University of Technology Sydney, AUSTRALIA</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>dbhattacharya@vt.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>31</day>
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <volume>19</volume>
    <issue>8</issue>
    <elocation-id>e1011435</elocation-id>
    <history>
      <date date-type="received">
        <day>10</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>15</day>
        <month>8</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 Roche et al</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Roche et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1011435.pdf"/>
    <abstract>
      <p>Artificial intelligence-powered protein structure prediction methods have led to a paradigm-shift in computational structural biology, yet contemporary approaches for predicting the interfacial residues (i.e., sites) of protein-protein interaction (PPI) still rely on experimental structures. Recent studies have demonstrated benefits of employing graph convolution for PPI site prediction, but ignore symmetries naturally occurring in 3-dimensional space and act only on experimental coordinates. Here we present EquiPPIS, an E(3) equivariant graph neural network approach for PPI site prediction. EquiPPIS employs symmetry-aware graph convolutions that transform equivariantly with translation, rotation, and reflection in 3D space, providing richer representations for molecular data compared to invariant convolutions. EquiPPIS substantially outperforms state-of-the-art approaches based on the same experimental input, and exhibits remarkable robustness by attaining better accuracy with predicted structural models from AlphaFold2 than what existing methods can achieve even with experimental structures. Freely available at <ext-link xlink:href="https://github.com/Bhattacharya-Lab/EquiPPIS" ext-link-type="uri">https://github.com/Bhattacharya-Lab/EquiPPIS</ext-link>, EquiPPIS enables accurate PPI site prediction at scale.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>Predicting how proteins interact and characterizing the interacting residues at the protein-protein interaction interface (i.e., sites) is of central importance to understanding various biological processes actuated by protein-protein interactions (PPI). Despite the remarkable recent progress in protein structure prediction driven by artificial intelligence, existing approaches for PPI site prediction still rely on experimental input. This paper presents an E(3) equivariant graph neural network approach for PPI site prediction that takes into account symmetries naturally occurring in 3-dimensional space and transforms equivariantly with translation, rotation, and reflection. Rigorous experimental validation shows that our method attains substantially improved accuracy and robustness over the existing approaches. Moving beyond what is currently possible with only experimental input, our method enables large-scale PPI site prediction using predicted structural models from AlphaFold2 without compromising on accuracy. An open-source software implementation of EquiPPIS, licensed under the GNU General Public License v3, is freely available at <ext-link xlink:href="https://github.com/Bhattacharya-Lab/EquiPPIS" ext-link-type="uri">https://github.com/Bhattacharya-Lab/EquiPPIS</ext-link>.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000057</institution-id>
            <institution>National Institute of General Medical Sciences</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R35GM138146</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9630-0141</contrib-id>
          <name>
            <surname>Bhattacharya</surname>
            <given-names>Debswapna</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000001</institution-id>
            <institution>National Science Foundation</institution>
          </institution-wrap>
        </funding-source>
        <award-id>DBI2208679</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9630-0141</contrib-id>
          <name>
            <surname>Bhattacharya</surname>
            <given-names>Debswapna</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>This work was partially supported by the National Institute of General Medical Sciences (R35GM138146 to D.B.) and the National Science Foundation (DBI2208679 to D.B.). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="3"/>
      <page-count count="19"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>PLOS Publication Stage</meta-name>
        <meta-value>vor-update-to-uncorrected-proof</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>Publication Update</meta-name>
        <meta-value>2023-09-13</meta-value>
      </custom-meta>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>Data availability: The raw data used in this study, including the datasets for train, test and validation are collected from publicly available sources and freely available at <ext-link xlink:href="https://github.com/biomed-AI/GraphPPIS" ext-link-type="uri">https://github.com/biomed-AI/GraphPPIS</ext-link>. Code availability: An open-source software implementation of EquiPPIS, licensed under the GNU General Public License v3, is freely available at <ext-link xlink:href="https://github.com/Bhattacharya-Lab/EquiPPIS" ext-link-type="uri">https://github.com/Bhattacharya-Lab/EquiPPIS</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>Data availability: The raw data used in this study, including the datasets for train, test and validation are collected from publicly available sources and freely available at <ext-link xlink:href="https://github.com/biomed-AI/GraphPPIS" ext-link-type="uri">https://github.com/biomed-AI/GraphPPIS</ext-link>. Code availability: An open-source software implementation of EquiPPIS, licensed under the GNU General Public License v3, is freely available at <ext-link xlink:href="https://github.com/Bhattacharya-Lab/EquiPPIS" ext-link-type="uri">https://github.com/Bhattacharya-Lab/EquiPPIS</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Protein-protein interactions (PPI) underpin numerous biological processes [<xref rid="pcbi.1011435.ref001" ref-type="bibr">1</xref>, <xref rid="pcbi.1011435.ref002" ref-type="bibr">2</xref>]. Despite their importance, experimental characterization of PPI remains challenging due to the costly and time-consuming nature of the experimental assays [<xref rid="pcbi.1011435.ref003" ref-type="bibr">3</xref>]. Computational methods offer a cheaper and high-throughput alternative by predicting the bound complex structures of interacting proteins from the sequences and/or the unbound structures of individual protein chains. A closely related problem—and the one addressed in this study—is the prediction of the PPI sites, which are the interfacial residues of the interacting protein chains.</p>
    <p>Accurately predicting the interface of interacting proteins and the identification of the PPI sites remain challenging even after decades of research [<xref rid="pcbi.1011435.ref004" ref-type="bibr">4</xref>–<xref rid="pcbi.1011435.ref006" ref-type="bibr">6</xref>]. Various methods have been proposed, but with limited success. Partner-independent PPI site prediction [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>–<xref rid="pcbi.1011435.ref012" ref-type="bibr">12</xref>], which involves the prediction of putative interaction sites based only upon the surface of an isolated protein, without any knowledge of the partner or complex, is even more challenging compared to partner-aware PPI site prediction [<xref rid="pcbi.1011435.ref013" ref-type="bibr">13</xref>–<xref rid="pcbi.1011435.ref017" ref-type="bibr">17</xref>] due to the absence of any information about the partner protein and auxiliary information on the complex interfaces. In this work, we focus on partner-independent PPI site prediction.</p>
    <p>Predicting how proteins interact, and in particular, predicting the PPI sites, has a long history [<xref rid="pcbi.1011435.ref012" ref-type="bibr">12</xref>, <xref rid="pcbi.1011435.ref015" ref-type="bibr">15</xref>, <xref rid="pcbi.1011435.ref018" ref-type="bibr">18</xref>–<xref rid="pcbi.1011435.ref025" ref-type="bibr">25</xref>]. While initial models focused on feature engineering with machine learning [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>, <xref rid="pcbi.1011435.ref019" ref-type="bibr">19</xref>, <xref rid="pcbi.1011435.ref026" ref-type="bibr">26</xref>, <xref rid="pcbi.1011435.ref027" ref-type="bibr">27</xref>], subsequent work sought to capture more complex patterns using deep learning [<xref rid="pcbi.1011435.ref008" ref-type="bibr">8</xref>, <xref rid="pcbi.1011435.ref010" ref-type="bibr">10</xref>, <xref rid="pcbi.1011435.ref013" ref-type="bibr">13</xref>, <xref rid="pcbi.1011435.ref014" ref-type="bibr">14</xref>, <xref rid="pcbi.1011435.ref017" ref-type="bibr">17</xref>]. The vast majority of the existing methods rely on readily available protein sequence information, but their predictive accuracies are often quite limited [<xref rid="pcbi.1011435.ref028" ref-type="bibr">28</xref>]. Structure-based methods that integrate known structural information from the Protein Data Bank (PDB [<xref rid="pcbi.1011435.ref029" ref-type="bibr">29</xref>]) are usually more accurate. However, these approaches are limited by the paucity of experimentally solved protein structures in the PDB. In the 14th edition of the Critical Assessment of Structure Prediction (CASP14) experiment, AlphaFold2 [<xref rid="pcbi.1011435.ref030" ref-type="bibr">30</xref>] attained an unprecedented performance level, enabling highly accurate prediction of single-chain protein structural models at proteome-wide scale [<xref rid="pcbi.1011435.ref031" ref-type="bibr">31</xref>, <xref rid="pcbi.1011435.ref032" ref-type="bibr">32</xref>]. Given the recent progress, a natural question arises: can we leverage the predicted structural information by AlphaFold2 for accurate partner-independent PPI site prediction at scale?</p>
    <p>In the recent past, representation learning with graph structured data has been prevailing in different applications. In particular, graph neural networks (GNNs) have surged as the major choice for deep graph learning [<xref rid="pcbi.1011435.ref033" ref-type="bibr">33</xref>–<xref rid="pcbi.1011435.ref035" ref-type="bibr">35</xref>]. GNNs are permutation equivariant networks that operate on graph structured data, with numerous applications ranging from dynamical systems to conformational energy estimation [<xref rid="pcbi.1011435.ref036" ref-type="bibr">36</xref>, <xref rid="pcbi.1011435.ref037" ref-type="bibr">37</xref>]. However, off-the-shelf GNNs do not take into account symmetries naturally occurring in 3-dimensional space. That is, they ignore the effects of invariance and equivariance with respect to the E(3) symmetry group, i.e., the group of rotations, reflections, and translations in 3D space. The recent E(n) equivariant graph neural networks [<xref rid="pcbi.1011435.ref038" ref-type="bibr">38</xref>] address this problem by being translation, rotation, and reflection equivariant in 3D space that can be scaled to higher dimensional spaces (E(n)), while preserving permutation equivariance. SE(3) equivariant neural networks [<xref rid="pcbi.1011435.ref039" ref-type="bibr">39</xref>] are another recent graph-based models that can deal with the absolute coordinate systems in 3D space, but SE(3) equivariant models do not commute with reflections of the input. E(3) equivariant neural networks, on the other hand, transform equivariantly with translation, rotation and reflections, which make them suitable for molecular data where chirality of the molecules is often important, such as proteins, particularly when predicted protein structures are used as input that may contain mirror images. As such, E(3) equivariant graph neural networks offer an elegant choice for partner-independent PPI site prediction, where the input consists of a 3D structure of an isolated protein, known to be involved in PPIs, but where the structure of the partner or complex is not known. Being designed from geometric first-principles, symmetry-aware models such as E(3) equivariant graph neural networks are highly suitable for 3D molecular data, providing richer representation while avoiding expensive data augmentation strategies.</p>
    <p>The contribution of the present work is the introduction of a symmetry-aware PPI site prediction method, EquiPPIS, built on E(3) equivariant graph neural networks that yields state-of-the-art accuracy by substantially outperforming existing approaches based on the same experimental input. What is more striking is that EquiPPIS attains better accuracy with AlphaFold2-predicted structural models as input than what existing methods can achieve even with experimental input. We directly verify that the performance gains are connected to the unique E(3) equivariant architecture of EquiPPIS. The robustness and performance resilience of our method enable large-scale PPI site prediction without compromising on accuracy.</p>
  </sec>
  <sec sec-type="results" id="sec002">
    <title>Results</title>
    <p>Overview of the E(3) equivariant graph neural network architecture for protein–protein interaction site prediction</p>
    <p><bold><xref rid="pcbi.1011435.g001" ref-type="fig">Fig 1</xref></bold> illustrates our E(3) equivariant graph neural network model for partner-independent PPI site prediction. Different from the recent structure-aware graph learning approaches for PPI site prediction [<xref rid="pcbi.1011435.ref010" ref-type="bibr">10</xref>] that only exploit pairwise distances between all residue pairs (i.e., distance maps) as the spatial information, our E(3) equivariant graph neural network model directly leverages the C<sub>α</sub> coordinates extracted from the input monomer together with sequence- and structure-based node and edge features. By using an E(3) equivariant architecture, our symmetry-aware model can learn to preserve the known transformation properties of 3D coordinates under translation, rotation, and reflection, improving PPI site prediction. The EquiPPIS method consists of three major modules. The first module (<bold><xref rid="pcbi.1011435.g001" ref-type="fig">Fig 1A</xref></bold>) converts the input protein monomer into an undirected graph <inline-formula id="pcbi.1011435.e001"><alternatives><graphic xlink:href="pcbi.1011435.e001.jpg" id="pcbi.1011435.e001g" position="anchor"/><mml:math id="M1" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, with <inline-formula id="pcbi.1011435.e002"><alternatives><graphic xlink:href="pcbi.1011435.e002.jpg" id="pcbi.1011435.e002g" position="anchor"/><mml:math id="M2" display="inline" overflow="scroll"><mml:mi mathvariant="script">V</mml:mi></mml:math></alternatives></inline-formula> denoting the residues (nodes) and ℰ denoting the interaction between nonsequential residue pairs according to their pairwise spatial proximity (edges). The spatial proximity between nonsequential residue pairs (i.e., having sequence separation greater or equal to 6) is determined by calculating the Euclidean distances between the C<sub>α</sub> atom of all residue pairs and then setting a cutoff distance of 14Å to obtain the interacting pairs, determined through ablation experiments using an independent validation set. The sequence- and structure-based node and edge features (see the <xref rid="sec012" ref-type="sec">Methods</xref> section) are then fed into the second module together with the C<sub>α</sub> coordinates extracted from the input monomer. The second module (<bold><xref rid="pcbi.1011435.g001" ref-type="fig">Fig 1B</xref></bold>) is a deep E(3) equivariant graph neural network that conducts a series of transformations of its input through a stack of equivariant graph convolution layer (EGCL) [<xref rid="pcbi.1011435.ref038" ref-type="bibr">38</xref>], each updating the coordinate and node embeddings using the edge information and the coordinate and node embeddings from the previous layer. Finally, a sigmoidal function is applied to the last EGCL node embedding to predict the probability of every residue in the input monomer to be a PPI site, thereby converting the PPI site prediction into a graph node classification task (<bold><xref rid="pcbi.1011435.g001" ref-type="fig">Fig 1C</xref></bold>).</p>
    <fig position="float" id="pcbi.1011435.g001">
      <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.g001</object-id>
      <label>Fig 1</label>
      <caption>
        <title>Illustration of the EquiPPIS method for protein–protein interaction site prediction.</title>
        <p>(<bold>a</bold>) The input protein monomer is converted into an undirected graph. (<bold>b</bold>) Equivariant graph convolutions are then employed on the input graph. (<bold>c</bold>) PPI sites are finally predicted as a graph node classification task.</p>
      </caption>
      <graphic xlink:href="pcbi.1011435.g001" position="float"/>
    </fig>
    <sec id="sec003">
      <title>Experiments</title>
      <p>For training and performance evaluation, we use a combination of three widely used and publicly available benchmark datasets: Dset_186 [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>], Dset_72 [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>], and Dset_164 [<xref rid="pcbi.1011435.ref040" ref-type="bibr">40</xref>], named by the number of proteins in the datasets. We follow the same train and test splits from the recent PPI site prediction method GraphPPIS [<xref rid="pcbi.1011435.ref010" ref-type="bibr">10</xref>], which combines the aforementioned three datasets and subsequently removes redundancy, resulting in 335 targets as the training set (Train_335) and 60 targets as the test set (Test_60). Details of our training procedure are provided in the Methods section. We evaluate our proposed method on a diverse series of challenging test scenarios using standard performance evaluation metrics including accuracy, precision, recall, F1-score (F1), Matthews correlation coefficient (MCC), area under the receiver operating characteristic curve (ROC-AUC), and area under the precision-recall curve (PR-AUC). First, we demonstrate that EquiPPIS improves upon state-of-the-art accuracy on Test_60 dataset by comparing it directly against a wide variety of existing approaches including PSIVER [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>] (based on Naïve Bayes), ProNA2020 [<xref rid="pcbi.1011435.ref041" ref-type="bibr">41</xref>] (based on neural network), SCRIBER [<xref rid="pcbi.1011435.ref042" ref-type="bibr">42</xref>] (based on two layers of logistic regression), DLPred [<xref rid="pcbi.1011435.ref043" ref-type="bibr">43</xref>] (based on long short-term memory), DELPHI [<xref rid="pcbi.1011435.ref009" ref-type="bibr">9</xref>] (based on an ensemble of convolutional and recurrent neural networks), DeepPPISP [<xref rid="pcbi.1011435.ref008" ref-type="bibr">8</xref>] (based on convolutional neural network), SPPIDER [<xref rid="pcbi.1011435.ref011" ref-type="bibr">11</xref>] (based on support vector machine, neural network, and linear discriminant analysis), MaSIF-site [<xref rid="pcbi.1011435.ref044" ref-type="bibr">44</xref>] (based on geometric deep learning), and GraphPPIS (based on deep graph convolutional network). Among the competing methods, PSIVER, ProNA2020, SCRIBER, DLPred, and DELPHI are purely sequence-based methods; whereas DeepPPIS, SPPIDER, MaSIF-site, GraphPPIS, and our new method EquiPPIS additionally integrate structural information. Next, we examine the reasons for such high performance attained by EquiPPIS and verify that it is indeed connected to the equivariant nature of the model used. To broaden the applicability of our method beyond predicting PPI sites based only on experimentally-solved input monomers extracted from the bound complex structures, we explore a number of extensions including using unbound experimental structures and computationally predicted structural models as input. Specifically, using a subset of 31 proteins from the Test_60 dataset with known unbound monomeric structures in the PDB as an additional unbound test set (hereafter called UBtest_31), we show that EquiPPIS exhibits remarkable robustness and performance resilience compared to the existing approaches. Furthermore, by replacing the experimental input monomers with AlphaFold2 predicted structural models for the Test_60 dataset, we demonstrate that EquiPPIS attains state-of-the-art accuracy, which is better than what the top performing competing method can achieve even with experimental structures. The superior performance of EquiPPIS even when using predicted structural models as input dramatically enhances the scalability of partner-independent PPI site prediction without compromising on accuracy. Finally, we examine the relative importance of each feature we adopted by conducting feature ablation experiments using an independent validation set consisting of 42 targets (hereafter called Validation_42) collected from the Test_315 dataset of the published work of GraphPPIS after filtering out proteins with &gt;25% pairwise sequence identity with our test sets. We also use this validation set for hyperparameter selection.</p>
    </sec>
    <sec id="sec004">
      <title>Test set performance</title>
      <p>We compare EquiPPIS with five sequence-based (PSIVER, ProNA2020, SCRIBER, DLPred and DELPHI) and four structure-based (DeepPPISP, SPPIDER, MaSIF-site, and GraphPPIS) predictors on the Test_60 set. As shown in <bold><xref rid="pcbi.1011435.t001" ref-type="table">Table 1</xref></bold>, in addition to outperforming the sequence-based methods (PR-AUC ranging from 0.190 to 0.319) by a large margin, EquiPPIS significantly improves upon state-of-the-art accuracy by outperforming the structure-based methods. Remarkably, EquiPPIS is the only method attaining ROC-AUC of more than 0.8, which is noticeably better than the closest competing method GraphPPIS. Interestingly, the published work of GraphPPIS sets the goal of achieving ROC-AUC of 0.8 as a motivation for future work, while acknowledging it as one of the current impediments. In summary, EquiPPIS is a leap forward for partner independent PPI site prediction.</p>
      <table-wrap position="float" id="pcbi.1011435.t001">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>PPI site prediction performance on the Test_60 dataset for various methods.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1011435.t001" id="pcbi.1011435.t001g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" style="background-color:#F2F2F2" rowspan="1" colspan="1">Method</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Accuracy</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Precision</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Recall</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">F1</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">MCC</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">ROC-AUC</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">PR-AUC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">PSIVER</td>
                <td align="center" rowspan="1" colspan="1">0.561</td>
                <td align="center" rowspan="1" colspan="1">0.188</td>
                <td align="center" rowspan="1" colspan="1">0.534</td>
                <td align="center" rowspan="1" colspan="1">0.278</td>
                <td align="center" rowspan="1" colspan="1">0.074</td>
                <td align="center" rowspan="1" colspan="1">0.573</td>
                <td align="center" rowspan="1" colspan="1">0.190</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">ProNA2020</td>
                <td align="center" rowspan="1" colspan="1">0.738</td>
                <td align="center" rowspan="1" colspan="1">0.275</td>
                <td align="center" rowspan="1" colspan="1">0.402</td>
                <td align="center" rowspan="1" colspan="1">0.326</td>
                <td align="center" rowspan="1" colspan="1">0.176</td>
                <td align="center" rowspan="1" colspan="1">N/A</td>
                <td align="center" rowspan="1" colspan="1">N/A</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">SCRIBER</td>
                <td align="center" rowspan="1" colspan="1">0.667</td>
                <td align="center" rowspan="1" colspan="1">0.253</td>
                <td align="center" rowspan="1" colspan="1">0.568</td>
                <td align="center" rowspan="1" colspan="1">0.350</td>
                <td align="center" rowspan="1" colspan="1">0.193</td>
                <td align="center" rowspan="1" colspan="1">0.665</td>
                <td align="center" rowspan="1" colspan="1">0.278</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">DLPred</td>
                <td align="center" rowspan="1" colspan="1">0.682</td>
                <td align="center" rowspan="1" colspan="1">0.264</td>
                <td align="center" rowspan="1" colspan="1">0.565</td>
                <td align="center" rowspan="1" colspan="1">0.360</td>
                <td align="center" rowspan="1" colspan="1">0.208</td>
                <td align="center" rowspan="1" colspan="1">0.677</td>
                <td align="center" rowspan="1" colspan="1">0.294</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">DELPHI</td>
                <td align="center" rowspan="1" colspan="1">0.697</td>
                <td align="center" rowspan="1" colspan="1">0.276</td>
                <td align="center" rowspan="1" colspan="1">0.568</td>
                <td align="center" rowspan="1" colspan="1">0.372</td>
                <td align="center" rowspan="1" colspan="1">0.225</td>
                <td align="center" rowspan="1" colspan="1">0.699</td>
                <td align="center" rowspan="1" colspan="1">0.319</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">DeepPPISP</td>
                <td align="center" rowspan="1" colspan="1">0.657</td>
                <td align="center" rowspan="1" colspan="1">0.243</td>
                <td align="center" rowspan="1" colspan="1">0.539</td>
                <td align="center" rowspan="1" colspan="1">0.335</td>
                <td align="center" rowspan="1" colspan="1">0.167</td>
                <td align="center" rowspan="1" colspan="1">0.653</td>
                <td align="center" rowspan="1" colspan="1">0.276</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">SPPIDER</td>
                <td align="center" rowspan="1" colspan="1">0.752</td>
                <td align="center" rowspan="1" colspan="1">0.331</td>
                <td align="center" rowspan="1" colspan="1">0.557</td>
                <td align="center" rowspan="1" colspan="1">0.415</td>
                <td align="center" rowspan="1" colspan="1">0.285</td>
                <td align="center" rowspan="1" colspan="1">0.755</td>
                <td align="center" rowspan="1" colspan="1">0.373</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">MaSIF-site</td>
                <td align="center" rowspan="1" colspan="1">0.780</td>
                <td align="center" rowspan="1" colspan="1">0.370</td>
                <td align="center" rowspan="1" colspan="1">0.561</td>
                <td align="center" rowspan="1" colspan="1">0.446</td>
                <td align="center" rowspan="1" colspan="1">0.326</td>
                <td align="center" rowspan="1" colspan="1">0.775</td>
                <td align="center" rowspan="1" colspan="1">0.439</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraphPPIS</td>
                <td align="center" rowspan="1" colspan="1">0.776</td>
                <td align="center" rowspan="1" colspan="1">0.368</td>
                <td align="center" rowspan="1" colspan="1">0.584</td>
                <td align="center" rowspan="1" colspan="1">0.451</td>
                <td align="center" rowspan="1" colspan="1">0.333</td>
                <td align="center" rowspan="1" colspan="1">0.786</td>
                <td align="center" rowspan="1" colspan="1">0.429</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">EquiPPIS</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.787</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.389</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.615</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.477</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.366</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.805</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.467</bold>
                </td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t001fn001">
            <p>Note: Except EquiPPS, results for the other methods are obtained directly from the published work of GraphPPIS; values in bold represent the best performance.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p><bold><xref rid="pcbi.1011435.g002" ref-type="fig">Fig 2</xref></bold> presents two representative examples from the Test_60 dataset comparing the PPI site predictions using EquiPPIS and GraphPPIS. For the first example of a sugar binding protein of Trichosanthes kirilowii (PDB ID: 1GGP, chain A) having length 234 (<bold><xref rid="pcbi.1011435.g002" ref-type="fig">Fig 2A</xref></bold>), EquiPPIS correctly predicts majority of the observed PPI sites, attaining Precision, Recall, F1, and MCC of 0.8, 0.545, 0.649, and 0.601, respectively; whereas GraphPPIS fails to predict any correct PPI sites with Precision, Recall, F1 and MCC of 0, 0, 0, -0.185, respectively. The second example is a Hydrolase inhibitor of Triticum aestivum in complex with Bacillus subtilis (PDB ID: 2B42, chain A) having length 364 (<bold><xref rid="pcbi.1011435.g002" ref-type="fig">Fig 2B</xref></bold>), where GraphPPIS predicts many false positive PPI sites, resulting in low Precision, Recall, F1 and MCC of 0.105, 0.231, 0.144, and -0.004, respectively. EquiPPIS on the other hand attains reasonably accurate predictive performance having Precision, Recall, F1, and MCC of 0.595, 0.564, 0.579, and 0.53, respectively. In both cases, EquiPPIS predictions are strikingly similar to the experimentally observed PPI sites.</p>
      <fig position="float" id="pcbi.1011435.g002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>GraphPPIS and EquiPPIS predictions compared to the experimental observation.</title>
          <p>(<bold>a</bold>) Sugar binding protein of Trichosanthes kirilowii. (<bold>b</bold>) Hydrolase inhibitor of Triticum aestivum in complex with Bacillus subtilis. The regions highlighted in green represent PPI sites.</p>
        </caption>
        <graphic xlink:href="pcbi.1011435.g002" position="float"/>
      </fig>
    </sec>
    <sec id="sec005">
      <title>Analyzing the importance of equivariance</title>
      <p>In the above experiments, EquiPPIS exhibits significantly improved performance. In order to gain insight into the reasons behind such high performance and verify that it is connected to the equivariant nature of the model, we perform a series of experiments by gradually isolating the effect of the equivariant graph convolutions used in EquiPPIS. In particular, we train several baseline models and compare them head-to-head with the full-fledged version of EquiPPIS. First, we train a baseline network by turning off the coordinate updates of the equivariant graph convolution layers, thus making it an invariant network (hereafter called ‘EquiPPIS invariant’). Since the full-fledged version of EquiPPIS employs attention operations for aggregated embedding as part of the equivariant message passing, we train another baseline network where attention operation is turned off during equivariant message passing, resulting in an equivariant network but without attention (hereafter called ‘EquiPPIS w/o attention’). Additionally, we train two off-the-shelf GNNs for PPI site prediction: graph convolution network (GCN) [<xref rid="pcbi.1011435.ref035" ref-type="bibr">35</xref>] and graph attention network (GAT) [<xref rid="pcbi.1011435.ref045" ref-type="bibr">45</xref>]. All baseline networks are trained on the same Train_335 dataset using the same set of input features and hyperparameters as the full-fledged version of EquiPPIS (see the <xref rid="sec012" ref-type="sec">Methods</xref> section). <bold><xref rid="pcbi.1011435.g003" ref-type="fig">Fig 3A to 3D</xref></bold> show the performance of EquiPPIS compared to the baseline networks on the Test_60 set. The results demonstrate that the full-fledged version of EquiPPIS outperforms all baseline models. For example, we observe that the full-fledged version of EquiPPIS attains an ROC-AUC of more than 0.8, which is the best accuracy compared to all baseline models. The ‘EquiPPIS invariant’ baseline, however, falls short of achieving an ROC-AUC of 0.8, suggesting that it is the equivariant nature of EquiPPIS that is responsible for the accuracy gain. Turning off the attention operation as done in the ‘EquiPPIS w/o attention’ baseline leads to an accuracy decline (an ROC-AUC of 0.8) compared to the full-fledged version of EquiPPIS, but still better than the invariant network. That is, attention operation during equivariant message passing contributes to an improvement in accuracy. It is worth noting that despite the accuracy drop from the full-fledged version of EquiPPIS, both ‘EquiPPIS invariant’ and ‘EquiPPIS w/o attention’ baselines outperform GraphPPIS. On the other hand, off-the-shelf GCN- and GAT-based baselines exhibit much lower accuracies compared to GraphPPIS, let alone EquiPPIS. Overall, the results underscore the importance of equivariance in particular and symmetry-aware nature of the new EquiPPIS model in general for improved predictive accuracy.</p>
      <fig position="float" id="pcbi.1011435.g003">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <p>Performance analysis on Test_60 set (<bold>a</bold>-<bold>d</bold>) and on UBtest_31 set (<bold>e</bold>-<bold>f</bold>). (<bold>a</bold>) MCC, (<bold>b</bold>) ROC-AUC, (<bold>c</bold>) F1, and (<bold>d</bold>) PR-AUC of EquiPPIS on Test_60 set compared to the baseline models ‘EquiPPIS invariant’, ‘EquiPPIS w/o attention’, graph convolution network (GCN), and graph attention network (GAT). (<bold>e</bold>) MCC and (<bold>f</bold>) PR-AUC of EquiPPIS on UBtest_31 set compared to other structure- based methods GraphPPIS, MaSIF-site, SPPIDER, and DeepPPISP.</p>
        </caption>
        <graphic xlink:href="pcbi.1011435.g003" position="float"/>
      </fig>
      <p>In addition to prediction accuracy, robustness of model is another key aspect to consider. While experimentally-solved bound complex structures are used during EquiPPIS training, protein–protein binding often leads to conformational changes by “induced fit” mechanism (binding first) or “conformational selection” (conformational change first) [<xref rid="pcbi.1011435.ref046" ref-type="bibr">46</xref>]. To evaluate the robustness of EquiPPIS and the effect of conformational changes, we examine the impact on the accuracy when unbound structures are used during prediction instead of their bound states for EquiPPIS as well as the other structure-based PPI site predictors (DeepPPISP, SPPIDER, MaSIF-site, and GraphPPIS) using the unbound test set (UBtest_31) of 31 proteins. As shown in <bold><xref rid="pcbi.1011435.g003" ref-type="fig">Fig 3E and 3F</xref></bold>, EquiPPIS outperforms all other methods by a large margin, while having the least impact on accuracy when unbound structures are used during prediction. For example, the closest competing methods MaSIF-site and GraphPPIS suffer from significant accuracy drop both in terms of MCC (35%, and 14.6% drop, respectively) and PR-AUC (24.7%, and 18.2% drop, respectively), whereas EquiPPIS experiences only 4.6%, and 5.5% drop in MCC and PR-AUC, respectively. What is most striking is that the accuracy gap between EquiPPIS and the competing methods is so large that EquiPPIS using unbound structures attains much better accuracy even when the competing methods are using the bound structures. That is, EquiPPIS exhibits remarkable robustness and performance resilience compared to existing approaches.</p>
    </sec>
    <sec id="sec006">
      <title>Beyond experimental input: state-of-the-art performance with AlphaFold2</title>
      <p>EquiPPIS achieves state-of-the-art accuracy with experimental structures as input in both bound and unbound states. A natural question to ask is can we achieve similar predictive accuracy when computationally predicted structural models are used as input instead of experimental structures? Given the exceptional performance of AlphaFold2 in the CASP14 experiment and the open availability of the AlphaFold2 protocol, it is now possible to predict single-chain protein structural models from the amino acid sequence with high degree of accuracy. In principle, a robust method such as EquiPPIS should be able to generalize when predicted structural models are used without significant drop in accuracy, thereby broadening its applicability beyond experimental input. Motivated by the prospect, we examine the impact on the accuracy by replacing the experimental input with AlphaFold2 predicted structural models for the Test_60 dataset. <bold><xref rid="pcbi.1011435.t002" ref-type="table">Table 2</xref></bold> shows the performance of EquiPPIS compared to the closest competing method GraphPPIS. Remarkably, EquiPPIS using AlphaFold2-predicted structural models attains better accuracy (PR-AUC = 0.451) than GraphPPIS using experimental structures (PR-AUC = 0.429), let alone GraphPPIS using predicted structural models (PR-AUC = 0.399). While there is a performance decline for both methods when switching from experimental input to prediction, the performance drop for EquiPPIS is lower (ΔPR-AUC = 0.016) than that of GraphPPIS (ΔPR-AUC = 0.03). The results demonstrate the generalizability of EquiPPIS, thus opening the possibility of large-scale PPI site prediction by utilizing high-throughput computational prediction without compromising on accuracy.</p>
      <table-wrap position="float" id="pcbi.1011435.t002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Performance comparison between EquiPPIS and GraphPPIS with experimental input and AlphaFold2 predicted structural models for the Test_60 dataset.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1011435.t002" id="pcbi.1011435.t002g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Method</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Input type</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Accuracy</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Precision</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Recall</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">F1</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">MCC</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">ROC-AUC</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">PR-AUC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="2" colspan="1">EquiPPIS</td>
                <td align="center" rowspan="1" colspan="1">Experimental</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.787</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.389</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.615</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.477</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.366</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.805</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.467</bold>
                </td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">AlphaFold2</td>
                <td align="center" rowspan="1" colspan="1">0.780</td>
                <td align="center" rowspan="1" colspan="1">0.379</td>
                <td align="center" rowspan="1" colspan="1">0.615</td>
                <td align="center" rowspan="1" colspan="1">0.469</td>
                <td align="center" rowspan="1" colspan="1">0.356</td>
                <td align="center" rowspan="1" colspan="1">0.795</td>
                <td align="center" rowspan="1" colspan="1">0.451</td>
              </tr>
              <tr>
                <td align="center" rowspan="2" colspan="1">GraphPPIS</td>
                <td align="center" rowspan="1" colspan="1">Experimental<xref rid="t002fn001" ref-type="table-fn">*</xref></td>
                <td align="center" rowspan="1" colspan="1">0.776</td>
                <td align="center" rowspan="1" colspan="1">0.368</td>
                <td align="center" rowspan="1" colspan="1">0.584</td>
                <td align="center" rowspan="1" colspan="1">0.451</td>
                <td align="center" rowspan="1" colspan="1">0.333</td>
                <td align="center" rowspan="1" colspan="1">0.786</td>
                <td align="center" rowspan="1" colspan="1">0.429</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">AlphaFold2</td>
                <td align="center" rowspan="1" colspan="1">0.767</td>
                <td align="center" rowspan="1" colspan="1">0.357</td>
                <td align="center" rowspan="1" colspan="1">0.590</td>
                <td align="center" rowspan="1" colspan="1">0.445</td>
                <td align="center" rowspan="1" colspan="1">0.324</td>
                <td align="center" rowspan="1" colspan="1">0.772</td>
                <td align="center" rowspan="1" colspan="1">0.399</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t002fn001">
            <p>* Results obtained directly from the published work of GraphPPIS; values in bold represent the best performance.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="sec007">
      <title>Significance test</title>
      <p>To investigate if our performance improvement is significant or due to chance, we perform significance tests, following the procedures of previous studies [<xref rid="pcbi.1011435.ref047" ref-type="bibr">47</xref>–<xref rid="pcbi.1011435.ref049" ref-type="bibr">49</xref>]. Specifically, we randomly sample 70% of the test set (Test_60), and calculate the F1, MCC, ROC-AUC, and PR-AUC scores of EquiPPIS and the closest competing method GraphPPIS with both experimental and AlphaFold2 predicted structures, where the same structures are used as inputs to both the prediction methods. We repeat this 10 times and obtain 10 pairs of scores. If the measurement is normal, which is determined through Anderson-Darling test [<xref rid="pcbi.1011435.ref050" ref-type="bibr">50</xref>], then paired t-test is used to calculate significance of the measurement. If the measurement is not normal, then we use Wilcoxon rank sum test [<xref rid="pcbi.1011435.ref051" ref-type="bibr">51</xref>]. As reported in <bold><xref rid="pcbi.1011435.t003" ref-type="table">Table 3</xref>,</bold> EquiPPIS is statistically significantly better than GraphPPIS on both experimental and predicted structures at 95% confidence level with p-values &lt; 0.05 for all four metrics.</p>
      <table-wrap position="float" id="pcbi.1011435.t003">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.t003</object-id>
        <label>Table 3</label>
        <caption>
          <title>Significance test between EquiPPIS and GraphPPIS using experimental and AlphaFold2 predicted structures.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1011435.t003" id="pcbi.1011435.t003g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" style="background-color:#F2F2F2" rowspan="1" colspan="1">Input type</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">Method</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">F1</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">MCC</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">ROC-AUC</th>
                <th align="center" style="background-color:#F2F2F2" rowspan="1" colspan="1">PR-AUC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="3" colspan="1"><break/>Experimental</td>
                <td align="center" rowspan="1" colspan="1">EquiPPIS</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.4793</bold><break/>±<break/>0.000302678</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.3664</bold><break/>±<break/>0.000287822</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.8032</bold><break/>±<break/>9.50667E-05</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.4684</bold><break/>±<break/>0.000536933</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">GraphPPIS</td>
                <td align="center" rowspan="1" colspan="1">0.4539<break/>±<break/>0.0004801</td>
                <td align="center" rowspan="1" colspan="1">0.3334<break/>±<break/>0.000352489</td>
                <td align="center" rowspan="1" colspan="1">0.7818<break/>±<break/>0.000117733</td>
                <td align="center" rowspan="1" colspan="1">0.4395<break/>±<break/>0.000764056</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <italic toggle="yes">p-value</italic>
                </td>
                <td align="center" rowspan="1" colspan="1">3.18683E-05</td>
                <td align="center" rowspan="1" colspan="1">2.41981E-05</td>
                <td align="center" rowspan="1" colspan="1">3.97085E-05</td>
                <td align="center" rowspan="1" colspan="1">0.000373678</td>
              </tr>
              <tr>
                <td align="left" rowspan="3" colspan="1"><break/>AlphaFold2</td>
                <td align="center" rowspan="1" colspan="1">EquiPPIS</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.4712</bold><break/>±<break/>0.000345067</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.356</bold><break/>±<break/>0.000401778</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.7912</bold><break/>±<break/>0.000189733</td>
                <td align="center" rowspan="1" colspan="1"><bold>0.4516</bold><break/>±<break/>0.0008396</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">GraphPPIS</td>
                <td align="center" rowspan="1" colspan="1">0.4434<break/>±<break/>0.000515378</td>
                <td align="center" rowspan="1" colspan="1">0.3199<break/>±<break/>0.000447433</td>
                <td align="center" rowspan="1" colspan="1">0.7667<break/>±<break/>0.000159567</td>
                <td align="center" rowspan="1" colspan="1">0.3956<break/>±<break/>0.0007036</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <italic toggle="yes">p-value</italic>
                </td>
                <td align="center" rowspan="1" colspan="1">7.71066E-06</td>
                <td align="center" rowspan="1" colspan="1">0.002827272</td>
                <td align="center" rowspan="1" colspan="1">0.001939728</td>
                <td align="center" rowspan="1" colspan="1">9.92622E-08</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t003fn001">
            <p>* For all four metrics, the two numbers reported are mean and variance respectively; values in bold represent the best performance in terms of mean.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="sec008">
      <title>Impact of secondary structure content on prediction accuracy</title>
      <p>To examine the impact of physical characteristics of the input structures on the prediction accuracy of EquiPPIS, we analyze the secondary structure content of the proteins for the Test_60 set. The targets are divided into three groups: (1) helices (referred to as ’Primarily helix’), (2) beta strands (referred to as ’Primarily beta’), and (3) mixture of helices and beta strands (referred to as ’Mix’). We calculate the ROC-AUC scores for each group and compare them with the results obtained from the full set. <bold><xref rid="pcbi.1011435.s001" ref-type="supplementary-material">S1 Fig</xref></bold> presents a comparison of our prediction accuracy in terms of ROC-AUC scores across the groups with different physical characteristics based on secondary structure. EquiPPIS achieves a higher ROC-AUC of 0.855 in the ’Primarily helix’ group compared to the full set’s ROC-AUC of 0.805. However, in the ’Primarily beta’ group, EquiPPIS attains a somewhat lower ROC-AUC of 0.783. As for the ’Mix’ group, EquiPPIS achieves the ROC-AUC of 0.799, which is comparable to that obtained on the full set. The results demonstrate that secondary structure content has a minor impact on the prediction accuracy with primarily helical proteins yielding the best performance, whereas there is still room for improvement for the proteins that are primarily made of beta strands.</p>
    </sec>
    <sec id="sec009">
      <title>Running time analysis</title>
      <p>We analyze the running time of EquiPPIS and the closest competing method GraphPPIS for all targets in the Test_60 set on the same Linux machine with identical hardware environment. <bold><xref rid="pcbi.1011435.g004" ref-type="fig">Fig 4</xref></bold> presents a target-wise running time comparison between EquiPPIS and GraphPPIS. Not surprisingly, free from time-consuming MSA-searching, EquiPPIS demonstrates noticeably lower running time compared to GraphPPIS. Overall, EquiPPIS is considerably efficient in terms of the running time.</p>
      <fig position="float" id="pcbi.1011435.g004">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>The running time of EquiPPIS and GraphPPIS on Test_60 set.</title>
          <p>For each target, input protein length versus runtime (in seconds) of EquiPPIS (blue) and GraphPPIS (red) are shown.</p>
        </caption>
        <graphic xlink:href="pcbi.1011435.g004" position="float"/>
      </fig>
    </sec>
    <sec id="sec010">
      <title>Ablation studies and choice of hyperparameters</title>
      <p>To examine the relative importance of the features adopted in EquiPPIS, we conduct feature ablation experiments by gradually isolating the contribution of individual feature or groups of features during model training and evaluating the accuracy on the independent validation set Validation_42. <bold><xref rid="pcbi.1011435.g005" ref-type="fig">Fig 5A</xref></bold> shows the accuracy decline measured in terms of ΔPR-AUC and ΔROC-AUC when various features are isolated from the full-fledged version of EquiPPIS. The results demonstrate that all features contribute to the overall accuracy achieved by EquiPPIS. For example, we notice accuracy decline when we isolate the sequence-based features one by one including amino acid residue type (No AA), position specific scoring matrix (No PSSM), and protein language model ESM2 (No ESM2). Not surprisingly, the evolutionarily feature PSSM and protein language model-based ESM2 feature contribute more than just the residue type features. We notice a significant performance drop when all three sequence-based features are isolated (No seq). Similarly, we notice consistent accuracy decline when we discard the structure-based features individually including secondary structure (No ss), relative solvent accessibility (No rsa), local geometry (No local geom), residue orientation (No orient), contact count (No contact count) as well as relative residue positioning and residue virtual surface area (No res pos + area). Because we use multi-level discretization of secondary structure (e.g., 3-state and 8-state) and relative solvent accessibility (e.g., 2-state and 8-state) as well as backbone torsion angles, which are closely related to the secondary structure, we conduct feature ablation experiments by discarding the 8-state secondary structure, 8- state relative solvent accessibility, and backbone torsion angles. The resulting model (No multi-level) shows accuracy decline compared to the full-fledged version of EquiPPIS, indicating the effectiveness of combining multi-granular information. Finally, we also notice an accuracy drop when we isolate the edge feature (No edge) that takes into account the contributions of sequence separation and spatial interaction.</p>
      <fig position="float" id="pcbi.1011435.g005">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011435.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <title>Ablation studies and hyperparameter selection.</title>
          <p>(<bold>a</bold>) Validation set accuracy decline after feature ablation. Dark and light blue bars indicate the PR-AUC decline (ΔPR-AUC) and the ROC-AUC decline (ΔROC-AUC), respectively. Validation set accuracy in terms of MCC and F1 for various choices of hyperparameters including (<bold>b</bold>, <bold>c</bold>) distance cutoff, (<bold>d</bold>, <bold>e</bold>) number of layers, and (<bold>f</bold>, <bold>g</bold>) hidden dimension. The selected hyperparameters yielding the best accuracy are highlighted in darker shade.</p>
        </caption>
        <graphic xlink:href="pcbi.1011435.g005" position="float"/>
      </fig>
      <p>We also use the Validation_42 set to select the hyperparameters. Based on the results of the grid search as shown in <bold><xref rid="pcbi.1011435.g005" ref-type="fig">Fig 5B to 5G</xref></bold>, we select a 10-layer EGCL framework with 256 hidden units and the cutoff distance used to obtain the interacting residue pairs is set to 14Å. We use the hyperparameters selected in the independent validation set during training and testing.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec011">
    <title>Discussion</title>
    <p>This work introduces EquiPPIS, a symmetry-aware deep graph learning model for protein–protein interaction site prediction based on E(3) equivariant graph neural networks. We demonstrate that EquiPPIS outperforms existing methods and despite being trained on experimental structures, it generalizes extremely well to predicted structural models from AlphaFold2 to the extent that EquiPPIS attains better accuracy with predicted structural models than what existing approaches can achieve even with experimental structures. Through controlled experiments, we verify the importance of equivariance as one of the major driving forces behind the improved performance. In addition to questions around the effect of equivariance on accuracy, our ablation study on an independent validation set confirms the contribution of various features adopted in EquiPPIS. Our study leads to a series of interesting questions to consider: of particular interest is the possibility of broadening the applicability of our method beyond experimental input for large-scale PPI site predictions with high accuracy by utilizing rapid computational prediction. In this regard, considering the diversity of the predictive modeling ensemble and accounting for the conformational states of the interacting proteins having multi-state conformational dynamics may help broaden the horizon of computational PPI site prediction. Further, a promising direction for future work is to investigate the potential benefits of explicitly including multiple sequence alignment (MSA) information and measure the extent to which it may influence the accuracy. While an MSA-free method such as EquiPPIS offers some unique advantages by being broadly applicable even for proteins that do not have homologous sequences in the current sequence databases and bypasses the computational overhead of MSA searching, MSA may still provide a rich source of additional information for further improving the accuracy of PPI site prediction that might be worth exploring. Finally, while we find that EquiPPIS exhibits excellent predictive accuracy and remarkable robustness, an open challenge that remains is the interpretability of our deep learning model. The evolutionary and functional significance of the residues predicted to be in PPI site by means of the latent representation underlying the neural architecture of EquiPPIS still need to be systematically explored. We expect our proposed method can be easily extended to other biomolecular interaction site prediction tasks, including predicting protein-binding sites with other molecules, such as DNA, RNA and small ligands, as well as predicting gene-gene interaction and gene-networks with improved accuracy and robustness.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec012">
    <title>Materials and Methods</title>
    <p>Graph representation and featurization.</p>
    <sec id="sec013">
      <title>Graph representation</title>
      <p>We represent the input protein monomer as a graph <inline-formula id="pcbi.1011435.e003"><alternatives><graphic xlink:href="pcbi.1011435.e003.jpg" id="pcbi.1011435.e003g" position="anchor"/><mml:math id="M3" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, in which a node <inline-formula id="pcbi.1011435.e004"><alternatives><graphic xlink:href="pcbi.1011435.e004.jpg" id="pcbi.1011435.e004g" position="anchor"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">V</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> represents a residue and an edge <italic toggle="yes">e</italic>∈ ℰ represents an interacting residue pair. We consider two residues to be interacting if their C<sub>α</sub> Euclidean distance is no more than 14Å. The cutoff 14Å is chosen on an independent validation set as presented in <bold><xref rid="pcbi.1011435.g005" ref-type="fig">Fig 5</xref></bold>. To focus on longer-rage interactions, we only consider interacting residue pairs having a minimum sequence separation of 6.</p>
    </sec>
    <sec id="sec014">
      <title>Node features</title>
      <p>We use three types of sequence-based node features: (1) one-hot encoding of the residue (i.e., a binary vector of 20 entries indicating its amino acid type), resulting in L×20 feature set, where L is the length of the input monomer; (2) position specific scoring matrix (PSSM) obtained by running PSI-BLAST [<xref rid="pcbi.1011435.ref052" ref-type="bibr">52</xref>] to obtain L×20 feature set by considering the first 20 columns from the PSSM and normalizing the values by applying a sigmoidal function; and (3) features from ESM2 [<xref rid="pcbi.1011435.ref053" ref-type="bibr">53</xref>], which is a recent protein language model trained on 15 billion parameters, leading to L×33 feature set, after normalizing the values using sigmoidal function.</p>
      <p>Additionally, we extract a total of L×45 structure-based node features from the structure of the input monomer by either calculating various structural information directly from the 3D coordinates or by running the DSSP [<xref rid="pcbi.1011435.ref054" ref-type="bibr">54</xref>] program. We describe them below.</p>
      <sec id="sec015">
        <title>Secondary structure and relative solvent accessibility</title>
        <p>We use one-hot encoding of both 3-state and 8-state secondary structures (SS), leading to L×3 and L×8 feature sets, respectively. Additionally, we use one-hot encoding of 2-state relative solvent accessibility (RSA) by adopting an RSA cutoff of 50 (L×2 feature set), and use finer-grained RSA binning by discretizing into 8 bins as 0–30, 30–60, 60–90, 90–120, 120–150, 150–180, 180–210, and &gt;210, represented by one-hot encoding (L×8 feature set). The rationale of using multiple discretization of SS (e.g., 3-state and 8-state) and RSA (e.g., 2-state and 8-state) is to combine multi-level information, and ablation studies guiding these decisions are presented in <bold><xref rid="pcbi.1011435.g005" ref-type="fig">Fig 5</xref></bold>.</p>
      </sec>
      <sec id="sec016">
        <title>Local geometry</title>
        <p>We use a total of L×11 feature set from the local geometries by calculating various planar and torsion angles of the polypeptide chain, including (1) the cosine angle between the consecutive residues of the C = O bond; (2) sine and cosine of the virtual bond and torsion angles formed between the consecutive C<sub>α</sub> atoms; (3) normalized values of the backbone torsion angles.</p>
      </sec>
      <sec id="sec017">
        <title>Relative residue positioning</title>
        <p>To capture the relative positional information for each residue, we extract two types of features: (1) for i<sup>th</sup> residue, we use the inverse of i to capture the relative sequence position (L×1 feature set); and (2) we use the inverse of the Euclidean distance from the centroid of the input protein monomer to the C<sub>α</sub> atom of the i<sup>th</sup> residue to capture the spatial positioning of a residue relative to the overall structure (L×1 feature set).</p>
      </sec>
      <sec id="sec018">
        <title>Residue orientation</title>
        <p>To define the orientation of each amino acid residue, we adopted features from a recent work [<xref rid="pcbi.1011435.ref055" ref-type="bibr">55</xref>] including (1) the forward and reverse unit vectors in the directions of C<sub>α</sub><sup>(i+1)</sup> − C<sub>α</sub><sup>i</sup> and C<sub>α</sub><sup>(i−1)</sup> − C<sub>α</sub><sup>i</sup>, respectively (L×6 feature set); and (2) the unit vector in the imputed direction of C<sub>β</sub><sup>i</sup> − C<sub>α</sub><sup>i</sup>, computed by assuming tetrahedral geometries and normalization (L×3 feature set).</p>
      </sec>
      <sec id="sec019">
        <title>Residue virtual surface area</title>
        <p>An amino acid residue can be perceived as a virtual convex hull constructed by its atoms. We calculate the virtual surface area of the convex hull and use its inverse as a feature (L×1 feature set).</p>
      </sec>
      <sec id="sec020">
        <title>Contact count</title>
        <p>If the Euclidean distance between the C<sub>β</sub> atoms of a residue pair is within a cutoff of 8Å, the two residues can be considered to be in contact. We calculate the contact-count by calculating the number of spatial neighbors of a given residue (i.e., residues which are in contact) and use the normalized number of contact count per residue as a feature (L×1 feature set).</p>
        <p>The sequence-based amino acid (L×20 feature set), PSSM (L×20 feature set), and ESM2 (L×33 feature set) features are concatenated with the structure-based node features (L×45 feature set), leading to a total of L×118 features, which serves as an input to our E(3) equivariant graph neural network model (<bold><xref rid="pcbi.1011435.s002" ref-type="supplementary-material">S2 Fig</xref></bold>).</p>
      </sec>
    </sec>
    <sec id="sec021">
      <title>Edge features</title>
      <p>As the edge feature for the graph <inline-formula id="pcbi.1011435.e005"><alternatives><graphic xlink:href="pcbi.1011435.e005.jpg" id="pcbi.1011435.e005g" position="anchor"/><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, we calculate the ratio of the logarithmic sequential separation of two residues (i.e., logarithm of the absolute difference between the two residue indices) corresponding to two nodes in the graph and the Euclidean distance between them, defined as:
<disp-formula id="pcbi.1011435.e006"><alternatives><graphic xlink:href="pcbi.1011435.e006.jpg" id="pcbi.1011435.e006g" position="anchor"/><mml:math id="M6" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">log</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
Here, the numerator captures how the two residues are separated in the primary sequence while the denominator captures their spatial interactions.</p>
    </sec>
    <sec id="sec022">
      <title>Network architecture</title>
      <p>We formulate the PPI site prediction into a graph node classification task and predict the probability of every residue in the input monomer to be a PPI site using a deep E(3) equivariant graph neural network. The network architecture consists of a stack of equivariant graph convolution layer (EGCL) [<xref rid="pcbi.1011435.ref038" ref-type="bibr">38</xref>], performing a series of transformations of its input by updating the coordinate and node embeddings using the edge information and the coordinate and node embeddings from the previous layer. The EGCL operation attains equivariance primarily by changing the standard message passing (<inline-formula id="pcbi.1011435.e007"><alternatives><graphic xlink:href="pcbi.1011435.e007.jpg" id="pcbi.1011435.e007g" position="anchor"/><mml:math id="M7" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> [<xref rid="pcbi.1011435.ref056" ref-type="bibr">56</xref>] to equivariant message passing and by introducing coordinate updates in the graph neural network, as follows:
<disp-formula id="pcbi.1011435.e008"><alternatives><graphic xlink:href="pcbi.1011435.e008.jpg" id="pcbi.1011435.e008g" position="anchor"/><mml:math id="M8" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e009"><alternatives><graphic xlink:href="pcbi.1011435.e009.jpg" id="pcbi.1011435.e009g" position="anchor"/><mml:math id="M9" display="block" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi><mml:mo>≠</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives></disp-formula>
where <bold><italic toggle="yes">a</italic></bold><sub><bold><italic toggle="yes">ij</italic></bold></sub> denotes edge features; <inline-formula id="pcbi.1011435.e010"><alternatives><graphic xlink:href="pcbi.1011435.e010.jpg" id="pcbi.1011435.e010g" position="anchor"/><mml:math id="M10" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1011435.e011"><alternatives><graphic xlink:href="pcbi.1011435.e011.jpg" id="pcbi.1011435.e011g" position="anchor"/><mml:math id="M11" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> are node embeddings at layer <bold><italic toggle="yes">l</italic></bold> for nodes <bold><italic toggle="yes">i</italic></bold> and <bold><italic toggle="yes">j</italic></bold>, respectively; <bold><italic toggle="yes">ϕ</italic></bold><sub><bold><italic toggle="yes">e</italic></bold></sub>, <bold><italic toggle="yes">ϕ</italic></bold><sub><bold><italic toggle="yes">h</italic></bold></sub>, and <bold><italic toggle="yes">ϕ</italic></bold><sub><bold><italic toggle="yes">x</italic></bold></sub> are multilayer perceptrons (MLP) for edge, node, and coordinate operations, respectively. Equivariant message passing for an edge (<bold><italic toggle="yes">i</italic>, <italic toggle="yes">j</italic></bold>) is attained by considering the squared distance between node <bold><italic toggle="yes">i</italic></bold> and <bold><italic toggle="yes">j</italic></bold>: <inline-formula id="pcbi.1011435.e012"><alternatives><graphic xlink:href="pcbi.1011435.e012.jpg" id="pcbi.1011435.e012g" position="anchor"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> in the edge operation. The coordinate update for node <bold><italic toggle="yes">i</italic></bold> is obtained by the weighted sum of coordinate embedding difference from the previous layer, normalizing with a factor <bold><italic toggle="yes">C</italic></bold> = 1/(<bold><italic toggle="yes">M</italic></bold>−1), where <bold><italic toggle="yes">M</italic></bold> is the number of nodes in the graph. The weights for the sum are generated through the multilayer perceptron (MLP) of coordinate operation applied on the equivariant message passing (<bold><italic toggle="yes">m</italic></bold><sub><bold><italic toggle="yes">ij</italic></bold></sub>) for each edge (<bold><italic toggle="yes">i</italic></bold>, <bold><italic toggle="yes">j</italic></bold>).</p>
      <p>Unlike off-the-shelf graph neural networks that aggregate messages only from the neighboring nodes, equivariant graph neural networks aggregate messages from the whole graph. Additionally, an attention embedding (<bold><italic toggle="yes">m</italic></bold><sub><bold><italic toggle="yes">a</italic></bold></sub>) can be employed through an attention operation (<bold><italic toggle="yes">ϕ</italic></bold><sub><bold><italic toggle="yes">a</italic></bold></sub>), which is a linear transformation on the aggregated message embedding (<bold><italic toggle="yes">m</italic></bold><sub><bold><italic toggle="yes">i</italic></bold></sub>), followed by a sigmoidal non-linear transformation. The ‘attended’ aggregated message embedding is subsequently obtained through a scalar multiplication with the attention embedding. The node embedding is updated by applying an MLP (<bold><italic toggle="yes">ϕ</italic></bold><sub><bold><italic toggle="yes">h</italic></bold></sub>) on the aggregated message and the node embeddings of the previous layer, as follows:
<disp-formula id="pcbi.1011435.e013"><alternatives><graphic xlink:href="pcbi.1011435.e013.jpg" id="pcbi.1011435.e013g" position="anchor"/><mml:math id="M13" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi><mml:mo>≠</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e014"><alternatives><graphic xlink:href="pcbi.1011435.e014.jpg" id="pcbi.1011435.e014g" position="anchor"/><mml:math id="M14" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>×</mml:mo><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e015"><alternatives><graphic xlink:href="pcbi.1011435.e015.jpg" id="pcbi.1011435.e015g" position="anchor"/><mml:math id="M15" display="block" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives></disp-formula>
Finally, A linear transformation (<bold><italic toggle="yes">ϕ</italic></bold><sub>0</sub>) is applied to squeeze the hidden dimension (<inline-formula id="pcbi.1011435.e016"><alternatives><graphic xlink:href="pcbi.1011435.e016.jpg" id="pcbi.1011435.e016g" position="anchor"/><mml:math id="M16" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">L</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>) of the last EGCL, followed by a sigmoidal function to obtain the node-level classification (<bold><italic toggle="yes">p</italic></bold><sub><italic toggle="yes">i</italic></sub>) for PPI site prediction:
<disp-formula id="pcbi.1011435.e017"><alternatives><graphic xlink:href="pcbi.1011435.e017.jpg" id="pcbi.1011435.e017g" position="anchor"/><mml:math id="M17" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">L</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e018"><alternatives><graphic xlink:href="pcbi.1011435.e018.jpg" id="pcbi.1011435.e018g" position="anchor"/><mml:math id="M18" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
The network architecture of EquiPPIS consists of 10 layers of EGCL with a hidden dimension of 256, where the hyperparameters are chosen on an independent validation set, and empirical results guiding these decisions are presented in <bold><xref rid="pcbi.1011435.g005" ref-type="fig">Fig 5</xref></bold>. EquiPPIS is implemented on Pytorch 1.12.0 [<xref rid="pcbi.1011435.ref057" ref-type="bibr">57</xref>] and Deep Graph Library (DGL) 0.9.0 [<xref rid="pcbi.1011435.ref058" ref-type="bibr">58</xref>]. We use binary cross entropy loss function between the node-level prediction and the ground truth, and we utilize cosine annealing scheduler from SGDR [<xref rid="pcbi.1011435.ref059" ref-type="bibr">59</xref>], ADAM optimizer [<xref rid="pcbi.1011435.ref060" ref-type="bibr">60</xref>] with a learning rate of 1e-4, and weight decay of 1e-16. The training process consists of at most 50 epochs on an NVIDIA A40 GPU. In addition to the full-fledged version of EquiPPIS, we train several baseline models on the same Train_335 dataset using the same set of input features and hyperparameters including off-the-shelf graph convolution network (GCN) [<xref rid="pcbi.1011435.ref035" ref-type="bibr">35</xref>] and graph attention network (GAT) [<xref rid="pcbi.1011435.ref045" ref-type="bibr">45</xref>], both implemented using the DGL [<xref rid="pcbi.1011435.ref058" ref-type="bibr">58</xref>], as well as two variants of EquiPPIS: (1) ‘EquiPPIS invariant’, an invariant network with the coordinate updates of the equivariant graph convolution layers turned off; and (2) ‘EquiPPIS w/o attention’, an equivariant network with the attention operation turned off during equivariant message passing.</p>
    </sec>
    <sec id="sec023">
      <title>Datasets, benchmarking, and performance evaluation</title>
      <p>We use a combination of three widely used and publicly available benchmark datasets: Dset_186 [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>], Dset_72 [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>], and Dset_164 [<xref rid="pcbi.1011435.ref040" ref-type="bibr">40</xref>]. Dset_72 is created based on protein-protein benchmark version 3.0 [<xref rid="pcbi.1011435.ref061" ref-type="bibr">61</xref>], Dset_186 is constructed through a six-step filtering process which involves the exclusion of structures containing over 30% missing residues, identical UniprotKB/Swiss-Prot accessions, interface polarity and buried surface accessibility below specific thresholds, as well as oligomeric structures, transmembrane, and redundant protein structures, where 186 targets are collected from known protein complexes, and Dset_164 consists of 164 targets obtained from known heterodimers. While Dset_186, Dset_72, and Dset_164 are non-redundant data sets independently, the combined dataset is further reduced to 395 targets by filtering out redundant chains among the datasets. Following the same train-test split as GraphPPIS [<xref rid="pcbi.1011435.ref010" ref-type="bibr">10</xref>], we use a train set (Train_335) having 10,374 and 55,992 interacting and noninteracting residues, respectively; and a test set (Test_60) having 2,075 and 11,069 interacting and noninteracting residues, respectively. In the Train_335 set, the average length of protein is ~198 residues ranging from 44 to 869 residues. In the Test_60 set, the average length of protein is ~219 residues ranging from 52 to 766 residues, with no homodimeric protein-protein interaction present within this set. To assess the robustness of EquiPPIS and examine the effect of conformational changes on its performance, we analyze a subset of 31 proteins from the Test_60 set with known unbound monomeric conformations. This additional unbound test set (UBtest_31) having 841 and 5813 interacting and non-interacting residues, respectively, is adopted from the published work on GraphPPIS. Additionally, we adopt a dataset named Test_315 from the published work on GraphPPIS consisting of newly solved protein complexes that are non-redundant to the train set. We filter out 42 targets from the Test_315 set by discarding protein chains having more than 25% pairwise sequence identity with our test set and create an independent validation set (Validation_42) to perform feature ablation and hyperparameter selection.</p>
      <p>During prediction, we use both experimentally-solved structures as well as on AlphaFold2-predicted structural models as input. We run AlphaFold2 with default parameter settings by locally installing the officially released version [<xref rid="pcbi.1011435.ref030" ref-type="bibr">30</xref>] to generate five predicted structural models and then select the model with the highest pLDDT confidence score. For target 4cdgA that failed during the MSA generation stage of the AlphaFold2 pipeline, we run Colabfold [<xref rid="pcbi.1011435.ref062" ref-type="bibr">62</xref>] that uses MMSeqs2 [<xref rid="pcbi.1011435.ref063" ref-type="bibr">63</xref>] for MSA generation and subsequently employs AlphaFold2 protocol for structure prediction.</p>
      <p>EquiPPIS is compared against both sequence-based (PSIVER [<xref rid="pcbi.1011435.ref007" ref-type="bibr">7</xref>], ProNA2020 [<xref rid="pcbi.1011435.ref041" ref-type="bibr">41</xref>], SCRIBER [<xref rid="pcbi.1011435.ref042" ref-type="bibr">42</xref>], DLPred [<xref rid="pcbi.1011435.ref043" ref-type="bibr">43</xref>], and DELPHI [<xref rid="pcbi.1011435.ref009" ref-type="bibr">9</xref>]) and structure-aware (DeepPPIS [<xref rid="pcbi.1011435.ref008" ref-type="bibr">8</xref>], SPPIDER [<xref rid="pcbi.1011435.ref011" ref-type="bibr">11</xref>], MaSIF-site [<xref rid="pcbi.1011435.ref044" ref-type="bibr">44</xref>], and GraphPPIS [<xref rid="pcbi.1011435.ref010" ref-type="bibr">10</xref>]) PPI site prediction methods. PSIVER employs a Naïve Bayes classifier along with kernel density estimation by utilizing sequence-based features. ProNA2020 combines homology modeling with a neural network for residue-level PPI site prediction. SCRIBER employs two layers of logistic regression, where the first layer utilizes sequence-based features while the second layer combines the output from the first layer for the final prediction. DLPred employs a simplified long-short-term memory model for PPI site prediction. DELPHI uses an ensemble of convolutional and recurrent neural networks architectures with a large feature set. DeepPPISP combines local contextual features with global features and employs convolutional neural networks to predict PPI sites. SPPIDER leverages support vector machine, neural network, and linear discriminant analysis with an extensive feature search and extraction process. MaSIF-site predicts PPI sites by learning protein structural fingerprints through geometric deep learning. GraphPPIS employs structure-aware deep residual neural networks for PPI site prediction.</p>
      <p>For benchmarking and performance assessment, we use standard performance evaluation metrics including accuracy, precision, recall, F1-score (F1), and Matthews correlation coefficient (MCC), defined as:
<disp-formula id="pcbi.1011435.e019"><alternatives><graphic xlink:href="pcbi.1011435.e019.jpg" id="pcbi.1011435.e019g" position="anchor"/><mml:math id="M19" display="block" overflow="scroll"><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e020"><alternatives><graphic xlink:href="pcbi.1011435.e020.jpg" id="pcbi.1011435.e020g" position="anchor"/><mml:math id="M20" display="block" overflow="scroll"><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e021"><alternatives><graphic xlink:href="pcbi.1011435.e021.jpg" id="pcbi.1011435.e021g" position="anchor"/><mml:math id="M21" display="block" overflow="scroll"><mml:mi mathvariant="bold-italic">R</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e022"><alternatives><graphic xlink:href="pcbi.1011435.e022.jpg" id="pcbi.1011435.e022g" position="anchor"/><mml:math id="M22" display="block" overflow="scroll"><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="bold-italic">R</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">R</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1011435.e023"><alternatives><graphic xlink:href="pcbi.1011435.e023.jpg" id="pcbi.1011435.e023g" position="anchor"/><mml:math id="M23" display="block" overflow="scroll"><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:msqrt></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
where, TP denotes the number of true PPI site residues that are correctly predicted, FP denotes the number of non-PPI site residues that are incorrectly predicted to be in PPI sites, TN denotes the number of non-PPI site residues that are correctly predicted, and FN denotes the number of PPI site residues that are incorrectly predicted as non-PPI site. We additionally use area under the receiver operating characteristic curve (ROC-AUC) and area under the precision-recall curve (PR-AUC) for performance evaluation.</p>
    </sec>
  </sec>
  <sec id="sec024" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pcbi.1011435.s001" position="float" content-type="local-data">
      <label>S1 Fig</label>
      <caption>
        <title>Impact of secondary structure content on prediction accuracy.</title>
        <p>ROC-AUC scores achieved by EquiPPIS grouped by secondary structure content (’Primarily helix’, ’Primarily beta’, and ’Mix’) as well as the overall ROC-AUC (’All’) in the Test_60 set.</p>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pcbi.1011435.s001.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011435.s002" position="float" content-type="local-data">
      <label>S2 Fig</label>
      <caption>
        <title>Input node feature generation.</title>
        <p>The sequence-based amino acid (L×20 feature set), PSSM (L×20 feature set), and ESM2 (L×33 feature set) features are concatenated with the structure-based node features (L×45 feature set), leading to a total of L×118 features, which serves as an input to the E(3) equivariant graph neural networks.</p>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pcbi.1011435.s002.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1011435.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Jones</surname><given-names>S</given-names></name>, <name><surname>Thornton</surname><given-names>JM</given-names></name>. <article-title>Principles of protein-protein interactions</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>1996</year>;<volume>93</volume>(<issue>1</issue>):<fpage>13</fpage>–<lpage>20</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.93.1.13</pub-id><?supplied-pmid 8552589?><pub-id pub-id-type="pmid">8552589</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Sharan</surname><given-names>R</given-names></name>, <name><surname>Suthram</surname><given-names>S</given-names></name>, <name><surname>Kelley</surname><given-names>RM</given-names></name>, <name><surname>Kuhn</surname><given-names>T</given-names></name>, <name><surname>McCuine</surname><given-names>S</given-names></name>, <name><surname>Uetz</surname><given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Conserved patterns of protein interaction in multiple species</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2005</year>;<volume>102</volume>(<issue>6</issue>):<fpage>1974</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.0409522102</pub-id><?supplied-pmid 15687504?><pub-id pub-id-type="pmid">15687504</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Shoemaker</surname><given-names>BA</given-names></name>, <name><surname>Panchenko</surname><given-names>AR</given-names></name>. <article-title>Deciphering protein–protein interactions</article-title>. <source>Part I. Experimental techniques and databases. PLoS computational biology</source>. <year>2007</year>;<volume>3</volume>(<issue>3</issue>):<fpage>e42</fpage>.<pub-id pub-id-type="pmid">17397251</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Keskin</surname><given-names>O</given-names></name>, <name><surname>Gursoy</surname><given-names>A</given-names></name>, <name><surname>Ma</surname><given-names>B</given-names></name>, <name><surname>Nussinov</surname><given-names>R</given-names></name>. <article-title>Principles of protein− protein interactions: what are the preferred ways for proteins to interact?</article-title><source>Chemical reviews</source>. <year>2008</year>;<volume>108</volume>(<issue>4</issue>):<fpage>1225</fpage>–<lpage>44</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1021/cr040409x</pub-id><?supplied-pmid 18355092?><pub-id pub-id-type="pmid">18355092</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Nooren</surname><given-names>IM</given-names></name>, <name><surname>Thornton</surname><given-names>JM</given-names></name>. <article-title>Diversity of protein–protein interactions</article-title>. <source>The EMBO journal</source>. <year>2003</year>;<volume>22</volume>(<issue>14</issue>):<fpage>3486</fpage>–<lpage>92</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/emboj/cdg359</pub-id><?supplied-pmid 12853464?><pub-id pub-id-type="pmid">12853464</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Chatrabgoun</surname><given-names>O</given-names></name>, <name><surname>Daneshkhah</surname><given-names>A</given-names></name>, <name><surname>Esmaeilbeigi</surname><given-names>M</given-names></name>, <name><surname>Safa</surname><given-names>NS</given-names></name>, <name><surname>Alenezi</surname><given-names>AH</given-names></name>, <name><surname>Rahman</surname><given-names>A</given-names></name>. <article-title>Predicting Primary Sequence-Based Protein-Protein Interactions Using a Mercer Series Representation of Nonlinear Support Vector Machine.</article-title><source>IEEE Access.</source><year>2022</year>;<volume>10</volume>:<fpage>124345</fpage>–<lpage>54</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Murakami</surname><given-names>Y</given-names></name>, <name><surname>Mizuguchi</surname><given-names>K</given-names></name>. <article-title>Applying the Naïve Bayes classifier with kernel density estimation to the prediction of protein–protein interaction sites</article-title>. <source>Bioinformatics</source>. <year>2010</year>;<volume>26</volume>(<issue>15</issue>):<fpage>1841</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">20529890</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Zeng</surname><given-names>M</given-names></name>, <name><surname>Zhang</surname><given-names>F</given-names></name>, <name><surname>Wu</surname><given-names>F-X</given-names></name>, <name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Wang</surname><given-names>J</given-names></name>, <name><surname>Li</surname><given-names>M</given-names></name>. <article-title>Protein–protein interaction site prediction through combining local and global features with deep neural networks</article-title>. <source>Bioinformatics</source>. <year>2020</year>;<volume>36</volume>(<issue>4</issue>):<fpage>1114</fpage>–<lpage>20</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz699</pub-id><?supplied-pmid 31593229?><pub-id pub-id-type="pmid">31593229</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Golding</surname><given-names>GB</given-names></name>, <name><surname>Ilie</surname><given-names>L</given-names></name>. <article-title>DELPHI: accurate deep ensemble model for protein interaction sites prediction</article-title>. <source>Bioinformatics</source>. <year>2021</year>;<volume>37</volume>(<issue>7</issue>):<fpage>896</fpage>–<lpage>904</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btaa750</pub-id><?supplied-pmid 32840562?><pub-id pub-id-type="pmid">32840562</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Yuan</surname><given-names>Q</given-names></name>, <name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Zhao</surname><given-names>H</given-names></name>, <name><surname>Zhou</surname><given-names>Y</given-names></name>, <name><surname>Yang</surname><given-names>Y</given-names></name>. <article-title>Structure-aware protein–protein interaction site prediction using deep graph convolutional network</article-title>. <source>Bioinformatics</source>. <year>2022</year>;<volume>38</volume>(<issue>1</issue>):<fpage>125</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Porollo</surname><given-names>A</given-names></name>, <name><surname>Meller</surname><given-names>J</given-names></name>. <article-title>Prediction-based fingerprints of protein–protein interactions.</article-title><source>Proteins: Structure, Function, and Bioinformatics.</source><year>2007</year>;<volume>66</volume>(<issue>3</issue>):<fpage>630</fpage>–<lpage>45</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/prot.21248</pub-id><?supplied-pmid 17152079?><pub-id pub-id-type="pmid">17152079</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>M-H</given-names></name>, <name><surname>Lin</surname><given-names>L</given-names></name>, <name><surname>Wang</surname><given-names>X-L</given-names></name>, <name><surname>Liu</surname><given-names>T</given-names></name>. <article-title>Protein–protein interaction site prediction based on conditional random fields</article-title>. <source>Bioinformatics</source>. <year>2007</year>;<volume>23</volume>(<issue>5</issue>):<fpage>597</fpage>–<lpage>604</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btl660</pub-id><?supplied-pmid 17234636?><pub-id pub-id-type="pmid">17234636</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Fout</surname><given-names>A</given-names></name>, <name><surname>Byrd</surname><given-names>J</given-names></name>, <name><surname>Shariat</surname><given-names>B</given-names></name>, <name><surname>Ben-Hur</surname><given-names>A</given-names></name>. <article-title>Protein interface prediction using graph convolutional networks</article-title>. <source>Advances in neural information processing systems</source>. <year>2017</year>;<fpage>30</fpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Townshend</surname><given-names>R</given-names></name>, <name><surname>Bedi</surname><given-names>R</given-names></name>, <name><surname>Suriana</surname><given-names>P</given-names></name>, <name><surname>Dror</surname><given-names>R</given-names></name>. <article-title>End-to-end learning on 3d protein structure for interface prediction</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2019</year>;<fpage>32</fpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Afsar Minhas FuA</surname><given-names>Geiss BJ</given-names></name>, <article-title>Ben-Hur A. PAIRpred: partner-specific prediction of interacting residues from sequence and structure.</article-title><source>Proteins: Structure, Function, and Bioinformatics.</source><year>2014</year>;<volume>82</volume>(<issue>7</issue>):<fpage>1142</fpage>–<lpage>55</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Sanchez-Garcia</surname><given-names>R</given-names></name>, <name><surname>Sorzano</surname><given-names>COS</given-names></name>, <name><surname>Carazo</surname><given-names>JM</given-names></name>, <name><surname>Segura</surname><given-names>J</given-names></name>. <article-title>BIPSPI: a method for the prediction of partner-specific protein–protein interfaces</article-title>. <source>Bioinformatics</source>. <year>2019</year>;<volume>35</volume>(<issue>3</issue>):<fpage>470</fpage>–<lpage>7</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/bty647</pub-id><?supplied-pmid 30020406?><pub-id pub-id-type="pmid">30020406</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Dai</surname><given-names>B</given-names></name>, <name><surname>Bailey-Kellogg</surname><given-names>C</given-names></name>. <article-title>Protein interaction interface region prediction by geometric deep learning</article-title>. <source>Bioinformatics</source>. <year>2021</year>;<volume>37</volume>(<issue>17</issue>):<fpage>2580</fpage>–<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btab154</pub-id><?supplied-pmid 33693581?><pub-id pub-id-type="pmid">33693581</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>N</given-names></name>, <name><surname>Sun</surname><given-names>Z</given-names></name>, <name><surname>Jiang</surname><given-names>F</given-names></name>. <article-title>Prediction of protein-protein binding site by using core interface residue and support vector machine</article-title>. <source>BMC bioinformatics</source>. <year>2008</year>;<volume>9</volume>:<fpage>1</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">18173834</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Northey</surname><given-names>TC</given-names></name>, <name><surname>Barešić</surname><given-names>A</given-names></name>, <name><surname>Martin</surname><given-names>AC</given-names></name>. <article-title>IntPred: a structure-based predictor of protein–protein interaction sites</article-title>. <source>Bioinformatics</source>. <year>2018</year>;<volume>34</volume>(<issue>2</issue>):<fpage>223</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btx585</pub-id><?supplied-pmid 28968673?><pub-id pub-id-type="pmid">28968673</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Hou</surname><given-names>Q</given-names></name>, <name><surname>De Geest</surname><given-names>PF</given-names></name>, <name><surname>Vranken</surname><given-names>WF</given-names></name>, <name><surname>Heringa</surname><given-names>J</given-names></name>, <name><surname>Feenstra</surname><given-names>KA</given-names></name>. <article-title>Seeing the trees through the forest: sequence-based homo-and heteromeric protein-protein interaction sites prediction using random forest</article-title>. <source>Bioinformatics</source>. <year>2017</year>;<volume>33</volume>(<issue>10</issue>):<fpage>1479</fpage>–<lpage>87</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btx005</pub-id><?supplied-pmid 28073761?><pub-id pub-id-type="pmid">28073761</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Sriwastava</surname><given-names>BK</given-names></name>, <name><surname>Basu</surname><given-names>S</given-names></name>, <name><surname>Maulik</surname><given-names>U</given-names></name>. <article-title>Protein–protein interaction site prediction in Homo sapiens and E. coli using an interaction-affinity based membership function in fuzzy SVM</article-title>. <source>Journal of biosciences</source>. <year>2015</year>;<volume>40</volume>:<fpage>809</fpage>–<lpage>18</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s12038-015-9564-y</pub-id><?supplied-pmid 26564981?><pub-id pub-id-type="pmid">26564981</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>X</given-names></name>, <name><surname>Chen</surname><given-names>Xw</given-names></name>. <article-title>Heterogeneous data integration by tree-augmented naïve B ayes for protein–protein interactions prediction</article-title>. <source>Proteomics</source>. <year>2013</year>;<volume>13</volume>(<issue>2</issue>):<fpage>261</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">23112070</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Fariselli</surname><given-names>P</given-names></name>, <name><surname>Pazos</surname><given-names>F</given-names></name>, <name><surname>Valencia</surname><given-names>A</given-names></name>, <name><surname>Casadio</surname><given-names>R</given-names></name>. <article-title>Prediction of protein–protein interaction sites in heterocomplexes with neural networks</article-title>. <source>European Journal of Biochemistry</source>. <year>2002</year>;<volume>269</volume>(<issue>5</issue>):<fpage>1356</fpage>–<lpage>61</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1046/j.1432-1033.2002.02767.x</pub-id><?supplied-pmid 11874449?><pub-id pub-id-type="pmid">11874449</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>H</given-names></name>, <name><surname>Zhou</surname><given-names>HX</given-names></name>. <article-title>Prediction of interface residues in protein–protein complexes by a consensus neural network method: test against NMR data.</article-title><source>Proteins: Structure, Function, and Bioinformatics.</source><year>2005</year>;<volume>61</volume>(<issue>1</issue>):<fpage>21</fpage>–<lpage>35</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/prot.20514</pub-id><?supplied-pmid 16080151?><pub-id pub-id-type="pmid">16080151</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Liang</surname><given-names>S</given-names></name>, <name><surname>Zhang</surname><given-names>C</given-names></name>, <name><surname>Liu</surname><given-names>S</given-names></name>, <name><surname>Zhou</surname><given-names>Y</given-names></name>. <article-title>Protein binding site prediction using an empirical scoring function</article-title>. <source>Nucleic acids research</source>. <year>2006</year>;<volume>34</volume>(<issue>13</issue>):<fpage>3698</fpage>–<lpage>707</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkl454</pub-id><?supplied-pmid 16893954?><pub-id pub-id-type="pmid">16893954</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Deng</surname><given-names>A</given-names></name>, <name><surname>Zhang</surname><given-names>H</given-names></name>, <name><surname>Wang</surname><given-names>W</given-names></name>, <name><surname>Zhang</surname><given-names>J</given-names></name>, <name><surname>Fan</surname><given-names>D</given-names></name>, <name><surname>Chen</surname><given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Developing computational model to predict protein-protein interaction sites based on the XGBoost algorithm</article-title>. <source>International journal of molecular sciences</source>. <year>2020</year>;<volume>21</volume>(<issue>7</issue>):<fpage>2274</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/ijms21072274</pub-id><?supplied-pmid 32218345?><pub-id pub-id-type="pmid">32218345</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>Z-S</given-names></name>, <name><surname>Han</surname><given-names>K</given-names></name>, <name><surname>Yang</surname><given-names>J-Y</given-names></name>, <name><surname>Shen</surname><given-names>H-B</given-names></name>, <name><surname>Yu</surname><given-names>D-J</given-names></name>. <article-title>Protein–protein interaction sites prediction by ensembling SVM and sample-weighted random forests.</article-title><source>Neurocomputing</source>. <year>2016</year>;<volume>193</volume>:<fpage>201</fpage>–<lpage>12</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>J</given-names></name>, <name><surname>Kurgan</surname><given-names>L</given-names></name>. <article-title>Review and comparative assessment of sequence-based predictors of protein-binding residues</article-title>. <source>Briefings in bioinformatics</source>. <year>2018</year>;<volume>19</volume>(<issue>5</issue>):<fpage>821</fpage>–<lpage>37</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/bbx022</pub-id><?supplied-pmid 28334258?><pub-id pub-id-type="pmid">28334258</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Berman</surname><given-names>HM</given-names></name>, <name><surname>Westbrook</surname><given-names>J</given-names></name>, <name><surname>Feng</surname><given-names>Z</given-names></name>, <name><surname>Gilliland</surname><given-names>G</given-names></name>, <name><surname>Bhat</surname><given-names>TN</given-names></name>, <name><surname>Weissig</surname><given-names>H</given-names></name>, <etal>et al</etal>. <article-title>The protein data bank</article-title>. <source>Nucleic acids research</source>. <year>2000</year>;<volume>28</volume>(<issue>1</issue>):<fpage>235</fpage>–<lpage>42</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/28.1.235</pub-id><?supplied-pmid 10592235?><pub-id pub-id-type="pmid">10592235</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Jumper</surname><given-names>J</given-names></name>, <name><surname>Evans</surname><given-names>R</given-names></name>, <name><surname>Pritzel</surname><given-names>A</given-names></name>, <name><surname>Green</surname><given-names>T</given-names></name>, <name><surname>Figurnov</surname><given-names>M</given-names></name>, <name><surname>Ronneberger</surname><given-names>O</given-names></name>, <etal>et al</etal>. <article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source>Nature</source>. <year>2021</year>;<volume>596</volume>(<issue>7873</issue>):<fpage>583</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41586-021-03819-2</pub-id><?supplied-pmid 34265844?><pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Tunyasuvunakool</surname><given-names>K</given-names></name>, <name><surname>Adler</surname><given-names>J</given-names></name>, <name><surname>Wu</surname><given-names>Z</given-names></name>, <name><surname>Green</surname><given-names>T</given-names></name>, <name><surname>Zielinski</surname><given-names>M</given-names></name>, <name><surname>Žídek</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Highly accurate protein structure prediction for the human proteome</article-title>. <source>Nature</source>. <year>2021</year>;<volume>596</volume>(<issue>7873</issue>):<fpage>590</fpage>–<lpage>6</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41586-021-03828-1</pub-id><?supplied-pmid 34293799?><pub-id pub-id-type="pmid">34293799</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Varadi</surname><given-names>M</given-names></name>, <name><surname>Anyango</surname><given-names>S</given-names></name>, <name><surname>Deshpande</surname><given-names>M</given-names></name>, <name><surname>Nair</surname><given-names>S</given-names></name>, <name><surname>Natassia</surname><given-names>C</given-names></name>, <name><surname>Yordanova</surname><given-names>G</given-names></name>, <etal>et al</etal>. <article-title>AlphaFold Protein Structure Database: massively expanding the structural coverage of protein-sequence space with high-accuracy models</article-title>. <source>Nucleic Acids Research</source>. <year>2022</year>;<volume>50</volume>(<issue>D1</issue>):<fpage>D439</fpage>–<lpage>D44</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkab1061</pub-id><?supplied-pmid 34791371?><pub-id pub-id-type="pmid">34791371</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Bruna</surname><given-names>J</given-names></name>, <name><surname>Zaremba</surname><given-names>W</given-names></name>, <name><surname>Szlam</surname><given-names>A</given-names></name>, <name><surname>LeCun</surname><given-names>Y</given-names></name>. <article-title>Spectral networks and locally connected networks on graphs.</article-title><source>arXiv preprint arXiv:13126203.</source><year>2013</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Defferrard</surname><given-names>M</given-names></name>, <name><surname>Bresson</surname><given-names>X</given-names></name>, <name><surname>Vandergheynst</surname><given-names>P</given-names></name>. <article-title>Convolutional neural networks on graphs with fast localized spectral filtering</article-title>. <source>Advances in neural information processing systems</source>. <year>2016</year>;<fpage>29</fpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Kipf</surname><given-names>TN</given-names></name>, <name><surname>Welling</surname><given-names>M</given-names></name>. <article-title>Semi-supervised classification with graph convolutional networks.</article-title><source>arXiv preprint arXiv:160902907.</source><year>2016</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Weiler</surname><given-names>M</given-names></name>, <name><surname>Cesa</surname><given-names>G</given-names></name>. <article-title>General e (2)-equivariant steerable cnns.</article-title><source>Advances in Neural Information Processing Systems</source>. <year>2019</year>;<fpage>32</fpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Rezende</surname><given-names>DJ</given-names></name>, <name><surname>Racanière</surname><given-names>S</given-names></name>, <name><surname>Higgins</surname><given-names>I</given-names></name>, <name><surname>Toth</surname><given-names>P</given-names></name>. <article-title>Equivariant hamiltonian flows.</article-title><source>arXiv preprint arXiv:190913739</source>. <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref038">
      <label>38</label>
      <mixed-citation publication-type="journal"><name><surname>Satorras</surname><given-names>VcG</given-names></name>, <name><surname>Hoogeboom</surname><given-names>E</given-names></name>, <name><surname>Welling</surname><given-names>M</given-names></name>. <article-title>E(n) Equivariant Graph Neural Networks.</article-title> In: <name><surname>Marina</surname><given-names>M</given-names></name>, <name><surname>Tong</surname><given-names>Z</given-names></name>, editors. Proceedings of the 38th <source>International Conference on Machine Learning; Proceedings of Machine Learning Research: PMLR</source>; <year>2021</year>. p. <fpage>9323</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Thomas</surname><given-names>N</given-names></name>, <name><surname>Smidt</surname><given-names>T</given-names></name>, <name><surname>Kearnes</surname><given-names>S</given-names></name>, <name><surname>Yang</surname><given-names>L</given-names></name>, <name><surname>Li</surname><given-names>L</given-names></name>, <name><surname>Kohlhoff</surname><given-names>K</given-names></name>, <etal>et al</etal>. <article-title>Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds.</article-title><source>arXiv preprint arXiv:180208219.</source><year>2018</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>Dhole</surname><given-names>K</given-names></name>, <name><surname>Singh</surname><given-names>G</given-names></name>, <name><surname>Pai</surname><given-names>PP</given-names></name>, <name><surname>Mondal</surname><given-names>S</given-names></name>. <article-title>Sequence-based prediction of protein–protein interaction sites with L1-logreg classifier</article-title>. <source>Journal of Theoretical Biology</source>. <year>2014</year>;<volume>348</volume>:<fpage>47</fpage>–<lpage>54</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jtbi.2014.01.028</pub-id><?supplied-pmid 24486250?><pub-id pub-id-type="pmid">24486250</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Qiu</surname><given-names>J</given-names></name>, <name><surname>Bernhofer</surname><given-names>M</given-names></name>, <name><surname>Heinzinger</surname><given-names>M</given-names></name>, <name><surname>Kemper</surname><given-names>S</given-names></name>, <name><surname>Norambuena</surname><given-names>T</given-names></name>, <name><surname>Melo</surname><given-names>F</given-names></name>, <etal>et al</etal>. <article-title>ProNA2020 predicts protein–DNA, protein–RNA, and protein–protein binding proteins and residues from sequence</article-title>. <source>Journal of Molecular Biology</source>. <year>2020</year>;<volume>432</volume>(<issue>7</issue>):<fpage>2428</fpage>–<lpage>43</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jmb.2020.02.026</pub-id><?supplied-pmid 32142788?><pub-id pub-id-type="pmid">32142788</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref042">
      <label>42</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>J</given-names></name>, <name><surname>Kurgan</surname><given-names>L</given-names></name>. <article-title>SCRIBER: accurate and partner type-specific prediction of protein-binding residues from proteins sequences</article-title>. <source>Bioinformatics</source>. <year>2019</year>;<volume>35</volume>(<issue>14</issue>):<fpage>i343</fpage>–<lpage>i53</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz324</pub-id><?supplied-pmid 31510679?><pub-id pub-id-type="pmid">31510679</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>B</given-names></name>, <name><surname>Li</surname><given-names>J</given-names></name>, <name><surname>Quan</surname><given-names>L</given-names></name>, <name><surname>Chen</surname><given-names>Y</given-names></name>, <name><surname>Lü</surname><given-names>Q</given-names></name>. <article-title>Sequence-based prediction of protein-protein interaction sites by simplified long short-term memory network.</article-title><source>Neurocomputing</source>. <year>2019</year>;<volume>357</volume>:<fpage>86</fpage>–<lpage>100</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neucom.2019.05.013</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref044">
      <label>44</label>
      <mixed-citation publication-type="journal"><name><surname>Gainza</surname><given-names>P</given-names></name>, <name><surname>Sverrisson</surname><given-names>F</given-names></name>, <name><surname>Monti</surname><given-names>F</given-names></name>, <name><surname>Rodolà</surname><given-names>E</given-names></name>, <name><surname>Boscaini</surname><given-names>D</given-names></name>, <name><surname>Bronstein</surname><given-names>MM</given-names></name>, <etal>et al</etal>. <article-title>Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning</article-title>. <source>Nature Methods</source>. <year>2020</year>;<volume>17</volume>(<issue>2</issue>):<fpage>184</fpage>–<lpage>92</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41592-019-0666-6</pub-id><?supplied-pmid 31819266?><pub-id pub-id-type="pmid">31819266</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref045">
      <label>45</label>
      <mixed-citation publication-type="journal"><name><surname>Veličković</surname><given-names>P</given-names></name>, <name><surname>Cucurull</surname><given-names>G</given-names></name>, <name><surname>Casanova</surname><given-names>A</given-names></name>, <name><surname>Romero</surname><given-names>A</given-names></name>, <name><surname>Lio</surname><given-names>P</given-names></name>, <name><surname>Bengio</surname><given-names>Y</given-names></name>. <article-title>Graph attention networks.</article-title><source>arXiv preprint arXiv:171010903</source>. <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref046">
      <label>46</label>
      <mixed-citation publication-type="journal"><name><surname>Hammes</surname><given-names>GG</given-names></name>, <name><surname>Chang</surname><given-names>Y-C</given-names></name>, <name><surname>Oas</surname><given-names>TG</given-names></name>. <article-title>Conformational selection or induced fit: A flux description of reaction mechanism</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2009</year>;<volume>106</volume>(<issue>33</issue>):<fpage>13737</fpage>–<lpage>41</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.0907195106</pub-id><?supplied-pmid 19666553?><pub-id pub-id-type="pmid">19666553</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref047">
      <label>47</label>
      <mixed-citation publication-type="journal"><name><surname>Peng</surname><given-names>Z</given-names></name>, <name><surname>Kurgan</surname><given-names>L</given-names></name>. <article-title>High-throughput prediction of RNA, DNA and protein binding regions mediated by intrinsic disorder</article-title>. <source>Nucleic acids research</source>. <year>2015</year>;<volume>43</volume>(<issue>18</issue>):<fpage>e121</fpage>–<lpage>e</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkv585</pub-id><?supplied-pmid 26109352?><pub-id pub-id-type="pmid">26109352</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref048">
      <label>48</label>
      <mixed-citation publication-type="journal"><name><surname>Xia</surname><given-names>Y</given-names></name>, <name><surname>Xia</surname><given-names>C-Q</given-names></name>, <name><surname>Pan</surname><given-names>X</given-names></name>, <name><surname>Shen</surname><given-names>H-B</given-names></name>. <article-title>GraphBind: protein structural context embedded rules learned by hierarchical graph neural networks for recognizing nucleic-acid-binding residues</article-title>. <source>Nucleic acids research</source>. <year>2021</year>;<volume>49</volume>(<issue>9</issue>):<fpage>e51</fpage>–<lpage>e</lpage>.<pub-id pub-id-type="pmid">33577689</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref049">
      <label>49</label>
      <mixed-citation publication-type="journal"><name><surname>Yuan</surname><given-names>Q</given-names></name>, <name><surname>Chen</surname><given-names>S</given-names></name>, <name><surname>Rao</surname><given-names>J</given-names></name>, <name><surname>Zheng</surname><given-names>S</given-names></name>, <name><surname>Zhao</surname><given-names>H</given-names></name>, <name><surname>Yang</surname><given-names>Y</given-names></name>. <article-title>AlphaFold2-aware protein–DNA binding site prediction using graph transformer</article-title>. <source>Briefings in Bioinformatics</source>. <year>2022</year>;<volume>23</volume>(<issue>2</issue>):<fpage>bbab564</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/bbab564</pub-id><?supplied-pmid 35039821?><pub-id pub-id-type="pmid">35039821</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref050">
      <label>50</label>
      <mixed-citation publication-type="journal"><name><surname>Anderson</surname><given-names>TW</given-names></name>, <name><surname>Darling</surname><given-names>DA</given-names></name>. <article-title>Asymptotic theory of certain" goodness of fit" criteria based on stochastic processes.</article-title><source>The annals of mathematical statistics</source>. <year>1952</year>:<fpage>193</fpage>–<lpage>212</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref051">
      <label>51</label>
      <mixed-citation publication-type="book"><name><surname>Wilcoxon</surname><given-names>F.</given-names></name><part-title>Individual comparisons by ranking methods</part-title>. In: <name><surname>Kotz</surname><given-names>S</given-names></name>, <name><surname>Johnson</surname><given-names>NL</given-names></name>, editors. <source>Breakthroughs in Statistics: Methodology and Distribution</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer New York</publisher-name>; <year>1992</year>. p. <fpage>196</fpage>–<lpage>202</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref052">
      <label>52</label>
      <mixed-citation publication-type="journal"><name><surname>Altschul</surname><given-names>SF</given-names></name>, <name><surname>Madden</surname><given-names>TL</given-names></name>, <name><surname>Schäffer</surname><given-names>AA</given-names></name>, <name><surname>Zhang</surname><given-names>J</given-names></name>, <name><surname>Zhang</surname><given-names>Z</given-names></name>, <name><surname>Miller</surname><given-names>W</given-names></name>, <etal>et al</etal>. <article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>. <source>Nucleic Acids Research</source>. <year>1997</year>;<volume>25</volume>(<issue>17</issue>):<fpage>3389</fpage>–<lpage>402</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/25.17.3389</pub-id><?supplied-pmid 9254694?><pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref053">
      <label>53</label>
      <mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>Z</given-names></name>, <name><surname>Akin</surname><given-names>H</given-names></name>, <name><surname>Rao</surname><given-names>R</given-names></name>, <name><surname>Hie</surname><given-names>B</given-names></name>, <name><surname>Zhu</surname><given-names>Z</given-names></name>, <name><surname>Lu</surname><given-names>W</given-names></name>, <etal>et al</etal>. <article-title>Evolutionary-scale prediction of atomic-level protein structure with a language model</article-title>. <source>Science</source>. <year>2023</year>;<volume>379</volume>(<issue>6637</issue>):<fpage>1123</fpage>–<lpage>30</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1126/science.ade2574</pub-id><?supplied-pmid 36927031?><pub-id pub-id-type="pmid">36927031</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref054">
      <label>54</label>
      <mixed-citation publication-type="journal"><name><surname>Kabsch</surname><given-names>W</given-names></name>, <name><surname>Sander</surname><given-names>C</given-names></name>. <article-title>Dictionary of protein secondary structure: Pattern recognition of hydrogen-bonded and geometrical features</article-title>. <source>Biopolymers</source>. <year>1983</year>;<volume>22</volume>(<issue>12</issue>):<fpage>2577</fpage>–<lpage>637</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/bip.360221211</pub-id><?supplied-pmid 6667333?><pub-id pub-id-type="pmid">6667333</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref055">
      <label>55</label>
      <mixed-citation publication-type="journal"><name><surname>Jing</surname><given-names>B</given-names></name>, <name><surname>Eismann</surname><given-names>S</given-names></name>, <name><surname>Suriana</surname><given-names>P</given-names></name>, <name><surname>Townshend</surname><given-names>RJ</given-names></name>, <name><surname>Dror</surname><given-names>R</given-names></name>. <article-title>Learning from protein structure with geometric vector perceptrons</article-title>. <source>arXiv preprint arXiv:200901411</source>. <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref056">
      <label>56</label>
      <mixed-citation publication-type="journal"><name><surname>Gilmer</surname><given-names>J</given-names></name>, <name><surname>Schoenholz</surname><given-names>SS</given-names></name>, <name><surname>Riley</surname><given-names>PF</given-names></name>, <name><surname>Vinyals</surname><given-names>O</given-names></name>, <name><surname>Dahl</surname><given-names>GE</given-names></name>, <article-title>editors. Neural message passing for quantum chemistry</article-title>. <source>International conference on machine learning</source>; <year>2017</year>: PMLR.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref057">
      <label>57</label>
      <mixed-citation publication-type="journal"><name><surname>Paszke</surname><given-names>A</given-names></name>, <name><surname>Gross</surname><given-names>S</given-names></name>, <name><surname>Massa</surname><given-names>F</given-names></name>, <name><surname>Lerer</surname><given-names>A</given-names></name>, <name><surname>Bradbury</surname><given-names>J</given-names></name>, <name><surname>Chanan</surname><given-names>G</given-names></name>, <etal>et al</etal>. <article-title>Pytorch: An imperative style, high-performance deep learning library</article-title>. <source>Advances in neural information processing systems</source>. <year>2019</year>;<fpage>32</fpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref058">
      <label>58</label>
      <mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>M</given-names></name>, <name><surname>Zheng</surname><given-names>D</given-names></name>, <name><surname>Ye</surname><given-names>Z</given-names></name>, <name><surname>Gan</surname><given-names>Q</given-names></name>, <name><surname>Li</surname><given-names>M</given-names></name>, <name><surname>Song</surname><given-names>X</given-names></name>, <etal>et al</etal>. <article-title>Deep graph library: A graph-centric, highly-performant package for graph neural networks.</article-title><source>arXiv preprint arXiv:190901315.</source><year>2019</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref059">
      <label>59</label>
      <mixed-citation publication-type="journal"><name><surname>Loshchilov</surname><given-names>I</given-names></name>, <name><surname>Hutter</surname><given-names>F</given-names></name>. <article-title>Sgdr: Stochastic gradient descent with warm restarts.</article-title><source>arXiv preprint arXiv:160803983.</source><year>2016</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref060">
      <label>60</label>
      <mixed-citation publication-type="journal"><name><surname>Kingma</surname><given-names>DP</given-names></name>, <name><surname>Ba</surname><given-names>J</given-names></name>. <article-title>Adam: A method for stochastic optimization.</article-title><source>arXiv preprint arXiv:14126980.</source><year>2014</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref061">
      <label>61</label>
      <mixed-citation publication-type="journal"><name><surname>Hwang</surname><given-names>H</given-names></name>, <name><surname>Pierce</surname><given-names>B</given-names></name>, <name><surname>Mintseris</surname><given-names>J</given-names></name>, <name><surname>Janin</surname><given-names>J</given-names></name>, <name><surname>Weng</surname><given-names>Z</given-names></name>. <article-title>Protein–protein docking benchmark version 3.0.</article-title><source>Proteins: Structure, Function, and Bioinformatics.</source><year>2008</year>;<volume>73</volume>(<issue>3</issue>):<fpage>705</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/prot.22106</pub-id><?supplied-pmid 18491384?><pub-id pub-id-type="pmid">18491384</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref062">
      <label>62</label>
      <mixed-citation publication-type="journal"><name><surname>Mirdita</surname><given-names>M</given-names></name>, <name><surname>Schütze</surname><given-names>K</given-names></name>, <name><surname>Moriwaki</surname><given-names>Y</given-names></name>, <name><surname>Heo</surname><given-names>L</given-names></name>, <name><surname>Ovchinnikov</surname><given-names>S</given-names></name>, <name><surname>Steinegger</surname><given-names>M</given-names></name>. <article-title>ColabFold: making protein folding accessible to all</article-title>. <source>Nature Methods</source>. <year>2022</year>;<volume>19</volume>(<issue>6</issue>):<fpage>679</fpage>–<lpage>82</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41592-022-01488-1</pub-id><?supplied-pmid 35637307?><pub-id pub-id-type="pmid">35637307</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011435.ref063">
      <label>63</label>
      <mixed-citation publication-type="journal"><name><surname>Steinegger</surname><given-names>M</given-names></name>, <name><surname>Söding</surname><given-names>J</given-names></name>. <article-title>MMseqs2 enables sensitive protein sequence searching for the analysis of massive data sets</article-title>. <source>Nature Biotechnology</source>. <year>2017</year>;<volume>35</volume>(<issue>11</issue>):<fpage>1026</fpage>–<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nbt.3988</pub-id><?supplied-pmid 29035372?><pub-id pub-id-type="pmid">29035372</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
