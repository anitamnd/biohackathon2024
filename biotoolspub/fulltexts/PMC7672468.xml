<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Gigascience</journal-id>
    <journal-id journal-id-type="iso-abbrev">Gigascience</journal-id>
    <journal-id journal-id-type="publisher-id">gigascience</journal-id>
    <journal-title-group>
      <journal-title>GigaScience</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2047-217X</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7672468</article-id>
    <article-id pub-id-type="doi">10.1093/gigascience/giaa127</article-id>
    <article-id pub-id-type="publisher-id">giaa127</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Technical Note</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI00960</subject>
        <subject>AcademicSubjects/SCI02254</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>GigaSOM.jl: High-performance clustering and visualization of huge cytometry datasets</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-7356-4075</contrib-id>
        <name>
          <surname>Kratochvíl</surname>
          <given-names>Miroslav</given-names>
        </name>
        <!--<email>markus.ollert@lih.lu</email>-->
        <aff><institution>Institute of Organic Chemistry and Biochemistry</institution>, Flemingovo náměstí 542/2, 160 00 Prague, Czech Republic</aff>
        <aff><institution>Charles University, Department of Software Engineering</institution>, Malostranské náměstí 25, 118 00 Prague, Czech Republic</aff>
        <xref ref-type="corresp" rid="cor1"/>
        <xref ref-type="author-notes" rid="afn1"/>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-5402-5084</contrib-id>
        <name>
          <surname>Hunewald</surname>
          <given-names>Oliver</given-names>
        </name>
        <aff><institution>Luxembourg Institute of Health, Department of Infection and Immunity</institution>, 29 rue Henri Koch, L-4354 Esch-sur-Alzette, <country country="LU">Luxembourg</country></aff>
        <xref ref-type="author-notes" rid="afn1"/>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-1861-0037</contrib-id>
        <name>
          <surname>Heirendt</surname>
          <given-names>Laurent</given-names>
        </name>
        <aff><institution>University of Luxembourg, Luxembourg Centre for Systems Biomedicine</institution>, 6 avenue du Swing, Campus Belval, L-4367 Belvaux, <country country="LU">Luxembourg</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-3884-9125</contrib-id>
        <name>
          <surname>Verissimo</surname>
          <given-names>Vasco</given-names>
        </name>
        <aff><institution>University of Luxembourg, Luxembourg Centre for Systems Biomedicine</institution>, 6 avenue du Swing, Campus Belval, L-4367 Belvaux, <country country="LU">Luxembourg</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-6066-973X</contrib-id>
        <name>
          <surname>Vondrášek</surname>
          <given-names>Jiří</given-names>
        </name>
        <aff><institution>Institute of Organic Chemistry and Biochemistry</institution>, Flemingovo náměstí 542/2, 160 00 Prague, Czech Republic</aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-6532-5880</contrib-id>
        <name>
          <surname>Satagopam</surname>
          <given-names>Venkata P</given-names>
        </name>
        <aff><institution>University of Luxembourg, Luxembourg Centre for Systems Biomedicine</institution>, 6 avenue du Swing, Campus Belval, L-4367 Belvaux, <country country="LU">Luxembourg</country></aff>
        <aff><institution>ELIXIR Luxembourg, University of Luxembourg</institution>, 6, avenue du Swing, Campus Belval, L-4367 Belvaux, <country country="LU">Luxembourg</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-8278-1618</contrib-id>
        <name>
          <surname>Schneider</surname>
          <given-names>Reinhard</given-names>
        </name>
        <aff><institution>University of Luxembourg, Luxembourg Centre for Systems Biomedicine</institution>, 6 avenue du Swing, Campus Belval, L-4367 Belvaux, <country country="LU">Luxembourg</country></aff>
        <aff><institution>ELIXIR Luxembourg, University of Luxembourg</institution>, 6, avenue du Swing, Campus Belval, L-4367 Belvaux, <country country="LU">Luxembourg</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-8991-6810</contrib-id>
        <name>
          <surname>Trefois</surname>
          <given-names>Christophe</given-names>
        </name>
        <aff><institution>University of Luxembourg, Luxembourg Centre for Systems Biomedicine</institution>, 6 avenue du Swing, Campus Belval, L-4367 Belvaux, <country country="LU">Luxembourg</country></aff>
        <aff><institution>ELIXIR Luxembourg, University of Luxembourg</institution>, 6, avenue du Swing, Campus Belval, L-4367 Belvaux, <country country="LU">Luxembourg</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-8055-0103</contrib-id>
        <name>
          <surname>Ollert</surname>
          <given-names>Markus</given-names>
        </name>
        <aff><institution>Luxembourg Institute of Health, Department of Infection and Immunity</institution>, 29 rue Henri Koch, L-4354 Esch-sur-Alzette, <country country="LU">Luxembourg</country></aff>
        <aff><institution>Odense Research Center for Anaphylaxis,</institution>
 <institution content-type="department">Department of Dermatology and Allergy Center, OdenseUniversity Hospital, University of Southern Denmark</institution>, Kløvervænget 15, DK-5000 Odense C,
<country country="DK">Denmark</country></aff>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><bold>Correspondence address</bold>. Markus Ollert, 29, rue Henri Koch L-4354, Esch-sur-Alzette, Luxembourg. Tel.: +352 26970-829. E-mail: <email>markus.ollert@lih.lu</email></corresp>
      <fn id="afn1">
        <p>Contributed equally.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub" iso-8601-date="2020-11-18">
      <day>18</day>
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>18</day>
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>9</volume>
    <issue>11</issue>
    <elocation-id>giaa127</elocation-id>
    <history>
      <date date-type="received">
        <day>03</day>
        <month>8</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>28</day>
        <month>9</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>10</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press GigaScience.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="giaa127.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="abs1">
        <title>Background</title>
        <p>The amount of data generated in large clinical and phenotyping studies that use single-cell cytometry is constantly growing. Recent technological advances allow the easy generation of data with hundreds of millions of single-cell data points with &gt;40 parameters, originating from thousands of individual samples. The analysis of that amount of high-dimensional data becomes demanding in both hardware and software of high-performance computational resources. Current software tools often do not scale to the datasets of such size; users are thus forced to downsample the data to bearable sizes, in turn losing accuracy and ability to detect many underlying complex phenomena.</p>
      </sec>
      <sec id="abs2">
        <title>Results</title>
        <p>We present GigaSOM.jl, a fast and scalable implementation of clustering and dimensionality reduction for flow and mass cytometry data. The implementation of GigaSOM.jl in the high-level and high-performance programming language Julia makes it accessible to the scientific community and allows for efficient handling and processing of datasets with billions of data points using distributed computing infrastructures. We describe the design of GigaSOM.jl, measure its performance and horizontal scaling capability, and showcase the functionality on a large dataset from a recent study.</p>
      </sec>
      <sec id="abs3">
        <title>Conclusions</title>
        <p>GigaSOM.jl facilitates the use of commonly available high-performance computing resources to process the largest available datasets within minutes, while producing results of the same quality as the current state-of-art software. Measurements indicate that the performance scales to much larger datasets. The example use on the data from a massive mouse phenotyping effort confirms the applicability of GigaSOM.jl to huge-scale studies.</p>
      </sec>
    </abstract>
    <kwd-group kwd-group-type="keywords">
      <kwd>high-performance computing</kwd>
      <kwd>single-cell cytometry</kwd>
      <kwd>self-organizing maps</kwd>
      <kwd>clustering</kwd>
      <kwd>dimensionality reduction</kwd>
      <kwd>Julia</kwd>
    </kwd-group>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Department of Forestry and Natural Resources, Purdue University</institution>
            <institution-id institution-id-type="DOI">10.13039/100007869</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Background</title>
    <p>Advances in single-cell technologies, such as mass cytometry, single-cell RNA sequencing, and spectral flow cytometry [<xref rid="bib1" ref-type="bibr">1–3</xref>], provide deep and comprehensive insights into the complex mechanism of cellular systems, such as immune cells in blood, tumor cells and their microenvironments, and various microbiomes, including single-celled marine life ecosystems. Mass cytometry and spectral cytometry have enabled cells to be stained with &gt;40 different markers to discover cellular differences under multiple conditions. The samples collected in recent studies often contain millions of measured cells (events), resulting in large and high-dimensional datasets. Traditional analysis methods, based on manual observation and selection of the clusters in 2D scatter-plots, is becoming increasingly difficult to apply on data of such complexity: for high-dimensional data, this procedure is extremely laborious, and the results often carry researcher or analysis bias [<xref rid="bib4" ref-type="bibr">4</xref>].</p>
    <p>Various dimensionality reduction, clustering, classification, and data mining methods have been used to aid with the semi-automated or fully automated processing, including neural networks [<xref rid="bib5" ref-type="bibr">5</xref>], various rule-based and tree-based classifiers in combination with clustering and visualization [<xref rid="bib6" ref-type="bibr">6</xref>,<xref rid="bib7" ref-type="bibr">7</xref>], or locality-sensitive and density-based statistical approaches [<xref rid="bib8" ref-type="bibr">8</xref>]. However, computational performance of the algorithms, necessary for scaling to larger datasets, is often neglected, and the available analysis software often relies on various simplifications (such as downsampling, which impairs the quality and precision of the result) required to process large datasets in reasonable time without disproportionate hardware requirements.</p>
    <p>To improve the performance, van Gassen et al. [<xref rid="bib9" ref-type="bibr">9</xref>] introduced FlowSOM clustering, based on an algorithm that combines the self-organizing maps (SOMs) by  Kohonen [<xref rid="bib10" ref-type="bibr">10</xref>] and metaclustering [<xref rid="bib11" ref-type="bibr">11</xref>], which allows efficient and accurate clustering of millions of cells [<xref rid="bib12" ref-type="bibr">12</xref>]. FlowSOM is currently available as an R package that has become an essential part of many workflows, analysis pipelines, and software suites, including FlowJo and Cytobank® [<xref rid="bib13" ref-type="bibr">13</xref>]. Despite the advance, the amount of data generated in large research-oriented and clinical studies frequently grows to hundreds of millions of cells, processing of which requires not only the efficiency of the algorithm but also a practical scalable implementation.</p>
    <p>Here, we present GigaSOM.jl, an implementation of SOM-based clustering and dimensionality reduction functionality using the Julia programming language [<xref rid="bib14" ref-type="bibr">14</xref>]. Compared with FlowSOM, GigaSOM.jl provides 2 major improvements: first, it uses computational and memory resources efficiently, enabling it to process datasets of size &gt;10<sup>8</sup> cells on commonly available hardware. Second, the implementation provides horizontal scaling support and can thus utilize large high-performance computing clusters (HPC) to gain improvements in speed and tangible dataset size, allowing datasets with &gt;10<sup>10</sup> cells to be processed in the distributed environment. Additionally, the implementation in Julia is sufficiently high-level to allow easy extensibility and cooperation with other tools in the Julia ecosystem. Several technical limitations imposed by the R-wrapped implementation in the C programming language of FlowSOM are also overcome.</p>
  </sec>
  <sec sec-type="methods" id="sec2">
    <title>Methods</title>
    <p>The Kohonen SOM algorithm [<xref rid="bib10" ref-type="bibr">10</xref>] is a kind of simplified neural network with a single layer equipped with a topology. The task of the SOM training is to assign values to the neurons so that the training dataset is covered by neighborhoods of the neurons, and, at the same time, that the topology of the neurons is preserved in the trained network. A 2D grid is one of the most commonly used topologies because it simplifies interpretation of the results as neuron values positioned in the 2D space, and related visualization purposes (e.g., EmbedSOM [<xref rid="bib15" ref-type="bibr">15</xref>]). At the same time, the trained network can serve as a simple clustering of the input dataset, classifying each data point to its nearest neuron.</p>
    <sec id="sec2-1">
      <title>Batch SOM training</title>
      <p>The original SOM training algorithm was introduced by  Kohonen [<xref rid="bib16" ref-type="bibr">16</xref>]. The map is organized as a collection of randomly initialized vectors called “codebook," with weights <italic>W</italic>(1). The training proceeds in iterations (indexed by time <italic>t</italic>), where in each iteration a randomly selected data point in the dataset is used to produce an updated codebook as
<disp-formula><tex-math id="M1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}
{W_i(t+1) = W_i(t) + \alpha (t)h(t)\odot \left[x - W_i(t)\right]},
\end{equation*}$$\end{document}</tex-math></disp-formula>where α is the learning rate parameter, <italic>i</italic> is the neuron nearest to the randomly selected data point <italic>x</italic>, and <italic>h</italic> is the vector of topological distances of the codebook vectors to the best matching unit. The learning has been shown to converge after a predictable number of iterations if <italic>α</italic> and topological neighborhood size in <italic>h</italic> are gradually decreased [<xref rid="bib10" ref-type="bibr">10</xref>].</p>
      <p>A more scalable variant of the algorithm can be obtained by running the single updates in batches where the values of <italic>x</italic> are taken from the whole dataset at once, which can be expressed in matrix form
<disp-formula><tex-math id="M2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}
W(t+1) = \hat{H}(t)\cdot \mathcal {N}(X,W(t))\cdot X,
\end{equation*}$$\end{document}</tex-math></disp-formula>where <inline-formula><tex-math id="M3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\mathcal {N}(X,W(t))$\end{document}</tex-math></inline-formula> is a binary matrix that contains 1 at position <italic>i, j</italic> if and only if <italic>W<sub>i</sub></italic>(<italic>t</italic>) is the closest codebook vector to <italic>X<sub>j</sub></italic>, and <inline-formula><tex-math id="M4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\hat{H}(t)$\end{document}</tex-math></inline-formula> is a distance matrix of the codebook in 2D map topology with rows scaled to sum 1. Notably, the algorithm converges in the same cases as the online version [<xref rid="bib17" ref-type="bibr">17</xref>] and may be viewed as a generalized version of <italic>k</italic>-means clustering, which is obtained by setting <italic>H</italic>(<italic>t</italic>) = <italic>I</italic>.</p>
      <p>Implementations of the batch training may rely on several assumptions that are not available with the online training:</p>
      <list list-type="bullet">
        <list-item>
          <p>computation of <inline-formula><tex-math id="M5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\mathcal {N}$\end{document}</tex-math></inline-formula> can use a pre-built spatial indexing structure on <italic>W</italic>(<italic>t</italic>), which is constant for the whole batch;</p>
        </list-item>
        <list-item>
          <p>all computations involving <italic>X</italic> can be sliced and parallelized (moreover, because the accesses to <italic>X</italic> are not randomized, the implementation is more cache-efficient and more suitable for SIMD- and GPU-based acceleration);</p>
        </list-item>
        <list-item>
          <p>multiplication by <inline-formula><tex-math id="M6">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\hat{H}(t)$\end{document}</tex-math></inline-formula> can be associatively postponed to work only with the small codebook matrix, saving &gt;50% required computation volume when compared with online training with large neighborhoods.</p>
        </list-item>
      </list>
    </sec>
    <sec id="sec2-2">
      <title>Distributed implementation of GigaSOM.jl</title>
      <p>The GigaSOM.jl package is a flexible, horizontally scalable, HPC-aware version of the batch SOM training written in the Julia programming language. The language choice has allowed a reasonably high-level description of the problem suitable for easy customization, while still supporting the efficient low-level operations necessary for fast data processing. GigaSOM.jl contains a library of functions for loading the data from Flow Cytometry Standard (FCS) files, distributing the data across a network to remote computation nodes present in the cluster, running the parallelized computation, and exporting and visualizing the results. The overall design of the main implemented operations is outlined in Fig. <xref ref-type="fig" rid="fig1">1</xref>. Example Julia code that executes the distributed operations is provided in <xref ref-type="supplementary-material" rid="sup8">Supplementary Listing S1</xref>.</p>
      <fig id="fig1" orientation="portrait" position="float">
        <label>Figure 1</label>
        <caption>
          <p>Architecture of GigaSOM.jl. <italic>Top:</italic> Data distribution process divides the available FCS files into balanced slices; individual workers retrieve their respective slice data using a shared storage. <italic>Bottom:</italic>The SOM learning and visualization processes require only a minimal amount of data to be transferred between the master and worker nodes, consisting of the relatively small codebook in the case of SOM learning (blue arrows) and pre-rasterized graphics in the case of visualization (green arrows).</p>
        </caption>
        <graphic xlink:href="giaa127fig1"/>
      </fig>
      <sec id="sec2-2-1">
        <title>Data distribution procedure</title>
        <p>The distributed computation process in GigaSOM is structured such that each computation node (“worker”) keeps its own, persistent slice of the whole dataset, and the partial results from the nodes are aggregated by the master node. To establish this structure, GigaSOM implements a separate procedure that aggregates the input FCS files and creates a balanced set of slices equally distributed among the workers.</p>
        <p>The distribution procedure is implemented as illustrated in Fig. <xref ref-type="fig" rid="fig1">1</xref> (top): First, the master node reads the headers and sizes of individual FCS files, verifying their structure and determining the total number of stored data points. This is used to create minimal descriptions of dataset slices of equal size (each description consists only of 4 numbers of the first and last file and the first and last data point index), which are transferred to individual workers. Each worker interprets its assigned slice description and extracts the part of the data from the relevant FCS files saved on a shared storage. The resulting slices may be easily exported to the storage and quickly imported again by individual workers, thus saving time if multiple analyses run on the same data (e.g., in case of several clustering and embedding runs with different parameters).</p>
        <p>Importantly, a shared filesystem is usually one of the most efficient ways to perform data transfers in HPC environments, which makes the dataset loading process relatively fast. If a shared filesystem is not available, GigaSOM.jl also includes optional support for direct data distribution using the Distributed.jl package.</p>
      </sec>
      <sec id="sec2-2-2">
        <title>Batch SOM implementation</title>
        <p>After the nodes are equipped with the data slices, the batch SOM training proceeds as illustrated in Fig. <xref ref-type="fig" rid="fig1">1</xref> (bottom):</p>
        <list list-type="order">
          <list-item>
            <p>The master node initializes the SOM codebook (usually by random sampling from available data).</p>
          </list-item>
          <list-item>
            <p>The codebook is broadcast to all worker nodes. Because the size of the usual codebook is at most several tens of kilobytes, data transfer speed does not represent a performance bottleneck in this case.</p>
          </list-item>
          <list-item>
            <p>The workers calculate a partial codebook update on their data and send the results back to the master node.</p>
          </list-item>
          <list-item>
            <p>Finally, the master node gathers the individual updates, multiplies the collected result by <inline-formula><tex-math id="M7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\hat{H}(t)$\end{document}</tex-math></inline-formula>, and continues with another iteration from step 2 if necessary.</p>
          </list-item>
        </list>
        <p>The time required to perform 1 iteration of the SOM training is mainly derived from the speed of the codebook transfer between nodes, and the amount of computation done by individual nodes. The current GigaSOM.jl implementation transfers all codebook versions directly between the master node and the workers, giving time complexity <inline-formula><tex-math id="M8">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\mathcal {O}(b)+\mathcal {O}(n/c)$\end{document}</tex-math></inline-formula> for <italic>b</italic> computation nodes equipped with <italic>c</italic> CPUs working on a dataset of size <italic>n</italic>. This complexity can be improved to <inline-formula><tex-math id="M9">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\mathcal {O}(\log _2 b)+\mathcal {O}(n/c)$\end{document}</tex-math></inline-formula> by using efficient algorithms for parallel data broadcast and reduction, but we have not found a realistic dataset of size sufficient to gain any benefit from such optimization.</p>
      </sec>
      <sec id="sec2-2-3">
        <title>Implementation methodology</title>
        <p>The GigaSOM.jl implementation of the batch SOM algorithm follows a similar structure as reported by other authors [<xref rid="bib18" ref-type="bibr">18–20</xref>]. All distributed computations are expressed as a series of MapReduce-style operations [<xref rid="bib21" ref-type="bibr">21</xref>], which are implemented as high-order functions. This has allowed us to clearly separate the low-level code required to support the parallel processing from the actual implementation of algorithms, and thus improve the code maintainability and vastly simplify further custom, user-specifiable data manipulation in the distributed environment. This abstraction additionally enables future transition to more complex data-handling routines or different parallelization systems. GigaSOM.jl can be transparently modified to support distributed parallel broadcast and reduction that might be required for handling huge SOMs on a very large number of workers (Collange et al. [<xref rid="bib22" ref-type="bibr">22</xref>] provide a comprehensive discussion on that topic), or even run on a different distributed framework, such as the industry-standard MPI [<xref rid="bib23" ref-type="bibr">23</xref>].</p>
        <p>Our choice of the Julia programming environment was mainly motivated by making this abstraction as efficient as possible—the relatively high-level Julia code is compiled into efficient low-level bytecode, which enables high algorithm execution performance without modifying the code to work with any specialized performance-supporting primitives. This benefit is rarely available in popular high-level programming environments: e.g., many approaches for distributed computation exist in R (R Project for Statistical Computing, <ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/RRID:SCR_001905">RRID:SCR_001905</ext-link>) [<xref rid="bib24" ref-type="bibr">24</xref>], such as GridR [<xref rid="bib25" ref-type="bibr">25</xref>], DistributedR, ddR, and sparklyr (for Apache Spark) (Apache Spark, <ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_016557">RRID:SCR_016557</ext-link>) [<xref rid="bib26" ref-type="bibr">26</xref>], but most of the projects unfortunately did not achieve general adoption or have been abandoned. Python libraries provide good support for optimized execution of specialized operations; parallel and distributed computing is supported, e.g., by the Dask project [<xref rid="bib27" ref-type="bibr">27</xref>], with similar mode of use as the distributed processing tools in Julia. Despite that, producing efficient Python code requires careful consideration and utilization of the low-level array processing primitives (such as NumPy) (NumPy, <ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_008633">RRID:SCR_008633</ext-link>) [<xref rid="bib28" ref-type="bibr">28</xref>], often by representing the algorithms using only the available optimized matrix operations, which are elusive for non-mathematicians.</p>
      </sec>
      <sec id="sec2-2-4">
        <title>Spatial indexing</title>
        <p>Because the most computationally expensive step of the SOM training is the search for nearest codebook vectors for each dataset item (i.e., construction of the matrix <inline-formula><tex-math id="M10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\mathcal {N}$\end{document}</tex-math></inline-formula>), we have evaluated the use of spatial indexing structures for accelerating this operation. GigaSOM.jl implementation can use the structures available in the package NearestNeighbors.jl, which include kd-trees and ball trees (also called vantage-point trees). [<xref rid="bib29" ref-type="bibr">29</xref>,<xref rid="bib30" ref-type="bibr">30</xref>]</p>
        <p>Although the efficiency of spatial indexing is vastly reduced with increasing dataset dimensionality, the measurements in section Results show that it can provide significant speedup with very large SOMs, even on data with &gt;20 dimensions.</p>
      </sec>
      <sec id="sec2-2-5">
        <title>Visualization support</title>
        <p>To simplify visualization of the results, GigaSOM.jl includes a parallel reimplementation of the EmbedSOM algorithm in Julia [<xref rid="bib15" ref-type="bibr">15</xref>], which quickly provides interpretable visualizations of the cell distribution within the datasets. EmbedSOM computes an embedding of the cells to 2D space, similarly as the popular t-SNE or UMAP algorithms [<xref rid="bib31" ref-type="bibr">31</xref>,<xref rid="bib32" ref-type="bibr">32</xref>]. Unlike the usual dimensionality reduction algorithms, it uses the constructed SOM as a guiding manifold for positioning the individual points into the low-dimensional space, and achieves linear time complexity in the size of the dataset. The parallel implementation of EmbedSOM is built upon the same distributed data framework as the batch SOMs—because EmbedSOM is designed to be trivially parallelizable, it can be run directly on the individual data slices and gain the same speedup from parallel processing.</p>
        <p>To aid the plotting of the EmbedSOM output, we have additionally implemented a custom scatterplot rasterizer in package GigaScatter.jl, which includes functions for quick plotting of large amounts of low-α points. To enable plotting of exceedingly large datasets, the rasterization can be executed in a distributed manner within the MapReduce framework, as shown in <xref ref-type="supplementary-material" rid="sup8">Supplementary Listing S1</xref>.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results" id="sec3">
    <title>Results</title>
    <p>The main result achieved by GigaSOM is the ability to quickly cluster and visualize datasets of previously unreachable size. In particular, we show that construction of a SOM from 10<sup>9</sup> cells with 40 parameters can be performed in minutes, even on relatively small compute clusters with less than hundreds of CPU cores. The SOM can be used to quickly dissect and analyze the samples, as with FlowSOM [<xref rid="bib9" ref-type="bibr">9</xref>]. This performance achievement vastly simplifies the interactive work with large datasets because the scientists can, for instance, try more combinations of hyperparameters and quickly get the feedback to improve the analysis and clustering of the data.</p>
    <p>In this section, we first compare the output of GigaSOM.jl to that of FlowSOM, showing that the change in the SOM training algorithm has minimal impact on the quality of results. Furthermore, we provide benchmark results that confirm that GigaSOM.jl scales horizontally, and details of the speedup achievable by employing spatial indexing data structures for acceleration of the nearest-neighbor queries. Finally, we demonstrate the results that can be achieved by processing a gigascale dataset from a recent study by the International Mouse Phenotyping Consortium (IMPC) [<xref rid="bib33" ref-type="bibr">33</xref>].</p>
    <p>The presented performance benchmarks were executed on a Slurm-managed HPC cluster equipped with Intel®Xeon®E5-2650 CPUs, each node with 2 physical CPUs (total 24 cores) and 128 GB of RAM. All benchmarks were executed several times; the times were measured as “real" (wall-clock) time using the standard Julia timer facility. Measurements of the first runs were discarded to prevent the influence of caching and Julia just-in-time compilation; remaining results were reduced to medians.</p>
    <sec id="sec3-1">
      <title>Validation of clustering quality</title>
      <p>To compare the GigaSOM.jl output with that from FlowSOM (FlowSOM, <ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resources/Tools/record/nlx_144509-1/SCR_016899/resolver">RRID:SCR_016899</ext-link>) [<xref rid="bib9" ref-type="bibr">9</xref>], we used a methodology similar to the one used by Weber and Robinson [<xref rid="bib12" ref-type="bibr">12</xref>]. The datasets were first processed by the clustering algorithms to generate clusters, which were then assigned to ground truth populations so that the coverage of individual populations by clusters was reasonably high. The mean F1 score was then computed between the aggregated clusters and ground truth. Unlike Weber and Robinson [<xref rid="bib12" ref-type="bibr">12</xref>], who use a complex method of cluster assignment optimization to find the assignment that produces the best possible mean F1 score, we used a simpler (and arguably more realistic) greedy algorithm that assigns each generated cluster to a population with the greatest part covered by that cluster.</p>
      <p>The benchmark did not consider FlowSOM metaclustering [<xref rid="bib9" ref-type="bibr">9</xref>] because the comparison primarily aimed to detect the differences caused by the modifications in SOM training.</p>
      <p>For the comparison, we reused the datasets Levine13 and Levine32 from the clustering benchmark [<xref rid="bib12" ref-type="bibr">12</xref>]. In a typical outcome, most populations were matched by GigaSOM.jl just as well as by FlowSOM, as displayed in Fig. <xref ref-type="fig" rid="fig2">2</xref> (detailed view is available in <xref ref-type="supplementary-material" rid="sup8">Supplementary Fig. S1</xref>). Both methods consistently achieved mean F1 scores in the range of 0.65–0.70 on the Levine13 dataset and 0.81–0.84 on the Levine32 dataset for a wide range of reasonable parameter settings. In the tests, neither algorithm showed a significantly better resulting mean F1 score.</p>
      <fig id="fig2" orientation="portrait" position="float">
        <label>Figure 2</label>
        <caption>
          <p>Comparison of GigaSOM.jl results with manual gating of the Levine32 dataset. The confusion matrix is normalized in rows, showing the ratio of cells in each aggregate of GigaSOM-originating clusters that matches the cell types from manual analysis. Darker color represents better match. The mean F1 score is comparable to FlowSOM. A more comprehensive comparison is available in <xref ref-type="supplementary-material" rid="sup8">Supplementary Fig. S1</xref>.</p>
        </caption>
        <graphic xlink:href="giaa127fig2"/>
      </fig>
    </sec>
    <sec id="sec3-2">
      <title>Scalable performance on large computer clusters</title>
      <p>The benchmark of implementation scalability was performed as follows: a randomly generated dataset was distributed among the available computation nodes (workers) so that all CPUs are assigned an equal amount of data. For the benchmark, node counts as powers of 2 up to 256 have been chosen while the numbers of dataset parameters were chosen from multiples of 10 up to 50. The size of the dataset slice for a single node varied between 100,000, 200,000, and 300,000 cells to verify the impact of data density in cluster. The dataset was then processed by the SOM training algorithm for SOM sizes 10 × 10, 20 × 20, and 40 × 40. The resulting SOMs were used for classifying the dataset into clusters (each input data point was assigned to a cluster defined by the nearest neighbor). An embedded view of the data was produced with the Julia implementation of EmbedSOM. All algorithms were also tested in variants where the naive search for nearest neighbors (or <italic>k</italic>-neighborhoods in the case of EmbedSOM) was replaced by utilization of a spatial-indexing data structure, in particular by the kd-trees and ball-trees.</p>
      <p>The scalability results are summarized in Fig. <xref ref-type="fig" rid="fig3">3</xref>: all 3 implemented algorithms scale almost linearly with the dataset size, the size of the SOM, and the dimension of the dataset. They reach an almost linear speedup with added compute capacity. In the case of SOM training, the required communication among the nodes caused only a negligible overhead; the majority of the computation pauses was caused by the random variance in execution time of computation steps on the nodes. The parallelized classification and embedding algorithms were not impaired by any communication overhead. Detailed benchmark results that show precise energy requirements of the training per processed data point, useful for deployment in large environments, are available in <xref ref-type="supplementary-material" rid="sup8">Supplementary Fig. S2</xref>.</p>
      <fig id="fig3" orientation="portrait" position="float">
        <label>Figure 3</label>
        <caption>
          <p>Performance dependency of distributed algorithms in GigaSOM on data dimensionality, SOM size, and number of available workers. Data processing performance is displayed as normalized to median speed in cells per second (c/s).</p>
        </caption>
        <graphic xlink:href="giaa127fig3"/>
      </fig>
      <p>Influence of the spatial indexing on the speed of various operations was collected as relative speedups (or slowdowns) when compared to a naive search. The results are displayed in Fig. <xref ref-type="fig" rid="fig4">4</xref>. We have observed that both kd-trees and ball-trees were able to accelerate some operations by a factor &gt;2×, but the use of spatial indexing was hindered by many trade-offs that often caused decreased performance.</p>
      <fig id="fig4" orientation="portrait" position="float">
        <label>Figure 4</label>
        <caption>
          <p>Effect of data-indexing structures on GigaSOM performance. The plotted points show relative speedup of the algorithms utilizing kd-trees (horizontal axis) and ball-trees (vertical axis) compared with brute-force neighbor search. Baseline (1× speedup) is highlighted by thick grid lines—a point plotted in the upper right quadrant represents a benchmark measurement that showed speedup for both kd-trees and ball-trees, upper left quadrant contains benchmark results where ball-trees provided speedup and kd-trees slowed the computation down, etc.</p>
        </caption>
        <graphic xlink:href="giaa127fig4"/>
      </fig>
      <p>Most importantly, the cost of building the index often surpassed the total cost of neighborhood lookups by the naive method, which is most easily observable on the measurements of ball-tree performance with smaller SOM sizes. Both trees struggled to provide sufficient speedup in the presence of higher-dimensionality overhead (&gt;30) and had only negligible impact on the execution time of EmbedSOM computation, which was dominated by other operations.</p>
      <p>On the other hand, it was easily possible to gain speedups ∼1.5× for SOM training in most tests with lower dimension and large SOM, reaching 2.7× for a 20-dimensional dataset (typical for current flow cytometry) processed with large 40 × 40 SOM. From the results, it seems appropriate to use the spatial indexing when the cost of other operations outweighs the cost of building the index, and the dimensionality overhead does not impede the efficiency of indexed lookup—in particular when training large SOMs of dimensionality &lt;∼30, and when data occupancy per node is sufficiently high. Detailed measurements for all SOM sizes and dataset dimensions are available in <xref ref-type="supplementary-material" rid="sup8">Supplementary Fig. S3</xref>.</p>
    </sec>
    <sec id="sec3-3">
      <title>HPC analysis of previously unreachable dataset sizes</title>
      <p>To showcase the GigaSOM.jl functionality on a realistic dataset, we have used a large dataset from the IMPC phenotyping effort [<xref rid="bib33" ref-type="bibr">33</xref>] that contains measurements of mouse spleens by a standardized T-cell targeting panel, with individual cohorts containing genetically modified animals (typically a single-gene knockout) and controls; total 2,905 samples contain 1,167,129,317 individual cells. (The dataset is available from FlowRepository under the accession ID <monospace>FR-FCM-ZYX9</monospace>.)</p>
      <p>The dataset was intentionally prepared by a very simple process—cell expressions were compensated, fluorescent marker expressions were transformed by the common asinh transformation with co-factor 500, and all dataset columns were scaled to μ = 0 and σ = 1. The resulting data were used to train a 32 × 32 SOM, which was in turn used to produce the embedding of the dataset (with EmbedSOM parameter <italic>k</italic> = 16), which was rasterized. The final result can be observed in Fig. <xref ref-type="fig" rid="fig5">5</xref>. The detailed workflow is shown in <xref ref-type="supplementary-material" rid="sup8">Supplementary Listing S1</xref>.</p>
      <fig id="fig5" orientation="portrait" position="float">
        <label>Figure 5</label>
        <caption>
          <p>Raw IMPC Spleen T-cell dataset, processed by GigaSOM.jl and embedded by the Julia implementation of EmbedSOM. The figure shows an aggregate of 1,167,129,317 individual cells. Expression of 3 main markers is displayed in combination as mixed colors: CD8 in red, CD4 in green, and CD161 in blue. A more detailed, annotated version of the visualization is available in <xref ref-type="supplementary-material" rid="sup8">Supplementary Fig. S4</xref>.</p>
        </caption>
        <graphic xlink:href="giaa127fig5"/>
      </fig>
      <p>Notably, on a relatively small 256-core computer cluster (total 11 server nodes within a larger cluster managed by Slurm), the whole operation, consisting of Julia initialization, data loading (82.6 GB of FCS files), SOM training for 30 epochs, embedding, and export of embedded data (17.4 GB), took slightly &lt;25 minutes and consumed at most 3 GB of RAM per core. From that, each epoch of the parallelized SOM training took ∼25 seconds, and the computation of EmbedSOM visualization took 3 minutes. Distributed plotting of the result was performed using the GigaScatter.jl package; the parallel rasterization and combination of partial rasters took slightly &gt;4 minutes.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec4">
    <title>Conclusions</title>
    <p>In this article, we presented the functionality of GigaSOM.jl, a new, highly scalable toolkit for analyzing cytometry data with algorithms derived from SOMs. The results conclusively show that GigaSOM.jl will support the growing demand for processing of huge datasets, and bolster the utilization of the HPC hardware resources that are becoming widely available for laboratories and universities.</p>
    <p>The ability to process a gigascale dataset to a comprehensible embedding and precise, easily scrutinizable statistics in mere minutes may play a crucial role in both design and analysis methods of future cytometry experiments. We believe that the accessible and flexible nature of the GigaSOM.jl implementation in the Julia programming language will also drive a transformation of other tools in the ecosystem towards the support of big data processing paradigms.</p>
    <p>The resulting software is publicly available as a Julia package. The interoperability with the Julia ecosystem allows GigaSOM.jl to benefit from many other available scientific computing packages, which simplifies its deployment not only in cytometry but also in other areas of research that use SOMs to extract information from large datasets.</p>
  </sec>
  <sec id="sec5">
    <title>Availability of Source Code and Requirements</title>
    <p>All software is available under <ext-link ext-link-type="doi" xlink:href="10.17881/lcsb.z5vy-fa75">https://doi.org/10.17881/lcsb.z5vy-fa75</ext-link>.</p>
    <list list-type="bullet">
      <list-item>
        <p>Package name: GigaSOM.jl</p>
      </list-item>
      <list-item>
        <p>Package home page: <ext-link ext-link-type="uri" xlink:href="https://git.io/GigaSOM.jl">https://git.io/GigaSOM.jl</ext-link></p>
      </list-item>
      <list-item>
        <p>Operating system(s): Portable to all Julia-supported platforms</p>
      </list-item>
      <list-item>
        <p>Programming language: Julia</p>
      </list-item>
      <list-item>
        <p>License: Apache License v2.0</p>
      </list-item>
      <list-item>
        <p>Julia package registry name: GigaSOM</p>
      </list-item>
      <list-item>
        <p>bio.tools ID: <monospace>biotools:GigaSOM.jl</monospace></p>
      </list-item>
      <list-item>
        <p>
          <ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/scicrunch/Resources/record/nlx_144509-1/SCR_019020/resolver">RRID:SCR_019020</ext-link>
        </p>
      </list-item>
    </list>
  </sec>
  <sec sec-type="materials" id="h1content1604085979581">
    <title>Availability of Supporting Data and Materials</title>
    <p>All supporting data and materials are available in the <italic>GigaScience</italic> GigaDB database [<xref rid="bib34" ref-type="bibr">34</xref>].</p>
  </sec>
  <sec id="sec6">
    <title>Abbreviations</title>
    <p>CPU: central processing unit; FCS: Flow Cytometry Standard; GPU: graphics processing unit; HPC: high-performance computing; IMPC: International Mouse Phenotyping Consortium; MPI: Message Passing Interface; RAM: random access memory; SIMD: single instruction, multiple data; SOM: self-organizing map; t-SNE: <italic>t</italic>-distributed stochastic neighbor embedding; UMAP: Uniform Manifold Approximation and Projection.</p>
  </sec>
  <sec id="h1content1604066709866">
    <title>Competing Interests</title>
    <p>The authors declare that they have no competing interests.</p>
  </sec>
  <sec id="h1content1604066698563">
    <title>Funding</title>
    <p>M.K. and J.V. were supported by ELIXIR CZ LM2018131 (MEYS).</p>
    <p>This work was supported by the Luxembourg National Research Fund (FNR) through the FNR AFR-RIKEN bilateral program (TregBar 2015/11228353) to M.O., and the FNR PRIDE Doctoral Training Unit program (PRIDE/11012546/NEXTIMMUNE) to V.V., R.S., and M.O.</p>
    <p>Funding for open access publication was provided by the Institute of Organic Chemistry and Biochemistry of the CAS (RVO: 61388963).</p>
    <p>The Responsible and Reproducible Research (R3) team of the Luxembourg Centre for Systems Biomedicine is acknowledged for supporting the project and promoting reproducible research.</p>
    <p>The experiments presented in this article were carried out using the HPC facilities of the University of Luxembourg [<xref rid="bib35" ref-type="bibr">35</xref>] (see <ext-link ext-link-type="uri" xlink:href="https://hpc.uni.lu">https://hpc.uni.lu</ext-link>).</p>
    <p>The project was supported by Staff Exchange programme of ELIXIR, the European life-sciences infrastructure.</p>
  </sec>
  <sec id="h1content1604066752346">
    <title>Authors' Contributions</title>
    <p>Conceptualization: O.H., L.H., C.T. Formal analysis, investigation, methodology: O.H., M.K., L.H. Software: O.H., M.K., L.H., V.V. Funding acquisition, supervision: J.V., V.P.S., R.S., C.T., M.O. Validation: O.H., M.K. Visualization: M.K. Writing: O.H., M.K. All authors participated in reviewing, editing, and finalization of the manuscript.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>giaa127_GIGA-D-20-00228_Original_Submission</label>
      <media xlink:href="giaa127_giga-d-20-00228_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup2">
      <label>giaa127_GIGA-D-20-00228_Revision_1</label>
      <media xlink:href="giaa127_giga-d-20-00228_revision_1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup3">
      <label>giaa127_GIGA-D-20-00228_Revision_2</label>
      <media xlink:href="giaa127_giga-d-20-00228_revision_2.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup4">
      <label>giaa127_Response_to_Reviewer_Comments_Original_Submission</label>
      <media xlink:href="giaa127_response_to_reviewer_comments_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup5">
      <label>giaa127_Response_to_Reviewer_Comments_Revision_1</label>
      <media xlink:href="giaa127_response_to_reviewer_comments_revision_1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup6">
      <label>giaa127_Reviewer_1_Report_Original_Submission</label>
      <media xlink:href="giaa127_reviewer_1_report_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup7">
      <label>giaa127_Reviewer_2_Report_Original_Submission</label>
      <media xlink:href="giaa127_reviewer_2_report_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup8">
      <label>giaa127_Supplemental_File</label>
      <media xlink:href="giaa127_supplemental_file.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="bib1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bandura</surname><given-names>DR</given-names></name>, <name name-style="western"><surname>Baranov</surname><given-names>VI</given-names></name>, <name name-style="western"><surname>Ornatsky</surname><given-names>OI</given-names></name>, <etal>et al.</etal></person-group>  <article-title>Mass cytometry: technique for real time single cell multitarget immunoassay based on inductively coupled plasma time-of-flight mass spectrometry</article-title>. <source>Anal Chem</source>. <year>2009</year>;<volume>81</volume>(<issue>16</issue>):<fpage>6813</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">19601617</pub-id></mixed-citation>
    </ref>
    <ref id="bib2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jaitin</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Kenigsberg</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Keren-Shaul</surname><given-names>H</given-names></name>, <etal>et al.</etal></person-group>  <article-title>Massively parallel single-cell RNA-Seq for marker-free decomposition of tissues into cell types</article-title>. <source>Science</source>. <year>2014</year>;<volume>343</volume>(<issue>6172</issue>):<fpage>776</fpage>–<lpage>79</lpage>.<pub-id pub-id-type="pmid">24531970</pub-id></mixed-citation>
    </ref>
    <ref id="bib3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schmutz</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Valente</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Cumano</surname><given-names>A</given-names></name>, <etal>et al.</etal></person-group>  <article-title>Spectral cytometry has unique properties allowing multicolor analysis of cell suspensions isolated from solid tissues</article-title>. <source>PLoS One</source>. <year>2016</year>;<volume>11</volume>(<issue>8</issue>):<fpage>e0159961</fpage>.<pub-id pub-id-type="pmid">27500930</pub-id></mixed-citation>
    </ref>
    <ref id="bib4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mair</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Hartmann</surname><given-names>FJ</given-names></name>, <name name-style="western"><surname>Mrdjen</surname><given-names>D</given-names></name>, <etal>et al.</etal></person-group>  <article-title>The end of gating? An introduction to automated analysis of high dimensional cytometry data</article-title>. <source>Eur J Immunol</source>. <year>2016</year>;<volume>46</volume>(<issue>1</issue>):<fpage>34</fpage>–<lpage>43</lpage>.<pub-id pub-id-type="pmid">26548301</pub-id></mixed-citation>
    </ref>
    <ref id="bib5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Arvaniti</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Claassen</surname><given-names>M</given-names></name></person-group><article-title>Sensitive detection of rare disease-associated cell subsets via representation learning</article-title>. <source>Nat Commun</source>. <year>2017</year>;<volume>8</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">28232747</pub-id></mixed-citation>
    </ref>
    <ref id="bib6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bruggner</surname><given-names>RV</given-names></name>, <name name-style="western"><surname>Bodenmiller</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Dill</surname><given-names>DL</given-names></name>, <etal>et al.</etal></person-group>  <article-title>Automated identification of stratifying signatures in cellular subpopulations</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2014</year>;<volume>111</volume>(<issue>26</issue>):<fpage>E2770</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">24979804</pub-id></mixed-citation>
    </ref>
    <ref id="bib7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Qiu</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Simonds</surname><given-names>EF</given-names></name>, <name name-style="western"><surname>Bendall</surname><given-names>SC</given-names></name>, <etal>et al.</etal></person-group>  <article-title>Extracting a Cellular Hierarchy from High-dimensional Cytometry Data with SPADE</article-title>. <source>Nat Biotechnol</source>. <year>2011</year>;<volume>29</volume>(<issue>10</issue>):<fpage>886</fpage>–<lpage>91</lpage>.<pub-id pub-id-type="pmid">21964415</pub-id></mixed-citation>
    </ref>
    <ref id="bib8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lun</surname><given-names>ATL</given-names></name>, <name name-style="western"><surname>Richard</surname><given-names>AC</given-names></name>, <name name-style="western"><surname>Marioni</surname><given-names>JC</given-names></name></person-group><article-title>Testing for differential abundance in mass cytometry data</article-title>. <source>Nat Methods</source>. <year>2017</year>;<volume>14</volume>(<issue>7</issue>):<fpage>707</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">28504682</pub-id></mixed-citation>
    </ref>
    <ref id="bib9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>van Gassen</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Callebaut</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Helden</surname><given-names>MJV</given-names></name>, <etal>et al.</etal></person-group>  <article-title>FlowSOM: Using self-organizing maps for visualization and interpretation of cytometry data</article-title>. <source>Cytometry Part A</source>. <year>2015</year>;<volume>87</volume>(<issue>7</issue>):<fpage>636</fpage>–<lpage>45</lpage>.</mixed-citation>
    </ref>
    <ref id="bib10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kohonen</surname><given-names>T</given-names></name></person-group><article-title>Essentials of the self-organizing map</article-title>. <source>Neural Netw</source>. <year>2013</year>;<volume>37</volume>:<fpage>52</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">23067803</pub-id></mixed-citation>
    </ref>
    <ref id="bib11">
      <label>11.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Caruana</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Elhawary</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Nguyen</surname><given-names>N</given-names></name>, <etal>et al.</etal></person-group>  <article-title>Meta Clustering</article-title>. In: <source>Sixth International Conference on Data Mining (ICDM’06)</source>; <year>2006</year>:<fpage>107</fpage>–<lpage>18</lpage>.</mixed-citation>
    </ref>
    <ref id="bib12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Weber</surname><given-names>LM</given-names></name>, <name name-style="western"><surname>Robinson</surname><given-names>MD</given-names></name></person-group><article-title>Comparison of clustering methods for high-dimensional single-cell flow and mass cytometry data</article-title>. <source>Cytometry Part A</source>. <year>2016</year>;<volume>89</volume>(<issue>12</issue>):<fpage>1084</fpage>–<lpage>96</lpage>.. <pub-id pub-id-type="doi">10.1002/cyto.a.23030</pub-id>.</mixed-citation>
    </ref>
    <ref id="bib13">
      <label>13.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>TJ</given-names></name>, <name name-style="western"><surname>Kotecha</surname><given-names>N</given-names></name></person-group><article-title>Cytobank: Providing an analytics platform for community cytometry data analysis and collaboration</article-title>, <person-group person-group-type="editor"><name name-style="western"><surname>Fienberg</surname><given-names>HG</given-names></name>, <name name-style="western"><surname>Nolan</surname><given-names>P</given-names></name></person-group> In: <source>High-Dimensional Single Cell Analysis</source>. <publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2014</year>:<fpage>127</fpage>–<lpage>57</lpage>.</mixed-citation>
    </ref>
    <ref id="bib14">
      <label>14.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Bezanson</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Edelman</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Karpinski</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Shah</surname><given-names>VB</given-names></name></person-group>, <article-title>Julia: A fresh approach to numerical computing</article-title>, <source>SIAM review</source>. <year>2017</year>;<volume>59</volume>(<issue>1)</issue>:<fpage>65</fpage>–<lpage>98</lpage>., <publisher-name>SIAM</publisher-name>.</mixed-citation>
    </ref>
    <ref id="bib15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kratochvíl</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Koladiya</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Vondrášek</surname><given-names>J</given-names></name></person-group><article-title>Generalized EmbedSOM on quadtree-structured self-organizing maps</article-title>. <source>F1000Res</source>. <year>2019</year>;<volume>8</volume>:<fpage>2120</fpage>.<pub-id pub-id-type="pmid">32518625</pub-id></mixed-citation>
    </ref>
    <ref id="bib16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kohonen</surname><given-names>T</given-names></name></person-group><article-title>Self-organized formation of topologically correct feature maps</article-title>. <source>Biological Cybernetics</source>. <year>1982</year>;<volume>43</volume>(<issue>1</issue>):<fpage>59</fpage>–<lpage>69</lpage>.. <comment><ext-link ext-link-type="uri" xlink:href="http://link.springer.com/10.1007/BF00337288">http://link.springer.com/10.1007/BF00337288</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cheng</surname><given-names>Y</given-names></name></person-group><article-title>Convergence and Ordering of Kohonen’s Batch Map</article-title>. <source>Neural Comput</source>. <year>1997</year>;<volume>9</volume>(<issue>8</issue>):<fpage>1667</fpage>–<lpage>76</lpage>.</mixed-citation>
    </ref>
    <ref id="bib18">
      <label>18.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Sul</surname><given-names>SJ</given-names></name>, <name name-style="western"><surname>Tovchigrechko</surname><given-names>A</given-names></name></person-group><article-title>Parallelizing BLAST and SOM Algorithms with MapReduce-MPI Library</article-title>. In: <source>2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum Anchorage</source>, <publisher-loc>AK, USA</publisher-loc>: <publisher-name>IEEE</publisher-name>; <year>2011</year>:<fpage>481</fpage>–<lpage>9</lpage>.. <comment><ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/document/6008868/">http://ieeexplore.ieee.org/document/6008868/</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib19">
      <label>19.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Sun</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Yao</surname><given-names>Q</given-names></name>, <etal>et al.</etal></person-group>  <article-title>A Scalable Heterogeneous Parallel SOM Based on MPI/CUDA</article-title>. In: <source>Asian Conference on Machine Learning</source>; <year>2018</year> p. <fpage>264</fpage>–<lpage>279</lpage>.. <comment><ext-link ext-link-type="uri" xlink:href="http://proceedings.mlr.press/v95/liu18b.html">http://proceedings.mlr.press/v95/liu18b.html</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib20">
      <label>20.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Sarazin</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Azzag</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Lebbah</surname><given-names>M</given-names></name></person-group><article-title>SOM Clustering Using Spark-MapReduce</article-title>. In: <source>2014 IEEE International Parallel and Distributed Processing Symposium Workshops Phoenix</source>, <publisher-loc>AZ, USA</publisher-loc>: <publisher-name>IEEE</publisher-name>; <year>2014</year> p. <fpage>1727</fpage>–<lpage>1734</lpage>.. <comment><ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/document/6969583/">http://ieeexplore.ieee.org/document/6969583/</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dean</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Ghemawat</surname><given-names>S</given-names></name></person-group><article-title>MapReduce: simplified data processing on large clusters</article-title>. <source>Commun ACM</source>. <year>2008</year>;<volume>51</volume>(<issue>1</issue>):<fpage>107</fpage>–<lpage>13</lpage>.</mixed-citation>
    </ref>
    <ref id="bib22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Collange</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Defour</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Graillat</surname><given-names>S</given-names></name>, <etal>et al.</etal></person-group>  <article-title>Numerical reproducibility for the parallel reduction on multi- and many-core architectures</article-title>. <source>Parallel Comput</source>. <year>2015</year>;<volume>49</volume>:<fpage>83</fpage>–<lpage>97</lpage>.</mixed-citation>
    </ref>
    <ref id="bib23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gropp</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Lusk</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Doss</surname><given-names>N</given-names></name>, <etal>et al.</etal></person-group>  <article-title>A high-performance, portable implementation of the MPI message passing interface standard</article-title>. <source>Parallel Comput</source>. <year>1996</year>;<volume>22</volume>(<issue>6</issue>):<fpage>789</fpage>–<lpage>828</lpage>.</mixed-citation>
    </ref>
    <ref id="bib24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ihaka</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Gentleman</surname><given-names>R</given-names></name></person-group><article-title>R: A language for data analysis and graphics</article-title>. <source>J Comput Graph Stat</source>. <year>1996</year>;<volume>5</volume>(<issue>3</issue>):<fpage>299</fpage>–<lpage>314</lpage>.</mixed-citation>
    </ref>
    <ref id="bib25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wegener</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Sengstag</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Sfakianakis</surname><given-names>S</given-names></name>, <etal>et al.</etal></person-group>  <article-title>GridR: An R-based tool for scientific data analysis in grid environments</article-title>. <source>Future Generation Comput Syst</source>. <year>2009</year>;<volume>25</volume>(<issue>4</issue>):<fpage>481</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="bib26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zaharia</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Xin</surname><given-names>RS</given-names></name>, <name name-style="western"><surname>Wendell</surname><given-names>P</given-names></name>, <etal>et al.</etal></person-group>  <article-title>Apache Spark: a unified engine for big data processing</article-title>. <source>Commun ACM</source>. <year>2016</year>;<volume>59</volume>(<issue>11</issue>):<fpage>56</fpage>–<lpage>65</lpage>.</mixed-citation>
    </ref>
    <ref id="bib27">
      <label>27.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Rocklin</surname><given-names>M</given-names></name></person-group><source>Dask: Parallel Computation with Blocked algorithms and Task Scheduling</source>. <publisher-loc>Austin, Texas</publisher-loc>; <year>2015</year>:<fpage>126</fpage>–<lpage>32</lpage>.. <comment><ext-link ext-link-type="uri" xlink:href="https://conference.scipy.org/proceedings/scipy2015/matthew_rocklin.html">https://conference.scipy.org/proceedings/scipy2015/matthew_rocklin.html</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Harris</surname><given-names>CR</given-names></name>, <name name-style="western"><surname>Millman</surname><given-names>KJ</given-names></name>, <name name-style="western"><surname>van der Walt</surname><given-names>SJ</given-names></name>, <etal>et al.</etal></person-group>  <article-title>Array programming with NumPy</article-title>. <source>Nature</source>. <year>2020</year>;<volume>585</volume>(<issue>7825</issue>):<fpage>357</fpage>–<lpage>62</lpage>.<pub-id pub-id-type="pmid">32939066</pub-id></mixed-citation>
    </ref>
    <ref id="bib29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bentley</surname><given-names>JL</given-names></name></person-group><article-title>Multidimensional binary search trees used for associative searching</article-title>. <source>Commun ACM</source>. <year>1975</year>;<volume>18</volume>(<issue>9</issue>):<fpage>509</fpage>–<lpage>17</lpage>.</mixed-citation>
    </ref>
    <ref id="bib30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Omohundro</surname><given-names>SM</given-names></name></person-group><article-title>Five Balltree Construction Algorithms</article-title>. <source>Int Comput Sci Inst</source>. <year>1989</year>; <fpage>22</fpage>.</mixed-citation>
    </ref>
    <ref id="bib31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Maaten</surname><given-names>Lvd</given-names></name>, <name name-style="western"><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title>Visualizing Data using t-SNE</article-title>. <source>J Mach Learn Res</source>. <year>2008</year>;<volume>9</volume>(<issue>Nov</issue>):<fpage>2579</fpage>–<lpage>605</lpage>.</mixed-citation>
    </ref>
    <ref id="bib32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>McInnes</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Healy</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Saul</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Grossberger</surname><given-names>L</given-names></name></person-group>, <article-title>UMAP: Uniform Manifold Approximation and Projection</article-title>, <source>Journal of Open Source Software</source>. <year>2018</year>;<volume>3</volume>(<issue>29)</issue>:<fpage>861</fpage>.</mixed-citation>
    </ref>
    <ref id="bib33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Brown</surname><given-names>SDM</given-names></name>, <name name-style="western"><surname>Moore</surname><given-names>MW</given-names></name></person-group><article-title>The International Mouse Phenotyping Consortium: past and future perspectives on mouse phenotyping</article-title>. <source>Mammalian Genome</source>. <year>2012</year>;<volume>23</volume>(<issue>9-10</issue>):<fpage>632</fpage>–<lpage>40</lpage>.. <comment><ext-link ext-link-type="uri" xlink:href="http://link.springer.com/10.1007/s00335-012-9427-x">http://link.springer.com/10.1007/s00335-012-9427-x</ext-link></comment>.<pub-id pub-id-type="pmid">22940749</pub-id></mixed-citation>
    </ref>
    <ref id="bib34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kratochvíl</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hunewald</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Heirendt</surname><given-names>L</given-names></name>, <etal>et al.</etal></person-group>  <article-title>Supporting data for “GigaSOM.jl: High-performance clustering and visualization of huge cytometry datasets”</article-title>. <source>GigaScience Database</source>. <year>2020</year>
<pub-id pub-id-type="doi">10.5524/100810</pub-id>.</mixed-citation>
    </ref>
    <ref id="bib35">
      <label>35.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Varrette</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Bouvry</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Cartiaux</surname><given-names>H</given-names></name>, <etal>et al.</etal></person-group>  <article-title>Management of an academic HPC cluster: The UL experience</article-title>. In: <source>2014 International Conference on High Performance Computing and Simulation (HPCS) Bologna</source>, <publisher-loc>Italy</publisher-loc>: <publisher-name>IEEE</publisher-name>; <year>2014</year> p. <fpage>959</fpage>–<lpage>967</lpage>.. <comment><ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/document/6903792/">http://ieeexplore.ieee.org/document/6903792/</ext-link></comment>.</mixed-citation>
    </ref>
  </ref-list>
</back>
