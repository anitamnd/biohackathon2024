<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6664725</article-id>
    <article-id pub-id-type="publisher-id">2910</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-019-2910-6</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Methodology Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Improving prediction of phenotypic drug response on cancer cell lines using deep convolutional network</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1510-0621</contrib-id>
        <name>
          <surname>Liu</surname>
          <given-names>Pengfei</given-names>
        </name>
        <address>
          <email>pfliu@cse.cuhk.edu.hk</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Hongjian</given-names>
        </name>
        <address>
          <email>jackyleehongjian@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Shuai</given-names>
        </name>
        <address>
          <email>shuaili@cse.cuhk.edu.hk</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Leung</surname>
          <given-names>Kwong-Sak</given-names>
        </name>
        <address>
          <email>ksleung@cse.cuhk.edu.hk</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1937 0482</institution-id><institution-id institution-id-type="GRID">grid.10784.3a</institution-id><institution>Department of Computer Science and Engineering, the Chinese University of Hong Kong, </institution></institution-wrap>Sha Tin, N.T., Hong Kong, China </aff>
      <aff id="Aff2"><label>2</label>SDIVF R&amp;D Centre, Hong Kong Science Park, Sha Tin, N.T., Hong Kong, China </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1937 0482</institution-id><institution-id institution-id-type="GRID">grid.10784.3a</institution-id><institution>CUHK-SDU Reproductive Genetics Joint Laboratory, School of Biomedical Sciences, the Chinese University of Hong Kong, </institution></institution-wrap>Sha Tin, N.T., Hong Kong, China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>29</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>29</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>20</volume>
    <elocation-id>408</elocation-id>
    <history>
      <date date-type="received">
        <day>13</day>
        <month>10</month>
        <year>2018</year>
      </date>
      <date date-type="accepted">
        <day>21</day>
        <month>5</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p>Understanding the phenotypic drug response on cancer cell lines plays a vital role in anti-cancer drug discovery and re-purposing. The Genomics of Drug Sensitivity in Cancer (GDSC) database provides open data for researchers in phenotypic screening to build and test their models. Previously, most research in these areas starts from the molecular fingerprints or physiochemical features of drugs, instead of their structures.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>In this paper, a model called twin Convolutional Neural Network for drugs in SMILES format (tCNNS) is introduced for phenotypic screening. tCNNS uses a convolutional network to extract features for drugs from their simplified molecular input line entry specification (SMILES) format and uses another convolutional network to extract features for cancer cell lines from the genetic feature vectors respectively. After that, a fully connected network is used to predict the interaction between the drugs and the cancer cell lines. When the training set and the testing set are divided based on the interaction pairs between drugs and cell lines, tCNNS achieves 0.826, 0.831 for the mean and top quartile of the coefficient of determinant (<italic>R</italic><sup>2</sup>) respectively and 0.909, 0.912 for the mean and top quartile of the Pearson correlation (<italic>R</italic><sub><italic>p</italic></sub>) respectively, which are significantly better than those of the previous works (Ammad-Ud-Din et al., J Chem Inf Model 54:2347–9, 2014), (Haider et al., PLoS ONE 10:0144490, 2015), (Menden et al., PLoS ONE 8:61318, 2013). However, when the training set and the testing set are divided exclusively based on drugs or cell lines, the performance of tCNNS decreases significantly and <italic>R</italic><sub><italic>p</italic></sub> and <italic>R</italic><sup>2</sup> drop to barely above 0.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p>Our approach is able to predict the drug effects on cancer cell lines with high accuracy, and its performance remains stable with less but high-quality data, and with fewer features for the cancer cell lines. tCNNS can also solve the problem of outliers in other feature space. Besides achieving high scores in these statistical metrics, tCNNS also provides some insights into the phenotypic screening. However, the performance of tCNNS drops in the blind test.</p>
      </sec>
      <sec>
        <title>Electronic supplementary material</title>
        <p>The online version of this article (10.1186/s12859-019-2910-6) contains supplementary material, which is available to authorized users.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Phenotypic screening</kwd>
      <kwd>Deep learning</kwd>
      <kwd>Convolutional network</kwd>
      <kwd>GDSC</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p>Historically, drug discovery was phenotypic by nature. Small organic molecules exhibiting observable phenotypic activity (e.g. whole-cell activity) were detected, a famous example being penicillin, which was serendipitously found. Phenotypic screening, an original drug screening paradigm, is now gaining new attention given the fact that in recent years the number of approved drugs discovered through phenotypic screens has exceeded those discovered through molecular target-based approaches. The latter, despite being the main drug discovery paradigm in the past 25 years, can potentially suffer from the failure in identifying and validating the therapeutic targets. In reality, most FDA approvals of first-in-class drugs actually originated from phenotypic screening before their precise mechanisms of actions or molecular targets were elaborated. A popular example of this is aspirin (acetylsalicylic acid), for which it took nearly a century to elucidate the mechanism of its actions and molecular targets.</p>
    <p>There are some public phenotypic screening datasets online to support the study of the pharmacological functions of drugs. Cancer Cell Line Encyclopedia (CCLE) and Genomics of Drug Sensitivity in Cancer (GDSC) are the most popular datasets in the field [<xref ref-type="bibr" rid="CR1">1</xref>].</p>
    <p>A pioneer work using machine-learning approaches to predict drug response on cancer cell lines was by Menden et al. [<xref ref-type="bibr" rid="CR2">2</xref>]. The authors used a neural network to analyze the response of drugs to cancer cell lines on the GDSC dataset. Their main result was the achievement of 0.72 for the coefficient of determination and 0.85 for the Pearson correlation. [<xref ref-type="bibr" rid="CR3">3</xref>] and [<xref ref-type="bibr" rid="CR4">4</xref>] are two other works on GDSC dataset. The first one used kernelized Bayesian matrix factorization to conduct QSAR analysis on cancer cell lines and anti-cancer drugs, and the second one used multivariate random forests. Both of their results were not as good as those in [<xref ref-type="bibr" rid="CR2">2</xref>], which is chosen to be the baseline for our work.</p>
    <p>The first wave of applications of deep learning in pharmaceutical research has emerged in recent years. Its utility has gone beyond bioactivity predictions and has shown promise in addressing diverse problems in drug discovery. Examples cover bioactivity prediction [<xref ref-type="bibr" rid="CR5">5</xref>], de novo molecular design [<xref ref-type="bibr" rid="CR6">6</xref>], synthesis prediction [<xref ref-type="bibr" rid="CR7">7</xref>] and biological image analysis [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR9">9</xref>]. A typical example of applying deep learning in protein-ligand interaction prediction is the investigation done by Ragoza et al. [<xref ref-type="bibr" rid="CR10">10</xref>].</p>
    <p>Convolutional neural network (CNN) is a machine learning model that can detect relevant patterns in data and support classification and regression [<xref ref-type="bibr" rid="CR11">11</xref>]. CNN has achieved breaking-through results in many areas, including pharmaceutical research [<xref ref-type="bibr" rid="CR12">12</xref>–<xref ref-type="bibr" rid="CR14">14</xref>] and has won the championship in ImageNet-2012 [<xref ref-type="bibr" rid="CR15">15</xref>].</p>
    <p>Inspired by the achievements of CNN in these areas, we are interested to see if CNN, compared to conventional machine-learning techniques [<xref ref-type="bibr" rid="CR2">2</xref>–<xref ref-type="bibr" rid="CR4">4</xref>], could significantly improve the prediction accuracy of phenotypic drug response on cancer cell lines. In this paper, a twin CNN networks model called tCNNS is introduced to predict the drug cell line interaction. tCNNS comprises a CNN for drugs and another CNN for cancer cell lines, which will be explained in detail later. The latest version of the GDSC dataset is adopted to evaluate the performance of tCNNS. Unlike previous works, here the structure of tCNNS is advanced, and it is tested on the bigger and more complete dataset. Most importantly, it achieves much better results than previous works. We share our model online, hoping to make a contribution to other researchers.</p>
  </sec>
  <sec id="Sec2">
    <title>Related work</title>
    <p>Erik et al. [<xref ref-type="bibr" rid="CR16">16</xref>] stated that both the qualitative classifiers and the quantitative structure-activity relationship (QSAR) models in drug discovery depend on the molecular descriptors, which is <italic>the decisive step in the model development process</italic>.</p>
    <p>Recently, in drug discovery, researchers started to use the molecular structure of drugs directly as features [<xref ref-type="bibr" rid="CR17">17</xref>–<xref ref-type="bibr" rid="CR20">20</xref>] instead of using extracted features from open source software [<xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR22">22</xref>]. Due to their good ability to process high-dimensional structure data, deep learning has been largely adopted in this area [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR23">23</xref>, <xref ref-type="bibr" rid="CR24">24</xref>].</p>
    <p>From the perspective of machine learning, drug cell line interaction analysis can be considered as a classification task where the outputs are some categorical values, such as sensitivity or resistance, or a regression task where the outputs are some numerical values, such as IC<sub>50</sub>. Wang et al. [<xref ref-type="bibr" rid="CR25">25</xref>] used support vector machine (SVM) to handle the classification problem by merging drug features from different sources, such as the chemical properties and the protein targets. The features they used to represent cell lines are the same as ours, which are the copy number variations, gene mutation states and expressions. Rahman et al. [<xref ref-type="bibr" rid="CR26">26</xref>] built a random forest based ensemble model for drug sensitivity prediction and they found that the information of cancer types can help researchers to enhance the performance even with a fewer number of samples for training. Ding et al. [<xref ref-type="bibr" rid="CR27">27</xref>] used the elastic net to generate a logistic model to predict drug sensitivity. Zhang et al. [<xref ref-type="bibr" rid="CR28">28</xref>] applied another approach on the classification problem. It predicted interaction labels using a drug-drug similarity network and a cell line-cell line similarity network. These similarity networks were computed based on the features of drugs and cell lines respectively.</p>
    <p>Regression is more challenging than classification because there are infinite possible outputs, and many machine learning models have been adopted to handle it. Among them, matrix factorization (MF) and neural network (NN) are the two most widely used models and have been proven to be most useful. In MF, the drug target interaction matrix is decomposed into two low-rank matrices, and the interactions among drugs and targets are represented by the inner products of the vectors in the two low-rank matrices. Ammad et al. [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR29">29</xref>] designed a kernelized Bayesian matrix factorization method for drug cell line interaction prediction and reported their <italic>R</italic><sup>2</sup> based on GDSC, which are not as good as the results in Menden et al. [<xref ref-type="bibr" rid="CR2">2</xref>]. Chayaporn et al. [<xref ref-type="bibr" rid="CR30">30</xref>] modified an MF based recommendation system algorithm and applied it to drug cell line interaction. The authors tested their algorithms on GDSC and reported the Spearman correlation as 0.6. Alexander et al. [<xref ref-type="bibr" rid="CR31">31</xref>] came up with a deep neural network to predict the pharmacological properties of drugs and drug repurposing. They built a fully connected network and the input features for drugs were the gene level transcriptomic data, which were processed using a pathway activation scoring algorithm.</p>
    <p>Simplified molecular input line entry specification (SMILES) of the drugs is converted into vectors using unsupervised auto-encoder [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR32">32</xref>]. These vectors can be used as features or fingerprints of drugs. This method was further extended for drug discovery by Han et al. [<xref ref-type="bibr" rid="CR20">20</xref>] and Zheng et al. [<xref ref-type="bibr" rid="CR33">33</xref>]. The authors predicted the use of drugs by comparing the similarity between those vectors of drugs.</p>
    <p>In the recent two years, there are several different deep neural network (DNN) models that were trained directly from drug structures and avoided the <italic>decisive step</italic>. These DNN models include unsupervised auto-encoder (AE), supervised convolution neural network(CNN), and recurrent neural network (RNN).</p>
    <p>Although it is attractive to apply CNN to the formulas of drugs, it is also very difficult to do so because there is no uniform pattern in the drug formulas. Instead, researchers tried to apply CNN on the image of the formulas of drugs as an alternative solution. Goh et al. [<xref ref-type="bibr" rid="CR34">34</xref>] adopted a computer vision method to screen the image of drugs. The advantage of starting from the image of drugs rather than from their formulas is that it can avoid the massive work of handling the diversity of drugs. However, the disadvantages are that the accuracy is compromised because the information will be distorted when mapping drug structures to images and the performance of this method relies on the quality of the image processing.</p>
    <p>Beyond the application of applying CNN to drug images, it is also possible to apply CNN to molecular 3D structures directly. Wallach et al. [<xref ref-type="bibr" rid="CR35">35</xref>] predicted the binding energy of the small area around an atom, rather than on the entire structure of drugs. It is interesting to compare the different representations of drugs, such as the 3D structured, the feature vectors learned from SMILES and the features extracted from other software like PaDEL [<xref ref-type="bibr" rid="CR36">36</xref>]. They may have different influences on different problems.</p>
    <p>Even though RNN is usually used to handle time sequence data [<xref ref-type="bibr" rid="CR37">37</xref>] instead of spatial data, it is very impressive that Lusci et al. [<xref ref-type="bibr" rid="CR38">38</xref>] applied RNN to the SMILES of drugs to predict their solubility. The authors converted the SMILES into indirect graphs, and then fed them into an RNN. In their work, the authors only considered the property of drugs alone, without considering the interactions among drugs and other biological factors, such as cell lines or proteins.</p>
    <p>We compare our model to that by Menden et al. [<xref ref-type="bibr" rid="CR2">2</xref>], where the authors used a neural network to analyze the IC<sub>50</sub> of drugs to cancer cells on the same dataset as ours. However, their network structure is not advanced enough, and the features they used are not informative enough. We designed tCNNS, a convolution neural network (CNN) based model, to predict the interaction between drugs and cell lines.</p>
  </sec>
  <sec id="Sec3">
    <title>Methods</title>
    <p>In this section, the chosen database GDSC, the preprocessing steps, and the proposed neural network structure are described in detail to make our experiments easier to replicate.</p>
    <sec id="Sec4">
      <title>Data acquisition and preprocessing</title>
      <p>Genomics of Drugs Sensitivity in Cancer (GDSC) [<xref ref-type="bibr" rid="CR39">39</xref>] is a public online database about the relationship among many types of cancer and various anti-cancer drugs. Cancer cell lines in GDSC are described by their genetic features, such as mutations state and copy number variances. For the drugs, GDSC provides their names and the compound id (CID). In chemistry, CID is a unique number assigned to each molecule and can be used as the reference number to extract more information about the drugs such as their molecular structures from other databases. GDSC uses IC<sub>50</sub> as the metric of drugs’ effectiveness on cancers. IC<sub>50</sub> is the amount of drug needed to inhibit a cancer by half. The less the value is, the more effective the drug is. GDSC is an ongoing project and is being updated regularly. In our paper, GDSC version 6.0 is used. As a comparison, Menden et al. [<xref ref-type="bibr" rid="CR2">2</xref>] used version 2.0 of the GDSC, which contains much fewer drugs and cell lines.</p>
      <p>The three downloaded files from GDSC are: 
<list list-type="alpha-lower"><list-item><p>Drug _list.csv, which is a list of 265 drugs. Each drug can be referred to by its CID or name.</p></list-item><list-item><p>PANCANCER _<italic>Genetic</italic>_feature.csv, which is a list of 990 cancer cell lines from 23 different types of cancers. Each cell line is described by at most 735 features. Any feature belongs to one of the two categories: mutation state or copy number alteration.</p></list-item><list-item><p>PANCANCER _IC.csv, which contains the IC<sub>50</sub> information between 250 drugs and 1074 cell lines.</p></list-item></list></p>
      <p>Note that the numbers of drugs in files (a) and (c) are inconsistent, and that the numbers of cell lines in files (b) and (c) are also inconsistent. Some cell lines have less than 735 features. Besides, GDSC does not provide the features for drugs, which have to be downloaded from other datasets. All of these indicate that three preprocessing steps are needed to clean the data. 
<list list-type="order"><list-item><p>The first step is to cleanse the drug list. There 15 repeating items in file (a), which are removed. Some CIDs in file (a) are inconsistent with the CIDs found in PubChem [<xref ref-type="bibr" rid="CR40">40</xref>], which is a popular public chemical compounds database. To enforce the consistency, the CIDs from PubChem have been adopted. Some drugs cannot be found in PubChem by referring to their names in the file (a) and they are removed. As a result, 223 drugs with both names and CIDs are left.</p></list-item><list-item><p>The second step is to cleanse the cell lines list. For the 990 cell lines in file (b), 42 of them has less than 735 features. After the removal, 948 cell lines are left.</p></list-item><list-item><p>In the third step, only the IC<sub>50</sub> values between the remaining drugs after the first step and the remaining cell lines after the second step are used. All the other IC<sub>50</sub> values in file (c) are removed. In summary, there are 223 drugs and 948 cell lines after preprocessing. Among the 223×948=211,404 interacting pairs, 81.4<italic>%</italic> (172,114) of the IC<sub>50</sub> values are provided in file (c), whereas 18.6<italic>%</italic> (39,290) are missing, which are also taken out.</p></list-item></list></p>
      <p>The IC<sub>50</sub> data in file (c) are the logarithm of their real value. To make it easy for training and comparison, the method reported in [<xref ref-type="bibr" rid="CR2">2</xref>] is used to normalize the logarithmic IC<sub>50</sub> values in the (0,1) interval. Given a logarithmic IC<sub>50</sub> value <italic>x</italic>, the real value <italic>y</italic>=<italic>e</italic><sup><italic>x</italic></sup> is got by taking the exponential formal of <italic>x</italic>, and the following function is used to normalize <italic>y</italic>: 
<disp-formula id="Equa"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$y \mapsto \frac{1}{1 + y^{-0.1}}\,. $$ \end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mi>y</mml:mi><mml:mo>↦</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mspace width="0.3em"/><mml:mi>.</mml:mi></mml:mrow></mml:math><graphic xlink:href="12859_2019_2910_Article_Equa.gif" position="anchor"/></alternatives></disp-formula> Usually <italic>y</italic> is very small (&lt; 10<sup>−3</sup>), and the parameter value − 0.1 has been chosen to distribute the result more uniformly on the interval (0,1) [<xref ref-type="bibr" rid="CR2">2</xref>].</p>
    </sec>
    <sec id="Sec5">
      <title>Numerical descriptor extraction</title>
      <p>Recently, there are some pioneering works that apply deep neural network (DNN) directly to the simplified molecular-input line-entry system (SMILES) of drugs. SMILES is a linear notation form to represent the structure of molecules, in which letters, digits and special characters are used to represent the chemical elements in a molecule. For example, “C” stands for carbon atom and “=” is for covalent bond between two atoms. Carbon dioxide can be represent as O=C=O and aspirin can be represented as O=C(C)OC1CCCCC1C(=O)O.</p>
      <p>There are some challenges to apply CNN on drugs in SMILES format: first, SMILES can be constructed in various ways and there can be many possible SMILESs for each drug; second, the size of the samples for a CNN should be consistent, but the lengths of the SMILES format of drugs are different from each other; third, and more importantly, the SMILES descriptions are composed of different letters representing different chemical elements, such as atoms and bonds, and it does not make sense to apply convolution operation among different chemical elements. To solve these problems, preprocessing is needed to convert the SMILES into a uniform format, so that different chemical elements are separated from each other and are independently treated under CNN.</p>
      <p>To keep unique SMILES format for the drugs, the <italic>canonical SMILES</italic> [<xref ref-type="bibr" rid="CR41">41</xref>] is adopted as the representation for the drugs. Among 223 drugs, 184 canonical SMILES have been found from PubChem by the drug names, using a python interface for PubChem. The canonical SMILES of the remaining 39 drugs are downloaded from the Library of the Integrated Network-based Cellular Signatures (LINCS) [<xref ref-type="bibr" rid="CR42">42</xref>].</p>
      <p>The longest SMILES for the drugs contains 188 symbols, and most SMILES lengths are between 20 and 90. To keep the size consistent and retain the complete information, all SMILESs are left aligned with space padding on the right if they are shorter than 188.</p>
      <p>The neural network cannot directly take the drugs in SMILES format as input, and it is needed to convert the SMILES format (they are of uniform length now after handling the second challenge) into a format that can be used in the neural network. There are 72 different symbols in the SMILES format for the total 223 drugs. The distribution of these symbols is quite unbalanced. For example, carbon atom [C] appears in all the 223 drugs. Meanwhile, there is only one drug containing [Au] and only one drug containing [Cl]. Suppose the rows are used to represent different symbols, and the columns are used to represent positions in the SMILES format, then each drug in SMILES format can be converted into a 72∗188 one-hot matrix which only contains 0 and 1. In the one-hot matrix for a drug, a value 1 at row <italic>i</italic> and column <italic>j</italic> means that the <italic>i</italic>th symbol appears at <italic>j</italic>th position in the SMILES format for the drug. In tCNNS, each row of the one-hot matrix is treated as a different channel in CNN, and the 1D convolutional operation will be applied along each row of the one-hot matrix, which restricts convolutional operation within the same chemical element.</p>
    </sec>
    <sec id="Sec6">
      <title>Deep neural network</title>
      <p>The structure of the proposed model tCNNS is shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. Its input data consist of the one-hot representation of drugs (phenanthroline is used as an example for the drugs) and the feature vectors of the cell lines. The work-flow can be divided into two stages as follows.
<fig id="Fig1"><label>Fig. 1</label><caption><p>The upper part is the branch for drugs, and the lower part is the branch for cell lines. Both are inputs of a fully connected network on the right-hand side. The general work-flow of our model is from left to right. The left-hand side is the input data of one-hot representations for drugs and the feature vectors for cell lines. The black square stands for 1 and empty square stands for 0. In the middle, there are a CNN branch to process the drug inputs and a CNN branch to process cell lines inputs respectively. They take the one-hot representations and feature vectors as input data respectively, and their outputs can be interpreted as the abstract features for drugs and cell lines. The structures of the two convolution neural networks are similar. The right-hand side is a fully connected network that does regression analysis from the IC<sub>50</sub> to the abstract features from the two CNNs in the middle part</p></caption><graphic xlink:href="12859_2019_2910_Fig1_HTML" id="MO1"/></fig></p>
      <p>First stage: A model with two CNN branches is built to distil features for drugs and cell lines separately. A 1D CNN is used for the cell-line branch since the input data are 1D feature vectors for cell lines. Another 1D CNN is used for the drug branch and treat different symbols as different channels in the CNN. The convolution is applied along the length of the SMILES format. The structures for the two branches are the same. For each branch, there are three similar layers: each layer with convolution width 7, convolution stride 1, max pooling width 3, and pooling stride 3. The only difference between the layers is that their number of channels are 40, 80 and 60, respectively. The choices of these parameters for the CNN are inspired by the model in [<xref ref-type="bibr" rid="CR43">43</xref>], in which the author chose a three-layers network model and used a prime number as filter width. It is found that either reducing the pooling size or adding the channel number has the potential to enhance the proposed model but with the cost of losing stability. Losing stability means that experimental results sometimes become unrepeatable. This problem will be detailed in “<xref rid="Sec8" ref-type="sec">Results</xref>” section.</p>
      <p>Second stage: After the two branches of the CNN, there is a fully connected network (FCN), which aims to do the regression analysis between the output of the two branches and the IC<sub>50</sub> values. There are three hidden layers in the FCN, each with 1024 neurons. The dropout probability is set to be 0.5 for the FCN during the training phase [<xref ref-type="bibr" rid="CR43">43</xref>].</p>
      <p>tCNNS is implemented using TensorFlow v1.4.0 [<xref ref-type="bibr" rid="CR44">44</xref>], which is a popular DNN library with many successful applications [<xref ref-type="bibr" rid="CR44">44</xref>, <xref ref-type="bibr" rid="CR45">45</xref>].</p>
    </sec>
    <sec id="Sec7">
      <title>Performance measures</title>
      <p>Three metrics are adopted to measure the performance of our model: the coefficient of determination (<italic>R</italic><sup>2</sup>), Pearson correlation coefficient (<italic>R</italic><sub><italic>p</italic></sub>), and root mean square error (RMSE). This is the same as that in the benchmark paper [<xref ref-type="bibr" rid="CR2">2</xref>].</p>
      <p><italic>R</italic><sup>2</sup> measures variance proportion of the dependent variables that is predictable from the independent variables. Let <italic>y</italic><sub><italic>i</italic></sub> be the label of a sample <italic>x</italic><sub><italic>i</italic></sub>, and our label prediction on <italic>x</italic><sub><italic>i</italic></sub> is <italic>f</italic><sub><italic>i</italic></sub>. The error of our prediction, or residual, is defined as <italic>e</italic><sub><italic>i</italic></sub>=<italic>y</italic><sub><italic>i</italic></sub>−<italic>f</italic><sub><italic>i</italic></sub>. Let the mean of <italic>y</italic><sub><italic>i</italic></sub> be <inline-formula id="IEq1"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\bar {y} = \frac {1}{n} \sum _{i} y_{i}$\end{document}</tex-math><mml:math id="M4"><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2019_2910_Article_IEq1.gif"/></alternatives></inline-formula>, there will be the total sum of squares: 
<disp-formula id="Equb"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $${SS}_{\text{tot}} = \sum_{i} (y_{i} - \bar{y})^{2},$$ \end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:msub><mml:mrow><mml:mtext mathvariant="italic">SS</mml:mtext></mml:mrow><mml:mrow><mml:mtext>tot</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2019_2910_Article_Equb.gif" position="anchor"/></alternatives></disp-formula> the regression sum of squares: 
<disp-formula id="Equc"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $${SS}_{\text{reg}} = \sum_{i} (f_{i} - \bar{y})^{2},$$ \end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:msub><mml:mrow><mml:mtext mathvariant="italic">SS</mml:mtext></mml:mrow><mml:mrow><mml:mtext>reg</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2019_2910_Article_Equc.gif" position="anchor"/></alternatives></disp-formula> the residual sum of squares: 
<disp-formula id="Equd"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $${SS}_{\text{res}}=\sum_{i} (y_{i} - f_{i})^{2} = \sum_{i} e_{i}^{2},$$ \end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:msub><mml:mrow><mml:mtext mathvariant="italic">SS</mml:mtext></mml:mrow><mml:mrow><mml:mtext>res</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2019_2910_Article_Equd.gif" position="anchor"/></alternatives></disp-formula><italic>R</italic><sup>2</sup> is defined as: 
<disp-formula id="Eque"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$R^{2} = 1 - \frac{SS_{\text{res}}}{SS_{\text{tot}}} \,.$$ \end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>res</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>tot</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mspace width="0.3em"/><mml:mi>.</mml:mi></mml:mrow></mml:math><graphic xlink:href="12859_2019_2910_Article_Eque.gif" position="anchor"/></alternatives></disp-formula><italic>R</italic><sub><italic>p</italic></sub> measures the linear correlation between two variables. <italic>Y</italic> is used as the true label and <italic>F</italic> as the corresponding prediction for any sample. Let the mean and standard deviation of <italic>Y</italic> be <inline-formula id="IEq2"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\bar {Y}$\end{document}</tex-math><mml:math id="M14"><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2019_2910_Article_IEq2.gif"/></alternatives></inline-formula> and <italic>σ</italic><sub><italic>Y</italic></sub> respectively, and those for the prediction <italic>F</italic> be <inline-formula id="IEq3"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\bar {F}$\end{document}</tex-math><mml:math id="M16"><mml:mover accent="true"><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2019_2910_Article_IEq3.gif"/></alternatives></inline-formula> and <italic>σ</italic><sub><italic>F</italic></sub> respectively. <italic>R</italic><sub><italic>p</italic></sub> is defined as: 
<disp-formula id="Equf"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$R_{p} = \frac{\mathbb{E}}{\sigma_{Y}\sigma_{F}} \,.$$ \end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">𝔼</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mspace width="0.3em"/><mml:mi>.</mml:mi></mml:mrow></mml:math><graphic xlink:href="12859_2019_2910_Article_Equf.gif" position="anchor"/></alternatives></disp-formula> RMSE measures the difference between two variables <italic>Y</italic> and <italic>F</italic>, and RMSE is defined as: 
<disp-formula id="Equg"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\text{RMSE} = \sqrt{\mathbb{E}} \,.$$ \end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mtext>RMSE</mml:mtext><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mi mathvariant="double-struck">𝔼</mml:mi></mml:mrow></mml:msqrt><mml:mspace width="0.3em"/><mml:mi>.</mml:mi></mml:mrow></mml:math><graphic xlink:href="12859_2019_2910_Article_Equg.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
  </sec>
  <sec id="Sec8" sec-type="results">
    <title>Results</title>
    <p>In this section, the performance of our model tCNNS is demonstrated under various data input settings. The titles and the meaning of these experiments are summarized as follows: 
<list list-type="bullet"><list-item><p>Rediscovering Known Drug-Cell Line Responses. In this part, the drug-cell line interaction pairs are divided into a training set, a validation set and a testing set. tCNNS is trained on the training set and the result on the test set is reported. The validation set is used to decide when to stop training.</p></list-item><list-item><p>Predicting Unknown Drug-Cell Line Responses. In this part, tCNNS is trained on the known drug-cell line interaction pairs in GDSC and is used to predict the missing pairs in GDSC.</p></list-item><list-item><p>Retraining Without Extrapolated Activity Data. In this part, tCNNS is trained and tested on a subset of GDSC data. The subset is called max_conc data, and it is more accurate than the rest of the data in GDSC.</p></list-item><list-item><p>Blind Test For Drugs And Cell lines. In this part, drugs and cell lines, instead of the interaction pairs, are divided into the training set, the validation set and the test set.</p></list-item><list-item><p>Cell Lines Features Impacts. In this part, the performance of tCNNS is tested with respect to the different sizes of the feature vectors for the cell lines.</p></list-item><list-item><p>Biological Meaning v.s Statistical Meaning. In this part, the input data are transformed in various ways to check whether tCNNS can capture the biological meaning in the data.</p></list-item><list-item><p>Eliminating Outliers. The 223 drugs are visualized in different feature spaces to show that the features extracted from SMILES can solve the problem of outliers in traditional feature space.</p></list-item></list></p>
    <sec id="Sec9">
      <title>Rediscovering known drug-cell line responses</title>
      <p>In the 223×948 (211,404) drug-cell line interaction pairs, GDSC provides the IC<sub>50</sub> for 172,114 of them. To compare to the results of previous studies [<xref ref-type="bibr" rid="CR2">2</xref>], the same procedure was employed. In this part, those known pairs were split into 80% as the training set, 10% as the validation set, and 10% as the testing set. This choice was made to guarantee any drug-cell line pair can only exist either in the training set or the test set. However, there was no restriction on the existence of drugs or cell lines. In each epoch, parameters in tCNNS were updated using gradient descent on the training set. The validation set was used to control the training of the tCNNS. If the RMSE on the validation set did not decrease in 10 recent epochs, the training process would stop and the predictions of our model on the testing set were compared with the given IC<sub>50</sub> values in GDSC.</p>
      <p>Experiments were set in this way to stimulate those real situations in which the models can only be trained on known interaction pairs between drugs and cell lines, and the models will be useful only if it can predict unknown interaction pairs. The validation set was separated from the training set so that it would be possible to choose a suitable time to stop training independently and avoid the problem of over-fitting.</p>
      <p>tCNNS was tested 50 times, and an example of the regression result is displayed in Fig. <xref rid="Fig2" ref-type="fig">2</xref>.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Regression results on the testing set compared to the ground truth IC<sub>50</sub> values. The <italic>x</italic> axis is the experimental IC<sub>50</sub> in natural logarithmic scale, and the <italic>y</italic> axis is the predicted IC<sub>50</sub> in natural logarithmic scale. Different colors demonstrate how many testing samples fall in each small square of 0.1×0.1, or the hot map of the distribution, where dark purple indicates more samples (around 30 samples per small square 0.1×0.1) and light blue indicates fewer samples (less than 5 samples per small square 0.1×0.1)</p></caption><graphic xlink:href="12859_2019_2910_Fig2_HTML" id="MO2"/></fig></p>
      <p>In the 50 repeated experiments, <italic>R</italic><sup>2</sup> was increased from 0.72 to 0.826 for the mean and 0.831 for the top quartile. <italic>R</italic><sub><italic>p</italic></sub> was increased from 0.85 to 0.909 for the mean and 0.912 for the top quartile, and RMSE was reduced from 0.83 to about 0.027.</p>
      <p>These results clearly showed that tCNNS outperformed the previous work reported in [<xref ref-type="bibr" rid="CR2">2</xref>] in many ways, however, it should be pointed out that the comparison could be overly optimistic as the version of GDSC has changed so much and it is difficult to make a direct comparison. Instead, some indirect comparisons were made. After replacing the network reported in [<xref ref-type="bibr" rid="CR2">2</xref>] with tCNNS, it did not converge using the features extracted from PaDEL. Then, the network in [<xref ref-type="bibr" rid="CR2">2</xref>] was replaced with a deeper one, a network with three hidden layers and 1024 neurons in each hidden layer. This modified model got <italic>R</italic><sup>2</sup> of around 0.65 and <italic>R</italic><sub><italic>p</italic></sub> of around 0.81, which is shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S1. It can be seen that the result was clearly horizontally stratified, which meant that the neural network lacked representational power using PaDEL features.</p>
      <p>Many hyper-parameters affected the performance of tCNNS, such as the number of layers and the filter size. It was found that a smaller pooling size and more numbers of channels could further enhance the performance, but with a decrease in stability. For example, when the pooling size was reduced from 3 to 2, the top quartile <italic>R</italic><sup>2</sup> was further increased to 0.92 and the top quartile <italic>R</italic><sub><italic>p</italic></sub> was further increased to 0.96. The cost of this enhancement was that the network would become unstable and diverge [<xref ref-type="bibr" rid="CR46">46</xref>] during the training. To keep experimental results repeatable, only the results with parameters that ensure stability are reported in this paper.</p>
    </sec>
    <sec id="Sec10">
      <title>Predicting unknown drug-cell line responses</title>
      <p>In this part, tCNNS was trained on all the known interaction pairs in GDSC and then it was used to predict the values for those missing pairs in GDSC. The known pairs were split into 90% as the training set, and 10% as the validation set. Again, if the RMSE on the validation set did not decrease in 10 recent epochs, the training process would stop and the trained tCNNS was used to predict the values for the missing items. The results are shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>.
<fig id="Fig3"><label>Fig. 3</label><caption><p>The predicted missing IC<sub>50</sub> values. The drugs are ranged according to the median of their predicted IC<sub>50</sub> values with cells. The horizontal axis denotes the drug names, and the vertical axis denotes their negative <italic>l</italic><italic>o</italic><italic>g</italic><sub>10</sub>(IC<sub>50</sub>) values with cell lines. The left part is the top 20 drugs with lowest IC<sub>50</sub> median, which means that they are probably the most effective drugs, and the right part is the last 20 drugs with the highest IC<sub>50</sub> median, which means that they are the most ineffective drugs. For each drug, there is a number in its associated column, which is the number of cell lines whose interaction with the drug are missing in GDSC</p></caption><graphic xlink:href="12859_2019_2910_Fig3_HTML" id="MO3"/></fig></p>
      <p>Figure <xref rid="Fig3" ref-type="fig">3</xref> is the box plot of the predicted IC<sub>50</sub> values for missing items grouped by drugs. For each drug, the box represents the distribution of the values with its related cell lines. Drugs were sorted by the median of the distribution: the 20 drugs with highest median and 20 drugs with the lowest median value were plotted. As the real values for these missing pairs were not known, the accuracy of our prediction was obtained by survey and analysis as follows.</p>
      <p><italic>Bortezomib</italic> was the best drug in our prediction. In fact, the top 40 pairs with the lowest IC<sub>50</sub> value were all from <italic>Bortezomib</italic> with some other cell lines. The outstanding performance of <italic>Bortesomib</italic> in missing pairs was consistent with that in the existing pairs. There is some supporting information in [<xref ref-type="bibr" rid="CR47">47</xref>] that the author found that drug <italic>Bortezomib</italic> can make cell lines to be sensitive to many other anti-cancer drugs.</p>
      <p><italic>Aica ribonucleotide</italic> and <italic>Phenformin</italic> have the poorest performance in tCNNS prediction. Based on our survey, the former one was initially invented to stop bleeding, and the later one was initially used as an anti-diabetic drug. These two drugs have the potential to cure cancer because they can inhibit the growth of cell (<italic>Aica ribonucleotide</italic>) or inhibit the growth of Complex I (<italic>Phenformin</italic>), but their effects are limited since anti-cancer is only the side effect of them, and not their main function.</p>
      <p>Based on the tCNNS predictions, the IC<sub>50</sub> of drug <italic>Bortezomib</italic> with cell line <italic>NCI-H2342</italic> was 1.19∗10<sup>−4</sup><italic>μ</italic><italic>g</italic>. The small value indicated that there may be a good therapeutic effect. This prediction was supported by the findings reported in [<xref ref-type="bibr" rid="CR48">48</xref>, <xref ref-type="bibr" rid="CR49">49</xref>], in which it is highlighted that <italic>Bortezomib</italic> is able to control Phosphorylation that causes lung cancer and <italic>NCI-H2342</italic> is a lung cell line. Similar evidence to support this prediction can also be found in Cell Signaling Technology’s 2011 published curation set (<ext-link ext-link-type="uri" xlink:href="https://www.phosphosite.org/siteAction.action?id=3131">https://www.phosphosite.org/siteAction.action?id=3131</ext-link>).</p>
    </sec>
    <sec id="Sec11">
      <title>Retraining without extrapolated activity data</title>
      <p>For each drug in GDSC, there are two important thresholds called minimum screening concentration (min_conc), which is the minimum IC<sub>50</sub> value verified by biological experiments, and maximum screening concentration (max_conc), which is the maximum IC<sub>50</sub> value verified by biological experiments. In GDSC, any IC<sub>50</sub> beyond these two thresholds is extrapolated, and not verified by experiments. In general, IC<sub>50</sub> value within min_conc and max_conc are more accurate than those outside of the thresholds.</p>
      <p>In the GDSC data that we used in this paper, only max_conc is provided, and there are 64,440 IC<sub>50</sub> values below max_conc, which is about 37% of the whole existing 172,114 IC<sub>50</sub> values.</p>
      <p>In this part, tCNNS was trained on the IC<sub>50</sub> values below the max_conc threshold, which were randomly divided into 10% data for validating, 10% data for testing. The remaining 80% data is used for training and the size is reduced to 1% while the experiment was repeated 20 times. The regression result is shown in the Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S2. The comparison against the tCNNS which trained on whole existing data is shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>.
<fig id="Fig4"><label>Fig. 4</label><caption><p>The performance with different percentages of data used. The x-axis is the percentage of data used as training data from the total existing IC<sub>50</sub> values (172114) in the database. Since there is 10% for validating and 10% for testing, the max x is 80%. The y-axis is the top-quartile performance of our model. The solid lines represent the result on total existing data, and the dash lines represent the results where only the IC<sub>50</sub> values below the max screening concentration threshold(max_conc) are used, below which the data is more accurate. Since there are only 64,440 values below max_conc, so the dash lines end at around <inline-formula id="IEq4"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\frac {64,440}{172,114}*80\% = 30\%$\end{document}</tex-math><mml:math id="M22"><mml:mfrac><mml:mrow><mml:mn>64</mml:mn><mml:mo>,</mml:mo><mml:mn>440</mml:mn></mml:mrow><mml:mrow><mml:mn>172</mml:mn><mml:mo>,</mml:mo><mml:mn>114</mml:mn></mml:mrow></mml:mfrac><mml:mo>∗</mml:mo><mml:mn>80</mml:mn><mml:mi>%</mml:mi><mml:mo>=</mml:mo><mml:mn>30</mml:mn><mml:mi>%</mml:mi></mml:math><inline-graphic xlink:href="12859_2019_2910_Article_IEq4.gif"/></alternatives></inline-formula></p></caption><graphic xlink:href="12859_2019_2910_Fig4_HTML" id="MO4"/></fig></p>
      <p>From Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S2, it can be observed that tCNNS can achieve almost the same good result just on max_conc data, which was faster because less data were needed. There were some other properties of tCNNS that could be concluded from Fig. <xref rid="Fig4" ref-type="fig">4</xref>. Firstly, it performed very well even with very limited training data. For example, when tCNNS was trained on only 1% of the existing IC<sub>50</sub> values, <italic>R</italic><sup>2</sup> can be almost 0.5 and <italic>R</italic><sub><italic>p</italic></sub> be around 0.7. Secondly, and more importantly, tCNNS performed better with less and more accurate data. The dash lines (results on data below max _conc) were always above the solid lines (result on all data), and the final performance on max _conc data was almost as good as that on the total data, although the amount of data for the former was only 37% of the latter. To further compare the best performance on all data and max _conc data only, the distribution of the 20 times experiments are shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S3.</p>
      <p>There are three experimental results shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S3, which are the experiments on all data, on the data below max _conc, and on a random subset of all data with the same size as those below max _conc. Comparing the result on data below max _conc with the result on the random data with the same size, it was observed that the performance of tCNNS was significantly better on data below max _conc than on random data with the same size, and it proved that tCNNS was able to utilize the information conveyed by accurate data.</p>
    </sec>
    <sec id="Sec12">
      <title>Blind test for drugs and cell lines</title>
      <p>In previous experiments, interaction pairs between drugs and cell lines were randomly selected to be in the training set, the validation set, or the testing set, which meant that a specific drug or a specific cell line can exist in training and testing at the same time. This experimental setting corresponds to the problem of predicting the effect of a certain drug on a new cell line when its effect on another cell line is given. The problem becomes more challenging if the tested drug is a brand new one, and its effect on any cell lines is not known. To evaluate the performance of tCNNS on this challenging problem, a new experimental setting called <italic>blind test</italic> was designed.</p>
      <p>In the blind test for drugs, drugs were constrained from existing in training and testing at the same time. The interaction pairs were divided based on drugs. 10% (23/223) drugs were randomly selected and their related IC<sub>50</sub> values were kept for testing. For the remaining 90% drugs, 90% of their related IC<sub>50</sub> values were randomly selected for training and 10% for validating.</p>
      <p>In the blind test for cell lines, cell lines were prevented from existing in the training set and the testing set at the same time. The interaction pairs were divided based on cell lines. Similar to the case for drugs, 10% (94/948) cell lines were randomly selected and their related IC<sub>50</sub> values were kept for testing. For the remaining 90% (904/948) cells, 90% of the related IC<sub>50</sub> were used for training and 10% for validating.</p>
      <p>The blind test for drugs on all data and on the data below max _conc were repeated for 150 times respectively to check the distribution of the results. The same number of experiments for the cell lines were also conducted. The results on all data are shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. The results on data below max_conc data are shown on Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S4 respectively.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Drug and cell blind test result on total data. Yellow color boxes represent the result of cells blind, and blue color boxes for drugs blind. From top to bottom is the result for <italic>R</italic><sup>2</sup>,<italic>R</italic><sub><italic>p</italic></sub> and RMSE respectively. The red star is the result without controlling data distribution</p></caption><graphic xlink:href="12859_2019_2910_Fig5_HTML" id="MO5"/></fig></p>
      <p>From Fig. <xref rid="Fig5" ref-type="fig">5</xref> and Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S4, it is observed that the performance of tCNNS was more robust with the blind test for cell lines but sensitive with the blind test for drugs. Without the knowledge of drugs in training, the performance dropped significantly. Comparing the results reported in Fig. <xref rid="Fig5" ref-type="fig">5</xref> and in the Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S4, it can be observed that the extrapolated data made no contribution in this setting.</p>
      <p>Comparing the results of the blind tests for drugs and for cell lines, the blind test for cell lines is slightly better, and the reason is that there is more common information shared among different cell lines and less among drugs. For example, cell lines share similar genetic information, but drugs can be very diversified. To reduce the information sharing among cells lines, another experimental setting was designed in which cell lines from the same tissue cannot exist in training and testing at the same time. The result was shown in Table <xref rid="Tab1" ref-type="table">1</xref>.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Tissue-Specific Test</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Tissue name</th><th align="left">Data amount</th><th align="left"><italic>R</italic><sup>2</sup></th><th align="left"><italic>R</italic><sub><italic>p</italic></sub></th><th align="left">RMSE</th></tr></thead><tbody><tr><td align="left">Aero digestive</td><td align="left">13806</td><td align="left">0.703</td><td align="left">0.843</td><td align="left">0.0375</td></tr><tr><td align="left">Tract</td><td align="left"/><td align="left">(0.826)</td><td align="left">(0.916)</td><td align="left">(0.0280)</td></tr><tr><td align="left">Blood</td><td align="left">31119</td><td align="left">0.500</td><td align="left">0.724</td><td align="left">0.0449</td></tr><tr><td align="left"/><td align="left"/><td align="left">(0.833)</td><td align="left">(0.917)</td><td align="left">(0.0276)</td></tr><tr><td align="left">Bone</td><td align="left">6826</td><td align="left">0.659</td><td align="left">0.813</td><td align="left">0.0405</td></tr><tr><td align="left"/><td align="left"/><td align="left">(0.825)</td><td align="left">(0.915)</td><td align="left">(0.0283)</td></tr><tr><td align="left">Breast</td><td align="left">9277</td><td align="left">0.657</td><td align="left">0.811</td><td align="left">0.0383</td></tr><tr><td align="left"/><td align="left"/><td align="left">(0.829)</td><td align="left">(0.919)</td><td align="left">(0.0281)</td></tr><tr><td align="left">Digestive</td><td align="left">17200</td><td align="left">0.667</td><td align="left">0.817</td><td align="left">0.0384</td></tr><tr><td align="left">System</td><td align="left"/><td align="left">(0.830)</td><td align="left">(0.918)</td><td align="left">(0.0282)</td></tr><tr><td align="left">Kidney</td><td align="left">5199</td><td align="left">0.669</td><td align="left">0.819</td><td align="left">0.0386</td></tr><tr><td align="left"/><td align="left"/><td align="left">(0.822)</td><td align="left">(0.914)</td><td align="left">(0.0286)</td></tr><tr><td align="left">Lung</td><td align="left">34086</td><td align="left">0.614</td><td align="left">0.784</td><td align="left">0.0371</td></tr><tr><td align="left"/><td align="left"/><td align="left">(0.827)</td><td align="left">(0.919)</td><td align="left">(0.0285)</td></tr><tr><td align="left">Nervous</td><td align="left">15763</td><td align="left">0.702</td><td align="left">0.839</td><td align="left">0.0364</td></tr><tr><td align="left">System</td><td align="left"/><td align="left">(0.830)</td><td align="left">(0.918)</td><td align="left">(0.0280)</td></tr><tr><td align="left">Pancreas</td><td align="left">5358</td><td align="left">0.703</td><td align="left">0.840</td><td align="left">0.0370</td></tr><tr><td align="left"/><td align="left"/><td align="left">(0.820)</td><td align="left">(0.913)</td><td align="left">(0.0287)</td></tr><tr><td align="left">Skin</td><td align="left">10488</td><td align="left">0.676</td><td align="left">0.824</td><td align="left">0.0394</td></tr><tr><td align="left"/><td align="left"/><td align="left">(0.827)</td><td align="left">(0.917)</td><td align="left">(0.0281)</td></tr><tr><td align="left">Soft tissue</td><td align="left">3165</td><td align="left">0.712</td><td align="left">0.853</td><td align="left">0.0384</td></tr><tr><td align="left"/><td align="left"/><td align="left">(0.821)</td><td align="left">(0.914)</td><td align="left">(0.0284)</td></tr><tr><td align="left">Thyroid</td><td align="left">2715</td><td align="left">0.672</td><td align="left">0.822</td><td align="left">0.0410</td></tr><tr><td align="left"/><td align="left"/><td align="left">(0.833)</td><td align="left">(0.918)</td><td align="left">(0.0277)</td></tr><tr><td align="left">Urogenital</td><td align="left">17112</td><td align="left">0.715</td><td align="left">0.849</td><td align="left">0.0363</td></tr><tr><td align="left">System</td><td align="left"/><td align="left">(0.825)</td><td align="left">(0.914)</td><td align="left">(0.0282)</td></tr></tbody></table><table-wrap-foot><p>The first column is the 13 tissue names which are ranged in alphabetical order. The second column is the number of the ground true IC<sub>50</sub> values for each tissue. The last three columns are <italic>R</italic><sup>2</sup>, <italic>R</italic><sub><italic>p</italic></sub> and RMSE that our model tCNNS achieved by training on all the other tissue data. The number in the bracket is the result for the validation set</p></table-wrap-foot></table-wrap></p>
      <p>In GDSC, the 948 cell lines belong to 13 tissue types and 49 sub-tissue types. The 13 tissue types were used instead of 49 sub-tissue types because it can increase the distances and reduce the similarities among different tissues. Each time one tissue type was selected as testing data. For the rest of the tissues, they were mixed together and split into 90% for training and 10% for validation. From Table <xref rid="Tab1" ref-type="table">1</xref>, it can be seen that the performance decrease differently for different tissues. For example, blood has the lowest <italic>R</italic><sup>2</sup> and <italic>R</italic><sub><italic>p</italic></sub> in all tissues, which indicated that blood is the most different tissue from other tissues.</p>
    </sec>
    <sec id="Sec13">
      <title>Cell lines features impacts</title>
      <p>In GDSC, the 735 features for cell lines after preprocessing belongs to 310 gene mutation states, and 425 copy number variations. As different laboratories may use different methods to extract the features for cell lines, in reality, it is not easy to have the complete 735 features for all cells. Besides, researchers may also have smaller and different feature groups for cell lines. It is attractive if tCNNS can have good performance with fewer features for cell lines. In this part, tCNNS performance was tested with different smaller numbers of features for cell lines to check the change of the performance with respect to the change of numbers of features for cell lines. The corresponding results in this part are shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>.
<fig id="Fig6"><label>Fig. 6</label><caption><p>Sensitivity to the number of features. The x-axis is the number of mutation states used for cells in the experiments, and the y-axis is the performance achieved by tCNNS</p></caption><graphic xlink:href="12859_2019_2910_Fig6_HTML" id="MO6"/></fig></p>
    </sec>
    <sec id="Sec14">
      <title>Biological meaning v.s statistical meaning</title>
      <p>tCNNS takes the one-hot representation of the SMILES format as the features for drugs. Initially, in the one-hot representation of the SMILES format, each row represents a symbol, and each column represents a position in the SMILES format, which is left aligned. For researchers, the SMILES format is a well-defined concept with biological meaning. However, tCNNS may lack the ability to comprehend the biological meaning of the SMILES format and it instead relies on the statistical pattern inside the data. To verify this hypothesis, the one-hot representation of the SMILES format was modified in three ways as follows: 
<list list-type="order"><list-item><p>The order of the symbols was randomly shuffled, which equals shuffling the rows in the one-hot representation.</p></list-item><list-item><p>The SMILES format was cut into two pieces, and the positions of which were switched. It is equivalent to shift the columns in the one-hot representation.</p></list-item><list-item><p>The positions in the SMILES format were shuffled, which equals to shuffling the columns in the one-hot representation.</p></list-item></list></p>
      <p>The experiments were repeated 10 times in the three settings respectively and the results were compared with those obtained by using the SMILES format without any modification. The comparison is shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S5. In the last two ways of the modification, the biological meaning of SMILES is corrupted. Initially, it was expected that the only the result of the first modification would be the same with the benchmark. It was surprising to see that the performances were similar in all three modifications. The stability among these results mean that tCNNS actually does not capture the biological meaning of the SMILES format for drugs, and it relied on the statistical patterns inside the SMILES format, cell line features, and the IC<sub>50</sub> values.</p>
    </sec>
    <sec id="Sec15">
      <title>Eliminating outliers</title>
      <p>In the last column of the Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S5, the results of tCNNS are compared with that of the baseline work [<xref ref-type="bibr" rid="CR2">2</xref>]. As GDSC has been changed in recent years, it was impossible to use the same data as [<xref ref-type="bibr" rid="CR2">2</xref>]. In the experiment, the method introduced in [<xref ref-type="bibr" rid="CR2">2</xref>] was applied to current data. PaDEL(version 2.1.1) was used to extract 778 features for each drug. For cell lines, 735 features were used, instead of the 157 features used in the old version of GDSC [<xref ref-type="bibr" rid="CR2">2</xref>].</p>
      <p>To check the differences between the features extracted using PaDEL and the features extracted from the SMILES descriptions using CNN, the distribution of the drugs were visualized in different feature spaces. In a deep neural network, the fully connected layer is responsible for regression analysis, and CNN is used for extracting high-level features from the drug features. The input data for the fully connected network is the output of CNN tranche. Hence when drawing the distribution of drugs using CNN, the output of the last layer of CNN tranche was used for drugs.</p>
      <p>The distribution of cell lines in genetic features space of GDSC was also compared with that found in the output space of the last layer in CNN. The visualization tool used was t-SNE [<xref ref-type="bibr" rid="CR50">50</xref>], which was widely used to visualize high dimensional data in deep learning. The visualization results are shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>. It can be seen that there were 7 outliers in the PaDEL space for drugs. However, the problem does not exist in the features space for drugs extracted by tCNNS.
<fig id="Fig7"><label>Fig. 7</label><caption><p>Visualization of drugs and cells in high-dimensional space. <bold>a</bold>) Drugs in PaDEL space (778 dims), <bold>b</bold>) Drugs in CNN space (420 dims), <bold>c</bold>) cells in mutation space (735 dims), and <bold>d</bold>) cells in CNN space (1680 dims)</p></caption><graphic xlink:href="12859_2019_2910_Fig7_HTML" id="MO7"/></fig></p>
      <p>To conclude, there are seven subsections in this section, and they are summarized as follows: 
<list list-type="bullet"><list-item><p>Rediscovering Known Drug-Cell Line Responses. In this part, tCNNS was trained on 80% data as the training set and tested on the other 10% data. The remaining 10% data were used as a validation set to decide when to stop training. The experiment was repeated 50 times and tCNNS achieves 0.826, 0.909 for mean <italic>R</italic><sup>2</sup>, <italic>R</italic><sub><italic>p</italic></sub> respectively, and 0.831, 0.912 for top quartile of <italic>R</italic><sup>2</sup>, <italic>R</italic><sub><italic>p</italic></sub> respectively.</p></list-item><list-item><p>Predicting Unknown Drug-Cell Line Responses. tCNNS was used to predict the missing interaction pairs in GDSC. A literature survey was carried out and some published works that support the predictions of tCNNS were found and discussed.</p></list-item><list-item><p>Retraining Without Extrapolated Activity Data. tCNNS was trained on max_conc data. Those IC<sub>50</sub> values below max_conc are divided as 80% for training, 10% for validation and 10% for testing. Figure <xref rid="Fig4" ref-type="fig">4</xref> shows that no statistically significant difference can be found between the results of tCNNS trained on data below max_conc and that on the whole data in 4.1.</p></list-item><list-item><p>Blind Test For Drugs And Cell lines. Drugs and cell lines were restricted from existing in the training set and the testing set at the same time. In the blind test, the performance of tCNNS drops significantly, especially in the drug blind test where the mean of <italic>R</italic><sub><italic>p</italic></sub> drops to 0.2 and the mean of <italic>R</italic><sup>2</sup> drops to barely above 0.</p></list-item><list-item><p>Cell Lines Features Impacts. The number of features for cell lines was reduced from about 700 to about 50. The mean of <italic>R</italic><sup>2</sup> remains above 0.80 when the number of features drops to 300, and it is still above 0.72 even when the number of features drops to 50.</p></list-item><list-item><p>Biological Meaning v.s Statistical Meaning. As the results remain almost the same with different modifications to the input data, it can be concluded that tCNNS relies on the statistical pattern, instead of capturing the biological meaning in the data.</p></list-item><list-item><p>Eliminating Outliers. 7 outliers exist in the traditional drug feature space. However, this problem does not exist in the feature space extracted from SMILES by tCNNS.</p></list-item></list></p>
    </sec>
  </sec>
  <sec id="Sec16" sec-type="discussion">
    <title>Discussion</title>
    <p>In Fig. <xref rid="Fig2" ref-type="fig">2</xref>, it can be observed that tCNNS is most accurate in the middle part, but less accurate in the two ends in the figure. In the bottom left corner, the input IC<sub>50</sub> values are small but the predictions of tCNNS are incorrectly large. In the top right corner, the input IC<sub>50</sub> values are large but the predictions of tCNNS are incorrectly small. This means that tCNNS can be further optimized if it can enhance its performance in these two areas.</p>
    <p>Based on these results, it is concluded that the connections between the IC<sub>50</sub> values and the SMILES format of drugs are stronger than those observed between the IC<sub>50</sub> values and the features extracted using PaDEL.</p>
    <p>Although the extrapolated data cannot enhance the accuracy of the model, they can help to improve scalability. The tCNNS model trained on all data performs well when tested on data below max_conc, which is natural because the later is a subset of the former. However, the model trained on data below max_conc performs poorly when tested on all data. <italic>R</italic><sup>2</sup> drops to 0.33 and <italic>R</italic><sub><italic>p</italic></sub> drops to 0.6. When tCNNS is trained on all data, it learns general knowledge which is useful on the whole dataset. That is why its performance remains stable when tested on data below max_conc. On the other hand, when tCNNS is trained on data below max_conc, it learns knowledge that only be applicable to this specific subset of all data. Its performance is dragged down by data above the max_conc when tested on all data. Although the performance of tCNNS on all data and data below max_conc is similar, the paths they achieve the performance are different.</p>
    <p>Comparing the result on data below max _conc with that on all data, it can be seen that the means of <italic>R</italic><sup>2</sup> were almost the same, and the mean of <italic>R</italic><sub><italic>p</italic></sub> on all data was only a bit better than that on the data below mac _conc. Moreover, the variations of <italic>R</italic><sup>2</sup> and <italic>R</italic><sub><italic>p</italic></sub> on data below max _conc was a bit bigger than those on all data. To conclude, the contribution from low quality extrapolated data was limited, and they can only reduce variation and improve <italic>R</italic><sub><italic>p</italic></sub> a bit.</p>
    <p>The results in the blind test give us some hint that with limited budgets, the in vivo experiment should be carefully arranged to cover a wider range of drugs and cells from different tissues to get better <italic>in silico</italic> predicting power.</p>
    <p>It is very important to have the specific drug or cell line in the training stage before the performance is predicted. Experimental results support that even with only one or two related IC<sub>50</sub> value, the performance will be significantly improved. For example, <italic>NCI-H378</italic> is a special cell line for lung cancer in GDSC, and there are only two IC<sub>50</sub> values records for it. For other cell lines, all of them have at least 20 IC<sub>50</sub> values. tCNNS can still make accurate predictions one of the IC<sub>50</sub> values for <italic>NCI-H378</italic> if the other value is used during the training. Based on the results, the best drug for <italic>NCI-H378</italic> is <italic>Bortezomib</italic>, which has been previously recalled [<xref ref-type="bibr" rid="CR48">48</xref>, <xref ref-type="bibr" rid="CR49">49</xref>].</p>
    <p>Moreover, tCNNS predicts another potential drug <italic>Docetaxel</italic> for them. The predicted IC<sub>50</sub> value between <italic>Docetaxel</italic> and <italic>NCI-H378</italic> is 0.03<italic>μ</italic><italic>g</italic> (third smallest for <italic>NCI-H378</italic>), and the predicted IC<sub>50</sub> between <italic>Docetaxel</italic> and <italic>NCI-H250</italic> is 0.04<italic>μ</italic><italic>g</italic> (forth smallest for <italic>NCI-H250</italic>). It is reported in [<xref ref-type="bibr" rid="CR51">51</xref>] that <italic>APR-246</italic> is a potential useful drug on lung cancer because of its synergy with <italic>T</italic><italic>P</italic>53 mutations in lung cells, and there is an <italic>"additive effects"</italic> between <italic>APR-246</italic> and <italic>Docetaxel</italic>.</p>
    <p>The visualization result of outliers highlights that CNN can distribute the drugs and cell lines more uniformly than features using PaDEL and features of GDSC. For drugs, those seven outliers in the PaDel space are exactly the seven drugs that are composed of multiple parts. The structures of the outliers are shown in the Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S6.</p>
  </sec>
  <sec id="Sec17" sec-type="conclusion">
    <title>Conclusion</title>
    <p>In this paper, a model called tCNNS has been illustrated for phenotypic screening between cancer cell lines and anti-cancer drugs. tCNNS has been tested on a new version of GDSC with more data compared to previous works. It has achieved a much better coefficient of determinant and Pearson correlation than previous works and has made predictions for missing values in GDSC with trustful evidence. tCNNS can also converge with a very small set of training data and fewer features for cancer cell lines, which is economically efficient. tCNNS can take SMILES as input data for drugs, and this can solve the outlier problem occured in previous works where drug fingerprints are used as features.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Additional file</title>
    <sec id="Sec18">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2019_2910_MOESM1_ESM.pdf">
            <label>Additional file 1</label>
            <caption>
              <p>Supplementary. Some experiments results and figures are in the supplementary file of this paper. (PDF 378 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>
          <italic>R</italic>
          <sup>2</sup>
        </term>
        <def>
          <p>Coefficient of determination</p>
        </def>
      </def-item>
      <def-item>
        <term>
          <italic>R</italic>
          <sub>
            <italic>p</italic>
          </sub>
        </term>
        <def>
          <p>Pearson correlation</p>
        </def>
      </def-item>
      <def-item>
        <term>RMSE</term>
        <def>
          <p>Root mean square error</p>
        </def>
      </def-item>
      <def-item>
        <term>tCNNS</term>
        <def>
          <p>Twin convolutional neural network for drugs in SMILES format</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to thank the reviewers for their detailed suggestions which greatly improved the quality and readability of this work.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>HL come up with the original idea and joined the discussion with PL, SL and KL. PL collected the data, built the model and conducted the experiments. SL and KL modified the manuscript many times to improve its quality. All authors read and approved the final manuscript</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported by The Chinese University of Hong Kong Direct Grants [ID: 4055073 and 4055104].</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The authors declare that they have provided the code and data publicly accessible, which can be downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/Lowpassfilter/tCNNS-Project">https://github.com/Lowpassfilter/tCNNS-Project</ext-link>.</p>
  </notes>
  <notes>
    <title>Ethics approval and consent to participate</title>
    <p>Not applicable.</p>
  </notes>
  <notes>
    <title>Consent for publication</title>
    <p>Not applicable.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p>The authors declare that they have no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1</label>
      <mixed-citation publication-type="other">Cancer Cell Line Encyclopedia Consortium. Genomics of Drug Sensitivity in Cancer Consortium: Pharmacogenomic agreement between two cancer cell line data sets. Nature. 2015; 528(7580):84.</mixed-citation>
    </ref>
    <ref id="CR2">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Menden</surname>
            <given-names>MP</given-names>
          </name>
          <name>
            <surname>Iorio</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Garnett</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>McDermott</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Benes</surname>
            <given-names>CH</given-names>
          </name>
          <name>
            <surname>Ballester</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Saez-Rodriguez</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Machine learning prediction of cancer cell sensitivity to drugs based on genomic and chemical properties</article-title>
        <source>PLoS ONE</source>
        <year>2013</year>
        <volume>8</volume>
        <issue>4</issue>
        <fpage>61318</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0061318</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ammad-Ud-Din</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Georgii</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Gonen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Laitinen</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Kallioniemi</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Wennerberg</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Poso</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kaski</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Integrative and personalized qsar analysis in cancer by kernelized bayesian matrix factorization</article-title>
        <source>J Chem Inf Model</source>
        <year>2014</year>
        <volume>54</volume>
        <issue>8</issue>
        <fpage>2347</fpage>
        <lpage>59</lpage>
        <pub-id pub-id-type="doi">10.1021/ci500152b</pub-id>
        <pub-id pub-id-type="pmid">25046554</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Haider</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Rahman</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Ghosh</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Pal</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>A copula based approach for design of multivariate random forests for drug sensitivity prediction</article-title>
        <source>PLoS ONE</source>
        <year>2015</year>
        <volume>10</volume>
        <issue>12</issue>
        <fpage>0144490</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0144490</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mitchell</surname>
            <given-names>JB</given-names>
          </name>
        </person-group>
        <article-title>Machine learning methods in chemoinformatics</article-title>
        <source>Wiley Interdiscip Rev Comput Mol Sci</source>
        <year>2014</year>
        <volume>4</volume>
        <issue>5</issue>
        <fpage>468</fpage>
        <lpage>81</lpage>
        <pub-id pub-id-type="doi">10.1002/wcms.1183</pub-id>
        <pub-id pub-id-type="pmid">25285160</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Goh</surname>
            <given-names>GB</given-names>
          </name>
          <name>
            <surname>Hodas</surname>
            <given-names>NO</given-names>
          </name>
          <name>
            <surname>Vishnu</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Deep learning for computational chemistry</article-title>
        <source>J Comput Chem</source>
        <year>2017</year>
        <volume>38</volume>
        <issue>16</issue>
        <fpage>1291</fpage>
        <lpage>307</lpage>
        <pub-id pub-id-type="doi">10.1002/jcc.24764</pub-id>
        <pub-id pub-id-type="pmid">28272810</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mamoshina</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Vieira</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Putin</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Zhavoronkov</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Applications of deep learning in biomedicine</article-title>
        <source>Mol Pharm</source>
        <year>2016</year>
        <volume>13</volume>
        <issue>5</issue>
        <fpage>1445</fpage>
        <lpage>54</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.molpharmaceut.5b00982</pub-id>
        <pub-id pub-id-type="pmid">27007977</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Cruz-Roa</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Ovalle</surname>
            <given-names>JEA</given-names>
          </name>
          <name>
            <surname>Madabhushi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Osorio</surname>
            <given-names>FAG</given-names>
          </name>
        </person-group>
        <article-title>A deep learning architecture for image representation, visual interpretability and automated basal-cell carcinoma cancer detection</article-title>
        <source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source>
        <year>2013</year>
        <publisher-loc>Berlin</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Litjens</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Kooi</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Bejnordi</surname>
            <given-names>BE</given-names>
          </name>
          <name>
            <surname>Setio</surname>
            <given-names>AAA</given-names>
          </name>
          <name>
            <surname>Ciompi</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Ghafoorian</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>van der Laak</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Van Ginneken</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Sánchez</surname>
            <given-names>CI</given-names>
          </name>
        </person-group>
        <article-title>A survey on deep learning in medical image analysis</article-title>
        <source>Med Image Anal</source>
        <year>2017</year>
        <volume>42</volume>
        <fpage>60</fpage>
        <lpage>88</lpage>
        <pub-id pub-id-type="doi">10.1016/j.media.2017.07.005</pub-id>
        <pub-id pub-id-type="pmid">28778026</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ragoza</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hochuli</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Idrobo</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Sunseri</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Koes</surname>
            <given-names>DR</given-names>
          </name>
        </person-group>
        <article-title>Protein–ligand scoring with convolutional neural networks</article-title>
        <source>J Chem Inf Model</source>
        <year>2017</year>
        <volume>57</volume>
        <issue>4</issue>
        <fpage>942</fpage>
        <lpage>57</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.6b00740</pub-id>
        <pub-id pub-id-type="pmid">28368587</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11</label>
      <mixed-citation publication-type="other">Yosinski J, Clune J, Bengio Y, Lipson H. How transferable are features in deep neural networks?. In: Advances in Neural Information Processing Systems. Curran Associates Inc., USA: 2014. p. 3320–8.</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12</label>
      <mixed-citation publication-type="other">Kalchbrenner N, Grefenstette E, Blunsom P. A convolutional neural network for modelling sentences. 2014. arXiv preprint arXiv:1404.2188.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Protein secondary structure prediction using deep convolutional neural fields</article-title>
        <source>Sci Rep</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>18962</fpage>
        <pub-id pub-id-type="doi">10.1038/srep18962</pub-id>
        <pub-id pub-id-type="pmid">26752681</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Mobadersany</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Yousefi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Amgad</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Gutman</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Barnholtz-Sloan</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Vega</surname>
            <given-names>JEV</given-names>
          </name>
          <name>
            <surname>Brat</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Cooper</surname>
            <given-names>LA</given-names>
          </name>
        </person-group>
        <article-title>Predicting cancer outcomes from histology and genomics using convolutional networks</article-title>
        <source>Proceedings of the National Academy of Sciences vol. 115</source>
        <year>2018</year>
        <publisher-loc>Washington</publisher-loc>
        <publisher-name>National Acad Sciences</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15</label>
      <mixed-citation publication-type="other">Krizhevsky A, Sutskever I, Hinton GE. Imagenet classification with deep convolutional neural networks. In: Advances in Neural Information Processing Systems. Curran Associates Inc., USA: 2012. p. 1097–105.</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gawehn</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Hiss</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Schneider</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Deep learning in drug discovery</article-title>
        <source>Mol Inf</source>
        <year>2016</year>
        <volume>35</volume>
        <issue>1</issue>
        <fpage>3</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="doi">10.1002/minf.201501008</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <mixed-citation publication-type="other">Gómez-Bombarelli R, Duvenaud D, Hernández-Lobato JM, Aguilera-Iparraguirre J, Hirzel TD, Adams RP, Aspuru-Guzik A. Automatic chemical design using a data-driven continuous representation of molecules. 2016. arXiv preprint arXiv:1610.02415.</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <mixed-citation publication-type="other">Gomes J, Ramsundar B, Feinberg EN, Pande VS. Atomic convolutional networks for predicting protein-ligand binding affinity. 2017. arXiv preprint arXiv:1703.10603.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gómez-Bombarelli</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>JN</given-names>
          </name>
          <name>
            <surname>Duvenaud</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hernández-Lobato</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Sánchez-Lengeling</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Sheberla</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Aguilera-Iparraguirre</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hirzel</surname>
            <given-names>TD</given-names>
          </name>
          <name>
            <surname>Adams</surname>
            <given-names>RP</given-names>
          </name>
          <name>
            <surname>Aspuru-Guzik</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Automatic chemical design using a data-driven continuous representation of molecules</article-title>
        <source>ACS Cent Sci</source>
        <year>2018</year>
        <volume>4</volume>
        <issue>2</issue>
        <fpage>268</fpage>
        <lpage>76</lpage>
        <pub-id pub-id-type="doi">10.1021/acscentsci.7b00572</pub-id>
        <pub-id pub-id-type="pmid">29532027</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Altae-Tran</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ramsundar</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Pappu</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>Pande</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Low data drug discovery with one-shot learning</article-title>
        <source>ACS Cent Sci</source>
        <year>2017</year>
        <volume>3</volume>
        <issue>4</issue>
        <fpage>283</fpage>
        <lpage>93</lpage>
        <pub-id pub-id-type="doi">10.1021/acscentsci.6b00367</pub-id>
        <pub-id pub-id-type="pmid">28470045</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Czarnecki</surname>
            <given-names>WM</given-names>
          </name>
        </person-group>
        <article-title>Weighted tanimoto extreme learning machine with case study in drug discovery</article-title>
        <source>IEEE Comput Intell Mag</source>
        <year>2015</year>
        <volume>10</volume>
        <issue>3</issue>
        <fpage>19</fpage>
        <lpage>29</lpage>
        <pub-id pub-id-type="doi">10.1109/MCI.2015.2437312</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vass</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kooistra</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Ritschel</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Leurs</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>de Esch</surname>
            <given-names>IJ</given-names>
          </name>
          <name>
            <surname>de Graaf</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Molecular interaction fingerprint approaches for gpcr drug discovery</article-title>
        <source>Curr Opin Pharmacol</source>
        <year>2016</year>
        <volume>30</volume>
        <fpage>59</fpage>
        <lpage>68</lpage>
        <pub-id pub-id-type="doi">10.1016/j.coph.2016.07.007</pub-id>
        <pub-id pub-id-type="pmid">27479316</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lavecchia</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Machine-learning approaches in drug discovery: methods and applications</article-title>
        <source>Drug Discov Today</source>
        <year>2015</year>
        <volume>20</volume>
        <issue>3</issue>
        <fpage>318</fpage>
        <lpage>31</lpage>
        <pub-id pub-id-type="doi">10.1016/j.drudis.2014.10.012</pub-id>
        <pub-id pub-id-type="pmid">25448759</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sliwoski</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Kothiwale</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Meiler</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Lowe</surname>
            <given-names>EW</given-names>
          </name>
        </person-group>
        <article-title>Computational methods in drug discovery</article-title>
        <source>Pharmacol Rev</source>
        <year>2014</year>
        <volume>66</volume>
        <issue>1</issue>
        <fpage>334</fpage>
        <lpage>95</lpage>
        <pub-id pub-id-type="doi">10.1124/pr.112.007336</pub-id>
        <pub-id pub-id-type="pmid">24381236</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Inferences of drug responses in cancer cells from cancer genomic features and compound chemical and therapeutic properties</article-title>
        <source>Sci Rep</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>32679</fpage>
        <pub-id pub-id-type="doi">10.1038/srep32679</pub-id>
        <pub-id pub-id-type="pmid">27645580</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rahman</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Matlock</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Ghosh</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Pal</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Heterogeneity aware random forest for drug sensitivity prediction</article-title>
        <source>Sci Rep</source>
        <year>2017</year>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>11347</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-017-11665-4</pub-id>
        <pub-id pub-id-type="pmid">28900181</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>MQ</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Cooper</surname>
            <given-names>GF</given-names>
          </name>
          <name>
            <surname>Young</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Precision oncology beyond targeted therapy: Combining omics data with machine learning matches the majority of cancer cells to effective therapeutics</article-title>
        <source>Mol Cancer Res</source>
        <year>2018</year>
        <volume>16</volume>
        <issue>2</issue>
        <fpage>269</fpage>
        <lpage>78</lpage>
        <pub-id pub-id-type="doi">10.1158/1541-7786.MCR-17-0378</pub-id>
        <pub-id pub-id-type="pmid">29133589</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>XS</given-names>
          </name>
        </person-group>
        <article-title>Predicting anticancer drug responses using a dual-layer integrated cell line-drug network model</article-title>
        <source>PLoS Comput Biol</source>
        <year>2015</year>
        <volume>11</volume>
        <issue>9</issue>
        <fpage>1004498</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1004498</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ammad-ud-din</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Malani</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Murumägi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kallioniemi</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Aittokallio</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Kaski</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Drug response prediction by inferring pathway-response associations with kernelized bayesian matrix factorization</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <issue>17</issue>
        <fpage>455</fpage>
        <lpage>63</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw433</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Suphavilai</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Bertrand</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Nagarajan</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Predicting cancer drug response using a recommender system</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>22</issue>
        <fpage>3907</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty452</pub-id>
        <pub-id pub-id-type="pmid">29868820</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31</label>
      <mixed-citation publication-type="other">Ali M, Aittokallio T. Machine learning and feature selection for drug response prediction in precision oncology applications. Biophys Rev. 2018:1–9.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kearnes</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>McCloskey</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Berndl</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Pande</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Riley</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Molecular graph convolutions: moving beyond fingerprints</article-title>
        <source>J Comput Aided Mol Des</source>
        <year>2016</year>
        <volume>30</volume>
        <issue>8</issue>
        <fpage>595</fpage>
        <lpage>608</lpage>
        <pub-id pub-id-type="doi">10.1007/s10822-016-9938-8</pub-id>
        <pub-id pub-id-type="pmid">27558503</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Seq2seq fingerprint: An unsupervised deep molecular embedding for drug discovery</article-title>
        <source>Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics</source>
        <year>2017</year>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>ACM</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34</label>
      <mixed-citation publication-type="other">Goh GB, Siegel C, Vishnu A, Hodas NO, Baker N. How much chemistry does a deep neural network need to know to make accurate predictions? 2017. arXiv preprint arXiv:1710.02238.</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35</label>
      <mixed-citation publication-type="other">Wallach I, Dzamba M, Heifets A. Atomnet: a deep convolutional neural network for bioactivity prediction in structure-based drug discovery. 2015. arXiv preprint arXiv:1510.02855.</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yap</surname>
            <given-names>CW</given-names>
          </name>
        </person-group>
        <article-title>Padel-descriptor: An open source software to calculate molecular descriptors and fingerprints</article-title>
        <source>J Comput Chem</source>
        <year>2011</year>
        <volume>32</volume>
        <issue>7</issue>
        <fpage>1466</fpage>
        <lpage>74</lpage>
        <pub-id pub-id-type="doi">10.1002/jcc.21707</pub-id>
        <pub-id pub-id-type="pmid">21425294</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Yao</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Torabi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Cho</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Ballas</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Pal</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Larochelle</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Courville</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Describing videos by exploiting temporal structure</article-title>
        <source>Proceedings of the IEEE International Conference on Computer Vision</source>
        <year>2015</year>
        <publisher-loc>Washington</publisher-loc>
        <publisher-name>IEEE Computer Society</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lusci</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Pollastri</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Baldi</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Deep architectures and deep learning in chemoinformatics: the prediction of aqueous solubility for drug-like molecules</article-title>
        <source>J Chem Inf Model</source>
        <year>2013</year>
        <volume>53</volume>
        <issue>7</issue>
        <fpage>1563</fpage>
        <lpage>75</lpage>
        <pub-id pub-id-type="doi">10.1021/ci400187y</pub-id>
        <pub-id pub-id-type="pmid">23795551</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Garnett</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Edelman</surname>
            <given-names>EJ</given-names>
          </name>
          <name>
            <surname>Heidorn</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Greenman</surname>
            <given-names>CD</given-names>
          </name>
          <name>
            <surname>Dastur</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lau</surname>
            <given-names>KW</given-names>
          </name>
          <name>
            <surname>Greninger</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Thompson</surname>
            <given-names>IR</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Soares</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Systematic identification of genomic markers of drug sensitivity in cancer cells</article-title>
        <source>Nature</source>
        <year>2012</year>
        <volume>483</volume>
        <issue>7391</issue>
        <fpage>570</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="doi">10.1038/nature11005</pub-id>
        <pub-id pub-id-type="pmid">22460902</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Thiessen</surname>
            <given-names>PA</given-names>
          </name>
          <name>
            <surname>Bolton</surname>
            <given-names>EE</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Gindulyte</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Shoemaker</surname>
            <given-names>BA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Pubchem substance and compound databases</article-title>
        <source>Nucleic Acids Res</source>
        <year>2015</year>
        <volume>44</volume>
        <issue>D1</issue>
        <fpage>1202</fpage>
        <lpage>13</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv951</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>O’Boyle</surname>
            <given-names>NM</given-names>
          </name>
        </person-group>
        <article-title>Towards a universal smiles representation-a standard method to generate canonical smiles based on the inchi</article-title>
        <source>J Cheminformatics</source>
        <year>2012</year>
        <volume>4</volume>
        <issue>1</issue>
        <fpage>22</fpage>
        <pub-id pub-id-type="doi">10.1186/1758-2946-4-22</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Keenan</surname>
            <given-names>AB</given-names>
          </name>
          <name>
            <surname>Jenkins</surname>
            <given-names>SL</given-names>
          </name>
          <name>
            <surname>Jagodnik</surname>
            <given-names>KM</given-names>
          </name>
          <name>
            <surname>Koplev</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Torre</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Dohlman</surname>
            <given-names>AB</given-names>
          </name>
          <name>
            <surname>Silverstein</surname>
            <given-names>MC</given-names>
          </name>
          <name>
            <surname>Lachmann</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The library of integrated network-based cellular signatures nih program: system-level cataloging of human cells response to perturbations</article-title>
        <source>Cell Syst</source>
        <year>2018</year>
        <volume>6</volume>
        <issue>1</issue>
        <fpage>13</fpage>
        <lpage>24</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2017.11.001</pub-id>
        <pub-id pub-id-type="pmid">29199020</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kelley</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>Snoek</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Rinn</surname>
            <given-names>JL</given-names>
          </name>
        </person-group>
        <article-title>Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks</article-title>
        <source>Genome Res</source>
        <year>2016</year>
        <volume>26</volume>
        <issue>7</issue>
        <fpage>990</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.200535.115</pub-id>
        <pub-id pub-id-type="pmid">27197224</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Abadi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Barham</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Davis</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Dean</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Devin</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ghemawat</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Irving</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Isard</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Tensorflow: a system for large-scale machine learning</article-title>
        <source>OSDI, vol. 16</source>
        <year>2016</year>
        <publisher-loc>Berkeley</publisher-loc>
        <publisher-name>USENIX Association</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45</label>
      <mixed-citation publication-type="other">Sawant A, Bhandari M, Yadav R, Yele R, Bendale MS. Brain cancer detection from mri: A machine learning approach (tensorflow). Brain. 2018;5(04).</mixed-citation>
    </ref>
    <ref id="CR46">
      <label>46</label>
      <mixed-citation publication-type="other">Kawaguchi K. Deep learning without poor local minima. In: Advances in Neural Information Processing Systems. Curran Associates Inc., USA: 2016. p. 586–94.</mixed-citation>
    </ref>
    <ref id="CR47">
      <label>47</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Friedman</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Amzallag</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Pruteanu-Malinici</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Baniya</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Cooper</surname>
            <given-names>ZA</given-names>
          </name>
          <name>
            <surname>Piris</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hargreaves</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Igras</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Frederick</surname>
            <given-names>DT</given-names>
          </name>
          <name>
            <surname>Lawrence</surname>
            <given-names>DP</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Landscape of targeted anti-cancer drug synergies in melanoma identifies a novel braf-vegfr/pdgfr combination treatment</article-title>
        <source>PLoS ONE</source>
        <year>2015</year>
        <volume>10</volume>
        <issue>10</issue>
        <fpage>0140310</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0140310</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ge</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>C-L</given-names>
          </name>
          <name>
            <surname>Bi</surname>
            <given-names>L-J</given-names>
          </name>
          <name>
            <surname>Tao</surname>
            <given-names>S-C</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Yin</surname>
            <given-names>X-F</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L-P</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>C-H</given-names>
          </name>
          <name>
            <surname>Jia</surname>
            <given-names>H-T</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>Q-Y</given-names>
          </name>
        </person-group>
        <article-title>Quantitative phosphoproteomics of proteasome inhibition in multiple myeloma cells</article-title>
        <source>PLoS ONE</source>
        <year>2010</year>
        <volume>5</volume>
        <issue>9</issue>
        <fpage>13095</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0013095</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hornbeck</surname>
            <given-names>PV</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Murray</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Kornhauser</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Latham</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Skrzypek</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Phosphositeplus, 2014: mutations, ptms and recalibrations</article-title>
        <source>Nucleic Acids Res</source>
        <year>2014</year>
        <volume>43</volume>
        <issue>D1</issue>
        <fpage>512</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gku1267</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Maaten</surname>
            <given-names>Lvd</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Visualizing data using t-sne</article-title>
        <source>J Mach Learn Res</source>
        <year>2008</year>
        <volume>9</volume>
        <issue>Nov</issue>
        <fpage>2579</fpage>
        <lpage>605</lpage>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mohell</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Alfredsson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Fransson</surname>
            <given-names>Å</given-names>
          </name>
          <name>
            <surname>Uustalu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Byström</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Gullbo</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hallberg</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bykov</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Björklund</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Wiman</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Apr-246 overcomes resistance to cisplatin and doxorubicin in ovarian cancer cells</article-title>
        <source>Cell Death Dis</source>
        <year>2015</year>
        <volume>6</volume>
        <issue>6</issue>
        <fpage>1794</fpage>
        <pub-id pub-id-type="doi">10.1038/cddis.2015.143</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
