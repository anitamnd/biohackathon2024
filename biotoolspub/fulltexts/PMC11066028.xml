<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Mol Syst Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">Mol Syst Biol</journal-id>
    <journal-title-group>
      <journal-title>Molecular Systems Biology</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1744-4292</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">11066028</article-id>
    <article-id pub-id-type="pmid">38472305</article-id>
    <article-id pub-id-type="publisher-id">29</article-id>
    <article-id pub-id-type="doi">10.1038/s44320-024-00029-6</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>PIFiA: self-supervised approach for protein functional annotation from single-cell imaging data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Razdaibiedina</surname>
          <given-names>Anastasia</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Brechalov</surname>
          <given-names>Alexander</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Friesen</surname>
          <given-names>Helena</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mattiazzi Usaj</surname>
          <given-names>Mojca</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Masinas</surname>
          <given-names>Myra Paz David</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Garadi Suresh</surname>
          <given-names>Harsha</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Kyle</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3542-6760</contrib-id>
        <name>
          <surname>Boone</surname>
          <given-names>Charles</given-names>
        </name>
        <address>
          <email>charlie.boone@utoronto.ca</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0009-0000-9062-4180</contrib-id>
        <name>
          <surname>Ba</surname>
          <given-names>Jimmy</given-names>
        </name>
        <address>
          <email>jba@cs.toronto.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6427-6493</contrib-id>
        <name>
          <surname>Andrews</surname>
          <given-names>Brenda</given-names>
        </name>
        <address>
          <email>brenda.andrews@utoronto.ca</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03dbr7087</institution-id><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>Department of Molecular Genetics, </institution><institution>University of Toronto, </institution></institution-wrap>Toronto, ON Canada </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03dbr7087</institution-id><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>The Donnelly Centre, </institution><institution>University of Toronto, </institution></institution-wrap>Toronto, ON Canada </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03kqdja62</institution-id><institution-id institution-id-type="GRID">grid.494618.6</institution-id><institution-id institution-id-type="ISNI">0000 0005 0272 1351</institution-id><institution>Vector Institute for Artificial Intelligence, </institution></institution-wrap>Toronto, ON Canada </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/010rf2m76</institution-id><institution-id institution-id-type="GRID">grid.509461.f</institution-id><institution-id institution-id-type="ISNI">0000 0004 1757 8255</institution-id><institution>RIKEN Center for Sustainable Resource Science, </institution></institution-wrap>2-1 Hirosawa, Wako, Saitama, Japan </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03dbr7087</institution-id><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>Department of Computer Science, </institution><institution>University of Toronto, </institution></institution-wrap>Toronto, ON Canada </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05g13zd79</institution-id><institution-id institution-id-type="GRID">grid.68312.3e</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 9422</institution-id><institution>Present Address: Department of Chemistry and Biology, </institution><institution>Toronto Metropolitan University, </institution></institution-wrap>Toronto, ON Canada </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>12</day>
      <month>3</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>12</day>
      <month>3</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>5</month>
      <year>2024</year>
    </pub-date>
    <volume>20</volume>
    <issue>5</issue>
    <fpage>521</fpage>
    <lpage>548</lpage>
    <history>
      <date date-type="received">
        <day>15</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>27</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="accepted">
        <day>28</day>
        <month>2</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. Creative Commons Public Domain Dedication waiver <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link> applies to the data associated with this article, unless otherwise stated in a credit line to the data, but does not extend to the graphical or creative elements of illustrations, charts, or figures. This waiver removes legal barriers to the re-use and mining of research data. According to standard scholarly practice, it is recommended to provide appropriate citation and attribution whenever technically possible.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Fluorescence microscopy data describe protein localization patterns at single-cell resolution and have the potential to reveal whole-proteome functional information with remarkable precision. Yet, extracting biologically meaningful representations from cell micrographs remains a major challenge. Existing approaches often fail to learn robust and noise-invariant features or rely on supervised labels for accurate annotations. We developed PIFiA (Protein Image-based Functional Annotation), a self-supervised approach for protein functional annotation from single-cell imaging data. We imaged the global yeast ORF-GFP collection and applied PIFiA to generate protein feature profiles from single-cell images of fluorescently tagged proteins. We show that PIFiA outperforms existing approaches for molecular representation learning and describe a range of downstream analysis tasks to explore the information content of the feature profiles. Specifically, we cluster extracted features into a hierarchy of functional organization, study cell population heterogeneity, and develop techniques to distinguish multi-localizing proteins and identify functional modules. Finally, we confirm new PIFiA predictions using a colocalization assay, suggesting previously unappreciated biological roles for several proteins. Paired with a fully interactive website (<ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia/">https://thecellvision.org/pifia/</ext-link>), PIFiA is a resource for the quantitative analysis of protein organization within the cell.</p>
    </abstract>
    <abstract id="Abs2" abstract-type="Synopsis">
      <title>Synopsis</title>
      <p id="Par2">
        <graphic position="anchor" xlink:href="44320_2024_29_Figa_HTML" id="d33e294"/>
      </p>
      <p id="Par3">PIFiA is a self-supervised deep-learning approach for protein functional annotation from single-cell images. It generates feature profiles from images of the yeast ORF-GFP collection that can be used in downstream analyses.</p>
      <p id="Par4">
        <list list-type="bullet">
          <list-item>
            <p id="Par5">PIFiA features identify new functional groups of proteins within organelles and proteins with heterogeneous localizations.</p>
          </list-item>
          <list-item>
            <p id="Par6">PIFiA features successfully predict protein–protein interactions and members of protein complexes.</p>
          </list-item>
          <list-item>
            <p id="Par7">PIFiA outperforms previous methods on four different standards of protein function.</p>
          </list-item>
          <list-item>
            <p id="Par8">Images and analysis are available at thecellvision.org/pifia.</p>
          </list-item>
        </list>
      </p>
    </abstract>
    <abstract id="Abs3" abstract-type="web-summary">
      <p id="Par9">PIFiA is a self-supervised deep-learning approach for protein functional annotation from single-cell images. It generates feature profiles from images of the yeast ORF-GFP collection that can be used in downstream analyses.</p>
      <p id="Par10">
        <graphic position="anchor" xlink:href="44320_2024_29_Figb_HTML" id="d33e321"/>
      </p>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Self-supervised</kwd>
      <kwd>Machine Learning</kwd>
      <kwd>Single-cell</kwd>
      <kwd>Imaging</kwd>
      <kwd>Protein</kwd>
    </kwd-group>
    <kwd-group kwd-group-type="embo-subject">
      <title>Subject terms</title>
      <kwd>Methods &amp; Resources</kwd>
      <kwd>Organelles</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
            <institution>HHS | National Institutes of Health (NIH)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01HG005853</award-id>
        <principal-award-recipient>
          <name>
            <surname>Friesen</surname>
            <given-names>Helena</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000024</institution-id>
            <institution>Canadian Government | Canadian Institutes of Health Research (CIHR)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>PJT-180259</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100007631</institution-id>
            <institution>Canadian Institute for Advanced Research (ICRA)</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100016327</institution-id>
            <institution>Ontario Government | Ministère des Services à l'enfance et des Services sociaux et communautaires, Gouvernement de l'Ontario (Ministry of Children, Community and Social Services, Government of Ontario)</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100019117</institution-id>
            <institution>Vector Institute (Institut Vecteur)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>PGA Fellowship</award-id>
        <principal-award-recipient>
          <name>
            <surname>Razdaibiedina</surname>
            <given-names>Anastasia</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© European Molecular Biology Organization 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par11">Recent progress in high-throughput microscopy and computational image analysis has catalyzed large-scale efforts to quantitatively describe single-cell biology (Cho et al, <xref ref-type="bibr" rid="CR5">2022</xref>; Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Mattiazzi Usaj et al, <xref ref-type="bibr" rid="CR39">2020</xref>; Mattiazzi Usaj et al, <xref ref-type="bibr" rid="CR40">2016</xref>; Thul et al, <xref ref-type="bibr" rid="CR59">2017</xref>; Thul and Lindskog, <xref ref-type="bibr" rid="CR60">2018</xref>). Advances in quantitative analysis of large-scale image datasets have been driven by the development of algorithms for protein localization prediction, which have been used for automated drug screening, and extracting morphological profiles from cell images (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>; McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>). Computational methods enable efficient analysis of millions of single-cell images by extracting morphological information in an unbiased quantitative form. However, generating meaningful numerical features from single-cell images remains a significant challenge. Cells in micrographs typically exhibit a variety of shapes and positions, while noise levels and pixel intensities can also vary between images, making it difficult to develop algorithms that extract functionally rich patterns while ignoring irrelevant information (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). For instance, early machine-learning approaches relied on hand-engineered feature sets extracted from images, such as cell texture and shape, which were often difficult to select and not transferable to other datasets or tasks (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>). Ideally, a computational workflow would map single cells and proteins to robust numerical representations, enabling analysis of the spatial organization of the cell in an objective way.</p>
    <p id="Par12">More recently, single-cell images have been analyzed using deep learning methods, which overcome the limitations associated with hand-engineered feature sets by learning the optimal feature representations directly from pixel level data (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Grys et al, <xref ref-type="bibr" rid="CR17">2017</xref>). The first machine-learning approaches for automated analysis of proteins’ localization patterns were supervised (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). Such methods were trained on a specific classification task, such as predicting cellular compartments from the input images (Grys et al, <xref ref-type="bibr" rid="CR17">2017</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). While supervised methods achieve state-of-the-art performance in their target tasks, they require manual annotation of images used for training, which is time-consuming and expensive. In one of the efforts to accelerate label collection, the Human Atlas Project leveraged crowd-sourcing on a large scale, involving thousands of video games players for microscopy image annotation (Sullivan et al, <xref ref-type="bibr" rid="CR58">2018</xref>). However, manual label assignment is still not practical for imaging datasets containing millions of single-cell micrographs (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). In addition, human-labeled standards may reflect the biases of an individual annotator and can preclude identification of subtle or incompletely penetrant phenotypes (Kraus et al, <xref ref-type="bibr" rid="CR35">2016</xref>; Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>). These problems motivated the development of methods that do not rely on supervised annotations during training (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>; Moshkov et al, <xref ref-type="bibr" rid="CR45">2024</xref>).</p>
    <p id="Par13">An emerging alternative to supervised methods for biological image analysis involves self-supervised approaches, which do not require manually assigned categories during training (Chen et al, <xref ref-type="bibr" rid="CR4">2020</xref>; Jenni and Favaro, <xref ref-type="bibr" rid="CR27">2018</xref>; Jing and Tian, <xref ref-type="bibr" rid="CR28">2020</xref>). Instead, self-supervised learning models define a training objective, or pretext task, using structural information from the data itself (Jaiswal et al, <xref ref-type="bibr" rid="CR26">2020</xref>; Jing and Tian, <xref ref-type="bibr" rid="CR28">2020</xref>; Kolesnikov et al, <xref ref-type="bibr" rid="CR34">2019</xref>). In the context of self-supervised training, features learned with the pretext task should encapsulate information from the images that is useful for downstream applications, such as the discovery of common localization patterns by clustering analysis (Sullivan et al, <xref ref-type="bibr" rid="CR58">2018</xref>). Recently, self-supervised and weakly-supervised methods based on auto-encoders have been used for representation learning on cellular data (Guo et al, <xref ref-type="bibr" rid="CR18">2020</xref>; Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>; Zaritsky et al, <xref ref-type="bibr" rid="CR67">2021</xref>). For example, weakly supervised learning with convolutional neural networks has been successfully applied for modeling associations between images and treatments, significantly improving performance over classical features (Moshkov et al, <xref ref-type="bibr" rid="CR45">2024</xref>). Autoencoder-based models are trained by compressing an image into the latent space (encoding), and subsequent image reconstruction (decoding) (Kingma and Welling, <xref ref-type="bibr" rid="CR31">2013</xref>). The encoding of the image in the latent space is then used as its representation. For instance, Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>), a self-supervised approach developed for analysis of yeast fluorescent micrographs, encodes several imaging channels to predict the appearance of a fluorescently-tagged protein in a target cell. Another autoencoder-based method developed for human cell data, <italic>cytoself</italic> (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>), trains a vector-quantized variational autoencoder (Kingma and Welling, <xref ref-type="bibr" rid="CR31">2013</xref>; Van Den Oord et al, <xref ref-type="bibr" rid="CR63">2017</xref>) (VQ-VAE) to reconstruct fluorescent signals of tagged proteins. Self-supervised learning with autoencoder-based approaches has also been applied for the analysis of human microglia data (Guo et al, <xref ref-type="bibr" rid="CR18">2020</xref>) and extraction of feature profiles predictive of cell metastatic potential (Zaritsky et al, <xref ref-type="bibr" rid="CR67">2021</xref>). One of the main disadvantages of auto-encoders is their difficulty in implementation and training challenges, as well as imperfect decoding (Chen et al, <xref ref-type="bibr" rid="CR4">2020</xref>; Jenni and Favaro, <xref ref-type="bibr" rid="CR27">2018</xref>; Kolesnikov et al, <xref ref-type="bibr" rid="CR34">2019</xref>). While <italic>cytoself</italic> and Paired Cell Inpainting achieved strong performance with decoder-based representations, replicating these networks on other datasets may be prohibitively complex. In this study, we asked whether other characteristics of microscopy data could be leveraged as self-supervised objectives to learn high-quality image representations with a relatively simple convolutional neural network.</p>
    <p id="Par14">Another challenge related to learning image-based features lies in their downstream analysis and interpretation. Current approaches typically extract representations with various machine learning methods and perform downstream analysis using clustering and tSNE/UMAP projections. (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>; Sullivan et al, <xref ref-type="bibr" rid="CR58">2018</xref>). However, there are no clear rules for more nuanced biological analysis, including analysis of extracted features for different levels of cellular organization, or high-confidence identification of protein functional modules. In general, data-backed guidelines on hyperparameter selection, which enable biologically meaningful clustering and consider the scale of cellular organization, are needed. Also, current molecular representation learning approaches generally lack methodologies that can characterize protein function by quantifying cell-to-cell variability in individual protein behavior. In summary, a gap remains in the image analysis field, requiring approaches that could (1) learn biologically meaningful features without human annotations, (2) produce universal features useful for studying subcellular organization at different scales, and (3) provide techniques for a wide range of downstream feature analyses.</p>
    <p id="Par15">Here, we present PIFiA (Protein Image-based Functional Annotation), a self-supervised approach for protein functional annotation derived from single-cell imaging data. PIFiA is coupled with a range of feature exploratory techniques for biological discovery. The representation learning component of PIFiA is performed by a convolutional neural network (CNN), which was trained with the objective of predicting protein identity directly from its fluorescently-labeled input image. This objective does not depend on pre-existing annotations or human labels and, unlike autoencoder-based models, PIFiA is robust to learning non-relevant information in the image, such as cell position, multiple cells in a crop, input noise, or imaging defects. In addition to the CNN component, the PIFiA workflow includes a set of downstream analysis steps for quantitative exploration of feature profiles extracted from single-cell imaging data. We applied PIFiA to ~3,000,000 live-cell confocal images of the budding yeast open reading frame (ORF)-GFP fusion collection (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). We compare PIFiA to existing approaches for protein representation learning and show that PIFiA outperforms previous methods on four different standards of protein function. We explore PIFiA feature profiles for use in a variety of downstream tasks, which are designed for the discovery of functional groups across different scales of cellular organization. Solely using distinct localization patterns of each protein, PIFiA can make remarkably precise functional predictions, identifying highly specific subcellular localization and distinct functional modules to reveal new biological insights.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <sec id="Sec3">
      <title>PIFiA architecture, feature profiles, and proteome-scale image dataset</title>
      <p id="Par16">PIFiA is a self-supervised deep learning approach designed to derive functional information about proteins from microscopy data without using any pre-existing annotations (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). The PIFiA workflow consists of a feature extraction step performed by a deep neural network (Fig. <xref rid="Fig1" ref-type="fig">1A,B</xref>), as well as subsequent analysis steps on the extracted feature profiles (Fig. <xref rid="Fig1" ref-type="fig">1C–E</xref>). The downstream analysis enables prediction of protein localization and the identification of functional modules or subsets of proteins with related cellular roles, such as protein complexes and their associated regulators. The feature profiles can be used for multiple downstream tasks, including construction of a hierarchical map of subcellular organization (Fig. <xref rid="Fig1" ref-type="fig">1C</xref>), predicting protein function (Fig. <xref rid="Fig1" ref-type="fig">1D</xref>), identifying localization heterogeneity at a cell population level (Fig. <xref rid="Fig1" ref-type="fig">1E</xref>), and finding functional modules.<fig id="Fig1"><label>Figure 1</label><caption><title>Overview of the PIFiA workflow (see also Fig. <xref rid="Fig7" ref-type="fig">EV1</xref>).</title><p>(<bold>A</bold>) Diagram of the PIFiA neural network architecture. Shown are examples of activations from passing a micrograph of fluorescently labeled Nup2 protein (Nup2-GFP) through the PIFiA network, with corresponding patterns recognized by the convolutional filters. Feature profiles are extracted from the second fully-connected layer, for use in downstream applications. (<bold>B</bold>) Illustration of two types of feature profiles produced by PIFiA—single-cell feature profiles (extracted from a single crop) and averaged feature profiles (obtained by averaging all single-cell feature profiles of that protein). (<bold>C</bold>) Schematic representation of the global hierarchy of protein feature profile similarities to reveal different levels of functional information. (<bold>D</bold>) Illustration of protein function prediction using self-supervised PIFiA feature profiles. (<bold>E</bold>) An illustrative example of using PIFiA single-cell feature profiles to investigate the localization heterogeneity of a protein.</p></caption><graphic xlink:href="44320_2024_29_Fig1_HTML" id="d33e544"/></fig></p>
      <p id="Par17">The deep learning backbone of PIFiA is a CNN consisting of eight convolutional blocks and three fully-connected (FC) layers, which was trained to predict a protein identifier associated with an input image (i.e. one out of 4049 classes (Fig. <xref rid="Fig1" ref-type="fig">1A</xref>)). The CNN produces a feature profile (or a representation profile) from the input image, which is unique to a particular image. Feature profiles are 64-dimensional real-valued vectors extracted from the second FC layer, which is followed by a classification layer (Fig. <xref rid="Fig7" ref-type="fig">EV1A</xref>). These feature profiles encapsulate condensed information about each protein’s identity, based solely on its localization pattern. Over the course of training, the model first learns straightforward characteristics, such as patterns of different cellular compartments, then it subsequently learns more subtle morphological features that may distinguish individual proteins (Fig. <xref rid="Fig7" ref-type="fig">EV1B</xref>). To achieve the best accuracy and simplicity trade-off, we searched for the optimal architecture, network depth/width and related hyperparameters based on the validation set (Fig. <xref rid="Fig7" ref-type="fig">EV1C,D</xref>) (see Methods). We found that more complex architectures, such as DenseNets (Huang et al, <xref ref-type="bibr" rid="CR24">2017</xref>), did not improve performance but increased the training time, hence we chose a simpler architecture that could achieve comparable performance. Similarly, we searched for optimal feature profile dimensionality and found that accuracy of protein identity prediction stabilized around a 64-dimensional feature profile (Fig. <xref rid="Fig7" ref-type="fig">EV1D</xref>).</p>
      <p id="Par18">To train PIFiA, we produced a comprehensive dataset of 3,058,961 live-cell images of individual strains expressing both a unique fusion gene from the yeast ORF-GFP collection (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>) and spatial markers of cell cycle position (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>), which provide cellular context for computational analysis of protein localization. In particular, we used automated yeast genetics (Tong and Boone, <xref ref-type="bibr" rid="CR62">2006</xref>) to engineer a new version of the ORF-GFP collection, in which the resultant strains also carried fluorescent markers of the nucleus (td-Tomato-NLS) and cytoplasm (E2-Crimson). In total, images of 4049 unique strains were obtained using an automated confocal microscope. Cell images were derived from two biological replicates, each of which had four fields of view for each ORF-GFP strain. The images acquired for the GFP channel were cropped into 64 × 64 pixels crops (median of 778 crops per tagged protein, see Methods), and each crop contained at least one cell at its center. The crops for each GFP-tagged protein were then split into training, validation, and test subsets (8:1:1 ratios).</p>
      <p id="Par19">After CNN training was completed, we extracted feature profiles of the individual single-cell crops from the test set to produce single-cell feature profiles (scFPs) (Fig. <xref rid="Fig1" ref-type="fig">1B</xref>). We then averaged the scFPs for each protein to create its average feature profile (aFP) (Fig. <xref rid="Fig1" ref-type="fig">1B</xref>). An aFP and scFP for an individual protein have the same dimensions, but they describe different levels of information: scFPs encapsulate the localization pattern of a protein in one cell, while aFPs describe the general spatial distribution of a protein. Below, we first use PIFiA aFPs to broadly explore protein localization and function. We then use scFPs to explore cell-to-cell heterogeneity, localization changes, and complex protein localization patterns (Fig. <xref rid="Fig1" ref-type="fig">1C–E</xref>).</p>
    </sec>
    <sec id="Sec4">
      <title>Comparison of PIFiA performance to other self-supervised and supervised approaches</title>
      <p id="Par20">We compared aFPs produced by PIFiA to the representations from three self-supervised methods (Fig. <xref rid="Fig2" ref-type="fig">2A–C</xref>) and two supervised methods (Fig. <xref rid="Fig2" ref-type="fig">2D,E</xref>). For self-supervised methods, we used CellProfiler (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>) (a feature-extraction tool) and its variant CellProfiler+PCA (see Methods), Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>) (a self-supervised autoencoder-based approach) and <italic>cytoself</italic> (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>) (a novel self-supervised method based on a VQ-VAE, that has been used to analyze human cell images). We also included a randomly initialized PIFiA network to show a baseline with the untrained model. For supervised approaches, we used DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>) (a deep-learning model that has been used previously to analyze images of the yeast ORF-GFP collection) and a combination of DeepLoc+PIFiA. We tried both the original DeepLoc version, which was trained on a set of 21,882 cell crops with single-cell labels, as well as our adaptation of DeepLoc, or DeepLoc+PIFiA, which was trained with less accurate but plentiful protein-level labels (see Methods).<fig id="Fig2"><label>Figure 2</label><caption><title>Comparison of PIFiA performance to existing supervised and self-supervised methods for protein representation learning.</title><p>(<bold>A</bold>) Bar graph showing the performance of PIFiA and four other methods (<italic>cytoself</italic> (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>), Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>), Cell Profiler (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>) and Cell Profiler + PCA) at detecting pairs of functionally related proteins (4049 total) using adjusted mutual information. A randomly initialized network (with PIFiA architecture) is shown for comparison as a dashed red line. Gene Ontology (GO) Cellular Component (CC), GO Slim Bioprocess (GO BP Slim), Kyoto Encyclopedia of Genes and Genomes Pathways (KEGG pathways) and European Bioinformatics Institute protein complexes (Protein Complexes). Error bars represent standard deviation from the mean across three network runs. (<bold>B</bold>) Bar graph (same setup as <bold>A</bold>) showing performance assessed using average precision. (<bold>C</bold>) Bar graph (same setup as <bold>A</bold>) showing performance assessed using F-score on four biological standards. (<bold>D</bold>) PIFiA performance versus supervised approaches (two variations of DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>)) assessed using average precision on four biological standards [X axis: Gene Ontology (GO) Cellular Component (CC), GO Slim Bioprocess (GO BP Slim), Kyoto Encyclopedia of Genes and Genomes Pathways (KEGG pathways) and European Bioinformatics Institute protein complexes (Protein Complexes). “DeepLoc original” is the original implementation (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>) trained on crops with manually annotated single-cell labels (4049 proteins total); DeepLoc+PIFiA is our modified version trained on protein-level labels using Huh et al. localization standard (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). Error bars indicate the standard deviation of the scores across three independent runs (for deep learning models). (<bold>E</bold>) Bar graph (same setup as E) showing performance assessed using F-score.</p></caption><graphic xlink:href="44320_2024_29_Fig2_HTML" id="d33e666"/></fig></p>
      <p id="Par21">We consider a model to have good performance if protein pairs with higher correlation between their aFPs are more likely to be functionally related. We evaluated feature profiles (aFPs) using three metrics: F-score and average precision (AP), both measures of feature relevance, and adjusted mutual information (AMI), an information theoretic metric to assess clustering quality (see Methods). PIFiA features showed superior performance on most evaluation criteria using four functional benchmarks: Gene Ontology (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>) (GO) Cellular Components (CC), GO Slim Bioprocesses (GO BP slim), Kyoto Encyclopedia of Genes and Genomes (Kanehisa and Goto, <xref ref-type="bibr" rid="CR29">2000</xref>) (KEGG) pathways and European Bioinformatics Institute (EBI) Protein Complexes (Meldal et al, <xref ref-type="bibr" rid="CR43">2015</xref>) (Fig. <xref rid="Fig2" ref-type="fig">2</xref>).</p>
      <p id="Par22">PIFiA reached better performance than the supervised method DeepLoc in predicting protein subcellular localization (DeepLoc’s target task), as indicated by higher values of F- and AP scores, on the GO CC standard (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). PIFiA also outperformed DeepLoc based on other functional standards, with the biggest performance gain in protein complex discovery. This result confirms the utility of the PIFiA training objective which targets identification of individual tagged proteins, the most detailed level of functional information present in the image. Although the objective does not directly focus on localization prediction, over the course of training the CNN implicitly learns a variety of localization patterns needed to successfully differentiate individual proteins. Thus, PIFiA self-supervised feature profiles can be used for exploratory analysis of protein localization instead of representations from a supervised method such as DeepLoc, bypassing the need for manual annotation while improving performance.</p>
      <p id="Par23">PIFiA also demonstrated better performance than Paired Cell Inpainting, another self-supervised method, achieving 1.2, 1.7, 2.2, and 10.4-fold improvements in terms of mean average precision using cellular component, bioprocess, pathway and protein complex standards, respectively. Also, PIFiA outperformed <italic>cytoself</italic>, a self-supervised approach that utilizes a VQ-VAE in its architecture, which achieved similar performance to Paired Cell Inpainting. Compared to all other approaches examined, PIFiA representations resulted in substantial improvement in clustering quality measured by AMI scores, with an average 5-fold AMI improvement over Paired Cell Inpainting (Fig. <xref rid="Fig2" ref-type="fig">2A</xref>). The significant improvement on the protein complex standard is again explained by PIFiA’s novel self-supervised objective, which forces the network to detect the most comprehensive morphological patterns while ignoring individual image artifacts, which contrasts with autoencoder-based objectives that learn features by naive image reconstruction.</p>
      <p id="Par24">Finally, to evaluate PIFiA performance specifically on proteins that localize to compartments with similar morphologies, we did an extra evaluation run similar to Fig. <xref rid="Fig2" ref-type="fig">2A</xref>, but only including aFPs of proteins from Golgi, endosome and peroxisome (with a single Huh et al localization label). We obtained 0.13, 0.09, 0.08, and 0.1 AP scores for PIFiA, Paired Cell Inpainting, DeepLoc original and DeepLoc+PIFiA, confirming that PIFiA is capable of distinguishing proteins from compartments with similar morphologies.</p>
    </sec>
    <sec id="Sec5">
      <title>Evaluation of the functional information associated with PIFiA average feature profiles</title>
      <p id="Par25">To further assess the biological information associated with the aFPs of each protein, we used hierarchical clustering of aFPs as an unsupervised approach to discover feature profile similarities (Murtagh and Contreras, <xref ref-type="bibr" rid="CR46">2012</xref>). We performed agglomerative hierarchical clustering of the whole-proteome aFPs (4049 proteins in total) using a correlation metric and average linkage. We surveyed the resulting dendrogram at different thresholds to explore whether aFPs are suitable for studying the spatial architecture of the cell at different scales of its organization (Fig. <xref rid="Fig3" ref-type="fig">3A</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S1</xref>). The hierarchical clustering results are shown in Fig. <xref rid="Fig3" ref-type="fig">3A</xref>, with 4049 proteins on the X-axis clustered according to the similarity of their feature profiles (each column is a 64-dimensional aFP). To determine optimal cutoff thresholds, we tracked AMI scores (Vinh et al, <xref ref-type="bibr" rid="CR65">2010</xref>) at different correlation thresholds for three functional standards: GO Cellular Component, GO Slim Bioprocess and Protein Complexes (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>) (see Methods).<fig id="Fig3"><label>Figure 3</label><caption><title>Clustering of PIFiA average feature profiles and analysis of the associated biological information (see also Figs. <xref rid="Fig8" ref-type="fig">EV2</xref>, <xref rid="Fig9" ref-type="fig">EV3</xref>, <xref rid="Fig10" ref-type="fig">EV4</xref>, <xref rid="Fig11" ref-type="fig">EV5</xref>; Dataset <xref rid="MOESM2" ref-type="media">EV1</xref> and <xref rid="MOESM3" ref-type="media">EV2</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S1</xref>).</title><p>(<bold>A</bold>) Clustergram of PIFiA’s average feature profiles for 4049 proteins. The plot to the left of the Y axis shows the adjusted mutual information curve between clustering labels and GO Cellular Component labels at different distance thresholds. The distance threshold (<italic>d</italic> = 0.72) indicated on the clustergram produces clusters associated with cell compartments (color codes on the right). (<bold>B</bold>) Bar graph showing top three Gene Ontology Cellular Component scores for each cluster defined in (<bold>A</bold>). (<bold>C</bold>) Whole-proteome tSNE projection of PIFiA average feature profiles. Each point on the plot represents a protein colored according to a localization category predicted by logistic regression (see Results for training details). (<bold>D</bold>) Annotation of the whole-proteome tSNE projection with GO bioprocess categories shown as Gaussian kernel density estimates. Bioprocesses were selected according to the lowest variance from different cellular components. A filled contour plot was used instead of contour lines to make bioprocess groups more easily distinguishable. The color intensity of the kernel density estimate contour plots corresponds to the cumulative probability mass below the drawn contour. (<bold>E</bold>) Annotation of the whole-proteome tSNE projection with sub-compartmental protein groups predicted by clustering of PIFiA feature profiles (cyto—cytoplasmic cluster, nuc—nuclear cluster, mito—mitochondrial cluster). (<bold>F</bold>) Colocalization analysis of proteins from different sub-compartmental groups. Representative micrographs of cells expressing mNeonGreen- (left) or mScarlet- (middle) tagged proteins annotated to different sub-compartmental groups within three cellular compartments: <italic>nucleus</italic> (top), <italic>cell periphery</italic> (middle) and <italic>endoplasmic reticulum</italic> (ER, bottom) groups. Overlays of the mNeonGreen and mScarlet images are shown on the right. The tagged proteins are indicated on the micrographs.</p></caption><graphic xlink:href="44320_2024_29_Fig3_HTML" id="d33e787"/></fig></p>
      <p id="Par26">First, we determined an optimal threshold (0.72) corresponding to the most general level of cellular organization—GO Cellular Component annotations (Fig. <xref rid="Fig3" ref-type="fig">3A</xref>). The nine clusters produced at this threshold were enriched for proteins with relatively broad cell component annotations: nucleus, mitochondrion, Golgi apparatus, cytoplasm, endoplasmic reticulum (ER), actin patches, nucleolus and cytosolic ribosome (all <italic>p</italic>-value &lt; 10e−20 except cluster 4 with <italic>p</italic>-value &lt; 10e−5; Fig. <xref rid="Fig3" ref-type="fig">3A,B</xref>; Dataset <xref rid="MOESM2" ref-type="media">EV1</xref>; examples of cell images from each cluster are shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1A</xref>). At this level of feature profile similarity, proteins annotated to subcellular components with visually distinct morphologies, such as organelles, tend to be in a single cluster, whereas proteins annotated to more heterogeneous cellular compartments are found in multiple clusters. For example, proteins with a <italic>nucleus</italic> GO cellular component annotation are enriched only in cluster 1, whereas proteins with a <italic>cytoplasm</italic> annotation were enriched in clusters 4, 8, and 9 (Fig. <xref rid="Fig3" ref-type="fig">3A,B</xref>). Detailed visual image inspection revealed that some clusters reflect protein localization to both the cytoplasm and another compartment, such as cluster 4 which contains subsets of proteins localized to the cytoplasm and cell surface proteins. Other clusters likely reflect differences in protein abundance, such as cluster 8, which includes a number of highly abundant proteins, including ribosomal proteins.</p>
      <p id="Par27">Next, we derived optimal correlation thresholds on our dendrogram corresponding to two additional, more detailed biological standards: GO Slim Bioprocess and Protein Complexes (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>). We obtained 21 clusters for GO Slim Bioprocesses (0.64 AMI distance threshold), 20 of which were functionally enriched (GO enrichments are shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1C</xref>; median <italic>p</italic>-value of 5e−10 across all enriched clusters; cluster entropies in terms of present localizations are shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1D</xref>). Similarly, 205 clusters were found at the dendrogram cutoff corresponding to a protein complex standard (0.29 AMI, Appendix Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>), which had 11-fold median enrichment in protein complex predictions across all clusters (distribution of the per-cluster enrichments at 0.29 AMI cutoff is shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1E,F</xref>). Hence, aFPs present robust and memory-efficient representations of protein features, which allow detection of clusters with functionally related proteins at various levels of cellular organization, with the highest functional resolution at more general levels of the hierarchy (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1F</xref>).</p>
    </sec>
    <sec id="Sec6">
      <title>Adaptation of PIFiA features to external annotations for protein localization and function</title>
      <p id="Par28">Our clustering analysis showed that PIFiA aFPs capture information from cell images that enables unsupervised resolution of cellular spatial organization, grouping proteins by shared localization and biological function (Fig. <xref rid="Fig3" ref-type="fig">3A,B</xref>). We have investigated another useful property of feature profiles—adaptability for subsequent supervised training. One of our goals was to create a model that produces universal feature profiles that can be used without the requirement to re-train a full neural network from scratch on a specific task. To evaluate the adaptability of feature profiles, we used the widely adopted linear evaluation protocol (Chen et al, <xref ref-type="bibr" rid="CR4">2020</xref>) where a linear classifier is trained on top of the representations extracted from the network, and test accuracy is used as a measure of representation quality.</p>
      <p id="Par29">We first evaluated how PIFiA features can be adapted to protein localization labels, which comprise the largest labeled functional standard available (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). This analysis enables assessment of whether information contained in self-supervised PIFiA features matches the content of the original images, when extracted with a supervised method. We trained a multinomial logistic regression (LR) using PIFiA scFPs from 2415 proteins manually annotated to localize to a single subcellular localization (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>) (see Methods). We compared the final performance of the LR trained on PIFiA scFPs to DeepLoc, a supervised neural network specifically trained to classify protein localization from images of the yeast ORF-GFP collection. To match the training protocol of DeepLoc, we used scFPs derived from the single-cell images in DeepLoc’s training set (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). We report AP scores on the same single-cell crops from the test set across the full roster of 2415 single-localized proteins (Fig. <xref rid="Fig8" ref-type="fig">EV2A</xref>). Remarkably, PIFiA self-supervised scFPs that were paired with LR yielded a comparable performance to the supervised network DeepLoc, even though PIFiA feature profiles are self-supervised and were fitted to localization labels solely using LR. This finding suggests that PIFiA feature profiles have rich functional content, and we can use them to predict functional protein attributes without training a full network from scratch.</p>
      <p id="Par30">To visualize adaptation of PIFiA feature profiles to the supervised localization labels, we transformed the 64-dimensional aFPs into 2-dimensional space using t-SNE (Van der Maaten and Hinton, <xref ref-type="bibr" rid="CR64">2008</xref>) and colored them according to LR localization predictions (Fig. <xref rid="Fig3" ref-type="fig">3C</xref>). Each aFP on the t-SNE projection was annotated with the localization category corresponding to the maximal LR prediction across all scFPs. In this visualization, the morphological similarity of proteins encapsulated in the aFPs was translated into proximity on the 2D t-SNE map, highlighting that the separation of self-supervised aFPs on the map was driven by subcellular localization signals. We compared the aFP localization assignments with the assignments made using supervised machine learning methods or manual annotations trained to specifically assign proteins to subcellular localizations (Fig. <xref rid="Fig8" ref-type="fig">EV2B</xref>). Ultimately, we observed higher quality of linear localization annotation compared to subcellular localization standards produced by other approaches (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>) (Fig. <xref rid="Fig8" ref-type="fig">EV2A</xref>).</p>
      <p id="Par31">These analyses show that PIFiA feature profiles can be adapted to the objective of a supervised neural network, which confirms the high information content of PIFiA features. Such adaptable feature profiles may accelerate training by replacing various task-specific supervised neural networks with one multi-purpose self-supervised approach, which yields universally applicable representations.</p>
    </sec>
    <sec id="Sec7">
      <title>Generalization to unseen datasets</title>
      <p id="Par32">We investigated the generalization capabilities of the PIFiA neural network by applying it to previously unseen yeast imaging datasets. Specifically, we evaluated the performance of PIFiA on the publicly available CYCLoPS (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>) and YeastRGB (Dubreuil et al, <xref ref-type="bibr" rid="CR12">2019</xref>) datasets. Both datasets contain images of &gt;4000 unique GFP-tagged proteins: CYCLoPs images show a version of the ORF-GFP collection and YeastRGB contains images of a new collection based on a different fluorescent protein, mNeonGreen. We applied the PIFiA network out-of-the-box to single-cell crops of the fluorescently-tagged protein images from these datasets and extracted their feature profiles (see Methods for details on feature extraction).</p>
      <p id="Par33">We generated aFPs from both datasets and used tSNE to visually represent the similarity between feature profiles, with points in close proximity reflecting similar visual characteristics (Fig. <xref rid="Fig9" ref-type="fig">EV3</xref>). We color-coded the tSNE maps according to the annotated subcellular localizations of the yeast cell components using a well-known standard of yeast protein localization (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). This visualization strategy allowed us to observe the formation of dense clusters corresponding to specific subcellular compartments. Nucleus, cytoplasm, mitochondrion, ER, vacuole and nucleolus were the most distinguishable localizations across both datasets (Fig. <xref rid="Fig9" ref-type="fig">EV3A,B</xref>). Thus, the PIFiA network showed strong generalization capabilities on two unseen datasets without any fine-tuning of its weights. We attribute this generalization to diverse data augmentation that was applied to the training data. Overall, our results confirm the feasibility of applying PIFiA for the analysis of novel datasets.</p>
    </sec>
    <sec id="Sec8">
      <title>Experimental validation of PIFiA predictions of sub-compartmental organization of the cell</title>
      <p id="Par34">We explored more specific functional information associated with PIFiA aFPs. We used Gaussian kernel density estimates (KDEs) (see Methods) to annotate our whole-proteome 2D tSNE projection of aFPs with Gene Ontology bioprocess terms. For illustration, we selected terms from different subcellular components that had the lowest variance on the t-SNE map. This annotation showed that PIFiA features distinguished biological processes within cellular compartments (Fig. <xref rid="Fig3" ref-type="fig">3D</xref>). For example, regions of the tSNE map corresponding to the cytoplasm (Fig. <xref rid="Fig3" ref-type="fig">3C</xref>) had distinct regions enriched for translation initiation and elongation, P-body assembly, pentose-phosphate shunt and glycogen metabolic process (Fig. <xref rid="Fig3" ref-type="fig">3D</xref>). This analysis illustrates that GFP-tagged proteins with similar biological roles have distinguishable appearances in cell images, and that PIFiA learns feature profiles that can be used to discover protein functional groups across different levels of subcellular organization, including organelles and possible sub-compartmental structures.</p>
      <p id="Par35">To further explore information in PIFiA profiles related to the sub-compartmental organization of the cell, we clustered aFPs of proteins that mapped to the same localization category to produce 15 per-compartment hierarchical trees (derived from the 15 categories defined by LR; Fig. <xref rid="Fig3" ref-type="fig">3C</xref>). We selected a sub-compartmental clustering threshold of 0.5 based on the highest morphological similarity within clusters and maximal separation between clusters, measured by a Silhouette score (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1E</xref>). We identified 30 clusters, which are indicated on the tSNE projection of PIFiA feature profiles in Fig. <xref rid="Fig3" ref-type="fig">3E</xref>, with example images of cells from each group shown in Fig. <xref rid="Fig10" ref-type="fig">EV4</xref> (see also Dataset <xref rid="MOESM3" ref-type="media">EV2</xref> for GO enrichment and other information). We refer to these clusters using their localization category and associated group number (e.g., nuc-1 corresponds to the first sub-compartmental group in the nucleus). We provide an interactive version of the t-SNE plot from Fig. <xref rid="Fig3" ref-type="fig">3E</xref> on the PIFiA website (<ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia/">https://thecellvision.org/pifia/</ext-link>), where each point on the plot is clickable and allows the user to explore the micrographs corresponding to the GFP-tagged protein, find its nearest neighbors and perform enrichment analysis based on the closest aFPs.</p>
      <p id="Par36">Several general features associated with the clusters in Fig. <xref rid="Fig3" ref-type="fig">3E</xref> suggest that they are functionally meaningful and reflect sub-compartmental organization. First, proteins localizing to compartments which tend to be more homogeneous in their morphological patterns were typically seen in a single cluster (e.g., peroxisome, spindle pole, vacuolar membrane, nuclear periphery), while proteins associated with large or heterogeneous compartments, such as the nucleus, cytoplasm, and mitochondria, defined more than one sub-compartmental cluster (Fig. <xref rid="Fig3" ref-type="fig">3E</xref>; Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). Second, 16 of 32 groups showed &gt;2-fold enrichment for a GO annotation category (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>, <italic>P</italic> &lt; 0.01). For example, the nucleus region of the whole-proteome map was divided into five clusters, enriched in GO bioprocesses such as small molecule metabolic process, chromatin remodeling and RNA polymerase II activity, mitotic nuclear division and proteolysis (Fig. <xref rid="Fig3" ref-type="fig">3E</xref>; Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). Third, as expected, some of the groupings appeared to be based on protein features that were easily discernible. Proteins in some sub-compartmental groups have a tight distribution of GFP intensities, suggesting that abundance is likely an important feature for that group. For example, <italic>nuc</italic>-1 clustering likely resulted from high protein abundance, and this cluster included histones and metabolic enzymes (median GFP intensity <italic>nuc</italic>-1 proteins = 5834 ± 2103 vs median for all <italic>nuc</italic> proteins = 745 ± 793) (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). Likewise, <italic>nuc</italic>-3 proteins had low abundance (median GFP intensity = 678 ± 52) and this group was enriched for mitotic nuclear division and chromosome segregation. For some of the other groups, clustering appeared to result from differences in the spatial distribution of pixels in a region. For example, <italic>cyto</italic>-3 proteins all had a prominent cytosolic signal overlaid with a punctate morphology, and most had roles in Golgi vesicle transport (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>; Fig. <xref rid="Fig9" ref-type="fig">EV3</xref>). Similarly, <italic>cyto-8</italic> contained only seven proteins with no obvious functional overlap, but by visual inspection, all the proteins localized to the cytoplasm and to one or more foci (Fig. <xref rid="Fig9" ref-type="fig">EV3</xref>). Thus, a fraction of sub-compartmental groups could be explained by distinct protein localization features, which may correspond to coherent functionality.</p>
      <p id="Par37">For many sub-compartmental groups, however, the features driving the clustering were less obvious. To ask if we could manually identify differences between proteins from different PIFiA sub-compartments with the same overall localization, we used a more sensitive colocalization assay. We chose pairs of proteins with similar abundances, tagged them with two fluorescent proteins, mNeonGreen and mScarlet, imaged cells containing both tagged proteins, taking Z-stacks of 5 optical sections, and manually assessed images (Fig. <xref rid="Fig3" ref-type="fig">3F</xref>; Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). Using colocalization, we observed subtle differences in most of the pairs from different sub-compartmental groups; specifically, we identified differences in 39/52 (75%) protein pairs from distinct groups, but in only 7/24 (29%) pairs from the same group (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). We show three examples of pairs of proteins from different sub-compartmental groups that vary in their localizations to different extents. In one example with a clear difference, we identified a distinct localization for <italic>nuc-5</italic> proteins, which were 13.5-fold enriched for components of the proteasome (<italic>P</italic> = 7.78E−22). The localization of <italic>nuc-5</italic> proteins overlapped extensively with that of other nuclear proteins, but <italic>nuc-5</italic> proteins additionally localized to the nuclear periphery (Fig. <xref rid="Fig3" ref-type="fig">3F</xref>, top row). We detected the nuclear periphery localization of <italic>nuc-5</italic> proteins when we looked at different proteasome components from <italic>nuc-5</italic>, in colocalization assays with proteins from different sub-compartmental <italic>nuc</italic> groups, and when the fluorescent proteins were reversed (Fig. <xref rid="Fig11" ref-type="fig">EV5</xref>).</p>
      <p id="Par38">In another example with a clear difference, we performed co-localization analysis with proteins assigned to different cell periphery (CP) groups. We examined cells expressing both a high-affinity iron transporter, Ftr1, from the <italic>CP-1</italic> group, and Tcb2, a protein involved in ER-plasma membrane tethering, from the <italic>CP-2</italic> group (Fig. <xref rid="Fig3" ref-type="fig">3F</xref>, middle row). Ftr1, tagged with mScarlet, and Tcb2, tagged with mNeonGreen, localized to distinct regions of the cell periphery. Ftr1 localized specifically to the mother cell periphery but was absent from the bud, whereas Tcb2 was present at both the mother and daughter cell peripheries. Indeed, by visual inspection, we found that many of the <italic>CP-1</italic> proteins had apparent mother-specific localization, like Ftr1. In total, the <italic>CP-1</italic> group contains 21 proteins, and includes 7 of the 8 proteins found previously to localize asymmetrically to mother cells, all of which are members of the MDR (multidrug resistance) transporter family: Fui1, Hip1, Hnm1, Pdr5, Snq2, Tpo1, Yor1 (Decottignies et al, <xref ref-type="bibr" rid="CR9">1998</xref>; Eldakak et al, <xref ref-type="bibr" rid="CR14">2010</xref>).</p>
      <p id="Par39">In addition to the MDR transporters, the <italic>CP-1</italic> group contains 14 novel mother-specific proteins, including several other transporter proteins (Atr1, Ftr1, Hxt6, Mep1, Mep3, Qdr2, and Qdr3), proteins with roles in signaling (Gpa2, Mid2, Psr1), and three relatively uncharacterized proteins (Ybr016w, Ina1, and Crp1; Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>).</p>
      <p id="Par40">In a third example, we looked at colocalization of two proteins whose ORF-GFP fusions show some ER localization: Ubx2, a protein involved in ER-associated protein degradation from the <italic>ER-3</italic> sub-compartmental group (Neuber et al, <xref ref-type="bibr" rid="CR47">2005</xref>), and Kre1, a protein that normally functions as a cell wall glycoprotein from the <italic>ER-5</italic> group (Boone et al, <xref ref-type="bibr" rid="CR3">1990</xref>). The difference between these is more subtle: the <italic>ER-5</italic> protein, Kre1, shows an ER localization but also an increased concentration at the cell periphery compared to Ubx2 (Fig. <xref rid="Fig3" ref-type="fig">3F</xref>, bottom row). This localization difference was observed in other members of these sub-compartmental groups, with <italic>ER-3</italic> proteins tending to have a more diffuse localization and <italic>ER-5</italic> proteins localizing more to the cell periphery (Fig. <xref rid="Fig11" ref-type="fig">EV5</xref>).</p>
      <p id="Par41">In summary, our data show that within a compartment, PIFiA features can distinguish groups of proteins with subtle differences in localization that often have different biological roles. Many of these groups are enriched for proteins that perform biological functions not previously associated with distinctive localization patterns.</p>
    </sec>
    <sec id="Sec9">
      <title>Analysis of proteins with multi-compartment localization using PIFiA single-cell feature profiles</title>
      <p id="Par42">The single-cell feature profiles (scFPs) produced by the PIFiA CNN provide an opportunity to explore more nuanced protein behaviors, including proteins localizing across multiple compartments. Previous analyses of the yeast ORF-GFP collection showed that a large fraction of the proteome localizes to two or more compartments in the same cell (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). These studies used average statistics for cell populations, precluding differentiation of proteins that localize to multiple compartments, or those that shuttle between compartments. We annotated scFPs of every protein with localization categories using LR classification scores, and then we investigated the distribution of each protein’s single-cell localization scores, focusing on the two most probable localizations (see Methods). Using this strategy, we found that most (3424) proteins have a homogeneous localization (localizing to a single compartment), while 652 proteins exhibit localization heterogeneity (localizing to two or more compartments) (Fig. <xref rid="Fig4" ref-type="fig">4A</xref>). We classified the proteins with heterogeneous localization into two categories: (1) 396 proteins that localized to more than one compartment in a single cell, which we refer to as AND-proteins, and (2) 256 proteins that appeared either in a primary or a secondary location but not in the same cell, which we refer to as OR-proteins (Fig. <xref rid="Fig4" ref-type="fig">4B,C,D</xref>; Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>). For most proteins the assigned localization probabilities were continuously distributed, but our classification summarizes the localization, indicating the compartments that the protein predominantly populates. For example, Pho85 was classified as an AND-protein with a mixed signal predominantly from nucleus and cytoplasm within single cells, consistent with its known biology (Huang et al, <xref ref-type="bibr" rid="CR23">2007</xref>) (Fig. <xref rid="Fig4" ref-type="fig">4C</xref>). In contrast, Stb1 is a transcription factor whose nuclear localization is cell cycle regulated and it was classified by our analysis of scFPs as being either nuclear or cytoplasmic (OR-protein), as seen in previous studies (Youn et al, <xref ref-type="bibr" rid="CR66">2017</xref>) (Fig. <xref rid="Fig4" ref-type="fig">4C</xref>).<fig id="Fig4"><label>Figure 4</label><caption><title>Identification of proteins with morphological heterogeneity using PIFiA single-cell feature profiles (see also Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S2</xref>).</title><p>(<bold>A</bold>) Heatmap depicting ratios of cells falling into a mixed localization category, secondary and primary localization regions. Proteins with low ratios in all three columns (yellow color) feature many cells that fall into the low-confidence region. (<bold>B</bold>) Scatter plot showing two proteins with homogeneous localization patterns. Each point on the scatter plot corresponds to a single-cell crop, mapped to the probability of nuclear and cytoplasmic localization according to the LR predictions. (<bold>C</bold>) Scatter plot showing a protein with AND-type localization heterogeneity, Pho85, and one with OR-type localization heterogeneity, Stb1. (<bold>D</bold>) Schema of scoring proteins for localization heterogeneity using a single-cell level distribution of localization probabilities. Probabilities are obtained from primary and secondary localizations (i.e. first and second most probable localizations of the logistic regression classification of that protein). (<bold>E</bold>) Localization co-occurrence heatmap for 396 AND-localizing proteins, showing numbers of proteins present at two localizations. The scale bar is set to a maximum intensity of 50 to enable visualization of categories with fewer proteins. (<bold>F</bold>) Circle plot depicting localization patterns of 256 OR-type proteins. The thickness of the line connecting two localizations indicates the number of proteins showing localization heterogeneity between these localizations. (<bold>G</bold>) Localization heterogeneity related to cell cycle position for 136 proteins exhibiting statistically significant cell cycle variation. Connections indicate localizations of the proteins at specific cell cycle stages (thicker lines indicate a more common connection between a particular localization change and cell cycle stage transition). The color of the heatmap indicates the number of heterogeneous proteins that are present in the corresponding cell cycle phase for a particular localization.</p></caption><graphic xlink:href="44320_2024_29_Fig4_HTML" id="d33e1182"/></fig></p>
      <p id="Par43">We summarized overall AND-/OR-localizations across 15 localization categories, which clearly illustrated that a large fraction of these changes involved the nucleus and cytoplasm compartments. Among the 922 proteins with a high confidence nuclear localization, 708 were solely nuclear, 159 nuclear AND cytoplasmic, and 55 nuclear OR cytoplasmic (Fig. <xref rid="Fig4" ref-type="fig">4E,F</xref>). We asked how these classes were distributed in different bioprocesses involving the nucleus (Costanzo et al, <xref ref-type="bibr" rid="CR7">2016</xref>). As expected, proteins with roles in RNA processing and chromatin organization tended to be solely nuclear (Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>). The trends for proteins that have dual localization were also consistent with well-established biology. For example, proteins with roles in cell cycle progression were 4.1-fold enriched in nucleus OR cytoplasm (<italic>P</italic> = 6.7E−05). Many cell cycle proteins, in particular many transcription factors, use localization to regulate protein activity (Haase and Wittenberg, <xref ref-type="bibr" rid="CR19">2014</xref>). Proteins with roles in DNA replication/repair and stress response were weakly enriched in nucleus AND cytoplasm (1.5-fold, <italic>P</italic> = 1.40E−03 and 1.9-fold, <italic>P</italic> = 9.7E−04, respectively). DNA repair proteins often alter their relative localization in the presence of damage, either to initiate a repair response or to prevent catastrophic cell cycle events (Tkach et al, <xref ref-type="bibr" rid="CR61">2012</xref>). Because our cells were not experiencing DNA damage at the time of imaging, many of these proteins displayed both nuclear AND cytoplasmic localization in our data. Hence, while many protein groups that show different patterns were too small to perform consistent enrichment analysis, enrichments that were seen for nuclear-cytoplasmic groups, where there are enough proteins to assess, were consistent with known biology.</p>
      <p id="Par44">Finally, because proteins with roles in cell cycle progression were enriched among both the OR- and the AND-proteins, we used our scFPs to assess how cell cycle position could account for some of the protein localization heterogeneity. To do so, we took advantage of the nuclear and cytoplasmic markers (td-Tomato-NLS; E2-Crimson) in our GFP collection to explore the relationship between cell cycle position and protein abundance or localization heterogeneity. We first trained an ensemble of CNNs on the nuclear and cytoplasmic RFP channels to predict one of three cell cycle stages, and we subsequently mapped each single-cell crop to a cell cycle category: T/G1 (Telophase, Gap phase 1), S/G2 (DNA synthesis phase/Gap phase 2) or M/A (metaphase/anaphase) (see Methods). We then compared the single-cell distributions of each cell cycle stage with the localization calls to discover relationships between protein localization and cell cycle (Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S2</xref>). In total, we identified 136 proteins with cell-cycle-dependent variation in PIFiA feature profiles, determined by Mann–Whitney U test (McKnight and Najab, <xref ref-type="bibr" rid="CR41">2010</xref>) (<italic>p</italic>-value &lt; 1e−3, see Methods). Our results are summarized in the connected heatmap shown in Fig. <xref rid="Fig4" ref-type="fig">4G</xref>. As expected, some of the discovered localization changes reflected cell-cycle-dependent differences in the corresponding compartment. For example, most bud neck/cytoplasm AND-localizing proteins (14/23 proteins) were cytosolic in G1 before the bud neck had formed and localized to the bud neck later in the cell cycle (Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>). However, many cell cycle-regulated proteins moved between permanent compartments, including 66 moving between the nucleus and cytoplasm. Indeed, PIFiA identified 4 proteins not previously known to be cell cycle regulated, that localized to the cytoplasm and nucleus, but showed a predominantly cytoplasmic localization in M/A (Yel025c, Atc1, Bop3, and Cmg1).</p>
      <p id="Par45">Overall, scFPs derived from the self-supervised PIFiA workflow enable resolution of single-cell localization and are suitable for cell-to-cell variability analysis. Notably, PIFiA feature profiles contain enough functional information to distinguish compartments and sub-compartmental morphologies without pre-assigned labels, enabling analysis of protein localization heterogeneity in a data-driven way, which precludes propagating annotation errors.</p>
    </sec>
    <sec id="Sec10">
      <title>Prediction of functional modules using PIFiA single-cell feature profiles</title>
      <p id="Par46">We showed that protein-level feature profiles, or aFPs, can present a range of microscopy patterns in a compressed numerical form, which can be used for clustering and building hierarchical dendrograms. Using AMI scores at different correlation thresholds we were able to resolve functional information associated with hierarchical clustering of PIFiA aFPs (Fig. <xref rid="Fig2" ref-type="fig">2A</xref>) and determine an optimal correlation threshold for discovering functional modules, such as protein complexes (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1A</xref>). However, averaging feature profiles leads to information loss, which is not optimal for more precise analysis. Hence, we explored the use of single-cell feature profiles for the identification of functional modules. In particular, we focused on whether we could use scFPs for improved identification of protein complexes, which represent functional modules whose components are expected to colocalize within a single cell.</p>
      <p id="Par47">We derived our scFPs clustering analysis from a straightforward intuition—scFPs belonging to the same protein or the same protein complex should be indistinguishable, given the resolution limits of light microscopy. To visually illustrate this hypothesis on protein complex member distributions with scFPs, we projected scFPs from the test set using 2D tSNE (Fig. <xref rid="Fig5" ref-type="fig">5A</xref>). The scFPs of proteins from the same complex often localized together on the tSNE map, but different proteins from the same complex were typically intermingled and difficult to separate from each other. In contrast, the scFPs corresponding to different protein complexes with the same subcellular localization were often separated on the tSNE map (e.g., Polymerase-II, Polymerase-III, and RSC in the nucleus; EGO and V-ATPase in the vacuolar membrane) (Fig. <xref rid="Fig5" ref-type="fig">5A</xref>).<fig id="Fig5"><label>Figure 5</label><caption><title>Prediction of protein functional modules using PIFiA single-cell feature profiles (see also Dataset <xref rid="MOESM5" ref-type="media">EV4</xref>).</title><p>(<bold>A</bold>) Visualization of protein complex clusters on a single-cell tSNE plot of PIFiA feature profiles. The central plot shows a whole-proteome tSNE projection of PIFiA single-cell feature profiles (scFPs). Each point on the plot represents a protein that is colored according to 15 different subcellular localizations (color codes are explained below the plot). Zoom-in plots show a more detailed view of some regions of the global tSNE, showing single-cell features from the test set corresponding to proteins from the same complex with the same color palette, each protein shown in different color. (<bold>B</bold>) Dendrogram of clustered scFPs highlighting a region that identifies a nuclear pore cluster among nuclear periphery scFPs. The line graph on the right shows different numbers of proteins in a cluster at different correlation thresholds for clustering. Zoom-in plots of two clusters at different correlation thresholds (red and gray dashed lines) are shown as scFPs tSNE plots to the right. (<bold>C</bold>) Violin plot comparing the performance of four clustering approaches on 140 protein complexes. (<bold>D</bold>) Plot illustrating the fraction of proteins in each cluster with a protein–protein interaction annotated in the BioGrid (blue) or as protein complex member (yellow). Cluster numbers are sorted based on the number of discovered interactions.</p></caption><graphic xlink:href="44320_2024_29_Fig5_HTML" id="d33e1275"/></fig></p>
      <p id="Par48">To further explore the utility of scFPs for algorithmically identifying protein complexes, we developed a modified hierarchical clustering approach, called adaptive thresholding, that is designed to identify correlation thresholds on the hierarchical dendrogram at which scFPs inside a cluster become indistinguishable, and thus might be expected to contain interacting proteins (see Methods). We performed hierarchical clustering of test set scFPs using average linkage and a correlation metric. We then traced the number of unique proteins inside the cluster along with the divisions of the single-cell dendrogram to discover levels of the dendrogram at which the number of proteins in a cluster plateaus (Fig. <xref rid="Fig5" ref-type="fig">5B</xref>). Such plateaus identify levels of the global scFPs dendrogram at which single-cell features are practically inseparable, a division threshold that we call a root cluster (see Methods). For example, our adaptive thresholding method identified a root cluster corresponding to the nuclear pore complex, which distinguished it from other nuclear periphery proteins (Fig. <xref rid="Fig5" ref-type="fig">5B</xref>).</p>
      <p id="Par49">We compared the adaptive thresholding method to other clustering approaches from three different families—connectivity (hierarchical clustering (Murtagh and Contreras, <xref ref-type="bibr" rid="CR46">2012</xref>)), centroid (k-means (Sculley, <xref ref-type="bibr" rid="CR52">2010</xref>)) and density methods (DBSCAN (Ester et al, <xref ref-type="bibr" rid="CR15">1996</xref>)) (Fig. <xref rid="Fig5" ref-type="fig">5C</xref>). For each of the methods used in our comparison, we tried a range of hyperparameters and selected the ones that maximized median F1-score (see Methods). Evaluation was performed on a set of 140 protein complexes that contain at least three proteins included in the ORF-GFP localization dataset (Meldal et al, <xref ref-type="bibr" rid="CR43">2015</xref>). Our approach outperformed other methods in terms of four different scores—fold enrichment, F1 score, precision, and recall (Fig. <xref rid="Fig5" ref-type="fig">5C</xref>). The distributions of scores highlight the advantages of our adaptive thresholding approach. Density-based clustering fails at the protein complex identification task due to the high density of the feature space. At the same time, k-means fails at the identification of larger protein complexes (more than 5 protein members), hence its violin plot has two peaks. Hierarchical clustering is a more advantageous approach for this task, yet it requires information on the distance threshold and lacks adaptability for the protein complex size and cellular compartment. In contrast, our adaptive thresholding approach finds an optimal distance threshold for each cluster and, hence, it can discover protein complexes of varying sizes.</p>
      <p id="Par50">Using the adaptive thresholding clustering approach, we constructed a list of 88 high-confidence clusters whose proteins were indistinguishable at the single cell level (Dataset <xref rid="MOESM5" ref-type="media">EV4</xref>; Fig. <xref rid="Fig5" ref-type="fig">5D</xref>). We mapped each cluster to a protein complex with the maximal fold enrichment and saw a median fold enrichment of 36.5 across 88 clusters, which is a 3-fold improvement over our clustering of aFPs with an optimized cut-off (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). Of the 88 predicted clusters, 42 captured members of 32 different protein complexes distributed across 15 subcellular compartments (Dataset <xref rid="MOESM5" ref-type="media">EV4</xref>). The remaining clusters did not capture two or more members of the same protein complex, although in 25/45 cases they contained proteins with PPIs (as annotated in BioGrid (Stark et al, <xref ref-type="bibr" rid="CR57">2006</xref>)). By using proteins from the same localization as our background set to compute fold enrichment, we tested whether the clusters could differentiate a protein complex from others in the same subcellular location (see Methods). We discovered that PIFiA confidently predicted members of protein complexes in multiple compartments, such as: [1] the proteasome and Ada2/Gcn5/Ada3 transcription activation complex in the nucleus; [2] LSM2-7 complex, decapping complex, and translation initiation factor 2B complex in the cytoplasm; [3] the oligosaccharyl transferase and Sec62-Sec63 complexes in the ER; [4] vacuolar proton translocating ATPase complex, phosphatidylinositol 3-kinase complex and iron exporter complex in the vacuolar membrane; [5] F-actin capping protein complex and PAN1 actin cytoskeleton-regulatory complex in the actin cytoskeleton; [6] Spc105 complex and NDC80 complex in the spindle pole; [7] retromer complex and SNX4-SNX41 sorting nexin complex in endosomes (see Dataset <xref rid="MOESM5" ref-type="media">EV4</xref>).</p>
      <p id="Par51">In some cases (17/44), we identified all members of a complex, together with some additional proteins, which may be previously unappreciated complex components or members of an extended functional module, such as regulators or target proteins. For example, cluster #6 contained all 4 subunits of COMA, a kinetochore complex that connects proteins bound to centromeric DNA with those bound to microtubules, as well as nine additional proteins, eight of which display protein–protein interactions (PPIs) with COMA members (Stark et al, <xref ref-type="bibr" rid="CR57">2006</xref>). Other clusters identified proteins with the same biological role that may participate in PPIs. For example, cluster #39 contained 26 proteins that localized to the nuclear periphery in a punctate fashion. This group contained the only two GFP-tagged members of the TREX-2 complex, which couples SAGA-dependent gene expression and transcription elongation to mRNA export at the nuclear pore complex. Cluster #39 also included 8 proteins reported to have PPIs with members of the TREX complex (Stark et al, <xref ref-type="bibr" rid="CR57">2006</xref>), suggesting they may function in concert with the complex<sup>,</sup> Among the remaining proteins were members of a silencing complex, including Sir2, Sir3, Sir4 and the Sir4-interacting protein Esc1, which suppress transcription at subtelomeric regions, tethering them to the nuclear periphery (Deshpande et al, <xref ref-type="bibr" rid="CR11">2019</xref>). Thus cluster #39 identified proteins with roles in gene expression that localize to the nuclear periphery, some of which function to modulate each other’s activity.</p>
      <p id="Par52">To provide some context into the limitations of the method, we looked at what types of protein complexes were under-represented in our set of high-confidence predictions. Identification by PIFiA was independent of protein abundance or number of members in the complex. The protein complexes we identified were enriched for localizations in small organelles and compartments (peroxisome, actin, nuclear periphery, endosome, spindle pole) and depleted for those in large diffuse compartments such as nucleus and cytoplasm. We note that not all protein complexes will have a distinct localization. Using PIFiA features we have identified protein complexes from most compartments in the cell.</p>
      <p id="Par53">In summary, we have developed a novel approach for discovery of functional modules using solely the self-supervised feature profiles and leveraging the properties of microscopy data for optimal clustering, and prediction of molecular interactions.</p>
    </sec>
    <sec id="Sec11">
      <title>Interpretation of PIFiA features</title>
      <p id="Par54">Our analysis shows that PIFiA feature profiles contain condensed information about protein function at various levels of granularity. However, since deep neural networks function as ‘black-box’ models, it is difficult to dissect feature profiles and explain how individual features are related to the input images. To attempt to interpret PIFiA features, we first quantified feature importance for 15 different localization categories covering a diverse set of subcellular morphological patterns. We used the LR model described earlier to derive importance scores for each feature; the coefficients of the trained LR quantify how much each feature is predictive of a certain localization (Fig. <xref rid="Fig6" ref-type="fig">6A</xref>). Most localizations had more than three strongly predictive features (LR coefficient value &gt; 5), suggesting that PIFiA learns to detect several distinctive patterns for each subcellular compartment. This confirms that PIFiA learns localization patterns with its convolutional filters, despite being trained on a completely different self-supervised objective. Also, the same feature could be predictive for several localizations (for example, features #3 and #28 recognize circular patterns corresponding to the vacuolar membrane and nuclear periphery), or react to some variation of visual patterns present in multiple localizations. Overall, larger and more complex compartments required more features to be confidently classified. To illustrate this finding, we plotted classification accuracy for the three largest compartments (cytoplasm, nucleus, and mitochondria), as well as three homogeneous compartments (nucleolus, peroxisome, and vacuolar membrane) with respect to the number of features used during LR training (see Methods) (Fig. <xref rid="Fig6" ref-type="fig">6B,C</xref>; Appendix Fig <xref rid="MOESM1" ref-type="media">S3A</xref>). While larger localization categories required approximately 30 features to reach their best performance, smaller localizations reached a saturation point at around 10 features.<fig id="Fig6"><label>Figure 6</label><caption><title>Interpretation of PIFiA features (see also Appendix Fig. <xref rid="MOESM1" ref-type="media">S3</xref>).</title><p>(<bold>A</bold>) Heatmap of the logistic regression coefficients for localization prediction associated with each feature. Each feature was mapped to a localization (based on the maximal coefficient value), and features were sorted in descending order of coefficients. (<bold>B</bold>) Plot of classification accuracy dependence on number of features used to train the logistic regression for the three largest and most complex localizations: nucleus, cytoplasm and mitochondria. (<bold>C</bold>) Plot of classification accuracy dependence on number of features, showing three smaller and more homogeneous localizations: nucleolus, peroxisome and vacuolar membrane. Shading shows standard deviation across 5 runs. (<bold>D</bold>) Gradient maps highlighting regions of the input image that CNN “pays attention to”. Proteins from six distinct subcellular compartments are shown with their most visually distinct gradient maps with the highest activation values.</p></caption><graphic xlink:href="44320_2024_29_Fig6_HTML" id="d33e1380"/></fig></p>
      <p id="Par55">Another way to interpret features learned by a CNN is to find regions of the image that had a large influence on the final result (Selvaraju et al, <xref ref-type="bibr" rid="CR53">2016</xref>; Zeiler and Fergus, <xref ref-type="bibr" rid="CR68">2014</xref>). Using gradient calculations, importance scores can be assigned to the input image pixels depending on the degree to which they affect the classification result or individual feature values (see Methods). We used the SmoothGrad approach (Smilkov et al, <xref ref-type="bibr" rid="CR55">2017</xref>; Zeiler and Fergus, <xref ref-type="bibr" rid="CR68">2014</xref>) to construct gradient maps for several features of the same protein image. We selected proteins representing five distinct subcellular localizations: Nup2 from nuclear periphery, Mcm2 from nucleus, Scs2 from ER, Ftr1, and Pst2 from cell periphery, and Pex3 from peroxisome. For each of the proteins, we used its scFPs to calculate 64 gradient maps for each of the individual features and selected four visually distinct gradient maps with the highest activation values for illustration purposes (Fig. <xref rid="Fig6" ref-type="fig">6D</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S3B</xref>).</p>
      <p id="Par56">We observed that different features of the same image resulted in different gradient maps. While regions with higher intensity often have higher gradient values (unless they are not meaningful for the training objective), the interesting observation here is which part of these regions are meaningful for the particular feature. For example, the last gradient map of Pex3-GFP protein shows punctate localization patterns with three distinct punctae. Interestingly, different features react to different parts of the image—feature 4 reacts to the lower dot on the image and feature 23 reacts to two other dots. Also, gradient maps of the Mcm2 protein highlighted the nuclear periphery region, focus points in the nucleus and nuclear background signal. Similarly, different features of Ftr1 reacted to various subregions of the cell periphery. Of note, the generated gradient maps showed that the region of network attention was always the single central cell of the crop even for crops containing more than one cell, confirming that per-crop feature profiles are in fact single-cell profiles (Fig. <xref rid="Fig6" ref-type="fig">6D</xref>, with Mcm2, Ftr1 and Pst2 proteins containing multiple cells in their crop, Appendix Fig. <xref rid="MOESM1" ref-type="media">S3B</xref>). Gradient-based interpretability approaches are useful to explain the relationship between individual features in the feature profile vector and input pixels in the image, and they constitute an important component of our downstream analysis pipeline. Hence, despite PIFiA’s self-supervised training objective, we can visually understand what each learned feature represents in terms of the input image regions.</p>
    </sec>
  </sec>
  <sec id="Sec12" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par57">We describe PIFiA, a self-supervised computational workflow that learns protein functional signatures from single-cell fluorescence microscopy data. Feature profiles learned by PIFiA show state-of-the-art performance on a variety of biological functional benchmarks, outperforming existing approaches for protein representation learning. Notably, our approach does not require any labels or annotations during training and uses only a single fluorescent channel. Hence, PIFiA can be easily applied to virtually any imaging dataset. We pre-trained PIFiA on a large-scale dataset encompassing over three million single-cell images of yeast cells expressing 4049 GFP-fusion proteins—a scale comparable to that of the commonly used computer vision dataset, ImageNet (Deng et al, <xref ref-type="bibr" rid="CR10">2009</xref>). As with ImageNet, we show that the yeast ORF-GFP dataset is a source for high-quality representation learning, enabling PIFiA to learn universal feature profiles that can be used out-of-the-box or minimally fine-tuned to suit an external standard. Thus, PIFiA can accelerate the rate of supervised training on external tasks by producing feature profiles that can fit any downstream task with simple linear regression, replacing multiple task-specific convolutional networks.</p>
    <p id="Par58">The PIFiA workflow unites a self-supervised convolutional neural network with multiple techniques for downstream feature profile analysis. The key advantage of our self-supervised objective is its independence of human annotations and its ability to learn high-quality features and ignore imaging artifacts and cell positions (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>; Razdaibiedina et al, <xref ref-type="bibr" rid="CR49">2019</xref>; Sullivan et al, <xref ref-type="bibr" rid="CR58">2018</xref>).To ensure that PIFiA remembers solely the biologically relevant patterns, yet ignores cell positioning and replicate noise, we require the network to learn the actual GFP-tagged protein by predicting its identity. Overall, we show that features learned by PIFiA outperform another self-supervised method, Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>), that was used to analyze the yeast GFP collection and even reaches the performance of the supervised approach, DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>), in its target task.</p>
    <p id="Par59">We describe downstream analysis techniques that use PIFiA feature profiles to explore different levels of subcellular organization that span both protein-level and single-cell feature profiles. Of note, our analysis focuses not only on the construction of a whole-proteome hierarchical map, but also provides quantitative rules to obtain clusters corresponding to a specific level of cellular organization, such as subcellular localization or biological process, and to identify proteins with multiple localizations and interacting proteins. This type of unbiased analysis can reveal unexpected properties and potential functions of proteins that can be further explored experimentally. For example, we used PIFiA features taken from images of yeast cells expressing GFP-tagged proteins to identify sub-compartmental groups enriched for proteins with biological processes not previously known to have distinctive subcellular localization patterns (Fig. <xref rid="Fig3" ref-type="fig">3E,F</xref>). We found that in addition to the known pan-nuclear localization, proteasome components are also localized at the nuclear periphery, a result we confirmed with co-localization experiments (Fig. <xref rid="Fig11" ref-type="fig">EV5</xref>). Nuclear periphery localization of proteasomes has not been reported in yeast, but an in situ cryo-electron tomography study in <italic>Chlamydomonas</italic> found nuclear 26S proteasomes crowding around nuclear pore complexes (Albert et al, <xref ref-type="bibr" rid="CR2">2017</xref>). The role of proteasomes at the nuclear periphery may be to regulate transcription and/or to degrade proteins transiting the nuclear pore complex (Albert et al, <xref ref-type="bibr" rid="CR2">2017</xref>).</p>
    <p id="Par60">We also identified a group of proteins that localized specifically at the cell periphery of mother cells and were depleted from the growing bud. Budding yeast divide asymmetrically, with a replicative lifespan of 20–30 generations, where each division gives rise to a daughter whose replicative lifespan is reset and a mother who continues to age (He et al, <xref ref-type="bibr" rid="CR21">2018</xref>). Mother-specific cell periphery localization is achieved when three conditions are fulfilled (Eldakak et al, <xref ref-type="bibr" rid="CR14">2010</xref>). First, mother-specific proteins lack diffusive mobility in the plasma membrane. Second, newly synthesized proteins are deposited specifically in the growing bud. Third, the genes encoding these mother-specific proteins are expressed late in the cell cycle, so for cells in S/G<sub>2</sub> (small-budded cells) protein is detectable only in the mother. These steps ensure that the new and old pools of these proteins become spatially segregated during asymmetric division. Indeed, mother-specific localization of cell periphery proteins has been proposed to play a role in aging, with the daughter cell getting the newly synthesized copies of the protein, and the older and potentially more damaged copies inherited by the aging mother (Eldakak et al, <xref ref-type="bibr" rid="CR14">2010</xref>). Our set of asymmetrically segregating proteins includes 7 proteins previously seen to have mother-specific localization, plus 14 novel mother-specific proteins, including other transporters, proteins with roles in signaling, and 3 uncharacterized cell surface proteins (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). It is possible that accumulation of old and damaged versions of these newly identified proteins may also play a role in mother-specific aging.</p>
    <p id="Par61">We also applied PIFiA features for the identification of interacting proteins and members of protein complexes. To accomplish this, we used an adaptive thresholding method for single-cell clustering that exploits the biological properties of protein–protein interactions and microscopy data, outperforming conventional clustering methods for identifying members of protein complexes. We show that proteins whose single-cell PIFiA features are indistinguishable can be members of the same protein complex, have PPIs with each other, or have functionally related biological roles. A similar approach, <italic>cytoself</italic> (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>), was used to visually separate protein complexes from different compartments in human cells. Like the PIFiA pipeline, its self-supervised training scheme requires no pre-existing knowledge or categories, allowing it to reveal a highly resolved protein subcellular localization atlas that summarizes the major scales of cell organization (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>). Both the <italic>cytoself</italic> study and our work validate image-based feature profiles for downstream studies of protein organization and function in eukaryotic cells, both yeast (this work) and human cells (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>). Notably, we demonstrate that PIFiA can distinguish protein complexes from the same compartment in yeast cells, which are 5 to 30-fold smaller in size than human cells, providing a quantitative approach for downstream analysis and identification of functionally related proteins. Another study has implemented a similar representation learning paradigm to learn feature profiles of the images of cells with chemical or genetic perturbations (Moshkov et al, <xref ref-type="bibr" rid="CR45">2024</xref>) where perturbations were used as training labels. Thus, perturbation phenotypes were learned as inner representations from the network, suggesting that such a training scheme is effective for various types of experiments and biological systems.</p>
    <p id="Par62">In summary, the PiFiA pipeline extracts high-quality functional information about proteins from cell images in a quantitative form, without relying on pre-existing labels or manual annotations. In essence, the approach performs in silico colocalization, when two or more biological entities, such as proteins, are analyzed for similarity based on their respective localization patterns or positions within a cell (Dunn et al, <xref ref-type="bibr" rid="CR13">2011</xref>). In contrast to experimental colocalization, which is time-consuming and expensive, in silico colocalization can be performed within seconds for multiple proteins at a time. In the case of PIFiA, this can be achieved not only with high speed but also with remarkable precision. Overall, PIFiA can be used to identify properties of proteins in single cells, including similarity and variability, that have the potential to inspire new experiments to uncover novel biological insights.</p>
  </sec>
  <sec id="Sec13">
    <title>Methods</title>
    <sec id="Sec14">
      <title>Construction of mutant arrays for imaging</title>
      <p id="Par63">For imaging screens, BY5299 (<italic>MAT</italic>α <italic>his3Δ1 leu2Δ0 ura3Δ0 met15Δ0</italic> lyp1pr::TDH3pr-E2-Crimson::HPH::<italic>lyp1</italic>Δ <italic>can1</italic>pr::TDH3pr-tdTomato-NLS::<italic>URA3</italic>::<italic>can1</italic>Δ::STE2pr-<italic>LEU2)</italic> was used as the starting query strain. E2-Crimson and td-Tomato-NLS are used as cytosolic and nuclear markers, respectively. The starting strain was crossed to the <italic>MAT</italic>a ORF-GFP (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>) and haploid strains carrying both the red fluorescent protein markers and the ORF-GFP were selected using the SGA method (Tong and Boone, <xref ref-type="bibr" rid="CR62">2006</xref>). All SGA selection steps were conducted at 30 °C, except sporulation, which was conducted at 22 °C for 10 days. The screen was performed in two biological replicates. We successfully constructed strains with 4049 (97.4%) GFP-tagged genes out of 4156 strains in the ORF-GFP collection. The missing GFP strains include those in linkage groups for <italic>CAN1</italic> and <italic>LYP1</italic>, as occurs in all SGA-derived collections. Other missing strains were those we were unable to grow from our original stocks. The missing strains had no bias for protein abundance (Ho et al, <xref ref-type="bibr" rid="CR22">2018</xref>). By GO cellular component, they were enriched for mitochondrial <italic>cytochrome complex</italic> (6 genes; Bonferroni corrected <italic>P</italic> value = 0.000368).</p>
    </sec>
    <sec id="Sec15">
      <title>High-throughput microscopy</title>
      <p id="Par64">Yeast cultures were prepared for microscopy and imaged as previously described (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Cox et al, <xref ref-type="bibr" rid="CR8">2016</xref>; Mattiazzi Usaj et al, <xref ref-type="bibr" rid="CR39">2020</xref>). Briefly, haploid wild-type <italic>MAT</italic>a strains expressing fluorescent protein fusions from SGA final selection plates were grown at 30 °C in low fluorescence synthetic minimal medium with Geneticin (200 μg/mL) and Noursoethricin (100 μg/ml). Cells were transferred to 384-well PerkinElmer CellCarrier Ultra imaging plates and centrifuged for 1 min at 500 g before imaging. Micrographs were obtained on an Opera Phenix (PerkinElmer) automated spinning disc confocal microscope. All imaging was done with a 63× water immersion objective. GFP was excited using a 488 nm laser and emission collected through a 520/35 nm filter. tdTomato was excited using a 561 nm laser, and emission collected through a 600/40 nm filter. E2Crimson was excited using a 640 nm laser, and emission collected through a 690/50 nm filter.</p>
    </sec>
    <sec id="Sec16">
      <title>Image acquisition for co-localization experiments</title>
      <p id="Par65">Protein pairs were chosen for co-localization if they had similar abundance (Ho et al, <xref ref-type="bibr" rid="CR22">2018</xref>) and localized to the same general subcellular compartment. For each protein, C-terminal fusions to both mNeonGreen and mScarlet were constructed as previously described (Meurer et al, <xref ref-type="bibr" rid="CR44">2018</xref>). Haploid cells in both configurations were mated to construct a/α diploids containing proteins tagged with the two fluorescent proteins. Diploid cells were grown and imaged in low fluorescence synthetic minimal media (Sheff and Thorn, <xref ref-type="bibr" rid="CR54">2004</xref>) supplemented with Hygromycin B (300 mg/mL), Geneticin (200 mg/mL), and 2% glucose. Cells were grown at 30 °C to mid-logarithmic phase and transferred to Concanavalin A-coated 384-well PerkinElmer CellCarrier Ultra imaging plates. Images were acquired at 22 °C using the Opera Phenix (PerkinElmer) automated spinning disc confocal microscope. Three image fields of 5 Z-stacks of optical sections 0.7 µm apart were taken for each well. Each field contained 100–150 cells, acquired using the 63× water immersion objective. mNeonGreen was excited using the 488 nM laser, with emissions collected through a 520/35 nm filter. mScarlet-I was excited using the 561 nm laser, with emissions collected through a 600/40 nm filter. Digital Phase Contrast was used for cell detection using LED bright field imaging. All images were assessed by visual inspection.</p>
    </sec>
    <sec id="Sec17">
      <title>Dataset overview and image preprocessing</title>
      <p id="Par66">Images of the 4049 strains expressing a GFP-tagged protein visible above background fluorescence were obtained using an automated confocal microscope as described above. Cell images were obtained from two biological replicates, each of which had four fields of view for each GFP-tagged strain.</p>
      <p id="Par67">As the first step of preprocessing, we computed cell centers’ coordinates across all images in the dataset using the nuclear channel. We obtained coordinates of the cells’ centers by segmenting the nuclear channel with a simple Watershed algorithm and computing <italic>x</italic>, <italic>y</italic> coordinates of the center of each cell’s nucleus (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>). We ignored cells with centers too close to the crop’s boundary (less than 10 pixels). Based on the cell center coordinates, we created single-cell crops of 64 × 64 pixels around those centers across all images in the dataset. We filtered crops that had GFP signal intensity less than the 5th percentile of the whole-proteome GFP intensity distribution, and crops dominated by the background noise (i.e., a uniform signal across the whole crop, with variance). After filtering low-quality crops, we dropped proteins with less than 10 cells, and we obtained 3,058,961 unique cells in the dataset. Then, the dataset was split into training, validation, and test sets using 80%, 10%, and 10% of the cells of each protein, respectively. The training subset contained 2,450,801 single-cell crops, and validation and test subsets contained 304,080 single-cell crops each. Finally, we applied instance normalization by standardizing the raw pixel intensities of every crop to a mean of 0 and a variance of 1 (independently for each channel of each sample). PIFiA was trained on 64 × 64 pixel crops of the GFP channel. During training, we used random flipping (horizontal and vertical) and random rotation across (0, 90, 180, 270) degrees to augment the training data. Labels of the training set are one-hot class vectors of length 4049.</p>
    </sec>
    <sec id="Sec18">
      <title>Architecture and training</title>
      <p id="Par68">The architecture details are illustrated in Fig. <xref rid="MOESM1" ref-type="media">S1A</xref>. The backbone of PIFiA consists of eight convolutional blocks followed by three fully-connected layers. Each convolutional block consists of a convolutional layer, batch normalization and rectified linear unit activation. Training was performed using Adam optimizer (Kingma and Ba, <xref ref-type="bibr" rid="CR30">2014</xref>) with a learning rate of 1e−3 and cosine decay learning rate schedule (number of steps equal to the number of training updates during 30 epochs), with cross-entropy as an objective function (<italic>y</italic><sub><italic>i</italic></sub> and <italic>ŷ</italic><sub><italic>i</italic></sub> are predicted probability and ground truth label of the protein <italic>i</italic>; <italic>N</italic> is the total number of classes, i.e.,4049 proteins):<disp-formula id="Equ1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L({\hat{{y}}}_{{i}},{y}_{i})=-{\sum }_{i=1}^{N}{y}_{i}\,\log {\hat{y}}_{i}$$\end{document}</tex-math><mml:math id="M2"><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mi>log</mml:mi><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><graphic xlink:href="44320_2024_29_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par69">To prevent overfitting, we applied dropout regularization (Srivastava et al, <xref ref-type="bibr" rid="CR56">2014</xref>) of 0.05 (5% dropout rate) after the second fully-connected layer (feature extraction layer). We performed hyperparameter optimization and selected the learning rate from {1e−4, 3e−4, 5e−4, 8e−4, 1e−3, 3e−3, 5e−3} and dropout rate from {0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5} based on maximal validation accuracy. Network parameters were initialized using a truncated normal distribution function with a standard deviation of 0.1. To report the performance, we ran the model three times with different random weights initializations; each run was 30 epochs and model weights were saved after every epoch. All the experiments were performed in Python using Tensorflow. The model was trained on the computing cluster of the Vector Institute for Artificial Intelligence, using NVIDIA T4 GPU with 12GB of VRAM, and up to 32GB of system RAM (single CPU). Source code and usage examples are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/arazd/pifia">https://github.com/arazd/pifia</ext-link>.</p>
      <p id="Par70">We used early stopping to select the final model (Girosi et al, <xref ref-type="bibr" rid="CR16">1995</xref>). We defined stopping criteria based on the model’s test accuracy of proteins classification across 4049 protein classes. We stop at an epoch where a derivative of the test accuracy becomes smaller than a threshold of 0.5% for at least 3 epochs, i.e., a point at which accuracy starts to saturate (Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>). Our goal was to stop at the point when the model has already grasped the most important morphological patterns, yet highly related and interacting proteins are not distinguished from each other. This trend is further illustrated by plots of average precision, F-score and precision (we show 0.9 threshold) for protein complexes and pathways standards (Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>). With protein prediction accuracy increasing over the course of training, the precision improved, but after some epochs, AP and F-score either saturated or started to decline. We found that accuracy saturation thresholds between 0.2% and 0.7% yielded comparable and optimal solutions, though other stopping points can be used depending on the training schedule, as well as model applications and goals. The proposed early stopping strategy helped to prevent memorizing noise and unnecessary patterns, while retaining morphologically similar proteins close in the feature space.</p>
    </sec>
    <sec id="Sec19">
      <title>Benchmarking and baseline feature extraction</title>
      <p id="Par71">We compared performance of feature profiles learned by PIFiA to features from three other popular methods for protein representation learning/extraction—DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>), Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>), and CellProfiler (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>).</p>
      <p id="Par72">A classic modular feature extraction tool, Cell Profiler (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>), was applied to the GFP and cytoplasmic channels of the test images across 4049 GFP-tagged proteins. We obtained 433 pre-defined CellProfiler features that quantitatively measure cellular phenotypes, including intensity, shape, and texture. Since some of the CellProfiler features can be repetitive, its representations are often post-processed with Principal Component Analysis (PCA) (Abdi and Williams, <xref ref-type="bibr" rid="CR1">2010</xref>). In our work, we evaluated both the original CellProfiler representation with 433 individual features, and its PCA projection (37 individual features) that explains 99% of the variance.</p>
      <p id="Par73">We used the DeepLoc model by Kraus et al, (<xref ref-type="bibr" rid="CR36">2017</xref>) as our supervised learning baseline. We investigated two training modes: (a) with per-protein localization labels from Huh et al, (<xref ref-type="bibr" rid="CR25">2003</xref>); (b) with single-cell localization labels manually annotated in our lab. Per-protein annotations can sometimes be subjective and might not capture the nuances of protein localization at a single-cell level accurately. Such annotations apply to all of single-cell images of a protein and are available for a significant part of the yeast proteome from the Huh et al, study (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). In contrast, single-cell labels were manually annotated for the individual cell images by research scientists in our lab. While more precise, such labels are expensive and encompass a much smaller portion of the proteome. The original DeepLoc version uses single-cell labels. For a fair comparison, we used both single-cell and protein-level localization labels to train DeepLoc and reported the corresponding results.</p>
      <p id="Par74">Hence, we used two model variants: (a) the original version of DeepLoc (which was trained on a set of 21,882 single-cell crops with manually assigned labels; pre-trained weights provided by Kraus et al, (<xref ref-type="bibr" rid="CR36">2017</xref>), and (b) our adaptation of DeepLoc, DeepLoc+PIFiA, which was re-trained on a larger set of 1,432,774 images with less accurate protein-level labels instead of expensive yet more precise single-cell labels.</p>
      <p id="Par75">We trained DeepLoc+PIFiA from scratch on the GFP channel of the same training set images using 1,432,774 single-cell crops from 15 one-hot localization categories derived from Huh et al, (<xref ref-type="bibr" rid="CR25">2003</xref>). We performed hyperparameter optimization and selected the most optimal learning rate from {1e−4, 3e−4, 5e−4, 8e−4, 1e−3, 3e−3, 5e−3} and dropout rate from {0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5}. We chose 3e−4 learning rate with cosine decay learning rate schedule and 0.05 dropout rate based on maximal validation accuracy. The model was trained with Adam optimizer for 30 epochs (model weights were saved every epoch for subsequent evaluation), with cross-entropy as an objective function, <italic>y</italic><sub><italic>i</italic></sub>, <italic>ŷ</italic><sub><italic>i</italic></sub> are predicted probability and ground truth label of localization <italic>i</italic>, total <italic>N</italic> = 15 localization classes):<disp-formula id="Equ2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L({\hat{y}}_{i},\,{y}_{i})=-{\sum }_{i=1}^{N}{y}_{i}\log {\hat{y}}_{i}$$\end{document}</tex-math><mml:math id="M4"><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><graphic xlink:href="44320_2024_29_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par76">We also used early stopping to select the final DeepLoc+PIFiA model weights. DeepLoc+PIFiA model selection was based on maximal validation set accuracy. Network parameters were initialized using a truncated normal distribution function with a standard deviation of 0.1. We performed 3 runs with different random weights initializations and performed training with a batch size of 128. After training, we extracted features of the test set images from the last hidden layer of the DeepLoc+PIFiA model following previous studies (Razdaibiedina and Brechalov, <xref ref-type="bibr" rid="CR48">2022</xref>).</p>
      <p id="Par77">For our self-supervised learning baseline, we used the Paired Cell Inpainting method (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>). Contrary to other models, Paired Cell Inpainting requires two channels for training—cytoplasmic background and target protein; hence we performed training of Paired Cell Inpainting using the GFP and cytoplasmic channels of the test images across 4049 GFP-tagged proteins. We used the exact same architecture and training objective described by Lu et al, (<xref ref-type="bibr" rid="CR38">2019</xref>). The objective function minimizes a standard pixel-wise mean-squared error loss between the predicted target protein <italic>ŝ</italic><sub><italic>t</italic></sub> and the actual target protein <italic>s</italic><sub><italic>t</italic></sub> (<italic>h</italic> and <italic>w</italic> are pixels across image width and height, respectively):<disp-formula id="Equ3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L({\hat{s}}_{t},\,{s}_{t})=\frac{1}{h\cdot w}{({\hat{s}}_{h,w,t}-{s}_{h,w,t})}^{2}$$\end{document}</tex-math><mml:math id="M6"><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>⋅</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><graphic xlink:href="44320_2024_29_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par78">We performed hyperparameter optimization and selected an optimal learning rate of 1e−4 from {1e−4, 3e−4, 5e−4, 8e−4, 1e−3, 3e−3, 5e−3}. The Model was trained with Adam optimizer for 30 epochs (3 runs in total), and model weights were saved every epoch for subsequent evaluation. We selected the final model with early stopping based on the minimal validation set loss. After training, we extracted feature profiles of the test set images by maximum pooling the output of an intermediate convolutional layer, across spatial dimensions, as suggested by Lu et al, (<xref ref-type="bibr" rid="CR38">2019</xref>).</p>
    </sec>
    <sec id="Sec20">
      <title>Evaluation of aFPs</title>
      <p id="Par79">Functional benchmarks used for assessment of the quality of the resulting feature profiles were derived from Gene Ontology Cellular Component (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>) (4045 protein annotations), Gene Ontology Slim Biological Process (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>) (3968 protein annotations), KEGG pathways (Kanehisa and Goto, <xref ref-type="bibr" rid="CR29">2000</xref>) (1422 protein annotations) and EMBL protein complexes (Meldal et al, <xref ref-type="bibr" rid="CR43">2015</xref>) (1402 protein annotations). Dubious ORFs and proteins without annotations were left out during comparison. To evaluate resulting features without further fine-tuning, we used strategies from two distinct perspectives: information retrieval and clustering quality.</p>
      <p id="Par80">Following standard practice, we computed pairwise distances across all available aFPs (4049 × 4049 distances in total) and sorted them from highest to lowest. Then protein pairs (which were not left out) were marked as positive if they had the same annotations, or negative otherwise, and AP and F-scores were computed. For proteins to be considered a positive pair, we required an exact agreement between labels in case of pathways and protein complexes standards, while for GO annotations we required at least 50% of the labels to overlap (due to high quantity of assigned labels). Results reported in Fig. <xref rid="Fig2" ref-type="fig">2B,C</xref> are based on ranking aFP pairs with correlation distance, and we found similar trends when using euclidean and cosine distances. We chose to continue analyses with the correlation metric due its lower susceptibility to fluctuations in individual feature values, and hence higher tolerance to outliers, which is a desirable property for the PIFiA workflow. For the clustering-driven benchmark, we clustered aFPs and compared clusters to the sets of proteins annotated to a certain term, and for each standard (we required cluster size to be at least 2 to be informative). For comparison, we applied AMI score (Vinh et al, <xref ref-type="bibr" rid="CR65">2010</xref>) between the resulting clusters and protein groups related to a certain term (with a higher score indicating more agreement between clusters and standard-defined categories). To obtain an AMI score for each method, we performed hierarchical clustering (with average linkage and correlation as a distance) of its per-protein representations and derived clusters across all similarity thresholds between 0.1 and 0.95 with a step of 0.05, and reported the maximal AMI across clusterings. For each deep learning model, feature profile evaluation was performed across 3 runs (results shown with bar plots in Fig. <xref rid="Fig2" ref-type="fig">2</xref>).</p>
    </sec>
    <sec id="Sec21">
      <title>Visualization of PIFiA feature profiles (aFPs and scFPs)</title>
      <p id="Par81">We used t-SNE (Van der Maaten and Hinton, <xref ref-type="bibr" rid="CR64">2008</xref>) for visualization of PIFiA feature profiles. We set the perplexity parameter to 40 for visualization of whole-proteome feature profiles averaged on the per-protein level (~4000 points) (Fig. <xref rid="Fig3" ref-type="fig">3C,D,F</xref>), and to 200 for visualizing single-cell feature profiles from the test set (&gt;100,000 points) (Fig. <xref rid="Fig5" ref-type="fig">5A</xref>). We represented the distribution of fundamental GO bioprocesses with a kernel-density estimate (KDE) using Gaussian kernels (Fig. <xref rid="Fig3" ref-type="fig">3D</xref>). We applied outlier filtering by removing points that do not lie within two standard deviations from the mean (across <italic>x</italic> or <italic>y</italic> t-SNE coordinates). We used Scott’s rule for KDE bandwidth selection (Scott, <xref ref-type="bibr" rid="CR51">1979</xref>).</p>
    </sec>
    <sec id="Sec22">
      <title>Hierarchical clustering with aFPs</title>
      <p id="Par82">We performed agglomerative hierarchical clustering (Murtagh and Contreras, <xref ref-type="bibr" rid="CR46">2012</xref>) of the whole-proteome aFPs (4049 in total) using correlation as a distance metric and average linkage. The optimal cut-off distance for the whole-proteome hierarchical clustering was determined using the AMI curve between clustering labels and provided standard annotations, following the diminishing returns principle to find the elbow point. At the optimal distance cutoff, the slope of the curve becomes negligible, indicating that the available clusters cover most of the standard’s functional groups. In Fig. <xref rid="Fig3" ref-type="fig">3</xref> we used GO Cellular Component annotations (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>) as a standard and calculated clustering labels at different correlation thresholds between 0 and 1, with a step of 0.01. Clustering was performed on the whole-proteome feature profiles, and AMI scores were calculated on a subset of proteins that had a single annotation according to GO Cellular Component. We identified an optimal cut-off point when the derivative of the AMI curve (calculated over 20 steps, starting at correlation of 1) was less than a threshold of 0.1. The proposed strategy can be used on different standards, without requiring annotations to cover all proteins (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1A</xref>).</p>
    </sec>
    <sec id="Sec23">
      <title>Training logistic regression</title>
      <p id="Par83">To perform localization mapping, we trained a multinomial logistic regression (LR) using single-cell feature profiles obtained with PIFiA from the training set. We used supervised labels from 17 manually annotated localizations defined by Huh et al, (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>) (we left out “ambiguous” category and classes with 5 or less proteins), and limited our training set to proteins that had a single annotated localization. Overall, our training set consisted of 1,432,774 single-cell feature profiles and included 2415 proteins from mitochondrion (465), nucleus (472), cytoplasm (799), actin (27), ER (245), vacuole (95), bud neck (8), spindle pole (35), Golgi (15), peroxisome (20), vacuolar membrane (47), cell periphery (51), nuclear periphery (45), endosome (28), and nucleolus (63). We followed our previously described dataset split (each protein’s single-cell crops were split into train, validation, and test sets with 8:1:1 ratios). We used NVIDIA T4 GPU with 12GB of VRAM, and up to 16GB of system RAM on a single CPU to accelerate training; we trained LR for 5 epochs using Adam optimizer (Kingma and Ba, <xref ref-type="bibr" rid="CR30">2014</xref>) (1e−3 learning rate) and cross-entropy as a training loss; LR weights were saved after every epoch and we selected the final LR model with early stopping based on maximal validation set accuracy. Of note, after 2 epochs LR predictions stabilized and the difference between subsequent models was minimal (less than 3% test accuracy deviations).</p>
      <p id="Par84">To evaluate the quality of LR predictions, we compared its test set performance with DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>) (training procedure described in the benchmarking section). DeepLoc and LR were trained and evaluated on the sets of the same size and protein composition, with the only difference being DeepLoc used image crops for training, while LR using self-supervised scFPs from the pre-trained PIFiA model. Precision-recall curves for PIFiA LR and DeepLoc were generated on unseen scFPs and corresponding images from the test set of the single-localizing proteins (Fig. <xref rid="Fig8" ref-type="fig">EV2B</xref>).</p>
    </sec>
    <sec id="Sec24">
      <title>Sub-compartmental clustering with aFPs</title>
      <p id="Par85">We performed sub-compartmental clustering using single-localizing aFPs from the test set that were classified to the same localization by the previously described LR. For an aFP to be single-localizing, we required that its highest softmax probability was at least 0.6, and second-highest was no greater than 0.2 (more detailed analysis of single-localizing proteins and localization heterogeneity is described in the next section). We clustered aFPs of proteins that mapped to the same localization category and produced 15 per-compartment hierarchical trees (we used average linkage and correlation distance for clustering).</p>
      <p id="Par86">We calculated the Silhouette score (Rousseeuw, <xref ref-type="bibr" rid="CR50">1987</xref>) using scikit-learn library, as the mean intra-cluster distance (<italic>a</italic>) and the mean nearest-cluster distance (<italic>b</italic>) for each aFP. The Silhouette coefficient for a sample is (<italic>b</italic>−<italic>a</italic>)/max(<italic>a</italic>, <italic>b</italic>); <italic>b</italic> is the distance between a sample and the nearest cluster that the sample is not a part of. We surveyed 15 per-localization hierarchical trees, clustered with average linkage and correlation metric, using correlation thresholds between 0.25 and 0.75, with a step of 0.05. Median of Silhouette scores across all localizations for a given threshold is shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1E</xref>. We found that thresholds between 0.5 and 0.6 yield maximal Silhouette scores, and a distance threshold of 0.5 corresponded to maximal GO bioprocess AMI value for whole-proteome aFPs clustering. Hence, we chose a 0.5 threshold to cluster aFPs belonging to each per-localization tree, and obtained 30 clusters, which we subsequently called sub-compartmental groups.</p>
    </sec>
    <sec id="Sec25">
      <title>Analysis of localization heterogeneity with scFPs</title>
      <p id="Par87">We used scFPs from the test set to analyze whole-proteome localization heterogeneity patterns. First, we used the pre-trained LR on 17 localization categories (described in the previous section) to map each protein’s test set scFPs to one of the 17 localization classes. We observed that the most probable localization class had an average 0.74 probability per protein (computed across all test set scFPs), while 2nd and 3rd classes scored 0.11 and 0.052 per-protein probabilities, respectively. This motivated us to perform heterogeneity analysis with the two most probable localization categories, to avoid low scFP quantities and potential noise effects. We then computed a mean probability across each localization class to determine the two most frequent localizations of the protein. Hence, for each protein X we obtained a distribution of 2-dimensional real-valued probability vectors [<italic>p</italic><sub><italic>i1</italic></sub>, <italic>p</italic><sub><italic>i2</italic></sub>] with <italic>p</italic><sub><italic>i1</italic></sub> and <italic>p</italic><sub><italic>i2</italic></sub> corresponding to the probabilities of the first and second most frequent localization classes, <italic>i</italic> ∈ {1, …, <italic>N</italic>}, <italic>N</italic> is the number of test set scFPs of the protein X. Given this distribution, we could compute whether protein X is single-localizing or has AND-type/OR-type localization heterogeneity. We filtered low-confidence scFPs <italic>i</italic>, whose sum of probabilities was below a confidence threshold: <italic>p</italic><sub><italic>i1</italic></sub> + <italic>p</italic><sub><italic>i2</italic></sub> &lt; α<sub>conf</sub> (low-confidence region). Next, based on a heterogeneity threshold β, we divided the rest of the scFPs into first localization if <italic>p</italic><sub><italic>i1</italic></sub> &gt; <italic>p</italic><sub><italic>i2</italic></sub> + β, second localization if <italic>p</italic><sub><italic>i2</italic></sub> &gt; <italic>p</italic><sub><italic>i1</italic></sub> + β, or mixed-localizing category otherwise. We varied values of α<sub>conf</sub> between 0.5 and 0.9, and values of β between 0.25 and 0.75 (with a step of 0.05), inspecting numbers of assignments into localization categories and low-confidence region, and selected α<sub>conf</sub> and β as 0.5 based on elbow point analysis. Hence, scFPs of each protein were mapped into one of four classes—primary localization, secondary localization, mixed localization or low-confidence region (Fig. <xref rid="Fig4" ref-type="fig">4D</xref>). If we assume that percentages of the corresponding categories for protein X are c<sub>1</sub>, c<sub>2</sub>, m, k (class 1, class 2, mixed and low-confidence, respectively), then protein X would be marked as AND-type localizing if the mixed category had a higher percentage of scFPs than primary and secondary localizations together: m &gt; c<sub>1</sub> + c<sub>2</sub>; otherwise protein X would be marked as OR-type if no less than 8% of scFPs belonged to the secondary localization: <italic>min</italic>(1, c<sub>2</sub>) &gt; 0.08, and single-localizing in the other case. We experimented with OR-type thresholds between 0.05 and 0.3 (with a step of 0.01), and found that the number of OR-type localizing proteins saturated between 0.07 and 0.1 thresholds. We selected 0.08 as an elbow point between <italic>min</italic>(1, c<sub>2</sub>) value and number of category assignments. Thus, each protein was marked as single-localizing, OR-type, AND-type, or undetermined (if too many scFPs were assigned as low-confidence).</p>
    </sec>
    <sec id="Sec26">
      <title>Cell cycle prediction and annotation with scFPs</title>
      <p id="Par88">We trained an ensemble of three CNNs for cell cycle classification using cytosolic and nuclear channels from our dataset. These two channels contained enough information to distinguish the cell cycle stage of a cell. The CNN contains four convolutional blocks followed by two fully-connected layers, and was trained to predict one of four cell cycle stages - G1, S, metaphase and anaphase (MA), or telophase (T) (Appendix Fig. <xref rid="MOESM1" ref-type="media">S2A</xref>).</p>
      <p id="Par89">We manually labeled 800 crops of cells from 103 different proteins, corresponding to distinct cell cycle stages (with 200 crops from each class) according to bud emergence; we used heavy data augmentation during training to prevent overfitting: rotation by arbitrary angle, vertical and horizontal flips, image zoom within 0.02 range, and vertical and horizontal shifts of up to 9 pixels. We used three-fold cross-validation. The training was performed on 64 × 64 × 2-dimensional crops over 150 epochs using Adam optimizer, with loss being a categorical cross-entropy across 4 cell cycle categories. We performed hyperparameter optimization to select learning rate (5e−4) and dropout rate (0.05). We performed 3 independent runs with random weights initialization (using truncated normal distribution with a standard deviation of 0.1). Model weights were saved after every epoch, and final models for each run were selected with early stopping based on maximal validation accuracy. Training and test accuracy and categorical cross-entropy loss are shown in Appendix Fig <xref rid="MOESM1" ref-type="media">S1</xref>. We created an ensemble of three CNNs (from epochs corresponding to minimal loss value), and subsequently mapped each single-cell crop to a 4-dimensional real-valued vector of cell cycle probabilities. The cell cycle probability vector was computed as an average of the probability vectors of three CNNs of that crop. We subsequently joined T and G1 categories due to high cell density in certain crops, which could potentially lead to an incorrect cell cycle category assignment.</p>
      <p id="Par90">We applied Mann–Whitney U test (McKnight and Najab, <xref ref-type="bibr" rid="CR41">2010</xref>) to identify proteins whose localization changes had cell cycle dependency. For each protein with localization heterogeneity, we annotated its single-cell crops from train, validation and test sets using both LR localization categories and cell cycle stages (via cell cycle classifier). We selected two primary annotated localizations, and compared cell cycle stage distribution of the corresponding crops. For each cell cycle stage, our null hypothesis was that the stage was equally represented among both localizations. Localizations with significant distribution differences (i.e. <italic>p</italic>-value &lt; 1e−3) were annotated as related to the particular cell cycle stage.</p>
    </sec>
    <sec id="Sec27">
      <title>Functional enrichment analysis</title>
      <p id="Par91">Gene Ontology (GO) enrichments were performed using GO-term Finder Version 0.86, available through the <italic>Saccharomyces cerevisiae</italic> Genome Database (<ext-link ext-link-type="uri" xlink:href="https://www.yeastgenome.org/goTermFinder">https://www.yeastgenome.org/goTermFinder</ext-link>). We applied gene set enrichment analysis (GSEA) using Python package GSEApy (Kuleshov et al, <xref ref-type="bibr" rid="CR37">2016</xref>) (<ext-link ext-link-type="uri" xlink:href="https://github.com/zqfang/GSEApy">https://github.com/zqfang/GSEApy</ext-link>) to analyze hierarchically clustered protein groups, sub-compartmental groups and sets of multi-localizing and mixed-localizing proteins (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref> and <xref rid="MOESM4" ref-type="media">EV3</xref>). Query gene sets for GSEA included GO biological process, cellular component, and molecular function standards (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>). GSEA results were filtered to include gene sets with <italic>p</italic>-values below 0.05 and a minimum gene set size of 2. We applied Bonferroni correction to obtain adjusted <italic>p</italic>-values. We also applied one-sided Fisher’s exact test with Costanzo group 19 (Costanzo et al, <xref ref-type="bibr" rid="CR7">2016</xref>) categories to analyse nucleus OR cytoplasm, nucleus AND cytoplasm gene sets, reporting protein sets with <italic>p</italic>-value &lt; 0.05 as the ones showing enrichment (Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>).</p>
    </sec>
    <sec id="Sec28">
      <title>Discovery of interacting proteins from scFPs</title>
      <p id="Par92">We identified clusters containing potentially interacting proteins using two steps. First, we hierarchically clustered scFPs from the test set (we used average linkage and a correlation metric). After that, we divided the dendrogram from top to bottom and traced the number of unique proteins inside the cluster along with the division thresholds of 0.05 points. We found thresholds of the dendrogram at which the number of proteins in a cluster plateaus (95% of protein composition remains the same). After such “morphologically inseparable” clusters were identified, we used three data-driven scores to measure the quality of the resulting clusters—cell ratio, elbow point, and child ratio. Cell ratio <italic>c</italic> is an average percentage of a protein’s cells that fall into a particular cluster. A higher cell ratio translates into less dispersed cells of the same protein, and more confident protein assignment into the particular cluster. Elbow point <italic>k</italic> is a clustering distance at the level of the current cut (1-PCC in our case). A lower elbow point corresponds to a smaller distance between proteins in their feature profiles space. Descendant ratio <italic>d</italic> of the particular root cluster is the percentage of its descendent clusters that were annotated to the same root. A high child ratio corresponds to more agreement of the child clusters, hence indicating a more confident prediction. We devise a final score <italic>s</italic> as follows:<disp-formula id="Equ4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s=\frac{c\cdot d}{k}$$\end{document}</tex-math><mml:math id="M8"><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:mo>⋅</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="44320_2024_29_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par93">We used a final score cutoff of 0.6 to produce a list of 88 high-confidence clusters. We compared performance of our adaptive thresholding approach with clustering approaches from three different families—connectivity (hierarchical clustering (Murtagh and Contreras, <xref ref-type="bibr" rid="CR46">2012</xref>)) centroid (k-means (Sculley, <xref ref-type="bibr" rid="CR52">2010</xref>)) and density methods (DBSCAN (Ester et al, <xref ref-type="bibr" rid="CR15">1996</xref>)) (Fig. <xref rid="Fig5" ref-type="fig">5C</xref>). We performed clustering on the same test set of scFPs with different approaches. For each of the methods used in our comparison, we tried a range of hyperparameters (k ranging from 5 to 500 with a step of 5 in k-means, epsilon ranging from 0.1 to 5 with a step of 0.1 in DBSCAN, and correlation threshold ranging from 0.05 to 0.5 with a step of 0.025 for hierarchical clustering) and report the ones corresponding to the maximal median F1-score across all clusters. F1 scores were calculated by assigning each pair of scFPs ground truth label (0 or 1 depending on whether they are part of the same protein complex) and predicted label (0 or 1 depending on whether they are part of the same cluster).</p>
    </sec>
    <sec id="Sec29">
      <title>Gradient maps</title>
      <p id="Par94">We applied the SmoothGrad method to obtain per-feature gradient maps of the input images (Smilkov et al, <xref ref-type="bibr" rid="CR55">2017</xref>). Original gradient maps <italic>m</italic><sub>c</sub>(<italic>x</italic>) compute the derivative of activation function <italic>S</italic> of the highest-scoring class <italic>c</italic> with respect to the input image <italic>x</italic>, and thus highlight pixels which influence classification decision:<disp-formula id="Equ5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${m}_{c}=\frac{\partial {S}_{c}(x)}{\partial x}$$\end{document}</tex-math><mml:math id="M10"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="44320_2024_29_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par95">Since we were interested in feature interpretation, but not interpreting the classification decision, we modified this computation. In our implementation of gradient map <italic>M</italic><sub><italic>i</italic></sub>(<italic>x</italic>), we take the derivative of specific feature <italic>f</italic><sub><italic>i</italic></sub> from the feature vector <italic>f</italic> with respect to the input image <italic>x</italic>:<disp-formula id="Equ6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${M}_{i}(x)=\frac{\partial {f}_{i}(x)}{\partial x}$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="44320_2024_29_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par96">Hence, our gradient maps highlight regions of the image that impact the value of the selected feature. SmoothGrad produces a gradient map <italic>M</italic><sub><italic>i</italic></sub>(<italic>x</italic>) by averaging a number of gradient maps obtained from an input image with added noise from Gaussian distribution <italic>N</italic>(0, <italic>σ</italic><sup>2</sup>) (with a mean 0 and a standard deviation <italic>σ</italic>):<disp-formula id="Equ7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{M}}_{i}(x)=\frac{1}{n}{\sum }_{i=1}^{n}{M}_{i}(x+N(0,\,{\sigma }^{2}))$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic xlink:href="44320_2024_29_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par97">We used <italic>n</italic> = 100 images and <italic>σ</italic> = 0.05 noise level.</p>
    </sec>
    <sec id="Sec30">
      <title>Generalization experiments</title>
      <p id="Par98">We performed generalization experiments by applying PIFiA out-of-the-box on two unseen yeast imaging datasets: CYCLoPS (Koh et al, <xref ref-type="bibr" rid="CR33">2015</xref>) and YeastRGB (Dubreuil et al, <xref ref-type="bibr" rid="CR12">2019</xref>).</p>
      <p id="Par99">CYCLoPS is a collection comprising more than 20 million cells of C terminal-tagged GFP images of 4144 proteins. To derive single-cell crops from this dataset, we applied the Watershed algorithm to the cytoplasmic channel and computed <italic>x</italic>, <italic>y</italic> coordinates of the center of each cell (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>) subsequently making 64 × 64 pixel crops around the centers. We only used GFP channel of the single-cell crops and performed per-image standardization of each crop.</p>
      <p id="Par100">The YeastRGB dataset is a collection of GFP-tagged microscopy screens produced using SWAT technology, where new-generation fluorescent reporters are fused at the N’ and C’ of open reading frames of over 4000 proteins. We used C’-tagged images (and excluded N’-tagged images) from the YeastRGB dataset to avoid performance mismatch related to the tag location since our training data has C’-tagged images. The YeastRGB database provides single-cell crops, from which we only used GFP channel images and performed per-image standardization of each crop.</p>
      <p id="Par101">For each dataset, we run single-cell crops through PIFiA and extracted scFPs. Next, we averaged scFPs to obtain aFPs for all proteins in the dataset. We used t-SNE (Van der Maaten and Hinton, <xref ref-type="bibr" rid="CR64">2008</xref>) for visualization of aFPs with perplexity = 40 and color-coded the resulting maps with the Huh et al, localization standard (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>).</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <sec id="Sec32">
      <title>Supplementary information</title>
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="44320_2024_29_MOESM1_ESM.pdf">
            <caption>
              <p>Appendix</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="44320_2024_29_MOESM2_ESM.xlsx">
            <caption>
              <p>Dataset EV1</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="44320_2024_29_MOESM3_ESM.xlsx">
            <caption>
              <p>Dataset EV2</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM4">
          <media xlink:href="44320_2024_29_MOESM4_ESM.xlsx">
            <caption>
              <p>Dataset EV3</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM5">
          <media xlink:href="44320_2024_29_MOESM5_ESM.xlsx">
            <caption>
              <p>Dataset EV4</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM6">
          <media xlink:href="44320_2024_29_MOESM6_ESM.pdf">
            <caption>
              <p>Peer Review File</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM7">
          <media xlink:href="44320_2024_29_MOESM7_ESM.pdf">
            <caption>
              <p>Expanded View Figures</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <app-group>
    <app id="App1">
      <sec id="Sec31">
        <title>Expanded view</title>
        <p id="Par102">
          <fig id="Fig7">
            <label>Figure EV1</label>
            <caption>
              <title>PIFiA network architecture and training settings.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig1" ref-type="fig">1</xref>. (<bold>A</bold>) Overview of the architecture of PIFiA convolutional network. (<bold>B</bold>) Left plot: test accuracies of three different runs over the course of training (X axis: epochs, Y axis: test accuracy). Smaller plots: average precision, F-score and precision on protein complexes and pathways standards (X axis: epochs, Y axis: corresponding score on test set). The purple line indicates point of early stopping, when accuracy starts to saturate (derivative of the test accuracy smaller than a threshold of 0.5%). (<bold>C</bold>) Bar graphs comparing the current PIFiA architecture with a common baseline, DenseNet-121, across four different standards (Gene Ontology Cellular Component, Gene Ontology Bioprocess Slim, KEGG Pathways, EBI Protein complexes) in terms of average precision, F-score and adjusted mutual information (assessed on aFPs of 4049 proteins). Error bars represent standard deviation from the mean across three network runs. (<bold>D</bold>) Bar graphs comparing PIFiA performance across different dimensions of the feature profiles (32, 52, 64, 80, 128).</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig7_ESM" id="d33e2590"/>
          </fig>
        </p>
        <p id="Par103">
          <fig id="Fig8">
            <label>Figure EV2</label>
            <caption>
              <title>Comparison of PIFiA annotations and existing localization standards.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig3" ref-type="fig">3</xref>. (<bold>A</bold>) Comparison of localization classification performance of DeepLoc versus PIFiA feature profiles coupled with a logistic regression. Precision-recall plots are shown for 15 subcellular localizations. (<bold>B</bold>) Whole-proteome aFPs tSNE colored by different annotations of subcellular localization: manual annotations from Huh et al, (<xref ref-type="bibr" rid="CR25">2003</xref>) (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>), and computationally-derived annotations from EnsLoc, DeepLoc and PIFiA.</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig8_ESM" id="d33e2619"/>
          </fig>
        </p>
        <p id="Par104">
          <fig id="Fig9">
            <label>Figure EV3</label>
            <caption>
              <title>Generalization of PIFiA network to two unseen datasets.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig3" ref-type="fig">3</xref>. (<bold>A</bold>) Localization-colored tSNE on aFPs obtained from the CYCLoPS dataset. (<bold>B</bold>) Localization-colored tSNE on aFPs obtained from the YeastRGB dataset.</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig9_ESM" id="d33e2642"/>
          </fig>
        </p>
        <p id="Par105">
          <fig id="Fig10">
            <label>Figure EV4</label>
            <caption>
              <title>Examples of proteins from 30 different sub-compartmental groups.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig3" ref-type="fig">3</xref>. Each row corresponds to a sub-compartmental cluster (e.g. nuc-1, nuc-2). The relevant GFP-tagged protein is identified on each micrograph.</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig10_ESM" id="d33e2659"/>
          </fig>
        </p>
        <p id="Par106">
          <fig id="Fig11">
            <label>Figure EV5</label>
            <caption>
              <title>Colocalization assay for proteins from different sub-compartmental.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig3" ref-type="fig">3</xref>. Colocalization experiment results: representative micrographs of cells expressing mNeonGreen- (green images) or mScarlet- (red images) tagged proteins annotated to nucleus (top panel) or cell periphery (bottom panel) groups. Overlays of the mNeonGreen and mScarlet images are shown on the right of each triplet of images. The tagged proteins are indicated on the micrographs (scale bar shown bottom right).</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig11_ESM" id="d33e2676"/>
          </fig>
        </p>
      </sec>
    </app>
  </app-group>
  <sec>
    <title>Supplementary information</title>
    <p>Expanded view data, supplementary information, appendices are available for this paper at 10.1038/s44320-024-00029-6.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank Oren Kraus, Michael Costanzo, Nil Sahin, Alan Moses, Leah Cowen, and Matej Usaj for valuable discussions and advice. This work was supported by grants from the National Institutes of Health (R01HG005853 to BA and CB), and the Canadian Institutes of Health Research (PJT-180259 to BA). Equipment for automated image acquisition and analysis was purchased using funds from the Canadian Foundation for Innovation and the Ontario Research Fund. JB was supported by the Canadian Institute for Advanced Research (CIFAR) AI Chairs program and the National Sciences and Engineering Research Council (Canada). We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Quadro P6000 GPU. Computational resources were provided, in part, by the Province of Ontario and the Government of Canada through the Vector Institute for Artificial Intelligence. AR was supported by the Province of Ontario (Ontario Graduate Scholarship, 2021–2022) and the Vector Institute for Artificial Intelligence (Vector Institute Postgraduate Affiliate Scholarship, 2019–2021). CB is a Fellow of the CIFAR.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p><bold>Anastasia Razdaibiedina</bold>: Conceptualization; Software; Formal analysis; Validation; Investigation; Visualization; Methodology; Writing—original draft; Writing—review and editing. <bold>Alexander Brechalov</bold>: Conceptualization; Software; Supervision; Methodology; Writing—original draft. <bold>Helena Friesen</bold>: Conceptualization; Formal analysis; Supervision; Validation; Methodology; Writing—original draft; Project administration; Writing—review and editing. <bold>Mojca Mattiazzi Usaj</bold>: Supervision; Writing—review and editing. <bold>Myra Paz David</bold><bold>Masinas</bold>: Software. <bold>Harsha Garadi Suresh</bold>: Resources. <bold>Kyle Wang</bold>: Resources. <bold>Charles Boone</bold>: Supervision. <bold>Jimmy Ba</bold>: Conceptualization; Supervision; Investigation; Methodology. <bold>Brenda Andrews</bold>: Supervision; Funding acquisition; Writing—review and editing.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The image data used in this work are available at the CellVision website (<ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia/">https://thecellvision.org/pifia/</ext-link>): The raw images: <ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia_files/pifia_raw_data.tar.gz">https://thecellvision.org/pifia_files/pifia_raw_data.tar.gz</ext-link>. The dataset of single-cell cropped images: (<ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia_files/pifia_single_cell_crops.tar.gz">https://thecellvision.org/pifia_files/pifia_single_cell_crops.tar.gz</ext-link>). Source code for the PIFiA network and downstream analysis is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/arazd/pifia">https://github.com/arazd/pifia</ext-link>.</p>
  </notes>
  <notes>
    <title>Disclosure and competing interests statement</title>
    <notes notes-type="COI-statement">
      <p>The authors declare no competing interests. Brenda J Andrews is a member of the Advisory Editorial Board of Molecular Systems Biology. This has no bearing on the editorial consideration of this article for publication.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Abdi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Williams</surname>
            <given-names>LJ</given-names>
          </name>
        </person-group>
        <article-title>Principal component analysis</article-title>
        <source>Wiley Interdiscip Rev Comput Stat</source>
        <year>2010</year>
        <volume>2</volume>
        <fpage>433</fpage>
        <lpage>459</lpage>
        <pub-id pub-id-type="doi">10.1002/wics.101</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Albert</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schaffer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Beck</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Mosalaganti</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Asano</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Thomas</surname>
            <given-names>HF</given-names>
          </name>
          <name>
            <surname>Plitzko</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Beck</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Baumeister</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Engel</surname>
            <given-names>BD</given-names>
          </name>
        </person-group>
        <article-title>Proteasomes tether to two distinct sites at the nuclear pore complex</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2017</year>
        <volume>114</volume>
        <fpage>13726</fpage>
        <lpage>13731</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1716305114</pub-id>
        <?supplied-pmid 29229809?>
        <pub-id pub-id-type="pmid">29229809</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sommer</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Hensel</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bussey</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Yeast KRE genes provide evidence for a pathway of cell wall beta-glucan assembly</article-title>
        <source>J Cell Biol</source>
        <year>1990</year>
        <volume>110</volume>
        <fpage>1833</fpage>
        <lpage>1843</lpage>
        <pub-id pub-id-type="doi">10.1083/jcb.110.5.1833</pub-id>
        <?supplied-pmid 2186051?>
        <pub-id pub-id-type="pmid">2186051</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <mixed-citation publication-type="other">Chen T, Kornblith S, Norouzi M, Hinton G (2020) A simple framework for contrastive learning of visual representations. In: Proceedings of the 37th international conference on machine learning, pp 1597–1607</mixed-citation>
    </ref>
    <ref id="CR5">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cho</surname>
            <given-names>NH</given-names>
          </name>
          <name>
            <surname>Cheveralls</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Brunner</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Michaelis</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Raghavan</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Kobayashi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Savy</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Canaj</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>OpenCell: Endogenous tagging for the cartography of human cellular organization</article-title>
        <source>Science</source>
        <year>2022</year>
        <volume>375</volume>
        <fpage>eabi6983</fpage>
        <pub-id pub-id-type="doi">10.1126/science.abi6983</pub-id>
        <?supplied-pmid 35271311?>
        <pub-id pub-id-type="pmid">35271311</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chong</surname>
            <given-names>YT</given-names>
          </name>
          <name>
            <surname>Koh</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Duffy</surname>
            <given-names>SK</given-names>
          </name>
          <name>
            <surname>Cox</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Moses</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Moffat</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Yeast proteome dynamics from single cell imaging and automated analysis</article-title>
        <source>Cell</source>
        <year>2015</year>
        <volume>161</volume>
        <fpage>1413</fpage>
        <lpage>1424</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2015.04.051</pub-id>
        <?supplied-pmid 26046442?>
        <pub-id pub-id-type="pmid">26046442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Costanzo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>VanderSluis</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Koch</surname>
            <given-names>EN</given-names>
          </name>
          <name>
            <surname>Baryshnikova</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Pons</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Tan</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Usaj</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hanchard</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>SD</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A global genetic interaction network maps a wiring diagram of cellular function</article-title>
        <source>Science</source>
        <year>2016</year>
        <volume>353</volume>
        <fpage>aaf1420</fpage>
        <pub-id pub-id-type="doi">10.1126/science.aaf1420</pub-id>
        <?supplied-pmid 27708008?>
        <pub-id pub-id-type="pmid">27708008</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cox</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>YT</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Liquid growth of arrayed fluorescently tagged Saccharomyces cerevisiae strains for live-cell high-throughput microscopy screens</article-title>
        <source>Cold Spring Harb Protoc</source>
        <year>2016</year>
        <volume>2016</volume>
        <fpage>pdb prot088799</fpage>
        <pub-id pub-id-type="doi">10.1101/pdb.prot088799</pub-id>
        <?supplied-pmid 27037071?>
        <pub-id pub-id-type="pmid">27037071</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Decottignies</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Grant</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Nichols</surname>
            <given-names>JW</given-names>
          </name>
          <name>
            <surname>de Wet</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>McIntosh</surname>
            <given-names>DB</given-names>
          </name>
          <name>
            <surname>Goffeau</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>ATPase and multidrug transport activities of the overexpressed yeast ABC protein Yor1p</article-title>
        <source>J Biol Chem</source>
        <year>1998</year>
        <volume>273</volume>
        <fpage>12612</fpage>
        <lpage>12622</lpage>
        <pub-id pub-id-type="doi">10.1074/jbc.273.20.12612</pub-id>
        <?supplied-pmid 9575223?>
        <pub-id pub-id-type="pmid">9575223</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <mixed-citation publication-type="other">Deng J, Dong W, Socher R, Li L-J, Li K, Fei-Fei L (2009) Imagenet: a large-scale hierarchical image database. In: IEEE conference on computer vision and pattern recognition (CVPR) 248–255</mixed-citation>
    </ref>
    <ref id="CR11">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deshpande</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Keusch</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Challa</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Iesmantavicius</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Gasser</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Gut</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>The Sir4 H-BRCT domain interacts with phospho-proteins to sequester and repress yeast heterochromatin</article-title>
        <source>EMBO J</source>
        <year>2019</year>
        <volume>38</volume>
        <fpage>e101744</fpage>
        <pub-id pub-id-type="doi">10.15252/embj.2019101744</pub-id>
        <?supplied-pmid 31515872?>
        <pub-id pub-id-type="pmid">31515872</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dubreuil</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Sass</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Nadav</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Heidenreich</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Georgeson</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Weill</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Meurer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Schuldiner</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Knop</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>YeastRGB: comparing the abundance and localization of yeast proteins across cells and libraries</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <fpage>D1245</fpage>
        <lpage>D1249</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky941</pub-id>
        <?supplied-pmid 30357397?>
        <pub-id pub-id-type="pmid">30357397</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dunn</surname>
            <given-names>KW</given-names>
          </name>
          <name>
            <surname>Kamocka</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>McDonald</surname>
            <given-names>JH</given-names>
          </name>
        </person-group>
        <article-title>A practical guide to evaluating colocalization in biological microscopy</article-title>
        <source>Am J Physiol Cell Physiol</source>
        <year>2011</year>
        <volume>300</volume>
        <fpage>C723</fpage>
        <lpage>742</lpage>
        <pub-id pub-id-type="doi">10.1152/ajpcell.00462.2010</pub-id>
        <?supplied-pmid 21209361?>
        <pub-id pub-id-type="pmid">21209361</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Eldakak</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Rancati</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Rubinstein</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Paul</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Conaway</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Asymmetrically inherited multidrug resistance transporters are recessive determinants in cellular replicative ageing</article-title>
        <source>Nat Cell Biol</source>
        <year>2010</year>
        <volume>12</volume>
        <fpage>799</fpage>
        <lpage>805</lpage>
        <pub-id pub-id-type="doi">10.1038/ncb2085</pub-id>
        <?supplied-pmid 20657593?>
        <pub-id pub-id-type="pmid">20657593</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <mixed-citation publication-type="other">Ester M, Kriegel H, Sander J, Xu X (1996) A density-based algorithm for discovering clusters in large spatial databases with noise. In: KDD'96: Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 226–231</mixed-citation>
    </ref>
    <ref id="CR16">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Girosi</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Poggio</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Regularization theory and neural networks architectures</article-title>
        <source>Neural Comput</source>
        <year>1995</year>
        <volume>7</volume>
        <fpage>219</fpage>
        <lpage>269</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1995.7.2.219</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grys</surname>
            <given-names>BT</given-names>
          </name>
          <name>
            <surname>Lo</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Sahin</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Kraus</surname>
            <given-names>OZ</given-names>
          </name>
          <name>
            <surname>Morris</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Machine learning and computer vision approaches for phenotypic profiling</article-title>
        <source>J Cell Biol</source>
        <year>2017</year>
        <volume>216</volume>
        <fpage>65</fpage>
        <lpage>71</lpage>
        <pub-id pub-id-type="doi">10.1083/jcb.201610026</pub-id>
        <?supplied-pmid 27940887?>
        <pub-id pub-id-type="pmid">27940887</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Yeh</surname>
            <given-names>LH</given-names>
          </name>
          <name>
            <surname>Folkesson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ivanov</surname>
            <given-names>IE</given-names>
          </name>
          <name>
            <surname>Krishnan</surname>
            <given-names>AP</given-names>
          </name>
          <name>
            <surname>Keefe</surname>
            <given-names>MG</given-names>
          </name>
          <name>
            <surname>Hashemi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Shin</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Chhun</surname>
            <given-names>BB</given-names>
          </name>
          <name>
            <surname>Cho</surname>
            <given-names>NH</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Revealing architectural order with quantitative label-free imaging and deep learning</article-title>
        <source>Elife</source>
        <year>2020</year>
        <volume>9</volume>
        <fpage>e55502</fpage>
        <pub-id pub-id-type="doi">10.7554/eLife.55502</pub-id>
        <?supplied-pmid 32716843?>
        <pub-id pub-id-type="pmid">32716843</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Haase</surname>
            <given-names>SB</given-names>
          </name>
          <name>
            <surname>Wittenberg</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Topology and control of the cell-cycle-regulated transcriptional circuitry</article-title>
        <source>Genetics</source>
        <year>2014</year>
        <volume>196</volume>
        <fpage>65</fpage>
        <lpage>90</lpage>
        <pub-id pub-id-type="doi">10.1534/genetics.113.152595</pub-id>
        <?supplied-pmid 24395825?>
        <pub-id pub-id-type="pmid">24395825</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Harris</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Clark</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ireland</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lomax</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ashburner</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Foulger</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Eilbeck</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Lewis</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Marshall</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Mungall</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The Gene Ontology (GO) database and informatics resource</article-title>
        <source>Nucleic Acids Res</source>
        <year>2004</year>
        <volume>32</volume>
        <fpage>D258</fpage>
        <lpage>261</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkh036</pub-id>
        <?supplied-pmid 14681407?>
        <pub-id pub-id-type="pmid">14681407</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Kennedy</surname>
            <given-names>BK</given-names>
          </name>
        </person-group>
        <article-title>The yeast replicative aging model</article-title>
        <source>Biochim Biophys Acta Mol Basis Dis</source>
        <year>2018</year>
        <volume>1864</volume>
        <fpage>2690</fpage>
        <lpage>2696</lpage>
        <pub-id pub-id-type="doi">10.1016/j.bbadis.2018.02.023</pub-id>
        <?supplied-pmid 29524633?>
        <pub-id pub-id-type="pmid">29524633</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ho</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Baryshnikova</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Brown</surname>
            <given-names>GW</given-names>
          </name>
        </person-group>
        <article-title>Unification of protein abundance datasets yields a quantitative Saccharomyces cerevisiae proteome</article-title>
        <source>Cell Syst</source>
        <year>2018</year>
        <volume>6</volume>
        <fpage>192</fpage>
        <lpage>205.e193</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2017.12.004</pub-id>
        <?supplied-pmid 29361465?>
        <pub-id pub-id-type="pmid">29361465</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Pho85, a multifunctional cyclin-dependent protein kinase in budding yeast</article-title>
        <source>Mol Microbiol</source>
        <year>2007</year>
        <volume>66</volume>
        <fpage>303</fpage>
        <lpage>314</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1365-2958.2007.05914.x</pub-id>
        <?supplied-pmid 17850263?>
        <pub-id pub-id-type="pmid">17850263</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <mixed-citation publication-type="other">Huang G, Liu Z, Van Der Maaten L, Weinberger KQ (2017) Densely connected convolutional networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 4700–4708</mixed-citation>
    </ref>
    <ref id="CR25">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huh</surname>
            <given-names>WK</given-names>
          </name>
          <name>
            <surname>Falvo</surname>
            <given-names>JV</given-names>
          </name>
          <name>
            <surname>Gerke</surname>
            <given-names>LC</given-names>
          </name>
          <name>
            <surname>Carroll</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>Howson</surname>
            <given-names>RW</given-names>
          </name>
          <name>
            <surname>Weissman</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>O’Shea</surname>
            <given-names>EK</given-names>
          </name>
        </person-group>
        <article-title>Global analysis of protein localization in budding yeast</article-title>
        <source>Nature</source>
        <year>2003</year>
        <volume>425</volume>
        <fpage>686</fpage>
        <lpage>691</lpage>
        <pub-id pub-id-type="doi">10.1038/nature02026</pub-id>
        <?supplied-pmid 14562095?>
        <pub-id pub-id-type="pmid">14562095</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jaiswal</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Babu</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Zadeh</surname>
            <given-names>MZ</given-names>
          </name>
          <name>
            <surname>Banerjee</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Makedon</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>A survey on contrastive self-supervised learning</article-title>
        <source>Technologies</source>
        <year>2020</year>
        <volume>9</volume>
        <fpage>2</fpage>
        <pub-id pub-id-type="doi">10.3390/technologies9010002</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <mixed-citation publication-type="other">Jenni S, Favaro P (2018) Self-supervised feature learning by learning to spot artifacts. In: IEEE/CVF conference on computer vision and pattern recognition (CVPR) 2733–2742</mixed-citation>
    </ref>
    <ref id="CR28">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jing</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Self-supervised visual feature learning with deep neural networks: a survey</article-title>
        <source>IEEE Tran Pattern Anal Mach Intell</source>
        <year>2020</year>
        <volume>43</volume>
        <fpage>4037</fpage>
        <lpage>4058</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2020.2992393</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kanehisa</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Goto</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>KEGG: kyoto encyclopedia of genes and genomes</article-title>
        <source>Nucleic Acids Res</source>
        <year>2000</year>
        <volume>28</volume>
        <fpage>27</fpage>
        <lpage>30</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/28.1.27</pub-id>
        <?supplied-pmid 10592173?>
        <pub-id pub-id-type="pmid">10592173</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <mixed-citation publication-type="other">Kingma DP, Ba J (2014) Adam: a method for stochastic optimization. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</ext-link></mixed-citation>
    </ref>
    <ref id="CR31">
      <mixed-citation publication-type="other">Kingma DP, Welling M (2013) Auto-encoding variational bayes. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</ext-link></mixed-citation>
    </ref>
    <ref id="CR32">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kobayashi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Cheveralls</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Leonetti</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Royer</surname>
            <given-names>LA</given-names>
          </name>
        </person-group>
        <article-title>Self-supervised deep learning encodes high-resolution features of protein subcellular localization</article-title>
        <source>Nat Methods</source>
        <year>2022</year>
        <volume>19</volume>
        <fpage>995</fpage>
        <lpage>1003</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-022-01541-z</pub-id>
        <?supplied-pmid 35879608?>
        <pub-id pub-id-type="pmid">35879608</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Koh</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>YT</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Moses</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
          <name>
            <surname>Moffat</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>CYCLoPs: a comprehensive database constructed from automated analysis of protein abundance and subcellular localization patterns in Saccharomyces cerevisiae</article-title>
        <source>G3</source>
        <year>2015</year>
        <volume>5</volume>
        <fpage>1223</fpage>
        <lpage>1232</lpage>
        <pub-id pub-id-type="doi">10.1534/g3.115.017830</pub-id>
        <?supplied-pmid 26048563?>
        <pub-id pub-id-type="pmid">26048563</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <mixed-citation publication-type="other">Kolesnikov A, Zhai X, Beyer L (2019) Revisiting self-supervised visual representation learning. In: IEEE/CVF conference on computer vision and pattern recognition 1920–1929</mixed-citation>
    </ref>
    <ref id="CR35">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kraus</surname>
            <given-names>OZ</given-names>
          </name>
          <name>
            <surname>Ba</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Frey</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Classifying and segmenting microscopy images with deep multiple instance learning</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <fpage>i52</fpage>
        <lpage>i59</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw252</pub-id>
        <?supplied-pmid 27307644?>
        <pub-id pub-id-type="pmid">27307644</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kraus</surname>
            <given-names>OZ</given-names>
          </name>
          <name>
            <surname>Grys</surname>
            <given-names>BT</given-names>
          </name>
          <name>
            <surname>Ba</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Frey</surname>
            <given-names>BJ</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Automated analysis of high-content microscopy data with deep learning</article-title>
        <source>Mol Syst Biol</source>
        <year>2017</year>
        <volume>13</volume>
        <fpage>924</fpage>
        <pub-id pub-id-type="doi">10.15252/msb.20177551</pub-id>
        <?supplied-pmid 28420678?>
        <pub-id pub-id-type="pmid">28420678</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kuleshov</surname>
            <given-names>MV</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>MR</given-names>
          </name>
          <name>
            <surname>Rouillard</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Fernandez</surname>
            <given-names>NF</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Koplev</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Jenkins</surname>
            <given-names>SL</given-names>
          </name>
          <name>
            <surname>Jagodnik</surname>
            <given-names>KM</given-names>
          </name>
          <name>
            <surname>Lachmann</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Enrichr: a comprehensive gene set enrichment analysis web server 2016 update</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <fpage>W90</fpage>
        <lpage>97</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw377</pub-id>
        <?supplied-pmid 27141961?>
        <pub-id pub-id-type="pmid">27141961</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>AX</given-names>
          </name>
          <name>
            <surname>Kraus</surname>
            <given-names>OZ</given-names>
          </name>
          <name>
            <surname>Cooper</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Moses</surname>
            <given-names>AM</given-names>
          </name>
        </person-group>
        <article-title>Learning unsupervised feature representations for single cell microscopy images with paired cell inpainting</article-title>
        <source>PLoS Comput Biol</source>
        <year>2019</year>
        <volume>15</volume>
        <fpage>e1007348</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1007348</pub-id>
        <?supplied-pmid 31479439?>
        <pub-id pub-id-type="pmid">31479439</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mattiazzi Usaj</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sahin</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Pons</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Usaj</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Masinas</surname>
            <given-names>MPD</given-names>
          </name>
          <name>
            <surname>Shuteriqi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Shkurin</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Aloy</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Morris</surname>
            <given-names>Q</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Systematic genetics and single-cell imaging reveal widespread morphological pleiotropy and cell-to-cell variability</article-title>
        <source>Mol Syst Biol</source>
        <year>2020</year>
        <volume>16</volume>
        <fpage>e9243</fpage>
        <pub-id pub-id-type="doi">10.15252/msb.20199243</pub-id>
        <?supplied-pmid 32064787?>
        <pub-id pub-id-type="pmid">32064787</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mattiazzi Usaj</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Styles</surname>
            <given-names>EB</given-names>
          </name>
          <name>
            <surname>Verster</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>High-content screening for quantitative cell biology</article-title>
        <source>Trends Cell Biol</source>
        <year>2016</year>
        <volume>26</volume>
        <fpage>598</fpage>
        <lpage>611</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tcb.2016.03.008</pub-id>
        <?supplied-pmid 27118708?>
        <pub-id pub-id-type="pmid">27118708</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <mixed-citation publication-type="other">McKnight PE, Najab J (2010) Mann-Whitney U test. The corsini encyclopedia of psychology. Wiley</mixed-citation>
    </ref>
    <ref id="CR42">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>McQuin</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Goodman</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Chernyshev</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Kamentsky</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Cimini</surname>
            <given-names>BA</given-names>
          </name>
          <name>
            <surname>Karhohs</surname>
            <given-names>KW</given-names>
          </name>
          <name>
            <surname>Doan</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Rafelski</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Thirstrup</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>CellProfiler 3.0: next-generation image processing for biology</article-title>
        <source>PLoS Biol</source>
        <year>2018</year>
        <volume>16</volume>
        <fpage>e2005970</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.2005970</pub-id>
        <?supplied-pmid 29969450?>
        <pub-id pub-id-type="pmid">29969450</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meldal</surname>
            <given-names>BH</given-names>
          </name>
          <name>
            <surname>Forner-Martinez</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Costanzo</surname>
            <given-names>MC</given-names>
          </name>
          <name>
            <surname>Dana</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Demeter</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Dumousseau</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dwight</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Gaulton</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Licata</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Melidoni</surname>
            <given-names>AN</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The complex portal-an encyclopaedia of macromolecular complexes</article-title>
        <source>Nucleic Acids Res</source>
        <year>2015</year>
        <volume>43</volume>
        <fpage>D479</fpage>
        <lpage>484</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gku975</pub-id>
        <?supplied-pmid 25313161?>
        <pub-id pub-id-type="pmid">25313161</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meurer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Sass</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Kats</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Herbst</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Buchmuller</surname>
            <given-names>BC</given-names>
          </name>
          <name>
            <surname>Dederer</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Huber</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Kirrmaier</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Stefl</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Genome-wide C-SWAT library for high-throughput yeast genome tagging</article-title>
        <source>Nat Methods</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>598</fpage>
        <lpage>600</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-018-0045-8</pub-id>
        <?supplied-pmid 29988096?>
        <pub-id pub-id-type="pmid">29988096</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <mixed-citation publication-type="other">Moshkov N, Bornholdt M, Benoit S, Smith M, McQuin C, Goodman A, Senft RA, Han Y, Babadi M, Horvath P et al (2024) Learning representations for image-based profiling of perturbations. Nat Commun 15:1594</mixed-citation>
    </ref>
    <ref id="CR46">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Murtagh</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Contreras</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Algorithms for hierarchical clustering: an overview</article-title>
        <source>Wiley Interdiscip Rev Data Min Knowl Discov</source>
        <year>2012</year>
        <volume>2</volume>
        <fpage>86</fpage>
        <lpage>97</lpage>
        <pub-id pub-id-type="doi">10.1002/widm.53</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Neuber</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Jarosch</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Volkwein</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Walter</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sommer</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Ubx2 links the Cdc48 complex to ER-associated protein degradation</article-title>
        <source>Nat Cell Biol</source>
        <year>2005</year>
        <volume>7</volume>
        <fpage>993</fpage>
        <lpage>998</lpage>
        <pub-id pub-id-type="doi">10.1038/ncb1298</pub-id>
        <?supplied-pmid 16179953?>
        <pub-id pub-id-type="pmid">16179953</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <mixed-citation publication-type="other">Razdaibiedina A, Brechalov A (2022) Learning multi-scale functional representations of proteins from single-cell microscopy data. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2205.11676">https://arxiv.org/abs/2205.11676</ext-link></mixed-citation>
    </ref>
    <ref id="CR49">
      <mixed-citation publication-type="other">Razdaibiedina A, Velayutham J, Modi M (2019) Multi-defect microscopy image restoration under limited data conditions. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1910.14207">https://arxiv.org/abs/1910.14207</ext-link></mixed-citation>
    </ref>
    <ref id="CR50">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rousseeuw</surname>
            <given-names>PJ</given-names>
          </name>
        </person-group>
        <article-title>Silhouettes: a graphical aid to the interpretation and validation of cluster analysis</article-title>
        <source>J Comput Appl Math</source>
        <year>1987</year>
        <volume>20</volume>
        <fpage>53</fpage>
        <lpage>65</lpage>
        <pub-id pub-id-type="doi">10.1016/0377-0427(87)90125-7</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scott</surname>
            <given-names>DW</given-names>
          </name>
        </person-group>
        <article-title>On optimal and data-based histograms</article-title>
        <source>Biometrika</source>
        <year>1979</year>
        <volume>66</volume>
        <fpage>605</fpage>
        <lpage>610</lpage>
        <pub-id pub-id-type="doi">10.1093/biomet/66.3.605</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <mixed-citation publication-type="other">Sculley D (2010) Web-scale k-means clustering. In: WWW ‘10: Proceedings of the 19th international conference on World wide web, pp 1177–1178</mixed-citation>
    </ref>
    <ref id="CR53">
      <mixed-citation publication-type="other">Selvaraju RR, Das A, Vedantam R, Cogswell M, Parikh D, Batra D (2016) Grad-Cam: Why Did You Say That? Visual Explanations from Deep Networks via Gradient-Based Localization. 2017 IEEE International Conference on Computer Vision, Venice, Italy, 618–626</mixed-citation>
    </ref>
    <ref id="CR54">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sheff</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Thorn</surname>
            <given-names>KS</given-names>
          </name>
        </person-group>
        <article-title>Optimized cassettes for fluorescent protein tagging in Saccharomyces cerevisiae</article-title>
        <source>Yeast</source>
        <year>2004</year>
        <volume>21</volume>
        <fpage>661</fpage>
        <lpage>670</lpage>
        <pub-id pub-id-type="doi">10.1002/yea.1130</pub-id>
        <?supplied-pmid 15197731?>
        <pub-id pub-id-type="pmid">15197731</pub-id>
      </element-citation>
    </ref>
    <ref id="CR55">
      <mixed-citation publication-type="other">Smilkov D, Thorat N, Kim B, Viégas F, Wattenberg M (2017) Smoothgrad: removing noise by adding noise. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1706.03825">https://arxiv.org/abs/1706.03825</ext-link></mixed-citation>
    </ref>
    <ref id="CR56">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
        <source>J Mach Learn Res</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
    <ref id="CR57">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stark</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Breitkreutz</surname>
            <given-names>BJ</given-names>
          </name>
          <name>
            <surname>Reguly</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Boucher</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Breitkreutz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tyers</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>BioGRID: a general repository for interaction datasets</article-title>
        <source>Nucleic Acids Res</source>
        <year>2006</year>
        <volume>34</volume>
        <fpage>D535</fpage>
        <lpage>539</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkj109</pub-id>
        <?supplied-pmid 16381927?>
        <pub-id pub-id-type="pmid">16381927</pub-id>
      </element-citation>
    </ref>
    <ref id="CR58">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sullivan</surname>
            <given-names>DP</given-names>
          </name>
          <name>
            <surname>Winsnes</surname>
            <given-names>CF</given-names>
          </name>
          <name>
            <surname>Akesson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Hjelmare</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wiking</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Schutten</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Campbell</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Leifsson</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Rhodes</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Nordgren</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep learning is combined with massive-scale citizen science to improve large-scale image classification</article-title>
        <source>Nat Biotechnol</source>
        <year>2018</year>
        <volume>36</volume>
        <fpage>820</fpage>
        <lpage>828</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.4225</pub-id>
        <?supplied-pmid 30125267?>
        <pub-id pub-id-type="pmid">30125267</pub-id>
      </element-citation>
    </ref>
    <ref id="CR59">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thul</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Akesson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wiking</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Mahdessian</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Geladaki</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ait Blal</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Alm</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Asplund</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bjork</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Breckels</surname>
            <given-names>LM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A subcellular map of the human proteome</article-title>
        <source>Science</source>
        <year>2017</year>
        <volume>356</volume>
        <fpage>eaal3321</fpage>
        <pub-id pub-id-type="doi">10.1126/science.aal3321</pub-id>
        <?supplied-pmid 28495876?>
        <pub-id pub-id-type="pmid">28495876</pub-id>
      </element-citation>
    </ref>
    <ref id="CR60">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thul</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Lindskog</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>The human protein atlas: a spatial map of the human proteome</article-title>
        <source>Protein Sci</source>
        <year>2018</year>
        <volume>27</volume>
        <fpage>233</fpage>
        <lpage>244</lpage>
        <pub-id pub-id-type="doi">10.1002/pro.3307</pub-id>
        <?supplied-pmid 28940711?>
        <pub-id pub-id-type="pmid">28940711</pub-id>
      </element-citation>
    </ref>
    <ref id="CR61">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tkach</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Yimit</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>AY</given-names>
          </name>
          <name>
            <surname>Riffle</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Costanzo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Jaschob</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hendry</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Ou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Moffat</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Dissecting DNA damage response pathways by analysing protein localization and abundance changes during DNA replication stress</article-title>
        <source>Nat Cell Biol</source>
        <year>2012</year>
        <volume>14</volume>
        <fpage>966</fpage>
        <lpage>976</lpage>
        <pub-id pub-id-type="doi">10.1038/ncb2549</pub-id>
        <?supplied-pmid 22842922?>
        <pub-id pub-id-type="pmid">22842922</pub-id>
      </element-citation>
    </ref>
    <ref id="CR62">
      <mixed-citation publication-type="other">Tong A, Boone C (2006) Synthetic genetic array analysis in Saccharomyces cerevisiae. In: Xiao W (ed) Yeast protocols, second edition. Humana Press, Totowa, pp 171–191</mixed-citation>
    </ref>
    <ref id="CR63">
      <mixed-citation publication-type="other">Van Den Oord A, Vinyals O, Kavukcuoglu K (2017) Neural discrete representation learning. In: Advances in neural information processing systems, vol 30 (NIPS 2017)</mixed-citation>
    </ref>
    <ref id="CR64">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Van der Maaten</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Visualizing data using t-SNE</article-title>
        <source>J Mach Learn Res</source>
        <year>2008</year>
        <volume>9</volume>
        <fpage>2579</fpage>
        <lpage>2605</lpage>
      </element-citation>
    </ref>
    <ref id="CR65">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vinh</surname>
            <given-names>NX</given-names>
          </name>
          <name>
            <surname>Epps</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bailey</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Information theoretic measures for clusterings comparison: variants, properties, normalization and correction for chance</article-title>
        <source>J Mach Learn Res</source>
        <year>2010</year>
        <volume>11</volume>
        <fpage>2837</fpage>
        <lpage>2854</lpage>
      </element-citation>
    </ref>
    <ref id="CR66">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Youn</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Nguyen Ba</surname>
            <given-names>AN</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Messier</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Cox</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Moses</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Functional analysis of kinases and transcription factors in saccharomyces cerevisiae using an integrated overexpression library</article-title>
        <source>G3</source>
        <year>2017</year>
        <volume>7</volume>
        <fpage>911</fpage>
        <lpage>921</lpage>
        <pub-id pub-id-type="doi">10.1534/g3.116.038471</pub-id>
        <?supplied-pmid 28122947?>
        <pub-id pub-id-type="pmid">28122947</pub-id>
      </element-citation>
    </ref>
    <ref id="CR67">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zaritsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jamieson</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Welf</surname>
            <given-names>ES</given-names>
          </name>
          <name>
            <surname>Nevarez</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Cillay</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Eskiocak</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Cantarel</surname>
            <given-names>BL</given-names>
          </name>
          <name>
            <surname>Danuser</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Interpretable deep learning uncovers cellular properties in label-free live cell images that are predictive of highly metastatic melanoma</article-title>
        <source>Cell Syst</source>
        <year>2021</year>
        <volume>12</volume>
        <fpage>733</fpage>
        <lpage>747</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2021.05.003</pub-id>
        <?supplied-pmid 34077708?>
        <pub-id pub-id-type="pmid">34077708</pub-id>
      </element-citation>
    </ref>
    <ref id="CR68">
      <mixed-citation publication-type="other">Zeiler MD, Fergus R (2014) Visualizing and understanding convolutional networks. Computer Vision – ECCV 2014</mixed-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Mol Syst Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">Mol Syst Biol</journal-id>
    <journal-title-group>
      <journal-title>Molecular Systems Biology</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1744-4292</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">11066028</article-id>
    <article-id pub-id-type="pmid">38472305</article-id>
    <article-id pub-id-type="publisher-id">29</article-id>
    <article-id pub-id-type="doi">10.1038/s44320-024-00029-6</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>PIFiA: self-supervised approach for protein functional annotation from single-cell imaging data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Razdaibiedina</surname>
          <given-names>Anastasia</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Brechalov</surname>
          <given-names>Alexander</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Friesen</surname>
          <given-names>Helena</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mattiazzi Usaj</surname>
          <given-names>Mojca</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Masinas</surname>
          <given-names>Myra Paz David</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Garadi Suresh</surname>
          <given-names>Harsha</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Kyle</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3542-6760</contrib-id>
        <name>
          <surname>Boone</surname>
          <given-names>Charles</given-names>
        </name>
        <address>
          <email>charlie.boone@utoronto.ca</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0009-0000-9062-4180</contrib-id>
        <name>
          <surname>Ba</surname>
          <given-names>Jimmy</given-names>
        </name>
        <address>
          <email>jba@cs.toronto.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6427-6493</contrib-id>
        <name>
          <surname>Andrews</surname>
          <given-names>Brenda</given-names>
        </name>
        <address>
          <email>brenda.andrews@utoronto.ca</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03dbr7087</institution-id><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>Department of Molecular Genetics, </institution><institution>University of Toronto, </institution></institution-wrap>Toronto, ON Canada </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03dbr7087</institution-id><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>The Donnelly Centre, </institution><institution>University of Toronto, </institution></institution-wrap>Toronto, ON Canada </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03kqdja62</institution-id><institution-id institution-id-type="GRID">grid.494618.6</institution-id><institution-id institution-id-type="ISNI">0000 0005 0272 1351</institution-id><institution>Vector Institute for Artificial Intelligence, </institution></institution-wrap>Toronto, ON Canada </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/010rf2m76</institution-id><institution-id institution-id-type="GRID">grid.509461.f</institution-id><institution-id institution-id-type="ISNI">0000 0004 1757 8255</institution-id><institution>RIKEN Center for Sustainable Resource Science, </institution></institution-wrap>2-1 Hirosawa, Wako, Saitama, Japan </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03dbr7087</institution-id><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>Department of Computer Science, </institution><institution>University of Toronto, </institution></institution-wrap>Toronto, ON Canada </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05g13zd79</institution-id><institution-id institution-id-type="GRID">grid.68312.3e</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 9422</institution-id><institution>Present Address: Department of Chemistry and Biology, </institution><institution>Toronto Metropolitan University, </institution></institution-wrap>Toronto, ON Canada </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>12</day>
      <month>3</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>12</day>
      <month>3</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>5</month>
      <year>2024</year>
    </pub-date>
    <volume>20</volume>
    <issue>5</issue>
    <fpage>521</fpage>
    <lpage>548</lpage>
    <history>
      <date date-type="received">
        <day>15</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>27</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="accepted">
        <day>28</day>
        <month>2</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. Creative Commons Public Domain Dedication waiver <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link> applies to the data associated with this article, unless otherwise stated in a credit line to the data, but does not extend to the graphical or creative elements of illustrations, charts, or figures. This waiver removes legal barriers to the re-use and mining of research data. According to standard scholarly practice, it is recommended to provide appropriate citation and attribution whenever technically possible.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Fluorescence microscopy data describe protein localization patterns at single-cell resolution and have the potential to reveal whole-proteome functional information with remarkable precision. Yet, extracting biologically meaningful representations from cell micrographs remains a major challenge. Existing approaches often fail to learn robust and noise-invariant features or rely on supervised labels for accurate annotations. We developed PIFiA (Protein Image-based Functional Annotation), a self-supervised approach for protein functional annotation from single-cell imaging data. We imaged the global yeast ORF-GFP collection and applied PIFiA to generate protein feature profiles from single-cell images of fluorescently tagged proteins. We show that PIFiA outperforms existing approaches for molecular representation learning and describe a range of downstream analysis tasks to explore the information content of the feature profiles. Specifically, we cluster extracted features into a hierarchy of functional organization, study cell population heterogeneity, and develop techniques to distinguish multi-localizing proteins and identify functional modules. Finally, we confirm new PIFiA predictions using a colocalization assay, suggesting previously unappreciated biological roles for several proteins. Paired with a fully interactive website (<ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia/">https://thecellvision.org/pifia/</ext-link>), PIFiA is a resource for the quantitative analysis of protein organization within the cell.</p>
    </abstract>
    <abstract id="Abs2" abstract-type="Synopsis">
      <title>Synopsis</title>
      <p id="Par2">
        <graphic position="anchor" xlink:href="44320_2024_29_Figa_HTML" id="d33e294"/>
      </p>
      <p id="Par3">PIFiA is a self-supervised deep-learning approach for protein functional annotation from single-cell images. It generates feature profiles from images of the yeast ORF-GFP collection that can be used in downstream analyses.</p>
      <p id="Par4">
        <list list-type="bullet">
          <list-item>
            <p id="Par5">PIFiA features identify new functional groups of proteins within organelles and proteins with heterogeneous localizations.</p>
          </list-item>
          <list-item>
            <p id="Par6">PIFiA features successfully predict protein–protein interactions and members of protein complexes.</p>
          </list-item>
          <list-item>
            <p id="Par7">PIFiA outperforms previous methods on four different standards of protein function.</p>
          </list-item>
          <list-item>
            <p id="Par8">Images and analysis are available at thecellvision.org/pifia.</p>
          </list-item>
        </list>
      </p>
    </abstract>
    <abstract id="Abs3" abstract-type="web-summary">
      <p id="Par9">PIFiA is a self-supervised deep-learning approach for protein functional annotation from single-cell images. It generates feature profiles from images of the yeast ORF-GFP collection that can be used in downstream analyses.</p>
      <p id="Par10">
        <graphic position="anchor" xlink:href="44320_2024_29_Figb_HTML" id="d33e321"/>
      </p>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Self-supervised</kwd>
      <kwd>Machine Learning</kwd>
      <kwd>Single-cell</kwd>
      <kwd>Imaging</kwd>
      <kwd>Protein</kwd>
    </kwd-group>
    <kwd-group kwd-group-type="embo-subject">
      <title>Subject terms</title>
      <kwd>Methods &amp; Resources</kwd>
      <kwd>Organelles</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
            <institution>HHS | National Institutes of Health (NIH)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01HG005853</award-id>
        <principal-award-recipient>
          <name>
            <surname>Friesen</surname>
            <given-names>Helena</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000024</institution-id>
            <institution>Canadian Government | Canadian Institutes of Health Research (CIHR)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>PJT-180259</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100007631</institution-id>
            <institution>Canadian Institute for Advanced Research (ICRA)</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100016327</institution-id>
            <institution>Ontario Government | Ministère des Services à l'enfance et des Services sociaux et communautaires, Gouvernement de l'Ontario (Ministry of Children, Community and Social Services, Government of Ontario)</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100019117</institution-id>
            <institution>Vector Institute (Institut Vecteur)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>PGA Fellowship</award-id>
        <principal-award-recipient>
          <name>
            <surname>Razdaibiedina</surname>
            <given-names>Anastasia</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© European Molecular Biology Organization 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par11">Recent progress in high-throughput microscopy and computational image analysis has catalyzed large-scale efforts to quantitatively describe single-cell biology (Cho et al, <xref ref-type="bibr" rid="CR5">2022</xref>; Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Mattiazzi Usaj et al, <xref ref-type="bibr" rid="CR39">2020</xref>; Mattiazzi Usaj et al, <xref ref-type="bibr" rid="CR40">2016</xref>; Thul et al, <xref ref-type="bibr" rid="CR59">2017</xref>; Thul and Lindskog, <xref ref-type="bibr" rid="CR60">2018</xref>). Advances in quantitative analysis of large-scale image datasets have been driven by the development of algorithms for protein localization prediction, which have been used for automated drug screening, and extracting morphological profiles from cell images (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>; McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>). Computational methods enable efficient analysis of millions of single-cell images by extracting morphological information in an unbiased quantitative form. However, generating meaningful numerical features from single-cell images remains a significant challenge. Cells in micrographs typically exhibit a variety of shapes and positions, while noise levels and pixel intensities can also vary between images, making it difficult to develop algorithms that extract functionally rich patterns while ignoring irrelevant information (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). For instance, early machine-learning approaches relied on hand-engineered feature sets extracted from images, such as cell texture and shape, which were often difficult to select and not transferable to other datasets or tasks (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>). Ideally, a computational workflow would map single cells and proteins to robust numerical representations, enabling analysis of the spatial organization of the cell in an objective way.</p>
    <p id="Par12">More recently, single-cell images have been analyzed using deep learning methods, which overcome the limitations associated with hand-engineered feature sets by learning the optimal feature representations directly from pixel level data (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Grys et al, <xref ref-type="bibr" rid="CR17">2017</xref>). The first machine-learning approaches for automated analysis of proteins’ localization patterns were supervised (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). Such methods were trained on a specific classification task, such as predicting cellular compartments from the input images (Grys et al, <xref ref-type="bibr" rid="CR17">2017</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). While supervised methods achieve state-of-the-art performance in their target tasks, they require manual annotation of images used for training, which is time-consuming and expensive. In one of the efforts to accelerate label collection, the Human Atlas Project leveraged crowd-sourcing on a large scale, involving thousands of video games players for microscopy image annotation (Sullivan et al, <xref ref-type="bibr" rid="CR58">2018</xref>). However, manual label assignment is still not practical for imaging datasets containing millions of single-cell micrographs (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). In addition, human-labeled standards may reflect the biases of an individual annotator and can preclude identification of subtle or incompletely penetrant phenotypes (Kraus et al, <xref ref-type="bibr" rid="CR35">2016</xref>; Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>). These problems motivated the development of methods that do not rely on supervised annotations during training (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>; Moshkov et al, <xref ref-type="bibr" rid="CR45">2024</xref>).</p>
    <p id="Par13">An emerging alternative to supervised methods for biological image analysis involves self-supervised approaches, which do not require manually assigned categories during training (Chen et al, <xref ref-type="bibr" rid="CR4">2020</xref>; Jenni and Favaro, <xref ref-type="bibr" rid="CR27">2018</xref>; Jing and Tian, <xref ref-type="bibr" rid="CR28">2020</xref>). Instead, self-supervised learning models define a training objective, or pretext task, using structural information from the data itself (Jaiswal et al, <xref ref-type="bibr" rid="CR26">2020</xref>; Jing and Tian, <xref ref-type="bibr" rid="CR28">2020</xref>; Kolesnikov et al, <xref ref-type="bibr" rid="CR34">2019</xref>). In the context of self-supervised training, features learned with the pretext task should encapsulate information from the images that is useful for downstream applications, such as the discovery of common localization patterns by clustering analysis (Sullivan et al, <xref ref-type="bibr" rid="CR58">2018</xref>). Recently, self-supervised and weakly-supervised methods based on auto-encoders have been used for representation learning on cellular data (Guo et al, <xref ref-type="bibr" rid="CR18">2020</xref>; Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>; Zaritsky et al, <xref ref-type="bibr" rid="CR67">2021</xref>). For example, weakly supervised learning with convolutional neural networks has been successfully applied for modeling associations between images and treatments, significantly improving performance over classical features (Moshkov et al, <xref ref-type="bibr" rid="CR45">2024</xref>). Autoencoder-based models are trained by compressing an image into the latent space (encoding), and subsequent image reconstruction (decoding) (Kingma and Welling, <xref ref-type="bibr" rid="CR31">2013</xref>). The encoding of the image in the latent space is then used as its representation. For instance, Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>), a self-supervised approach developed for analysis of yeast fluorescent micrographs, encodes several imaging channels to predict the appearance of a fluorescently-tagged protein in a target cell. Another autoencoder-based method developed for human cell data, <italic>cytoself</italic> (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>), trains a vector-quantized variational autoencoder (Kingma and Welling, <xref ref-type="bibr" rid="CR31">2013</xref>; Van Den Oord et al, <xref ref-type="bibr" rid="CR63">2017</xref>) (VQ-VAE) to reconstruct fluorescent signals of tagged proteins. Self-supervised learning with autoencoder-based approaches has also been applied for the analysis of human microglia data (Guo et al, <xref ref-type="bibr" rid="CR18">2020</xref>) and extraction of feature profiles predictive of cell metastatic potential (Zaritsky et al, <xref ref-type="bibr" rid="CR67">2021</xref>). One of the main disadvantages of auto-encoders is their difficulty in implementation and training challenges, as well as imperfect decoding (Chen et al, <xref ref-type="bibr" rid="CR4">2020</xref>; Jenni and Favaro, <xref ref-type="bibr" rid="CR27">2018</xref>; Kolesnikov et al, <xref ref-type="bibr" rid="CR34">2019</xref>). While <italic>cytoself</italic> and Paired Cell Inpainting achieved strong performance with decoder-based representations, replicating these networks on other datasets may be prohibitively complex. In this study, we asked whether other characteristics of microscopy data could be leveraged as self-supervised objectives to learn high-quality image representations with a relatively simple convolutional neural network.</p>
    <p id="Par14">Another challenge related to learning image-based features lies in their downstream analysis and interpretation. Current approaches typically extract representations with various machine learning methods and perform downstream analysis using clustering and tSNE/UMAP projections. (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>; Sullivan et al, <xref ref-type="bibr" rid="CR58">2018</xref>). However, there are no clear rules for more nuanced biological analysis, including analysis of extracted features for different levels of cellular organization, or high-confidence identification of protein functional modules. In general, data-backed guidelines on hyperparameter selection, which enable biologically meaningful clustering and consider the scale of cellular organization, are needed. Also, current molecular representation learning approaches generally lack methodologies that can characterize protein function by quantifying cell-to-cell variability in individual protein behavior. In summary, a gap remains in the image analysis field, requiring approaches that could (1) learn biologically meaningful features without human annotations, (2) produce universal features useful for studying subcellular organization at different scales, and (3) provide techniques for a wide range of downstream feature analyses.</p>
    <p id="Par15">Here, we present PIFiA (Protein Image-based Functional Annotation), a self-supervised approach for protein functional annotation derived from single-cell imaging data. PIFiA is coupled with a range of feature exploratory techniques for biological discovery. The representation learning component of PIFiA is performed by a convolutional neural network (CNN), which was trained with the objective of predicting protein identity directly from its fluorescently-labeled input image. This objective does not depend on pre-existing annotations or human labels and, unlike autoencoder-based models, PIFiA is robust to learning non-relevant information in the image, such as cell position, multiple cells in a crop, input noise, or imaging defects. In addition to the CNN component, the PIFiA workflow includes a set of downstream analysis steps for quantitative exploration of feature profiles extracted from single-cell imaging data. We applied PIFiA to ~3,000,000 live-cell confocal images of the budding yeast open reading frame (ORF)-GFP fusion collection (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). We compare PIFiA to existing approaches for protein representation learning and show that PIFiA outperforms previous methods on four different standards of protein function. We explore PIFiA feature profiles for use in a variety of downstream tasks, which are designed for the discovery of functional groups across different scales of cellular organization. Solely using distinct localization patterns of each protein, PIFiA can make remarkably precise functional predictions, identifying highly specific subcellular localization and distinct functional modules to reveal new biological insights.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <sec id="Sec3">
      <title>PIFiA architecture, feature profiles, and proteome-scale image dataset</title>
      <p id="Par16">PIFiA is a self-supervised deep learning approach designed to derive functional information about proteins from microscopy data without using any pre-existing annotations (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). The PIFiA workflow consists of a feature extraction step performed by a deep neural network (Fig. <xref rid="Fig1" ref-type="fig">1A,B</xref>), as well as subsequent analysis steps on the extracted feature profiles (Fig. <xref rid="Fig1" ref-type="fig">1C–E</xref>). The downstream analysis enables prediction of protein localization and the identification of functional modules or subsets of proteins with related cellular roles, such as protein complexes and their associated regulators. The feature profiles can be used for multiple downstream tasks, including construction of a hierarchical map of subcellular organization (Fig. <xref rid="Fig1" ref-type="fig">1C</xref>), predicting protein function (Fig. <xref rid="Fig1" ref-type="fig">1D</xref>), identifying localization heterogeneity at a cell population level (Fig. <xref rid="Fig1" ref-type="fig">1E</xref>), and finding functional modules.<fig id="Fig1"><label>Figure 1</label><caption><title>Overview of the PIFiA workflow (see also Fig. <xref rid="Fig7" ref-type="fig">EV1</xref>).</title><p>(<bold>A</bold>) Diagram of the PIFiA neural network architecture. Shown are examples of activations from passing a micrograph of fluorescently labeled Nup2 protein (Nup2-GFP) through the PIFiA network, with corresponding patterns recognized by the convolutional filters. Feature profiles are extracted from the second fully-connected layer, for use in downstream applications. (<bold>B</bold>) Illustration of two types of feature profiles produced by PIFiA—single-cell feature profiles (extracted from a single crop) and averaged feature profiles (obtained by averaging all single-cell feature profiles of that protein). (<bold>C</bold>) Schematic representation of the global hierarchy of protein feature profile similarities to reveal different levels of functional information. (<bold>D</bold>) Illustration of protein function prediction using self-supervised PIFiA feature profiles. (<bold>E</bold>) An illustrative example of using PIFiA single-cell feature profiles to investigate the localization heterogeneity of a protein.</p></caption><graphic xlink:href="44320_2024_29_Fig1_HTML" id="d33e544"/></fig></p>
      <p id="Par17">The deep learning backbone of PIFiA is a CNN consisting of eight convolutional blocks and three fully-connected (FC) layers, which was trained to predict a protein identifier associated with an input image (i.e. one out of 4049 classes (Fig. <xref rid="Fig1" ref-type="fig">1A</xref>)). The CNN produces a feature profile (or a representation profile) from the input image, which is unique to a particular image. Feature profiles are 64-dimensional real-valued vectors extracted from the second FC layer, which is followed by a classification layer (Fig. <xref rid="Fig7" ref-type="fig">EV1A</xref>). These feature profiles encapsulate condensed information about each protein’s identity, based solely on its localization pattern. Over the course of training, the model first learns straightforward characteristics, such as patterns of different cellular compartments, then it subsequently learns more subtle morphological features that may distinguish individual proteins (Fig. <xref rid="Fig7" ref-type="fig">EV1B</xref>). To achieve the best accuracy and simplicity trade-off, we searched for the optimal architecture, network depth/width and related hyperparameters based on the validation set (Fig. <xref rid="Fig7" ref-type="fig">EV1C,D</xref>) (see Methods). We found that more complex architectures, such as DenseNets (Huang et al, <xref ref-type="bibr" rid="CR24">2017</xref>), did not improve performance but increased the training time, hence we chose a simpler architecture that could achieve comparable performance. Similarly, we searched for optimal feature profile dimensionality and found that accuracy of protein identity prediction stabilized around a 64-dimensional feature profile (Fig. <xref rid="Fig7" ref-type="fig">EV1D</xref>).</p>
      <p id="Par18">To train PIFiA, we produced a comprehensive dataset of 3,058,961 live-cell images of individual strains expressing both a unique fusion gene from the yeast ORF-GFP collection (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>) and spatial markers of cell cycle position (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>), which provide cellular context for computational analysis of protein localization. In particular, we used automated yeast genetics (Tong and Boone, <xref ref-type="bibr" rid="CR62">2006</xref>) to engineer a new version of the ORF-GFP collection, in which the resultant strains also carried fluorescent markers of the nucleus (td-Tomato-NLS) and cytoplasm (E2-Crimson). In total, images of 4049 unique strains were obtained using an automated confocal microscope. Cell images were derived from two biological replicates, each of which had four fields of view for each ORF-GFP strain. The images acquired for the GFP channel were cropped into 64 × 64 pixels crops (median of 778 crops per tagged protein, see Methods), and each crop contained at least one cell at its center. The crops for each GFP-tagged protein were then split into training, validation, and test subsets (8:1:1 ratios).</p>
      <p id="Par19">After CNN training was completed, we extracted feature profiles of the individual single-cell crops from the test set to produce single-cell feature profiles (scFPs) (Fig. <xref rid="Fig1" ref-type="fig">1B</xref>). We then averaged the scFPs for each protein to create its average feature profile (aFP) (Fig. <xref rid="Fig1" ref-type="fig">1B</xref>). An aFP and scFP for an individual protein have the same dimensions, but they describe different levels of information: scFPs encapsulate the localization pattern of a protein in one cell, while aFPs describe the general spatial distribution of a protein. Below, we first use PIFiA aFPs to broadly explore protein localization and function. We then use scFPs to explore cell-to-cell heterogeneity, localization changes, and complex protein localization patterns (Fig. <xref rid="Fig1" ref-type="fig">1C–E</xref>).</p>
    </sec>
    <sec id="Sec4">
      <title>Comparison of PIFiA performance to other self-supervised and supervised approaches</title>
      <p id="Par20">We compared aFPs produced by PIFiA to the representations from three self-supervised methods (Fig. <xref rid="Fig2" ref-type="fig">2A–C</xref>) and two supervised methods (Fig. <xref rid="Fig2" ref-type="fig">2D,E</xref>). For self-supervised methods, we used CellProfiler (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>) (a feature-extraction tool) and its variant CellProfiler+PCA (see Methods), Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>) (a self-supervised autoencoder-based approach) and <italic>cytoself</italic> (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>) (a novel self-supervised method based on a VQ-VAE, that has been used to analyze human cell images). We also included a randomly initialized PIFiA network to show a baseline with the untrained model. For supervised approaches, we used DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>) (a deep-learning model that has been used previously to analyze images of the yeast ORF-GFP collection) and a combination of DeepLoc+PIFiA. We tried both the original DeepLoc version, which was trained on a set of 21,882 cell crops with single-cell labels, as well as our adaptation of DeepLoc, or DeepLoc+PIFiA, which was trained with less accurate but plentiful protein-level labels (see Methods).<fig id="Fig2"><label>Figure 2</label><caption><title>Comparison of PIFiA performance to existing supervised and self-supervised methods for protein representation learning.</title><p>(<bold>A</bold>) Bar graph showing the performance of PIFiA and four other methods (<italic>cytoself</italic> (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>), Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>), Cell Profiler (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>) and Cell Profiler + PCA) at detecting pairs of functionally related proteins (4049 total) using adjusted mutual information. A randomly initialized network (with PIFiA architecture) is shown for comparison as a dashed red line. Gene Ontology (GO) Cellular Component (CC), GO Slim Bioprocess (GO BP Slim), Kyoto Encyclopedia of Genes and Genomes Pathways (KEGG pathways) and European Bioinformatics Institute protein complexes (Protein Complexes). Error bars represent standard deviation from the mean across three network runs. (<bold>B</bold>) Bar graph (same setup as <bold>A</bold>) showing performance assessed using average precision. (<bold>C</bold>) Bar graph (same setup as <bold>A</bold>) showing performance assessed using F-score on four biological standards. (<bold>D</bold>) PIFiA performance versus supervised approaches (two variations of DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>)) assessed using average precision on four biological standards [X axis: Gene Ontology (GO) Cellular Component (CC), GO Slim Bioprocess (GO BP Slim), Kyoto Encyclopedia of Genes and Genomes Pathways (KEGG pathways) and European Bioinformatics Institute protein complexes (Protein Complexes). “DeepLoc original” is the original implementation (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>) trained on crops with manually annotated single-cell labels (4049 proteins total); DeepLoc+PIFiA is our modified version trained on protein-level labels using Huh et al. localization standard (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). Error bars indicate the standard deviation of the scores across three independent runs (for deep learning models). (<bold>E</bold>) Bar graph (same setup as E) showing performance assessed using F-score.</p></caption><graphic xlink:href="44320_2024_29_Fig2_HTML" id="d33e666"/></fig></p>
      <p id="Par21">We consider a model to have good performance if protein pairs with higher correlation between their aFPs are more likely to be functionally related. We evaluated feature profiles (aFPs) using three metrics: F-score and average precision (AP), both measures of feature relevance, and adjusted mutual information (AMI), an information theoretic metric to assess clustering quality (see Methods). PIFiA features showed superior performance on most evaluation criteria using four functional benchmarks: Gene Ontology (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>) (GO) Cellular Components (CC), GO Slim Bioprocesses (GO BP slim), Kyoto Encyclopedia of Genes and Genomes (Kanehisa and Goto, <xref ref-type="bibr" rid="CR29">2000</xref>) (KEGG) pathways and European Bioinformatics Institute (EBI) Protein Complexes (Meldal et al, <xref ref-type="bibr" rid="CR43">2015</xref>) (Fig. <xref rid="Fig2" ref-type="fig">2</xref>).</p>
      <p id="Par22">PIFiA reached better performance than the supervised method DeepLoc in predicting protein subcellular localization (DeepLoc’s target task), as indicated by higher values of F- and AP scores, on the GO CC standard (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). PIFiA also outperformed DeepLoc based on other functional standards, with the biggest performance gain in protein complex discovery. This result confirms the utility of the PIFiA training objective which targets identification of individual tagged proteins, the most detailed level of functional information present in the image. Although the objective does not directly focus on localization prediction, over the course of training the CNN implicitly learns a variety of localization patterns needed to successfully differentiate individual proteins. Thus, PIFiA self-supervised feature profiles can be used for exploratory analysis of protein localization instead of representations from a supervised method such as DeepLoc, bypassing the need for manual annotation while improving performance.</p>
      <p id="Par23">PIFiA also demonstrated better performance than Paired Cell Inpainting, another self-supervised method, achieving 1.2, 1.7, 2.2, and 10.4-fold improvements in terms of mean average precision using cellular component, bioprocess, pathway and protein complex standards, respectively. Also, PIFiA outperformed <italic>cytoself</italic>, a self-supervised approach that utilizes a VQ-VAE in its architecture, which achieved similar performance to Paired Cell Inpainting. Compared to all other approaches examined, PIFiA representations resulted in substantial improvement in clustering quality measured by AMI scores, with an average 5-fold AMI improvement over Paired Cell Inpainting (Fig. <xref rid="Fig2" ref-type="fig">2A</xref>). The significant improvement on the protein complex standard is again explained by PIFiA’s novel self-supervised objective, which forces the network to detect the most comprehensive morphological patterns while ignoring individual image artifacts, which contrasts with autoencoder-based objectives that learn features by naive image reconstruction.</p>
      <p id="Par24">Finally, to evaluate PIFiA performance specifically on proteins that localize to compartments with similar morphologies, we did an extra evaluation run similar to Fig. <xref rid="Fig2" ref-type="fig">2A</xref>, but only including aFPs of proteins from Golgi, endosome and peroxisome (with a single Huh et al localization label). We obtained 0.13, 0.09, 0.08, and 0.1 AP scores for PIFiA, Paired Cell Inpainting, DeepLoc original and DeepLoc+PIFiA, confirming that PIFiA is capable of distinguishing proteins from compartments with similar morphologies.</p>
    </sec>
    <sec id="Sec5">
      <title>Evaluation of the functional information associated with PIFiA average feature profiles</title>
      <p id="Par25">To further assess the biological information associated with the aFPs of each protein, we used hierarchical clustering of aFPs as an unsupervised approach to discover feature profile similarities (Murtagh and Contreras, <xref ref-type="bibr" rid="CR46">2012</xref>). We performed agglomerative hierarchical clustering of the whole-proteome aFPs (4049 proteins in total) using a correlation metric and average linkage. We surveyed the resulting dendrogram at different thresholds to explore whether aFPs are suitable for studying the spatial architecture of the cell at different scales of its organization (Fig. <xref rid="Fig3" ref-type="fig">3A</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S1</xref>). The hierarchical clustering results are shown in Fig. <xref rid="Fig3" ref-type="fig">3A</xref>, with 4049 proteins on the X-axis clustered according to the similarity of their feature profiles (each column is a 64-dimensional aFP). To determine optimal cutoff thresholds, we tracked AMI scores (Vinh et al, <xref ref-type="bibr" rid="CR65">2010</xref>) at different correlation thresholds for three functional standards: GO Cellular Component, GO Slim Bioprocess and Protein Complexes (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>) (see Methods).<fig id="Fig3"><label>Figure 3</label><caption><title>Clustering of PIFiA average feature profiles and analysis of the associated biological information (see also Figs. <xref rid="Fig8" ref-type="fig">EV2</xref>, <xref rid="Fig9" ref-type="fig">EV3</xref>, <xref rid="Fig10" ref-type="fig">EV4</xref>, <xref rid="Fig11" ref-type="fig">EV5</xref>; Dataset <xref rid="MOESM2" ref-type="media">EV1</xref> and <xref rid="MOESM3" ref-type="media">EV2</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S1</xref>).</title><p>(<bold>A</bold>) Clustergram of PIFiA’s average feature profiles for 4049 proteins. The plot to the left of the Y axis shows the adjusted mutual information curve between clustering labels and GO Cellular Component labels at different distance thresholds. The distance threshold (<italic>d</italic> = 0.72) indicated on the clustergram produces clusters associated with cell compartments (color codes on the right). (<bold>B</bold>) Bar graph showing top three Gene Ontology Cellular Component scores for each cluster defined in (<bold>A</bold>). (<bold>C</bold>) Whole-proteome tSNE projection of PIFiA average feature profiles. Each point on the plot represents a protein colored according to a localization category predicted by logistic regression (see Results for training details). (<bold>D</bold>) Annotation of the whole-proteome tSNE projection with GO bioprocess categories shown as Gaussian kernel density estimates. Bioprocesses were selected according to the lowest variance from different cellular components. A filled contour plot was used instead of contour lines to make bioprocess groups more easily distinguishable. The color intensity of the kernel density estimate contour plots corresponds to the cumulative probability mass below the drawn contour. (<bold>E</bold>) Annotation of the whole-proteome tSNE projection with sub-compartmental protein groups predicted by clustering of PIFiA feature profiles (cyto—cytoplasmic cluster, nuc—nuclear cluster, mito—mitochondrial cluster). (<bold>F</bold>) Colocalization analysis of proteins from different sub-compartmental groups. Representative micrographs of cells expressing mNeonGreen- (left) or mScarlet- (middle) tagged proteins annotated to different sub-compartmental groups within three cellular compartments: <italic>nucleus</italic> (top), <italic>cell periphery</italic> (middle) and <italic>endoplasmic reticulum</italic> (ER, bottom) groups. Overlays of the mNeonGreen and mScarlet images are shown on the right. The tagged proteins are indicated on the micrographs.</p></caption><graphic xlink:href="44320_2024_29_Fig3_HTML" id="d33e787"/></fig></p>
      <p id="Par26">First, we determined an optimal threshold (0.72) corresponding to the most general level of cellular organization—GO Cellular Component annotations (Fig. <xref rid="Fig3" ref-type="fig">3A</xref>). The nine clusters produced at this threshold were enriched for proteins with relatively broad cell component annotations: nucleus, mitochondrion, Golgi apparatus, cytoplasm, endoplasmic reticulum (ER), actin patches, nucleolus and cytosolic ribosome (all <italic>p</italic>-value &lt; 10e−20 except cluster 4 with <italic>p</italic>-value &lt; 10e−5; Fig. <xref rid="Fig3" ref-type="fig">3A,B</xref>; Dataset <xref rid="MOESM2" ref-type="media">EV1</xref>; examples of cell images from each cluster are shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1A</xref>). At this level of feature profile similarity, proteins annotated to subcellular components with visually distinct morphologies, such as organelles, tend to be in a single cluster, whereas proteins annotated to more heterogeneous cellular compartments are found in multiple clusters. For example, proteins with a <italic>nucleus</italic> GO cellular component annotation are enriched only in cluster 1, whereas proteins with a <italic>cytoplasm</italic> annotation were enriched in clusters 4, 8, and 9 (Fig. <xref rid="Fig3" ref-type="fig">3A,B</xref>). Detailed visual image inspection revealed that some clusters reflect protein localization to both the cytoplasm and another compartment, such as cluster 4 which contains subsets of proteins localized to the cytoplasm and cell surface proteins. Other clusters likely reflect differences in protein abundance, such as cluster 8, which includes a number of highly abundant proteins, including ribosomal proteins.</p>
      <p id="Par27">Next, we derived optimal correlation thresholds on our dendrogram corresponding to two additional, more detailed biological standards: GO Slim Bioprocess and Protein Complexes (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>). We obtained 21 clusters for GO Slim Bioprocesses (0.64 AMI distance threshold), 20 of which were functionally enriched (GO enrichments are shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1C</xref>; median <italic>p</italic>-value of 5e−10 across all enriched clusters; cluster entropies in terms of present localizations are shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1D</xref>). Similarly, 205 clusters were found at the dendrogram cutoff corresponding to a protein complex standard (0.29 AMI, Appendix Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>), which had 11-fold median enrichment in protein complex predictions across all clusters (distribution of the per-cluster enrichments at 0.29 AMI cutoff is shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1E,F</xref>). Hence, aFPs present robust and memory-efficient representations of protein features, which allow detection of clusters with functionally related proteins at various levels of cellular organization, with the highest functional resolution at more general levels of the hierarchy (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1F</xref>).</p>
    </sec>
    <sec id="Sec6">
      <title>Adaptation of PIFiA features to external annotations for protein localization and function</title>
      <p id="Par28">Our clustering analysis showed that PIFiA aFPs capture information from cell images that enables unsupervised resolution of cellular spatial organization, grouping proteins by shared localization and biological function (Fig. <xref rid="Fig3" ref-type="fig">3A,B</xref>). We have investigated another useful property of feature profiles—adaptability for subsequent supervised training. One of our goals was to create a model that produces universal feature profiles that can be used without the requirement to re-train a full neural network from scratch on a specific task. To evaluate the adaptability of feature profiles, we used the widely adopted linear evaluation protocol (Chen et al, <xref ref-type="bibr" rid="CR4">2020</xref>) where a linear classifier is trained on top of the representations extracted from the network, and test accuracy is used as a measure of representation quality.</p>
      <p id="Par29">We first evaluated how PIFiA features can be adapted to protein localization labels, which comprise the largest labeled functional standard available (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). This analysis enables assessment of whether information contained in self-supervised PIFiA features matches the content of the original images, when extracted with a supervised method. We trained a multinomial logistic regression (LR) using PIFiA scFPs from 2415 proteins manually annotated to localize to a single subcellular localization (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>) (see Methods). We compared the final performance of the LR trained on PIFiA scFPs to DeepLoc, a supervised neural network specifically trained to classify protein localization from images of the yeast ORF-GFP collection. To match the training protocol of DeepLoc, we used scFPs derived from the single-cell images in DeepLoc’s training set (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). We report AP scores on the same single-cell crops from the test set across the full roster of 2415 single-localized proteins (Fig. <xref rid="Fig8" ref-type="fig">EV2A</xref>). Remarkably, PIFiA self-supervised scFPs that were paired with LR yielded a comparable performance to the supervised network DeepLoc, even though PIFiA feature profiles are self-supervised and were fitted to localization labels solely using LR. This finding suggests that PIFiA feature profiles have rich functional content, and we can use them to predict functional protein attributes without training a full network from scratch.</p>
      <p id="Par30">To visualize adaptation of PIFiA feature profiles to the supervised localization labels, we transformed the 64-dimensional aFPs into 2-dimensional space using t-SNE (Van der Maaten and Hinton, <xref ref-type="bibr" rid="CR64">2008</xref>) and colored them according to LR localization predictions (Fig. <xref rid="Fig3" ref-type="fig">3C</xref>). Each aFP on the t-SNE projection was annotated with the localization category corresponding to the maximal LR prediction across all scFPs. In this visualization, the morphological similarity of proteins encapsulated in the aFPs was translated into proximity on the 2D t-SNE map, highlighting that the separation of self-supervised aFPs on the map was driven by subcellular localization signals. We compared the aFP localization assignments with the assignments made using supervised machine learning methods or manual annotations trained to specifically assign proteins to subcellular localizations (Fig. <xref rid="Fig8" ref-type="fig">EV2B</xref>). Ultimately, we observed higher quality of linear localization annotation compared to subcellular localization standards produced by other approaches (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>) (Fig. <xref rid="Fig8" ref-type="fig">EV2A</xref>).</p>
      <p id="Par31">These analyses show that PIFiA feature profiles can be adapted to the objective of a supervised neural network, which confirms the high information content of PIFiA features. Such adaptable feature profiles may accelerate training by replacing various task-specific supervised neural networks with one multi-purpose self-supervised approach, which yields universally applicable representations.</p>
    </sec>
    <sec id="Sec7">
      <title>Generalization to unseen datasets</title>
      <p id="Par32">We investigated the generalization capabilities of the PIFiA neural network by applying it to previously unseen yeast imaging datasets. Specifically, we evaluated the performance of PIFiA on the publicly available CYCLoPS (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>) and YeastRGB (Dubreuil et al, <xref ref-type="bibr" rid="CR12">2019</xref>) datasets. Both datasets contain images of &gt;4000 unique GFP-tagged proteins: CYCLoPs images show a version of the ORF-GFP collection and YeastRGB contains images of a new collection based on a different fluorescent protein, mNeonGreen. We applied the PIFiA network out-of-the-box to single-cell crops of the fluorescently-tagged protein images from these datasets and extracted their feature profiles (see Methods for details on feature extraction).</p>
      <p id="Par33">We generated aFPs from both datasets and used tSNE to visually represent the similarity between feature profiles, with points in close proximity reflecting similar visual characteristics (Fig. <xref rid="Fig9" ref-type="fig">EV3</xref>). We color-coded the tSNE maps according to the annotated subcellular localizations of the yeast cell components using a well-known standard of yeast protein localization (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). This visualization strategy allowed us to observe the formation of dense clusters corresponding to specific subcellular compartments. Nucleus, cytoplasm, mitochondrion, ER, vacuole and nucleolus were the most distinguishable localizations across both datasets (Fig. <xref rid="Fig9" ref-type="fig">EV3A,B</xref>). Thus, the PIFiA network showed strong generalization capabilities on two unseen datasets without any fine-tuning of its weights. We attribute this generalization to diverse data augmentation that was applied to the training data. Overall, our results confirm the feasibility of applying PIFiA for the analysis of novel datasets.</p>
    </sec>
    <sec id="Sec8">
      <title>Experimental validation of PIFiA predictions of sub-compartmental organization of the cell</title>
      <p id="Par34">We explored more specific functional information associated with PIFiA aFPs. We used Gaussian kernel density estimates (KDEs) (see Methods) to annotate our whole-proteome 2D tSNE projection of aFPs with Gene Ontology bioprocess terms. For illustration, we selected terms from different subcellular components that had the lowest variance on the t-SNE map. This annotation showed that PIFiA features distinguished biological processes within cellular compartments (Fig. <xref rid="Fig3" ref-type="fig">3D</xref>). For example, regions of the tSNE map corresponding to the cytoplasm (Fig. <xref rid="Fig3" ref-type="fig">3C</xref>) had distinct regions enriched for translation initiation and elongation, P-body assembly, pentose-phosphate shunt and glycogen metabolic process (Fig. <xref rid="Fig3" ref-type="fig">3D</xref>). This analysis illustrates that GFP-tagged proteins with similar biological roles have distinguishable appearances in cell images, and that PIFiA learns feature profiles that can be used to discover protein functional groups across different levels of subcellular organization, including organelles and possible sub-compartmental structures.</p>
      <p id="Par35">To further explore information in PIFiA profiles related to the sub-compartmental organization of the cell, we clustered aFPs of proteins that mapped to the same localization category to produce 15 per-compartment hierarchical trees (derived from the 15 categories defined by LR; Fig. <xref rid="Fig3" ref-type="fig">3C</xref>). We selected a sub-compartmental clustering threshold of 0.5 based on the highest morphological similarity within clusters and maximal separation between clusters, measured by a Silhouette score (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1E</xref>). We identified 30 clusters, which are indicated on the tSNE projection of PIFiA feature profiles in Fig. <xref rid="Fig3" ref-type="fig">3E</xref>, with example images of cells from each group shown in Fig. <xref rid="Fig10" ref-type="fig">EV4</xref> (see also Dataset <xref rid="MOESM3" ref-type="media">EV2</xref> for GO enrichment and other information). We refer to these clusters using their localization category and associated group number (e.g., nuc-1 corresponds to the first sub-compartmental group in the nucleus). We provide an interactive version of the t-SNE plot from Fig. <xref rid="Fig3" ref-type="fig">3E</xref> on the PIFiA website (<ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia/">https://thecellvision.org/pifia/</ext-link>), where each point on the plot is clickable and allows the user to explore the micrographs corresponding to the GFP-tagged protein, find its nearest neighbors and perform enrichment analysis based on the closest aFPs.</p>
      <p id="Par36">Several general features associated with the clusters in Fig. <xref rid="Fig3" ref-type="fig">3E</xref> suggest that they are functionally meaningful and reflect sub-compartmental organization. First, proteins localizing to compartments which tend to be more homogeneous in their morphological patterns were typically seen in a single cluster (e.g., peroxisome, spindle pole, vacuolar membrane, nuclear periphery), while proteins associated with large or heterogeneous compartments, such as the nucleus, cytoplasm, and mitochondria, defined more than one sub-compartmental cluster (Fig. <xref rid="Fig3" ref-type="fig">3E</xref>; Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). Second, 16 of 32 groups showed &gt;2-fold enrichment for a GO annotation category (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>, <italic>P</italic> &lt; 0.01). For example, the nucleus region of the whole-proteome map was divided into five clusters, enriched in GO bioprocesses such as small molecule metabolic process, chromatin remodeling and RNA polymerase II activity, mitotic nuclear division and proteolysis (Fig. <xref rid="Fig3" ref-type="fig">3E</xref>; Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). Third, as expected, some of the groupings appeared to be based on protein features that were easily discernible. Proteins in some sub-compartmental groups have a tight distribution of GFP intensities, suggesting that abundance is likely an important feature for that group. For example, <italic>nuc</italic>-1 clustering likely resulted from high protein abundance, and this cluster included histones and metabolic enzymes (median GFP intensity <italic>nuc</italic>-1 proteins = 5834 ± 2103 vs median for all <italic>nuc</italic> proteins = 745 ± 793) (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). Likewise, <italic>nuc</italic>-3 proteins had low abundance (median GFP intensity = 678 ± 52) and this group was enriched for mitotic nuclear division and chromosome segregation. For some of the other groups, clustering appeared to result from differences in the spatial distribution of pixels in a region. For example, <italic>cyto</italic>-3 proteins all had a prominent cytosolic signal overlaid with a punctate morphology, and most had roles in Golgi vesicle transport (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>; Fig. <xref rid="Fig9" ref-type="fig">EV3</xref>). Similarly, <italic>cyto-8</italic> contained only seven proteins with no obvious functional overlap, but by visual inspection, all the proteins localized to the cytoplasm and to one or more foci (Fig. <xref rid="Fig9" ref-type="fig">EV3</xref>). Thus, a fraction of sub-compartmental groups could be explained by distinct protein localization features, which may correspond to coherent functionality.</p>
      <p id="Par37">For many sub-compartmental groups, however, the features driving the clustering were less obvious. To ask if we could manually identify differences between proteins from different PIFiA sub-compartments with the same overall localization, we used a more sensitive colocalization assay. We chose pairs of proteins with similar abundances, tagged them with two fluorescent proteins, mNeonGreen and mScarlet, imaged cells containing both tagged proteins, taking Z-stacks of 5 optical sections, and manually assessed images (Fig. <xref rid="Fig3" ref-type="fig">3F</xref>; Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). Using colocalization, we observed subtle differences in most of the pairs from different sub-compartmental groups; specifically, we identified differences in 39/52 (75%) protein pairs from distinct groups, but in only 7/24 (29%) pairs from the same group (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). We show three examples of pairs of proteins from different sub-compartmental groups that vary in their localizations to different extents. In one example with a clear difference, we identified a distinct localization for <italic>nuc-5</italic> proteins, which were 13.5-fold enriched for components of the proteasome (<italic>P</italic> = 7.78E−22). The localization of <italic>nuc-5</italic> proteins overlapped extensively with that of other nuclear proteins, but <italic>nuc-5</italic> proteins additionally localized to the nuclear periphery (Fig. <xref rid="Fig3" ref-type="fig">3F</xref>, top row). We detected the nuclear periphery localization of <italic>nuc-5</italic> proteins when we looked at different proteasome components from <italic>nuc-5</italic>, in colocalization assays with proteins from different sub-compartmental <italic>nuc</italic> groups, and when the fluorescent proteins were reversed (Fig. <xref rid="Fig11" ref-type="fig">EV5</xref>).</p>
      <p id="Par38">In another example with a clear difference, we performed co-localization analysis with proteins assigned to different cell periphery (CP) groups. We examined cells expressing both a high-affinity iron transporter, Ftr1, from the <italic>CP-1</italic> group, and Tcb2, a protein involved in ER-plasma membrane tethering, from the <italic>CP-2</italic> group (Fig. <xref rid="Fig3" ref-type="fig">3F</xref>, middle row). Ftr1, tagged with mScarlet, and Tcb2, tagged with mNeonGreen, localized to distinct regions of the cell periphery. Ftr1 localized specifically to the mother cell periphery but was absent from the bud, whereas Tcb2 was present at both the mother and daughter cell peripheries. Indeed, by visual inspection, we found that many of the <italic>CP-1</italic> proteins had apparent mother-specific localization, like Ftr1. In total, the <italic>CP-1</italic> group contains 21 proteins, and includes 7 of the 8 proteins found previously to localize asymmetrically to mother cells, all of which are members of the MDR (multidrug resistance) transporter family: Fui1, Hip1, Hnm1, Pdr5, Snq2, Tpo1, Yor1 (Decottignies et al, <xref ref-type="bibr" rid="CR9">1998</xref>; Eldakak et al, <xref ref-type="bibr" rid="CR14">2010</xref>).</p>
      <p id="Par39">In addition to the MDR transporters, the <italic>CP-1</italic> group contains 14 novel mother-specific proteins, including several other transporter proteins (Atr1, Ftr1, Hxt6, Mep1, Mep3, Qdr2, and Qdr3), proteins with roles in signaling (Gpa2, Mid2, Psr1), and three relatively uncharacterized proteins (Ybr016w, Ina1, and Crp1; Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>).</p>
      <p id="Par40">In a third example, we looked at colocalization of two proteins whose ORF-GFP fusions show some ER localization: Ubx2, a protein involved in ER-associated protein degradation from the <italic>ER-3</italic> sub-compartmental group (Neuber et al, <xref ref-type="bibr" rid="CR47">2005</xref>), and Kre1, a protein that normally functions as a cell wall glycoprotein from the <italic>ER-5</italic> group (Boone et al, <xref ref-type="bibr" rid="CR3">1990</xref>). The difference between these is more subtle: the <italic>ER-5</italic> protein, Kre1, shows an ER localization but also an increased concentration at the cell periphery compared to Ubx2 (Fig. <xref rid="Fig3" ref-type="fig">3F</xref>, bottom row). This localization difference was observed in other members of these sub-compartmental groups, with <italic>ER-3</italic> proteins tending to have a more diffuse localization and <italic>ER-5</italic> proteins localizing more to the cell periphery (Fig. <xref rid="Fig11" ref-type="fig">EV5</xref>).</p>
      <p id="Par41">In summary, our data show that within a compartment, PIFiA features can distinguish groups of proteins with subtle differences in localization that often have different biological roles. Many of these groups are enriched for proteins that perform biological functions not previously associated with distinctive localization patterns.</p>
    </sec>
    <sec id="Sec9">
      <title>Analysis of proteins with multi-compartment localization using PIFiA single-cell feature profiles</title>
      <p id="Par42">The single-cell feature profiles (scFPs) produced by the PIFiA CNN provide an opportunity to explore more nuanced protein behaviors, including proteins localizing across multiple compartments. Previous analyses of the yeast ORF-GFP collection showed that a large fraction of the proteome localizes to two or more compartments in the same cell (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). These studies used average statistics for cell populations, precluding differentiation of proteins that localize to multiple compartments, or those that shuttle between compartments. We annotated scFPs of every protein with localization categories using LR classification scores, and then we investigated the distribution of each protein’s single-cell localization scores, focusing on the two most probable localizations (see Methods). Using this strategy, we found that most (3424) proteins have a homogeneous localization (localizing to a single compartment), while 652 proteins exhibit localization heterogeneity (localizing to two or more compartments) (Fig. <xref rid="Fig4" ref-type="fig">4A</xref>). We classified the proteins with heterogeneous localization into two categories: (1) 396 proteins that localized to more than one compartment in a single cell, which we refer to as AND-proteins, and (2) 256 proteins that appeared either in a primary or a secondary location but not in the same cell, which we refer to as OR-proteins (Fig. <xref rid="Fig4" ref-type="fig">4B,C,D</xref>; Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>). For most proteins the assigned localization probabilities were continuously distributed, but our classification summarizes the localization, indicating the compartments that the protein predominantly populates. For example, Pho85 was classified as an AND-protein with a mixed signal predominantly from nucleus and cytoplasm within single cells, consistent with its known biology (Huang et al, <xref ref-type="bibr" rid="CR23">2007</xref>) (Fig. <xref rid="Fig4" ref-type="fig">4C</xref>). In contrast, Stb1 is a transcription factor whose nuclear localization is cell cycle regulated and it was classified by our analysis of scFPs as being either nuclear or cytoplasmic (OR-protein), as seen in previous studies (Youn et al, <xref ref-type="bibr" rid="CR66">2017</xref>) (Fig. <xref rid="Fig4" ref-type="fig">4C</xref>).<fig id="Fig4"><label>Figure 4</label><caption><title>Identification of proteins with morphological heterogeneity using PIFiA single-cell feature profiles (see also Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S2</xref>).</title><p>(<bold>A</bold>) Heatmap depicting ratios of cells falling into a mixed localization category, secondary and primary localization regions. Proteins with low ratios in all three columns (yellow color) feature many cells that fall into the low-confidence region. (<bold>B</bold>) Scatter plot showing two proteins with homogeneous localization patterns. Each point on the scatter plot corresponds to a single-cell crop, mapped to the probability of nuclear and cytoplasmic localization according to the LR predictions. (<bold>C</bold>) Scatter plot showing a protein with AND-type localization heterogeneity, Pho85, and one with OR-type localization heterogeneity, Stb1. (<bold>D</bold>) Schema of scoring proteins for localization heterogeneity using a single-cell level distribution of localization probabilities. Probabilities are obtained from primary and secondary localizations (i.e. first and second most probable localizations of the logistic regression classification of that protein). (<bold>E</bold>) Localization co-occurrence heatmap for 396 AND-localizing proteins, showing numbers of proteins present at two localizations. The scale bar is set to a maximum intensity of 50 to enable visualization of categories with fewer proteins. (<bold>F</bold>) Circle plot depicting localization patterns of 256 OR-type proteins. The thickness of the line connecting two localizations indicates the number of proteins showing localization heterogeneity between these localizations. (<bold>G</bold>) Localization heterogeneity related to cell cycle position for 136 proteins exhibiting statistically significant cell cycle variation. Connections indicate localizations of the proteins at specific cell cycle stages (thicker lines indicate a more common connection between a particular localization change and cell cycle stage transition). The color of the heatmap indicates the number of heterogeneous proteins that are present in the corresponding cell cycle phase for a particular localization.</p></caption><graphic xlink:href="44320_2024_29_Fig4_HTML" id="d33e1182"/></fig></p>
      <p id="Par43">We summarized overall AND-/OR-localizations across 15 localization categories, which clearly illustrated that a large fraction of these changes involved the nucleus and cytoplasm compartments. Among the 922 proteins with a high confidence nuclear localization, 708 were solely nuclear, 159 nuclear AND cytoplasmic, and 55 nuclear OR cytoplasmic (Fig. <xref rid="Fig4" ref-type="fig">4E,F</xref>). We asked how these classes were distributed in different bioprocesses involving the nucleus (Costanzo et al, <xref ref-type="bibr" rid="CR7">2016</xref>). As expected, proteins with roles in RNA processing and chromatin organization tended to be solely nuclear (Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>). The trends for proteins that have dual localization were also consistent with well-established biology. For example, proteins with roles in cell cycle progression were 4.1-fold enriched in nucleus OR cytoplasm (<italic>P</italic> = 6.7E−05). Many cell cycle proteins, in particular many transcription factors, use localization to regulate protein activity (Haase and Wittenberg, <xref ref-type="bibr" rid="CR19">2014</xref>). Proteins with roles in DNA replication/repair and stress response were weakly enriched in nucleus AND cytoplasm (1.5-fold, <italic>P</italic> = 1.40E−03 and 1.9-fold, <italic>P</italic> = 9.7E−04, respectively). DNA repair proteins often alter their relative localization in the presence of damage, either to initiate a repair response or to prevent catastrophic cell cycle events (Tkach et al, <xref ref-type="bibr" rid="CR61">2012</xref>). Because our cells were not experiencing DNA damage at the time of imaging, many of these proteins displayed both nuclear AND cytoplasmic localization in our data. Hence, while many protein groups that show different patterns were too small to perform consistent enrichment analysis, enrichments that were seen for nuclear-cytoplasmic groups, where there are enough proteins to assess, were consistent with known biology.</p>
      <p id="Par44">Finally, because proteins with roles in cell cycle progression were enriched among both the OR- and the AND-proteins, we used our scFPs to assess how cell cycle position could account for some of the protein localization heterogeneity. To do so, we took advantage of the nuclear and cytoplasmic markers (td-Tomato-NLS; E2-Crimson) in our GFP collection to explore the relationship between cell cycle position and protein abundance or localization heterogeneity. We first trained an ensemble of CNNs on the nuclear and cytoplasmic RFP channels to predict one of three cell cycle stages, and we subsequently mapped each single-cell crop to a cell cycle category: T/G1 (Telophase, Gap phase 1), S/G2 (DNA synthesis phase/Gap phase 2) or M/A (metaphase/anaphase) (see Methods). We then compared the single-cell distributions of each cell cycle stage with the localization calls to discover relationships between protein localization and cell cycle (Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S2</xref>). In total, we identified 136 proteins with cell-cycle-dependent variation in PIFiA feature profiles, determined by Mann–Whitney U test (McKnight and Najab, <xref ref-type="bibr" rid="CR41">2010</xref>) (<italic>p</italic>-value &lt; 1e−3, see Methods). Our results are summarized in the connected heatmap shown in Fig. <xref rid="Fig4" ref-type="fig">4G</xref>. As expected, some of the discovered localization changes reflected cell-cycle-dependent differences in the corresponding compartment. For example, most bud neck/cytoplasm AND-localizing proteins (14/23 proteins) were cytosolic in G1 before the bud neck had formed and localized to the bud neck later in the cell cycle (Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>). However, many cell cycle-regulated proteins moved between permanent compartments, including 66 moving between the nucleus and cytoplasm. Indeed, PIFiA identified 4 proteins not previously known to be cell cycle regulated, that localized to the cytoplasm and nucleus, but showed a predominantly cytoplasmic localization in M/A (Yel025c, Atc1, Bop3, and Cmg1).</p>
      <p id="Par45">Overall, scFPs derived from the self-supervised PIFiA workflow enable resolution of single-cell localization and are suitable for cell-to-cell variability analysis. Notably, PIFiA feature profiles contain enough functional information to distinguish compartments and sub-compartmental morphologies without pre-assigned labels, enabling analysis of protein localization heterogeneity in a data-driven way, which precludes propagating annotation errors.</p>
    </sec>
    <sec id="Sec10">
      <title>Prediction of functional modules using PIFiA single-cell feature profiles</title>
      <p id="Par46">We showed that protein-level feature profiles, or aFPs, can present a range of microscopy patterns in a compressed numerical form, which can be used for clustering and building hierarchical dendrograms. Using AMI scores at different correlation thresholds we were able to resolve functional information associated with hierarchical clustering of PIFiA aFPs (Fig. <xref rid="Fig2" ref-type="fig">2A</xref>) and determine an optimal correlation threshold for discovering functional modules, such as protein complexes (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1A</xref>). However, averaging feature profiles leads to information loss, which is not optimal for more precise analysis. Hence, we explored the use of single-cell feature profiles for the identification of functional modules. In particular, we focused on whether we could use scFPs for improved identification of protein complexes, which represent functional modules whose components are expected to colocalize within a single cell.</p>
      <p id="Par47">We derived our scFPs clustering analysis from a straightforward intuition—scFPs belonging to the same protein or the same protein complex should be indistinguishable, given the resolution limits of light microscopy. To visually illustrate this hypothesis on protein complex member distributions with scFPs, we projected scFPs from the test set using 2D tSNE (Fig. <xref rid="Fig5" ref-type="fig">5A</xref>). The scFPs of proteins from the same complex often localized together on the tSNE map, but different proteins from the same complex were typically intermingled and difficult to separate from each other. In contrast, the scFPs corresponding to different protein complexes with the same subcellular localization were often separated on the tSNE map (e.g., Polymerase-II, Polymerase-III, and RSC in the nucleus; EGO and V-ATPase in the vacuolar membrane) (Fig. <xref rid="Fig5" ref-type="fig">5A</xref>).<fig id="Fig5"><label>Figure 5</label><caption><title>Prediction of protein functional modules using PIFiA single-cell feature profiles (see also Dataset <xref rid="MOESM5" ref-type="media">EV4</xref>).</title><p>(<bold>A</bold>) Visualization of protein complex clusters on a single-cell tSNE plot of PIFiA feature profiles. The central plot shows a whole-proteome tSNE projection of PIFiA single-cell feature profiles (scFPs). Each point on the plot represents a protein that is colored according to 15 different subcellular localizations (color codes are explained below the plot). Zoom-in plots show a more detailed view of some regions of the global tSNE, showing single-cell features from the test set corresponding to proteins from the same complex with the same color palette, each protein shown in different color. (<bold>B</bold>) Dendrogram of clustered scFPs highlighting a region that identifies a nuclear pore cluster among nuclear periphery scFPs. The line graph on the right shows different numbers of proteins in a cluster at different correlation thresholds for clustering. Zoom-in plots of two clusters at different correlation thresholds (red and gray dashed lines) are shown as scFPs tSNE plots to the right. (<bold>C</bold>) Violin plot comparing the performance of four clustering approaches on 140 protein complexes. (<bold>D</bold>) Plot illustrating the fraction of proteins in each cluster with a protein–protein interaction annotated in the BioGrid (blue) or as protein complex member (yellow). Cluster numbers are sorted based on the number of discovered interactions.</p></caption><graphic xlink:href="44320_2024_29_Fig5_HTML" id="d33e1275"/></fig></p>
      <p id="Par48">To further explore the utility of scFPs for algorithmically identifying protein complexes, we developed a modified hierarchical clustering approach, called adaptive thresholding, that is designed to identify correlation thresholds on the hierarchical dendrogram at which scFPs inside a cluster become indistinguishable, and thus might be expected to contain interacting proteins (see Methods). We performed hierarchical clustering of test set scFPs using average linkage and a correlation metric. We then traced the number of unique proteins inside the cluster along with the divisions of the single-cell dendrogram to discover levels of the dendrogram at which the number of proteins in a cluster plateaus (Fig. <xref rid="Fig5" ref-type="fig">5B</xref>). Such plateaus identify levels of the global scFPs dendrogram at which single-cell features are practically inseparable, a division threshold that we call a root cluster (see Methods). For example, our adaptive thresholding method identified a root cluster corresponding to the nuclear pore complex, which distinguished it from other nuclear periphery proteins (Fig. <xref rid="Fig5" ref-type="fig">5B</xref>).</p>
      <p id="Par49">We compared the adaptive thresholding method to other clustering approaches from three different families—connectivity (hierarchical clustering (Murtagh and Contreras, <xref ref-type="bibr" rid="CR46">2012</xref>)), centroid (k-means (Sculley, <xref ref-type="bibr" rid="CR52">2010</xref>)) and density methods (DBSCAN (Ester et al, <xref ref-type="bibr" rid="CR15">1996</xref>)) (Fig. <xref rid="Fig5" ref-type="fig">5C</xref>). For each of the methods used in our comparison, we tried a range of hyperparameters and selected the ones that maximized median F1-score (see Methods). Evaluation was performed on a set of 140 protein complexes that contain at least three proteins included in the ORF-GFP localization dataset (Meldal et al, <xref ref-type="bibr" rid="CR43">2015</xref>). Our approach outperformed other methods in terms of four different scores—fold enrichment, F1 score, precision, and recall (Fig. <xref rid="Fig5" ref-type="fig">5C</xref>). The distributions of scores highlight the advantages of our adaptive thresholding approach. Density-based clustering fails at the protein complex identification task due to the high density of the feature space. At the same time, k-means fails at the identification of larger protein complexes (more than 5 protein members), hence its violin plot has two peaks. Hierarchical clustering is a more advantageous approach for this task, yet it requires information on the distance threshold and lacks adaptability for the protein complex size and cellular compartment. In contrast, our adaptive thresholding approach finds an optimal distance threshold for each cluster and, hence, it can discover protein complexes of varying sizes.</p>
      <p id="Par50">Using the adaptive thresholding clustering approach, we constructed a list of 88 high-confidence clusters whose proteins were indistinguishable at the single cell level (Dataset <xref rid="MOESM5" ref-type="media">EV4</xref>; Fig. <xref rid="Fig5" ref-type="fig">5D</xref>). We mapped each cluster to a protein complex with the maximal fold enrichment and saw a median fold enrichment of 36.5 across 88 clusters, which is a 3-fold improvement over our clustering of aFPs with an optimized cut-off (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). Of the 88 predicted clusters, 42 captured members of 32 different protein complexes distributed across 15 subcellular compartments (Dataset <xref rid="MOESM5" ref-type="media">EV4</xref>). The remaining clusters did not capture two or more members of the same protein complex, although in 25/45 cases they contained proteins with PPIs (as annotated in BioGrid (Stark et al, <xref ref-type="bibr" rid="CR57">2006</xref>)). By using proteins from the same localization as our background set to compute fold enrichment, we tested whether the clusters could differentiate a protein complex from others in the same subcellular location (see Methods). We discovered that PIFiA confidently predicted members of protein complexes in multiple compartments, such as: [1] the proteasome and Ada2/Gcn5/Ada3 transcription activation complex in the nucleus; [2] LSM2-7 complex, decapping complex, and translation initiation factor 2B complex in the cytoplasm; [3] the oligosaccharyl transferase and Sec62-Sec63 complexes in the ER; [4] vacuolar proton translocating ATPase complex, phosphatidylinositol 3-kinase complex and iron exporter complex in the vacuolar membrane; [5] F-actin capping protein complex and PAN1 actin cytoskeleton-regulatory complex in the actin cytoskeleton; [6] Spc105 complex and NDC80 complex in the spindle pole; [7] retromer complex and SNX4-SNX41 sorting nexin complex in endosomes (see Dataset <xref rid="MOESM5" ref-type="media">EV4</xref>).</p>
      <p id="Par51">In some cases (17/44), we identified all members of a complex, together with some additional proteins, which may be previously unappreciated complex components or members of an extended functional module, such as regulators or target proteins. For example, cluster #6 contained all 4 subunits of COMA, a kinetochore complex that connects proteins bound to centromeric DNA with those bound to microtubules, as well as nine additional proteins, eight of which display protein–protein interactions (PPIs) with COMA members (Stark et al, <xref ref-type="bibr" rid="CR57">2006</xref>). Other clusters identified proteins with the same biological role that may participate in PPIs. For example, cluster #39 contained 26 proteins that localized to the nuclear periphery in a punctate fashion. This group contained the only two GFP-tagged members of the TREX-2 complex, which couples SAGA-dependent gene expression and transcription elongation to mRNA export at the nuclear pore complex. Cluster #39 also included 8 proteins reported to have PPIs with members of the TREX complex (Stark et al, <xref ref-type="bibr" rid="CR57">2006</xref>), suggesting they may function in concert with the complex<sup>,</sup> Among the remaining proteins were members of a silencing complex, including Sir2, Sir3, Sir4 and the Sir4-interacting protein Esc1, which suppress transcription at subtelomeric regions, tethering them to the nuclear periphery (Deshpande et al, <xref ref-type="bibr" rid="CR11">2019</xref>). Thus cluster #39 identified proteins with roles in gene expression that localize to the nuclear periphery, some of which function to modulate each other’s activity.</p>
      <p id="Par52">To provide some context into the limitations of the method, we looked at what types of protein complexes were under-represented in our set of high-confidence predictions. Identification by PIFiA was independent of protein abundance or number of members in the complex. The protein complexes we identified were enriched for localizations in small organelles and compartments (peroxisome, actin, nuclear periphery, endosome, spindle pole) and depleted for those in large diffuse compartments such as nucleus and cytoplasm. We note that not all protein complexes will have a distinct localization. Using PIFiA features we have identified protein complexes from most compartments in the cell.</p>
      <p id="Par53">In summary, we have developed a novel approach for discovery of functional modules using solely the self-supervised feature profiles and leveraging the properties of microscopy data for optimal clustering, and prediction of molecular interactions.</p>
    </sec>
    <sec id="Sec11">
      <title>Interpretation of PIFiA features</title>
      <p id="Par54">Our analysis shows that PIFiA feature profiles contain condensed information about protein function at various levels of granularity. However, since deep neural networks function as ‘black-box’ models, it is difficult to dissect feature profiles and explain how individual features are related to the input images. To attempt to interpret PIFiA features, we first quantified feature importance for 15 different localization categories covering a diverse set of subcellular morphological patterns. We used the LR model described earlier to derive importance scores for each feature; the coefficients of the trained LR quantify how much each feature is predictive of a certain localization (Fig. <xref rid="Fig6" ref-type="fig">6A</xref>). Most localizations had more than three strongly predictive features (LR coefficient value &gt; 5), suggesting that PIFiA learns to detect several distinctive patterns for each subcellular compartment. This confirms that PIFiA learns localization patterns with its convolutional filters, despite being trained on a completely different self-supervised objective. Also, the same feature could be predictive for several localizations (for example, features #3 and #28 recognize circular patterns corresponding to the vacuolar membrane and nuclear periphery), or react to some variation of visual patterns present in multiple localizations. Overall, larger and more complex compartments required more features to be confidently classified. To illustrate this finding, we plotted classification accuracy for the three largest compartments (cytoplasm, nucleus, and mitochondria), as well as three homogeneous compartments (nucleolus, peroxisome, and vacuolar membrane) with respect to the number of features used during LR training (see Methods) (Fig. <xref rid="Fig6" ref-type="fig">6B,C</xref>; Appendix Fig <xref rid="MOESM1" ref-type="media">S3A</xref>). While larger localization categories required approximately 30 features to reach their best performance, smaller localizations reached a saturation point at around 10 features.<fig id="Fig6"><label>Figure 6</label><caption><title>Interpretation of PIFiA features (see also Appendix Fig. <xref rid="MOESM1" ref-type="media">S3</xref>).</title><p>(<bold>A</bold>) Heatmap of the logistic regression coefficients for localization prediction associated with each feature. Each feature was mapped to a localization (based on the maximal coefficient value), and features were sorted in descending order of coefficients. (<bold>B</bold>) Plot of classification accuracy dependence on number of features used to train the logistic regression for the three largest and most complex localizations: nucleus, cytoplasm and mitochondria. (<bold>C</bold>) Plot of classification accuracy dependence on number of features, showing three smaller and more homogeneous localizations: nucleolus, peroxisome and vacuolar membrane. Shading shows standard deviation across 5 runs. (<bold>D</bold>) Gradient maps highlighting regions of the input image that CNN “pays attention to”. Proteins from six distinct subcellular compartments are shown with their most visually distinct gradient maps with the highest activation values.</p></caption><graphic xlink:href="44320_2024_29_Fig6_HTML" id="d33e1380"/></fig></p>
      <p id="Par55">Another way to interpret features learned by a CNN is to find regions of the image that had a large influence on the final result (Selvaraju et al, <xref ref-type="bibr" rid="CR53">2016</xref>; Zeiler and Fergus, <xref ref-type="bibr" rid="CR68">2014</xref>). Using gradient calculations, importance scores can be assigned to the input image pixels depending on the degree to which they affect the classification result or individual feature values (see Methods). We used the SmoothGrad approach (Smilkov et al, <xref ref-type="bibr" rid="CR55">2017</xref>; Zeiler and Fergus, <xref ref-type="bibr" rid="CR68">2014</xref>) to construct gradient maps for several features of the same protein image. We selected proteins representing five distinct subcellular localizations: Nup2 from nuclear periphery, Mcm2 from nucleus, Scs2 from ER, Ftr1, and Pst2 from cell periphery, and Pex3 from peroxisome. For each of the proteins, we used its scFPs to calculate 64 gradient maps for each of the individual features and selected four visually distinct gradient maps with the highest activation values for illustration purposes (Fig. <xref rid="Fig6" ref-type="fig">6D</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S3B</xref>).</p>
      <p id="Par56">We observed that different features of the same image resulted in different gradient maps. While regions with higher intensity often have higher gradient values (unless they are not meaningful for the training objective), the interesting observation here is which part of these regions are meaningful for the particular feature. For example, the last gradient map of Pex3-GFP protein shows punctate localization patterns with three distinct punctae. Interestingly, different features react to different parts of the image—feature 4 reacts to the lower dot on the image and feature 23 reacts to two other dots. Also, gradient maps of the Mcm2 protein highlighted the nuclear periphery region, focus points in the nucleus and nuclear background signal. Similarly, different features of Ftr1 reacted to various subregions of the cell periphery. Of note, the generated gradient maps showed that the region of network attention was always the single central cell of the crop even for crops containing more than one cell, confirming that per-crop feature profiles are in fact single-cell profiles (Fig. <xref rid="Fig6" ref-type="fig">6D</xref>, with Mcm2, Ftr1 and Pst2 proteins containing multiple cells in their crop, Appendix Fig. <xref rid="MOESM1" ref-type="media">S3B</xref>). Gradient-based interpretability approaches are useful to explain the relationship between individual features in the feature profile vector and input pixels in the image, and they constitute an important component of our downstream analysis pipeline. Hence, despite PIFiA’s self-supervised training objective, we can visually understand what each learned feature represents in terms of the input image regions.</p>
    </sec>
  </sec>
  <sec id="Sec12" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par57">We describe PIFiA, a self-supervised computational workflow that learns protein functional signatures from single-cell fluorescence microscopy data. Feature profiles learned by PIFiA show state-of-the-art performance on a variety of biological functional benchmarks, outperforming existing approaches for protein representation learning. Notably, our approach does not require any labels or annotations during training and uses only a single fluorescent channel. Hence, PIFiA can be easily applied to virtually any imaging dataset. We pre-trained PIFiA on a large-scale dataset encompassing over three million single-cell images of yeast cells expressing 4049 GFP-fusion proteins—a scale comparable to that of the commonly used computer vision dataset, ImageNet (Deng et al, <xref ref-type="bibr" rid="CR10">2009</xref>). As with ImageNet, we show that the yeast ORF-GFP dataset is a source for high-quality representation learning, enabling PIFiA to learn universal feature profiles that can be used out-of-the-box or minimally fine-tuned to suit an external standard. Thus, PIFiA can accelerate the rate of supervised training on external tasks by producing feature profiles that can fit any downstream task with simple linear regression, replacing multiple task-specific convolutional networks.</p>
    <p id="Par58">The PIFiA workflow unites a self-supervised convolutional neural network with multiple techniques for downstream feature profile analysis. The key advantage of our self-supervised objective is its independence of human annotations and its ability to learn high-quality features and ignore imaging artifacts and cell positions (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>; Razdaibiedina et al, <xref ref-type="bibr" rid="CR49">2019</xref>; Sullivan et al, <xref ref-type="bibr" rid="CR58">2018</xref>).To ensure that PIFiA remembers solely the biologically relevant patterns, yet ignores cell positioning and replicate noise, we require the network to learn the actual GFP-tagged protein by predicting its identity. Overall, we show that features learned by PIFiA outperform another self-supervised method, Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>), that was used to analyze the yeast GFP collection and even reaches the performance of the supervised approach, DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>), in its target task.</p>
    <p id="Par59">We describe downstream analysis techniques that use PIFiA feature profiles to explore different levels of subcellular organization that span both protein-level and single-cell feature profiles. Of note, our analysis focuses not only on the construction of a whole-proteome hierarchical map, but also provides quantitative rules to obtain clusters corresponding to a specific level of cellular organization, such as subcellular localization or biological process, and to identify proteins with multiple localizations and interacting proteins. This type of unbiased analysis can reveal unexpected properties and potential functions of proteins that can be further explored experimentally. For example, we used PIFiA features taken from images of yeast cells expressing GFP-tagged proteins to identify sub-compartmental groups enriched for proteins with biological processes not previously known to have distinctive subcellular localization patterns (Fig. <xref rid="Fig3" ref-type="fig">3E,F</xref>). We found that in addition to the known pan-nuclear localization, proteasome components are also localized at the nuclear periphery, a result we confirmed with co-localization experiments (Fig. <xref rid="Fig11" ref-type="fig">EV5</xref>). Nuclear periphery localization of proteasomes has not been reported in yeast, but an in situ cryo-electron tomography study in <italic>Chlamydomonas</italic> found nuclear 26S proteasomes crowding around nuclear pore complexes (Albert et al, <xref ref-type="bibr" rid="CR2">2017</xref>). The role of proteasomes at the nuclear periphery may be to regulate transcription and/or to degrade proteins transiting the nuclear pore complex (Albert et al, <xref ref-type="bibr" rid="CR2">2017</xref>).</p>
    <p id="Par60">We also identified a group of proteins that localized specifically at the cell periphery of mother cells and were depleted from the growing bud. Budding yeast divide asymmetrically, with a replicative lifespan of 20–30 generations, where each division gives rise to a daughter whose replicative lifespan is reset and a mother who continues to age (He et al, <xref ref-type="bibr" rid="CR21">2018</xref>). Mother-specific cell periphery localization is achieved when three conditions are fulfilled (Eldakak et al, <xref ref-type="bibr" rid="CR14">2010</xref>). First, mother-specific proteins lack diffusive mobility in the plasma membrane. Second, newly synthesized proteins are deposited specifically in the growing bud. Third, the genes encoding these mother-specific proteins are expressed late in the cell cycle, so for cells in S/G<sub>2</sub> (small-budded cells) protein is detectable only in the mother. These steps ensure that the new and old pools of these proteins become spatially segregated during asymmetric division. Indeed, mother-specific localization of cell periphery proteins has been proposed to play a role in aging, with the daughter cell getting the newly synthesized copies of the protein, and the older and potentially more damaged copies inherited by the aging mother (Eldakak et al, <xref ref-type="bibr" rid="CR14">2010</xref>). Our set of asymmetrically segregating proteins includes 7 proteins previously seen to have mother-specific localization, plus 14 novel mother-specific proteins, including other transporters, proteins with roles in signaling, and 3 uncharacterized cell surface proteins (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). It is possible that accumulation of old and damaged versions of these newly identified proteins may also play a role in mother-specific aging.</p>
    <p id="Par61">We also applied PIFiA features for the identification of interacting proteins and members of protein complexes. To accomplish this, we used an adaptive thresholding method for single-cell clustering that exploits the biological properties of protein–protein interactions and microscopy data, outperforming conventional clustering methods for identifying members of protein complexes. We show that proteins whose single-cell PIFiA features are indistinguishable can be members of the same protein complex, have PPIs with each other, or have functionally related biological roles. A similar approach, <italic>cytoself</italic> (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>), was used to visually separate protein complexes from different compartments in human cells. Like the PIFiA pipeline, its self-supervised training scheme requires no pre-existing knowledge or categories, allowing it to reveal a highly resolved protein subcellular localization atlas that summarizes the major scales of cell organization (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>). Both the <italic>cytoself</italic> study and our work validate image-based feature profiles for downstream studies of protein organization and function in eukaryotic cells, both yeast (this work) and human cells (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>). Notably, we demonstrate that PIFiA can distinguish protein complexes from the same compartment in yeast cells, which are 5 to 30-fold smaller in size than human cells, providing a quantitative approach for downstream analysis and identification of functionally related proteins. Another study has implemented a similar representation learning paradigm to learn feature profiles of the images of cells with chemical or genetic perturbations (Moshkov et al, <xref ref-type="bibr" rid="CR45">2024</xref>) where perturbations were used as training labels. Thus, perturbation phenotypes were learned as inner representations from the network, suggesting that such a training scheme is effective for various types of experiments and biological systems.</p>
    <p id="Par62">In summary, the PiFiA pipeline extracts high-quality functional information about proteins from cell images in a quantitative form, without relying on pre-existing labels or manual annotations. In essence, the approach performs in silico colocalization, when two or more biological entities, such as proteins, are analyzed for similarity based on their respective localization patterns or positions within a cell (Dunn et al, <xref ref-type="bibr" rid="CR13">2011</xref>). In contrast to experimental colocalization, which is time-consuming and expensive, in silico colocalization can be performed within seconds for multiple proteins at a time. In the case of PIFiA, this can be achieved not only with high speed but also with remarkable precision. Overall, PIFiA can be used to identify properties of proteins in single cells, including similarity and variability, that have the potential to inspire new experiments to uncover novel biological insights.</p>
  </sec>
  <sec id="Sec13">
    <title>Methods</title>
    <sec id="Sec14">
      <title>Construction of mutant arrays for imaging</title>
      <p id="Par63">For imaging screens, BY5299 (<italic>MAT</italic>α <italic>his3Δ1 leu2Δ0 ura3Δ0 met15Δ0</italic> lyp1pr::TDH3pr-E2-Crimson::HPH::<italic>lyp1</italic>Δ <italic>can1</italic>pr::TDH3pr-tdTomato-NLS::<italic>URA3</italic>::<italic>can1</italic>Δ::STE2pr-<italic>LEU2)</italic> was used as the starting query strain. E2-Crimson and td-Tomato-NLS are used as cytosolic and nuclear markers, respectively. The starting strain was crossed to the <italic>MAT</italic>a ORF-GFP (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>) and haploid strains carrying both the red fluorescent protein markers and the ORF-GFP were selected using the SGA method (Tong and Boone, <xref ref-type="bibr" rid="CR62">2006</xref>). All SGA selection steps were conducted at 30 °C, except sporulation, which was conducted at 22 °C for 10 days. The screen was performed in two biological replicates. We successfully constructed strains with 4049 (97.4%) GFP-tagged genes out of 4156 strains in the ORF-GFP collection. The missing GFP strains include those in linkage groups for <italic>CAN1</italic> and <italic>LYP1</italic>, as occurs in all SGA-derived collections. Other missing strains were those we were unable to grow from our original stocks. The missing strains had no bias for protein abundance (Ho et al, <xref ref-type="bibr" rid="CR22">2018</xref>). By GO cellular component, they were enriched for mitochondrial <italic>cytochrome complex</italic> (6 genes; Bonferroni corrected <italic>P</italic> value = 0.000368).</p>
    </sec>
    <sec id="Sec15">
      <title>High-throughput microscopy</title>
      <p id="Par64">Yeast cultures were prepared for microscopy and imaged as previously described (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Cox et al, <xref ref-type="bibr" rid="CR8">2016</xref>; Mattiazzi Usaj et al, <xref ref-type="bibr" rid="CR39">2020</xref>). Briefly, haploid wild-type <italic>MAT</italic>a strains expressing fluorescent protein fusions from SGA final selection plates were grown at 30 °C in low fluorescence synthetic minimal medium with Geneticin (200 μg/mL) and Noursoethricin (100 μg/ml). Cells were transferred to 384-well PerkinElmer CellCarrier Ultra imaging plates and centrifuged for 1 min at 500 g before imaging. Micrographs were obtained on an Opera Phenix (PerkinElmer) automated spinning disc confocal microscope. All imaging was done with a 63× water immersion objective. GFP was excited using a 488 nm laser and emission collected through a 520/35 nm filter. tdTomato was excited using a 561 nm laser, and emission collected through a 600/40 nm filter. E2Crimson was excited using a 640 nm laser, and emission collected through a 690/50 nm filter.</p>
    </sec>
    <sec id="Sec16">
      <title>Image acquisition for co-localization experiments</title>
      <p id="Par65">Protein pairs were chosen for co-localization if they had similar abundance (Ho et al, <xref ref-type="bibr" rid="CR22">2018</xref>) and localized to the same general subcellular compartment. For each protein, C-terminal fusions to both mNeonGreen and mScarlet were constructed as previously described (Meurer et al, <xref ref-type="bibr" rid="CR44">2018</xref>). Haploid cells in both configurations were mated to construct a/α diploids containing proteins tagged with the two fluorescent proteins. Diploid cells were grown and imaged in low fluorescence synthetic minimal media (Sheff and Thorn, <xref ref-type="bibr" rid="CR54">2004</xref>) supplemented with Hygromycin B (300 mg/mL), Geneticin (200 mg/mL), and 2% glucose. Cells were grown at 30 °C to mid-logarithmic phase and transferred to Concanavalin A-coated 384-well PerkinElmer CellCarrier Ultra imaging plates. Images were acquired at 22 °C using the Opera Phenix (PerkinElmer) automated spinning disc confocal microscope. Three image fields of 5 Z-stacks of optical sections 0.7 µm apart were taken for each well. Each field contained 100–150 cells, acquired using the 63× water immersion objective. mNeonGreen was excited using the 488 nM laser, with emissions collected through a 520/35 nm filter. mScarlet-I was excited using the 561 nm laser, with emissions collected through a 600/40 nm filter. Digital Phase Contrast was used for cell detection using LED bright field imaging. All images were assessed by visual inspection.</p>
    </sec>
    <sec id="Sec17">
      <title>Dataset overview and image preprocessing</title>
      <p id="Par66">Images of the 4049 strains expressing a GFP-tagged protein visible above background fluorescence were obtained using an automated confocal microscope as described above. Cell images were obtained from two biological replicates, each of which had four fields of view for each GFP-tagged strain.</p>
      <p id="Par67">As the first step of preprocessing, we computed cell centers’ coordinates across all images in the dataset using the nuclear channel. We obtained coordinates of the cells’ centers by segmenting the nuclear channel with a simple Watershed algorithm and computing <italic>x</italic>, <italic>y</italic> coordinates of the center of each cell’s nucleus (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>). We ignored cells with centers too close to the crop’s boundary (less than 10 pixels). Based on the cell center coordinates, we created single-cell crops of 64 × 64 pixels around those centers across all images in the dataset. We filtered crops that had GFP signal intensity less than the 5th percentile of the whole-proteome GFP intensity distribution, and crops dominated by the background noise (i.e., a uniform signal across the whole crop, with variance). After filtering low-quality crops, we dropped proteins with less than 10 cells, and we obtained 3,058,961 unique cells in the dataset. Then, the dataset was split into training, validation, and test sets using 80%, 10%, and 10% of the cells of each protein, respectively. The training subset contained 2,450,801 single-cell crops, and validation and test subsets contained 304,080 single-cell crops each. Finally, we applied instance normalization by standardizing the raw pixel intensities of every crop to a mean of 0 and a variance of 1 (independently for each channel of each sample). PIFiA was trained on 64 × 64 pixel crops of the GFP channel. During training, we used random flipping (horizontal and vertical) and random rotation across (0, 90, 180, 270) degrees to augment the training data. Labels of the training set are one-hot class vectors of length 4049.</p>
    </sec>
    <sec id="Sec18">
      <title>Architecture and training</title>
      <p id="Par68">The architecture details are illustrated in Fig. <xref rid="MOESM1" ref-type="media">S1A</xref>. The backbone of PIFiA consists of eight convolutional blocks followed by three fully-connected layers. Each convolutional block consists of a convolutional layer, batch normalization and rectified linear unit activation. Training was performed using Adam optimizer (Kingma and Ba, <xref ref-type="bibr" rid="CR30">2014</xref>) with a learning rate of 1e−3 and cosine decay learning rate schedule (number of steps equal to the number of training updates during 30 epochs), with cross-entropy as an objective function (<italic>y</italic><sub><italic>i</italic></sub> and <italic>ŷ</italic><sub><italic>i</italic></sub> are predicted probability and ground truth label of the protein <italic>i</italic>; <italic>N</italic> is the total number of classes, i.e.,4049 proteins):<disp-formula id="Equ1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L({\hat{{y}}}_{{i}},{y}_{i})=-{\sum }_{i=1}^{N}{y}_{i}\,\log {\hat{y}}_{i}$$\end{document}</tex-math><mml:math id="M2"><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mi>log</mml:mi><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><graphic xlink:href="44320_2024_29_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par69">To prevent overfitting, we applied dropout regularization (Srivastava et al, <xref ref-type="bibr" rid="CR56">2014</xref>) of 0.05 (5% dropout rate) after the second fully-connected layer (feature extraction layer). We performed hyperparameter optimization and selected the learning rate from {1e−4, 3e−4, 5e−4, 8e−4, 1e−3, 3e−3, 5e−3} and dropout rate from {0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5} based on maximal validation accuracy. Network parameters were initialized using a truncated normal distribution function with a standard deviation of 0.1. To report the performance, we ran the model three times with different random weights initializations; each run was 30 epochs and model weights were saved after every epoch. All the experiments were performed in Python using Tensorflow. The model was trained on the computing cluster of the Vector Institute for Artificial Intelligence, using NVIDIA T4 GPU with 12GB of VRAM, and up to 32GB of system RAM (single CPU). Source code and usage examples are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/arazd/pifia">https://github.com/arazd/pifia</ext-link>.</p>
      <p id="Par70">We used early stopping to select the final model (Girosi et al, <xref ref-type="bibr" rid="CR16">1995</xref>). We defined stopping criteria based on the model’s test accuracy of proteins classification across 4049 protein classes. We stop at an epoch where a derivative of the test accuracy becomes smaller than a threshold of 0.5% for at least 3 epochs, i.e., a point at which accuracy starts to saturate (Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>). Our goal was to stop at the point when the model has already grasped the most important morphological patterns, yet highly related and interacting proteins are not distinguished from each other. This trend is further illustrated by plots of average precision, F-score and precision (we show 0.9 threshold) for protein complexes and pathways standards (Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>). With protein prediction accuracy increasing over the course of training, the precision improved, but after some epochs, AP and F-score either saturated or started to decline. We found that accuracy saturation thresholds between 0.2% and 0.7% yielded comparable and optimal solutions, though other stopping points can be used depending on the training schedule, as well as model applications and goals. The proposed early stopping strategy helped to prevent memorizing noise and unnecessary patterns, while retaining morphologically similar proteins close in the feature space.</p>
    </sec>
    <sec id="Sec19">
      <title>Benchmarking and baseline feature extraction</title>
      <p id="Par71">We compared performance of feature profiles learned by PIFiA to features from three other popular methods for protein representation learning/extraction—DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>), Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>), and CellProfiler (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>).</p>
      <p id="Par72">A classic modular feature extraction tool, Cell Profiler (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>), was applied to the GFP and cytoplasmic channels of the test images across 4049 GFP-tagged proteins. We obtained 433 pre-defined CellProfiler features that quantitatively measure cellular phenotypes, including intensity, shape, and texture. Since some of the CellProfiler features can be repetitive, its representations are often post-processed with Principal Component Analysis (PCA) (Abdi and Williams, <xref ref-type="bibr" rid="CR1">2010</xref>). In our work, we evaluated both the original CellProfiler representation with 433 individual features, and its PCA projection (37 individual features) that explains 99% of the variance.</p>
      <p id="Par73">We used the DeepLoc model by Kraus et al, (<xref ref-type="bibr" rid="CR36">2017</xref>) as our supervised learning baseline. We investigated two training modes: (a) with per-protein localization labels from Huh et al, (<xref ref-type="bibr" rid="CR25">2003</xref>); (b) with single-cell localization labels manually annotated in our lab. Per-protein annotations can sometimes be subjective and might not capture the nuances of protein localization at a single-cell level accurately. Such annotations apply to all of single-cell images of a protein and are available for a significant part of the yeast proteome from the Huh et al, study (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). In contrast, single-cell labels were manually annotated for the individual cell images by research scientists in our lab. While more precise, such labels are expensive and encompass a much smaller portion of the proteome. The original DeepLoc version uses single-cell labels. For a fair comparison, we used both single-cell and protein-level localization labels to train DeepLoc and reported the corresponding results.</p>
      <p id="Par74">Hence, we used two model variants: (a) the original version of DeepLoc (which was trained on a set of 21,882 single-cell crops with manually assigned labels; pre-trained weights provided by Kraus et al, (<xref ref-type="bibr" rid="CR36">2017</xref>), and (b) our adaptation of DeepLoc, DeepLoc+PIFiA, which was re-trained on a larger set of 1,432,774 images with less accurate protein-level labels instead of expensive yet more precise single-cell labels.</p>
      <p id="Par75">We trained DeepLoc+PIFiA from scratch on the GFP channel of the same training set images using 1,432,774 single-cell crops from 15 one-hot localization categories derived from Huh et al, (<xref ref-type="bibr" rid="CR25">2003</xref>). We performed hyperparameter optimization and selected the most optimal learning rate from {1e−4, 3e−4, 5e−4, 8e−4, 1e−3, 3e−3, 5e−3} and dropout rate from {0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5}. We chose 3e−4 learning rate with cosine decay learning rate schedule and 0.05 dropout rate based on maximal validation accuracy. The model was trained with Adam optimizer for 30 epochs (model weights were saved every epoch for subsequent evaluation), with cross-entropy as an objective function, <italic>y</italic><sub><italic>i</italic></sub>, <italic>ŷ</italic><sub><italic>i</italic></sub> are predicted probability and ground truth label of localization <italic>i</italic>, total <italic>N</italic> = 15 localization classes):<disp-formula id="Equ2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L({\hat{y}}_{i},\,{y}_{i})=-{\sum }_{i=1}^{N}{y}_{i}\log {\hat{y}}_{i}$$\end{document}</tex-math><mml:math id="M4"><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><graphic xlink:href="44320_2024_29_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par76">We also used early stopping to select the final DeepLoc+PIFiA model weights. DeepLoc+PIFiA model selection was based on maximal validation set accuracy. Network parameters were initialized using a truncated normal distribution function with a standard deviation of 0.1. We performed 3 runs with different random weights initializations and performed training with a batch size of 128. After training, we extracted features of the test set images from the last hidden layer of the DeepLoc+PIFiA model following previous studies (Razdaibiedina and Brechalov, <xref ref-type="bibr" rid="CR48">2022</xref>).</p>
      <p id="Par77">For our self-supervised learning baseline, we used the Paired Cell Inpainting method (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>). Contrary to other models, Paired Cell Inpainting requires two channels for training—cytoplasmic background and target protein; hence we performed training of Paired Cell Inpainting using the GFP and cytoplasmic channels of the test images across 4049 GFP-tagged proteins. We used the exact same architecture and training objective described by Lu et al, (<xref ref-type="bibr" rid="CR38">2019</xref>). The objective function minimizes a standard pixel-wise mean-squared error loss between the predicted target protein <italic>ŝ</italic><sub><italic>t</italic></sub> and the actual target protein <italic>s</italic><sub><italic>t</italic></sub> (<italic>h</italic> and <italic>w</italic> are pixels across image width and height, respectively):<disp-formula id="Equ3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L({\hat{s}}_{t},\,{s}_{t})=\frac{1}{h\cdot w}{({\hat{s}}_{h,w,t}-{s}_{h,w,t})}^{2}$$\end{document}</tex-math><mml:math id="M6"><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>⋅</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><graphic xlink:href="44320_2024_29_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par78">We performed hyperparameter optimization and selected an optimal learning rate of 1e−4 from {1e−4, 3e−4, 5e−4, 8e−4, 1e−3, 3e−3, 5e−3}. The Model was trained with Adam optimizer for 30 epochs (3 runs in total), and model weights were saved every epoch for subsequent evaluation. We selected the final model with early stopping based on the minimal validation set loss. After training, we extracted feature profiles of the test set images by maximum pooling the output of an intermediate convolutional layer, across spatial dimensions, as suggested by Lu et al, (<xref ref-type="bibr" rid="CR38">2019</xref>).</p>
    </sec>
    <sec id="Sec20">
      <title>Evaluation of aFPs</title>
      <p id="Par79">Functional benchmarks used for assessment of the quality of the resulting feature profiles were derived from Gene Ontology Cellular Component (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>) (4045 protein annotations), Gene Ontology Slim Biological Process (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>) (3968 protein annotations), KEGG pathways (Kanehisa and Goto, <xref ref-type="bibr" rid="CR29">2000</xref>) (1422 protein annotations) and EMBL protein complexes (Meldal et al, <xref ref-type="bibr" rid="CR43">2015</xref>) (1402 protein annotations). Dubious ORFs and proteins without annotations were left out during comparison. To evaluate resulting features without further fine-tuning, we used strategies from two distinct perspectives: information retrieval and clustering quality.</p>
      <p id="Par80">Following standard practice, we computed pairwise distances across all available aFPs (4049 × 4049 distances in total) and sorted them from highest to lowest. Then protein pairs (which were not left out) were marked as positive if they had the same annotations, or negative otherwise, and AP and F-scores were computed. For proteins to be considered a positive pair, we required an exact agreement between labels in case of pathways and protein complexes standards, while for GO annotations we required at least 50% of the labels to overlap (due to high quantity of assigned labels). Results reported in Fig. <xref rid="Fig2" ref-type="fig">2B,C</xref> are based on ranking aFP pairs with correlation distance, and we found similar trends when using euclidean and cosine distances. We chose to continue analyses with the correlation metric due its lower susceptibility to fluctuations in individual feature values, and hence higher tolerance to outliers, which is a desirable property for the PIFiA workflow. For the clustering-driven benchmark, we clustered aFPs and compared clusters to the sets of proteins annotated to a certain term, and for each standard (we required cluster size to be at least 2 to be informative). For comparison, we applied AMI score (Vinh et al, <xref ref-type="bibr" rid="CR65">2010</xref>) between the resulting clusters and protein groups related to a certain term (with a higher score indicating more agreement between clusters and standard-defined categories). To obtain an AMI score for each method, we performed hierarchical clustering (with average linkage and correlation as a distance) of its per-protein representations and derived clusters across all similarity thresholds between 0.1 and 0.95 with a step of 0.05, and reported the maximal AMI across clusterings. For each deep learning model, feature profile evaluation was performed across 3 runs (results shown with bar plots in Fig. <xref rid="Fig2" ref-type="fig">2</xref>).</p>
    </sec>
    <sec id="Sec21">
      <title>Visualization of PIFiA feature profiles (aFPs and scFPs)</title>
      <p id="Par81">We used t-SNE (Van der Maaten and Hinton, <xref ref-type="bibr" rid="CR64">2008</xref>) for visualization of PIFiA feature profiles. We set the perplexity parameter to 40 for visualization of whole-proteome feature profiles averaged on the per-protein level (~4000 points) (Fig. <xref rid="Fig3" ref-type="fig">3C,D,F</xref>), and to 200 for visualizing single-cell feature profiles from the test set (&gt;100,000 points) (Fig. <xref rid="Fig5" ref-type="fig">5A</xref>). We represented the distribution of fundamental GO bioprocesses with a kernel-density estimate (KDE) using Gaussian kernels (Fig. <xref rid="Fig3" ref-type="fig">3D</xref>). We applied outlier filtering by removing points that do not lie within two standard deviations from the mean (across <italic>x</italic> or <italic>y</italic> t-SNE coordinates). We used Scott’s rule for KDE bandwidth selection (Scott, <xref ref-type="bibr" rid="CR51">1979</xref>).</p>
    </sec>
    <sec id="Sec22">
      <title>Hierarchical clustering with aFPs</title>
      <p id="Par82">We performed agglomerative hierarchical clustering (Murtagh and Contreras, <xref ref-type="bibr" rid="CR46">2012</xref>) of the whole-proteome aFPs (4049 in total) using correlation as a distance metric and average linkage. The optimal cut-off distance for the whole-proteome hierarchical clustering was determined using the AMI curve between clustering labels and provided standard annotations, following the diminishing returns principle to find the elbow point. At the optimal distance cutoff, the slope of the curve becomes negligible, indicating that the available clusters cover most of the standard’s functional groups. In Fig. <xref rid="Fig3" ref-type="fig">3</xref> we used GO Cellular Component annotations (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>) as a standard and calculated clustering labels at different correlation thresholds between 0 and 1, with a step of 0.01. Clustering was performed on the whole-proteome feature profiles, and AMI scores were calculated on a subset of proteins that had a single annotation according to GO Cellular Component. We identified an optimal cut-off point when the derivative of the AMI curve (calculated over 20 steps, starting at correlation of 1) was less than a threshold of 0.1. The proposed strategy can be used on different standards, without requiring annotations to cover all proteins (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1A</xref>).</p>
    </sec>
    <sec id="Sec23">
      <title>Training logistic regression</title>
      <p id="Par83">To perform localization mapping, we trained a multinomial logistic regression (LR) using single-cell feature profiles obtained with PIFiA from the training set. We used supervised labels from 17 manually annotated localizations defined by Huh et al, (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>) (we left out “ambiguous” category and classes with 5 or less proteins), and limited our training set to proteins that had a single annotated localization. Overall, our training set consisted of 1,432,774 single-cell feature profiles and included 2415 proteins from mitochondrion (465), nucleus (472), cytoplasm (799), actin (27), ER (245), vacuole (95), bud neck (8), spindle pole (35), Golgi (15), peroxisome (20), vacuolar membrane (47), cell periphery (51), nuclear periphery (45), endosome (28), and nucleolus (63). We followed our previously described dataset split (each protein’s single-cell crops were split into train, validation, and test sets with 8:1:1 ratios). We used NVIDIA T4 GPU with 12GB of VRAM, and up to 16GB of system RAM on a single CPU to accelerate training; we trained LR for 5 epochs using Adam optimizer (Kingma and Ba, <xref ref-type="bibr" rid="CR30">2014</xref>) (1e−3 learning rate) and cross-entropy as a training loss; LR weights were saved after every epoch and we selected the final LR model with early stopping based on maximal validation set accuracy. Of note, after 2 epochs LR predictions stabilized and the difference between subsequent models was minimal (less than 3% test accuracy deviations).</p>
      <p id="Par84">To evaluate the quality of LR predictions, we compared its test set performance with DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>) (training procedure described in the benchmarking section). DeepLoc and LR were trained and evaluated on the sets of the same size and protein composition, with the only difference being DeepLoc used image crops for training, while LR using self-supervised scFPs from the pre-trained PIFiA model. Precision-recall curves for PIFiA LR and DeepLoc were generated on unseen scFPs and corresponding images from the test set of the single-localizing proteins (Fig. <xref rid="Fig8" ref-type="fig">EV2B</xref>).</p>
    </sec>
    <sec id="Sec24">
      <title>Sub-compartmental clustering with aFPs</title>
      <p id="Par85">We performed sub-compartmental clustering using single-localizing aFPs from the test set that were classified to the same localization by the previously described LR. For an aFP to be single-localizing, we required that its highest softmax probability was at least 0.6, and second-highest was no greater than 0.2 (more detailed analysis of single-localizing proteins and localization heterogeneity is described in the next section). We clustered aFPs of proteins that mapped to the same localization category and produced 15 per-compartment hierarchical trees (we used average linkage and correlation distance for clustering).</p>
      <p id="Par86">We calculated the Silhouette score (Rousseeuw, <xref ref-type="bibr" rid="CR50">1987</xref>) using scikit-learn library, as the mean intra-cluster distance (<italic>a</italic>) and the mean nearest-cluster distance (<italic>b</italic>) for each aFP. The Silhouette coefficient for a sample is (<italic>b</italic>−<italic>a</italic>)/max(<italic>a</italic>, <italic>b</italic>); <italic>b</italic> is the distance between a sample and the nearest cluster that the sample is not a part of. We surveyed 15 per-localization hierarchical trees, clustered with average linkage and correlation metric, using correlation thresholds between 0.25 and 0.75, with a step of 0.05. Median of Silhouette scores across all localizations for a given threshold is shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1E</xref>. We found that thresholds between 0.5 and 0.6 yield maximal Silhouette scores, and a distance threshold of 0.5 corresponded to maximal GO bioprocess AMI value for whole-proteome aFPs clustering. Hence, we chose a 0.5 threshold to cluster aFPs belonging to each per-localization tree, and obtained 30 clusters, which we subsequently called sub-compartmental groups.</p>
    </sec>
    <sec id="Sec25">
      <title>Analysis of localization heterogeneity with scFPs</title>
      <p id="Par87">We used scFPs from the test set to analyze whole-proteome localization heterogeneity patterns. First, we used the pre-trained LR on 17 localization categories (described in the previous section) to map each protein’s test set scFPs to one of the 17 localization classes. We observed that the most probable localization class had an average 0.74 probability per protein (computed across all test set scFPs), while 2nd and 3rd classes scored 0.11 and 0.052 per-protein probabilities, respectively. This motivated us to perform heterogeneity analysis with the two most probable localization categories, to avoid low scFP quantities and potential noise effects. We then computed a mean probability across each localization class to determine the two most frequent localizations of the protein. Hence, for each protein X we obtained a distribution of 2-dimensional real-valued probability vectors [<italic>p</italic><sub><italic>i1</italic></sub>, <italic>p</italic><sub><italic>i2</italic></sub>] with <italic>p</italic><sub><italic>i1</italic></sub> and <italic>p</italic><sub><italic>i2</italic></sub> corresponding to the probabilities of the first and second most frequent localization classes, <italic>i</italic> ∈ {1, …, <italic>N</italic>}, <italic>N</italic> is the number of test set scFPs of the protein X. Given this distribution, we could compute whether protein X is single-localizing or has AND-type/OR-type localization heterogeneity. We filtered low-confidence scFPs <italic>i</italic>, whose sum of probabilities was below a confidence threshold: <italic>p</italic><sub><italic>i1</italic></sub> + <italic>p</italic><sub><italic>i2</italic></sub> &lt; α<sub>conf</sub> (low-confidence region). Next, based on a heterogeneity threshold β, we divided the rest of the scFPs into first localization if <italic>p</italic><sub><italic>i1</italic></sub> &gt; <italic>p</italic><sub><italic>i2</italic></sub> + β, second localization if <italic>p</italic><sub><italic>i2</italic></sub> &gt; <italic>p</italic><sub><italic>i1</italic></sub> + β, or mixed-localizing category otherwise. We varied values of α<sub>conf</sub> between 0.5 and 0.9, and values of β between 0.25 and 0.75 (with a step of 0.05), inspecting numbers of assignments into localization categories and low-confidence region, and selected α<sub>conf</sub> and β as 0.5 based on elbow point analysis. Hence, scFPs of each protein were mapped into one of four classes—primary localization, secondary localization, mixed localization or low-confidence region (Fig. <xref rid="Fig4" ref-type="fig">4D</xref>). If we assume that percentages of the corresponding categories for protein X are c<sub>1</sub>, c<sub>2</sub>, m, k (class 1, class 2, mixed and low-confidence, respectively), then protein X would be marked as AND-type localizing if the mixed category had a higher percentage of scFPs than primary and secondary localizations together: m &gt; c<sub>1</sub> + c<sub>2</sub>; otherwise protein X would be marked as OR-type if no less than 8% of scFPs belonged to the secondary localization: <italic>min</italic>(1, c<sub>2</sub>) &gt; 0.08, and single-localizing in the other case. We experimented with OR-type thresholds between 0.05 and 0.3 (with a step of 0.01), and found that the number of OR-type localizing proteins saturated between 0.07 and 0.1 thresholds. We selected 0.08 as an elbow point between <italic>min</italic>(1, c<sub>2</sub>) value and number of category assignments. Thus, each protein was marked as single-localizing, OR-type, AND-type, or undetermined (if too many scFPs were assigned as low-confidence).</p>
    </sec>
    <sec id="Sec26">
      <title>Cell cycle prediction and annotation with scFPs</title>
      <p id="Par88">We trained an ensemble of three CNNs for cell cycle classification using cytosolic and nuclear channels from our dataset. These two channels contained enough information to distinguish the cell cycle stage of a cell. The CNN contains four convolutional blocks followed by two fully-connected layers, and was trained to predict one of four cell cycle stages - G1, S, metaphase and anaphase (MA), or telophase (T) (Appendix Fig. <xref rid="MOESM1" ref-type="media">S2A</xref>).</p>
      <p id="Par89">We manually labeled 800 crops of cells from 103 different proteins, corresponding to distinct cell cycle stages (with 200 crops from each class) according to bud emergence; we used heavy data augmentation during training to prevent overfitting: rotation by arbitrary angle, vertical and horizontal flips, image zoom within 0.02 range, and vertical and horizontal shifts of up to 9 pixels. We used three-fold cross-validation. The training was performed on 64 × 64 × 2-dimensional crops over 150 epochs using Adam optimizer, with loss being a categorical cross-entropy across 4 cell cycle categories. We performed hyperparameter optimization to select learning rate (5e−4) and dropout rate (0.05). We performed 3 independent runs with random weights initialization (using truncated normal distribution with a standard deviation of 0.1). Model weights were saved after every epoch, and final models for each run were selected with early stopping based on maximal validation accuracy. Training and test accuracy and categorical cross-entropy loss are shown in Appendix Fig <xref rid="MOESM1" ref-type="media">S1</xref>. We created an ensemble of three CNNs (from epochs corresponding to minimal loss value), and subsequently mapped each single-cell crop to a 4-dimensional real-valued vector of cell cycle probabilities. The cell cycle probability vector was computed as an average of the probability vectors of three CNNs of that crop. We subsequently joined T and G1 categories due to high cell density in certain crops, which could potentially lead to an incorrect cell cycle category assignment.</p>
      <p id="Par90">We applied Mann–Whitney U test (McKnight and Najab, <xref ref-type="bibr" rid="CR41">2010</xref>) to identify proteins whose localization changes had cell cycle dependency. For each protein with localization heterogeneity, we annotated its single-cell crops from train, validation and test sets using both LR localization categories and cell cycle stages (via cell cycle classifier). We selected two primary annotated localizations, and compared cell cycle stage distribution of the corresponding crops. For each cell cycle stage, our null hypothesis was that the stage was equally represented among both localizations. Localizations with significant distribution differences (i.e. <italic>p</italic>-value &lt; 1e−3) were annotated as related to the particular cell cycle stage.</p>
    </sec>
    <sec id="Sec27">
      <title>Functional enrichment analysis</title>
      <p id="Par91">Gene Ontology (GO) enrichments were performed using GO-term Finder Version 0.86, available through the <italic>Saccharomyces cerevisiae</italic> Genome Database (<ext-link ext-link-type="uri" xlink:href="https://www.yeastgenome.org/goTermFinder">https://www.yeastgenome.org/goTermFinder</ext-link>). We applied gene set enrichment analysis (GSEA) using Python package GSEApy (Kuleshov et al, <xref ref-type="bibr" rid="CR37">2016</xref>) (<ext-link ext-link-type="uri" xlink:href="https://github.com/zqfang/GSEApy">https://github.com/zqfang/GSEApy</ext-link>) to analyze hierarchically clustered protein groups, sub-compartmental groups and sets of multi-localizing and mixed-localizing proteins (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref> and <xref rid="MOESM4" ref-type="media">EV3</xref>). Query gene sets for GSEA included GO biological process, cellular component, and molecular function standards (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>). GSEA results were filtered to include gene sets with <italic>p</italic>-values below 0.05 and a minimum gene set size of 2. We applied Bonferroni correction to obtain adjusted <italic>p</italic>-values. We also applied one-sided Fisher’s exact test with Costanzo group 19 (Costanzo et al, <xref ref-type="bibr" rid="CR7">2016</xref>) categories to analyse nucleus OR cytoplasm, nucleus AND cytoplasm gene sets, reporting protein sets with <italic>p</italic>-value &lt; 0.05 as the ones showing enrichment (Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>).</p>
    </sec>
    <sec id="Sec28">
      <title>Discovery of interacting proteins from scFPs</title>
      <p id="Par92">We identified clusters containing potentially interacting proteins using two steps. First, we hierarchically clustered scFPs from the test set (we used average linkage and a correlation metric). After that, we divided the dendrogram from top to bottom and traced the number of unique proteins inside the cluster along with the division thresholds of 0.05 points. We found thresholds of the dendrogram at which the number of proteins in a cluster plateaus (95% of protein composition remains the same). After such “morphologically inseparable” clusters were identified, we used three data-driven scores to measure the quality of the resulting clusters—cell ratio, elbow point, and child ratio. Cell ratio <italic>c</italic> is an average percentage of a protein’s cells that fall into a particular cluster. A higher cell ratio translates into less dispersed cells of the same protein, and more confident protein assignment into the particular cluster. Elbow point <italic>k</italic> is a clustering distance at the level of the current cut (1-PCC in our case). A lower elbow point corresponds to a smaller distance between proteins in their feature profiles space. Descendant ratio <italic>d</italic> of the particular root cluster is the percentage of its descendent clusters that were annotated to the same root. A high child ratio corresponds to more agreement of the child clusters, hence indicating a more confident prediction. We devise a final score <italic>s</italic> as follows:<disp-formula id="Equ4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s=\frac{c\cdot d}{k}$$\end{document}</tex-math><mml:math id="M8"><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:mo>⋅</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="44320_2024_29_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par93">We used a final score cutoff of 0.6 to produce a list of 88 high-confidence clusters. We compared performance of our adaptive thresholding approach with clustering approaches from three different families—connectivity (hierarchical clustering (Murtagh and Contreras, <xref ref-type="bibr" rid="CR46">2012</xref>)) centroid (k-means (Sculley, <xref ref-type="bibr" rid="CR52">2010</xref>)) and density methods (DBSCAN (Ester et al, <xref ref-type="bibr" rid="CR15">1996</xref>)) (Fig. <xref rid="Fig5" ref-type="fig">5C</xref>). We performed clustering on the same test set of scFPs with different approaches. For each of the methods used in our comparison, we tried a range of hyperparameters (k ranging from 5 to 500 with a step of 5 in k-means, epsilon ranging from 0.1 to 5 with a step of 0.1 in DBSCAN, and correlation threshold ranging from 0.05 to 0.5 with a step of 0.025 for hierarchical clustering) and report the ones corresponding to the maximal median F1-score across all clusters. F1 scores were calculated by assigning each pair of scFPs ground truth label (0 or 1 depending on whether they are part of the same protein complex) and predicted label (0 or 1 depending on whether they are part of the same cluster).</p>
    </sec>
    <sec id="Sec29">
      <title>Gradient maps</title>
      <p id="Par94">We applied the SmoothGrad method to obtain per-feature gradient maps of the input images (Smilkov et al, <xref ref-type="bibr" rid="CR55">2017</xref>). Original gradient maps <italic>m</italic><sub>c</sub>(<italic>x</italic>) compute the derivative of activation function <italic>S</italic> of the highest-scoring class <italic>c</italic> with respect to the input image <italic>x</italic>, and thus highlight pixels which influence classification decision:<disp-formula id="Equ5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${m}_{c}=\frac{\partial {S}_{c}(x)}{\partial x}$$\end{document}</tex-math><mml:math id="M10"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="44320_2024_29_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par95">Since we were interested in feature interpretation, but not interpreting the classification decision, we modified this computation. In our implementation of gradient map <italic>M</italic><sub><italic>i</italic></sub>(<italic>x</italic>), we take the derivative of specific feature <italic>f</italic><sub><italic>i</italic></sub> from the feature vector <italic>f</italic> with respect to the input image <italic>x</italic>:<disp-formula id="Equ6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${M}_{i}(x)=\frac{\partial {f}_{i}(x)}{\partial x}$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="44320_2024_29_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par96">Hence, our gradient maps highlight regions of the image that impact the value of the selected feature. SmoothGrad produces a gradient map <italic>M</italic><sub><italic>i</italic></sub>(<italic>x</italic>) by averaging a number of gradient maps obtained from an input image with added noise from Gaussian distribution <italic>N</italic>(0, <italic>σ</italic><sup>2</sup>) (with a mean 0 and a standard deviation <italic>σ</italic>):<disp-formula id="Equ7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{M}}_{i}(x)=\frac{1}{n}{\sum }_{i=1}^{n}{M}_{i}(x+N(0,\,{\sigma }^{2}))$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic xlink:href="44320_2024_29_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par97">We used <italic>n</italic> = 100 images and <italic>σ</italic> = 0.05 noise level.</p>
    </sec>
    <sec id="Sec30">
      <title>Generalization experiments</title>
      <p id="Par98">We performed generalization experiments by applying PIFiA out-of-the-box on two unseen yeast imaging datasets: CYCLoPS (Koh et al, <xref ref-type="bibr" rid="CR33">2015</xref>) and YeastRGB (Dubreuil et al, <xref ref-type="bibr" rid="CR12">2019</xref>).</p>
      <p id="Par99">CYCLoPS is a collection comprising more than 20 million cells of C terminal-tagged GFP images of 4144 proteins. To derive single-cell crops from this dataset, we applied the Watershed algorithm to the cytoplasmic channel and computed <italic>x</italic>, <italic>y</italic> coordinates of the center of each cell (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>) subsequently making 64 × 64 pixel crops around the centers. We only used GFP channel of the single-cell crops and performed per-image standardization of each crop.</p>
      <p id="Par100">The YeastRGB dataset is a collection of GFP-tagged microscopy screens produced using SWAT technology, where new-generation fluorescent reporters are fused at the N’ and C’ of open reading frames of over 4000 proteins. We used C’-tagged images (and excluded N’-tagged images) from the YeastRGB dataset to avoid performance mismatch related to the tag location since our training data has C’-tagged images. The YeastRGB database provides single-cell crops, from which we only used GFP channel images and performed per-image standardization of each crop.</p>
      <p id="Par101">For each dataset, we run single-cell crops through PIFiA and extracted scFPs. Next, we averaged scFPs to obtain aFPs for all proteins in the dataset. We used t-SNE (Van der Maaten and Hinton, <xref ref-type="bibr" rid="CR64">2008</xref>) for visualization of aFPs with perplexity = 40 and color-coded the resulting maps with the Huh et al, localization standard (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>).</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <sec id="Sec32">
      <title>Supplementary information</title>
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="44320_2024_29_MOESM1_ESM.pdf">
            <caption>
              <p>Appendix</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="44320_2024_29_MOESM2_ESM.xlsx">
            <caption>
              <p>Dataset EV1</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="44320_2024_29_MOESM3_ESM.xlsx">
            <caption>
              <p>Dataset EV2</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM4">
          <media xlink:href="44320_2024_29_MOESM4_ESM.xlsx">
            <caption>
              <p>Dataset EV3</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM5">
          <media xlink:href="44320_2024_29_MOESM5_ESM.xlsx">
            <caption>
              <p>Dataset EV4</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM6">
          <media xlink:href="44320_2024_29_MOESM6_ESM.pdf">
            <caption>
              <p>Peer Review File</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM7">
          <media xlink:href="44320_2024_29_MOESM7_ESM.pdf">
            <caption>
              <p>Expanded View Figures</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <app-group>
    <app id="App1">
      <sec id="Sec31">
        <title>Expanded view</title>
        <p id="Par102">
          <fig id="Fig7">
            <label>Figure EV1</label>
            <caption>
              <title>PIFiA network architecture and training settings.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig1" ref-type="fig">1</xref>. (<bold>A</bold>) Overview of the architecture of PIFiA convolutional network. (<bold>B</bold>) Left plot: test accuracies of three different runs over the course of training (X axis: epochs, Y axis: test accuracy). Smaller plots: average precision, F-score and precision on protein complexes and pathways standards (X axis: epochs, Y axis: corresponding score on test set). The purple line indicates point of early stopping, when accuracy starts to saturate (derivative of the test accuracy smaller than a threshold of 0.5%). (<bold>C</bold>) Bar graphs comparing the current PIFiA architecture with a common baseline, DenseNet-121, across four different standards (Gene Ontology Cellular Component, Gene Ontology Bioprocess Slim, KEGG Pathways, EBI Protein complexes) in terms of average precision, F-score and adjusted mutual information (assessed on aFPs of 4049 proteins). Error bars represent standard deviation from the mean across three network runs. (<bold>D</bold>) Bar graphs comparing PIFiA performance across different dimensions of the feature profiles (32, 52, 64, 80, 128).</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig7_ESM" id="d33e2590"/>
          </fig>
        </p>
        <p id="Par103">
          <fig id="Fig8">
            <label>Figure EV2</label>
            <caption>
              <title>Comparison of PIFiA annotations and existing localization standards.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig3" ref-type="fig">3</xref>. (<bold>A</bold>) Comparison of localization classification performance of DeepLoc versus PIFiA feature profiles coupled with a logistic regression. Precision-recall plots are shown for 15 subcellular localizations. (<bold>B</bold>) Whole-proteome aFPs tSNE colored by different annotations of subcellular localization: manual annotations from Huh et al, (<xref ref-type="bibr" rid="CR25">2003</xref>) (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>), and computationally-derived annotations from EnsLoc, DeepLoc and PIFiA.</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig8_ESM" id="d33e2619"/>
          </fig>
        </p>
        <p id="Par104">
          <fig id="Fig9">
            <label>Figure EV3</label>
            <caption>
              <title>Generalization of PIFiA network to two unseen datasets.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig3" ref-type="fig">3</xref>. (<bold>A</bold>) Localization-colored tSNE on aFPs obtained from the CYCLoPS dataset. (<bold>B</bold>) Localization-colored tSNE on aFPs obtained from the YeastRGB dataset.</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig9_ESM" id="d33e2642"/>
          </fig>
        </p>
        <p id="Par105">
          <fig id="Fig10">
            <label>Figure EV4</label>
            <caption>
              <title>Examples of proteins from 30 different sub-compartmental groups.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig3" ref-type="fig">3</xref>. Each row corresponds to a sub-compartmental cluster (e.g. nuc-1, nuc-2). The relevant GFP-tagged protein is identified on each micrograph.</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig10_ESM" id="d33e2659"/>
          </fig>
        </p>
        <p id="Par106">
          <fig id="Fig11">
            <label>Figure EV5</label>
            <caption>
              <title>Colocalization assay for proteins from different sub-compartmental.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig3" ref-type="fig">3</xref>. Colocalization experiment results: representative micrographs of cells expressing mNeonGreen- (green images) or mScarlet- (red images) tagged proteins annotated to nucleus (top panel) or cell periphery (bottom panel) groups. Overlays of the mNeonGreen and mScarlet images are shown on the right of each triplet of images. The tagged proteins are indicated on the micrographs (scale bar shown bottom right).</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig11_ESM" id="d33e2676"/>
          </fig>
        </p>
      </sec>
    </app>
  </app-group>
  <sec>
    <title>Supplementary information</title>
    <p>Expanded view data, supplementary information, appendices are available for this paper at 10.1038/s44320-024-00029-6.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank Oren Kraus, Michael Costanzo, Nil Sahin, Alan Moses, Leah Cowen, and Matej Usaj for valuable discussions and advice. This work was supported by grants from the National Institutes of Health (R01HG005853 to BA and CB), and the Canadian Institutes of Health Research (PJT-180259 to BA). Equipment for automated image acquisition and analysis was purchased using funds from the Canadian Foundation for Innovation and the Ontario Research Fund. JB was supported by the Canadian Institute for Advanced Research (CIFAR) AI Chairs program and the National Sciences and Engineering Research Council (Canada). We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Quadro P6000 GPU. Computational resources were provided, in part, by the Province of Ontario and the Government of Canada through the Vector Institute for Artificial Intelligence. AR was supported by the Province of Ontario (Ontario Graduate Scholarship, 2021–2022) and the Vector Institute for Artificial Intelligence (Vector Institute Postgraduate Affiliate Scholarship, 2019–2021). CB is a Fellow of the CIFAR.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p><bold>Anastasia Razdaibiedina</bold>: Conceptualization; Software; Formal analysis; Validation; Investigation; Visualization; Methodology; Writing—original draft; Writing—review and editing. <bold>Alexander Brechalov</bold>: Conceptualization; Software; Supervision; Methodology; Writing—original draft. <bold>Helena Friesen</bold>: Conceptualization; Formal analysis; Supervision; Validation; Methodology; Writing—original draft; Project administration; Writing—review and editing. <bold>Mojca Mattiazzi Usaj</bold>: Supervision; Writing—review and editing. <bold>Myra Paz David</bold><bold>Masinas</bold>: Software. <bold>Harsha Garadi Suresh</bold>: Resources. <bold>Kyle Wang</bold>: Resources. <bold>Charles Boone</bold>: Supervision. <bold>Jimmy Ba</bold>: Conceptualization; Supervision; Investigation; Methodology. <bold>Brenda Andrews</bold>: Supervision; Funding acquisition; Writing—review and editing.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The image data used in this work are available at the CellVision website (<ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia/">https://thecellvision.org/pifia/</ext-link>): The raw images: <ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia_files/pifia_raw_data.tar.gz">https://thecellvision.org/pifia_files/pifia_raw_data.tar.gz</ext-link>. The dataset of single-cell cropped images: (<ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia_files/pifia_single_cell_crops.tar.gz">https://thecellvision.org/pifia_files/pifia_single_cell_crops.tar.gz</ext-link>). Source code for the PIFiA network and downstream analysis is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/arazd/pifia">https://github.com/arazd/pifia</ext-link>.</p>
  </notes>
  <notes>
    <title>Disclosure and competing interests statement</title>
    <notes notes-type="COI-statement">
      <p>The authors declare no competing interests. Brenda J Andrews is a member of the Advisory Editorial Board of Molecular Systems Biology. This has no bearing on the editorial consideration of this article for publication.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Abdi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Williams</surname>
            <given-names>LJ</given-names>
          </name>
        </person-group>
        <article-title>Principal component analysis</article-title>
        <source>Wiley Interdiscip Rev Comput Stat</source>
        <year>2010</year>
        <volume>2</volume>
        <fpage>433</fpage>
        <lpage>459</lpage>
        <pub-id pub-id-type="doi">10.1002/wics.101</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Albert</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schaffer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Beck</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Mosalaganti</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Asano</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Thomas</surname>
            <given-names>HF</given-names>
          </name>
          <name>
            <surname>Plitzko</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Beck</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Baumeister</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Engel</surname>
            <given-names>BD</given-names>
          </name>
        </person-group>
        <article-title>Proteasomes tether to two distinct sites at the nuclear pore complex</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2017</year>
        <volume>114</volume>
        <fpage>13726</fpage>
        <lpage>13731</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1716305114</pub-id>
        <?supplied-pmid 29229809?>
        <pub-id pub-id-type="pmid">29229809</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sommer</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Hensel</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bussey</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Yeast KRE genes provide evidence for a pathway of cell wall beta-glucan assembly</article-title>
        <source>J Cell Biol</source>
        <year>1990</year>
        <volume>110</volume>
        <fpage>1833</fpage>
        <lpage>1843</lpage>
        <pub-id pub-id-type="doi">10.1083/jcb.110.5.1833</pub-id>
        <?supplied-pmid 2186051?>
        <pub-id pub-id-type="pmid">2186051</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <mixed-citation publication-type="other">Chen T, Kornblith S, Norouzi M, Hinton G (2020) A simple framework for contrastive learning of visual representations. In: Proceedings of the 37th international conference on machine learning, pp 1597–1607</mixed-citation>
    </ref>
    <ref id="CR5">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cho</surname>
            <given-names>NH</given-names>
          </name>
          <name>
            <surname>Cheveralls</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Brunner</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Michaelis</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Raghavan</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Kobayashi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Savy</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Canaj</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>OpenCell: Endogenous tagging for the cartography of human cellular organization</article-title>
        <source>Science</source>
        <year>2022</year>
        <volume>375</volume>
        <fpage>eabi6983</fpage>
        <pub-id pub-id-type="doi">10.1126/science.abi6983</pub-id>
        <?supplied-pmid 35271311?>
        <pub-id pub-id-type="pmid">35271311</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chong</surname>
            <given-names>YT</given-names>
          </name>
          <name>
            <surname>Koh</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Duffy</surname>
            <given-names>SK</given-names>
          </name>
          <name>
            <surname>Cox</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Moses</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Moffat</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Yeast proteome dynamics from single cell imaging and automated analysis</article-title>
        <source>Cell</source>
        <year>2015</year>
        <volume>161</volume>
        <fpage>1413</fpage>
        <lpage>1424</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2015.04.051</pub-id>
        <?supplied-pmid 26046442?>
        <pub-id pub-id-type="pmid">26046442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Costanzo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>VanderSluis</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Koch</surname>
            <given-names>EN</given-names>
          </name>
          <name>
            <surname>Baryshnikova</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Pons</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Tan</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Usaj</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hanchard</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>SD</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A global genetic interaction network maps a wiring diagram of cellular function</article-title>
        <source>Science</source>
        <year>2016</year>
        <volume>353</volume>
        <fpage>aaf1420</fpage>
        <pub-id pub-id-type="doi">10.1126/science.aaf1420</pub-id>
        <?supplied-pmid 27708008?>
        <pub-id pub-id-type="pmid">27708008</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cox</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>YT</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Liquid growth of arrayed fluorescently tagged Saccharomyces cerevisiae strains for live-cell high-throughput microscopy screens</article-title>
        <source>Cold Spring Harb Protoc</source>
        <year>2016</year>
        <volume>2016</volume>
        <fpage>pdb prot088799</fpage>
        <pub-id pub-id-type="doi">10.1101/pdb.prot088799</pub-id>
        <?supplied-pmid 27037071?>
        <pub-id pub-id-type="pmid">27037071</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Decottignies</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Grant</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Nichols</surname>
            <given-names>JW</given-names>
          </name>
          <name>
            <surname>de Wet</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>McIntosh</surname>
            <given-names>DB</given-names>
          </name>
          <name>
            <surname>Goffeau</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>ATPase and multidrug transport activities of the overexpressed yeast ABC protein Yor1p</article-title>
        <source>J Biol Chem</source>
        <year>1998</year>
        <volume>273</volume>
        <fpage>12612</fpage>
        <lpage>12622</lpage>
        <pub-id pub-id-type="doi">10.1074/jbc.273.20.12612</pub-id>
        <?supplied-pmid 9575223?>
        <pub-id pub-id-type="pmid">9575223</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <mixed-citation publication-type="other">Deng J, Dong W, Socher R, Li L-J, Li K, Fei-Fei L (2009) Imagenet: a large-scale hierarchical image database. In: IEEE conference on computer vision and pattern recognition (CVPR) 248–255</mixed-citation>
    </ref>
    <ref id="CR11">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deshpande</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Keusch</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Challa</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Iesmantavicius</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Gasser</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Gut</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>The Sir4 H-BRCT domain interacts with phospho-proteins to sequester and repress yeast heterochromatin</article-title>
        <source>EMBO J</source>
        <year>2019</year>
        <volume>38</volume>
        <fpage>e101744</fpage>
        <pub-id pub-id-type="doi">10.15252/embj.2019101744</pub-id>
        <?supplied-pmid 31515872?>
        <pub-id pub-id-type="pmid">31515872</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dubreuil</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Sass</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Nadav</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Heidenreich</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Georgeson</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Weill</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Meurer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Schuldiner</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Knop</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>YeastRGB: comparing the abundance and localization of yeast proteins across cells and libraries</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <fpage>D1245</fpage>
        <lpage>D1249</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky941</pub-id>
        <?supplied-pmid 30357397?>
        <pub-id pub-id-type="pmid">30357397</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dunn</surname>
            <given-names>KW</given-names>
          </name>
          <name>
            <surname>Kamocka</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>McDonald</surname>
            <given-names>JH</given-names>
          </name>
        </person-group>
        <article-title>A practical guide to evaluating colocalization in biological microscopy</article-title>
        <source>Am J Physiol Cell Physiol</source>
        <year>2011</year>
        <volume>300</volume>
        <fpage>C723</fpage>
        <lpage>742</lpage>
        <pub-id pub-id-type="doi">10.1152/ajpcell.00462.2010</pub-id>
        <?supplied-pmid 21209361?>
        <pub-id pub-id-type="pmid">21209361</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Eldakak</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Rancati</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Rubinstein</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Paul</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Conaway</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Asymmetrically inherited multidrug resistance transporters are recessive determinants in cellular replicative ageing</article-title>
        <source>Nat Cell Biol</source>
        <year>2010</year>
        <volume>12</volume>
        <fpage>799</fpage>
        <lpage>805</lpage>
        <pub-id pub-id-type="doi">10.1038/ncb2085</pub-id>
        <?supplied-pmid 20657593?>
        <pub-id pub-id-type="pmid">20657593</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <mixed-citation publication-type="other">Ester M, Kriegel H, Sander J, Xu X (1996) A density-based algorithm for discovering clusters in large spatial databases with noise. In: KDD'96: Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 226–231</mixed-citation>
    </ref>
    <ref id="CR16">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Girosi</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Poggio</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Regularization theory and neural networks architectures</article-title>
        <source>Neural Comput</source>
        <year>1995</year>
        <volume>7</volume>
        <fpage>219</fpage>
        <lpage>269</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1995.7.2.219</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grys</surname>
            <given-names>BT</given-names>
          </name>
          <name>
            <surname>Lo</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Sahin</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Kraus</surname>
            <given-names>OZ</given-names>
          </name>
          <name>
            <surname>Morris</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Machine learning and computer vision approaches for phenotypic profiling</article-title>
        <source>J Cell Biol</source>
        <year>2017</year>
        <volume>216</volume>
        <fpage>65</fpage>
        <lpage>71</lpage>
        <pub-id pub-id-type="doi">10.1083/jcb.201610026</pub-id>
        <?supplied-pmid 27940887?>
        <pub-id pub-id-type="pmid">27940887</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Yeh</surname>
            <given-names>LH</given-names>
          </name>
          <name>
            <surname>Folkesson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ivanov</surname>
            <given-names>IE</given-names>
          </name>
          <name>
            <surname>Krishnan</surname>
            <given-names>AP</given-names>
          </name>
          <name>
            <surname>Keefe</surname>
            <given-names>MG</given-names>
          </name>
          <name>
            <surname>Hashemi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Shin</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Chhun</surname>
            <given-names>BB</given-names>
          </name>
          <name>
            <surname>Cho</surname>
            <given-names>NH</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Revealing architectural order with quantitative label-free imaging and deep learning</article-title>
        <source>Elife</source>
        <year>2020</year>
        <volume>9</volume>
        <fpage>e55502</fpage>
        <pub-id pub-id-type="doi">10.7554/eLife.55502</pub-id>
        <?supplied-pmid 32716843?>
        <pub-id pub-id-type="pmid">32716843</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Haase</surname>
            <given-names>SB</given-names>
          </name>
          <name>
            <surname>Wittenberg</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Topology and control of the cell-cycle-regulated transcriptional circuitry</article-title>
        <source>Genetics</source>
        <year>2014</year>
        <volume>196</volume>
        <fpage>65</fpage>
        <lpage>90</lpage>
        <pub-id pub-id-type="doi">10.1534/genetics.113.152595</pub-id>
        <?supplied-pmid 24395825?>
        <pub-id pub-id-type="pmid">24395825</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Harris</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Clark</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ireland</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lomax</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ashburner</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Foulger</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Eilbeck</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Lewis</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Marshall</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Mungall</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The Gene Ontology (GO) database and informatics resource</article-title>
        <source>Nucleic Acids Res</source>
        <year>2004</year>
        <volume>32</volume>
        <fpage>D258</fpage>
        <lpage>261</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkh036</pub-id>
        <?supplied-pmid 14681407?>
        <pub-id pub-id-type="pmid">14681407</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Kennedy</surname>
            <given-names>BK</given-names>
          </name>
        </person-group>
        <article-title>The yeast replicative aging model</article-title>
        <source>Biochim Biophys Acta Mol Basis Dis</source>
        <year>2018</year>
        <volume>1864</volume>
        <fpage>2690</fpage>
        <lpage>2696</lpage>
        <pub-id pub-id-type="doi">10.1016/j.bbadis.2018.02.023</pub-id>
        <?supplied-pmid 29524633?>
        <pub-id pub-id-type="pmid">29524633</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ho</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Baryshnikova</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Brown</surname>
            <given-names>GW</given-names>
          </name>
        </person-group>
        <article-title>Unification of protein abundance datasets yields a quantitative Saccharomyces cerevisiae proteome</article-title>
        <source>Cell Syst</source>
        <year>2018</year>
        <volume>6</volume>
        <fpage>192</fpage>
        <lpage>205.e193</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2017.12.004</pub-id>
        <?supplied-pmid 29361465?>
        <pub-id pub-id-type="pmid">29361465</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Pho85, a multifunctional cyclin-dependent protein kinase in budding yeast</article-title>
        <source>Mol Microbiol</source>
        <year>2007</year>
        <volume>66</volume>
        <fpage>303</fpage>
        <lpage>314</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1365-2958.2007.05914.x</pub-id>
        <?supplied-pmid 17850263?>
        <pub-id pub-id-type="pmid">17850263</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <mixed-citation publication-type="other">Huang G, Liu Z, Van Der Maaten L, Weinberger KQ (2017) Densely connected convolutional networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 4700–4708</mixed-citation>
    </ref>
    <ref id="CR25">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huh</surname>
            <given-names>WK</given-names>
          </name>
          <name>
            <surname>Falvo</surname>
            <given-names>JV</given-names>
          </name>
          <name>
            <surname>Gerke</surname>
            <given-names>LC</given-names>
          </name>
          <name>
            <surname>Carroll</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>Howson</surname>
            <given-names>RW</given-names>
          </name>
          <name>
            <surname>Weissman</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>O’Shea</surname>
            <given-names>EK</given-names>
          </name>
        </person-group>
        <article-title>Global analysis of protein localization in budding yeast</article-title>
        <source>Nature</source>
        <year>2003</year>
        <volume>425</volume>
        <fpage>686</fpage>
        <lpage>691</lpage>
        <pub-id pub-id-type="doi">10.1038/nature02026</pub-id>
        <?supplied-pmid 14562095?>
        <pub-id pub-id-type="pmid">14562095</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jaiswal</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Babu</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Zadeh</surname>
            <given-names>MZ</given-names>
          </name>
          <name>
            <surname>Banerjee</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Makedon</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>A survey on contrastive self-supervised learning</article-title>
        <source>Technologies</source>
        <year>2020</year>
        <volume>9</volume>
        <fpage>2</fpage>
        <pub-id pub-id-type="doi">10.3390/technologies9010002</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <mixed-citation publication-type="other">Jenni S, Favaro P (2018) Self-supervised feature learning by learning to spot artifacts. In: IEEE/CVF conference on computer vision and pattern recognition (CVPR) 2733–2742</mixed-citation>
    </ref>
    <ref id="CR28">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jing</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Self-supervised visual feature learning with deep neural networks: a survey</article-title>
        <source>IEEE Tran Pattern Anal Mach Intell</source>
        <year>2020</year>
        <volume>43</volume>
        <fpage>4037</fpage>
        <lpage>4058</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2020.2992393</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kanehisa</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Goto</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>KEGG: kyoto encyclopedia of genes and genomes</article-title>
        <source>Nucleic Acids Res</source>
        <year>2000</year>
        <volume>28</volume>
        <fpage>27</fpage>
        <lpage>30</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/28.1.27</pub-id>
        <?supplied-pmid 10592173?>
        <pub-id pub-id-type="pmid">10592173</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <mixed-citation publication-type="other">Kingma DP, Ba J (2014) Adam: a method for stochastic optimization. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</ext-link></mixed-citation>
    </ref>
    <ref id="CR31">
      <mixed-citation publication-type="other">Kingma DP, Welling M (2013) Auto-encoding variational bayes. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</ext-link></mixed-citation>
    </ref>
    <ref id="CR32">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kobayashi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Cheveralls</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Leonetti</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Royer</surname>
            <given-names>LA</given-names>
          </name>
        </person-group>
        <article-title>Self-supervised deep learning encodes high-resolution features of protein subcellular localization</article-title>
        <source>Nat Methods</source>
        <year>2022</year>
        <volume>19</volume>
        <fpage>995</fpage>
        <lpage>1003</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-022-01541-z</pub-id>
        <?supplied-pmid 35879608?>
        <pub-id pub-id-type="pmid">35879608</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Koh</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>YT</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Moses</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
          <name>
            <surname>Moffat</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>CYCLoPs: a comprehensive database constructed from automated analysis of protein abundance and subcellular localization patterns in Saccharomyces cerevisiae</article-title>
        <source>G3</source>
        <year>2015</year>
        <volume>5</volume>
        <fpage>1223</fpage>
        <lpage>1232</lpage>
        <pub-id pub-id-type="doi">10.1534/g3.115.017830</pub-id>
        <?supplied-pmid 26048563?>
        <pub-id pub-id-type="pmid">26048563</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <mixed-citation publication-type="other">Kolesnikov A, Zhai X, Beyer L (2019) Revisiting self-supervised visual representation learning. In: IEEE/CVF conference on computer vision and pattern recognition 1920–1929</mixed-citation>
    </ref>
    <ref id="CR35">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kraus</surname>
            <given-names>OZ</given-names>
          </name>
          <name>
            <surname>Ba</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Frey</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Classifying and segmenting microscopy images with deep multiple instance learning</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <fpage>i52</fpage>
        <lpage>i59</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw252</pub-id>
        <?supplied-pmid 27307644?>
        <pub-id pub-id-type="pmid">27307644</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kraus</surname>
            <given-names>OZ</given-names>
          </name>
          <name>
            <surname>Grys</surname>
            <given-names>BT</given-names>
          </name>
          <name>
            <surname>Ba</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Frey</surname>
            <given-names>BJ</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Automated analysis of high-content microscopy data with deep learning</article-title>
        <source>Mol Syst Biol</source>
        <year>2017</year>
        <volume>13</volume>
        <fpage>924</fpage>
        <pub-id pub-id-type="doi">10.15252/msb.20177551</pub-id>
        <?supplied-pmid 28420678?>
        <pub-id pub-id-type="pmid">28420678</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kuleshov</surname>
            <given-names>MV</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>MR</given-names>
          </name>
          <name>
            <surname>Rouillard</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Fernandez</surname>
            <given-names>NF</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Koplev</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Jenkins</surname>
            <given-names>SL</given-names>
          </name>
          <name>
            <surname>Jagodnik</surname>
            <given-names>KM</given-names>
          </name>
          <name>
            <surname>Lachmann</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Enrichr: a comprehensive gene set enrichment analysis web server 2016 update</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <fpage>W90</fpage>
        <lpage>97</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw377</pub-id>
        <?supplied-pmid 27141961?>
        <pub-id pub-id-type="pmid">27141961</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>AX</given-names>
          </name>
          <name>
            <surname>Kraus</surname>
            <given-names>OZ</given-names>
          </name>
          <name>
            <surname>Cooper</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Moses</surname>
            <given-names>AM</given-names>
          </name>
        </person-group>
        <article-title>Learning unsupervised feature representations for single cell microscopy images with paired cell inpainting</article-title>
        <source>PLoS Comput Biol</source>
        <year>2019</year>
        <volume>15</volume>
        <fpage>e1007348</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1007348</pub-id>
        <?supplied-pmid 31479439?>
        <pub-id pub-id-type="pmid">31479439</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mattiazzi Usaj</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sahin</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Pons</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Usaj</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Masinas</surname>
            <given-names>MPD</given-names>
          </name>
          <name>
            <surname>Shuteriqi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Shkurin</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Aloy</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Morris</surname>
            <given-names>Q</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Systematic genetics and single-cell imaging reveal widespread morphological pleiotropy and cell-to-cell variability</article-title>
        <source>Mol Syst Biol</source>
        <year>2020</year>
        <volume>16</volume>
        <fpage>e9243</fpage>
        <pub-id pub-id-type="doi">10.15252/msb.20199243</pub-id>
        <?supplied-pmid 32064787?>
        <pub-id pub-id-type="pmid">32064787</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mattiazzi Usaj</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Styles</surname>
            <given-names>EB</given-names>
          </name>
          <name>
            <surname>Verster</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>High-content screening for quantitative cell biology</article-title>
        <source>Trends Cell Biol</source>
        <year>2016</year>
        <volume>26</volume>
        <fpage>598</fpage>
        <lpage>611</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tcb.2016.03.008</pub-id>
        <?supplied-pmid 27118708?>
        <pub-id pub-id-type="pmid">27118708</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <mixed-citation publication-type="other">McKnight PE, Najab J (2010) Mann-Whitney U test. The corsini encyclopedia of psychology. Wiley</mixed-citation>
    </ref>
    <ref id="CR42">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>McQuin</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Goodman</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Chernyshev</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Kamentsky</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Cimini</surname>
            <given-names>BA</given-names>
          </name>
          <name>
            <surname>Karhohs</surname>
            <given-names>KW</given-names>
          </name>
          <name>
            <surname>Doan</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Rafelski</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Thirstrup</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>CellProfiler 3.0: next-generation image processing for biology</article-title>
        <source>PLoS Biol</source>
        <year>2018</year>
        <volume>16</volume>
        <fpage>e2005970</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.2005970</pub-id>
        <?supplied-pmid 29969450?>
        <pub-id pub-id-type="pmid">29969450</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meldal</surname>
            <given-names>BH</given-names>
          </name>
          <name>
            <surname>Forner-Martinez</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Costanzo</surname>
            <given-names>MC</given-names>
          </name>
          <name>
            <surname>Dana</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Demeter</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Dumousseau</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dwight</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Gaulton</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Licata</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Melidoni</surname>
            <given-names>AN</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The complex portal-an encyclopaedia of macromolecular complexes</article-title>
        <source>Nucleic Acids Res</source>
        <year>2015</year>
        <volume>43</volume>
        <fpage>D479</fpage>
        <lpage>484</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gku975</pub-id>
        <?supplied-pmid 25313161?>
        <pub-id pub-id-type="pmid">25313161</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meurer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Sass</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Kats</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Herbst</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Buchmuller</surname>
            <given-names>BC</given-names>
          </name>
          <name>
            <surname>Dederer</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Huber</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Kirrmaier</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Stefl</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Genome-wide C-SWAT library for high-throughput yeast genome tagging</article-title>
        <source>Nat Methods</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>598</fpage>
        <lpage>600</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-018-0045-8</pub-id>
        <?supplied-pmid 29988096?>
        <pub-id pub-id-type="pmid">29988096</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <mixed-citation publication-type="other">Moshkov N, Bornholdt M, Benoit S, Smith M, McQuin C, Goodman A, Senft RA, Han Y, Babadi M, Horvath P et al (2024) Learning representations for image-based profiling of perturbations. Nat Commun 15:1594</mixed-citation>
    </ref>
    <ref id="CR46">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Murtagh</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Contreras</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Algorithms for hierarchical clustering: an overview</article-title>
        <source>Wiley Interdiscip Rev Data Min Knowl Discov</source>
        <year>2012</year>
        <volume>2</volume>
        <fpage>86</fpage>
        <lpage>97</lpage>
        <pub-id pub-id-type="doi">10.1002/widm.53</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Neuber</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Jarosch</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Volkwein</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Walter</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sommer</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Ubx2 links the Cdc48 complex to ER-associated protein degradation</article-title>
        <source>Nat Cell Biol</source>
        <year>2005</year>
        <volume>7</volume>
        <fpage>993</fpage>
        <lpage>998</lpage>
        <pub-id pub-id-type="doi">10.1038/ncb1298</pub-id>
        <?supplied-pmid 16179953?>
        <pub-id pub-id-type="pmid">16179953</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <mixed-citation publication-type="other">Razdaibiedina A, Brechalov A (2022) Learning multi-scale functional representations of proteins from single-cell microscopy data. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2205.11676">https://arxiv.org/abs/2205.11676</ext-link></mixed-citation>
    </ref>
    <ref id="CR49">
      <mixed-citation publication-type="other">Razdaibiedina A, Velayutham J, Modi M (2019) Multi-defect microscopy image restoration under limited data conditions. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1910.14207">https://arxiv.org/abs/1910.14207</ext-link></mixed-citation>
    </ref>
    <ref id="CR50">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rousseeuw</surname>
            <given-names>PJ</given-names>
          </name>
        </person-group>
        <article-title>Silhouettes: a graphical aid to the interpretation and validation of cluster analysis</article-title>
        <source>J Comput Appl Math</source>
        <year>1987</year>
        <volume>20</volume>
        <fpage>53</fpage>
        <lpage>65</lpage>
        <pub-id pub-id-type="doi">10.1016/0377-0427(87)90125-7</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scott</surname>
            <given-names>DW</given-names>
          </name>
        </person-group>
        <article-title>On optimal and data-based histograms</article-title>
        <source>Biometrika</source>
        <year>1979</year>
        <volume>66</volume>
        <fpage>605</fpage>
        <lpage>610</lpage>
        <pub-id pub-id-type="doi">10.1093/biomet/66.3.605</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <mixed-citation publication-type="other">Sculley D (2010) Web-scale k-means clustering. In: WWW ‘10: Proceedings of the 19th international conference on World wide web, pp 1177–1178</mixed-citation>
    </ref>
    <ref id="CR53">
      <mixed-citation publication-type="other">Selvaraju RR, Das A, Vedantam R, Cogswell M, Parikh D, Batra D (2016) Grad-Cam: Why Did You Say That? Visual Explanations from Deep Networks via Gradient-Based Localization. 2017 IEEE International Conference on Computer Vision, Venice, Italy, 618–626</mixed-citation>
    </ref>
    <ref id="CR54">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sheff</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Thorn</surname>
            <given-names>KS</given-names>
          </name>
        </person-group>
        <article-title>Optimized cassettes for fluorescent protein tagging in Saccharomyces cerevisiae</article-title>
        <source>Yeast</source>
        <year>2004</year>
        <volume>21</volume>
        <fpage>661</fpage>
        <lpage>670</lpage>
        <pub-id pub-id-type="doi">10.1002/yea.1130</pub-id>
        <?supplied-pmid 15197731?>
        <pub-id pub-id-type="pmid">15197731</pub-id>
      </element-citation>
    </ref>
    <ref id="CR55">
      <mixed-citation publication-type="other">Smilkov D, Thorat N, Kim B, Viégas F, Wattenberg M (2017) Smoothgrad: removing noise by adding noise. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1706.03825">https://arxiv.org/abs/1706.03825</ext-link></mixed-citation>
    </ref>
    <ref id="CR56">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
        <source>J Mach Learn Res</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
    <ref id="CR57">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stark</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Breitkreutz</surname>
            <given-names>BJ</given-names>
          </name>
          <name>
            <surname>Reguly</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Boucher</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Breitkreutz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tyers</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>BioGRID: a general repository for interaction datasets</article-title>
        <source>Nucleic Acids Res</source>
        <year>2006</year>
        <volume>34</volume>
        <fpage>D535</fpage>
        <lpage>539</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkj109</pub-id>
        <?supplied-pmid 16381927?>
        <pub-id pub-id-type="pmid">16381927</pub-id>
      </element-citation>
    </ref>
    <ref id="CR58">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sullivan</surname>
            <given-names>DP</given-names>
          </name>
          <name>
            <surname>Winsnes</surname>
            <given-names>CF</given-names>
          </name>
          <name>
            <surname>Akesson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Hjelmare</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wiking</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Schutten</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Campbell</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Leifsson</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Rhodes</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Nordgren</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep learning is combined with massive-scale citizen science to improve large-scale image classification</article-title>
        <source>Nat Biotechnol</source>
        <year>2018</year>
        <volume>36</volume>
        <fpage>820</fpage>
        <lpage>828</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.4225</pub-id>
        <?supplied-pmid 30125267?>
        <pub-id pub-id-type="pmid">30125267</pub-id>
      </element-citation>
    </ref>
    <ref id="CR59">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thul</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Akesson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wiking</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Mahdessian</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Geladaki</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ait Blal</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Alm</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Asplund</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bjork</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Breckels</surname>
            <given-names>LM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A subcellular map of the human proteome</article-title>
        <source>Science</source>
        <year>2017</year>
        <volume>356</volume>
        <fpage>eaal3321</fpage>
        <pub-id pub-id-type="doi">10.1126/science.aal3321</pub-id>
        <?supplied-pmid 28495876?>
        <pub-id pub-id-type="pmid">28495876</pub-id>
      </element-citation>
    </ref>
    <ref id="CR60">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thul</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Lindskog</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>The human protein atlas: a spatial map of the human proteome</article-title>
        <source>Protein Sci</source>
        <year>2018</year>
        <volume>27</volume>
        <fpage>233</fpage>
        <lpage>244</lpage>
        <pub-id pub-id-type="doi">10.1002/pro.3307</pub-id>
        <?supplied-pmid 28940711?>
        <pub-id pub-id-type="pmid">28940711</pub-id>
      </element-citation>
    </ref>
    <ref id="CR61">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tkach</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Yimit</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>AY</given-names>
          </name>
          <name>
            <surname>Riffle</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Costanzo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Jaschob</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hendry</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Ou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Moffat</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Dissecting DNA damage response pathways by analysing protein localization and abundance changes during DNA replication stress</article-title>
        <source>Nat Cell Biol</source>
        <year>2012</year>
        <volume>14</volume>
        <fpage>966</fpage>
        <lpage>976</lpage>
        <pub-id pub-id-type="doi">10.1038/ncb2549</pub-id>
        <?supplied-pmid 22842922?>
        <pub-id pub-id-type="pmid">22842922</pub-id>
      </element-citation>
    </ref>
    <ref id="CR62">
      <mixed-citation publication-type="other">Tong A, Boone C (2006) Synthetic genetic array analysis in Saccharomyces cerevisiae. In: Xiao W (ed) Yeast protocols, second edition. Humana Press, Totowa, pp 171–191</mixed-citation>
    </ref>
    <ref id="CR63">
      <mixed-citation publication-type="other">Van Den Oord A, Vinyals O, Kavukcuoglu K (2017) Neural discrete representation learning. In: Advances in neural information processing systems, vol 30 (NIPS 2017)</mixed-citation>
    </ref>
    <ref id="CR64">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Van der Maaten</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Visualizing data using t-SNE</article-title>
        <source>J Mach Learn Res</source>
        <year>2008</year>
        <volume>9</volume>
        <fpage>2579</fpage>
        <lpage>2605</lpage>
      </element-citation>
    </ref>
    <ref id="CR65">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vinh</surname>
            <given-names>NX</given-names>
          </name>
          <name>
            <surname>Epps</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bailey</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Information theoretic measures for clusterings comparison: variants, properties, normalization and correction for chance</article-title>
        <source>J Mach Learn Res</source>
        <year>2010</year>
        <volume>11</volume>
        <fpage>2837</fpage>
        <lpage>2854</lpage>
      </element-citation>
    </ref>
    <ref id="CR66">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Youn</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Nguyen Ba</surname>
            <given-names>AN</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Messier</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Cox</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Moses</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Functional analysis of kinases and transcription factors in saccharomyces cerevisiae using an integrated overexpression library</article-title>
        <source>G3</source>
        <year>2017</year>
        <volume>7</volume>
        <fpage>911</fpage>
        <lpage>921</lpage>
        <pub-id pub-id-type="doi">10.1534/g3.116.038471</pub-id>
        <?supplied-pmid 28122947?>
        <pub-id pub-id-type="pmid">28122947</pub-id>
      </element-citation>
    </ref>
    <ref id="CR67">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zaritsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jamieson</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Welf</surname>
            <given-names>ES</given-names>
          </name>
          <name>
            <surname>Nevarez</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Cillay</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Eskiocak</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Cantarel</surname>
            <given-names>BL</given-names>
          </name>
          <name>
            <surname>Danuser</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Interpretable deep learning uncovers cellular properties in label-free live cell images that are predictive of highly metastatic melanoma</article-title>
        <source>Cell Syst</source>
        <year>2021</year>
        <volume>12</volume>
        <fpage>733</fpage>
        <lpage>747</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2021.05.003</pub-id>
        <?supplied-pmid 34077708?>
        <pub-id pub-id-type="pmid">34077708</pub-id>
      </element-citation>
    </ref>
    <ref id="CR68">
      <mixed-citation publication-type="other">Zeiler MD, Fergus R (2014) Visualizing and understanding convolutional networks. Computer Vision – ECCV 2014</mixed-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Mol Syst Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">Mol Syst Biol</journal-id>
    <journal-title-group>
      <journal-title>Molecular Systems Biology</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1744-4292</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">11066028</article-id>
    <article-id pub-id-type="pmid">38472305</article-id>
    <article-id pub-id-type="publisher-id">29</article-id>
    <article-id pub-id-type="doi">10.1038/s44320-024-00029-6</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>PIFiA: self-supervised approach for protein functional annotation from single-cell imaging data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Razdaibiedina</surname>
          <given-names>Anastasia</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Brechalov</surname>
          <given-names>Alexander</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Friesen</surname>
          <given-names>Helena</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mattiazzi Usaj</surname>
          <given-names>Mojca</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Masinas</surname>
          <given-names>Myra Paz David</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Garadi Suresh</surname>
          <given-names>Harsha</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Kyle</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3542-6760</contrib-id>
        <name>
          <surname>Boone</surname>
          <given-names>Charles</given-names>
        </name>
        <address>
          <email>charlie.boone@utoronto.ca</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0009-0000-9062-4180</contrib-id>
        <name>
          <surname>Ba</surname>
          <given-names>Jimmy</given-names>
        </name>
        <address>
          <email>jba@cs.toronto.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6427-6493</contrib-id>
        <name>
          <surname>Andrews</surname>
          <given-names>Brenda</given-names>
        </name>
        <address>
          <email>brenda.andrews@utoronto.ca</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03dbr7087</institution-id><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>Department of Molecular Genetics, </institution><institution>University of Toronto, </institution></institution-wrap>Toronto, ON Canada </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03dbr7087</institution-id><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>The Donnelly Centre, </institution><institution>University of Toronto, </institution></institution-wrap>Toronto, ON Canada </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03kqdja62</institution-id><institution-id institution-id-type="GRID">grid.494618.6</institution-id><institution-id institution-id-type="ISNI">0000 0005 0272 1351</institution-id><institution>Vector Institute for Artificial Intelligence, </institution></institution-wrap>Toronto, ON Canada </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/010rf2m76</institution-id><institution-id institution-id-type="GRID">grid.509461.f</institution-id><institution-id institution-id-type="ISNI">0000 0004 1757 8255</institution-id><institution>RIKEN Center for Sustainable Resource Science, </institution></institution-wrap>2-1 Hirosawa, Wako, Saitama, Japan </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03dbr7087</institution-id><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>Department of Computer Science, </institution><institution>University of Toronto, </institution></institution-wrap>Toronto, ON Canada </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05g13zd79</institution-id><institution-id institution-id-type="GRID">grid.68312.3e</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 9422</institution-id><institution>Present Address: Department of Chemistry and Biology, </institution><institution>Toronto Metropolitan University, </institution></institution-wrap>Toronto, ON Canada </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>12</day>
      <month>3</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>12</day>
      <month>3</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>5</month>
      <year>2024</year>
    </pub-date>
    <volume>20</volume>
    <issue>5</issue>
    <fpage>521</fpage>
    <lpage>548</lpage>
    <history>
      <date date-type="received">
        <day>15</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>27</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="accepted">
        <day>28</day>
        <month>2</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. Creative Commons Public Domain Dedication waiver <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link> applies to the data associated with this article, unless otherwise stated in a credit line to the data, but does not extend to the graphical or creative elements of illustrations, charts, or figures. This waiver removes legal barriers to the re-use and mining of research data. According to standard scholarly practice, it is recommended to provide appropriate citation and attribution whenever technically possible.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Fluorescence microscopy data describe protein localization patterns at single-cell resolution and have the potential to reveal whole-proteome functional information with remarkable precision. Yet, extracting biologically meaningful representations from cell micrographs remains a major challenge. Existing approaches often fail to learn robust and noise-invariant features or rely on supervised labels for accurate annotations. We developed PIFiA (Protein Image-based Functional Annotation), a self-supervised approach for protein functional annotation from single-cell imaging data. We imaged the global yeast ORF-GFP collection and applied PIFiA to generate protein feature profiles from single-cell images of fluorescently tagged proteins. We show that PIFiA outperforms existing approaches for molecular representation learning and describe a range of downstream analysis tasks to explore the information content of the feature profiles. Specifically, we cluster extracted features into a hierarchy of functional organization, study cell population heterogeneity, and develop techniques to distinguish multi-localizing proteins and identify functional modules. Finally, we confirm new PIFiA predictions using a colocalization assay, suggesting previously unappreciated biological roles for several proteins. Paired with a fully interactive website (<ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia/">https://thecellvision.org/pifia/</ext-link>), PIFiA is a resource for the quantitative analysis of protein organization within the cell.</p>
    </abstract>
    <abstract id="Abs2" abstract-type="Synopsis">
      <title>Synopsis</title>
      <p id="Par2">
        <graphic position="anchor" xlink:href="44320_2024_29_Figa_HTML" id="d33e294"/>
      </p>
      <p id="Par3">PIFiA is a self-supervised deep-learning approach for protein functional annotation from single-cell images. It generates feature profiles from images of the yeast ORF-GFP collection that can be used in downstream analyses.</p>
      <p id="Par4">
        <list list-type="bullet">
          <list-item>
            <p id="Par5">PIFiA features identify new functional groups of proteins within organelles and proteins with heterogeneous localizations.</p>
          </list-item>
          <list-item>
            <p id="Par6">PIFiA features successfully predict protein–protein interactions and members of protein complexes.</p>
          </list-item>
          <list-item>
            <p id="Par7">PIFiA outperforms previous methods on four different standards of protein function.</p>
          </list-item>
          <list-item>
            <p id="Par8">Images and analysis are available at thecellvision.org/pifia.</p>
          </list-item>
        </list>
      </p>
    </abstract>
    <abstract id="Abs3" abstract-type="web-summary">
      <p id="Par9">PIFiA is a self-supervised deep-learning approach for protein functional annotation from single-cell images. It generates feature profiles from images of the yeast ORF-GFP collection that can be used in downstream analyses.</p>
      <p id="Par10">
        <graphic position="anchor" xlink:href="44320_2024_29_Figb_HTML" id="d33e321"/>
      </p>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Self-supervised</kwd>
      <kwd>Machine Learning</kwd>
      <kwd>Single-cell</kwd>
      <kwd>Imaging</kwd>
      <kwd>Protein</kwd>
    </kwd-group>
    <kwd-group kwd-group-type="embo-subject">
      <title>Subject terms</title>
      <kwd>Methods &amp; Resources</kwd>
      <kwd>Organelles</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
            <institution>HHS | National Institutes of Health (NIH)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01HG005853</award-id>
        <principal-award-recipient>
          <name>
            <surname>Friesen</surname>
            <given-names>Helena</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000024</institution-id>
            <institution>Canadian Government | Canadian Institutes of Health Research (CIHR)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>PJT-180259</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100007631</institution-id>
            <institution>Canadian Institute for Advanced Research (ICRA)</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100016327</institution-id>
            <institution>Ontario Government | Ministère des Services à l'enfance et des Services sociaux et communautaires, Gouvernement de l'Ontario (Ministry of Children, Community and Social Services, Government of Ontario)</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100019117</institution-id>
            <institution>Vector Institute (Institut Vecteur)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>PGA Fellowship</award-id>
        <principal-award-recipient>
          <name>
            <surname>Razdaibiedina</surname>
            <given-names>Anastasia</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© European Molecular Biology Organization 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par11">Recent progress in high-throughput microscopy and computational image analysis has catalyzed large-scale efforts to quantitatively describe single-cell biology (Cho et al, <xref ref-type="bibr" rid="CR5">2022</xref>; Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Mattiazzi Usaj et al, <xref ref-type="bibr" rid="CR39">2020</xref>; Mattiazzi Usaj et al, <xref ref-type="bibr" rid="CR40">2016</xref>; Thul et al, <xref ref-type="bibr" rid="CR59">2017</xref>; Thul and Lindskog, <xref ref-type="bibr" rid="CR60">2018</xref>). Advances in quantitative analysis of large-scale image datasets have been driven by the development of algorithms for protein localization prediction, which have been used for automated drug screening, and extracting morphological profiles from cell images (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>; McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>). Computational methods enable efficient analysis of millions of single-cell images by extracting morphological information in an unbiased quantitative form. However, generating meaningful numerical features from single-cell images remains a significant challenge. Cells in micrographs typically exhibit a variety of shapes and positions, while noise levels and pixel intensities can also vary between images, making it difficult to develop algorithms that extract functionally rich patterns while ignoring irrelevant information (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). For instance, early machine-learning approaches relied on hand-engineered feature sets extracted from images, such as cell texture and shape, which were often difficult to select and not transferable to other datasets or tasks (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>). Ideally, a computational workflow would map single cells and proteins to robust numerical representations, enabling analysis of the spatial organization of the cell in an objective way.</p>
    <p id="Par12">More recently, single-cell images have been analyzed using deep learning methods, which overcome the limitations associated with hand-engineered feature sets by learning the optimal feature representations directly from pixel level data (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Grys et al, <xref ref-type="bibr" rid="CR17">2017</xref>). The first machine-learning approaches for automated analysis of proteins’ localization patterns were supervised (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). Such methods were trained on a specific classification task, such as predicting cellular compartments from the input images (Grys et al, <xref ref-type="bibr" rid="CR17">2017</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). While supervised methods achieve state-of-the-art performance in their target tasks, they require manual annotation of images used for training, which is time-consuming and expensive. In one of the efforts to accelerate label collection, the Human Atlas Project leveraged crowd-sourcing on a large scale, involving thousands of video games players for microscopy image annotation (Sullivan et al, <xref ref-type="bibr" rid="CR58">2018</xref>). However, manual label assignment is still not practical for imaging datasets containing millions of single-cell micrographs (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). In addition, human-labeled standards may reflect the biases of an individual annotator and can preclude identification of subtle or incompletely penetrant phenotypes (Kraus et al, <xref ref-type="bibr" rid="CR35">2016</xref>; Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>). These problems motivated the development of methods that do not rely on supervised annotations during training (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>; Moshkov et al, <xref ref-type="bibr" rid="CR45">2024</xref>).</p>
    <p id="Par13">An emerging alternative to supervised methods for biological image analysis involves self-supervised approaches, which do not require manually assigned categories during training (Chen et al, <xref ref-type="bibr" rid="CR4">2020</xref>; Jenni and Favaro, <xref ref-type="bibr" rid="CR27">2018</xref>; Jing and Tian, <xref ref-type="bibr" rid="CR28">2020</xref>). Instead, self-supervised learning models define a training objective, or pretext task, using structural information from the data itself (Jaiswal et al, <xref ref-type="bibr" rid="CR26">2020</xref>; Jing and Tian, <xref ref-type="bibr" rid="CR28">2020</xref>; Kolesnikov et al, <xref ref-type="bibr" rid="CR34">2019</xref>). In the context of self-supervised training, features learned with the pretext task should encapsulate information from the images that is useful for downstream applications, such as the discovery of common localization patterns by clustering analysis (Sullivan et al, <xref ref-type="bibr" rid="CR58">2018</xref>). Recently, self-supervised and weakly-supervised methods based on auto-encoders have been used for representation learning on cellular data (Guo et al, <xref ref-type="bibr" rid="CR18">2020</xref>; Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>; Zaritsky et al, <xref ref-type="bibr" rid="CR67">2021</xref>). For example, weakly supervised learning with convolutional neural networks has been successfully applied for modeling associations between images and treatments, significantly improving performance over classical features (Moshkov et al, <xref ref-type="bibr" rid="CR45">2024</xref>). Autoencoder-based models are trained by compressing an image into the latent space (encoding), and subsequent image reconstruction (decoding) (Kingma and Welling, <xref ref-type="bibr" rid="CR31">2013</xref>). The encoding of the image in the latent space is then used as its representation. For instance, Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>), a self-supervised approach developed for analysis of yeast fluorescent micrographs, encodes several imaging channels to predict the appearance of a fluorescently-tagged protein in a target cell. Another autoencoder-based method developed for human cell data, <italic>cytoself</italic> (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>), trains a vector-quantized variational autoencoder (Kingma and Welling, <xref ref-type="bibr" rid="CR31">2013</xref>; Van Den Oord et al, <xref ref-type="bibr" rid="CR63">2017</xref>) (VQ-VAE) to reconstruct fluorescent signals of tagged proteins. Self-supervised learning with autoencoder-based approaches has also been applied for the analysis of human microglia data (Guo et al, <xref ref-type="bibr" rid="CR18">2020</xref>) and extraction of feature profiles predictive of cell metastatic potential (Zaritsky et al, <xref ref-type="bibr" rid="CR67">2021</xref>). One of the main disadvantages of auto-encoders is their difficulty in implementation and training challenges, as well as imperfect decoding (Chen et al, <xref ref-type="bibr" rid="CR4">2020</xref>; Jenni and Favaro, <xref ref-type="bibr" rid="CR27">2018</xref>; Kolesnikov et al, <xref ref-type="bibr" rid="CR34">2019</xref>). While <italic>cytoself</italic> and Paired Cell Inpainting achieved strong performance with decoder-based representations, replicating these networks on other datasets may be prohibitively complex. In this study, we asked whether other characteristics of microscopy data could be leveraged as self-supervised objectives to learn high-quality image representations with a relatively simple convolutional neural network.</p>
    <p id="Par14">Another challenge related to learning image-based features lies in their downstream analysis and interpretation. Current approaches typically extract representations with various machine learning methods and perform downstream analysis using clustering and tSNE/UMAP projections. (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>; Sullivan et al, <xref ref-type="bibr" rid="CR58">2018</xref>). However, there are no clear rules for more nuanced biological analysis, including analysis of extracted features for different levels of cellular organization, or high-confidence identification of protein functional modules. In general, data-backed guidelines on hyperparameter selection, which enable biologically meaningful clustering and consider the scale of cellular organization, are needed. Also, current molecular representation learning approaches generally lack methodologies that can characterize protein function by quantifying cell-to-cell variability in individual protein behavior. In summary, a gap remains in the image analysis field, requiring approaches that could (1) learn biologically meaningful features without human annotations, (2) produce universal features useful for studying subcellular organization at different scales, and (3) provide techniques for a wide range of downstream feature analyses.</p>
    <p id="Par15">Here, we present PIFiA (Protein Image-based Functional Annotation), a self-supervised approach for protein functional annotation derived from single-cell imaging data. PIFiA is coupled with a range of feature exploratory techniques for biological discovery. The representation learning component of PIFiA is performed by a convolutional neural network (CNN), which was trained with the objective of predicting protein identity directly from its fluorescently-labeled input image. This objective does not depend on pre-existing annotations or human labels and, unlike autoencoder-based models, PIFiA is robust to learning non-relevant information in the image, such as cell position, multiple cells in a crop, input noise, or imaging defects. In addition to the CNN component, the PIFiA workflow includes a set of downstream analysis steps for quantitative exploration of feature profiles extracted from single-cell imaging data. We applied PIFiA to ~3,000,000 live-cell confocal images of the budding yeast open reading frame (ORF)-GFP fusion collection (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). We compare PIFiA to existing approaches for protein representation learning and show that PIFiA outperforms previous methods on four different standards of protein function. We explore PIFiA feature profiles for use in a variety of downstream tasks, which are designed for the discovery of functional groups across different scales of cellular organization. Solely using distinct localization patterns of each protein, PIFiA can make remarkably precise functional predictions, identifying highly specific subcellular localization and distinct functional modules to reveal new biological insights.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <sec id="Sec3">
      <title>PIFiA architecture, feature profiles, and proteome-scale image dataset</title>
      <p id="Par16">PIFiA is a self-supervised deep learning approach designed to derive functional information about proteins from microscopy data without using any pre-existing annotations (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). The PIFiA workflow consists of a feature extraction step performed by a deep neural network (Fig. <xref rid="Fig1" ref-type="fig">1A,B</xref>), as well as subsequent analysis steps on the extracted feature profiles (Fig. <xref rid="Fig1" ref-type="fig">1C–E</xref>). The downstream analysis enables prediction of protein localization and the identification of functional modules or subsets of proteins with related cellular roles, such as protein complexes and their associated regulators. The feature profiles can be used for multiple downstream tasks, including construction of a hierarchical map of subcellular organization (Fig. <xref rid="Fig1" ref-type="fig">1C</xref>), predicting protein function (Fig. <xref rid="Fig1" ref-type="fig">1D</xref>), identifying localization heterogeneity at a cell population level (Fig. <xref rid="Fig1" ref-type="fig">1E</xref>), and finding functional modules.<fig id="Fig1"><label>Figure 1</label><caption><title>Overview of the PIFiA workflow (see also Fig. <xref rid="Fig7" ref-type="fig">EV1</xref>).</title><p>(<bold>A</bold>) Diagram of the PIFiA neural network architecture. Shown are examples of activations from passing a micrograph of fluorescently labeled Nup2 protein (Nup2-GFP) through the PIFiA network, with corresponding patterns recognized by the convolutional filters. Feature profiles are extracted from the second fully-connected layer, for use in downstream applications. (<bold>B</bold>) Illustration of two types of feature profiles produced by PIFiA—single-cell feature profiles (extracted from a single crop) and averaged feature profiles (obtained by averaging all single-cell feature profiles of that protein). (<bold>C</bold>) Schematic representation of the global hierarchy of protein feature profile similarities to reveal different levels of functional information. (<bold>D</bold>) Illustration of protein function prediction using self-supervised PIFiA feature profiles. (<bold>E</bold>) An illustrative example of using PIFiA single-cell feature profiles to investigate the localization heterogeneity of a protein.</p></caption><graphic xlink:href="44320_2024_29_Fig1_HTML" id="d33e544"/></fig></p>
      <p id="Par17">The deep learning backbone of PIFiA is a CNN consisting of eight convolutional blocks and three fully-connected (FC) layers, which was trained to predict a protein identifier associated with an input image (i.e. one out of 4049 classes (Fig. <xref rid="Fig1" ref-type="fig">1A</xref>)). The CNN produces a feature profile (or a representation profile) from the input image, which is unique to a particular image. Feature profiles are 64-dimensional real-valued vectors extracted from the second FC layer, which is followed by a classification layer (Fig. <xref rid="Fig7" ref-type="fig">EV1A</xref>). These feature profiles encapsulate condensed information about each protein’s identity, based solely on its localization pattern. Over the course of training, the model first learns straightforward characteristics, such as patterns of different cellular compartments, then it subsequently learns more subtle morphological features that may distinguish individual proteins (Fig. <xref rid="Fig7" ref-type="fig">EV1B</xref>). To achieve the best accuracy and simplicity trade-off, we searched for the optimal architecture, network depth/width and related hyperparameters based on the validation set (Fig. <xref rid="Fig7" ref-type="fig">EV1C,D</xref>) (see Methods). We found that more complex architectures, such as DenseNets (Huang et al, <xref ref-type="bibr" rid="CR24">2017</xref>), did not improve performance but increased the training time, hence we chose a simpler architecture that could achieve comparable performance. Similarly, we searched for optimal feature profile dimensionality and found that accuracy of protein identity prediction stabilized around a 64-dimensional feature profile (Fig. <xref rid="Fig7" ref-type="fig">EV1D</xref>).</p>
      <p id="Par18">To train PIFiA, we produced a comprehensive dataset of 3,058,961 live-cell images of individual strains expressing both a unique fusion gene from the yeast ORF-GFP collection (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>) and spatial markers of cell cycle position (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>), which provide cellular context for computational analysis of protein localization. In particular, we used automated yeast genetics (Tong and Boone, <xref ref-type="bibr" rid="CR62">2006</xref>) to engineer a new version of the ORF-GFP collection, in which the resultant strains also carried fluorescent markers of the nucleus (td-Tomato-NLS) and cytoplasm (E2-Crimson). In total, images of 4049 unique strains were obtained using an automated confocal microscope. Cell images were derived from two biological replicates, each of which had four fields of view for each ORF-GFP strain. The images acquired for the GFP channel were cropped into 64 × 64 pixels crops (median of 778 crops per tagged protein, see Methods), and each crop contained at least one cell at its center. The crops for each GFP-tagged protein were then split into training, validation, and test subsets (8:1:1 ratios).</p>
      <p id="Par19">After CNN training was completed, we extracted feature profiles of the individual single-cell crops from the test set to produce single-cell feature profiles (scFPs) (Fig. <xref rid="Fig1" ref-type="fig">1B</xref>). We then averaged the scFPs for each protein to create its average feature profile (aFP) (Fig. <xref rid="Fig1" ref-type="fig">1B</xref>). An aFP and scFP for an individual protein have the same dimensions, but they describe different levels of information: scFPs encapsulate the localization pattern of a protein in one cell, while aFPs describe the general spatial distribution of a protein. Below, we first use PIFiA aFPs to broadly explore protein localization and function. We then use scFPs to explore cell-to-cell heterogeneity, localization changes, and complex protein localization patterns (Fig. <xref rid="Fig1" ref-type="fig">1C–E</xref>).</p>
    </sec>
    <sec id="Sec4">
      <title>Comparison of PIFiA performance to other self-supervised and supervised approaches</title>
      <p id="Par20">We compared aFPs produced by PIFiA to the representations from three self-supervised methods (Fig. <xref rid="Fig2" ref-type="fig">2A–C</xref>) and two supervised methods (Fig. <xref rid="Fig2" ref-type="fig">2D,E</xref>). For self-supervised methods, we used CellProfiler (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>) (a feature-extraction tool) and its variant CellProfiler+PCA (see Methods), Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>) (a self-supervised autoencoder-based approach) and <italic>cytoself</italic> (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>) (a novel self-supervised method based on a VQ-VAE, that has been used to analyze human cell images). We also included a randomly initialized PIFiA network to show a baseline with the untrained model. For supervised approaches, we used DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>) (a deep-learning model that has been used previously to analyze images of the yeast ORF-GFP collection) and a combination of DeepLoc+PIFiA. We tried both the original DeepLoc version, which was trained on a set of 21,882 cell crops with single-cell labels, as well as our adaptation of DeepLoc, or DeepLoc+PIFiA, which was trained with less accurate but plentiful protein-level labels (see Methods).<fig id="Fig2"><label>Figure 2</label><caption><title>Comparison of PIFiA performance to existing supervised and self-supervised methods for protein representation learning.</title><p>(<bold>A</bold>) Bar graph showing the performance of PIFiA and four other methods (<italic>cytoself</italic> (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>), Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>), Cell Profiler (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>) and Cell Profiler + PCA) at detecting pairs of functionally related proteins (4049 total) using adjusted mutual information. A randomly initialized network (with PIFiA architecture) is shown for comparison as a dashed red line. Gene Ontology (GO) Cellular Component (CC), GO Slim Bioprocess (GO BP Slim), Kyoto Encyclopedia of Genes and Genomes Pathways (KEGG pathways) and European Bioinformatics Institute protein complexes (Protein Complexes). Error bars represent standard deviation from the mean across three network runs. (<bold>B</bold>) Bar graph (same setup as <bold>A</bold>) showing performance assessed using average precision. (<bold>C</bold>) Bar graph (same setup as <bold>A</bold>) showing performance assessed using F-score on four biological standards. (<bold>D</bold>) PIFiA performance versus supervised approaches (two variations of DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>)) assessed using average precision on four biological standards [X axis: Gene Ontology (GO) Cellular Component (CC), GO Slim Bioprocess (GO BP Slim), Kyoto Encyclopedia of Genes and Genomes Pathways (KEGG pathways) and European Bioinformatics Institute protein complexes (Protein Complexes). “DeepLoc original” is the original implementation (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>) trained on crops with manually annotated single-cell labels (4049 proteins total); DeepLoc+PIFiA is our modified version trained on protein-level labels using Huh et al. localization standard (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). Error bars indicate the standard deviation of the scores across three independent runs (for deep learning models). (<bold>E</bold>) Bar graph (same setup as E) showing performance assessed using F-score.</p></caption><graphic xlink:href="44320_2024_29_Fig2_HTML" id="d33e666"/></fig></p>
      <p id="Par21">We consider a model to have good performance if protein pairs with higher correlation between their aFPs are more likely to be functionally related. We evaluated feature profiles (aFPs) using three metrics: F-score and average precision (AP), both measures of feature relevance, and adjusted mutual information (AMI), an information theoretic metric to assess clustering quality (see Methods). PIFiA features showed superior performance on most evaluation criteria using four functional benchmarks: Gene Ontology (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>) (GO) Cellular Components (CC), GO Slim Bioprocesses (GO BP slim), Kyoto Encyclopedia of Genes and Genomes (Kanehisa and Goto, <xref ref-type="bibr" rid="CR29">2000</xref>) (KEGG) pathways and European Bioinformatics Institute (EBI) Protein Complexes (Meldal et al, <xref ref-type="bibr" rid="CR43">2015</xref>) (Fig. <xref rid="Fig2" ref-type="fig">2</xref>).</p>
      <p id="Par22">PIFiA reached better performance than the supervised method DeepLoc in predicting protein subcellular localization (DeepLoc’s target task), as indicated by higher values of F- and AP scores, on the GO CC standard (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). PIFiA also outperformed DeepLoc based on other functional standards, with the biggest performance gain in protein complex discovery. This result confirms the utility of the PIFiA training objective which targets identification of individual tagged proteins, the most detailed level of functional information present in the image. Although the objective does not directly focus on localization prediction, over the course of training the CNN implicitly learns a variety of localization patterns needed to successfully differentiate individual proteins. Thus, PIFiA self-supervised feature profiles can be used for exploratory analysis of protein localization instead of representations from a supervised method such as DeepLoc, bypassing the need for manual annotation while improving performance.</p>
      <p id="Par23">PIFiA also demonstrated better performance than Paired Cell Inpainting, another self-supervised method, achieving 1.2, 1.7, 2.2, and 10.4-fold improvements in terms of mean average precision using cellular component, bioprocess, pathway and protein complex standards, respectively. Also, PIFiA outperformed <italic>cytoself</italic>, a self-supervised approach that utilizes a VQ-VAE in its architecture, which achieved similar performance to Paired Cell Inpainting. Compared to all other approaches examined, PIFiA representations resulted in substantial improvement in clustering quality measured by AMI scores, with an average 5-fold AMI improvement over Paired Cell Inpainting (Fig. <xref rid="Fig2" ref-type="fig">2A</xref>). The significant improvement on the protein complex standard is again explained by PIFiA’s novel self-supervised objective, which forces the network to detect the most comprehensive morphological patterns while ignoring individual image artifacts, which contrasts with autoencoder-based objectives that learn features by naive image reconstruction.</p>
      <p id="Par24">Finally, to evaluate PIFiA performance specifically on proteins that localize to compartments with similar morphologies, we did an extra evaluation run similar to Fig. <xref rid="Fig2" ref-type="fig">2A</xref>, but only including aFPs of proteins from Golgi, endosome and peroxisome (with a single Huh et al localization label). We obtained 0.13, 0.09, 0.08, and 0.1 AP scores for PIFiA, Paired Cell Inpainting, DeepLoc original and DeepLoc+PIFiA, confirming that PIFiA is capable of distinguishing proteins from compartments with similar morphologies.</p>
    </sec>
    <sec id="Sec5">
      <title>Evaluation of the functional information associated with PIFiA average feature profiles</title>
      <p id="Par25">To further assess the biological information associated with the aFPs of each protein, we used hierarchical clustering of aFPs as an unsupervised approach to discover feature profile similarities (Murtagh and Contreras, <xref ref-type="bibr" rid="CR46">2012</xref>). We performed agglomerative hierarchical clustering of the whole-proteome aFPs (4049 proteins in total) using a correlation metric and average linkage. We surveyed the resulting dendrogram at different thresholds to explore whether aFPs are suitable for studying the spatial architecture of the cell at different scales of its organization (Fig. <xref rid="Fig3" ref-type="fig">3A</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S1</xref>). The hierarchical clustering results are shown in Fig. <xref rid="Fig3" ref-type="fig">3A</xref>, with 4049 proteins on the X-axis clustered according to the similarity of their feature profiles (each column is a 64-dimensional aFP). To determine optimal cutoff thresholds, we tracked AMI scores (Vinh et al, <xref ref-type="bibr" rid="CR65">2010</xref>) at different correlation thresholds for three functional standards: GO Cellular Component, GO Slim Bioprocess and Protein Complexes (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>) (see Methods).<fig id="Fig3"><label>Figure 3</label><caption><title>Clustering of PIFiA average feature profiles and analysis of the associated biological information (see also Figs. <xref rid="Fig8" ref-type="fig">EV2</xref>, <xref rid="Fig9" ref-type="fig">EV3</xref>, <xref rid="Fig10" ref-type="fig">EV4</xref>, <xref rid="Fig11" ref-type="fig">EV5</xref>; Dataset <xref rid="MOESM2" ref-type="media">EV1</xref> and <xref rid="MOESM3" ref-type="media">EV2</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S1</xref>).</title><p>(<bold>A</bold>) Clustergram of PIFiA’s average feature profiles for 4049 proteins. The plot to the left of the Y axis shows the adjusted mutual information curve between clustering labels and GO Cellular Component labels at different distance thresholds. The distance threshold (<italic>d</italic> = 0.72) indicated on the clustergram produces clusters associated with cell compartments (color codes on the right). (<bold>B</bold>) Bar graph showing top three Gene Ontology Cellular Component scores for each cluster defined in (<bold>A</bold>). (<bold>C</bold>) Whole-proteome tSNE projection of PIFiA average feature profiles. Each point on the plot represents a protein colored according to a localization category predicted by logistic regression (see Results for training details). (<bold>D</bold>) Annotation of the whole-proteome tSNE projection with GO bioprocess categories shown as Gaussian kernel density estimates. Bioprocesses were selected according to the lowest variance from different cellular components. A filled contour plot was used instead of contour lines to make bioprocess groups more easily distinguishable. The color intensity of the kernel density estimate contour plots corresponds to the cumulative probability mass below the drawn contour. (<bold>E</bold>) Annotation of the whole-proteome tSNE projection with sub-compartmental protein groups predicted by clustering of PIFiA feature profiles (cyto—cytoplasmic cluster, nuc—nuclear cluster, mito—mitochondrial cluster). (<bold>F</bold>) Colocalization analysis of proteins from different sub-compartmental groups. Representative micrographs of cells expressing mNeonGreen- (left) or mScarlet- (middle) tagged proteins annotated to different sub-compartmental groups within three cellular compartments: <italic>nucleus</italic> (top), <italic>cell periphery</italic> (middle) and <italic>endoplasmic reticulum</italic> (ER, bottom) groups. Overlays of the mNeonGreen and mScarlet images are shown on the right. The tagged proteins are indicated on the micrographs.</p></caption><graphic xlink:href="44320_2024_29_Fig3_HTML" id="d33e787"/></fig></p>
      <p id="Par26">First, we determined an optimal threshold (0.72) corresponding to the most general level of cellular organization—GO Cellular Component annotations (Fig. <xref rid="Fig3" ref-type="fig">3A</xref>). The nine clusters produced at this threshold were enriched for proteins with relatively broad cell component annotations: nucleus, mitochondrion, Golgi apparatus, cytoplasm, endoplasmic reticulum (ER), actin patches, nucleolus and cytosolic ribosome (all <italic>p</italic>-value &lt; 10e−20 except cluster 4 with <italic>p</italic>-value &lt; 10e−5; Fig. <xref rid="Fig3" ref-type="fig">3A,B</xref>; Dataset <xref rid="MOESM2" ref-type="media">EV1</xref>; examples of cell images from each cluster are shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1A</xref>). At this level of feature profile similarity, proteins annotated to subcellular components with visually distinct morphologies, such as organelles, tend to be in a single cluster, whereas proteins annotated to more heterogeneous cellular compartments are found in multiple clusters. For example, proteins with a <italic>nucleus</italic> GO cellular component annotation are enriched only in cluster 1, whereas proteins with a <italic>cytoplasm</italic> annotation were enriched in clusters 4, 8, and 9 (Fig. <xref rid="Fig3" ref-type="fig">3A,B</xref>). Detailed visual image inspection revealed that some clusters reflect protein localization to both the cytoplasm and another compartment, such as cluster 4 which contains subsets of proteins localized to the cytoplasm and cell surface proteins. Other clusters likely reflect differences in protein abundance, such as cluster 8, which includes a number of highly abundant proteins, including ribosomal proteins.</p>
      <p id="Par27">Next, we derived optimal correlation thresholds on our dendrogram corresponding to two additional, more detailed biological standards: GO Slim Bioprocess and Protein Complexes (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>). We obtained 21 clusters for GO Slim Bioprocesses (0.64 AMI distance threshold), 20 of which were functionally enriched (GO enrichments are shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1C</xref>; median <italic>p</italic>-value of 5e−10 across all enriched clusters; cluster entropies in terms of present localizations are shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1D</xref>). Similarly, 205 clusters were found at the dendrogram cutoff corresponding to a protein complex standard (0.29 AMI, Appendix Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>), which had 11-fold median enrichment in protein complex predictions across all clusters (distribution of the per-cluster enrichments at 0.29 AMI cutoff is shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1E,F</xref>). Hence, aFPs present robust and memory-efficient representations of protein features, which allow detection of clusters with functionally related proteins at various levels of cellular organization, with the highest functional resolution at more general levels of the hierarchy (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1F</xref>).</p>
    </sec>
    <sec id="Sec6">
      <title>Adaptation of PIFiA features to external annotations for protein localization and function</title>
      <p id="Par28">Our clustering analysis showed that PIFiA aFPs capture information from cell images that enables unsupervised resolution of cellular spatial organization, grouping proteins by shared localization and biological function (Fig. <xref rid="Fig3" ref-type="fig">3A,B</xref>). We have investigated another useful property of feature profiles—adaptability for subsequent supervised training. One of our goals was to create a model that produces universal feature profiles that can be used without the requirement to re-train a full neural network from scratch on a specific task. To evaluate the adaptability of feature profiles, we used the widely adopted linear evaluation protocol (Chen et al, <xref ref-type="bibr" rid="CR4">2020</xref>) where a linear classifier is trained on top of the representations extracted from the network, and test accuracy is used as a measure of representation quality.</p>
      <p id="Par29">We first evaluated how PIFiA features can be adapted to protein localization labels, which comprise the largest labeled functional standard available (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). This analysis enables assessment of whether information contained in self-supervised PIFiA features matches the content of the original images, when extracted with a supervised method. We trained a multinomial logistic regression (LR) using PIFiA scFPs from 2415 proteins manually annotated to localize to a single subcellular localization (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>) (see Methods). We compared the final performance of the LR trained on PIFiA scFPs to DeepLoc, a supervised neural network specifically trained to classify protein localization from images of the yeast ORF-GFP collection. To match the training protocol of DeepLoc, we used scFPs derived from the single-cell images in DeepLoc’s training set (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). We report AP scores on the same single-cell crops from the test set across the full roster of 2415 single-localized proteins (Fig. <xref rid="Fig8" ref-type="fig">EV2A</xref>). Remarkably, PIFiA self-supervised scFPs that were paired with LR yielded a comparable performance to the supervised network DeepLoc, even though PIFiA feature profiles are self-supervised and were fitted to localization labels solely using LR. This finding suggests that PIFiA feature profiles have rich functional content, and we can use them to predict functional protein attributes without training a full network from scratch.</p>
      <p id="Par30">To visualize adaptation of PIFiA feature profiles to the supervised localization labels, we transformed the 64-dimensional aFPs into 2-dimensional space using t-SNE (Van der Maaten and Hinton, <xref ref-type="bibr" rid="CR64">2008</xref>) and colored them according to LR localization predictions (Fig. <xref rid="Fig3" ref-type="fig">3C</xref>). Each aFP on the t-SNE projection was annotated with the localization category corresponding to the maximal LR prediction across all scFPs. In this visualization, the morphological similarity of proteins encapsulated in the aFPs was translated into proximity on the 2D t-SNE map, highlighting that the separation of self-supervised aFPs on the map was driven by subcellular localization signals. We compared the aFP localization assignments with the assignments made using supervised machine learning methods or manual annotations trained to specifically assign proteins to subcellular localizations (Fig. <xref rid="Fig8" ref-type="fig">EV2B</xref>). Ultimately, we observed higher quality of linear localization annotation compared to subcellular localization standards produced by other approaches (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>) (Fig. <xref rid="Fig8" ref-type="fig">EV2A</xref>).</p>
      <p id="Par31">These analyses show that PIFiA feature profiles can be adapted to the objective of a supervised neural network, which confirms the high information content of PIFiA features. Such adaptable feature profiles may accelerate training by replacing various task-specific supervised neural networks with one multi-purpose self-supervised approach, which yields universally applicable representations.</p>
    </sec>
    <sec id="Sec7">
      <title>Generalization to unseen datasets</title>
      <p id="Par32">We investigated the generalization capabilities of the PIFiA neural network by applying it to previously unseen yeast imaging datasets. Specifically, we evaluated the performance of PIFiA on the publicly available CYCLoPS (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>) and YeastRGB (Dubreuil et al, <xref ref-type="bibr" rid="CR12">2019</xref>) datasets. Both datasets contain images of &gt;4000 unique GFP-tagged proteins: CYCLoPs images show a version of the ORF-GFP collection and YeastRGB contains images of a new collection based on a different fluorescent protein, mNeonGreen. We applied the PIFiA network out-of-the-box to single-cell crops of the fluorescently-tagged protein images from these datasets and extracted their feature profiles (see Methods for details on feature extraction).</p>
      <p id="Par33">We generated aFPs from both datasets and used tSNE to visually represent the similarity between feature profiles, with points in close proximity reflecting similar visual characteristics (Fig. <xref rid="Fig9" ref-type="fig">EV3</xref>). We color-coded the tSNE maps according to the annotated subcellular localizations of the yeast cell components using a well-known standard of yeast protein localization (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). This visualization strategy allowed us to observe the formation of dense clusters corresponding to specific subcellular compartments. Nucleus, cytoplasm, mitochondrion, ER, vacuole and nucleolus were the most distinguishable localizations across both datasets (Fig. <xref rid="Fig9" ref-type="fig">EV3A,B</xref>). Thus, the PIFiA network showed strong generalization capabilities on two unseen datasets without any fine-tuning of its weights. We attribute this generalization to diverse data augmentation that was applied to the training data. Overall, our results confirm the feasibility of applying PIFiA for the analysis of novel datasets.</p>
    </sec>
    <sec id="Sec8">
      <title>Experimental validation of PIFiA predictions of sub-compartmental organization of the cell</title>
      <p id="Par34">We explored more specific functional information associated with PIFiA aFPs. We used Gaussian kernel density estimates (KDEs) (see Methods) to annotate our whole-proteome 2D tSNE projection of aFPs with Gene Ontology bioprocess terms. For illustration, we selected terms from different subcellular components that had the lowest variance on the t-SNE map. This annotation showed that PIFiA features distinguished biological processes within cellular compartments (Fig. <xref rid="Fig3" ref-type="fig">3D</xref>). For example, regions of the tSNE map corresponding to the cytoplasm (Fig. <xref rid="Fig3" ref-type="fig">3C</xref>) had distinct regions enriched for translation initiation and elongation, P-body assembly, pentose-phosphate shunt and glycogen metabolic process (Fig. <xref rid="Fig3" ref-type="fig">3D</xref>). This analysis illustrates that GFP-tagged proteins with similar biological roles have distinguishable appearances in cell images, and that PIFiA learns feature profiles that can be used to discover protein functional groups across different levels of subcellular organization, including organelles and possible sub-compartmental structures.</p>
      <p id="Par35">To further explore information in PIFiA profiles related to the sub-compartmental organization of the cell, we clustered aFPs of proteins that mapped to the same localization category to produce 15 per-compartment hierarchical trees (derived from the 15 categories defined by LR; Fig. <xref rid="Fig3" ref-type="fig">3C</xref>). We selected a sub-compartmental clustering threshold of 0.5 based on the highest morphological similarity within clusters and maximal separation between clusters, measured by a Silhouette score (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1E</xref>). We identified 30 clusters, which are indicated on the tSNE projection of PIFiA feature profiles in Fig. <xref rid="Fig3" ref-type="fig">3E</xref>, with example images of cells from each group shown in Fig. <xref rid="Fig10" ref-type="fig">EV4</xref> (see also Dataset <xref rid="MOESM3" ref-type="media">EV2</xref> for GO enrichment and other information). We refer to these clusters using their localization category and associated group number (e.g., nuc-1 corresponds to the first sub-compartmental group in the nucleus). We provide an interactive version of the t-SNE plot from Fig. <xref rid="Fig3" ref-type="fig">3E</xref> on the PIFiA website (<ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia/">https://thecellvision.org/pifia/</ext-link>), where each point on the plot is clickable and allows the user to explore the micrographs corresponding to the GFP-tagged protein, find its nearest neighbors and perform enrichment analysis based on the closest aFPs.</p>
      <p id="Par36">Several general features associated with the clusters in Fig. <xref rid="Fig3" ref-type="fig">3E</xref> suggest that they are functionally meaningful and reflect sub-compartmental organization. First, proteins localizing to compartments which tend to be more homogeneous in their morphological patterns were typically seen in a single cluster (e.g., peroxisome, spindle pole, vacuolar membrane, nuclear periphery), while proteins associated with large or heterogeneous compartments, such as the nucleus, cytoplasm, and mitochondria, defined more than one sub-compartmental cluster (Fig. <xref rid="Fig3" ref-type="fig">3E</xref>; Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). Second, 16 of 32 groups showed &gt;2-fold enrichment for a GO annotation category (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>, <italic>P</italic> &lt; 0.01). For example, the nucleus region of the whole-proteome map was divided into five clusters, enriched in GO bioprocesses such as small molecule metabolic process, chromatin remodeling and RNA polymerase II activity, mitotic nuclear division and proteolysis (Fig. <xref rid="Fig3" ref-type="fig">3E</xref>; Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). Third, as expected, some of the groupings appeared to be based on protein features that were easily discernible. Proteins in some sub-compartmental groups have a tight distribution of GFP intensities, suggesting that abundance is likely an important feature for that group. For example, <italic>nuc</italic>-1 clustering likely resulted from high protein abundance, and this cluster included histones and metabolic enzymes (median GFP intensity <italic>nuc</italic>-1 proteins = 5834 ± 2103 vs median for all <italic>nuc</italic> proteins = 745 ± 793) (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). Likewise, <italic>nuc</italic>-3 proteins had low abundance (median GFP intensity = 678 ± 52) and this group was enriched for mitotic nuclear division and chromosome segregation. For some of the other groups, clustering appeared to result from differences in the spatial distribution of pixels in a region. For example, <italic>cyto</italic>-3 proteins all had a prominent cytosolic signal overlaid with a punctate morphology, and most had roles in Golgi vesicle transport (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>; Fig. <xref rid="Fig9" ref-type="fig">EV3</xref>). Similarly, <italic>cyto-8</italic> contained only seven proteins with no obvious functional overlap, but by visual inspection, all the proteins localized to the cytoplasm and to one or more foci (Fig. <xref rid="Fig9" ref-type="fig">EV3</xref>). Thus, a fraction of sub-compartmental groups could be explained by distinct protein localization features, which may correspond to coherent functionality.</p>
      <p id="Par37">For many sub-compartmental groups, however, the features driving the clustering were less obvious. To ask if we could manually identify differences between proteins from different PIFiA sub-compartments with the same overall localization, we used a more sensitive colocalization assay. We chose pairs of proteins with similar abundances, tagged them with two fluorescent proteins, mNeonGreen and mScarlet, imaged cells containing both tagged proteins, taking Z-stacks of 5 optical sections, and manually assessed images (Fig. <xref rid="Fig3" ref-type="fig">3F</xref>; Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). Using colocalization, we observed subtle differences in most of the pairs from different sub-compartmental groups; specifically, we identified differences in 39/52 (75%) protein pairs from distinct groups, but in only 7/24 (29%) pairs from the same group (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). We show three examples of pairs of proteins from different sub-compartmental groups that vary in their localizations to different extents. In one example with a clear difference, we identified a distinct localization for <italic>nuc-5</italic> proteins, which were 13.5-fold enriched for components of the proteasome (<italic>P</italic> = 7.78E−22). The localization of <italic>nuc-5</italic> proteins overlapped extensively with that of other nuclear proteins, but <italic>nuc-5</italic> proteins additionally localized to the nuclear periphery (Fig. <xref rid="Fig3" ref-type="fig">3F</xref>, top row). We detected the nuclear periphery localization of <italic>nuc-5</italic> proteins when we looked at different proteasome components from <italic>nuc-5</italic>, in colocalization assays with proteins from different sub-compartmental <italic>nuc</italic> groups, and when the fluorescent proteins were reversed (Fig. <xref rid="Fig11" ref-type="fig">EV5</xref>).</p>
      <p id="Par38">In another example with a clear difference, we performed co-localization analysis with proteins assigned to different cell periphery (CP) groups. We examined cells expressing both a high-affinity iron transporter, Ftr1, from the <italic>CP-1</italic> group, and Tcb2, a protein involved in ER-plasma membrane tethering, from the <italic>CP-2</italic> group (Fig. <xref rid="Fig3" ref-type="fig">3F</xref>, middle row). Ftr1, tagged with mScarlet, and Tcb2, tagged with mNeonGreen, localized to distinct regions of the cell periphery. Ftr1 localized specifically to the mother cell periphery but was absent from the bud, whereas Tcb2 was present at both the mother and daughter cell peripheries. Indeed, by visual inspection, we found that many of the <italic>CP-1</italic> proteins had apparent mother-specific localization, like Ftr1. In total, the <italic>CP-1</italic> group contains 21 proteins, and includes 7 of the 8 proteins found previously to localize asymmetrically to mother cells, all of which are members of the MDR (multidrug resistance) transporter family: Fui1, Hip1, Hnm1, Pdr5, Snq2, Tpo1, Yor1 (Decottignies et al, <xref ref-type="bibr" rid="CR9">1998</xref>; Eldakak et al, <xref ref-type="bibr" rid="CR14">2010</xref>).</p>
      <p id="Par39">In addition to the MDR transporters, the <italic>CP-1</italic> group contains 14 novel mother-specific proteins, including several other transporter proteins (Atr1, Ftr1, Hxt6, Mep1, Mep3, Qdr2, and Qdr3), proteins with roles in signaling (Gpa2, Mid2, Psr1), and three relatively uncharacterized proteins (Ybr016w, Ina1, and Crp1; Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>).</p>
      <p id="Par40">In a third example, we looked at colocalization of two proteins whose ORF-GFP fusions show some ER localization: Ubx2, a protein involved in ER-associated protein degradation from the <italic>ER-3</italic> sub-compartmental group (Neuber et al, <xref ref-type="bibr" rid="CR47">2005</xref>), and Kre1, a protein that normally functions as a cell wall glycoprotein from the <italic>ER-5</italic> group (Boone et al, <xref ref-type="bibr" rid="CR3">1990</xref>). The difference between these is more subtle: the <italic>ER-5</italic> protein, Kre1, shows an ER localization but also an increased concentration at the cell periphery compared to Ubx2 (Fig. <xref rid="Fig3" ref-type="fig">3F</xref>, bottom row). This localization difference was observed in other members of these sub-compartmental groups, with <italic>ER-3</italic> proteins tending to have a more diffuse localization and <italic>ER-5</italic> proteins localizing more to the cell periphery (Fig. <xref rid="Fig11" ref-type="fig">EV5</xref>).</p>
      <p id="Par41">In summary, our data show that within a compartment, PIFiA features can distinguish groups of proteins with subtle differences in localization that often have different biological roles. Many of these groups are enriched for proteins that perform biological functions not previously associated with distinctive localization patterns.</p>
    </sec>
    <sec id="Sec9">
      <title>Analysis of proteins with multi-compartment localization using PIFiA single-cell feature profiles</title>
      <p id="Par42">The single-cell feature profiles (scFPs) produced by the PIFiA CNN provide an opportunity to explore more nuanced protein behaviors, including proteins localizing across multiple compartments. Previous analyses of the yeast ORF-GFP collection showed that a large fraction of the proteome localizes to two or more compartments in the same cell (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>; Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>). These studies used average statistics for cell populations, precluding differentiation of proteins that localize to multiple compartments, or those that shuttle between compartments. We annotated scFPs of every protein with localization categories using LR classification scores, and then we investigated the distribution of each protein’s single-cell localization scores, focusing on the two most probable localizations (see Methods). Using this strategy, we found that most (3424) proteins have a homogeneous localization (localizing to a single compartment), while 652 proteins exhibit localization heterogeneity (localizing to two or more compartments) (Fig. <xref rid="Fig4" ref-type="fig">4A</xref>). We classified the proteins with heterogeneous localization into two categories: (1) 396 proteins that localized to more than one compartment in a single cell, which we refer to as AND-proteins, and (2) 256 proteins that appeared either in a primary or a secondary location but not in the same cell, which we refer to as OR-proteins (Fig. <xref rid="Fig4" ref-type="fig">4B,C,D</xref>; Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>). For most proteins the assigned localization probabilities were continuously distributed, but our classification summarizes the localization, indicating the compartments that the protein predominantly populates. For example, Pho85 was classified as an AND-protein with a mixed signal predominantly from nucleus and cytoplasm within single cells, consistent with its known biology (Huang et al, <xref ref-type="bibr" rid="CR23">2007</xref>) (Fig. <xref rid="Fig4" ref-type="fig">4C</xref>). In contrast, Stb1 is a transcription factor whose nuclear localization is cell cycle regulated and it was classified by our analysis of scFPs as being either nuclear or cytoplasmic (OR-protein), as seen in previous studies (Youn et al, <xref ref-type="bibr" rid="CR66">2017</xref>) (Fig. <xref rid="Fig4" ref-type="fig">4C</xref>).<fig id="Fig4"><label>Figure 4</label><caption><title>Identification of proteins with morphological heterogeneity using PIFiA single-cell feature profiles (see also Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S2</xref>).</title><p>(<bold>A</bold>) Heatmap depicting ratios of cells falling into a mixed localization category, secondary and primary localization regions. Proteins with low ratios in all three columns (yellow color) feature many cells that fall into the low-confidence region. (<bold>B</bold>) Scatter plot showing two proteins with homogeneous localization patterns. Each point on the scatter plot corresponds to a single-cell crop, mapped to the probability of nuclear and cytoplasmic localization according to the LR predictions. (<bold>C</bold>) Scatter plot showing a protein with AND-type localization heterogeneity, Pho85, and one with OR-type localization heterogeneity, Stb1. (<bold>D</bold>) Schema of scoring proteins for localization heterogeneity using a single-cell level distribution of localization probabilities. Probabilities are obtained from primary and secondary localizations (i.e. first and second most probable localizations of the logistic regression classification of that protein). (<bold>E</bold>) Localization co-occurrence heatmap for 396 AND-localizing proteins, showing numbers of proteins present at two localizations. The scale bar is set to a maximum intensity of 50 to enable visualization of categories with fewer proteins. (<bold>F</bold>) Circle plot depicting localization patterns of 256 OR-type proteins. The thickness of the line connecting two localizations indicates the number of proteins showing localization heterogeneity between these localizations. (<bold>G</bold>) Localization heterogeneity related to cell cycle position for 136 proteins exhibiting statistically significant cell cycle variation. Connections indicate localizations of the proteins at specific cell cycle stages (thicker lines indicate a more common connection between a particular localization change and cell cycle stage transition). The color of the heatmap indicates the number of heterogeneous proteins that are present in the corresponding cell cycle phase for a particular localization.</p></caption><graphic xlink:href="44320_2024_29_Fig4_HTML" id="d33e1182"/></fig></p>
      <p id="Par43">We summarized overall AND-/OR-localizations across 15 localization categories, which clearly illustrated that a large fraction of these changes involved the nucleus and cytoplasm compartments. Among the 922 proteins with a high confidence nuclear localization, 708 were solely nuclear, 159 nuclear AND cytoplasmic, and 55 nuclear OR cytoplasmic (Fig. <xref rid="Fig4" ref-type="fig">4E,F</xref>). We asked how these classes were distributed in different bioprocesses involving the nucleus (Costanzo et al, <xref ref-type="bibr" rid="CR7">2016</xref>). As expected, proteins with roles in RNA processing and chromatin organization tended to be solely nuclear (Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>). The trends for proteins that have dual localization were also consistent with well-established biology. For example, proteins with roles in cell cycle progression were 4.1-fold enriched in nucleus OR cytoplasm (<italic>P</italic> = 6.7E−05). Many cell cycle proteins, in particular many transcription factors, use localization to regulate protein activity (Haase and Wittenberg, <xref ref-type="bibr" rid="CR19">2014</xref>). Proteins with roles in DNA replication/repair and stress response were weakly enriched in nucleus AND cytoplasm (1.5-fold, <italic>P</italic> = 1.40E−03 and 1.9-fold, <italic>P</italic> = 9.7E−04, respectively). DNA repair proteins often alter their relative localization in the presence of damage, either to initiate a repair response or to prevent catastrophic cell cycle events (Tkach et al, <xref ref-type="bibr" rid="CR61">2012</xref>). Because our cells were not experiencing DNA damage at the time of imaging, many of these proteins displayed both nuclear AND cytoplasmic localization in our data. Hence, while many protein groups that show different patterns were too small to perform consistent enrichment analysis, enrichments that were seen for nuclear-cytoplasmic groups, where there are enough proteins to assess, were consistent with known biology.</p>
      <p id="Par44">Finally, because proteins with roles in cell cycle progression were enriched among both the OR- and the AND-proteins, we used our scFPs to assess how cell cycle position could account for some of the protein localization heterogeneity. To do so, we took advantage of the nuclear and cytoplasmic markers (td-Tomato-NLS; E2-Crimson) in our GFP collection to explore the relationship between cell cycle position and protein abundance or localization heterogeneity. We first trained an ensemble of CNNs on the nuclear and cytoplasmic RFP channels to predict one of three cell cycle stages, and we subsequently mapped each single-cell crop to a cell cycle category: T/G1 (Telophase, Gap phase 1), S/G2 (DNA synthesis phase/Gap phase 2) or M/A (metaphase/anaphase) (see Methods). We then compared the single-cell distributions of each cell cycle stage with the localization calls to discover relationships between protein localization and cell cycle (Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S2</xref>). In total, we identified 136 proteins with cell-cycle-dependent variation in PIFiA feature profiles, determined by Mann–Whitney U test (McKnight and Najab, <xref ref-type="bibr" rid="CR41">2010</xref>) (<italic>p</italic>-value &lt; 1e−3, see Methods). Our results are summarized in the connected heatmap shown in Fig. <xref rid="Fig4" ref-type="fig">4G</xref>. As expected, some of the discovered localization changes reflected cell-cycle-dependent differences in the corresponding compartment. For example, most bud neck/cytoplasm AND-localizing proteins (14/23 proteins) were cytosolic in G1 before the bud neck had formed and localized to the bud neck later in the cell cycle (Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>). However, many cell cycle-regulated proteins moved between permanent compartments, including 66 moving between the nucleus and cytoplasm. Indeed, PIFiA identified 4 proteins not previously known to be cell cycle regulated, that localized to the cytoplasm and nucleus, but showed a predominantly cytoplasmic localization in M/A (Yel025c, Atc1, Bop3, and Cmg1).</p>
      <p id="Par45">Overall, scFPs derived from the self-supervised PIFiA workflow enable resolution of single-cell localization and are suitable for cell-to-cell variability analysis. Notably, PIFiA feature profiles contain enough functional information to distinguish compartments and sub-compartmental morphologies without pre-assigned labels, enabling analysis of protein localization heterogeneity in a data-driven way, which precludes propagating annotation errors.</p>
    </sec>
    <sec id="Sec10">
      <title>Prediction of functional modules using PIFiA single-cell feature profiles</title>
      <p id="Par46">We showed that protein-level feature profiles, or aFPs, can present a range of microscopy patterns in a compressed numerical form, which can be used for clustering and building hierarchical dendrograms. Using AMI scores at different correlation thresholds we were able to resolve functional information associated with hierarchical clustering of PIFiA aFPs (Fig. <xref rid="Fig2" ref-type="fig">2A</xref>) and determine an optimal correlation threshold for discovering functional modules, such as protein complexes (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1A</xref>). However, averaging feature profiles leads to information loss, which is not optimal for more precise analysis. Hence, we explored the use of single-cell feature profiles for the identification of functional modules. In particular, we focused on whether we could use scFPs for improved identification of protein complexes, which represent functional modules whose components are expected to colocalize within a single cell.</p>
      <p id="Par47">We derived our scFPs clustering analysis from a straightforward intuition—scFPs belonging to the same protein or the same protein complex should be indistinguishable, given the resolution limits of light microscopy. To visually illustrate this hypothesis on protein complex member distributions with scFPs, we projected scFPs from the test set using 2D tSNE (Fig. <xref rid="Fig5" ref-type="fig">5A</xref>). The scFPs of proteins from the same complex often localized together on the tSNE map, but different proteins from the same complex were typically intermingled and difficult to separate from each other. In contrast, the scFPs corresponding to different protein complexes with the same subcellular localization were often separated on the tSNE map (e.g., Polymerase-II, Polymerase-III, and RSC in the nucleus; EGO and V-ATPase in the vacuolar membrane) (Fig. <xref rid="Fig5" ref-type="fig">5A</xref>).<fig id="Fig5"><label>Figure 5</label><caption><title>Prediction of protein functional modules using PIFiA single-cell feature profiles (see also Dataset <xref rid="MOESM5" ref-type="media">EV4</xref>).</title><p>(<bold>A</bold>) Visualization of protein complex clusters on a single-cell tSNE plot of PIFiA feature profiles. The central plot shows a whole-proteome tSNE projection of PIFiA single-cell feature profiles (scFPs). Each point on the plot represents a protein that is colored according to 15 different subcellular localizations (color codes are explained below the plot). Zoom-in plots show a more detailed view of some regions of the global tSNE, showing single-cell features from the test set corresponding to proteins from the same complex with the same color palette, each protein shown in different color. (<bold>B</bold>) Dendrogram of clustered scFPs highlighting a region that identifies a nuclear pore cluster among nuclear periphery scFPs. The line graph on the right shows different numbers of proteins in a cluster at different correlation thresholds for clustering. Zoom-in plots of two clusters at different correlation thresholds (red and gray dashed lines) are shown as scFPs tSNE plots to the right. (<bold>C</bold>) Violin plot comparing the performance of four clustering approaches on 140 protein complexes. (<bold>D</bold>) Plot illustrating the fraction of proteins in each cluster with a protein–protein interaction annotated in the BioGrid (blue) or as protein complex member (yellow). Cluster numbers are sorted based on the number of discovered interactions.</p></caption><graphic xlink:href="44320_2024_29_Fig5_HTML" id="d33e1275"/></fig></p>
      <p id="Par48">To further explore the utility of scFPs for algorithmically identifying protein complexes, we developed a modified hierarchical clustering approach, called adaptive thresholding, that is designed to identify correlation thresholds on the hierarchical dendrogram at which scFPs inside a cluster become indistinguishable, and thus might be expected to contain interacting proteins (see Methods). We performed hierarchical clustering of test set scFPs using average linkage and a correlation metric. We then traced the number of unique proteins inside the cluster along with the divisions of the single-cell dendrogram to discover levels of the dendrogram at which the number of proteins in a cluster plateaus (Fig. <xref rid="Fig5" ref-type="fig">5B</xref>). Such plateaus identify levels of the global scFPs dendrogram at which single-cell features are practically inseparable, a division threshold that we call a root cluster (see Methods). For example, our adaptive thresholding method identified a root cluster corresponding to the nuclear pore complex, which distinguished it from other nuclear periphery proteins (Fig. <xref rid="Fig5" ref-type="fig">5B</xref>).</p>
      <p id="Par49">We compared the adaptive thresholding method to other clustering approaches from three different families—connectivity (hierarchical clustering (Murtagh and Contreras, <xref ref-type="bibr" rid="CR46">2012</xref>)), centroid (k-means (Sculley, <xref ref-type="bibr" rid="CR52">2010</xref>)) and density methods (DBSCAN (Ester et al, <xref ref-type="bibr" rid="CR15">1996</xref>)) (Fig. <xref rid="Fig5" ref-type="fig">5C</xref>). For each of the methods used in our comparison, we tried a range of hyperparameters and selected the ones that maximized median F1-score (see Methods). Evaluation was performed on a set of 140 protein complexes that contain at least three proteins included in the ORF-GFP localization dataset (Meldal et al, <xref ref-type="bibr" rid="CR43">2015</xref>). Our approach outperformed other methods in terms of four different scores—fold enrichment, F1 score, precision, and recall (Fig. <xref rid="Fig5" ref-type="fig">5C</xref>). The distributions of scores highlight the advantages of our adaptive thresholding approach. Density-based clustering fails at the protein complex identification task due to the high density of the feature space. At the same time, k-means fails at the identification of larger protein complexes (more than 5 protein members), hence its violin plot has two peaks. Hierarchical clustering is a more advantageous approach for this task, yet it requires information on the distance threshold and lacks adaptability for the protein complex size and cellular compartment. In contrast, our adaptive thresholding approach finds an optimal distance threshold for each cluster and, hence, it can discover protein complexes of varying sizes.</p>
      <p id="Par50">Using the adaptive thresholding clustering approach, we constructed a list of 88 high-confidence clusters whose proteins were indistinguishable at the single cell level (Dataset <xref rid="MOESM5" ref-type="media">EV4</xref>; Fig. <xref rid="Fig5" ref-type="fig">5D</xref>). We mapped each cluster to a protein complex with the maximal fold enrichment and saw a median fold enrichment of 36.5 across 88 clusters, which is a 3-fold improvement over our clustering of aFPs with an optimized cut-off (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). Of the 88 predicted clusters, 42 captured members of 32 different protein complexes distributed across 15 subcellular compartments (Dataset <xref rid="MOESM5" ref-type="media">EV4</xref>). The remaining clusters did not capture two or more members of the same protein complex, although in 25/45 cases they contained proteins with PPIs (as annotated in BioGrid (Stark et al, <xref ref-type="bibr" rid="CR57">2006</xref>)). By using proteins from the same localization as our background set to compute fold enrichment, we tested whether the clusters could differentiate a protein complex from others in the same subcellular location (see Methods). We discovered that PIFiA confidently predicted members of protein complexes in multiple compartments, such as: [1] the proteasome and Ada2/Gcn5/Ada3 transcription activation complex in the nucleus; [2] LSM2-7 complex, decapping complex, and translation initiation factor 2B complex in the cytoplasm; [3] the oligosaccharyl transferase and Sec62-Sec63 complexes in the ER; [4] vacuolar proton translocating ATPase complex, phosphatidylinositol 3-kinase complex and iron exporter complex in the vacuolar membrane; [5] F-actin capping protein complex and PAN1 actin cytoskeleton-regulatory complex in the actin cytoskeleton; [6] Spc105 complex and NDC80 complex in the spindle pole; [7] retromer complex and SNX4-SNX41 sorting nexin complex in endosomes (see Dataset <xref rid="MOESM5" ref-type="media">EV4</xref>).</p>
      <p id="Par51">In some cases (17/44), we identified all members of a complex, together with some additional proteins, which may be previously unappreciated complex components or members of an extended functional module, such as regulators or target proteins. For example, cluster #6 contained all 4 subunits of COMA, a kinetochore complex that connects proteins bound to centromeric DNA with those bound to microtubules, as well as nine additional proteins, eight of which display protein–protein interactions (PPIs) with COMA members (Stark et al, <xref ref-type="bibr" rid="CR57">2006</xref>). Other clusters identified proteins with the same biological role that may participate in PPIs. For example, cluster #39 contained 26 proteins that localized to the nuclear periphery in a punctate fashion. This group contained the only two GFP-tagged members of the TREX-2 complex, which couples SAGA-dependent gene expression and transcription elongation to mRNA export at the nuclear pore complex. Cluster #39 also included 8 proteins reported to have PPIs with members of the TREX complex (Stark et al, <xref ref-type="bibr" rid="CR57">2006</xref>), suggesting they may function in concert with the complex<sup>,</sup> Among the remaining proteins were members of a silencing complex, including Sir2, Sir3, Sir4 and the Sir4-interacting protein Esc1, which suppress transcription at subtelomeric regions, tethering them to the nuclear periphery (Deshpande et al, <xref ref-type="bibr" rid="CR11">2019</xref>). Thus cluster #39 identified proteins with roles in gene expression that localize to the nuclear periphery, some of which function to modulate each other’s activity.</p>
      <p id="Par52">To provide some context into the limitations of the method, we looked at what types of protein complexes were under-represented in our set of high-confidence predictions. Identification by PIFiA was independent of protein abundance or number of members in the complex. The protein complexes we identified were enriched for localizations in small organelles and compartments (peroxisome, actin, nuclear periphery, endosome, spindle pole) and depleted for those in large diffuse compartments such as nucleus and cytoplasm. We note that not all protein complexes will have a distinct localization. Using PIFiA features we have identified protein complexes from most compartments in the cell.</p>
      <p id="Par53">In summary, we have developed a novel approach for discovery of functional modules using solely the self-supervised feature profiles and leveraging the properties of microscopy data for optimal clustering, and prediction of molecular interactions.</p>
    </sec>
    <sec id="Sec11">
      <title>Interpretation of PIFiA features</title>
      <p id="Par54">Our analysis shows that PIFiA feature profiles contain condensed information about protein function at various levels of granularity. However, since deep neural networks function as ‘black-box’ models, it is difficult to dissect feature profiles and explain how individual features are related to the input images. To attempt to interpret PIFiA features, we first quantified feature importance for 15 different localization categories covering a diverse set of subcellular morphological patterns. We used the LR model described earlier to derive importance scores for each feature; the coefficients of the trained LR quantify how much each feature is predictive of a certain localization (Fig. <xref rid="Fig6" ref-type="fig">6A</xref>). Most localizations had more than three strongly predictive features (LR coefficient value &gt; 5), suggesting that PIFiA learns to detect several distinctive patterns for each subcellular compartment. This confirms that PIFiA learns localization patterns with its convolutional filters, despite being trained on a completely different self-supervised objective. Also, the same feature could be predictive for several localizations (for example, features #3 and #28 recognize circular patterns corresponding to the vacuolar membrane and nuclear periphery), or react to some variation of visual patterns present in multiple localizations. Overall, larger and more complex compartments required more features to be confidently classified. To illustrate this finding, we plotted classification accuracy for the three largest compartments (cytoplasm, nucleus, and mitochondria), as well as three homogeneous compartments (nucleolus, peroxisome, and vacuolar membrane) with respect to the number of features used during LR training (see Methods) (Fig. <xref rid="Fig6" ref-type="fig">6B,C</xref>; Appendix Fig <xref rid="MOESM1" ref-type="media">S3A</xref>). While larger localization categories required approximately 30 features to reach their best performance, smaller localizations reached a saturation point at around 10 features.<fig id="Fig6"><label>Figure 6</label><caption><title>Interpretation of PIFiA features (see also Appendix Fig. <xref rid="MOESM1" ref-type="media">S3</xref>).</title><p>(<bold>A</bold>) Heatmap of the logistic regression coefficients for localization prediction associated with each feature. Each feature was mapped to a localization (based on the maximal coefficient value), and features were sorted in descending order of coefficients. (<bold>B</bold>) Plot of classification accuracy dependence on number of features used to train the logistic regression for the three largest and most complex localizations: nucleus, cytoplasm and mitochondria. (<bold>C</bold>) Plot of classification accuracy dependence on number of features, showing three smaller and more homogeneous localizations: nucleolus, peroxisome and vacuolar membrane. Shading shows standard deviation across 5 runs. (<bold>D</bold>) Gradient maps highlighting regions of the input image that CNN “pays attention to”. Proteins from six distinct subcellular compartments are shown with their most visually distinct gradient maps with the highest activation values.</p></caption><graphic xlink:href="44320_2024_29_Fig6_HTML" id="d33e1380"/></fig></p>
      <p id="Par55">Another way to interpret features learned by a CNN is to find regions of the image that had a large influence on the final result (Selvaraju et al, <xref ref-type="bibr" rid="CR53">2016</xref>; Zeiler and Fergus, <xref ref-type="bibr" rid="CR68">2014</xref>). Using gradient calculations, importance scores can be assigned to the input image pixels depending on the degree to which they affect the classification result or individual feature values (see Methods). We used the SmoothGrad approach (Smilkov et al, <xref ref-type="bibr" rid="CR55">2017</xref>; Zeiler and Fergus, <xref ref-type="bibr" rid="CR68">2014</xref>) to construct gradient maps for several features of the same protein image. We selected proteins representing five distinct subcellular localizations: Nup2 from nuclear periphery, Mcm2 from nucleus, Scs2 from ER, Ftr1, and Pst2 from cell periphery, and Pex3 from peroxisome. For each of the proteins, we used its scFPs to calculate 64 gradient maps for each of the individual features and selected four visually distinct gradient maps with the highest activation values for illustration purposes (Fig. <xref rid="Fig6" ref-type="fig">6D</xref>; Appendix Fig. <xref rid="MOESM1" ref-type="media">S3B</xref>).</p>
      <p id="Par56">We observed that different features of the same image resulted in different gradient maps. While regions with higher intensity often have higher gradient values (unless they are not meaningful for the training objective), the interesting observation here is which part of these regions are meaningful for the particular feature. For example, the last gradient map of Pex3-GFP protein shows punctate localization patterns with three distinct punctae. Interestingly, different features react to different parts of the image—feature 4 reacts to the lower dot on the image and feature 23 reacts to two other dots. Also, gradient maps of the Mcm2 protein highlighted the nuclear periphery region, focus points in the nucleus and nuclear background signal. Similarly, different features of Ftr1 reacted to various subregions of the cell periphery. Of note, the generated gradient maps showed that the region of network attention was always the single central cell of the crop even for crops containing more than one cell, confirming that per-crop feature profiles are in fact single-cell profiles (Fig. <xref rid="Fig6" ref-type="fig">6D</xref>, with Mcm2, Ftr1 and Pst2 proteins containing multiple cells in their crop, Appendix Fig. <xref rid="MOESM1" ref-type="media">S3B</xref>). Gradient-based interpretability approaches are useful to explain the relationship between individual features in the feature profile vector and input pixels in the image, and they constitute an important component of our downstream analysis pipeline. Hence, despite PIFiA’s self-supervised training objective, we can visually understand what each learned feature represents in terms of the input image regions.</p>
    </sec>
  </sec>
  <sec id="Sec12" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par57">We describe PIFiA, a self-supervised computational workflow that learns protein functional signatures from single-cell fluorescence microscopy data. Feature profiles learned by PIFiA show state-of-the-art performance on a variety of biological functional benchmarks, outperforming existing approaches for protein representation learning. Notably, our approach does not require any labels or annotations during training and uses only a single fluorescent channel. Hence, PIFiA can be easily applied to virtually any imaging dataset. We pre-trained PIFiA on a large-scale dataset encompassing over three million single-cell images of yeast cells expressing 4049 GFP-fusion proteins—a scale comparable to that of the commonly used computer vision dataset, ImageNet (Deng et al, <xref ref-type="bibr" rid="CR10">2009</xref>). As with ImageNet, we show that the yeast ORF-GFP dataset is a source for high-quality representation learning, enabling PIFiA to learn universal feature profiles that can be used out-of-the-box or minimally fine-tuned to suit an external standard. Thus, PIFiA can accelerate the rate of supervised training on external tasks by producing feature profiles that can fit any downstream task with simple linear regression, replacing multiple task-specific convolutional networks.</p>
    <p id="Par58">The PIFiA workflow unites a self-supervised convolutional neural network with multiple techniques for downstream feature profile analysis. The key advantage of our self-supervised objective is its independence of human annotations and its ability to learn high-quality features and ignore imaging artifacts and cell positions (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>; Razdaibiedina et al, <xref ref-type="bibr" rid="CR49">2019</xref>; Sullivan et al, <xref ref-type="bibr" rid="CR58">2018</xref>).To ensure that PIFiA remembers solely the biologically relevant patterns, yet ignores cell positioning and replicate noise, we require the network to learn the actual GFP-tagged protein by predicting its identity. Overall, we show that features learned by PIFiA outperform another self-supervised method, Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>), that was used to analyze the yeast GFP collection and even reaches the performance of the supervised approach, DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>), in its target task.</p>
    <p id="Par59">We describe downstream analysis techniques that use PIFiA feature profiles to explore different levels of subcellular organization that span both protein-level and single-cell feature profiles. Of note, our analysis focuses not only on the construction of a whole-proteome hierarchical map, but also provides quantitative rules to obtain clusters corresponding to a specific level of cellular organization, such as subcellular localization or biological process, and to identify proteins with multiple localizations and interacting proteins. This type of unbiased analysis can reveal unexpected properties and potential functions of proteins that can be further explored experimentally. For example, we used PIFiA features taken from images of yeast cells expressing GFP-tagged proteins to identify sub-compartmental groups enriched for proteins with biological processes not previously known to have distinctive subcellular localization patterns (Fig. <xref rid="Fig3" ref-type="fig">3E,F</xref>). We found that in addition to the known pan-nuclear localization, proteasome components are also localized at the nuclear periphery, a result we confirmed with co-localization experiments (Fig. <xref rid="Fig11" ref-type="fig">EV5</xref>). Nuclear periphery localization of proteasomes has not been reported in yeast, but an in situ cryo-electron tomography study in <italic>Chlamydomonas</italic> found nuclear 26S proteasomes crowding around nuclear pore complexes (Albert et al, <xref ref-type="bibr" rid="CR2">2017</xref>). The role of proteasomes at the nuclear periphery may be to regulate transcription and/or to degrade proteins transiting the nuclear pore complex (Albert et al, <xref ref-type="bibr" rid="CR2">2017</xref>).</p>
    <p id="Par60">We also identified a group of proteins that localized specifically at the cell periphery of mother cells and were depleted from the growing bud. Budding yeast divide asymmetrically, with a replicative lifespan of 20–30 generations, where each division gives rise to a daughter whose replicative lifespan is reset and a mother who continues to age (He et al, <xref ref-type="bibr" rid="CR21">2018</xref>). Mother-specific cell periphery localization is achieved when three conditions are fulfilled (Eldakak et al, <xref ref-type="bibr" rid="CR14">2010</xref>). First, mother-specific proteins lack diffusive mobility in the plasma membrane. Second, newly synthesized proteins are deposited specifically in the growing bud. Third, the genes encoding these mother-specific proteins are expressed late in the cell cycle, so for cells in S/G<sub>2</sub> (small-budded cells) protein is detectable only in the mother. These steps ensure that the new and old pools of these proteins become spatially segregated during asymmetric division. Indeed, mother-specific localization of cell periphery proteins has been proposed to play a role in aging, with the daughter cell getting the newly synthesized copies of the protein, and the older and potentially more damaged copies inherited by the aging mother (Eldakak et al, <xref ref-type="bibr" rid="CR14">2010</xref>). Our set of asymmetrically segregating proteins includes 7 proteins previously seen to have mother-specific localization, plus 14 novel mother-specific proteins, including other transporters, proteins with roles in signaling, and 3 uncharacterized cell surface proteins (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref>). It is possible that accumulation of old and damaged versions of these newly identified proteins may also play a role in mother-specific aging.</p>
    <p id="Par61">We also applied PIFiA features for the identification of interacting proteins and members of protein complexes. To accomplish this, we used an adaptive thresholding method for single-cell clustering that exploits the biological properties of protein–protein interactions and microscopy data, outperforming conventional clustering methods for identifying members of protein complexes. We show that proteins whose single-cell PIFiA features are indistinguishable can be members of the same protein complex, have PPIs with each other, or have functionally related biological roles. A similar approach, <italic>cytoself</italic> (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>), was used to visually separate protein complexes from different compartments in human cells. Like the PIFiA pipeline, its self-supervised training scheme requires no pre-existing knowledge or categories, allowing it to reveal a highly resolved protein subcellular localization atlas that summarizes the major scales of cell organization (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>). Both the <italic>cytoself</italic> study and our work validate image-based feature profiles for downstream studies of protein organization and function in eukaryotic cells, both yeast (this work) and human cells (Kobayashi et al, <xref ref-type="bibr" rid="CR32">2022</xref>). Notably, we demonstrate that PIFiA can distinguish protein complexes from the same compartment in yeast cells, which are 5 to 30-fold smaller in size than human cells, providing a quantitative approach for downstream analysis and identification of functionally related proteins. Another study has implemented a similar representation learning paradigm to learn feature profiles of the images of cells with chemical or genetic perturbations (Moshkov et al, <xref ref-type="bibr" rid="CR45">2024</xref>) where perturbations were used as training labels. Thus, perturbation phenotypes were learned as inner representations from the network, suggesting that such a training scheme is effective for various types of experiments and biological systems.</p>
    <p id="Par62">In summary, the PiFiA pipeline extracts high-quality functional information about proteins from cell images in a quantitative form, without relying on pre-existing labels or manual annotations. In essence, the approach performs in silico colocalization, when two or more biological entities, such as proteins, are analyzed for similarity based on their respective localization patterns or positions within a cell (Dunn et al, <xref ref-type="bibr" rid="CR13">2011</xref>). In contrast to experimental colocalization, which is time-consuming and expensive, in silico colocalization can be performed within seconds for multiple proteins at a time. In the case of PIFiA, this can be achieved not only with high speed but also with remarkable precision. Overall, PIFiA can be used to identify properties of proteins in single cells, including similarity and variability, that have the potential to inspire new experiments to uncover novel biological insights.</p>
  </sec>
  <sec id="Sec13">
    <title>Methods</title>
    <sec id="Sec14">
      <title>Construction of mutant arrays for imaging</title>
      <p id="Par63">For imaging screens, BY5299 (<italic>MAT</italic>α <italic>his3Δ1 leu2Δ0 ura3Δ0 met15Δ0</italic> lyp1pr::TDH3pr-E2-Crimson::HPH::<italic>lyp1</italic>Δ <italic>can1</italic>pr::TDH3pr-tdTomato-NLS::<italic>URA3</italic>::<italic>can1</italic>Δ::STE2pr-<italic>LEU2)</italic> was used as the starting query strain. E2-Crimson and td-Tomato-NLS are used as cytosolic and nuclear markers, respectively. The starting strain was crossed to the <italic>MAT</italic>a ORF-GFP (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>) and haploid strains carrying both the red fluorescent protein markers and the ORF-GFP were selected using the SGA method (Tong and Boone, <xref ref-type="bibr" rid="CR62">2006</xref>). All SGA selection steps were conducted at 30 °C, except sporulation, which was conducted at 22 °C for 10 days. The screen was performed in two biological replicates. We successfully constructed strains with 4049 (97.4%) GFP-tagged genes out of 4156 strains in the ORF-GFP collection. The missing GFP strains include those in linkage groups for <italic>CAN1</italic> and <italic>LYP1</italic>, as occurs in all SGA-derived collections. Other missing strains were those we were unable to grow from our original stocks. The missing strains had no bias for protein abundance (Ho et al, <xref ref-type="bibr" rid="CR22">2018</xref>). By GO cellular component, they were enriched for mitochondrial <italic>cytochrome complex</italic> (6 genes; Bonferroni corrected <italic>P</italic> value = 0.000368).</p>
    </sec>
    <sec id="Sec15">
      <title>High-throughput microscopy</title>
      <p id="Par64">Yeast cultures were prepared for microscopy and imaged as previously described (Chong et al, <xref ref-type="bibr" rid="CR6">2015</xref>; Cox et al, <xref ref-type="bibr" rid="CR8">2016</xref>; Mattiazzi Usaj et al, <xref ref-type="bibr" rid="CR39">2020</xref>). Briefly, haploid wild-type <italic>MAT</italic>a strains expressing fluorescent protein fusions from SGA final selection plates were grown at 30 °C in low fluorescence synthetic minimal medium with Geneticin (200 μg/mL) and Noursoethricin (100 μg/ml). Cells were transferred to 384-well PerkinElmer CellCarrier Ultra imaging plates and centrifuged for 1 min at 500 g before imaging. Micrographs were obtained on an Opera Phenix (PerkinElmer) automated spinning disc confocal microscope. All imaging was done with a 63× water immersion objective. GFP was excited using a 488 nm laser and emission collected through a 520/35 nm filter. tdTomato was excited using a 561 nm laser, and emission collected through a 600/40 nm filter. E2Crimson was excited using a 640 nm laser, and emission collected through a 690/50 nm filter.</p>
    </sec>
    <sec id="Sec16">
      <title>Image acquisition for co-localization experiments</title>
      <p id="Par65">Protein pairs were chosen for co-localization if they had similar abundance (Ho et al, <xref ref-type="bibr" rid="CR22">2018</xref>) and localized to the same general subcellular compartment. For each protein, C-terminal fusions to both mNeonGreen and mScarlet were constructed as previously described (Meurer et al, <xref ref-type="bibr" rid="CR44">2018</xref>). Haploid cells in both configurations were mated to construct a/α diploids containing proteins tagged with the two fluorescent proteins. Diploid cells were grown and imaged in low fluorescence synthetic minimal media (Sheff and Thorn, <xref ref-type="bibr" rid="CR54">2004</xref>) supplemented with Hygromycin B (300 mg/mL), Geneticin (200 mg/mL), and 2% glucose. Cells were grown at 30 °C to mid-logarithmic phase and transferred to Concanavalin A-coated 384-well PerkinElmer CellCarrier Ultra imaging plates. Images were acquired at 22 °C using the Opera Phenix (PerkinElmer) automated spinning disc confocal microscope. Three image fields of 5 Z-stacks of optical sections 0.7 µm apart were taken for each well. Each field contained 100–150 cells, acquired using the 63× water immersion objective. mNeonGreen was excited using the 488 nM laser, with emissions collected through a 520/35 nm filter. mScarlet-I was excited using the 561 nm laser, with emissions collected through a 600/40 nm filter. Digital Phase Contrast was used for cell detection using LED bright field imaging. All images were assessed by visual inspection.</p>
    </sec>
    <sec id="Sec17">
      <title>Dataset overview and image preprocessing</title>
      <p id="Par66">Images of the 4049 strains expressing a GFP-tagged protein visible above background fluorescence were obtained using an automated confocal microscope as described above. Cell images were obtained from two biological replicates, each of which had four fields of view for each GFP-tagged strain.</p>
      <p id="Par67">As the first step of preprocessing, we computed cell centers’ coordinates across all images in the dataset using the nuclear channel. We obtained coordinates of the cells’ centers by segmenting the nuclear channel with a simple Watershed algorithm and computing <italic>x</italic>, <italic>y</italic> coordinates of the center of each cell’s nucleus (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>). We ignored cells with centers too close to the crop’s boundary (less than 10 pixels). Based on the cell center coordinates, we created single-cell crops of 64 × 64 pixels around those centers across all images in the dataset. We filtered crops that had GFP signal intensity less than the 5th percentile of the whole-proteome GFP intensity distribution, and crops dominated by the background noise (i.e., a uniform signal across the whole crop, with variance). After filtering low-quality crops, we dropped proteins with less than 10 cells, and we obtained 3,058,961 unique cells in the dataset. Then, the dataset was split into training, validation, and test sets using 80%, 10%, and 10% of the cells of each protein, respectively. The training subset contained 2,450,801 single-cell crops, and validation and test subsets contained 304,080 single-cell crops each. Finally, we applied instance normalization by standardizing the raw pixel intensities of every crop to a mean of 0 and a variance of 1 (independently for each channel of each sample). PIFiA was trained on 64 × 64 pixel crops of the GFP channel. During training, we used random flipping (horizontal and vertical) and random rotation across (0, 90, 180, 270) degrees to augment the training data. Labels of the training set are one-hot class vectors of length 4049.</p>
    </sec>
    <sec id="Sec18">
      <title>Architecture and training</title>
      <p id="Par68">The architecture details are illustrated in Fig. <xref rid="MOESM1" ref-type="media">S1A</xref>. The backbone of PIFiA consists of eight convolutional blocks followed by three fully-connected layers. Each convolutional block consists of a convolutional layer, batch normalization and rectified linear unit activation. Training was performed using Adam optimizer (Kingma and Ba, <xref ref-type="bibr" rid="CR30">2014</xref>) with a learning rate of 1e−3 and cosine decay learning rate schedule (number of steps equal to the number of training updates during 30 epochs), with cross-entropy as an objective function (<italic>y</italic><sub><italic>i</italic></sub> and <italic>ŷ</italic><sub><italic>i</italic></sub> are predicted probability and ground truth label of the protein <italic>i</italic>; <italic>N</italic> is the total number of classes, i.e.,4049 proteins):<disp-formula id="Equ1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L({\hat{{y}}}_{{i}},{y}_{i})=-{\sum }_{i=1}^{N}{y}_{i}\,\log {\hat{y}}_{i}$$\end{document}</tex-math><mml:math id="M2"><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mi>log</mml:mi><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><graphic xlink:href="44320_2024_29_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par69">To prevent overfitting, we applied dropout regularization (Srivastava et al, <xref ref-type="bibr" rid="CR56">2014</xref>) of 0.05 (5% dropout rate) after the second fully-connected layer (feature extraction layer). We performed hyperparameter optimization and selected the learning rate from {1e−4, 3e−4, 5e−4, 8e−4, 1e−3, 3e−3, 5e−3} and dropout rate from {0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5} based on maximal validation accuracy. Network parameters were initialized using a truncated normal distribution function with a standard deviation of 0.1. To report the performance, we ran the model three times with different random weights initializations; each run was 30 epochs and model weights were saved after every epoch. All the experiments were performed in Python using Tensorflow. The model was trained on the computing cluster of the Vector Institute for Artificial Intelligence, using NVIDIA T4 GPU with 12GB of VRAM, and up to 32GB of system RAM (single CPU). Source code and usage examples are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/arazd/pifia">https://github.com/arazd/pifia</ext-link>.</p>
      <p id="Par70">We used early stopping to select the final model (Girosi et al, <xref ref-type="bibr" rid="CR16">1995</xref>). We defined stopping criteria based on the model’s test accuracy of proteins classification across 4049 protein classes. We stop at an epoch where a derivative of the test accuracy becomes smaller than a threshold of 0.5% for at least 3 epochs, i.e., a point at which accuracy starts to saturate (Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>). Our goal was to stop at the point when the model has already grasped the most important morphological patterns, yet highly related and interacting proteins are not distinguished from each other. This trend is further illustrated by plots of average precision, F-score and precision (we show 0.9 threshold) for protein complexes and pathways standards (Fig. <xref rid="MOESM1" ref-type="media">S1B</xref>). With protein prediction accuracy increasing over the course of training, the precision improved, but after some epochs, AP and F-score either saturated or started to decline. We found that accuracy saturation thresholds between 0.2% and 0.7% yielded comparable and optimal solutions, though other stopping points can be used depending on the training schedule, as well as model applications and goals. The proposed early stopping strategy helped to prevent memorizing noise and unnecessary patterns, while retaining morphologically similar proteins close in the feature space.</p>
    </sec>
    <sec id="Sec19">
      <title>Benchmarking and baseline feature extraction</title>
      <p id="Par71">We compared performance of feature profiles learned by PIFiA to features from three other popular methods for protein representation learning/extraction—DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>), Paired Cell Inpainting (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>), and CellProfiler (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>).</p>
      <p id="Par72">A classic modular feature extraction tool, Cell Profiler (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>), was applied to the GFP and cytoplasmic channels of the test images across 4049 GFP-tagged proteins. We obtained 433 pre-defined CellProfiler features that quantitatively measure cellular phenotypes, including intensity, shape, and texture. Since some of the CellProfiler features can be repetitive, its representations are often post-processed with Principal Component Analysis (PCA) (Abdi and Williams, <xref ref-type="bibr" rid="CR1">2010</xref>). In our work, we evaluated both the original CellProfiler representation with 433 individual features, and its PCA projection (37 individual features) that explains 99% of the variance.</p>
      <p id="Par73">We used the DeepLoc model by Kraus et al, (<xref ref-type="bibr" rid="CR36">2017</xref>) as our supervised learning baseline. We investigated two training modes: (a) with per-protein localization labels from Huh et al, (<xref ref-type="bibr" rid="CR25">2003</xref>); (b) with single-cell localization labels manually annotated in our lab. Per-protein annotations can sometimes be subjective and might not capture the nuances of protein localization at a single-cell level accurately. Such annotations apply to all of single-cell images of a protein and are available for a significant part of the yeast proteome from the Huh et al, study (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>). In contrast, single-cell labels were manually annotated for the individual cell images by research scientists in our lab. While more precise, such labels are expensive and encompass a much smaller portion of the proteome. The original DeepLoc version uses single-cell labels. For a fair comparison, we used both single-cell and protein-level localization labels to train DeepLoc and reported the corresponding results.</p>
      <p id="Par74">Hence, we used two model variants: (a) the original version of DeepLoc (which was trained on a set of 21,882 single-cell crops with manually assigned labels; pre-trained weights provided by Kraus et al, (<xref ref-type="bibr" rid="CR36">2017</xref>), and (b) our adaptation of DeepLoc, DeepLoc+PIFiA, which was re-trained on a larger set of 1,432,774 images with less accurate protein-level labels instead of expensive yet more precise single-cell labels.</p>
      <p id="Par75">We trained DeepLoc+PIFiA from scratch on the GFP channel of the same training set images using 1,432,774 single-cell crops from 15 one-hot localization categories derived from Huh et al, (<xref ref-type="bibr" rid="CR25">2003</xref>). We performed hyperparameter optimization and selected the most optimal learning rate from {1e−4, 3e−4, 5e−4, 8e−4, 1e−3, 3e−3, 5e−3} and dropout rate from {0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5}. We chose 3e−4 learning rate with cosine decay learning rate schedule and 0.05 dropout rate based on maximal validation accuracy. The model was trained with Adam optimizer for 30 epochs (model weights were saved every epoch for subsequent evaluation), with cross-entropy as an objective function, <italic>y</italic><sub><italic>i</italic></sub>, <italic>ŷ</italic><sub><italic>i</italic></sub> are predicted probability and ground truth label of localization <italic>i</italic>, total <italic>N</italic> = 15 localization classes):<disp-formula id="Equ2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L({\hat{y}}_{i},\,{y}_{i})=-{\sum }_{i=1}^{N}{y}_{i}\log {\hat{y}}_{i}$$\end{document}</tex-math><mml:math id="M4"><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><graphic xlink:href="44320_2024_29_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par76">We also used early stopping to select the final DeepLoc+PIFiA model weights. DeepLoc+PIFiA model selection was based on maximal validation set accuracy. Network parameters were initialized using a truncated normal distribution function with a standard deviation of 0.1. We performed 3 runs with different random weights initializations and performed training with a batch size of 128. After training, we extracted features of the test set images from the last hidden layer of the DeepLoc+PIFiA model following previous studies (Razdaibiedina and Brechalov, <xref ref-type="bibr" rid="CR48">2022</xref>).</p>
      <p id="Par77">For our self-supervised learning baseline, we used the Paired Cell Inpainting method (Lu et al, <xref ref-type="bibr" rid="CR38">2019</xref>). Contrary to other models, Paired Cell Inpainting requires two channels for training—cytoplasmic background and target protein; hence we performed training of Paired Cell Inpainting using the GFP and cytoplasmic channels of the test images across 4049 GFP-tagged proteins. We used the exact same architecture and training objective described by Lu et al, (<xref ref-type="bibr" rid="CR38">2019</xref>). The objective function minimizes a standard pixel-wise mean-squared error loss between the predicted target protein <italic>ŝ</italic><sub><italic>t</italic></sub> and the actual target protein <italic>s</italic><sub><italic>t</italic></sub> (<italic>h</italic> and <italic>w</italic> are pixels across image width and height, respectively):<disp-formula id="Equ3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L({\hat{s}}_{t},\,{s}_{t})=\frac{1}{h\cdot w}{({\hat{s}}_{h,w,t}-{s}_{h,w,t})}^{2}$$\end{document}</tex-math><mml:math id="M6"><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>⋅</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><graphic xlink:href="44320_2024_29_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par78">We performed hyperparameter optimization and selected an optimal learning rate of 1e−4 from {1e−4, 3e−4, 5e−4, 8e−4, 1e−3, 3e−3, 5e−3}. The Model was trained with Adam optimizer for 30 epochs (3 runs in total), and model weights were saved every epoch for subsequent evaluation. We selected the final model with early stopping based on the minimal validation set loss. After training, we extracted feature profiles of the test set images by maximum pooling the output of an intermediate convolutional layer, across spatial dimensions, as suggested by Lu et al, (<xref ref-type="bibr" rid="CR38">2019</xref>).</p>
    </sec>
    <sec id="Sec20">
      <title>Evaluation of aFPs</title>
      <p id="Par79">Functional benchmarks used for assessment of the quality of the resulting feature profiles were derived from Gene Ontology Cellular Component (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>) (4045 protein annotations), Gene Ontology Slim Biological Process (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>) (3968 protein annotations), KEGG pathways (Kanehisa and Goto, <xref ref-type="bibr" rid="CR29">2000</xref>) (1422 protein annotations) and EMBL protein complexes (Meldal et al, <xref ref-type="bibr" rid="CR43">2015</xref>) (1402 protein annotations). Dubious ORFs and proteins without annotations were left out during comparison. To evaluate resulting features without further fine-tuning, we used strategies from two distinct perspectives: information retrieval and clustering quality.</p>
      <p id="Par80">Following standard practice, we computed pairwise distances across all available aFPs (4049 × 4049 distances in total) and sorted them from highest to lowest. Then protein pairs (which were not left out) were marked as positive if they had the same annotations, or negative otherwise, and AP and F-scores were computed. For proteins to be considered a positive pair, we required an exact agreement between labels in case of pathways and protein complexes standards, while for GO annotations we required at least 50% of the labels to overlap (due to high quantity of assigned labels). Results reported in Fig. <xref rid="Fig2" ref-type="fig">2B,C</xref> are based on ranking aFP pairs with correlation distance, and we found similar trends when using euclidean and cosine distances. We chose to continue analyses with the correlation metric due its lower susceptibility to fluctuations in individual feature values, and hence higher tolerance to outliers, which is a desirable property for the PIFiA workflow. For the clustering-driven benchmark, we clustered aFPs and compared clusters to the sets of proteins annotated to a certain term, and for each standard (we required cluster size to be at least 2 to be informative). For comparison, we applied AMI score (Vinh et al, <xref ref-type="bibr" rid="CR65">2010</xref>) between the resulting clusters and protein groups related to a certain term (with a higher score indicating more agreement between clusters and standard-defined categories). To obtain an AMI score for each method, we performed hierarchical clustering (with average linkage and correlation as a distance) of its per-protein representations and derived clusters across all similarity thresholds between 0.1 and 0.95 with a step of 0.05, and reported the maximal AMI across clusterings. For each deep learning model, feature profile evaluation was performed across 3 runs (results shown with bar plots in Fig. <xref rid="Fig2" ref-type="fig">2</xref>).</p>
    </sec>
    <sec id="Sec21">
      <title>Visualization of PIFiA feature profiles (aFPs and scFPs)</title>
      <p id="Par81">We used t-SNE (Van der Maaten and Hinton, <xref ref-type="bibr" rid="CR64">2008</xref>) for visualization of PIFiA feature profiles. We set the perplexity parameter to 40 for visualization of whole-proteome feature profiles averaged on the per-protein level (~4000 points) (Fig. <xref rid="Fig3" ref-type="fig">3C,D,F</xref>), and to 200 for visualizing single-cell feature profiles from the test set (&gt;100,000 points) (Fig. <xref rid="Fig5" ref-type="fig">5A</xref>). We represented the distribution of fundamental GO bioprocesses with a kernel-density estimate (KDE) using Gaussian kernels (Fig. <xref rid="Fig3" ref-type="fig">3D</xref>). We applied outlier filtering by removing points that do not lie within two standard deviations from the mean (across <italic>x</italic> or <italic>y</italic> t-SNE coordinates). We used Scott’s rule for KDE bandwidth selection (Scott, <xref ref-type="bibr" rid="CR51">1979</xref>).</p>
    </sec>
    <sec id="Sec22">
      <title>Hierarchical clustering with aFPs</title>
      <p id="Par82">We performed agglomerative hierarchical clustering (Murtagh and Contreras, <xref ref-type="bibr" rid="CR46">2012</xref>) of the whole-proteome aFPs (4049 in total) using correlation as a distance metric and average linkage. The optimal cut-off distance for the whole-proteome hierarchical clustering was determined using the AMI curve between clustering labels and provided standard annotations, following the diminishing returns principle to find the elbow point. At the optimal distance cutoff, the slope of the curve becomes negligible, indicating that the available clusters cover most of the standard’s functional groups. In Fig. <xref rid="Fig3" ref-type="fig">3</xref> we used GO Cellular Component annotations (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>) as a standard and calculated clustering labels at different correlation thresholds between 0 and 1, with a step of 0.01. Clustering was performed on the whole-proteome feature profiles, and AMI scores were calculated on a subset of proteins that had a single annotation according to GO Cellular Component. We identified an optimal cut-off point when the derivative of the AMI curve (calculated over 20 steps, starting at correlation of 1) was less than a threshold of 0.1. The proposed strategy can be used on different standards, without requiring annotations to cover all proteins (Appendix Fig. <xref rid="MOESM1" ref-type="media">S1A</xref>).</p>
    </sec>
    <sec id="Sec23">
      <title>Training logistic regression</title>
      <p id="Par83">To perform localization mapping, we trained a multinomial logistic regression (LR) using single-cell feature profiles obtained with PIFiA from the training set. We used supervised labels from 17 manually annotated localizations defined by Huh et al, (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>) (we left out “ambiguous” category and classes with 5 or less proteins), and limited our training set to proteins that had a single annotated localization. Overall, our training set consisted of 1,432,774 single-cell feature profiles and included 2415 proteins from mitochondrion (465), nucleus (472), cytoplasm (799), actin (27), ER (245), vacuole (95), bud neck (8), spindle pole (35), Golgi (15), peroxisome (20), vacuolar membrane (47), cell periphery (51), nuclear periphery (45), endosome (28), and nucleolus (63). We followed our previously described dataset split (each protein’s single-cell crops were split into train, validation, and test sets with 8:1:1 ratios). We used NVIDIA T4 GPU with 12GB of VRAM, and up to 16GB of system RAM on a single CPU to accelerate training; we trained LR for 5 epochs using Adam optimizer (Kingma and Ba, <xref ref-type="bibr" rid="CR30">2014</xref>) (1e−3 learning rate) and cross-entropy as a training loss; LR weights were saved after every epoch and we selected the final LR model with early stopping based on maximal validation set accuracy. Of note, after 2 epochs LR predictions stabilized and the difference between subsequent models was minimal (less than 3% test accuracy deviations).</p>
      <p id="Par84">To evaluate the quality of LR predictions, we compared its test set performance with DeepLoc (Kraus et al, <xref ref-type="bibr" rid="CR36">2017</xref>) (training procedure described in the benchmarking section). DeepLoc and LR were trained and evaluated on the sets of the same size and protein composition, with the only difference being DeepLoc used image crops for training, while LR using self-supervised scFPs from the pre-trained PIFiA model. Precision-recall curves for PIFiA LR and DeepLoc were generated on unseen scFPs and corresponding images from the test set of the single-localizing proteins (Fig. <xref rid="Fig8" ref-type="fig">EV2B</xref>).</p>
    </sec>
    <sec id="Sec24">
      <title>Sub-compartmental clustering with aFPs</title>
      <p id="Par85">We performed sub-compartmental clustering using single-localizing aFPs from the test set that were classified to the same localization by the previously described LR. For an aFP to be single-localizing, we required that its highest softmax probability was at least 0.6, and second-highest was no greater than 0.2 (more detailed analysis of single-localizing proteins and localization heterogeneity is described in the next section). We clustered aFPs of proteins that mapped to the same localization category and produced 15 per-compartment hierarchical trees (we used average linkage and correlation distance for clustering).</p>
      <p id="Par86">We calculated the Silhouette score (Rousseeuw, <xref ref-type="bibr" rid="CR50">1987</xref>) using scikit-learn library, as the mean intra-cluster distance (<italic>a</italic>) and the mean nearest-cluster distance (<italic>b</italic>) for each aFP. The Silhouette coefficient for a sample is (<italic>b</italic>−<italic>a</italic>)/max(<italic>a</italic>, <italic>b</italic>); <italic>b</italic> is the distance between a sample and the nearest cluster that the sample is not a part of. We surveyed 15 per-localization hierarchical trees, clustered with average linkage and correlation metric, using correlation thresholds between 0.25 and 0.75, with a step of 0.05. Median of Silhouette scores across all localizations for a given threshold is shown in Appendix Fig. <xref rid="MOESM1" ref-type="media">S1E</xref>. We found that thresholds between 0.5 and 0.6 yield maximal Silhouette scores, and a distance threshold of 0.5 corresponded to maximal GO bioprocess AMI value for whole-proteome aFPs clustering. Hence, we chose a 0.5 threshold to cluster aFPs belonging to each per-localization tree, and obtained 30 clusters, which we subsequently called sub-compartmental groups.</p>
    </sec>
    <sec id="Sec25">
      <title>Analysis of localization heterogeneity with scFPs</title>
      <p id="Par87">We used scFPs from the test set to analyze whole-proteome localization heterogeneity patterns. First, we used the pre-trained LR on 17 localization categories (described in the previous section) to map each protein’s test set scFPs to one of the 17 localization classes. We observed that the most probable localization class had an average 0.74 probability per protein (computed across all test set scFPs), while 2nd and 3rd classes scored 0.11 and 0.052 per-protein probabilities, respectively. This motivated us to perform heterogeneity analysis with the two most probable localization categories, to avoid low scFP quantities and potential noise effects. We then computed a mean probability across each localization class to determine the two most frequent localizations of the protein. Hence, for each protein X we obtained a distribution of 2-dimensional real-valued probability vectors [<italic>p</italic><sub><italic>i1</italic></sub>, <italic>p</italic><sub><italic>i2</italic></sub>] with <italic>p</italic><sub><italic>i1</italic></sub> and <italic>p</italic><sub><italic>i2</italic></sub> corresponding to the probabilities of the first and second most frequent localization classes, <italic>i</italic> ∈ {1, …, <italic>N</italic>}, <italic>N</italic> is the number of test set scFPs of the protein X. Given this distribution, we could compute whether protein X is single-localizing or has AND-type/OR-type localization heterogeneity. We filtered low-confidence scFPs <italic>i</italic>, whose sum of probabilities was below a confidence threshold: <italic>p</italic><sub><italic>i1</italic></sub> + <italic>p</italic><sub><italic>i2</italic></sub> &lt; α<sub>conf</sub> (low-confidence region). Next, based on a heterogeneity threshold β, we divided the rest of the scFPs into first localization if <italic>p</italic><sub><italic>i1</italic></sub> &gt; <italic>p</italic><sub><italic>i2</italic></sub> + β, second localization if <italic>p</italic><sub><italic>i2</italic></sub> &gt; <italic>p</italic><sub><italic>i1</italic></sub> + β, or mixed-localizing category otherwise. We varied values of α<sub>conf</sub> between 0.5 and 0.9, and values of β between 0.25 and 0.75 (with a step of 0.05), inspecting numbers of assignments into localization categories and low-confidence region, and selected α<sub>conf</sub> and β as 0.5 based on elbow point analysis. Hence, scFPs of each protein were mapped into one of four classes—primary localization, secondary localization, mixed localization or low-confidence region (Fig. <xref rid="Fig4" ref-type="fig">4D</xref>). If we assume that percentages of the corresponding categories for protein X are c<sub>1</sub>, c<sub>2</sub>, m, k (class 1, class 2, mixed and low-confidence, respectively), then protein X would be marked as AND-type localizing if the mixed category had a higher percentage of scFPs than primary and secondary localizations together: m &gt; c<sub>1</sub> + c<sub>2</sub>; otherwise protein X would be marked as OR-type if no less than 8% of scFPs belonged to the secondary localization: <italic>min</italic>(1, c<sub>2</sub>) &gt; 0.08, and single-localizing in the other case. We experimented with OR-type thresholds between 0.05 and 0.3 (with a step of 0.01), and found that the number of OR-type localizing proteins saturated between 0.07 and 0.1 thresholds. We selected 0.08 as an elbow point between <italic>min</italic>(1, c<sub>2</sub>) value and number of category assignments. Thus, each protein was marked as single-localizing, OR-type, AND-type, or undetermined (if too many scFPs were assigned as low-confidence).</p>
    </sec>
    <sec id="Sec26">
      <title>Cell cycle prediction and annotation with scFPs</title>
      <p id="Par88">We trained an ensemble of three CNNs for cell cycle classification using cytosolic and nuclear channels from our dataset. These two channels contained enough information to distinguish the cell cycle stage of a cell. The CNN contains four convolutional blocks followed by two fully-connected layers, and was trained to predict one of four cell cycle stages - G1, S, metaphase and anaphase (MA), or telophase (T) (Appendix Fig. <xref rid="MOESM1" ref-type="media">S2A</xref>).</p>
      <p id="Par89">We manually labeled 800 crops of cells from 103 different proteins, corresponding to distinct cell cycle stages (with 200 crops from each class) according to bud emergence; we used heavy data augmentation during training to prevent overfitting: rotation by arbitrary angle, vertical and horizontal flips, image zoom within 0.02 range, and vertical and horizontal shifts of up to 9 pixels. We used three-fold cross-validation. The training was performed on 64 × 64 × 2-dimensional crops over 150 epochs using Adam optimizer, with loss being a categorical cross-entropy across 4 cell cycle categories. We performed hyperparameter optimization to select learning rate (5e−4) and dropout rate (0.05). We performed 3 independent runs with random weights initialization (using truncated normal distribution with a standard deviation of 0.1). Model weights were saved after every epoch, and final models for each run were selected with early stopping based on maximal validation accuracy. Training and test accuracy and categorical cross-entropy loss are shown in Appendix Fig <xref rid="MOESM1" ref-type="media">S1</xref>. We created an ensemble of three CNNs (from epochs corresponding to minimal loss value), and subsequently mapped each single-cell crop to a 4-dimensional real-valued vector of cell cycle probabilities. The cell cycle probability vector was computed as an average of the probability vectors of three CNNs of that crop. We subsequently joined T and G1 categories due to high cell density in certain crops, which could potentially lead to an incorrect cell cycle category assignment.</p>
      <p id="Par90">We applied Mann–Whitney U test (McKnight and Najab, <xref ref-type="bibr" rid="CR41">2010</xref>) to identify proteins whose localization changes had cell cycle dependency. For each protein with localization heterogeneity, we annotated its single-cell crops from train, validation and test sets using both LR localization categories and cell cycle stages (via cell cycle classifier). We selected two primary annotated localizations, and compared cell cycle stage distribution of the corresponding crops. For each cell cycle stage, our null hypothesis was that the stage was equally represented among both localizations. Localizations with significant distribution differences (i.e. <italic>p</italic>-value &lt; 1e−3) were annotated as related to the particular cell cycle stage.</p>
    </sec>
    <sec id="Sec27">
      <title>Functional enrichment analysis</title>
      <p id="Par91">Gene Ontology (GO) enrichments were performed using GO-term Finder Version 0.86, available through the <italic>Saccharomyces cerevisiae</italic> Genome Database (<ext-link ext-link-type="uri" xlink:href="https://www.yeastgenome.org/goTermFinder">https://www.yeastgenome.org/goTermFinder</ext-link>). We applied gene set enrichment analysis (GSEA) using Python package GSEApy (Kuleshov et al, <xref ref-type="bibr" rid="CR37">2016</xref>) (<ext-link ext-link-type="uri" xlink:href="https://github.com/zqfang/GSEApy">https://github.com/zqfang/GSEApy</ext-link>) to analyze hierarchically clustered protein groups, sub-compartmental groups and sets of multi-localizing and mixed-localizing proteins (Dataset <xref rid="MOESM3" ref-type="media">EV2</xref> and <xref rid="MOESM4" ref-type="media">EV3</xref>). Query gene sets for GSEA included GO biological process, cellular component, and molecular function standards (Harris et al, <xref ref-type="bibr" rid="CR20">2004</xref>). GSEA results were filtered to include gene sets with <italic>p</italic>-values below 0.05 and a minimum gene set size of 2. We applied Bonferroni correction to obtain adjusted <italic>p</italic>-values. We also applied one-sided Fisher’s exact test with Costanzo group 19 (Costanzo et al, <xref ref-type="bibr" rid="CR7">2016</xref>) categories to analyse nucleus OR cytoplasm, nucleus AND cytoplasm gene sets, reporting protein sets with <italic>p</italic>-value &lt; 0.05 as the ones showing enrichment (Dataset <xref rid="MOESM4" ref-type="media">EV3</xref>).</p>
    </sec>
    <sec id="Sec28">
      <title>Discovery of interacting proteins from scFPs</title>
      <p id="Par92">We identified clusters containing potentially interacting proteins using two steps. First, we hierarchically clustered scFPs from the test set (we used average linkage and a correlation metric). After that, we divided the dendrogram from top to bottom and traced the number of unique proteins inside the cluster along with the division thresholds of 0.05 points. We found thresholds of the dendrogram at which the number of proteins in a cluster plateaus (95% of protein composition remains the same). After such “morphologically inseparable” clusters were identified, we used three data-driven scores to measure the quality of the resulting clusters—cell ratio, elbow point, and child ratio. Cell ratio <italic>c</italic> is an average percentage of a protein’s cells that fall into a particular cluster. A higher cell ratio translates into less dispersed cells of the same protein, and more confident protein assignment into the particular cluster. Elbow point <italic>k</italic> is a clustering distance at the level of the current cut (1-PCC in our case). A lower elbow point corresponds to a smaller distance between proteins in their feature profiles space. Descendant ratio <italic>d</italic> of the particular root cluster is the percentage of its descendent clusters that were annotated to the same root. A high child ratio corresponds to more agreement of the child clusters, hence indicating a more confident prediction. We devise a final score <italic>s</italic> as follows:<disp-formula id="Equ4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s=\frac{c\cdot d}{k}$$\end{document}</tex-math><mml:math id="M8"><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:mo>⋅</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="44320_2024_29_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par93">We used a final score cutoff of 0.6 to produce a list of 88 high-confidence clusters. We compared performance of our adaptive thresholding approach with clustering approaches from three different families—connectivity (hierarchical clustering (Murtagh and Contreras, <xref ref-type="bibr" rid="CR46">2012</xref>)) centroid (k-means (Sculley, <xref ref-type="bibr" rid="CR52">2010</xref>)) and density methods (DBSCAN (Ester et al, <xref ref-type="bibr" rid="CR15">1996</xref>)) (Fig. <xref rid="Fig5" ref-type="fig">5C</xref>). We performed clustering on the same test set of scFPs with different approaches. For each of the methods used in our comparison, we tried a range of hyperparameters (k ranging from 5 to 500 with a step of 5 in k-means, epsilon ranging from 0.1 to 5 with a step of 0.1 in DBSCAN, and correlation threshold ranging from 0.05 to 0.5 with a step of 0.025 for hierarchical clustering) and report the ones corresponding to the maximal median F1-score across all clusters. F1 scores were calculated by assigning each pair of scFPs ground truth label (0 or 1 depending on whether they are part of the same protein complex) and predicted label (0 or 1 depending on whether they are part of the same cluster).</p>
    </sec>
    <sec id="Sec29">
      <title>Gradient maps</title>
      <p id="Par94">We applied the SmoothGrad method to obtain per-feature gradient maps of the input images (Smilkov et al, <xref ref-type="bibr" rid="CR55">2017</xref>). Original gradient maps <italic>m</italic><sub>c</sub>(<italic>x</italic>) compute the derivative of activation function <italic>S</italic> of the highest-scoring class <italic>c</italic> with respect to the input image <italic>x</italic>, and thus highlight pixels which influence classification decision:<disp-formula id="Equ5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${m}_{c}=\frac{\partial {S}_{c}(x)}{\partial x}$$\end{document}</tex-math><mml:math id="M10"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="44320_2024_29_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par95">Since we were interested in feature interpretation, but not interpreting the classification decision, we modified this computation. In our implementation of gradient map <italic>M</italic><sub><italic>i</italic></sub>(<italic>x</italic>), we take the derivative of specific feature <italic>f</italic><sub><italic>i</italic></sub> from the feature vector <italic>f</italic> with respect to the input image <italic>x</italic>:<disp-formula id="Equ6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${M}_{i}(x)=\frac{\partial {f}_{i}(x)}{\partial x}$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="44320_2024_29_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par96">Hence, our gradient maps highlight regions of the image that impact the value of the selected feature. SmoothGrad produces a gradient map <italic>M</italic><sub><italic>i</italic></sub>(<italic>x</italic>) by averaging a number of gradient maps obtained from an input image with added noise from Gaussian distribution <italic>N</italic>(0, <italic>σ</italic><sup>2</sup>) (with a mean 0 and a standard deviation <italic>σ</italic>):<disp-formula id="Equ7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{M}}_{i}(x)=\frac{1}{n}{\sum }_{i=1}^{n}{M}_{i}(x+N(0,\,{\sigma }^{2}))$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic xlink:href="44320_2024_29_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par97">We used <italic>n</italic> = 100 images and <italic>σ</italic> = 0.05 noise level.</p>
    </sec>
    <sec id="Sec30">
      <title>Generalization experiments</title>
      <p id="Par98">We performed generalization experiments by applying PIFiA out-of-the-box on two unseen yeast imaging datasets: CYCLoPS (Koh et al, <xref ref-type="bibr" rid="CR33">2015</xref>) and YeastRGB (Dubreuil et al, <xref ref-type="bibr" rid="CR12">2019</xref>).</p>
      <p id="Par99">CYCLoPS is a collection comprising more than 20 million cells of C terminal-tagged GFP images of 4144 proteins. To derive single-cell crops from this dataset, we applied the Watershed algorithm to the cytoplasmic channel and computed <italic>x</italic>, <italic>y</italic> coordinates of the center of each cell (McQuin et al, <xref ref-type="bibr" rid="CR42">2018</xref>) subsequently making 64 × 64 pixel crops around the centers. We only used GFP channel of the single-cell crops and performed per-image standardization of each crop.</p>
      <p id="Par100">The YeastRGB dataset is a collection of GFP-tagged microscopy screens produced using SWAT technology, where new-generation fluorescent reporters are fused at the N’ and C’ of open reading frames of over 4000 proteins. We used C’-tagged images (and excluded N’-tagged images) from the YeastRGB dataset to avoid performance mismatch related to the tag location since our training data has C’-tagged images. The YeastRGB database provides single-cell crops, from which we only used GFP channel images and performed per-image standardization of each crop.</p>
      <p id="Par101">For each dataset, we run single-cell crops through PIFiA and extracted scFPs. Next, we averaged scFPs to obtain aFPs for all proteins in the dataset. We used t-SNE (Van der Maaten and Hinton, <xref ref-type="bibr" rid="CR64">2008</xref>) for visualization of aFPs with perplexity = 40 and color-coded the resulting maps with the Huh et al, localization standard (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>).</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <sec id="Sec32">
      <title>Supplementary information</title>
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="44320_2024_29_MOESM1_ESM.pdf">
            <caption>
              <p>Appendix</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="44320_2024_29_MOESM2_ESM.xlsx">
            <caption>
              <p>Dataset EV1</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="44320_2024_29_MOESM3_ESM.xlsx">
            <caption>
              <p>Dataset EV2</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM4">
          <media xlink:href="44320_2024_29_MOESM4_ESM.xlsx">
            <caption>
              <p>Dataset EV3</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM5">
          <media xlink:href="44320_2024_29_MOESM5_ESM.xlsx">
            <caption>
              <p>Dataset EV4</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM6">
          <media xlink:href="44320_2024_29_MOESM6_ESM.pdf">
            <caption>
              <p>Peer Review File</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM7">
          <media xlink:href="44320_2024_29_MOESM7_ESM.pdf">
            <caption>
              <p>Expanded View Figures</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <app-group>
    <app id="App1">
      <sec id="Sec31">
        <title>Expanded view</title>
        <p id="Par102">
          <fig id="Fig7">
            <label>Figure EV1</label>
            <caption>
              <title>PIFiA network architecture and training settings.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig1" ref-type="fig">1</xref>. (<bold>A</bold>) Overview of the architecture of PIFiA convolutional network. (<bold>B</bold>) Left plot: test accuracies of three different runs over the course of training (X axis: epochs, Y axis: test accuracy). Smaller plots: average precision, F-score and precision on protein complexes and pathways standards (X axis: epochs, Y axis: corresponding score on test set). The purple line indicates point of early stopping, when accuracy starts to saturate (derivative of the test accuracy smaller than a threshold of 0.5%). (<bold>C</bold>) Bar graphs comparing the current PIFiA architecture with a common baseline, DenseNet-121, across four different standards (Gene Ontology Cellular Component, Gene Ontology Bioprocess Slim, KEGG Pathways, EBI Protein complexes) in terms of average precision, F-score and adjusted mutual information (assessed on aFPs of 4049 proteins). Error bars represent standard deviation from the mean across three network runs. (<bold>D</bold>) Bar graphs comparing PIFiA performance across different dimensions of the feature profiles (32, 52, 64, 80, 128).</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig7_ESM" id="d33e2590"/>
          </fig>
        </p>
        <p id="Par103">
          <fig id="Fig8">
            <label>Figure EV2</label>
            <caption>
              <title>Comparison of PIFiA annotations and existing localization standards.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig3" ref-type="fig">3</xref>. (<bold>A</bold>) Comparison of localization classification performance of DeepLoc versus PIFiA feature profiles coupled with a logistic regression. Precision-recall plots are shown for 15 subcellular localizations. (<bold>B</bold>) Whole-proteome aFPs tSNE colored by different annotations of subcellular localization: manual annotations from Huh et al, (<xref ref-type="bibr" rid="CR25">2003</xref>) (Huh et al, <xref ref-type="bibr" rid="CR25">2003</xref>), and computationally-derived annotations from EnsLoc, DeepLoc and PIFiA.</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig8_ESM" id="d33e2619"/>
          </fig>
        </p>
        <p id="Par104">
          <fig id="Fig9">
            <label>Figure EV3</label>
            <caption>
              <title>Generalization of PIFiA network to two unseen datasets.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig3" ref-type="fig">3</xref>. (<bold>A</bold>) Localization-colored tSNE on aFPs obtained from the CYCLoPS dataset. (<bold>B</bold>) Localization-colored tSNE on aFPs obtained from the YeastRGB dataset.</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig9_ESM" id="d33e2642"/>
          </fig>
        </p>
        <p id="Par105">
          <fig id="Fig10">
            <label>Figure EV4</label>
            <caption>
              <title>Examples of proteins from 30 different sub-compartmental groups.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig3" ref-type="fig">3</xref>. Each row corresponds to a sub-compartmental cluster (e.g. nuc-1, nuc-2). The relevant GFP-tagged protein is identified on each micrograph.</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig10_ESM" id="d33e2659"/>
          </fig>
        </p>
        <p id="Par106">
          <fig id="Fig11">
            <label>Figure EV5</label>
            <caption>
              <title>Colocalization assay for proteins from different sub-compartmental.</title>
              <p><bold>Related to Fig.</bold><xref rid="Fig3" ref-type="fig">3</xref>. Colocalization experiment results: representative micrographs of cells expressing mNeonGreen- (green images) or mScarlet- (red images) tagged proteins annotated to nucleus (top panel) or cell periphery (bottom panel) groups. Overlays of the mNeonGreen and mScarlet images are shown on the right of each triplet of images. The tagged proteins are indicated on the micrographs (scale bar shown bottom right).</p>
            </caption>
            <graphic position="anchor" xlink:href="44320_2024_29_Fig11_ESM" id="d33e2676"/>
          </fig>
        </p>
      </sec>
    </app>
  </app-group>
  <sec>
    <title>Supplementary information</title>
    <p>Expanded view data, supplementary information, appendices are available for this paper at 10.1038/s44320-024-00029-6.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank Oren Kraus, Michael Costanzo, Nil Sahin, Alan Moses, Leah Cowen, and Matej Usaj for valuable discussions and advice. This work was supported by grants from the National Institutes of Health (R01HG005853 to BA and CB), and the Canadian Institutes of Health Research (PJT-180259 to BA). Equipment for automated image acquisition and analysis was purchased using funds from the Canadian Foundation for Innovation and the Ontario Research Fund. JB was supported by the Canadian Institute for Advanced Research (CIFAR) AI Chairs program and the National Sciences and Engineering Research Council (Canada). We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Quadro P6000 GPU. Computational resources were provided, in part, by the Province of Ontario and the Government of Canada through the Vector Institute for Artificial Intelligence. AR was supported by the Province of Ontario (Ontario Graduate Scholarship, 2021–2022) and the Vector Institute for Artificial Intelligence (Vector Institute Postgraduate Affiliate Scholarship, 2019–2021). CB is a Fellow of the CIFAR.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p><bold>Anastasia Razdaibiedina</bold>: Conceptualization; Software; Formal analysis; Validation; Investigation; Visualization; Methodology; Writing—original draft; Writing—review and editing. <bold>Alexander Brechalov</bold>: Conceptualization; Software; Supervision; Methodology; Writing—original draft. <bold>Helena Friesen</bold>: Conceptualization; Formal analysis; Supervision; Validation; Methodology; Writing—original draft; Project administration; Writing—review and editing. <bold>Mojca Mattiazzi Usaj</bold>: Supervision; Writing—review and editing. <bold>Myra Paz David</bold><bold>Masinas</bold>: Software. <bold>Harsha Garadi Suresh</bold>: Resources. <bold>Kyle Wang</bold>: Resources. <bold>Charles Boone</bold>: Supervision. <bold>Jimmy Ba</bold>: Conceptualization; Supervision; Investigation; Methodology. <bold>Brenda Andrews</bold>: Supervision; Funding acquisition; Writing—review and editing.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The image data used in this work are available at the CellVision website (<ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia/">https://thecellvision.org/pifia/</ext-link>): The raw images: <ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia_files/pifia_raw_data.tar.gz">https://thecellvision.org/pifia_files/pifia_raw_data.tar.gz</ext-link>. The dataset of single-cell cropped images: (<ext-link ext-link-type="uri" xlink:href="https://thecellvision.org/pifia_files/pifia_single_cell_crops.tar.gz">https://thecellvision.org/pifia_files/pifia_single_cell_crops.tar.gz</ext-link>). Source code for the PIFiA network and downstream analysis is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/arazd/pifia">https://github.com/arazd/pifia</ext-link>.</p>
  </notes>
  <notes>
    <title>Disclosure and competing interests statement</title>
    <notes notes-type="COI-statement">
      <p>The authors declare no competing interests. Brenda J Andrews is a member of the Advisory Editorial Board of Molecular Systems Biology. This has no bearing on the editorial consideration of this article for publication.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Abdi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Williams</surname>
            <given-names>LJ</given-names>
          </name>
        </person-group>
        <article-title>Principal component analysis</article-title>
        <source>Wiley Interdiscip Rev Comput Stat</source>
        <year>2010</year>
        <volume>2</volume>
        <fpage>433</fpage>
        <lpage>459</lpage>
        <pub-id pub-id-type="doi">10.1002/wics.101</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Albert</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schaffer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Beck</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Mosalaganti</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Asano</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Thomas</surname>
            <given-names>HF</given-names>
          </name>
          <name>
            <surname>Plitzko</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Beck</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Baumeister</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Engel</surname>
            <given-names>BD</given-names>
          </name>
        </person-group>
        <article-title>Proteasomes tether to two distinct sites at the nuclear pore complex</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2017</year>
        <volume>114</volume>
        <fpage>13726</fpage>
        <lpage>13731</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1716305114</pub-id>
        <?supplied-pmid 29229809?>
        <pub-id pub-id-type="pmid">29229809</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sommer</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Hensel</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bussey</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Yeast KRE genes provide evidence for a pathway of cell wall beta-glucan assembly</article-title>
        <source>J Cell Biol</source>
        <year>1990</year>
        <volume>110</volume>
        <fpage>1833</fpage>
        <lpage>1843</lpage>
        <pub-id pub-id-type="doi">10.1083/jcb.110.5.1833</pub-id>
        <?supplied-pmid 2186051?>
        <pub-id pub-id-type="pmid">2186051</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <mixed-citation publication-type="other">Chen T, Kornblith S, Norouzi M, Hinton G (2020) A simple framework for contrastive learning of visual representations. In: Proceedings of the 37th international conference on machine learning, pp 1597–1607</mixed-citation>
    </ref>
    <ref id="CR5">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cho</surname>
            <given-names>NH</given-names>
          </name>
          <name>
            <surname>Cheveralls</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Brunner</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Michaelis</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Raghavan</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Kobayashi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Savy</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Canaj</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>OpenCell: Endogenous tagging for the cartography of human cellular organization</article-title>
        <source>Science</source>
        <year>2022</year>
        <volume>375</volume>
        <fpage>eabi6983</fpage>
        <pub-id pub-id-type="doi">10.1126/science.abi6983</pub-id>
        <?supplied-pmid 35271311?>
        <pub-id pub-id-type="pmid">35271311</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chong</surname>
            <given-names>YT</given-names>
          </name>
          <name>
            <surname>Koh</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Duffy</surname>
            <given-names>SK</given-names>
          </name>
          <name>
            <surname>Cox</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Moses</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Moffat</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Yeast proteome dynamics from single cell imaging and automated analysis</article-title>
        <source>Cell</source>
        <year>2015</year>
        <volume>161</volume>
        <fpage>1413</fpage>
        <lpage>1424</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2015.04.051</pub-id>
        <?supplied-pmid 26046442?>
        <pub-id pub-id-type="pmid">26046442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Costanzo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>VanderSluis</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Koch</surname>
            <given-names>EN</given-names>
          </name>
          <name>
            <surname>Baryshnikova</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Pons</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Tan</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Usaj</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hanchard</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>SD</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A global genetic interaction network maps a wiring diagram of cellular function</article-title>
        <source>Science</source>
        <year>2016</year>
        <volume>353</volume>
        <fpage>aaf1420</fpage>
        <pub-id pub-id-type="doi">10.1126/science.aaf1420</pub-id>
        <?supplied-pmid 27708008?>
        <pub-id pub-id-type="pmid">27708008</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cox</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>YT</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Liquid growth of arrayed fluorescently tagged Saccharomyces cerevisiae strains for live-cell high-throughput microscopy screens</article-title>
        <source>Cold Spring Harb Protoc</source>
        <year>2016</year>
        <volume>2016</volume>
        <fpage>pdb prot088799</fpage>
        <pub-id pub-id-type="doi">10.1101/pdb.prot088799</pub-id>
        <?supplied-pmid 27037071?>
        <pub-id pub-id-type="pmid">27037071</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Decottignies</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Grant</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Nichols</surname>
            <given-names>JW</given-names>
          </name>
          <name>
            <surname>de Wet</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>McIntosh</surname>
            <given-names>DB</given-names>
          </name>
          <name>
            <surname>Goffeau</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>ATPase and multidrug transport activities of the overexpressed yeast ABC protein Yor1p</article-title>
        <source>J Biol Chem</source>
        <year>1998</year>
        <volume>273</volume>
        <fpage>12612</fpage>
        <lpage>12622</lpage>
        <pub-id pub-id-type="doi">10.1074/jbc.273.20.12612</pub-id>
        <?supplied-pmid 9575223?>
        <pub-id pub-id-type="pmid">9575223</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <mixed-citation publication-type="other">Deng J, Dong W, Socher R, Li L-J, Li K, Fei-Fei L (2009) Imagenet: a large-scale hierarchical image database. In: IEEE conference on computer vision and pattern recognition (CVPR) 248–255</mixed-citation>
    </ref>
    <ref id="CR11">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deshpande</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Keusch</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Challa</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Iesmantavicius</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Gasser</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Gut</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>The Sir4 H-BRCT domain interacts with phospho-proteins to sequester and repress yeast heterochromatin</article-title>
        <source>EMBO J</source>
        <year>2019</year>
        <volume>38</volume>
        <fpage>e101744</fpage>
        <pub-id pub-id-type="doi">10.15252/embj.2019101744</pub-id>
        <?supplied-pmid 31515872?>
        <pub-id pub-id-type="pmid">31515872</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dubreuil</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Sass</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Nadav</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Heidenreich</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Georgeson</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Weill</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Meurer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Schuldiner</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Knop</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>YeastRGB: comparing the abundance and localization of yeast proteins across cells and libraries</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <fpage>D1245</fpage>
        <lpage>D1249</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky941</pub-id>
        <?supplied-pmid 30357397?>
        <pub-id pub-id-type="pmid">30357397</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dunn</surname>
            <given-names>KW</given-names>
          </name>
          <name>
            <surname>Kamocka</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>McDonald</surname>
            <given-names>JH</given-names>
          </name>
        </person-group>
        <article-title>A practical guide to evaluating colocalization in biological microscopy</article-title>
        <source>Am J Physiol Cell Physiol</source>
        <year>2011</year>
        <volume>300</volume>
        <fpage>C723</fpage>
        <lpage>742</lpage>
        <pub-id pub-id-type="doi">10.1152/ajpcell.00462.2010</pub-id>
        <?supplied-pmid 21209361?>
        <pub-id pub-id-type="pmid">21209361</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Eldakak</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Rancati</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Rubinstein</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Paul</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Conaway</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Asymmetrically inherited multidrug resistance transporters are recessive determinants in cellular replicative ageing</article-title>
        <source>Nat Cell Biol</source>
        <year>2010</year>
        <volume>12</volume>
        <fpage>799</fpage>
        <lpage>805</lpage>
        <pub-id pub-id-type="doi">10.1038/ncb2085</pub-id>
        <?supplied-pmid 20657593?>
        <pub-id pub-id-type="pmid">20657593</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <mixed-citation publication-type="other">Ester M, Kriegel H, Sander J, Xu X (1996) A density-based algorithm for discovering clusters in large spatial databases with noise. In: KDD'96: Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 226–231</mixed-citation>
    </ref>
    <ref id="CR16">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Girosi</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Poggio</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Regularization theory and neural networks architectures</article-title>
        <source>Neural Comput</source>
        <year>1995</year>
        <volume>7</volume>
        <fpage>219</fpage>
        <lpage>269</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1995.7.2.219</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grys</surname>
            <given-names>BT</given-names>
          </name>
          <name>
            <surname>Lo</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Sahin</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Kraus</surname>
            <given-names>OZ</given-names>
          </name>
          <name>
            <surname>Morris</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Machine learning and computer vision approaches for phenotypic profiling</article-title>
        <source>J Cell Biol</source>
        <year>2017</year>
        <volume>216</volume>
        <fpage>65</fpage>
        <lpage>71</lpage>
        <pub-id pub-id-type="doi">10.1083/jcb.201610026</pub-id>
        <?supplied-pmid 27940887?>
        <pub-id pub-id-type="pmid">27940887</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Yeh</surname>
            <given-names>LH</given-names>
          </name>
          <name>
            <surname>Folkesson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ivanov</surname>
            <given-names>IE</given-names>
          </name>
          <name>
            <surname>Krishnan</surname>
            <given-names>AP</given-names>
          </name>
          <name>
            <surname>Keefe</surname>
            <given-names>MG</given-names>
          </name>
          <name>
            <surname>Hashemi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Shin</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Chhun</surname>
            <given-names>BB</given-names>
          </name>
          <name>
            <surname>Cho</surname>
            <given-names>NH</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Revealing architectural order with quantitative label-free imaging and deep learning</article-title>
        <source>Elife</source>
        <year>2020</year>
        <volume>9</volume>
        <fpage>e55502</fpage>
        <pub-id pub-id-type="doi">10.7554/eLife.55502</pub-id>
        <?supplied-pmid 32716843?>
        <pub-id pub-id-type="pmid">32716843</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Haase</surname>
            <given-names>SB</given-names>
          </name>
          <name>
            <surname>Wittenberg</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Topology and control of the cell-cycle-regulated transcriptional circuitry</article-title>
        <source>Genetics</source>
        <year>2014</year>
        <volume>196</volume>
        <fpage>65</fpage>
        <lpage>90</lpage>
        <pub-id pub-id-type="doi">10.1534/genetics.113.152595</pub-id>
        <?supplied-pmid 24395825?>
        <pub-id pub-id-type="pmid">24395825</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Harris</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Clark</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ireland</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lomax</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ashburner</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Foulger</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Eilbeck</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Lewis</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Marshall</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Mungall</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The Gene Ontology (GO) database and informatics resource</article-title>
        <source>Nucleic Acids Res</source>
        <year>2004</year>
        <volume>32</volume>
        <fpage>D258</fpage>
        <lpage>261</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkh036</pub-id>
        <?supplied-pmid 14681407?>
        <pub-id pub-id-type="pmid">14681407</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Kennedy</surname>
            <given-names>BK</given-names>
          </name>
        </person-group>
        <article-title>The yeast replicative aging model</article-title>
        <source>Biochim Biophys Acta Mol Basis Dis</source>
        <year>2018</year>
        <volume>1864</volume>
        <fpage>2690</fpage>
        <lpage>2696</lpage>
        <pub-id pub-id-type="doi">10.1016/j.bbadis.2018.02.023</pub-id>
        <?supplied-pmid 29524633?>
        <pub-id pub-id-type="pmid">29524633</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ho</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Baryshnikova</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Brown</surname>
            <given-names>GW</given-names>
          </name>
        </person-group>
        <article-title>Unification of protein abundance datasets yields a quantitative Saccharomyces cerevisiae proteome</article-title>
        <source>Cell Syst</source>
        <year>2018</year>
        <volume>6</volume>
        <fpage>192</fpage>
        <lpage>205.e193</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2017.12.004</pub-id>
        <?supplied-pmid 29361465?>
        <pub-id pub-id-type="pmid">29361465</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Pho85, a multifunctional cyclin-dependent protein kinase in budding yeast</article-title>
        <source>Mol Microbiol</source>
        <year>2007</year>
        <volume>66</volume>
        <fpage>303</fpage>
        <lpage>314</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1365-2958.2007.05914.x</pub-id>
        <?supplied-pmid 17850263?>
        <pub-id pub-id-type="pmid">17850263</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <mixed-citation publication-type="other">Huang G, Liu Z, Van Der Maaten L, Weinberger KQ (2017) Densely connected convolutional networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 4700–4708</mixed-citation>
    </ref>
    <ref id="CR25">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huh</surname>
            <given-names>WK</given-names>
          </name>
          <name>
            <surname>Falvo</surname>
            <given-names>JV</given-names>
          </name>
          <name>
            <surname>Gerke</surname>
            <given-names>LC</given-names>
          </name>
          <name>
            <surname>Carroll</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>Howson</surname>
            <given-names>RW</given-names>
          </name>
          <name>
            <surname>Weissman</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>O’Shea</surname>
            <given-names>EK</given-names>
          </name>
        </person-group>
        <article-title>Global analysis of protein localization in budding yeast</article-title>
        <source>Nature</source>
        <year>2003</year>
        <volume>425</volume>
        <fpage>686</fpage>
        <lpage>691</lpage>
        <pub-id pub-id-type="doi">10.1038/nature02026</pub-id>
        <?supplied-pmid 14562095?>
        <pub-id pub-id-type="pmid">14562095</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jaiswal</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Babu</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Zadeh</surname>
            <given-names>MZ</given-names>
          </name>
          <name>
            <surname>Banerjee</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Makedon</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>A survey on contrastive self-supervised learning</article-title>
        <source>Technologies</source>
        <year>2020</year>
        <volume>9</volume>
        <fpage>2</fpage>
        <pub-id pub-id-type="doi">10.3390/technologies9010002</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <mixed-citation publication-type="other">Jenni S, Favaro P (2018) Self-supervised feature learning by learning to spot artifacts. In: IEEE/CVF conference on computer vision and pattern recognition (CVPR) 2733–2742</mixed-citation>
    </ref>
    <ref id="CR28">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jing</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Self-supervised visual feature learning with deep neural networks: a survey</article-title>
        <source>IEEE Tran Pattern Anal Mach Intell</source>
        <year>2020</year>
        <volume>43</volume>
        <fpage>4037</fpage>
        <lpage>4058</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2020.2992393</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kanehisa</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Goto</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>KEGG: kyoto encyclopedia of genes and genomes</article-title>
        <source>Nucleic Acids Res</source>
        <year>2000</year>
        <volume>28</volume>
        <fpage>27</fpage>
        <lpage>30</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/28.1.27</pub-id>
        <?supplied-pmid 10592173?>
        <pub-id pub-id-type="pmid">10592173</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <mixed-citation publication-type="other">Kingma DP, Ba J (2014) Adam: a method for stochastic optimization. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</ext-link></mixed-citation>
    </ref>
    <ref id="CR31">
      <mixed-citation publication-type="other">Kingma DP, Welling M (2013) Auto-encoding variational bayes. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</ext-link></mixed-citation>
    </ref>
    <ref id="CR32">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kobayashi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Cheveralls</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Leonetti</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Royer</surname>
            <given-names>LA</given-names>
          </name>
        </person-group>
        <article-title>Self-supervised deep learning encodes high-resolution features of protein subcellular localization</article-title>
        <source>Nat Methods</source>
        <year>2022</year>
        <volume>19</volume>
        <fpage>995</fpage>
        <lpage>1003</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-022-01541-z</pub-id>
        <?supplied-pmid 35879608?>
        <pub-id pub-id-type="pmid">35879608</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Koh</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>YT</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Moses</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
          <name>
            <surname>Moffat</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>CYCLoPs: a comprehensive database constructed from automated analysis of protein abundance and subcellular localization patterns in Saccharomyces cerevisiae</article-title>
        <source>G3</source>
        <year>2015</year>
        <volume>5</volume>
        <fpage>1223</fpage>
        <lpage>1232</lpage>
        <pub-id pub-id-type="doi">10.1534/g3.115.017830</pub-id>
        <?supplied-pmid 26048563?>
        <pub-id pub-id-type="pmid">26048563</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <mixed-citation publication-type="other">Kolesnikov A, Zhai X, Beyer L (2019) Revisiting self-supervised visual representation learning. In: IEEE/CVF conference on computer vision and pattern recognition 1920–1929</mixed-citation>
    </ref>
    <ref id="CR35">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kraus</surname>
            <given-names>OZ</given-names>
          </name>
          <name>
            <surname>Ba</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Frey</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Classifying and segmenting microscopy images with deep multiple instance learning</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <fpage>i52</fpage>
        <lpage>i59</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw252</pub-id>
        <?supplied-pmid 27307644?>
        <pub-id pub-id-type="pmid">27307644</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kraus</surname>
            <given-names>OZ</given-names>
          </name>
          <name>
            <surname>Grys</surname>
            <given-names>BT</given-names>
          </name>
          <name>
            <surname>Ba</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Frey</surname>
            <given-names>BJ</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Automated analysis of high-content microscopy data with deep learning</article-title>
        <source>Mol Syst Biol</source>
        <year>2017</year>
        <volume>13</volume>
        <fpage>924</fpage>
        <pub-id pub-id-type="doi">10.15252/msb.20177551</pub-id>
        <?supplied-pmid 28420678?>
        <pub-id pub-id-type="pmid">28420678</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kuleshov</surname>
            <given-names>MV</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>MR</given-names>
          </name>
          <name>
            <surname>Rouillard</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Fernandez</surname>
            <given-names>NF</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Koplev</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Jenkins</surname>
            <given-names>SL</given-names>
          </name>
          <name>
            <surname>Jagodnik</surname>
            <given-names>KM</given-names>
          </name>
          <name>
            <surname>Lachmann</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Enrichr: a comprehensive gene set enrichment analysis web server 2016 update</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <fpage>W90</fpage>
        <lpage>97</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw377</pub-id>
        <?supplied-pmid 27141961?>
        <pub-id pub-id-type="pmid">27141961</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>AX</given-names>
          </name>
          <name>
            <surname>Kraus</surname>
            <given-names>OZ</given-names>
          </name>
          <name>
            <surname>Cooper</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Moses</surname>
            <given-names>AM</given-names>
          </name>
        </person-group>
        <article-title>Learning unsupervised feature representations for single cell microscopy images with paired cell inpainting</article-title>
        <source>PLoS Comput Biol</source>
        <year>2019</year>
        <volume>15</volume>
        <fpage>e1007348</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1007348</pub-id>
        <?supplied-pmid 31479439?>
        <pub-id pub-id-type="pmid">31479439</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mattiazzi Usaj</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sahin</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Pons</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Usaj</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Masinas</surname>
            <given-names>MPD</given-names>
          </name>
          <name>
            <surname>Shuteriqi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Shkurin</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Aloy</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Morris</surname>
            <given-names>Q</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Systematic genetics and single-cell imaging reveal widespread morphological pleiotropy and cell-to-cell variability</article-title>
        <source>Mol Syst Biol</source>
        <year>2020</year>
        <volume>16</volume>
        <fpage>e9243</fpage>
        <pub-id pub-id-type="doi">10.15252/msb.20199243</pub-id>
        <?supplied-pmid 32064787?>
        <pub-id pub-id-type="pmid">32064787</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mattiazzi Usaj</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Styles</surname>
            <given-names>EB</given-names>
          </name>
          <name>
            <surname>Verster</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>High-content screening for quantitative cell biology</article-title>
        <source>Trends Cell Biol</source>
        <year>2016</year>
        <volume>26</volume>
        <fpage>598</fpage>
        <lpage>611</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tcb.2016.03.008</pub-id>
        <?supplied-pmid 27118708?>
        <pub-id pub-id-type="pmid">27118708</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <mixed-citation publication-type="other">McKnight PE, Najab J (2010) Mann-Whitney U test. The corsini encyclopedia of psychology. Wiley</mixed-citation>
    </ref>
    <ref id="CR42">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>McQuin</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Goodman</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Chernyshev</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Kamentsky</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Cimini</surname>
            <given-names>BA</given-names>
          </name>
          <name>
            <surname>Karhohs</surname>
            <given-names>KW</given-names>
          </name>
          <name>
            <surname>Doan</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Rafelski</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Thirstrup</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>CellProfiler 3.0: next-generation image processing for biology</article-title>
        <source>PLoS Biol</source>
        <year>2018</year>
        <volume>16</volume>
        <fpage>e2005970</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.2005970</pub-id>
        <?supplied-pmid 29969450?>
        <pub-id pub-id-type="pmid">29969450</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meldal</surname>
            <given-names>BH</given-names>
          </name>
          <name>
            <surname>Forner-Martinez</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Costanzo</surname>
            <given-names>MC</given-names>
          </name>
          <name>
            <surname>Dana</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Demeter</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Dumousseau</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dwight</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Gaulton</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Licata</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Melidoni</surname>
            <given-names>AN</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The complex portal-an encyclopaedia of macromolecular complexes</article-title>
        <source>Nucleic Acids Res</source>
        <year>2015</year>
        <volume>43</volume>
        <fpage>D479</fpage>
        <lpage>484</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gku975</pub-id>
        <?supplied-pmid 25313161?>
        <pub-id pub-id-type="pmid">25313161</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meurer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Sass</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Kats</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Herbst</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Buchmuller</surname>
            <given-names>BC</given-names>
          </name>
          <name>
            <surname>Dederer</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Huber</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Kirrmaier</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Stefl</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Genome-wide C-SWAT library for high-throughput yeast genome tagging</article-title>
        <source>Nat Methods</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>598</fpage>
        <lpage>600</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-018-0045-8</pub-id>
        <?supplied-pmid 29988096?>
        <pub-id pub-id-type="pmid">29988096</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <mixed-citation publication-type="other">Moshkov N, Bornholdt M, Benoit S, Smith M, McQuin C, Goodman A, Senft RA, Han Y, Babadi M, Horvath P et al (2024) Learning representations for image-based profiling of perturbations. Nat Commun 15:1594</mixed-citation>
    </ref>
    <ref id="CR46">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Murtagh</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Contreras</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Algorithms for hierarchical clustering: an overview</article-title>
        <source>Wiley Interdiscip Rev Data Min Knowl Discov</source>
        <year>2012</year>
        <volume>2</volume>
        <fpage>86</fpage>
        <lpage>97</lpage>
        <pub-id pub-id-type="doi">10.1002/widm.53</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Neuber</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Jarosch</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Volkwein</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Walter</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sommer</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Ubx2 links the Cdc48 complex to ER-associated protein degradation</article-title>
        <source>Nat Cell Biol</source>
        <year>2005</year>
        <volume>7</volume>
        <fpage>993</fpage>
        <lpage>998</lpage>
        <pub-id pub-id-type="doi">10.1038/ncb1298</pub-id>
        <?supplied-pmid 16179953?>
        <pub-id pub-id-type="pmid">16179953</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <mixed-citation publication-type="other">Razdaibiedina A, Brechalov A (2022) Learning multi-scale functional representations of proteins from single-cell microscopy data. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2205.11676">https://arxiv.org/abs/2205.11676</ext-link></mixed-citation>
    </ref>
    <ref id="CR49">
      <mixed-citation publication-type="other">Razdaibiedina A, Velayutham J, Modi M (2019) Multi-defect microscopy image restoration under limited data conditions. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1910.14207">https://arxiv.org/abs/1910.14207</ext-link></mixed-citation>
    </ref>
    <ref id="CR50">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rousseeuw</surname>
            <given-names>PJ</given-names>
          </name>
        </person-group>
        <article-title>Silhouettes: a graphical aid to the interpretation and validation of cluster analysis</article-title>
        <source>J Comput Appl Math</source>
        <year>1987</year>
        <volume>20</volume>
        <fpage>53</fpage>
        <lpage>65</lpage>
        <pub-id pub-id-type="doi">10.1016/0377-0427(87)90125-7</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scott</surname>
            <given-names>DW</given-names>
          </name>
        </person-group>
        <article-title>On optimal and data-based histograms</article-title>
        <source>Biometrika</source>
        <year>1979</year>
        <volume>66</volume>
        <fpage>605</fpage>
        <lpage>610</lpage>
        <pub-id pub-id-type="doi">10.1093/biomet/66.3.605</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <mixed-citation publication-type="other">Sculley D (2010) Web-scale k-means clustering. In: WWW ‘10: Proceedings of the 19th international conference on World wide web, pp 1177–1178</mixed-citation>
    </ref>
    <ref id="CR53">
      <mixed-citation publication-type="other">Selvaraju RR, Das A, Vedantam R, Cogswell M, Parikh D, Batra D (2016) Grad-Cam: Why Did You Say That? Visual Explanations from Deep Networks via Gradient-Based Localization. 2017 IEEE International Conference on Computer Vision, Venice, Italy, 618–626</mixed-citation>
    </ref>
    <ref id="CR54">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sheff</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Thorn</surname>
            <given-names>KS</given-names>
          </name>
        </person-group>
        <article-title>Optimized cassettes for fluorescent protein tagging in Saccharomyces cerevisiae</article-title>
        <source>Yeast</source>
        <year>2004</year>
        <volume>21</volume>
        <fpage>661</fpage>
        <lpage>670</lpage>
        <pub-id pub-id-type="doi">10.1002/yea.1130</pub-id>
        <?supplied-pmid 15197731?>
        <pub-id pub-id-type="pmid">15197731</pub-id>
      </element-citation>
    </ref>
    <ref id="CR55">
      <mixed-citation publication-type="other">Smilkov D, Thorat N, Kim B, Viégas F, Wattenberg M (2017) Smoothgrad: removing noise by adding noise. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1706.03825">https://arxiv.org/abs/1706.03825</ext-link></mixed-citation>
    </ref>
    <ref id="CR56">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
        <source>J Mach Learn Res</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
    <ref id="CR57">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stark</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Breitkreutz</surname>
            <given-names>BJ</given-names>
          </name>
          <name>
            <surname>Reguly</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Boucher</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Breitkreutz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tyers</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>BioGRID: a general repository for interaction datasets</article-title>
        <source>Nucleic Acids Res</source>
        <year>2006</year>
        <volume>34</volume>
        <fpage>D535</fpage>
        <lpage>539</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkj109</pub-id>
        <?supplied-pmid 16381927?>
        <pub-id pub-id-type="pmid">16381927</pub-id>
      </element-citation>
    </ref>
    <ref id="CR58">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sullivan</surname>
            <given-names>DP</given-names>
          </name>
          <name>
            <surname>Winsnes</surname>
            <given-names>CF</given-names>
          </name>
          <name>
            <surname>Akesson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Hjelmare</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wiking</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Schutten</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Campbell</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Leifsson</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Rhodes</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Nordgren</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep learning is combined with massive-scale citizen science to improve large-scale image classification</article-title>
        <source>Nat Biotechnol</source>
        <year>2018</year>
        <volume>36</volume>
        <fpage>820</fpage>
        <lpage>828</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.4225</pub-id>
        <?supplied-pmid 30125267?>
        <pub-id pub-id-type="pmid">30125267</pub-id>
      </element-citation>
    </ref>
    <ref id="CR59">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thul</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Akesson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wiking</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Mahdessian</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Geladaki</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ait Blal</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Alm</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Asplund</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bjork</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Breckels</surname>
            <given-names>LM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A subcellular map of the human proteome</article-title>
        <source>Science</source>
        <year>2017</year>
        <volume>356</volume>
        <fpage>eaal3321</fpage>
        <pub-id pub-id-type="doi">10.1126/science.aal3321</pub-id>
        <?supplied-pmid 28495876?>
        <pub-id pub-id-type="pmid">28495876</pub-id>
      </element-citation>
    </ref>
    <ref id="CR60">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thul</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Lindskog</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>The human protein atlas: a spatial map of the human proteome</article-title>
        <source>Protein Sci</source>
        <year>2018</year>
        <volume>27</volume>
        <fpage>233</fpage>
        <lpage>244</lpage>
        <pub-id pub-id-type="doi">10.1002/pro.3307</pub-id>
        <?supplied-pmid 28940711?>
        <pub-id pub-id-type="pmid">28940711</pub-id>
      </element-citation>
    </ref>
    <ref id="CR61">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tkach</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Yimit</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>AY</given-names>
          </name>
          <name>
            <surname>Riffle</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Costanzo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Jaschob</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hendry</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Ou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Moffat</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Dissecting DNA damage response pathways by analysing protein localization and abundance changes during DNA replication stress</article-title>
        <source>Nat Cell Biol</source>
        <year>2012</year>
        <volume>14</volume>
        <fpage>966</fpage>
        <lpage>976</lpage>
        <pub-id pub-id-type="doi">10.1038/ncb2549</pub-id>
        <?supplied-pmid 22842922?>
        <pub-id pub-id-type="pmid">22842922</pub-id>
      </element-citation>
    </ref>
    <ref id="CR62">
      <mixed-citation publication-type="other">Tong A, Boone C (2006) Synthetic genetic array analysis in Saccharomyces cerevisiae. In: Xiao W (ed) Yeast protocols, second edition. Humana Press, Totowa, pp 171–191</mixed-citation>
    </ref>
    <ref id="CR63">
      <mixed-citation publication-type="other">Van Den Oord A, Vinyals O, Kavukcuoglu K (2017) Neural discrete representation learning. In: Advances in neural information processing systems, vol 30 (NIPS 2017)</mixed-citation>
    </ref>
    <ref id="CR64">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Van der Maaten</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Visualizing data using t-SNE</article-title>
        <source>J Mach Learn Res</source>
        <year>2008</year>
        <volume>9</volume>
        <fpage>2579</fpage>
        <lpage>2605</lpage>
      </element-citation>
    </ref>
    <ref id="CR65">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vinh</surname>
            <given-names>NX</given-names>
          </name>
          <name>
            <surname>Epps</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bailey</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Information theoretic measures for clusterings comparison: variants, properties, normalization and correction for chance</article-title>
        <source>J Mach Learn Res</source>
        <year>2010</year>
        <volume>11</volume>
        <fpage>2837</fpage>
        <lpage>2854</lpage>
      </element-citation>
    </ref>
    <ref id="CR66">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Youn</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Nguyen Ba</surname>
            <given-names>AN</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Messier</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Cox</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Moses</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Functional analysis of kinases and transcription factors in saccharomyces cerevisiae using an integrated overexpression library</article-title>
        <source>G3</source>
        <year>2017</year>
        <volume>7</volume>
        <fpage>911</fpage>
        <lpage>921</lpage>
        <pub-id pub-id-type="doi">10.1534/g3.116.038471</pub-id>
        <?supplied-pmid 28122947?>
        <pub-id pub-id-type="pmid">28122947</pub-id>
      </element-citation>
    </ref>
    <ref id="CR67">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zaritsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jamieson</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Welf</surname>
            <given-names>ES</given-names>
          </name>
          <name>
            <surname>Nevarez</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Cillay</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Eskiocak</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Cantarel</surname>
            <given-names>BL</given-names>
          </name>
          <name>
            <surname>Danuser</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Interpretable deep learning uncovers cellular properties in label-free live cell images that are predictive of highly metastatic melanoma</article-title>
        <source>Cell Syst</source>
        <year>2021</year>
        <volume>12</volume>
        <fpage>733</fpage>
        <lpage>747</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2021.05.003</pub-id>
        <?supplied-pmid 34077708?>
        <pub-id pub-id-type="pmid">34077708</pub-id>
      </element-citation>
    </ref>
    <ref id="CR68">
      <mixed-citation publication-type="other">Zeiler MD, Fergus R (2014) Visualizing and understanding convolutional networks. Computer Vision – ECCV 2014</mixed-citation>
    </ref>
  </ref-list>
</back>
