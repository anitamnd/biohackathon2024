<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9019949</article-id>
    <article-id pub-id-type="publisher-id">4683</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-022-04683-1</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DISTEMA: distance map-based estimation of single protein model accuracy with attentive 2D convolutional neural network</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Xiao</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0305-2853</contrib-id>
        <name>
          <surname>Cheng</surname>
          <given-names>Jianlin</given-names>
        </name>
        <address>
          <email>chengji@missouri.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="GRID">grid.134936.a</institution-id><institution-id institution-id-type="ISNI">0000 0001 2162 3504</institution-id><institution>Department of Electrical Engineering and Computer Science, </institution><institution>University of Missouri Columbia, </institution></institution-wrap>Columbia, MO 65211 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>19</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>19</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <issue>Suppl 3</issue>
    <issue-sponsor>Publication of this supplement has not been supported by sponsorship. Information about the source of funding for publication charges can be found in the individual articles. The articles have undergone the journal's standard peer review process for supplements. Supplement Editors were not involved in the peer review of any article that they co-authored. The Supplement Editors declare that they have no other competing interests.</issue-sponsor>
    <elocation-id>141</elocation-id>
    <history>
      <date date-type="received">
        <day>8</day>
        <month>4</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>11</day>
        <month>4</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Estimation of the accuracy (quality) of protein structural models is important for both prediction and use of protein structural models. Deep learning methods have been used to integrate protein structure features to predict the quality of protein models. Inter-residue distances are key information for predicting protein’s tertiary structures and therefore have good potentials to predict the quality of protein structural models. However, few methods have been developed to fully take advantage of predicted inter-residue distance maps to estimate the accuracy of a single protein structural model.</p>
      </sec>
      <sec>
        <title>Result</title>
        <p id="Par2">We developed an attentive 2D convolutional neural network (CNN) with channel-wise attention to take only a raw difference map between the inter-residue distance map calculated from a single protein model and the distance map predicted from the protein sequence as input to predict the quality of the model. The network comprises multiple convolutional layers, batch normalization layers, dense layers, and Squeeze-and-Excitation blocks with attention to automatically extract features relevant to protein model quality from the raw input without using any expert-curated features. We evaluated DISTEMA’s capability of selecting the best models for CASP13 targets in terms of ranking loss of GDT-TS score. The ranking loss of DISTEMA is 0.079, lower than several state-of-the-art single-model quality assessment methods.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p id="Par3">This work demonstrates that using raw inter-residue distance information with deep learning can predict the quality of protein structural models reasonably well. DISTEMA is freely at <ext-link ext-link-type="uri" xlink:href="https://github.com/jianlin-cheng/DISTEMA">https://github.com/jianlin-cheng/DISTEMA</ext-link></p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Protein quality</kwd>
      <kwd>Distance map</kwd>
      <kwd>Deep learning</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
            <institution>National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>GM093123</award-id>
        <principal-award-recipient>
          <name>
            <surname>Cheng</surname>
            <given-names>Jianlin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100008982</institution-id>
            <institution>National Science Foundation</institution>
          </institution-wrap>
        </funding-source>
        <award-id>DBI 1759934</award-id>
        <award-id>IIS1763246</award-id>
        <principal-award-recipient>
          <name>
            <surname>Cheng</surname>
            <given-names>Jianlin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Department of Energy</institution>
        </funding-source>
        <award-id>DE-SC0020400</award-id>
        <award-id>DE-SC0021303</award-id>
        <principal-award-recipient>
          <name>
            <surname>Cheng</surname>
            <given-names>Jianlin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <conference xlink:href="https://icibm2021.iaibm.org/">
      <conf-name>International Conference on Intelligent Biology and Medicine (ICIBM 2021)</conf-name>
      <conf-loc>Philadelphia, PA, USA</conf-loc>
      <conf-date>8-10 August 2021</conf-date>
    </conference>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par8">Estimation of protein model accuracy (EMA) or assessment of protein model quality (QA) is an important problem in protein structure prediction. Since the seventh Critical Assessment of Techniques for Protein Structure Prediction (CASP7) [<xref ref-type="bibr" rid="CR1">1</xref>] EMA (or QA) has been a prediction category in CASP experiments. A lot of methods have been developed to evaluate the quality of protein models [<xref ref-type="bibr" rid="CR2">2</xref>–<xref ref-type="bibr" rid="CR6">6</xref>]. These EMA methods fell into two main categories: multi-model methods and single-model methods. A multi-model method takes a pool of prediction structure models of the same target as input to evaluate their quality based on the similarity between the models and possibly other structural features. A single-model method predicts the quality of a single protein without comparing it to any other structure models. A multi-model method’s performance depends on the proportion of good models in the pool and may perform poorly when there are only a few good models. In contrast, a single-model EMA method [<xref ref-type="bibr" rid="CR7">7</xref>] can estimate the accuracy of a single protein model without being influenced by the existence of other models. A recent study [<xref ref-type="bibr" rid="CR8">8</xref>] shows the single-model methods can perform better than multi-model methods in some cases. Moreover, different from multi-model methods that can only predict relative quality of models in a pool, single-model methods can predict the absolute quality of a single model, which is important for users to decide how to use the model. Therefore, single-model quality assessment is receiving more and more attention, even though its average performance was still lower than multi-model methods in the past several CASP experiments.</p>
    <p id="Par9">Numerous machine-learning methods have been developed to combine various protein structural features to assess the quality of protein models. ProQ2 [<xref ref-type="bibr" rid="CR9">9</xref>] and Model Evaluator [<xref ref-type="bibr" rid="CR7">7</xref>] applied support vector machines (SVM) with residue contacts, secondary structure information, solvent accessible surface area, and/or sequence features to predict a global quality score—the global similarity between a protein model and its native structure. ProQ3 [<xref ref-type="bibr" rid="CR9">9</xref>] added the Talaris energy as a new feature on top of the ProQ2. ProQ3D [<xref ref-type="bibr" rid="CR10">10</xref>] used a multi-layer perceptron with the same features used in ProQ3 for protein model quality prediction. Recently, deep learning-based models have been applied to improve the estimation of model accuracy. DeepQA [<xref ref-type="bibr" rid="CR3">3</xref>] utilized deep belief networks to predict the global quality score. ProQ4 [<xref ref-type="bibr" rid="CR11">11</xref>] exploited the transfer learning and 1D convolutional neural network (CNN) to predict the Local Distance Difference Test (LDDT) score [<xref ref-type="bibr" rid="CR12">12</xref>]. DeepRank [<xref ref-type="bibr" rid="CR5">5</xref>] applied deep learning to integrate multiple features including residue-residue contact features to predict model quality and performed best in selecting best protein models in the CASP13 experiment. DeepRank2 [<xref ref-type="bibr" rid="CR6">6</xref>] added a new inter-residue distance feature with a deeper and wider neural network to predict global model quality. Some recent methods leverage more complex deep learning architectures. Treating a protein structural model as a graph, ProteinGCN [<xref ref-type="bibr" rid="CR13">13</xref>], GraphQA [<xref ref-type="bibr" rid="CR14">14</xref>] and VoroCNN [<xref ref-type="bibr" rid="CR15">15</xref>] applied graph convolutional networks (GCN) to estimate the model accuracy. ResNetQA [<xref ref-type="bibr" rid="CR16">16</xref>] and DeepAccNet [<xref ref-type="bibr" rid="CR17">17</xref>] used deep residue networks to address the problem.</p>
    <p id="Par10">In addition to the inference technology, the performance of EMA method depends on input features. In CSAP13, DeepRank [<xref ref-type="bibr" rid="CR5">5</xref>] demonstrated that accurate residue-residue contacts (a simplified representation of distances between residues) predicted by deep learning improved the prediction of the quality of protein structural models, suggesting that more detailed residue-residue distance predictions could further improve EMA. However, only a few methods [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>], use residue-residue distances to estimate the accuracy of protein structural models.</p>
    <p id="Par11">Instead of extracting features from the predicted residue-residue distance maps based on human intuition or expertise as most existing methods did, we designed a 2D convolutional neural network (2D-CNN) with the channel-wise attention to directly use the raw difference map between the distance map of a model and the distance map predicted from the protein sequence to estimate the accuracy of a single protein model. On the CASP13 dataset, our method—DISTEMA—achieved the better performance than other state-of-art single-model methods in terms of the ranking loss of selecting the best models for protein targets. The results show that the attentive 2D-CNN methods can automatically extract useful information from raw residue-residue distance maps alone to predict the quality of a single protein model without using other protein structural features.
</p>
  </sec>
  <sec id="Sec2">
    <title>Results and discussion</title>
    <sec id="Sec3">
      <title>Results on the CASP13 dataset and comparison with single-model QA methods</title>
      <p id="Par12">We evaluated DISTEMA with several single-model EMA methods on CASP13 dataset. The results of ProQ2 [<xref ref-type="bibr" rid="CR18">18</xref>], ProQ3 [<xref ref-type="bibr" rid="CR9">9</xref>], ProQ3D [<xref ref-type="bibr" rid="CR10">10</xref>], ProQ4 [<xref ref-type="bibr" rid="CR11">11</xref>], and the two VoroMQA methods [<xref ref-type="bibr" rid="CR19">19</xref>] on the CASP13 dataset were taken from [<xref ref-type="bibr" rid="CR8">8</xref>]. The results of a distance-based method—QDeep [<xref ref-type="bibr" rid="CR20">20</xref>] were obtained by running it on the same CASP13 dataset. The average ranking loss and Pearson’s Correlation Coefficient (PCC) of these methods are reported in Table <xref rid="Tab1" ref-type="table">1</xref>. DISTEMA and ProQ4 have the lowest ranking loss of 0.079, which is a 9% improvement over the second-lowest loss of 0.086. The PCC of DISTEMA is 0.929, which is 38% higher than the second highest PCC achieved by QDeep.<table-wrap id="Tab1"><label>Table 1</label><caption><p>The ranking loss and PCC of eight methods on the CASP13 dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Model</th><th align="left">Ranking loss</th><th align="left">Pearson’s correlation coefficient (PCC)</th></tr></thead><tbody><tr><td align="left">DISTEMA</td><td char="." align="char"><bold>0</bold><bold><italic>.</italic></bold><bold>079</bold></td><td char="." align="char"><bold>0</bold><bold><italic>.</italic></bold><bold>929</bold></td></tr><tr><td align="left">ProQ4</td><td char="." align="char"><bold>0</bold><bold><italic>.</italic></bold><bold>079</bold></td><td char="." align="char">0<italic>.</italic>711</td></tr><tr><td align="left">ProQ3D</td><td char="." align="char">0<italic>.</italic>086</td><td char="." align="char">0<italic>.</italic>652</td></tr><tr><td align="left">ProQ3</td><td char="." align="char">0<italic>.</italic>089</td><td char="." align="char">0<italic>.</italic>594</td></tr><tr><td align="left">VoroMQA-B</td><td char="." align="char">0<italic>.</italic>095</td><td char="." align="char">0.618</td></tr><tr><td align="left">VoroMQA-A</td><td char="." align="char">0<italic>.</italic>109</td><td char="." align="char">0<italic>.</italic>642</td></tr><tr><td align="left">QDeep</td><td char="." align="char">0.110</td><td char="." align="char">0.895</td></tr><tr><td align="left">ProQ2</td><td char="." align="char">0<italic>.</italic>114</td><td char="." align="char">0<italic>.</italic>604</td></tr></tbody></table><table-wrap-foot><p>The best performance is denoted by the bold font</p></table-wrap-foot></table-wrap></p>
      <p id="Par13">Figure <xref rid="Fig1" ref-type="fig">1</xref> is the scatter plot of the true GDT-TS score of the best model of each target against the true GDT-TS score of the top model selected by DISTEMA for the target. The solid red line denotes the regression line between predicted GDT TS and true GDT TS and the yellow line is the 45-degree line on which points have 0 loss. Larger the distance between a data point and the yellow line, bigger the loss is. For four targets (i.e., T0949, T0987, T0980s2, T1019s2), their best models were successfully selected as top models by DISTEMA, yielding a loss of 0. Two outliers—T1008, T1022s2—have the largest loss for DISTEMA. Figure <xref rid="Fig2" ref-type="fig">2</xref> illustrates the distribution of the ranking losses of DISTEMA on the CASP13 dataset. The vertical dashed black line is the mark for the mean loss. More data points are located on the left side of the black line. The skewness of the distribution <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\frac{1}{n}\mathop \sum \nolimits_{i = 1}^{n} \left( {x_{i} - \overline{x}} \right)^{3} }}{{\left( {\frac{1}{n}\mathop \sum \nolimits_{i = 1}^{n} \left( {x_{i} - \overline{x}} \right)^{2} } \right)^{\frac{3}{2}} }}\;{\text{is}}\;2.377.$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mfrac><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mn>3</mml:mn></mml:msup></mml:mrow><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfenced><mml:mfrac><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:msup></mml:mfrac><mml:mspace width="0.277778em"/><mml:mtext>is</mml:mtext><mml:mspace width="0.277778em"/><mml:mn>2.377</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq1.gif"/></alternatives></inline-formula><fig id="Fig1"><label>Fig. 1</label><caption><p>The plot of the true GDT-TS scores of the best models against the true GDT-TS scores of the top models selected by DISTEMA for 80 CASP13 targets. The histogram at the top is the distribution of the GDT-TS scores of the top selected models. The histogram on the right shows the distribution of the GDT-TS scores of the best models. The yellow is a 45-degree line with the slop of 1. The points on the yellow line represent the targets whose best models and top selected models have the same GDT-TS score (i.e., 0 loss). Four targets (T0949, T0987, T0980s2, T1019s2) have 0 loss. Closer a point to the yellow line, lower loss of GDT-TS score for the target. Two targets (T1008 and T2022s2) are the two outliers with very high loss. The red line is the linear regression line between the two groups of GDT-TS scores. The correlation between the two groups of the scores is 0.93</p></caption><graphic xlink:href="12859_2022_4683_Fig1_HTML" id="MO1"/></fig><fig id="Fig2"><label>Fig. 2</label><caption><p>Histogram of the distribution of the ranking loss of DISTEMA over the 80 CASP13 targets. The vertical black dashed line represents the position of the mean value</p></caption><graphic xlink:href="12859_2022_4683_Fig2_HTML" id="MO2"/></fig></p>
      <p id="Par14">In addition to the ranking loss, we applied a non-parametric method Kolmogorov Smirnov test (KS test) to measure the distance between the distribution of true GDT-TS scores and that of predicted GDT-TS scores of the CASP13 models. We conducted the KS test on the two datasets. The first dataset contains the true GDT-TS scores of all the CASP13 models, and their GDT-TS scores predicted by DISTEMA. The distributions of the two kinds of scores were compared. The second dataset include the true GDT-TS scores of the best models for the CASP13 targets and the true GDT-TS scores of the top models selected for them. For both tests, we used the same null hypothesis H0: no difference between the two distributions. We calculated Kolmogorov–Smirnov statistics <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_{{\left( {n,m} \right)}}$$\end{document}</tex-math><mml:math id="M4"><mml:msub><mml:mi>D</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mfenced></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq2.gif"/></alternatives></inline-formula> (i.e., <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathop {\sup }\limits_{x} {\mid }F_{1,n} \left( x \right) - F_{2,m} \left( x \right)$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:munder><mml:mo movablelimits="false">sup</mml:mo><mml:mi>x</mml:mi></mml:munder><mml:mo>∣</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi>x</mml:mi></mml:mfenced><mml:mo>-</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi>x</mml:mi></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq3.gif"/></alternatives></inline-formula>) the measurement of the difference between the two distributions. Here, <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$sup_{x}$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq4.gif"/></alternatives></inline-formula> is the supremum function, which in this case is considered as the <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$max$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq5.gif"/></alternatives></inline-formula> function. <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_{1,n}$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq6.gif"/></alternatives></inline-formula> and <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_{2,m}$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq7.gif"/></alternatives></inline-formula> are the empirical distribution functions for first and second sample respectively, where <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M16"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq8.gif"/></alternatives></inline-formula> and <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m$$\end{document}</tex-math><mml:math id="M18"><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq9.gif"/></alternatives></inline-formula> are sample size.</p>
      <p id="Par15">On the dataset 1, D-statistics of the KS test is 0.11266, and the p-value (2.2e − 16) is smaller than a significance threshold (i.e., 0.05), which means these two samples come from different distributions. Figure <xref rid="Fig3" ref-type="fig">3</xref> shows the two samples’ cumulative distribution function (CDF) curves. The red vertical dashed line is the D-statistics, representing the maximum absolute difference between these two CDF. The shapes of the two curves are different.<fig id="Fig3"><label>Fig. 3</label><caption><p>K-S plot for true GDT-TS scores of the models (blue) V.S. predicted GDT-TS scores of the models (red). D statistics: 0.11266, p-value: 2.2e − 16</p></caption><graphic xlink:href="12859_2022_4683_Fig3_HTML" id="MO3"/></fig></p>
      <p id="Par16">The analysis shows that the distribution of the true GDT-TS scores of all the models and the distribution of their predicted GDT-TS scores have somewhat different distributions, indicating that the quality scores of some models (e.g., some models of very low quality) are hard to predict. Enlarging the training dataset may alleviate the problem.</p>
      <p id="Par17">In contrast, on the dataset 2, the D-statistics is 0.2 and the p-value of KS-test is 0.08152, higher than the threshold, suggesting the null hypothesis be accepted. That is, the distribution of the true GDT-TS score of the best model for each target has no difference than the distribution of the true GDT-TS score of the top model selected for each target. Figure <xref rid="Fig4" ref-type="fig">4</xref> illustrates the two distributions’ CDF curves, where the blue line and red line are generally in the same shape. The similar distribution of the GDT-TS scores of best models and top selected models further confirm that the ranking capability of DISTEMA is sound.<fig id="Fig4"><label>Fig. 4</label><caption><p>K-S plot for true GDT-TS scores of the best models (red) V.S. the true GDT-TS scores of the top selected models (blue). D statistics:0.2, p-value:0.08152</p></caption><graphic xlink:href="12859_2022_4683_Fig4_HTML" id="MO4"/></fig></p>
    </sec>
    <sec id="Sec4">
      <title>Comparison with a distanced-based EMA method</title>
      <p id="Par18">We further compared DISTEMA with the distance-based single-model method QDeep on the same 3000 models of 20 CASP13 targets whose true structures are publicly available [<xref ref-type="bibr" rid="CR21">21</xref>] used to evaluate QDeep in [<xref ref-type="bibr" rid="CR20">20</xref>]. QDeep uses one dimensional CNN with inter-residue distance features derived from distance predictions, sequence information, and energy scores, while DISTEMA only uses the raw distance maps as input. Table <xref rid="Tab2" ref-type="table">2</xref> reports the results of the two methods. DISTEMA performed better than QDeep according to the ranking loss even though it only used one kind of input information, but worse than QDeep according to PCC. The results show that using only raw distance maps with deep learning can predict the quality of a single protein model reasonably well and integrating other features with the distance information may further improve the prediction performance.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>The ranking loss and PCC of DISTEMA and QDeep</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Methods</th><th align="left">Ranking loss</th><th align="left">Pearson’s correlation coefficient (PCC)</th></tr></thead><tbody><tr><td align="left">QDeep</td><td char="." align="char">0.088</td><td char="." align="char"><bold>0.866</bold></td></tr><tr><td align="left">DISETMA</td><td char="." align="char"><bold>0.083</bold></td><td char="." align="char">0.826</td></tr></tbody></table><table-wrap-foot><p>The bold numbers denote the best results</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec5">
      <title>Contribution of squeeze-and-excitation (SE) blocks with attention</title>
      <p id="Par19">We trained two deep learning networks to investigate the impact of SE blocks with attention. The two networks have the same architecture except one network has SE blocks, but another does not. The two networks were trained with the same experimental setting and were evaluated on the CASP13 dataset. The network with SE blocks has the ranking loss of 0.079, 7.5% lower than 0.085 of the network without SE blocks, indicating that attentive SE blocks can improve the performance of model quality prediction. The attention mechanism in SE blocks can more effectively pick up the relevant features anywhere in the input and assign them higher weights to improve the prediction performance.</p>
    </sec>
  </sec>
  <sec id="Sec6">
    <title>Conclusion and future work</title>
    <p id="Par20">We designed and developed an attentive 2D CNN with the channel-wise attention to directly leverage a raw inter-residue distance map to predict the global quality of a single protein model. Using only the protein distance information, the deep learning method with the attention mechanism is able to automatically extract features relevant to model quality from the raw input and achieves the lower model ranking loss than other state-of-the-art single-model EMA methods that use various expert-curated protein structural features. The results demonstrate that raw protein distance maps contain substantial information that can be captured by advanced deep learning methods to estimate the accuracy of a single protein model. In the future, larger training datasets, additional input features, and more advanced deep learning architectures [<xref ref-type="bibr" rid="CR22">22</xref>] can be used to further improve the distance map-based methods for improving the prediction of protein model quality.</p>
  </sec>
  <sec id="Sec7">
    <title>Methods and materials</title>
    <sec id="Sec8">
      <title>Difference map as input feature</title>
      <p id="Par21">We applied a real-value distance predictor DeepDist [<xref ref-type="bibr" rid="CR23">23</xref>] to predict an inter-residue distance map from the sequence of a protein target as matrix <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A \left( {L \times L} \right)$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mi>A</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq10.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L$$\end{document}</tex-math><mml:math id="M22"><mml:mi>L</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq11.gif"/></alternatives></inline-formula> denotes the sequence length and <inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A\left[ {i,j} \right]$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:mi>A</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq12.gif"/></alternatives></inline-formula> is the distance between residues <inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M26"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq13.gif"/></alternatives></inline-formula> and <inline-formula id="IEq14"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M28"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq14.gif"/></alternatives></inline-formula>. A was compared with the distance matrix <inline-formula id="IEq15"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$B \left( {L \times L} \right)$$\end{document}</tex-math><mml:math id="M30"><mml:mrow><mml:mi>B</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq15.gif"/></alternatives></inline-formula> calculated from the coordinates of residues in a protein structure model to generate a difference map <inline-formula id="IEq16"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M32"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq16.gif"/></alternatives></inline-formula>. Because <inline-formula id="IEq17"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A$$\end{document}</tex-math><mml:math id="M34"><mml:mi>A</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq17.gif"/></alternatives></inline-formula> can be considered the expected distances between residues and <inline-formula id="IEq18"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$B$$\end{document}</tex-math><mml:math id="M36"><mml:mi>B</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq18.gif"/></alternatives></inline-formula> the actual distances between residues in a model, <inline-formula id="IEq19"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M38"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq19.gif"/></alternatives></inline-formula> measures how well the model meets the expectation and therefore provides useful information about the quality of the model. Considering that large distances tend to have little impact on the fold of a protein structure, before the generation of the distance map, a distance threshold (i.e., <inline-formula id="IEq20"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$16$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:mn>16</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq20.gif"/></alternatives></inline-formula> Angstrom) was applied <inline-formula id="IEq21"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A$$\end{document}</tex-math><mml:math id="M42"><mml:mi>A</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq21.gif"/></alternatives></inline-formula> and <inline-formula id="IEq22"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$B$$\end{document}</tex-math><mml:math id="M44"><mml:mi>B</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq22.gif"/></alternatives></inline-formula> to filter out the distances that are greater than the threshold. That is, if either <inline-formula id="IEq23"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A\left[ {i,j} \right]$$\end{document}</tex-math><mml:math id="M46"><mml:mrow><mml:mi>A</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq23.gif"/></alternatives></inline-formula> or <inline-formula id="IEq24"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$B\left[ { i,j} \right]$$\end{document}</tex-math><mml:math id="M48"><mml:mrow><mml:mi>B</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq24.gif"/></alternatives></inline-formula> is greater than 16, both <inline-formula id="IEq25"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A\left[ {i,j} \right]$$\end{document}</tex-math><mml:math id="M50"><mml:mrow><mml:mi>A</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq25.gif"/></alternatives></inline-formula> or <inline-formula id="IEq26"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$B\left[ {i,j} \right]$$\end{document}</tex-math><mml:math id="M52"><mml:mrow><mml:mi>B</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq26.gif"/></alternatives></inline-formula> were set to 0, producing two filtered distance matrices <inline-formula id="IEq27"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A^{*}$$\end{document}</tex-math><mml:math id="M54"><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq27.gif"/></alternatives></inline-formula> and <inline-formula id="IEq28"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$B^{*}$$\end{document}</tex-math><mml:math id="M56"><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq28.gif"/></alternatives></inline-formula>. The difference map <inline-formula id="IEq29"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M58"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq29.gif"/></alternatives></inline-formula> was an element-wise subtraction between <inline-formula id="IEq30"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A^{*}$$\end{document}</tex-math><mml:math id="M60"><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq30.gif"/></alternatives></inline-formula> and <inline-formula id="IEq31"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$B^{*}$$\end{document}</tex-math><mml:math id="M62"><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq31.gif"/></alternatives></inline-formula>. Since <inline-formula id="IEq32"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A^{*}$$\end{document}</tex-math><mml:math id="M64"><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq32.gif"/></alternatives></inline-formula> and <inline-formula id="IEq33"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$B^{*}$$\end{document}</tex-math><mml:math id="M66"><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq33.gif"/></alternatives></inline-formula> are symmetrical, <inline-formula id="IEq34"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M68"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq34.gif"/></alternatives></inline-formula> is also symmetrical. To speed up the training of the deep learning method, the distances in the lower triangle of <inline-formula id="IEq35"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M70"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq35.gif"/></alternatives></inline-formula> is set to <inline-formula id="IEq36"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0$$\end{document}</tex-math><mml:math id="M72"><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq36.gif"/></alternatives></inline-formula> to produce a matrix <inline-formula id="IEq37"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$U$$\end{document}</tex-math><mml:math id="M74"><mml:mi>U</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq37.gif"/></alternatives></inline-formula>. <inline-formula id="IEq38"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$U$$\end{document}</tex-math><mml:math id="M76"><mml:mi>U</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq38.gif"/></alternatives></inline-formula> that only contains the values of the upper triangle of <inline-formula id="IEq39"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M78"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq39.gif"/></alternatives></inline-formula> is used as input for the deep learning method to predict model quality. For example, Fig. <xref rid="Fig5" ref-type="fig">5</xref> visualizes <inline-formula id="IEq40"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A^{*}$$\end{document}</tex-math><mml:math id="M80"><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq40.gif"/></alternatives></inline-formula>, <inline-formula id="IEq41"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$B^{*}$$\end{document}</tex-math><mml:math id="M82"><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq41.gif"/></alternatives></inline-formula>, <inline-formula id="IEq42"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M84"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq42.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq43"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$U$$\end{document}</tex-math><mml:math id="M86"><mml:mi>U</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq43.gif"/></alternatives></inline-formula> of a model of CASP13 target T0949.<fig id="Fig5"><label>Fig. 5</label><caption><p>The difference map for CASP13 target T0949. <inline-formula id="IEq53"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a$$\end{document}</tex-math><mml:math id="M88"><mml:mi>a</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq53.gif"/></alternatives></inline-formula> and <inline-formula id="IEq54"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b$$\end{document}</tex-math><mml:math id="M90"><mml:mi>b</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq54.gif"/></alternatives></inline-formula> are filtered matrices from predicted distance map, and model structure distance map. <inline-formula id="IEq55"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c$$\end{document}</tex-math><mml:math id="M92"><mml:mi>c</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq55.gif"/></alternatives></inline-formula> is the element-wise subtraction between <inline-formula id="IEq56"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a$$\end{document}</tex-math><mml:math id="M94"><mml:mi>a</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq56.gif"/></alternatives></inline-formula> and <inline-formula id="IEq57"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b$$\end{document}</tex-math><mml:math id="M96"><mml:mi>b</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq57.gif"/></alternatives></inline-formula>. <inline-formula id="IEq58"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d$$\end{document}</tex-math><mml:math id="M98"><mml:mi>d</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq58.gif"/></alternatives></inline-formula> is the upper triangular part of <inline-formula id="IEq59"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c$$\end{document}</tex-math><mml:math id="M100"><mml:mi>c</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq59.gif"/></alternatives></inline-formula>. <inline-formula id="IEq60"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d$$\end{document}</tex-math><mml:math id="M102"><mml:mi>d</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq60.gif"/></alternatives></inline-formula> is the difference map. For those four maps, the lighter area represents for larger value</p></caption><graphic xlink:href="12859_2022_4683_Fig5_HTML" id="MO5"/></fig></p>
    </sec>
    <sec id="Sec9">
      <title>Deep learning architecture and training</title>
      <p id="Par22">The architecture of the deep learning network of DISTEMA is illustrated in Fig. <xref rid="Fig6" ref-type="fig">6</xref>. The network takes the difference map <italic>U</italic> of a model as input to predict the global distance test total score (GDT-TS) [<xref ref-type="bibr" rid="CR24">24</xref>] of the model. A GDT-TS score ranges from 0 to 1, measuring the global similarity between a model and its corresponding native structure. Higher the score, better is the model quality. A true GDT-TS score of a model can be calculated by comparing a model with its native structure using some tools like TM-score [<xref ref-type="bibr" rid="CR25">25</xref>] if the latter is known. Otherwise, the GDT-TS score needs to be estimated or predicted from the features of the model.<fig id="Fig6"><label>Fig. 6</label><caption><p>The schematic shows the architecture of DISTEMA. We applied four CONV blocks, two SE blocks, four dense blocks to build this model. The input is difference map and predicted GDT TS score is output</p></caption><graphic xlink:href="12859_2022_4683_Fig6_HTML" id="MO6"/></fig></p>
      <p id="Par23">The protein models of CASP8-12 whose true GDT-TS scores are known were used to train the deep learning method to predict their GDT-TS scores. The input size for the deep learning method is <inline-formula id="IEq44"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b \times 1 \times L \times L$$\end{document}</tex-math><mml:math id="M104"><mml:mrow><mml:mi>b</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq44.gif"/></alternatives></inline-formula>, and the output size is <inline-formula id="IEq45"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b \times 1$$\end{document}</tex-math><mml:math id="M106"><mml:mrow><mml:mi>b</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq45.gif"/></alternatives></inline-formula>. Here <inline-formula id="IEq46"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b$$\end{document}</tex-math><mml:math id="M108"><mml:mi>b</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq46.gif"/></alternatives></inline-formula> denotes the batch size, <inline-formula id="IEq47"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1 \times L \times L$$\end{document}</tex-math><mml:math id="M110"><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq47.gif"/></alternatives></inline-formula> the size of the difference map, and 1 the number of input channel (i.e., the distance difference value). We let the input in the same batch have the same <inline-formula id="IEq48"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L$$\end{document}</tex-math><mml:math id="M112"><mml:mi>L</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq48.gif"/></alternatives></inline-formula> to speed up training, even though the <inline-formula id="IEq49"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Ls$$\end{document}</tex-math><mml:math id="M114"><mml:mrow><mml:mi mathvariant="italic">Ls</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq49.gif"/></alternatives></inline-formula> in different batches can be different. The deep network is composed of four convolutional (Conv) blocks, a global pooling layer, a flatten layer, and four dense blocks. The four Conv blocks extract features from the input. Each of the first two Conv blocks contains a squeeze-and-excitation (SE) block [<xref ref-type="bibr" rid="CR26">26</xref>] with the channel-wise attention mechanism to automatically assign higher weights to more relevant features. Both SE blocks use the same squeeze-and-excitation ratio (i.e., 16). In each SE block, the global average pooling layer extracts single average value from the previous convolutional layer’s channels; two fully connected layers shrank the inner neural size first and then increase the size to the original number; the sigmoid function scales each value into the range [0, 1], which is treated as an independent weight score for each channel; and the previous convolutional layer’s weights multiply the weight score as the re-scored weights.</p>
      <p id="Par24">The four Conv blocks increase the input channel number from 1 to 256. A global max-pooling layer is applied to the last Conv block to extract each channel’s max value. A flatten layer combined these features and reshaped the size to <italic>b</italic> × 256. The following four dense blocks reduce the feature size from <italic>b</italic> × 256 to <inline-formula id="IEq50"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b \times 1$$\end{document}</tex-math><mml:math id="M116"><mml:mrow><mml:mi>b</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq50.gif"/></alternatives></inline-formula> to get the predicted GDT-TS score.</p>
      <p id="Par25">Except the sigmoid activation function used in the two SE blocks and the ReLu activation used in the last output layer, all the other layers use the Leakey-ReLu activation function if applicable. The deep learning network above was trained with the Smooth L1 loss function [<xref ref-type="bibr" rid="CR27">27</xref>]. Unlike the mean squared error (MSE) loss and standard L1-loss function, the Smooth L1 loss is less sensitive to the outliers and derivable at 0 point. The Eq. <xref rid="Equ1" ref-type="">1</xref> is the formula of the smooth L1 loss, where <italic>x</italic> denotes the difference between the predicted and true GDT-TS scores. It is a combination of MSE loss and L1 loss. The derivative of the smooth L1 loss is represented by Eq. <xref rid="Equ2" ref-type="">2</xref>. The derivative is x when x is in the range [1, 1], which is linear. Otherwise, it is a constant (1 or − 1). This property ensures the deep network is stable and converges fast.<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{smooth}}_{{L_{1} }} \left( x \right) = \left\{ {\begin{array}{*{20}l} {0.5x^{2} } \hfill &amp; {\left| x \right| &lt; 1} \hfill \\ {\left| x \right| - 0.5} \hfill &amp; {\text{ otherwise }} \hfill \\ \end{array} } \right.$$\end{document}</tex-math><mml:math id="M118" display="block"><mml:mrow><mml:msub><mml:mtext>smooth</mml:mtext><mml:msub><mml:mi>L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub><mml:mfenced close=")" open="("><mml:mi>x</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mn>0.5</mml:mn><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mfenced close="|" open="|"><mml:mi>x</mml:mi></mml:mfenced><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mrow><mml:mfenced close="|" open="|"><mml:mi>x</mml:mi></mml:mfenced><mml:mo>-</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mspace width="0.333333em"/><mml:mtext>otherwise</mml:mtext><mml:mspace width="0.333333em"/></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2022_4683_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{smooth}}_{{L_{1} }} (x)^{\prime } = \left\{ {\begin{array}{*{20}l} x \hfill &amp; { - 1 &lt; x &lt; 1} \hfill \\ { - 1} \hfill &amp; {x \le - 1} \hfill \\ 1 \hfill &amp; {x \ge 1} \hfill \\ \end{array} } \right.$$\end{document}</tex-math><mml:math id="M120" display="block"><mml:mrow><mml:msub><mml:mtext>smooth</mml:mtext><mml:msub><mml:mi>L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mi>x</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mn>1</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2022_4683_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par26">For the convolutional and linear layers, we utilized the kaiming initialization [<xref ref-type="bibr" rid="CR28">28</xref>] to initialize the start values. We implemented the deep network with PyTorch [<xref ref-type="bibr" rid="CR29">29</xref>]. It was trained by Adam optimization method [<xref ref-type="bibr" rid="CR30">30</xref>] with <inline-formula id="IEq51"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\beta_{1} = 0.9$$\end{document}</tex-math><mml:math id="M122"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq51.gif"/></alternatives></inline-formula> and <inline-formula id="IEq52"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\beta_{2} = 0.999$$\end{document}</tex-math><mml:math id="M124"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.999</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq52.gif"/></alternatives></inline-formula>. The learning rate was set as a constant value of 0.00005 and the batch size as 16.</p>
    </sec>
    <sec id="Sec10">
      <title>Datasets and evaluation metrics</title>
      <p id="Par27">We generated the difference map for each structural model predicted for CASP8-13 targets by CASP8-13 structure prediction servers. Each CASP protein target may have up to a few hundred structural models (decoys). The true GDT-TS scores of these models were calculated as labels to train the deep learning method. 120,064 structural models were used for training and validation, and 14,580 structural models of CASP13 were used as the test dataset. CASP8-12 targets used for training have different sequence lengths (see Fig. <xref rid="Fig7" ref-type="fig">7</xref> for the length distribution). To improve the effectiveness of training on the models of different lengths, the CASP8-12 models were divided into many batches, each of which consisted of 16 structural models of the same length. 80% of randomly selected models in each batch were pooled together to form the training dataset and the remaining models were used as the validation dataset. Figure <xref rid="Fig8" ref-type="fig">8</xref> illustrates the GDT-TS score distribution of the training dataset. The density plot shows that it is approximately a mixture distribution composed of two Gaussian distribution components.<fig id="Fig7"><label>Fig. 7</label><caption><p>The distribution of the sequence length of CASP8-12 targets</p></caption><graphic xlink:href="12859_2022_4683_Fig7_HTML" id="MO7"/></fig><fig id="Fig8"><label>Fig. 8</label><caption><p>The GDT-TS score distribution of the training dataset. This mixture distribution is approximately composed of two Gaussian distributions <inline-formula id="IEq61"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{N}}_{1} \left( {0.241, 0.015} \right)$$\end{document}</tex-math><mml:math id="M126"><mml:mrow><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mn>0.241</mml:mn><mml:mo>,</mml:mo><mml:mn>0.015</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq61.gif"/></alternatives></inline-formula> and <inline-formula id="IEq62"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{N}}_{2} \left( {0.667, 0.018} \right)$$\end{document}</tex-math><mml:math id="M128"><mml:mrow><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mn>0.667</mml:mn><mml:mo>,</mml:mo><mml:mn>0.018</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq62.gif"/></alternatives></inline-formula>. The red line represents the mean of <inline-formula id="IEq63"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{N}}_{1}$$\end{document}</tex-math><mml:math id="M130"><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq63.gif"/></alternatives></inline-formula> and the blue line the mean of <inline-formula id="IEq64"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{N}}_{2}$$\end{document}</tex-math><mml:math id="M132"><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4683_Article_IEq64.gif"/></alternatives></inline-formula></p></caption><graphic xlink:href="12859_2022_4683_Fig8_HTML" id="MO8"/></fig></p>
      <p id="Par28">The predicted performance of DISTEMA and other methods for a target was evaluated by the GDT-TS score loss of ranking the models of the target, which is defined as the absolute difference between the true GDT-TS score of the best model of a target and that of the top model selected by the predicted GDT-TS scores of the models of the target. A ranking loss of 0 means that the best model for a target has been selected by the predicted GDT-TS scores. The average GDT-TS loss of ranking models of all the targets in the test dataset was used to evaluate the performance of the EMA methods. Moreover, the Pearson’s correlation coefficient between the predicted GDT-TS scores of the models of a target and their GDT-TS scores was calculated. The average Pearson’s correlation coefficient over all the targets in the test dataset was also employed to estimate the performance of the EMA methods.</p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>DISTEMA</term>
        <def>
          <p id="Par4">Distance-based estimation of protein model accuracy</p>
        </def>
      </def-item>
      <def-item>
        <term>CASP</term>
        <def>
          <p id="Par5">Critical assessment of techniques for protein structure prediction</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par6">Convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>GDT-TS</term>
        <def>
          <p id="Par7">Global distance test score</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank CASP for providing the data for public use.</p>
    <sec id="d32e1939">
      <title>About this supplement</title>
      <p id="Par29">This article has been published as part of BMC Bioinformatics Volume 23 Supplement 3, 2022: Selected articles from the International Conference on Intelligent Biology and Medicine (ICIBM 2021): bioinformatics. The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="https://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-23-supplement-3">https://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-23-supplement-3</ext-link> 
.</p>
    </sec>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>JC and XC designed this project. XC implemented it and collected the results. XC and JC wrote the manuscript. Both authors read and approved the manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>The project is partially supported by two NSF Grants (DBI 1759934 and IIS1763246), one NIH Grant (GM093123), two DOE Grants (DE-SC0020400 and DE-SC0021303), and the computing allocation on the Summit supercomputer provided by Oak Ridge Leadership Computing Facility (DOE Grant: DE-AC05-00OR22725). The funders do not play a role in conducting this research. The publication cost is funded by an NSF Grant (IIS1763246).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>Availability: <ext-link ext-link-type="uri" xlink:href="https://github.com/jianlin-cheng/DISTEMA">https://github.com/jianlin-cheng/DISTEMA</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par30">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par31">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par32">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cozzetto</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Kryshtafovych</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ceriani</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Tramontano</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Assessment of predictions in the model quality assessment category</article-title>
        <source>Prot Struct Funct Bioinf</source>
        <year>2007</year>
        <volume>69</volume>
        <issue>S8</issue>
        <fpage>175</fpage>
        <lpage>183</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.21669</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>McGuffin</surname>
            <given-names>LJ</given-names>
          </name>
          <name>
            <surname>Buenavista</surname>
            <given-names>MT</given-names>
          </name>
          <name>
            <surname>Roche</surname>
            <given-names>DB</given-names>
          </name>
        </person-group>
        <article-title>The modfold4 server for the quality assessment of 3d protein models</article-title>
        <source>Nucleic Acids Res</source>
        <year>2013</year>
        <volume>41</volume>
        <issue>W1</issue>
        <fpage>368</fpage>
        <lpage>372</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkt294</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cao</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Bhattacharya</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Deepqa: improving the estimation of single protein model quality with deep belief networks</article-title>
        <source>BMC Bioinf</source>
        <year>2016</year>
        <volume>17</volume>
        <issue>1</issue>
        <fpage>495</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-016-1405-y</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Karasikov</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Pages</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Grudinin</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Smooth orientation-dependent scoring function for coarse-grained protein quality assessment</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <issue>16</issue>
        <fpage>2801</fpage>
        <lpage>2808</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty1037</pub-id>
        <pub-id pub-id-type="pmid">30590384</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Protein tertiary structure modeling driven by deep learning and contact distance prediction in casp13</article-title>
        <source>Prot Struct Funct Bioinf</source>
        <year>2019</year>
        <volume>87</volume>
        <issue>12</issue>
        <fpage>1165</fpage>
        <lpage>1178</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.25697</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">Chen X, Akhter N, Guo Z, Wu T, Hou J, Shehu A, Cheng J. Deep ranking in template-free protein structure prediction. In: Proceedings of the 11th ACM international conference on bioinformatics, computational biology and health informatics, pp. 1–10 (2020).</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Tegge</surname>
            <given-names>AN</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Evaluating the absolute quality of a single protein model using structural features and support vector machines</article-title>
        <source>Prot Struct Funct Bioinf</source>
        <year>2009</year>
        <volume>75</volume>
        <issue>3</issue>
        <fpage>638</fpage>
        <lpage>647</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.22275</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Choe</surname>
            <given-names>M-H</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>K-S</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Maghrabi</surname>
            <given-names>AH</given-names>
          </name>
          <name>
            <surname>McGuffin</surname>
            <given-names>LJ</given-names>
          </name>
          <name>
            <surname>Menendez-Hurtado</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Olechnovic</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Schwede</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Estimation of model accuracy in casp13</article-title>
        <source>Prot Struct Funct Bioinf</source>
        <year>2019</year>
        <volume>87</volume>
        <issue>12</issue>
        <fpage>1361</fpage>
        <lpage>1377</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.25767</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Uziela</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Shu</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Wallner</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Proq 3: Improved model quality assessments using rosetta energy terms</article-title>
        <source>Sci Rep</source>
        <year>2016</year>
        <volume>6</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1038/srep33509</pub-id>
        <pub-id pub-id-type="pmid">28442746</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Uziela</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Menendez Hurtado</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Shu</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Wallner</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Proq3d: improved model quality assessments using deep learning</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <issue>10</issue>
        <fpage>1578</fpage>
        <lpage>1580</lpage>
        <pub-id pub-id-type="pmid">28052925</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Hurtado DM, Uziela K, Elofsson A. Deep transfer learning in the assessment of the quality of protein models. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1804.06281">arXiv:1804.06281</ext-link> (2018).</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mariani</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Biasini</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Barbato</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Schwede</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>lddt: a local superposition-free score for comparing protein structures and models using distance difference tests</article-title>
        <source>Bioinformatics</source>
        <year>2013</year>
        <volume>29</volume>
        <issue>21</issue>
        <fpage>2722</fpage>
        <lpage>2728</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btt473</pub-id>
        <pub-id pub-id-type="pmid">23986568</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Sanyal S, Anishchenko I, Dagar A, Baker D, Talukdar P. Proteingcn: protein model quality assessment using graph convolutional networks. BioRxiv (2020).</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Baldassarre F, Menendez Hurtado D, Elofsson A, Azizpour H. GraphQA: protein model quality assessment using graph convolutional networks. Bioinformatics (2020). 10.1093/bioinformatics/btaa714/34192500/btaa714.pdf</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Igashov I, Olechnovic K, Kadukova M, Venclovas C, Grudinin S. Vorocnn: deep convolutional neural network built on 3d voronoi tessellation of protein structures. bioRxiv (2020).</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Jing X, Xu J. Improved protein model quality assessment by integrating sequential and pairwise features using deep learning. bioRxiv (2020).</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hiranuma</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Baek</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Anishchenko</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Dauparas</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Baker</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Improved protein structure refinement guided by deep learning based accuracy estimation</article-title>
        <source>Nat Commun</source>
        <year>2021</year>
        <volume>12</volume>
        <issue>1</issue>
        <fpage>1340</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-021-21511-x</pub-id>
        <pub-id pub-id-type="pmid">33637700</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ray</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lindahl</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Wallner</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Improved model quality assessment using proq2</article-title>
        <source>BMC Bioinf</source>
        <year>2012</year>
        <volume>13</volume>
        <issue>1</issue>
        <fpage>224</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-13-224</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Olechnoviˇc</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Venclovas</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Voromqa: assessment of protein structure quality using interatomic contactˇ areas</article-title>
        <source>Prot Struct Funct Bioinf</source>
        <year>2017</year>
        <volume>85</volume>
        <issue>6</issue>
        <fpage>1131</fpage>
        <lpage>1145</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.25278</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shuvo</surname>
            <given-names>MH</given-names>
          </name>
          <name>
            <surname>Bhattacharya</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Bhattacharya</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>QDeep: distance-based protein model quality estimation by residue-level ensemble error classifications using stacked deep residual neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>Supplement1</issue>
        <fpage>285</fpage>
        <lpage>291</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa455</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other"><ext-link ext-link-type="uri" xlink:href="https://www.predictioncenter.org/download_area/CASP13/targets/casp13.targets.T.4public.tar.gz">https://www.predictioncenter.org/download_area/CASP13/targets/casp13.targets.T.4public.tar.gz</ext-link> Date of access: 2018-11-20 23:59.</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Zagoruyko S, Komodakis N. Wide residual networks. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1605.07146">arXiv:1605.07146</ext-link> (2016).</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Deepdist: real-value inter-residue distance prediction with deep residual convolutional network</article-title>
        <source>BMC Bioinf</source>
        <year>2021</year>
        <volume>22</volume>
        <issue>1</issue>
        <fpage>30</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-021-03960-9</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zemla</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Lga: a method for finding 3d similarities in protein structures</article-title>
        <source>Nucleic Acids Res</source>
        <year>2003</year>
        <volume>31</volume>
        <issue>13</issue>
        <fpage>3370</fpage>
        <lpage>3374</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkg571</pub-id>
        <pub-id pub-id-type="pmid">12824330</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Skolnick</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Scoring function for automated assessment of protein structure template quality</article-title>
        <source>Prot Struct Funct Bioinf</source>
        <year>2004</year>
        <volume>57</volume>
        <issue>4</issue>
        <fpage>702</fpage>
        <lpage>710</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.20264</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Hu J, Shen L, Sun G. Squeeze-and-excitation networks. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 7132–7141 (2018).</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Ren S, He K, Girshick R, Sun J. Faster r-cnn: towards real-time object detection with region proposal networks. In: Advances in neural information processing systems, pp. 91–99 (2015).</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">He K, Zhang X, Ren S, Sun J. Delving deep into rectifiers: surpassing human-level performance on imagenet classification. In: Proceedings of the IEEE international conference on computer vision, pp. 1026–1034 (2015).</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Paszke A, Gross S, Massa F, Lerer A, Bradbury J, Chanan G, Killeen T, Lin Z, Gimelshein N, Antiga L. et al. Pytorch: an imperative style, high-performance deep learning library. In: Advances in neural information processing systems, pp. 8026–8037 (2019).</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Kingma DP, Ba J. Adam: a method for stochastic optimization. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1412.6980">arXiv:1412.6980</ext-link> (2014).</mixed-citation>
    </ref>
  </ref-list>
</back>
