<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD with MathML3 v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1-mathml3.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?all-math-mml yes?>
<?use-mml?>
<?properties open_access?>
<?properties manuscript?>
<?origin nihpa?>
<?iso-abbr Med Image Anal?>
<?submitter-system nihms?>
<?submitter-canonical-name Elsevier?>
<?submitter-canonical-id ELSEVIERAM?>
<?submitter-userid 8068823?>
<?submitter-authority myNCBI?>
<?submitter-login elsevieram?>
<?submitter-name Elsevier Author Support?>
<?domain nihpa?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-journal-id">9713490</journal-id>
    <journal-id journal-id-type="pubmed-jr-id">21159</journal-id>
    <journal-id journal-id-type="nlm-ta">Med Image Anal</journal-id>
    <journal-id journal-id-type="iso-abbrev">Med Image Anal</journal-id>
    <journal-title-group>
      <journal-title>Medical image analysis</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1361-8415</issn>
    <issn pub-type="epub">1361-8423</issn>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9340569</article-id>
    <article-id pub-id-type="pmid">34911013</article-id>
    <article-id pub-id-type="doi">10.1016/j.media.2021.102298</article-id>
    <article-id pub-id-type="manuscript">nihpa1763910</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Federated learning for computational pathology on gigapixel whole slide images</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Lu</surname>
          <given-names>Ming Y.</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A3" ref-type="aff">c</xref>
        <xref rid="FN1" ref-type="author-notes">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Richard J.</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
        <xref rid="FN1" ref-type="author-notes">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kong</surname>
          <given-names>Dehan</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lipkova</surname>
          <given-names>Jana</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A3" ref-type="aff">c</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Singh</surname>
          <given-names>Rajendra</given-names>
        </name>
        <xref rid="A5" ref-type="aff">e</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Williamson</surname>
          <given-names>Drew F.K.</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A3" ref-type="aff">c</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Tiffany Y.</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A3" ref-type="aff">c</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mahmood</surname>
          <given-names>Faisal</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A3" ref-type="aff">c</xref>
        <xref rid="A4" ref-type="aff">d</xref>
        <xref rid="A6" ref-type="aff">f</xref>
        <xref rid="CR1" ref-type="corresp">*</xref>
      </contrib>
    </contrib-group>
    <aff id="A1"><label>a</label>Department of Pathology, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States</aff>
    <aff id="A2"><label>b</label>Department of Biomedical Informatics, Harvard Medical School, Boston, MA, United States</aff>
    <aff id="A3"><label>c</label>Cancer Program, Broad Institute of Harvard and MIT, Cambridge, MA, United States</aff>
    <aff id="A4"><label>d</label>Data Science Department, Dana-Farber/Harvard Cancer Center, Boston, MA, United States</aff>
    <aff id="A5"><label>e</label>Department of Pathology, Northwell Health, NY, United States</aff>
    <aff id="A6"><label>f</label>Harvard Data Science Initiative, Harvard University, Cambridge, MA, United States</aff>
    <author-notes>
      <fn fn-type="equal" id="FN1">
        <label>1</label>
        <p id="P1">These authors contributed equally to this work.</p>
      </fn>
      <corresp id="CR1"><label>*</label>Corresponding author at: Department of Pathology, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States. <email>faisalmahmood@bwh.harvard.edu</email> (F. Mahmood).</corresp>
    </author-notes>
    <pub-date pub-type="nihms-submitted">
      <day>26</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <month>2</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>25</day>
      <month>11</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>01</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <volume>76</volume>
    <fpage>102298</fpage>
    <lpage>102298</lpage>
    <permissions>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY-NC-ND license ( <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link> )</license-p>
      </license>
    </permissions>
    <abstract id="ABS1">
      <p id="P2">Deep Learning-based computational pathology algorithms have demonstrated profound ability to excel in a wide array of tasks that range from characterization of well known morphological phenotypes to predicting non human-identifiable features from histology such as molecular alterations. However, the development of robust, adaptable and accurate deep learning-based models often rely on the collection and time-costly curation large high-quality annotated training data that should ideally come from diverse sources and patient populations to cater for the heterogeneity that exists in such datasets. Multi-centric and collaborative integration of medical data across multiple institutions can naturally help overcome this challenge and boost the model performance but is limited by privacy concerns among other difficulties that may arise in the complex data sharing process as models scale towards using hundreds of thousands of gigapixel whole slide images. In this paper, we introduce privacy-preserving federated learning for gigapixel whole slide images in computational pathology using weakly-supervised attention multiple instance learning and differential privacy. We evaluated our approach on two different diagnostic problems using thousands of histology whole slide images with only slide-level labels. Additionally, we present a weakly-supervised learning framework for survival prediction and patient stratification from whole slide images and demonstrate its effectiveness in a federated setting. Our results show that using federated learning, we can effectively develop accurate weakly-supervised deep learning models from distributed data silos without direct data sharing and its associated complexities, while also preserving differential privacy using randomized noise generation. We also make available an easy-to-use federated learning for computational pathology software package: <ext-link xlink:href="http://github.com/mahmoodlab/HistoFL" ext-link-type="uri">http://github.com/mahmoodlab/HistoFL</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>Federated learning</kwd>
      <kwd>Pathology</kwd>
      <kwd>Computational pathology</kwd>
      <kwd>Whole slide imaging</kwd>
      <kwd>Split learning</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="S1">
    <label>1.</label>
    <title>Introduction</title>
    <p id="P3">The emerging field of computational pathology holds great potential in increasing objectivity and enhancing precision of histopathological examination of tissue. Machine learning – and deep learning in particular – have demonstrated unprecedented performance in various pathology tasks such as characterization of a disease phenotype (<xref rid="R56" ref-type="bibr">Wang et al., 2020</xref>; <xref rid="R63" ref-type="bibr">Zhou et al., 2019</xref>; <xref rid="R2" ref-type="bibr">Anand et al., 2020</xref>; <xref rid="R8" ref-type="bibr">Bulten et al., 2020</xref>; <xref rid="R38" ref-type="bibr">Mahmood et al., 2019</xref>), quantification of the tumor microenvironment (<xref rid="R26" ref-type="bibr">Javed et al., 2020</xref>; <xref rid="R21" ref-type="bibr">Graham et al., 2019</xref>; <xref rid="R50" ref-type="bibr">Schapiro et al., 2017</xref>), prediction of survival (<xref rid="R42" ref-type="bibr">Muhammad et al., 2019</xref>) and treatment response (<xref rid="R44" ref-type="bibr">Niazi et al., 2019</xref>; <xref rid="R6" ref-type="bibr">Bera et al., 2019</xref>), and integration of genomics with histology for improved patient stratification (<xref rid="R9" ref-type="bibr">Chen et al., 2020</xref>; <xref rid="R41" ref-type="bibr">Mobadersany et al., 2018</xref>; <xref rid="R31" ref-type="bibr">Lazar et al., 2017</xref>). Thanks to the ability of such algorithms to mine sub-visual features – even beyond the scope of known pathological markers – deep learning models have managed to tackle challenging tasks such as estimating primary source for metastatic tumors of unknown origin, identify- ing novel features of prognostic relevance (<xref rid="R59" ref-type="bibr">Yamamoto et al., 2019</xref>; <xref rid="R45" ref-type="bibr">Pell et al., 2019</xref>; <xref rid="R6" ref-type="bibr">Bera et al., 2019</xref>), and predicting genetic mutations from histomorphologic images only, without the use of immunohistochemical staining (<xref rid="R15" ref-type="bibr">Coudray et al., 2018</xref>). Among various approaches, weakly-supervised methods such as attention MIL (<xref rid="R35" ref-type="bibr">Lu et al., 2019</xref>, <xref rid="R37" ref-type="bibr">2020a</xref>) appear well-suited to potential adoption in clinical practice. Xiao et al. recently presented a censoring-aware deep ordinal regression method for survival prediction in computational pathology <xref rid="R58" ref-type="bibr">Xiao et al. (2020)</xref>. These models learn from weak annotations in the form of image or patient-level labels which can include labels such as diagnosis or survival associated with the patient. Such information is readily available in clinical records and thus the data annotation does not introduce significant overhead over standard clinical workflow, in contrast to pixel-level annotations of regions of interest required by supervised models.</p>
    <p id="P4">As in all machine learning affairs, the model’s accuracy and robustness can be significantly increased by incorporating diverse data reflecting variations in underlying patient populations, as well as data collection and preparation protocols. Specifically, in pathology, whole slide images (WSIs) used for computational analysis can exhibit immense heterogeneity. Such diversities arise from not only the patient group corresponding to the histology specimens and variations in the tissue preparation, fixation and staining protocols, but also different scanner hardware that are used for digitization. While it may be possible and desirable to gain increased exposure to such heterogeneity through agglomeration of medical data from multiple institutions into a centralized data repository in order to develop more generalizable models, data centralization poses challenges not only in the form of regulatory and legal concerns (e.g. differing standards for data interoperability may preclude data transfer among institutions <xref rid="R51" ref-type="bibr">Scheibner et al. (2020)</xref>) but also technical difficulties such as high cost of transfer and storage of huge quantities of data. The latter is particularly relevant for computational pathology at scale since just 500 gp WSIs can be as large as the entirety of ImageNet (<xref rid="R16" ref-type="bibr">Deng et al., 2009</xref>).</p>
    <p id="P5">Federated learning (<xref rid="R60" ref-type="bibr">Yang et al., 2019</xref>; <xref rid="R30" ref-type="bibr">Konecˇny’ et al., 2016</xref>; <xref rid="R40" ref-type="bibr">McMahan et al., 2017</xref>; <xref rid="R47" ref-type="bibr">Rieke et al., 2020</xref>) offers means to mitigate these challenges by enabling algorithms to learn from decentralized data distributed across various institutions. In this way, sensitive patient data are never transferred beyond the safety of institutional firewalls, and instead, the model training and validation occur locally at each institution and only the model specifics (e.g. parameters or gradients) are transferred. In general, federated learning can be achieved through two approaches. 1) Master-server: a master-server is used to transfer the model to each node (i.e. participating institution), where the model trains for several iterations using the local data. The master-server then collects the model parameters from each node, aggregates them in some manner, and updates the parameters of the global model. Updated parameters are then transferred back to the local nodes for the next iteration. 2) Peer-to-peer: each node transfers the locally-trained parameters to some or all of its peers and each node does its own parameter aggregation. The benefit of the master-server approach is that all governing mechanisms are separated from the local nodes which allows for easier protocol updates and inclusion of new institutions. In contrast, the peer-to-peer approach is less flexible – since all the protocols must be agreed-on in advance – however, the absence of a single controlling entity might be preferred in some cases e.g. due to lower costs or greater decentralization.</p>
    <p id="P6">Although the nodes never transfer data themselves – only the model specifics – if leaked or attacked these can be sufficient to indirectly expose sensitive private information. Data anonymization alone does not provide sufficient protection (<xref rid="R48" ref-type="bibr">Rocher et al., 2019</xref>) since parts of the training data can be reconstructed by inversion of model parameters (<xref rid="R12" ref-type="bibr">Carlini et al., 2019</xref>; <xref rid="R62" ref-type="bibr">Zhang et al., 2020</xref>), gradients (<xref rid="R64" ref-type="bibr">Zhu et al., 2019</xref>; <xref rid="R20" ref-type="bibr">Geiping et al., 2020</xref>), or through adversarial attacks (<xref rid="R57" ref-type="bibr">Wang et al., 2019</xref>; <xref rid="R22" ref-type="bibr">Hitaj et al., 2017</xref>). This is particularly worrisome in radiology where the medical scans can be used to reconstruct a patient’s face or body image. Even though histology data do not hold such a direct link with patient identity, it might still allow an indirect patient identification e.g. in the case of rare diseases. The design of countermeasures for increasing differential privacy is thus a very active field of research (<xref rid="R29" ref-type="bibr">Kaissis et al., 2020</xref>; <xref rid="R28" ref-type="bibr">Kairouz et al., 2019</xref>). A popular strategy in the medical field is a contamination of the input data (<xref rid="R11" ref-type="bibr">Cheu et al., 2019</xref>) or the model parameters (<xref rid="R17" ref-type="bibr">Dong et al., 2019</xref>) with certain levels of noise. This de- creases the individually recognizable information while preserving the global distribution of the data (<xref rid="R29" ref-type="bibr">Kaissis et al., 2020</xref>).</p>
    <p id="P7">Though federated learning was originally proposed for non-clinical use, since its inception in <xref rid="R30" ref-type="bibr">Konecˇny’ et al. (2016)</xref>, it has already appeared in some medical applications. These include large-scale multicenter studies of genomics (<xref rid="R39" ref-type="bibr">Mandl et al., 2020</xref>; <xref rid="R46" ref-type="bibr">Rehm, 2017</xref>; <xref rid="R25" ref-type="bibr">Jagadeesh et al., 2017</xref>), electronic health records (<xref rid="R7" ref-type="bibr">Brisimi et al., 2018</xref>; <xref rid="R13" ref-type="bibr">Choudhury et al., 2019a</xref>, <xref rid="R14" ref-type="bibr">b</xref>), or wearable health devices (<xref rid="R10" ref-type="bibr">Chen et al., 2020</xref>). In the field of medical imaging, federated learning is particularly popular in the neurosciences. So far it has been applied in tasks such as brain tumor (<xref rid="R33" ref-type="bibr">Li et al., 2019</xref>; <xref rid="R52" ref-type="bibr">Sheller et al., 2018</xref>) and brain tissue (<xref rid="R49" ref-type="bibr">Roy et al., 2019</xref>) segmentation, EEG signal classification (<xref rid="R27" ref-type="bibr">Ju et al., 2020</xref>), analysis of fMRI scans of patients with autism (<xref rid="R34" ref-type="bibr">Li et al., 2020b</xref>) or MRI scans of neurodegenerative disease (<xref rid="R54" ref-type="bibr">Silva et al., 2019</xref>). Further adoption of federated learning in other medical domains is strongly anticipated due to the increasing demand for large and inter-institutional studies.</p>
    <p id="P8">One of the fields that would strongly benefit from the federated framework is computational pathology (<xref rid="R4" ref-type="bibr">Andreux et al., 2020b</xref>, <xref rid="R3" ref-type="bibr">a</xref>; <xref rid="R47" ref-type="bibr">Rieke et al., 2020</xref>). Since histopathologic diagnosis is the gold standard for many diseases, pathology data is largely available in almost any hospital. Federated learning would in principle enable deep learning models to learn from much larger and more diverse multi-institutional data sources without the challenges associated with data centralization and healthcare interoperability. Furthermore, while fully-supervised approaches are burdened by the need for time-costly pixel-level annotation based on pathologist expertise, weakly-supervised approaches such as MIL simplify collaborative efforts by alleviating the requirement for such human expertise and the burden of creating pixel-level labels under unified annotation protocol in all participating institutions.</p>
    <p id="P9">Herin, we present the key contributions of our work as follows:</p>
    <list list-type="order" id="L1">
      <list-item>
        <p id="P10">We present a large-scale computational pathology study to demonstrate the feasibility and effectiveness of privacy-preserving federated learning using thousands of gigapixel whole slide images from multiple institutions.</p>
      </list-item>
      <list-item>
        <p id="P11">We account for the challenges associated with the lack of de- tailed annotations in most real world whole slide histopathology datasets and demonstrate how federated learning can be coupled with weakly-supervised multiple instance learning to perform both binary and multi- class classification problems (demonstrated on breast cancer and renal cell cancer histological subtyping) using only slide-level labels for supervision.</p>
      </list-item>
      <list-item>
        <p id="P12">We extend the usage of attention-based pooling in multiple instance learning-based classification and present an interpretable, weakly-supervised framework for survival prediction (demonstrated on renal cell carcinoma patients) in computational pathology using whole slide images and patient-level prognostic information.</p>
      </list-item>
      <list-item>
        <p id="P13">We further validate the effectiveness of weakly-supervised deep survival models in a federated framework, paving the way for the development of prognostic models trained on multi-institutional cohorts with diverse populations.</p>
      </list-item>
    </list>
    <p id="P14">We also make available an easy-to-use federated learning for computational pathology software package: <ext-link xlink:href="http://github.com/mahmoodlab/HistoFL" ext-link-type="uri">http://github.com/mahmoodlab/HistoFL</ext-link></p>
  </sec>
  <sec id="S2">
    <label>2.</label>
    <title>Methods</title>
    <p id="P15">In this section, we will formulate our weakly-supervised federated multiple instance learning framework for performing privacy-preserving federated learning on data from across multiple institutions in the form of digitized gigapixel whole slide images.</p>
    <sec id="S3">
      <label>2.1.</label>
      <title>Differential privacy and federated learning</title>
      <p id="P16">In this problem, we want to develop deep learning models for performing predictive tasks on gigapixel WSIs by using data from different institutions. We denote data owned by institution <italic toggle="yes">i</italic> as <italic toggle="yes">D</italic><sub><italic toggle="yes">i</italic></sub>, which we assume for simplicity, is simply a data matrix with a finite number of entries. Suppose there are in total B sites and we denote their corresponding data silo as <italic toggle="yes">D</italic><sub>1</sub>, <italic toggle="yes">D</italic><sub>2</sub>, . . ., <italic toggle="yes">D</italic><sub><italic toggle="yes">B</italic></sub>. Since each medical institution will not share data with other parties due to various issues (e.g. institutional policies, incompatible data sharing protocols, technical difficulties associated with sharing large amount of data or fear of privacy loss), we cannot pool together their data and train a single deep learning model <italic toggle="yes">f</italic><sub>centralized</sub> for solving the desired task. Instead, our objective is to develop a federated learning framework where the data owners collaboratively train a model <italic toggle="yes">f</italic><sub>global</sub>, in which each data owner does not need to share its data <italic toggle="yes">D</italic><sub><italic toggle="yes">i</italic></sub> with others but can all benefit from the usefulness of the final model. In this paper, we adapted a master-server architecture, where each client node, representing each medical institution, locally utilizes the same deep learning architecture as one another and the global model, which we assume to be hosted on a central server hub. Each institution trains its respective model using local data and uploads the values of the trainable model parameters to the master server at a consistent frequency (i.e. once every one epoch of local training). We also adopt a randomized mechanism previously utilized on multi-site fMRI analysis (<xref rid="R32" ref-type="bibr">Li et al., 2020a</xref>), which allows each data owner to blur the shared weight parameters by a randomly noise vector <bold>z</bold><sub><italic toggle="yes">i</italic></sub> to protect against leak-age of patient-specific information. After the master server receives all the parameters, it averages them in the global model and sends new parameters back to each local model for synchronization. Differential privacy is a popular definition of individual privacy (<xref rid="R19" ref-type="bibr">Dwork et al., 2014</xref>; <xref rid="R53" ref-type="bibr">Shokri and Shmatikov, 2015</xref>), which informally means that the attacker can learn virtually nothing about an individual sample if it were removed from or added to the dataset (<xref rid="R1" ref-type="bibr">Abadi et al., 2016</xref>). In this problem, it means when a data point <italic toggle="yes">d</italic><sub><italic toggle="yes">i</italic></sub> is removed from or added to the dataset <italic toggle="yes">D</italic><sub><italic toggle="yes">i</italic></sub>, the attacker can not infer any information about <italic toggle="yes">d</italic><sub><italic toggle="yes">i</italic></sub> from the output of weights of model <italic toggle="yes">f</italic><sub>global</sub>. Differential privacy provides a bound s to represent the level of privacy preference that each institution can control. Formally, it says (<xref rid="R18" ref-type="bibr">Dwork et al., 2006</xref>), given a real-valued function <italic toggle="yes">f</italic>, and two adjacent datasets <italic toggle="yes">D</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">D</italic><sub><italic toggle="yes">i</italic></sub><sup><italic toggle="yes">’</italic></sup> differing by exactly one example, i.e., <inline-formula><mml:math id="M1" display="inline"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">f</italic>satisfies (ε, δ)- differential privacy if for any subset of outputs <italic toggle="yes">S</italic>:
<disp-formula id="FD1"><label>(1)</label><mml:math id="M2" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mi>ϵ</mml:mi></mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:msup><mml:mi>D</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:math></disp-formula></p>
      <p id="P17">where the introduction of the <italic toggle="yes">δ</italic> term relaxes the stricter notion of <italic toggle="yes">ε</italic>-differential privacy and allows the unlikely event of differential privacy being broken to occur with a small probability.</p>
      <p id="P18">To satisfy (<italic toggle="yes">ε</italic>, <italic toggle="yes">δ</italic>)-differential privacy, first, we provide the definition of <italic toggle="yes">l</italic><sub>2</sub> sensitivity of <italic toggle="yes">f</italic>, denoted by Δ<sub>2</sub>(<italic toggle="yes">f</italic>) as the maximum difference in the outputs of f over all possible adjacent datasets <italic toggle="yes">D</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">D</italic><sub><italic toggle="yes">i</italic></sub>
<sup><italic toggle="yes">’</italic></sup>:
<disp-formula id="FD2"><label>(2)</label><mml:math id="M3" display="block"><mml:mrow><mml:msub><mml:mtext>Δ</mml:mtext><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></disp-formula></p>
      <p id="P19">For arbitrary <inline-formula><mml:math id="M4" display="inline"><mml:mrow><mml:mi>ε</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, as stated by Theorem 3.22 (<xref rid="R19" ref-type="bibr">Dwork et al., 2014</xref>), adding random noise to f that is generated from a Gaussian distribution with zero mean and standard deviation σ, i.e., <inline-formula><mml:math id="M5" display="inline"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, will result in <italic toggle="yes">f</italic> satisfying <inline-formula><mml:math id="M6" display="inline"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ε</mml:mi><mml:mo>,</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>-differential privacy if <inline-formula><mml:math id="M7" display="inline"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>≥</mml:mo><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:msub><mml:mtext>Δ</mml:mtext><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>ϵ</mml:mi></mml:mfrac></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M8" display="inline"><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> ln <inline-formula><mml:math id="M9" display="inline"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1.25</mml:mn></mml:mrow><mml:mi>δ</mml:mi></mml:mfrac></mml:mrow></mml:math></inline-formula>. After rewriting the two inequalities, in other words, for any choice of <italic toggle="yes">ε, (ε, δ)</italic> -differential privacy can be satisfied for <italic toggle="yes">f</italic> by using the Gaussian mechanism, where <italic toggle="yes">δ</italic> is related to the variance of the Gaussian noise distribution via:
<disp-formula id="FD3"><label>(3)</label><mml:math id="M10" display="block"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>≥</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msubsup><mml:mtext>Δ</mml:mtext><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>⇒</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&gt;</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>ln</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1.25</mml:mn></mml:mrow><mml:mi>δ</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mtext>Δ</mml:mtext><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mtext>Δ</mml:mtext><mml:mn>2</mml:mn></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>&gt;</mml:mo><mml:mi>ln</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1.25</mml:mn></mml:mrow><mml:mi>δ</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mspace linebreak="newline"/><mml:mrow><mml:mo>⇒</mml:mo><mml:mfrac><mml:mrow><mml:mn>1.25</mml:mn></mml:mrow><mml:mi>δ</mml:mi></mml:mfrac><mml:mo>&lt;</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mtext>Δ</mml:mtext><mml:mn>2</mml:mn></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mo>&gt;</mml:mo><mml:mfrac><mml:mn>5</mml:mn><mml:mn>4</mml:mn></mml:mfrac><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mtext>Δ</mml:mtext><mml:mn>2</mml:mn></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p id="P20">In our federated learning setting, <italic toggle="yes">f</italic> involves a neural network consisting of many layers of trainable parameters making computing <inline-formula><mml:math id="M11" display="inline"><mml:mrow><mml:msub><mml:mtext>Δ</mml:mtext><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> intractable. However, without loss of generality, if we assume <inline-formula><mml:math id="M12" display="inline"><mml:mrow><mml:msub><mml:mtext>Δ</mml:mtext><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, we see that for a given level of <italic toggle="yes">δ</italic>, increasing σ will enable a smaller <italic toggle="yes">ε</italic> to be satisfied. Following <xref rid="R34" ref-type="bibr">Li et al., (2020b)</xref>, we let <inline-formula><mml:math id="M13" display="inline"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mi>η</mml:mi></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">η</italic> is the standard deviation of the weight parameters of each layer in the neural network, effectively linking <italic toggle="yes">α</italic>, a parameter adjustable for participating institutions, to the level of differential privacy protection.</p>
    </sec>
    <sec id="S4">
      <label>2.2.</label>
      <title>Data preprocessing</title>
      <p id="P21">We processed and analyzed all of our WSI data at 20 × magnification. Due to the lack of labeled ROIs and the intractable computational expense of deploying a convolutional neural network (CNN) directly to the whole spatial extent of each WSI, we utilize a form of weakly-supervised machine learning known as multiple instance learning (MIL). Under the MIL framework, each WSI is treated as a collection (bag) of smaller regions (instances), enabling the model to learn directly from the bag-level label (diagnosis or survival information) during training. The details of the MIL-inspired weakly-supervised learning algorithms we use are described in <xref rid="S5" ref-type="sec">Sections 2.3</xref> and <xref rid="S6" ref-type="sec">2.4</xref>. To construct the MIL bags, we utilize the CLAM (<xref rid="R37" ref-type="bibr">Lu et al., 2020a</xref>) WSI processing pipeline to automatically segment the tissue regions in each WSI and divide them into <italic toggle="yes">M</italic> 256 × 256 image crops (instances), where <italic toggle="yes">M</italic> varies with the amount of tissue content in each slide. To overcome the computational challenges resulting from the enormous sizes of gigapixel WSI bags, each 256 × 256 RGB instance further undergoes dimensionality-reduction via a pretrained ResNet50 CNN encoder (truncated after the 3rd residual block for spatial average pooling), and is embedded as a 1024-dimensional feature vector for efficient training and inference. Accordingly, each WSI in the dataset is represented by a <italic toggle="yes">M</italic> × 1024 matrix tensor.</p>
      <p id="P22">For survival prediction, all WSIs corresponding to each patient case are analyzed collectively, i.e., for a case with <italic toggle="yes">N</italic> WSIs represented by individual bags of size <inline-formula><mml:math id="M14" display="inline"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> respectively, the bags are concatenated along the first dimension to form a single patient bag of dimensions <inline-formula><mml:math id="M15" display="inline"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mn>1024</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p>
    </sec>
    <sec id="S5">
      <label>2.3.</label>
      <title>Weakly-supervised learning on WSIs</title>
      <p id="P23">We adopted a multiple instance learning-based framework for weakly-supervised classification and survival prediction and use it as the basis for performing federated learning on gigapixel WSIs. We begin by describing the weakly-supervised learning algorithms in the case of a single local model (no federated learning). Each model consists of a projection module <inline-formula><mml:math id="M16" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>proj</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, an attention module <inline-formula><mml:math id="M17" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>attn</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, and a prediction layer <inline-formula><mml:math id="M18" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>pred</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. The projection module consists of sequential, trainable fully-connected layers that project the fixed feature embeddings obtained using a pretrained feature encoder into a more compact, feature space specific to histopathology images of the chosen disease model. Given the <italic toggle="yes">j</italic>th incoming WSI/patient bag of <italic toggle="yes">M</italic><sub><italic toggle="yes">j</italic></sub> patch embeddings in the form of a <inline-formula><mml:math id="M19" display="inline"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mn>1024</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> matrix tensor, for simplicity, we use a single linear layer <inline-formula><mml:math id="M20" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mrow><mml:mtext>proj</mml:mtext></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mn>512</mml:mn><mml:mo>×</mml:mo><mml:mn>1024</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> to project incoming patch-level embeddings into a 512-dimensional latent space, denoted by <inline-formula><mml:math id="M21" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mn>512</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. The attention module <inline-formula><mml:math id="M22" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>attn</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> uses attention-based pooling (<xref rid="R24" ref-type="bibr">Ilse et al., 2018</xref>) to identify information rich patches/locations from the slides and aggregates their information into a single global representation for making a prediction at the bag level. We use the gated variant of the attention network architecture introduced by <xref rid="R24" ref-type="bibr">Ilse et al. (2018)</xref>. Accordingly, <inline-formula><mml:math id="M23" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>attn</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> consists of 3 fully-connected layers with weights <bold>U</bold><sub>a</sub>, <bold>V</bold><sub>a</sub> and <bold>W</bold><sub>a</sub> and learns to assign an attention score to each patch embedding <inline-formula><mml:math id="M24" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mn>512</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> (each row entry in <bold>H</bold><sub><italic toggle="yes">j</italic></sub>), indicating its contribution to the bag-level feature representation <inline-formula><mml:math id="M25" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mn>512</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="M26" display="inline"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> represents the score for the <italic toggle="yes">m</italic><sup>th</sup> patch and is given by:
<disp-formula id="FD4"><label>(4)</label><mml:math id="M27" display="block"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>tanh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">V</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>⊤</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⊙</mml:mo><mml:mtext>sigm</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">U</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>⊤</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>tanh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">V</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>⊤</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⊙</mml:mo><mml:mtext>sigm</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">U</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>⊤</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
      <p id="P24">Alternatively, the attention score vector for the whole bag is denoted by: <inline-formula><mml:math id="M28" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>attn</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Subsequently, the bag-level representation <inline-formula><mml:math id="M29" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is calculated by using the predicted attention scores as weights for averaging all the feature embeddings in the bag as:
<disp-formula id="FD5"><label>(5)</label><mml:math id="M30" display="block"><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>Attn</mml:mtext><mml:mo>-</mml:mo><mml:mtext>pool</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p>
      <p id="P25">We used a 256-dimensional representation for the hidden layers in the attention network and apply Dropout with <italic toggle="yes">p</italic> = 0.25 to these activations for regularization - namely, <inline-formula><mml:math id="M31" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">U</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mn>256</mml:mn><mml:mo>×</mml:mo><mml:mn>512</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M32" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">V</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mn>256</mml:mn><mml:mo>×</mml:mo><mml:mn>512</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M33" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>256</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. Lastly, the prediction layer <inline-formula><mml:math id="M34" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>pred</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> maps the bag representation <inline-formula><mml:math id="M35" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> to predictions logits <bold>s</bold><sub><italic toggle="yes">j</italic></sub>, using a different activation function and loss function for classification and survival prediction: <inline-formula><mml:math id="M36" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>pred</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The methodological details are described below.</p>
      <p id="P26">Weakly-supervised classification For weakly-supervised classification, we use the prediction layer <inline-formula><mml:math id="M37" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>pred</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> to predict the unnormalized class-probability logits <bold>s</bold><sub><italic toggle="yes">j</italic></sub>, which are then super-vised using the slide-level label <italic toggle="yes">Y</italic><sub><italic toggle="yes">j</italic></sub> by applying the softmax activation and computing the standard cross-entropy loss.</p>
      <p id="P27">Weakly-supervised survival prediction For weakly-supervised survival prediction using right-censored survival data, we consider discrete time intervals based on quantiles of event times for uncensored patients. More formally, we first consider the continuous time scale, where each labeled patient entry in the dataset, indexed by <italic toggle="yes">j</italic>, consists of a follow-up time <inline-formula><mml:math id="M38" display="inline"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mtext>cont</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>∞</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and a binary censorship status <italic toggle="yes">c</italic><sub>j</sub> where <italic toggle="yes">c</italic><sub><italic toggle="yes">j</italic></sub> = 1 indicates censorship (the event did not occur by the end of the follow-up period) while <italic toggle="yes">c</italic><sub><italic toggle="yes">j</italic></sub> = 0 indicates that the event occurred precisely at time <inline-formula><mml:math id="M39" display="inline"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mtext>cont</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Next, we partition the continuous time scale <inline-formula><mml:math id="M40" display="inline"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mtext>cont</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> into <italic toggle="yes">R</italic> non-overlapping bins: <inline-formula><mml:math id="M41" display="inline"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>.</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and discretize <inline-formula><mml:math id="M42" display="inline"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mtext>cont</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> accordingly where:
<disp-formula id="FD6"><label>(6)</label><mml:math id="M43" display="block"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mtext>disc</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mspace width="0.25em"/><mml:mtext>iff</mml:mtext><mml:mspace width="0.25em"/><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mtext>cont</mml:mtext></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p id="P28">In our study, we investigated <italic toggle="yes">R</italic> ∈ {2, 4, 6, 8} (results presented in <xref rid="S15" ref-type="sec">Section 3.5</xref>), where for each choice of <italic toggle="yes">R</italic> (number of bins), <inline-formula><mml:math id="M44" display="inline"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are determined based on quantiles of event times of uncensored patients. For simplicity, from now on we refer to a patient’s discrete survival time <inline-formula><mml:math id="M45" display="inline"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mtext>disc</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> simply as <italic toggle="yes">T</italic><sub><italic toggle="yes">j</italic></sub> and to be consistent with the notation we used for classification, we refer to the ground truth label as <italic toggle="yes">Y</italic><sub><italic toggle="yes">j</italic></sub>. Given a patient’s bag-level feature representation <inline-formula><mml:math id="M46" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> as calculated by the model, the prediction layer <inline-formula><mml:math id="M47" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>pred</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is responsible for modeling the hazard function defined as:
<disp-formula id="FD7"><label>(7)</label><mml:math id="M48" display="block"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>hazard</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>≥</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p id="P29">which relates to the survival function through:
<disp-formula id="FD8"><label>(8)</label><mml:math id="M49" display="block"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>surv</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>r</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mspace linebreak="newline"/><mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>r</mml:mi></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>hazard</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p id="P30">Since we consider the label set <inline-formula><mml:math id="M50" display="inline"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mtext>j</mml:mtext></mml:msub><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> to be the support of the hazard function, and R corresponding to number of bins of event times, <inline-formula><mml:math id="M51" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>pred</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is a linear layer with weight parameters <inline-formula><mml:math id="M52" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mrow><mml:mtext>pred</mml:mtext></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>×</mml:mo><mml:mn>512</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> Finally, given logits <inline-formula><mml:math id="M53" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>pred</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the sigmoid activation is applied to predict hazard distribution since it represents conditional probabilities, which are confined to positive real-values in the range of [0, 1]. For model optimization, we maximize the log likelihood function corresponding to a discrete survival model (<xref rid="R55" ref-type="bibr">Tutz et al., 2016</xref>), which is written as:
<disp-formula id="FD9"><label>(9)</label><mml:math id="M54" display="block"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>P</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>surv</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p id="P31">By rewriting <inline-formula><mml:math id="M55" display="inline"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>hazard</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>surv</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the loss we minimize based on the log likelihood function (<xref rid="R61" ref-type="bibr">Zadeh and Schmid, 2020</xref>) can be expressed as:
<disp-formula id="FD10"><label>(10)</label><mml:math id="M56" display="block"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>surv</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mspace linebreak="newline"/><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>surv</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mspace linebreak="newline"/><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>hazard</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p id="P32">During training, we additionally upweight the contribution of uncensored patient cases by minimizing a weighted sum of <italic toggle="yes">L</italic> and <inline-formula><mml:math id="M57" display="inline"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>uncensored</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, which is defined by the terms:
<disp-formula id="FD11"><label>(11)</label><mml:math id="M58" display="block"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>uncensored</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>surv</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mspace linebreak="newline"/><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>hazard</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p id="P33">Accordingly, the loss we optimize for weakly-supervised sur- vival prediction is:
<disp-formula id="FD12"><label>(12)</label><mml:math id="M59" display="block"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>surv</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>L</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mo>⋅</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>uncensored</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p>
    </sec>
    <sec id="S6">
      <label>2.4.</label>
      <title>Weakly-supervised federated learning with differential privacy</title>
      <p id="P34">For both classification and survival prediction, we train the models on each client server within a federated learning setup, where each model is trained locally and the weights of the model are collected each epoch and aggregated to update the central model. The central model then sends back the new weights to each client model (<xref rid="F1" ref-type="fig">Fig. 1</xref>). To preserve the differential privacy of the individual data located on each client server, we utilize a randomized mechanism, i.e., the Gaussian mechanism which we introduced in <xref rid="S3" ref-type="sec">Section 2.1</xref>. Hereby, our algorithm for collaboratively training server model and client models is shown in <xref rid="T1" ref-type="table">Algorithm 1</xref>.</p>
      <p id="P35">In the proceeding section, we demonstrate the feasibility, adaptability and interpretability of attention-based multiple instance federated learning on three different computational pathology problems: (A) Breast Invasive Carcinoma (BRCA) subtyping (B) Renal Cell Carcinoma (RCC) subtyping (C) Clear Cell Renal Cell Carcinoma (CCRCC) survival prediction.</p>
      <table-wrap position="anchor" id="T1">
        <label>Algorithm 1</label>
        <caption>
          <p id="P36">Privacy-preserving federated learning using attention-based multiple instance learning for multi-site histology-based classification and survival prediction.</p>
        </caption>
        <table frame="hsides" rules="none">
          <colgroup span="1">
            <col align="left" valign="middle" span="1"/>
          </colgroup>
          <tbody>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">Input:</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> I. WSI Data and weak annotation (e.g. patient diagnosis or prognosis) scattered among <italic toggle="yes">B</italic> participating institutional sites:</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">  <inline-formula><mml:math id="M60" display="inline"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">  <inline-formula><mml:math id="M61" display="inline"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represents the set of <italic toggle="yes">N</italic><sub><italic toggle="yes">i</italic></sub>. pairs of WSI data and corresponding label for training stored at site <italic toggle="yes">i</italic> (in survival prediction, <bold>X</bold><sub>i,j</sub>. is the set of all diagnostic WSIs for patient <italic toggle="yes">j</italic> whereas in classification, it is a single WSI). We use</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">  <inline-formula><mml:math id="M62" display="inline"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>X</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mstyle><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to denote WSI data-label pair after pre-processing (patching and feature extraction via a pretrained CNN feature encoder).</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> II. Neural network models on local clients <inline-formula><mml:math id="M63" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>local</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and global model <inline-formula><mml:math id="M64" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>global</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, stored on the central server. Each model <inline-formula><mml:math id="M65" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, consists of a projection module <inline-formula><mml:math id="M66" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext>proj</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, an attention module <inline-formula><mml:math id="M67" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext> attn</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and prediction layer <inline-formula><mml:math id="M68" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext>pred</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. We denote the weights of the local models as <inline-formula><mml:math id="M69" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mi mathvariant="bold">B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and weights of the global model as <inline-formula><mml:math id="M70" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mrow><mml:mtext>global</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>.</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> III. Noise generator <inline-formula><mml:math id="M71" display="inline"><mml:mrow><mml:mtext>M</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, which generates Gaussian random noise <inline-formula><mml:math id="M72" display="inline"><mml:mrow><mml:mi mathvariant="bold">z</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> where <italic toggle="yes">a</italic> denotes the noise level for and <italic toggle="yes">n</italic> is the standard deviation of a neural network weight matrix.</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> IV. Number of training epochs or federated rounds, <italic toggle="yes">K</italic>.</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> V. Optimizers <inline-formula><mml:math id="M73" display="inline"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mtext>opt</mml:mtext><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mtext>opt</mml:mtext><mml:mtext>B</mml:mtext></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> that update the model weights w.r.t a suitable loss metric <italic toggle="yes">L</italic> using gradient descent.</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> VI. Weight coefficient for each client during federated averaging, e.g. <inline-formula><mml:math id="M74" display="inline"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>∑</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>.</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> 1. initialize all model weights <inline-formula><mml:math id="M75" display="inline"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">W</mml:mi><mml:mrow><mml:mtext>global</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold">W</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold">W</mml:mi><mml:mi>B</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> 2. for <inline-formula><mml:math id="M76" display="inline"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> to <italic toggle="yes">K</italic> do</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> 3.  for <inline-formula><mml:math id="M77" display="inline"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> to <italic toggle="yes">B</italic> do</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> 4.   for <inline-formula><mml:math id="M78" display="inline"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> to <italic toggle="yes">Ni</italic> do</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">      <inline-formula><mml:math id="M79" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext>proj</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">      <inline-formula><mml:math id="M80" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext> attn</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> 5.     <inline-formula><mml:math id="M81" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:mtext>Attn</mml:mtext><mml:mspace width="0.25em"/><mml:mo>-</mml:mo><mml:mspace width="0.25em"/><mml:mtext>pool</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">      <inline-formula><mml:math id="M82" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext> pred</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mtext>bag</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">      <inline-formula><mml:math id="M83" display="inline"><mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">W</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>←</mml:mo><mml:msub><mml:mtext>opt</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold">W</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> 6.   end for</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> 7.  end for</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> 8.   <inline-formula><mml:math id="M84" display="inline"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">W</mml:mi><mml:mrow><mml:mtext>global</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>←</mml:mo><mml:msub><mml:mtext>Σ</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>γ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">W</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>M</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">W</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> 9.  for <inline-formula><mml:math id="M85" display="inline"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> to <italic toggle="yes">B</italic> do</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> 10.    <inline-formula><mml:math id="M86" display="inline"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">W</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:msubsup><mml:mi mathvariant="bold">W</mml:mi><mml:mrow><mml:mtext>global</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula></td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> 11.   end for</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> 12. end for</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1"> 13. return global model <inline-formula><mml:math id="M87" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mtext>global</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
  </sec>
  <sec id="S7">
    <label>3.</label>
    <title>Experiments and results</title>
    <sec id="S8">
      <label>3.1.</label>
      <title>Dataset description</title>
      <sec id="S9">
        <title>Weakly-supervised classification.</title>
        <p id="P37">To evaluate the proposed federated learning framework for weakly-supervised classification in histopathology, we examined two clinical diagnostic tasks for two separate disease models, namely, Renal Cell Carcinoma (RCC) and Breast Invasive Carcinoma (BRCA). For both tasks, we used publicly available WSIs from the TCGA (The Cancer Genome Atlas) in addition to in-house data collected at the Brigham and Women’s Hospital for model development and evaluation. In all cases, each gigapixel WSI is associated with a single ground truth slide-level diagnosis and no pixel or ROI-level annotation available.</p>
      </sec>
      <sec id="S10">
        <title>Breast cancer dataset.</title>
        <p id="P38">For the first binary task of classifying primary Breast Invasive Carcinoma as either lobular or ductal morphologial subtypes, 1056 FFPE dianostic WSIs (211 lobular and 845 ductal) were retrieved from the TCGA BRCA (Breast Invasive Carcinoma) study and our in-house dataset consists of 1070 WSIs of primary breast cancer (158 lobular and 912 ductal). Accordingly, in total we used 2126 breast WSIs (369 lobular and 1757 ductal).</p>
        <p id="P39">Renal cell cancer dataset In the second task of multi-class classification of Renal Cell Carcinoma into clear cell (CCRCC), papillary cell (PRCC) and chromophobe cell (CHRCC) morphological subtypes, we collected 937 WSIs (519 CCRCC, 297 PRCC and 121 CHRCC) from the corresponding studies in TCGA and our in-house dataset consists of 247 WSIs of primary Renal cell carcinoma (184 CCRCC, 40 PRCC and 23 CHRCC). In total we used 1184 kidney WSIs (703 CCRCC, 337 PRCC and 144 CHRCC).</p>
      </sec>
      <sec id="S11">
        <title>Weakly-supervised survival prediction.</title>
        <p id="P40">We also examined federated learning for weakly-supervised survival prediction based on histopathology. Specifically, for patients diagnosed with renal clear cell carcinoma, we used right-censored, overall survival data from the TCGA-KIRC available via the cbio- portal. In total, 511 patient cases were retrieved from TCGA-KIRC. All diagnostic WSIs corresponding to each patient case were used for analysis.</p>
      </sec>
    </sec>
    <sec id="S12">
      <label>3.2.</label>
      <title>Experiments on multi-institutional WSI data</title>
      <p id="P41">In each of the two weakly-supervised classification tasks, we considered four distinct “institutional sites”. These sites were identified by first naturally considering all in-house BWH data as one distinct institutional site. Then, for each TCGA cohort, we identified the tissue source site for each patient case. For the purpose of simulating federated learning across multiple institutions, we then randomly partitioned the set of unique tissue source sites into 3 non-overlapping, roughly equal-sized subsets, and grouped together the data corresponding to each subset of tissue source sites to serve as 3 distinct institutional sites. Similarly, for CCRCC survival prediction, we used 3 institutional sites created by randomly partitioning the tissue source sites that contributed to the TCGA-KIRC cohort. The details of these partitions are summarized below for each task (<xref rid="T2" ref-type="table">Tables 1</xref>–<xref rid="T4" ref-type="table">3</xref>).</p>
      <p id="P42">Once the institutional sites were identified, the dataset is then randomly partitioned into a training, validation and test set, respectively consisting of 70, 15 and 15% of patient cases from each site, repeated using 5 different random seeds. For classification, given the class-imbalance nature of the datasets, within each institutional site, stratified sampling is used to ensure sufficient representation of minority classes across the training, validation and test set. Additionally, if a single patient case contains multiple diagnostic slides, all of them were drawn together into the same set when that patient is sampled. Similarly, for survival prediction, sampling is stratified based on both the discretized follow-up time (binned based on quartiles of event times of uncensored patients) and the censorship status.</p>
      <p id="P43">For each task, we used the model architecture and loss function as described in detail in <xref rid="S5" ref-type="sec">Section 2.3</xref>. To train each local model, we used the Adam optimizer with default hyperparamters, a learning rate of 2e-4 and <italic toggle="yes">l</italic><sub>2</sub> weight decay of 1e-5 for all experiments. For survival prediction, <italic toggle="yes">β</italic>, which controls how much the contribution of uncensored patients should be upweighted, was set to 0.15. Additionally, we monitored the validation performance each epoch and performed early stopping on the global model when it does not improve for 20 consecutive epochs (federated rounds), but only after it has been trained for at least 35 epochs. The model check-point with the best validation performance (lowest loss for classification and best c-index for survival prediction) was then used to evaluate on the held-out test set. For each task, we investigated 3 scenarios: (1) training on data from a single institution, (2) training a single model by centralizing or pooling together all data (no federated learning) and (3) training on data from all institutions using federated averaging, as described in <xref rid="S6" ref-type="sec">Section 2.4</xref> and outlined in details in <xref rid="T1" ref-type="table">Algorithm 1</xref>.</p>
      <p id="P44">For scenario 3), while the originally proposed federated aver- aging algorithm (<xref rid="R40" ref-type="bibr">McMahan et al., 2017</xref>) weighs the contribution of each local model by its respective number of training samples <inline-formula><mml:math id="M88" display="inline"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mtext>Σ</mml:mtext><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> when updating the weights of the central model, <xref rid="R32" ref-type="bibr">Li et al. (2020a)</xref> chose to weigh each local model equally <inline-formula><mml:math id="M89" display="inline"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>B</mml:mi></mml:mfrac></mml:mrow></mml:math></inline-formula>. In our study, we stick to the design of the original algorithm but also investigate the performance between weighted averaging vs. simple averaging in <xref rid="S16" ref-type="sec">Section 3.6</xref>, where results show minimal difference between the two design choices. We also studied changing the strength of Gaussian random noise added to local model weights during federated averaging, and its effect on the performance of the central model. As described in <xref rid="S3" ref-type="sec">Section 2.1</xref>, for each model <italic toggle="yes">f</italic><sub><italic toggle="yes">i</italic></sub>, we generated Gaus- sian noise <inline-formula><mml:math id="M90" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold">z</mml:mi><mml:mtext>i</mml:mtext></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> where <italic toggle="yes">η</italic> is the standard deviation of the weight parameters in each individual layer of the network and <italic toggle="yes">α</italic> controls the noise level. In our experiments, we varied <inline-formula><mml:math id="M91" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>1.0</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. In the next section, we present results demonstrating the effectiveness of weakly-supervised fed- erated learning for both binary and multi- class classification, as well as survival prediction.</p>
    </sec>
    <sec id="S13">
      <label>3.3.</label>
      <title>Experimental results</title>
      <p id="P45">We evaluated our proposed weakly-supervised, federating learning framework on both a multi-class and a binary classification problem (<xref rid="F2" ref-type="fig">Figs. 2</xref>, <xref rid="F3" ref-type="fig">3</xref>, <xref rid="T5" ref-type="table">Tables 4</xref> and <xref rid="T6" ref-type="table">5</xref>) as well as survival prediction (<xref rid="F4" ref-type="fig">Fig. 4</xref> and <xref rid="T7" ref-type="table">Table 6</xref>) and demonstrated the feasibility of performing privacy-preserving, federated learning on WSI data in all tasks.</p>
      <p id="P46">In both BRCA subtyping (<xref rid="T5" ref-type="table">Table 4</xref>) and RCC subtyping (<xref rid="T6" ref-type="table">Table 5</xref>), the model performance is evaluated using a wide variety of classification metrics including the AUC of the ROC curve, mean average precision (mAP), classification error, F1 score, balanced accuracy (bAcc) and Cohen’s <italic toggle="yes">κ</italic> (macro-averaging is used to extend binary classification metrics to multi-class classification in the case of RCC subtyping). We found that the model performance benefited significantly from training on multi-institutional data using federated learning, compared to learning from data within a single institution. In fact, we found the models trained using federated learning to be generally competitive in performance even when compared to scenario 2), where model is trained by first centralizing (sharing) all training data from each institution. This is true even when different levels of random noise are applied for privacy preservation. For <inline-formula><mml:math id="M92" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, for BRCA subtyping, the mean test AUC ranged from 0.833 to 0.862 when using federated learning for different levels of random noise and for RCC subtyping, the macro-averaged test AUC ranged from 0.974 to 0.976. In addition to strong performance, in <xref rid="F3" ref-type="fig">Fig. 3</xref>, we also demonstrated that models trained using privacy-preserving federated learning can saliently localize regions of high diagnostic relevance and identify morphological features characteristic of each underlying tumor subtype. However, consistent with previous studies (<xref rid="R34" ref-type="bibr">Li et al., 2020b</xref>), we found that the model performance significantly deteriorated when α was set too high (e.g., <italic toggle="yes">α</italic> = 1), showing that there is indeed a trade off between model performance and privacy protection.</p>
      <p id="P47">For survival prediction, we evaluated the model performance using the c-Index, which measures the concordance in ranking patients by their assigned risk w.r.t. their ground truth survival time, as well as the average cumulative/dynamic AUC (<xref rid="R23" ref-type="bibr">Hung and Chiang, 2010</xref>) for time dependent ROC curves, which quantifies the ability of a model to distinguish subjects who fail by a given time with subjects who fail after this time, across many time points. Additionally, based on the predicted risk score for each patient in the test set, we performed hypothesis testing using the log-rank test to assess whether each model can stratify patients into distinct high risk and low risk groups (cutoff based on 50th percentile of the model’s predicted risk scores) that resulted in statistically significantly different survival distributions (<xref rid="T7" ref-type="table">Table 6</xref>). When trained using data from a single institution, only 1 out of 3 institutions was able to yield a model that can stratify patients into distinct survival groups based on predicted risk scores. Notably, we observed that the model trained using data local to site 3 delivered performance comparable to that of centralized training and using federated learning. This can likely be attributed to site 3 having a much larger local dataset (<italic toggle="yes">n</italic> = 331) compared to the other 2 sites (<italic toggle="yes">n</italic> = 104 and <italic toggle="yes">n</italic> = 76 respectively). Similar dataset-size imbalance among different participating institutions frequently occurs in the real-world and is also reflected in the imbalanced distribution of patient cases among the original tissue source sites in the TCGA. In settings where the data at a single institution are insufficient (e.g. site 1 and 2) in either size or diversity to yield a meaningful, generalizable model, soliciting data from collaborating institutions or other external sources may be necessary. On the other hand, we found that federated learning can overcome this challenge as all models trained in the federated framework (with the exception of when using <italic toggle="yes">α</italic> = 1) resulted in statistical significance (p-value &lt; 0.05) and produced reasonable performance both in terms of c-Index values and average cumulative/dynamic AUC.</p>
      <p id="P48">Similar to classification, we visualized attention heatmaps over the entire WSI for low risk (long survival) and high risk (short sur-vival) patients in order to interpret the regions and morphological features learned by the weakly-supervised model to be of high prognostic relevance (<xref rid="F4" ref-type="fig">Fig. 4</xref>).</p>
    </sec>
    <sec id="S14">
      <label>3.4.</label>
      <title>Intra- and inter-center performance</title>
      <p id="P49">The ability of a trained AI model to generalize to unseen, heterogeneous data with population and institutional-site specific variations is not only desirable but also crucial to its reliability and usability in real-world settings. As such, for both classification and survival prediction tasks, we examine more closely the intra- versus inter-center performance of different approaches. As expected, federated learning not only enables better generalization on average, as measured in terms of both micro- and macro-averaged scores (ROC AUC for classification and c-indices for survival prediction) across all sites, but is also mostly competitive in performance against models developed using single-site data on their respective intra-center portion of the test data (<xref rid="T8" ref-type="table">Tables 7</xref>, <xref rid="T9" ref-type="table">8</xref>, <xref rid="T10" ref-type="table">9</xref>.)</p>
    </sec>
    <sec id="S15">
      <label>3.5.</label>
      <title>Comparison of weakly-supervised survival prediction and existing strategies</title>
      <p id="P50">In this section, we investigate the effectiveness of the proposed weakly-supervised survival prediction method for different hyper-parameter choices, and in comparison with existing strategies such as manual grading by pathologists (low vs. high fuhrman nuclear grade) in combination with other covariates such as age and gender on the aforementioned TCGA-KIRC dataset (<italic toggle="yes">n</italic> = 511). Both the “Grade” only and “Grade + Age + Gender” methods are trained based on the Cox proportional hazard models using the same 5-fold splits as the weakly-supervised survival models are trained in the “centralized” set- ting (without using federated learning). We observed that in general the performance difference between the deep learning model trained using different values of <italic toggle="yes">R</italic> are under a few percents, with <italic toggle="yes">R</italic> = 8 performing the best for the particular task (<xref rid="T12" ref-type="table">Table 11</xref>). Additionally we note that the cox proportional hazard model based on nuclear grade lags behind the weakly- supervised deep learning-based approach, and only matches its performance when combined with additional variables including age and gender, beyond histologic features made available to the deep learning model.</p>
    </sec>
    <sec id="S16">
      <label>3.6.</label>
      <title>Ablating hyperparamter choices in federated averaging</title>
      <p id="P51">Instead of aggregating the weights of local models after each epoch, a less frequent communication pace can be used. We investigated model performance for each task by varying <italic toggle="yes">E</italic>, the number of epochs each local model is updated before communicating with the central model for aggregation, for <italic toggle="yes">E</italic> ∈ {1, 2, 4, 8}. As shown in <xref rid="T11" ref-type="table">Table 10</xref>, for classification tasks, the resulting performance shows minimal difference for larger <italic toggle="yes">E</italic> (less frequent communication) while survival prediction a decrease in c-indices of around 2 – 3% was observed for <italic toggle="yes">E</italic> = 4 and <italic toggle="yes">E</italic> = 8 respectively. This could potentially be explained by the smaller training set sizes available for the task, which makes it easier for client models to overfit on their local training data when a longer communication pace is used.</p>
      <p id="P52">In addition to the weighted averaging aggregation used in the originally proposed federated averaging algorithm, where <inline-formula><mml:math id="M93" display="inline"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mtext>Σ</mml:mtext><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, and the contribution of each local model is weighted proportionally to the size of its training set, we investigate the alternative choice used by <xref rid="R32" ref-type="bibr">Li et al. (2020a)</xref>, <inline-formula><mml:math id="M94" display="inline"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>B</mml:mi></mml:mfrac></mml:mrow></mml:math></inline-formula>, where uniform weights are used for averaging the updated weights of different local models in each training round. The results are shown for both classification and survival tasks and for different levels of <italic toggle="yes">α</italic> (<xref rid="F5" ref-type="fig">Fig. 5</xref>), where minimal differences between the two design choices were observed.</p>
    </sec>
  </sec>
  <sec id="S17">
    <label>4.</label>
    <title>Conclusion</title>
    <p id="P53">Over the past several years, computational pathology has seen enormous growth due to deep learning achieving “clinical-grade” performance on many clinically-relevant pathology tasks. As a result, AI algorithms for pathology data have received considerable attention as an support decision system in assisting clinicians in pathology and laboratory medicine services, with recent FDA approval given to weakly-supervised AI algorithms for cancer diagnosis. Despite these breakthroughs, the development and validation in AI algorithms in pathology have been mainly limited to single-institutional datasets, which may not generalize at deployment time due to variations in the underlying patient population, staining protocols, and scanner hardware. Federated learning has been suggested as a path forward in enabling differential privacy and overcoming stagnant healthcare interoperability for sharing sensitive medical data. With increasing demand for multi-institutional studies for validating clinical-grade AI systems in pathology, the robust validation of federated learning systems, in both differential-privacy and model performance, is urgently needed to enable collaboration and validation of all AI systems that would participate in medical decision making.</p>
    <p id="P54">In this work, we demonstrate the feasibility and effectiveness of applying federated, attention-based weakly-supervised learning for general purpose classification and survival prediction on gigapixel whole slide images from different sites, without the need for institutions to directly share potentially sensitive patient data. Our proposed framework opens the possibility for multiple institutions to integrate their WSI datasets and train a more robust model that tends to generalize better on unseen data than models developed on data from a single institution, while also allowing participating institutions to preserve differential privacy via a randomized mechanism. Backed by a flexible and interpretable attention-based weakly-supervised learning framework, we believe our federated learning framework has the clear potential to be applied to many important computational pathology tasks beyond what we have already shown in this study.</p>
    <p id="P55">Decreasing barriers to cross-institutional collaborations in this way will be key to the future development of computational pathology tools. This is especially true in two applications: (1) rare diseases, where a single institution may not possess enough cases of a single entity to train an effective model on its own due to a lack of diversity in morphology, and (2) global health, in which AI algorithms are deployed and finetuned in low- and middle-income countries that lack access to pathology and laboratory medicine services (<xref rid="R43" ref-type="bibr">Nabi, 2018</xref>; <xref rid="R5" ref-type="bibr">Anglade et al., 2020</xref>; <xref rid="R36" ref-type="bibr">Lu et al., 2021</xref>). These techniques may also be useful in situations where transferring large quantities of physical or digital slides may be impossible due to institutional or governmental regulations. Models that give institutions greater control over their data while still achieving at or near state-of-the-art perfor- mance will be instrumental in progress towards democratized computational pathology.</p>
  </sec>
</body>
<back>
  <ack id="S18">
    <title>Acknowledgments</title>
    <p id="P56">The authors would like to thank Alexander Bruce for scanning internal cohorts of patient histology slides at BWH; Jing-wen Wang, Katerina Bronstein, Lia Cirelli and Sharifa Sahai for querying the BWH slide database and retrieving archival slides; Martina Bragg, Sarah Zimmet and Terri Mellen for administrative support. This work was supported in part by internal funds from BWH Pathology, NIH National Institute of General Medical Sciences (NIGMS) R35GM138216 (to F.M.), Google Cloud Research Grant and the Nvidia GPU Grant Program. R.J.C. was additionally supported by the NSF Graduate Research Fellowship. The content is solely the responsibility of the authors and does not reflect the official views of the NIH, NIGMS, NHGRI or the NSF.</p>
  </ack>
  <fn-group>
    <fn id="FN2">
      <p id="P57">Ethics oversight</p>
      <p id="P58">The study was approved by the Mass General Brigham (MGB) IRB office under protocol 2020P000233.</p>
    </fn>
    <fn fn-type="COI-statement" id="FN3">
      <p id="P59">Declaration of Competing Interest</p>
      <p id="P60">COI Statement The following applies to all authors included in this study, o All authors have participated in (a) conception and design, or analysis and interpretation of the data; (b) drafting the article or revising it critically for important intellectual content; and (c) approval of the final version. o This manuscript has not been submitted to, nor is under review at, another journal or other publishing venue. o The authors have no affiliation with any organization with a direct or indirect financial interest in the subject matter discussed in the manuscript.</p>
    </fn>
    <fn id="FN4">
      <p id="P61">CRediT authorship contribution statement</p>
      <p id="P62"><bold>Ming Y. Lu:</bold> Conceptualization, Visualization, Formal analysis, Writing – review &amp; editing. <bold>Richard J. Chen:</bold> Conceptualization, Visualization, Formal analysis, Writing – review &amp; editing. <bold>Dehan Kong:</bold> Formal analysis, Writing – review &amp; editing. <bold>Jana Lipkova:</bold> Visualization, Writing – review &amp; editing. <bold>Rajendra Singh:</bold> Writing – review &amp; editing. <bold>Drew F.K. Williamson:</bold> Formal analysis, Writing – review &amp; editing. <bold>Tiffany Y. Chen:</bold> Formal analysis, Writing – review &amp; editing. <bold>Faisal Mahmood:</bold> Conceptualization, Visualization, Supervision, Writing – review &amp; editing.</p>
    </fn>
  </fn-group>
  <ref-list>
    <title>References</title>
    <ref id="R1">
      <mixed-citation publication-type="confproc"><name><surname>Abadi</surname><given-names>M</given-names></name>, <name><surname>Chu</surname><given-names>A</given-names></name>, <name><surname>Goodfellow</surname><given-names>I</given-names></name>, <name><surname>McMahan</surname><given-names>HB</given-names></name>, <name><surname>Mironov</surname><given-names>I</given-names></name>, <name><surname>Talwar</surname><given-names>K</given-names></name>, <name><surname>Zhang</surname><given-names>L</given-names></name>, <year>2016</year>. <source>Deep learning with differential privacy</source>. In: <conf-name>Proceedings of the ACM SIGSAC Conference on Computer and Communications Security</conf-name>, pp. <fpage>308</fpage>–<lpage>318</lpage>.</mixed-citation>
    </ref>
    <ref id="R2">
      <mixed-citation publication-type="book"><name><surname>Anand</surname><given-names>D</given-names></name>, <name><surname>Gadiya</surname><given-names>S</given-names></name>, <name><surname>Sethi</surname><given-names>A</given-names></name>, <year>2020</year>. <source>Histographs: graphs in histopathology. Medical Imaging 2020: Digital Pathology</source>. <publisher-name>International Society for Optics and Photonics</publisher-name>.</mixed-citation>
    </ref>
    <ref id="R3">
      <mixed-citation publication-type="journal"><name><surname>Andreux</surname><given-names>M</given-names></name>, <name><surname>Manoel</surname><given-names>A</given-names></name>, <name><surname>Menuet</surname><given-names>R</given-names></name>, <name><surname>Saillard</surname><given-names>C</given-names></name>, <name><surname>Simpson</surname><given-names>C</given-names></name>, <year>2020a</year>. <article-title>Federated survival analysis with discrete-time cox models</article-title>. <source>arXiv preprint arXiv</source>: 2006.08997.</mixed-citation>
    </ref>
    <ref id="R4">
      <mixed-citation publication-type="book"><name><surname>Andreux</surname><given-names>M</given-names></name>, <name><surname>du Terrail</surname><given-names>JO</given-names></name>, <name><surname>Beguier</surname><given-names>C</given-names></name>, <name><surname>Tramel</surname><given-names>EW</given-names></name>, <year>2020b</year>. <part-title>Siloed federated learning for multi-centric histopathology datasets</part-title>. In: <source>Domain Adaptation and Representation Transfer, and Distributed and Collaborative Learning</source>. <publisher-name>Springer</publisher-name>, pp. <fpage>129</fpage>–<lpage>139</lpage>.</mixed-citation>
    </ref>
    <ref id="R5">
      <mixed-citation publication-type="journal"><name><surname>Anglade</surname><given-names>F</given-names></name>, <name><surname>Milner</surname><given-names>DA</given-names></name>, <name><surname>Brock</surname><given-names>JE</given-names></name>, <year>2020</year>. <article-title>Can pathology diagnostic services for cancer be stratified and serve global health?</article-title><source>Cancer</source><volume>126</volume>, <fpage>2431</fpage>–<lpage>2438</lpage>.<pub-id pub-id-type="pmid">32348564</pub-id></mixed-citation>
    </ref>
    <ref id="R6">
      <mixed-citation publication-type="journal"><name><surname>Bera</surname><given-names>K</given-names></name>, <name><surname>Schalper</surname><given-names>KA</given-names></name>, <name><surname>Rimm</surname><given-names>DL</given-names></name>, <name><surname>Velcheti</surname><given-names>V</given-names></name>, <name><surname>Madabhushi</surname><given-names>A</given-names></name>, <year>2019</year>. <article-title>Artificial intelligence in digital pathology—new tools for diagnosis and precision oncology</article-title>. <source>Nat. Rev. Clin. Oncol</source><volume>16</volume>, <fpage>703</fpage>–<lpage>715</lpage>.<pub-id pub-id-type="pmid">31399699</pub-id></mixed-citation>
    </ref>
    <ref id="R7">
      <mixed-citation publication-type="journal"><name><surname>Brisimi</surname><given-names>TS</given-names></name>, <name><surname>Chen</surname><given-names>R</given-names></name>, <name><surname>Mela</surname><given-names>T</given-names></name>, <name><surname>Olshevsky</surname><given-names>A</given-names></name>, <name><surname>Paschalidis</surname><given-names>IC</given-names></name>, <name><surname>Shi</surname><given-names>W</given-names></name>, <year>2018</year>. <article-title>Federated learning of predictive models from federated electronic health records</article-title>. <source>Int. J. Med. Inf</source><volume>112</volume>, <fpage>59</fpage>–<lpage>67</lpage>.</mixed-citation>
    </ref>
    <ref id="R8">
      <mixed-citation publication-type="journal"><name><surname>Bulten</surname><given-names>W</given-names></name>, <name><surname>Pinckaers</surname><given-names>H</given-names></name>, <name><surname>van Boven</surname><given-names>H</given-names></name>, <name><surname>Vink</surname><given-names>R</given-names></name>, <name><surname>de Bel</surname><given-names>T</given-names></name>, <name><surname>van Ginneken</surname><given-names>B</given-names></name>, <name><surname>van der Laak</surname><given-names>J</given-names></name>, <name><surname>Hulsbergen-van de Kaa</surname><given-names>C</given-names></name>, <name><surname>Litjens</surname><given-names>G</given-names></name>, <year>2020</year>. <article-title>Automated deep-learning system for gleason grading of prostate cancer using biopsies: a diagnostic study</article-title>. <source>Lancet Oncol</source>. <volume>21</volume>, <fpage>233</fpage>–<lpage>241</lpage>.<pub-id pub-id-type="pmid">31926805</pub-id></mixed-citation>
    </ref>
    <ref id="R9">
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>RJ</given-names></name>, <name><surname>Lu</surname><given-names>MY</given-names></name>, <name><surname>Wang</surname><given-names>J</given-names></name>, <name><surname>Williamson</surname><given-names>DFK</given-names></name>, <name><surname>Rodig</surname><given-names>SJ</given-names></name>, <name><surname>Lindeman</surname><given-names>NI</given-names></name>, <name><surname>Mahmood</surname><given-names>F</given-names></name>, <year>2020</year>. <article-title>Pathomic fusion: an integrated framework for fusing histopathology and genomic features for cancer diagnosis and prognosis</article-title>. <source>IEEE Trans. Med. Imaging</source><volume>11</volume>.</mixed-citation>
    </ref>
    <ref id="R10">
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>Y</given-names></name>, <name><surname>Qin</surname><given-names>X</given-names></name>, <name><surname>Wang</surname><given-names>J</given-names></name>, <name><surname>Yu</surname><given-names>C</given-names></name>, <name><surname>Gao</surname><given-names>W</given-names></name>, <year>2020</year>. <article-title>Fedhealth: a federated transfer learning framework for wearable healthcare</article-title>. <source>IEEE Intell. Syst</source></mixed-citation>
    </ref>
    <ref id="R11">
      <mixed-citation publication-type="book"><name><surname>Cheu</surname><given-names>A</given-names></name>, <name><surname>Smith</surname><given-names>A</given-names></name>, <name><surname>Ullman</surname><given-names>J</given-names></name>, <name><surname>Zeber</surname><given-names>D</given-names></name>, <name><surname>Zhilyaev</surname><given-names>M</given-names></name>, <year>2019</year>. <part-title>Distributed differential privacy via shuffling</part-title>. In: <source>Proceedings of the Annual International Confer- ence on the Theory and Applications of Cryptographic Techniques</source>. <publisher-name>Springer</publisher-name>, pp. <fpage>375</fpage>–<lpage>403</lpage>.</mixed-citation>
    </ref>
    <ref id="R12">
      <mixed-citation publication-type="book"><name><surname>Carlini</surname><given-names>N</given-names></name>, <name><surname>Liu</surname><given-names>C</given-names></name>, <name><surname>Erlingsson</surname><given-names>Ú</given-names></name>, <name><surname>Kos</surname><given-names>J</given-names></name>.and <name><surname>Song</surname><given-names>D</given-names></name>, <year>2019</year>. <part-title>The secret sharer: Evaluating and testing unintended memorization in neural networks</part-title>. In <source>28th {USENIX} Security Symposium ({USENIX} Security 19)</source> (pp. <fpage>267</fpage>–<lpage>284</lpage>).</mixed-citation>
    </ref>
    <ref id="R13">
      <mixed-citation publication-type="journal"><name><surname>Choudhury</surname><given-names>O</given-names></name>, <name><surname>Gkoulalas-Divanis</surname><given-names>A</given-names></name>, <name><surname>Salonidis</surname><given-names>T</given-names></name>, <name><surname>Sylla</surname><given-names>I</given-names></name>, <name><surname>Park</surname><given-names>Y</given-names></name>, <name><surname>Hsu</surname><given-names>G</given-names></name>, <name><surname>Das</surname><given-names>A</given-names></name>, <year>2019a</year>. <article-title>Differential privacy-enabled federated learning for sensitive health data</article-title>. <source>arXiv preprint arXiv</source>: 1910.02578.</mixed-citation>
    </ref>
    <ref id="R14">
      <mixed-citation publication-type="book"><name><surname>Choudhury</surname><given-names>O</given-names></name>, <name><surname>Park</surname><given-names>Y</given-names></name>, <name><surname>Salonidis</surname><given-names>T</given-names></name>, <name><surname>Gkoulalas-Divanis</surname><given-names>A</given-names></name>, <name><surname>Sylla</surname><given-names>I</given-names></name>, <etal/>, <year>2019b</year>. <part-title>Predicting adverse drug reactions on distributed health data using federated learning</part-title>. In: <source>Proceedings of the AMIA Annual Symposium Proceedings, American Medical Informatics Association</source>, p. <fpage>313</fpage>.</mixed-citation>
    </ref>
    <ref id="R15">
      <mixed-citation publication-type="journal"><name><surname>Coudray</surname><given-names>N</given-names></name>, <name><surname>Ocampo</surname><given-names>PS</given-names></name>, <name><surname>Sakellaropoulos</surname><given-names>T</given-names></name>, <name><surname>Narula</surname><given-names>N</given-names></name>, <name><surname>Snuderl</surname><given-names>M</given-names></name>, <name><surname>Fenyö</surname><given-names>D</given-names></name>, <name><surname>Moreira</surname><given-names>AL</given-names></name>, <name><surname>Razavian</surname><given-names>N</given-names></name>, <name><surname>Tsirigos</surname><given-names>A</given-names></name>, <year>2018</year>. <article-title>Classification and mutation prediction from non–small cell lung cancer histopathology im- ages using deep learning</article-title>. <source>Nat. Med</source><volume>24</volume>, <fpage>1559</fpage>–<lpage>1567</lpage>.<pub-id pub-id-type="pmid">30224757</pub-id></mixed-citation>
    </ref>
    <ref id="R16">
      <mixed-citation publication-type="confproc"><name><surname>Deng</surname><given-names>J</given-names></name>, <name><surname>Dong</surname><given-names>W</given-names></name>, <name><surname>Socher</surname><given-names>R</given-names></name>, <name><surname>Li</surname><given-names>LJ</given-names></name>, <name><surname>Li</surname><given-names>K</given-names></name>, <name><surname>Fei-Fei</surname><given-names>L</given-names></name>, <year>2009</year>. <source>Imagenet: a large-scale hierarchical image database</source>. In: <conf-name>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</conf-name>. <publisher-name>IEEE</publisher-name>, pp. <fpage>248</fpage>–<lpage>255</lpage>.</mixed-citation>
    </ref>
    <ref id="R17">
      <mixed-citation publication-type="journal"><name><surname>Dong</surname><given-names>J</given-names></name>, <name><surname>Roth</surname><given-names>A</given-names></name>, &amp; <name><surname>Su</surname><given-names>WJ</given-names></name> (<year>2019</year>). <article-title>Gaussian differential privacy</article-title>. <source>arXiv preprint arXiv</source>: 1905.02383.</mixed-citation>
    </ref>
    <ref id="R18">
      <mixed-citation publication-type="confproc"><name><surname>Dwork</surname><given-names>C</given-names></name>, <name><surname>Kenthapadi</surname><given-names>K</given-names></name>, <name><surname>McSherry</surname><given-names>F</given-names></name>, <name><surname>Mironov</surname><given-names>I</given-names></name>, <name><surname>Naor</surname><given-names>M</given-names></name>, <year>2006</year>. <source>Our data, ourselves: privacy via distributed noise generation</source>. In: <conf-name>Proceedings of the Annual International Conference on the Theory and Applications of Cryptographic Techniques</conf-name>. <publisher-name>Springer</publisher-name>, pp. <fpage>486</fpage>–<lpage>503</lpage>.</mixed-citation>
    </ref>
    <ref id="R19">
      <mixed-citation publication-type="journal"><name><surname>Dwork</surname><given-names>C</given-names></name>, <name><surname>Roth</surname><given-names>A</given-names></name>, <etal/>, <year>2014</year>. <article-title>The algorithmic foundations of differential privacy</article-title>. <source>Found. Trends Theor. Comput. Sci</source><volume>9</volume>, <fpage>211</fpage>–<lpage>407</lpage>.</mixed-citation>
    </ref>
    <ref id="R20">
      <mixed-citation publication-type="book"><name><surname>Geiping</surname><given-names>J</given-names></name>, <name><surname>Bauermeister</surname><given-names>H</given-names></name>, <name><surname>Dröge</surname><given-names>H</given-names></name>, <name><surname>Moeller</surname><given-names>M</given-names></name>, <year>2020</year>. <part-title>Inverting gradients how easy is it to break privacy in federated learning?</part-title> In: <name><surname>Larochelle</surname><given-names>H</given-names></name>, <name><surname>Ranzato</surname><given-names>M</given-names></name>, <name><surname>Hadsell</surname><given-names>R</given-names></name>, <name><surname>Balcan</surname><given-names>MF</given-names></name>, <name><surname>Lin</surname><given-names>H</given-names></name>.(Eds.) <source>Advances in Neural Information Processing Systems</source>. <publisher-name>Curran Associates, Inc.</publisher-name>, pp. <fpage>16937</fpage>–<lpage>16947</lpage>.</mixed-citation>
    </ref>
    <ref id="R21">
      <mixed-citation publication-type="journal"><name><surname>Graham</surname><given-names>S</given-names></name>, <name><surname>Vu</surname><given-names>QD</given-names></name>, <name><surname>Raza</surname><given-names>SEA</given-names></name>, <name><surname>Azam</surname><given-names>A</given-names></name>, <name><surname>Tsang</surname><given-names>YW</given-names></name>, <name><surname>Kwak</surname><given-names>JT</given-names></name>, <name><surname>Rajpoot</surname><given-names>N</given-names></name>, <year>2019</year>. <article-title>Hover-net: simultaneous segmentation and classification of nuclei in multi-tissue histology images</article-title>. <source>Med. Image Anal</source> 58 101563.</mixed-citation>
    </ref>
    <ref id="R22">
      <mixed-citation publication-type="confproc"><name><surname>Hitaj</surname><given-names>B</given-names></name>, <name><surname>Ateniese</surname><given-names>G</given-names></name>, <name><surname>Perez-Cruz</surname><given-names>F</given-names></name>, <year>2017</year>. <source>Deep models under the gan: information leakage from collaborative deep learning</source>. In: <conf-name>Proceedings of the ACM SIGSAC Conference on Computer and Communications Security</conf-name>, pp. <fpage>603</fpage>–<lpage>618</lpage>.</mixed-citation>
    </ref>
    <ref id="R23">
      <mixed-citation publication-type="journal"><name><surname>Hung</surname><given-names>H</given-names></name>, <name><surname>Chiang</surname><given-names>CT</given-names></name>, <year>2010</year>. <article-title>Estimation methods for time-dependent auc models with survival data</article-title>. <source>Can. J. Stat</source><volume>38</volume>, <fpage>8</fpage>–<lpage>26</lpage>.</mixed-citation>
    </ref>
    <ref id="R24">
      <mixed-citation publication-type="confproc"><name><surname>Ilse</surname><given-names>M</given-names></name>, <name><surname>Tomczak</surname><given-names>J</given-names></name>, <name><surname>Welling</surname><given-names>M</given-names></name>, <year>2018</year>. <source>Attention-based deep multiple instance learning</source>. In: <conf-name>Proceedings of the International Conference on Machine Learning</conf-name>. <publisher-name>PMLR</publisher-name>, pp. <fpage>2132</fpage>–<lpage>2141</lpage>.</mixed-citation>
    </ref>
    <ref id="R25">
      <mixed-citation publication-type="journal"><name><surname>Jagadeesh</surname><given-names>KA</given-names></name>, <name><surname>Wu</surname><given-names>DJ</given-names></name>, <name><surname>Birgmeier</surname><given-names>JA</given-names></name>, <name><surname>Boneh</surname><given-names>D</given-names></name>, <name><surname>Bejerano</surname><given-names>G</given-names></name>, <year>2017</year>. <article-title>Deriving genomic diagnoses without revealing patient genomes</article-title>. <source>Science</source><volume>357</volume>, <fpage>692</fpage>–<lpage>695</lpage>.<pub-id pub-id-type="pmid">28818945</pub-id></mixed-citation>
    </ref>
    <ref id="R26">
      <mixed-citation publication-type="journal"><name><surname>Javed</surname><given-names>S</given-names></name>, <name><surname>Mahmood</surname><given-names>A</given-names></name>, <name><surname>Fraz</surname><given-names>MM</given-names></name>, <name><surname>Koohbanani</surname><given-names>NA</given-names></name>, <name><surname>Benes</surname><given-names>K</given-names></name>, <name><surname>Tsang</surname><given-names>YW</given-names></name>, <name><surname>Hewitt</surname><given-names>K</given-names></name>, <name><surname>Epstein</surname><given-names>D</given-names></name>, <name><surname>Snead</surname><given-names>D</given-names></name>, <name><surname>Rajpoot</surname><given-names>N</given-names></name>, <year>2020</year>. <article-title>Cellular community detection for tissue phenotyping in colorectal cancer histology images</article-title>. <source>Med. Image Anal</source> 63 101696.</mixed-citation>
    </ref>
    <ref id="R27">
      <mixed-citation publication-type="book"><name><surname>Ju</surname><given-names>C</given-names></name>, <name><surname>Gao</surname><given-names>D</given-names></name>, <name><surname>Mane</surname><given-names>R</given-names></name>, <name><surname>Tan</surname><given-names>B</given-names></name>, <name><surname>Liu</surname><given-names>Y</given-names></name>, <name><surname>Guan</surname><given-names>C</given-names></name>, <year>2020</year>, <month>July</month>. <part-title>Federated transfer learning for eeg signal classification</part-title>. In: <source>Engineering in Medicine &amp; Biology Society (EMBC)</source>. <publisher-name>IEEE</publisher-name>, pp. <fpage>3040</fpage>–<lpage>3045</lpage>.</mixed-citation>
    </ref>
    <ref id="R28">
      <mixed-citation publication-type="journal"><name><surname>Kairouz</surname><given-names>P</given-names></name>, <name><surname>McMahan</surname><given-names>HB</given-names></name>, <name><surname>Avent</surname><given-names>B</given-names></name>, <name><surname>Bellet</surname><given-names>A</given-names></name>, <name><surname>Bennis</surname><given-names>M</given-names></name>, <name><surname>Bhagoji</surname><given-names>AN</given-names></name>, <name><surname>Bonawitz</surname><given-names>K</given-names></name>, <name><surname>Charles</surname><given-names>Z</given-names></name>, <name><surname>Cormode</surname><given-names>G</given-names></name>, <name><surname>Cummings</surname><given-names>R</given-names></name>.and <name><surname>D’Oliveira</surname><given-names>RG</given-names></name>, <year>2019</year>. <article-title>Advances and open problems in federated learning</article-title>. <source>arXiv preprint arXiv</source>: 1912.04977.</mixed-citation>
    </ref>
    <ref id="R29">
      <mixed-citation publication-type="journal"><name><surname>Kaissis</surname><given-names>GA</given-names></name>, <name><surname>Makowski</surname><given-names>MR</given-names></name>, <name><surname>Rückert</surname><given-names>D</given-names></name>, <name><surname>Braren</surname><given-names>RF</given-names></name>, <year>2020</year>. <article-title>Secure, privacy-preserving and federated machine learning in medical imaging</article-title>. <source>Nat. Mach. In- tell</source><volume>2</volume>, <fpage>305</fpage>–<lpage>311</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s42256-020-0186-1</pub-id>.</mixed-citation>
    </ref>
    <ref id="R30">
      <mixed-citation publication-type="journal"><name><surname>Konecˇny’</surname><given-names>J</given-names></name>, <name><surname>McMahan</surname><given-names>HB</given-names></name>, <name><surname>Yu</surname><given-names>FX</given-names></name>, <name><surname>Richtaŕik</surname><given-names>P</given-names></name>, <name><surname>Suresh</surname><given-names>AT</given-names></name>, <name><surname>Bacon</surname><given-names>D</given-names></name>, <year>2016</year>. <article-title>Federated learning: strategies for improving communication efficiency</article-title>. <source>arXiv preprint arXiv</source>: 1610.05492.</mixed-citation>
    </ref>
    <ref id="R31">
      <mixed-citation publication-type="journal"><name><surname>Lazar</surname><given-names>AJ</given-names></name>, <name><surname>McLellan</surname><given-names>MD</given-names></name>, <name><surname>Bailey</surname><given-names>MH</given-names></name>, <name><surname>Miller</surname><given-names>CA</given-names></name>, <name><surname>Appelbaum</surname><given-names>EL</given-names></name>, <name><surname>Cordes</surname><given-names>MG</given-names></name>, <name><surname>Fronick</surname><given-names>CC</given-names></name>, <name><surname>Fulton</surname><given-names>LA</given-names></name>, <name><surname>Fulton</surname><given-names>RS</given-names></name>, <name><surname>Mardis</surname><given-names>ER</given-names></name>, <etal/>, <year>2017</year>. <article-title>Comprehensive and integrated genomic characterization of adult soft tissue sarcomas</article-title>. <source>Cell</source><volume>171</volume>, <fpage>950</fpage>–<lpage>965</lpage>.<pub-id pub-id-type="pmid">29100075</pub-id></mixed-citation>
    </ref>
    <ref id="R32">
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>T</given-names></name>, <name><surname>Sahu</surname><given-names>AK</given-names></name>, <name><surname>Talwalkar</surname><given-names>A</given-names></name>, <name><surname>Smith</surname><given-names>V</given-names></name>, <year>2020a</year>. <article-title>Federated learning: challenges, methods, and future directions</article-title>. <source>IEEE Signal Process. Mag</source><volume>37</volume>, <fpage>50</fpage>–<lpage>60</lpage>.</mixed-citation>
    </ref>
    <ref id="R33">
      <mixed-citation publication-type="book"><name><surname>Li</surname><given-names>W</given-names></name>, <name><surname>Milletar’ı</surname><given-names>F</given-names></name>, <name><surname>Xu</surname><given-names>D</given-names></name>, <name><surname>Rieke</surname><given-names>N</given-names></name>, <name><surname>Hancox</surname><given-names>J</given-names></name>, <name><surname>Zhu</surname><given-names>W</given-names></name>, <name><surname>Baust</surname><given-names>M</given-names></name>, <name><surname>Cheng</surname><given-names>Y</given-names></name>, <name><surname>Ourselin</surname><given-names>S</given-names></name>, <name><surname>Cardoso</surname><given-names>MJ</given-names></name>, <etal/>, <year>2019</year>. <part-title>Privacy-preserving federated brain tumour segmentation</part-title>. In: <source>Proceedings of the International Workshop on Machine Learning in Medical Imaging</source>. <publisher-name>Springer</publisher-name>, pp. <fpage>133</fpage>–<lpage>141</lpage>.</mixed-citation>
    </ref>
    <ref id="R34">
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>X</given-names></name>, <name><surname>Gu</surname><given-names>Y</given-names></name>, <name><surname>Dvornek</surname><given-names>N</given-names></name>, <name><surname>Staib</surname><given-names>LH</given-names></name>, <name><surname>Ventola</surname><given-names>P</given-names></name>, <name><surname>Duncan</surname><given-names>JS</given-names></name>, <year>2020b</year>. <article-title>Multisite fmri analysis using privacy-preserving federated learning and domain adaptation: abide results</article-title>. <source>Med. Image Anal</source><volume>65</volume>, <fpage>101765</fpage>.<pub-id pub-id-type="pmid">32679533</pub-id></mixed-citation>
    </ref>
    <ref id="R35">
      <mixed-citation publication-type="journal"><name><surname>Lu</surname><given-names>MY</given-names></name>, <name><surname>Chen</surname><given-names>RJ</given-names></name>, <name><surname>Wang</surname><given-names>J</given-names></name>, <name><surname>Dillon</surname><given-names>D</given-names></name>, <name><surname>Mahmood</surname><given-names>F</given-names></name>, <year>2019</year>. <article-title>Semi-supervised histology classification using deep multiple instance learning and contrastive predictive coding</article-title>. <source>arXiv preprint arXiv</source>: 1910.10825.</mixed-citation>
    </ref>
    <ref id="R36">
      <mixed-citation publication-type="journal"><name><surname>Lu</surname><given-names>MY</given-names></name>, <name><surname>Chen</surname><given-names>TY</given-names></name>, <name><surname>Williamson</surname><given-names>DF</given-names></name>, <name><surname>Zhao</surname><given-names>M</given-names></name>, <name><surname>Shady</surname><given-names>M</given-names></name>, <name><surname>Lipkova</surname><given-names>J</given-names></name>, <name><surname>Mahmood</surname><given-names>F</given-names></name>, <year>2021</year>. <article-title>Ai-based pathology predicts origins for cancers of unknown primary</article-title>. <source>Nature</source><volume>594</volume>, <fpage>106</fpage>–<lpage>110</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41586-021-03512-4</pub-id>.<pub-id pub-id-type="pmid">33953404</pub-id></mixed-citation>
    </ref>
    <ref id="R37">
      <mixed-citation publication-type="journal"><name><surname>Lu</surname><given-names>MY</given-names></name>, <name><surname>Williamson</surname><given-names>DF</given-names></name>, <name><surname>Chen</surname><given-names>TY</given-names></name>, <name><surname>Chen</surname><given-names>RJ</given-names></name>, <name><surname>Barbieri</surname><given-names>M</given-names></name>, <name><surname>Mahmood</surname><given-names>F</given-names></name>, <year>2020a</year>. <article-title>Data efficient and weakly supervised computational pathology on whole slide images</article-title>. <source>arXiv preprint arXiv</source>: 2004.09666.</mixed-citation>
    </ref>
    <ref id="R38">
      <mixed-citation publication-type="journal"><name><surname>Mahmood</surname><given-names>F</given-names></name>, <name><surname>Borders</surname><given-names>D</given-names></name>, <name><surname>Chen</surname><given-names>R</given-names></name>, <name><surname>McKay</surname><given-names>GN</given-names></name>, <name><surname>Salimian</surname><given-names>KJ</given-names></name>, <name><surname>Baras</surname><given-names>A</given-names></name>, <name><surname>Durr</surname><given-names>NJ</given-names></name>, <year>2019</year>. <article-title>Deep adversarial training for multi-organ nuclei segmentation in histopathology images</article-title>. <source>IEEE Trans. Med. Imaging</source></mixed-citation>
    </ref>
    <ref id="R39">
      <mixed-citation publication-type="journal"><name><surname>Mandl</surname><given-names>KD</given-names></name>, <name><surname>Glauser</surname><given-names>T</given-names></name>, <name><surname>Krantz</surname><given-names>ID</given-names></name>, <name><surname>Avillach</surname><given-names>P</given-names></name>, <name><surname>Bartels</surname><given-names>A</given-names></name>, <name><surname>Beggs</surname><given-names>AH</given-names></name>, <name><surname>Biswas</surname><given-names>S</given-names></name>, <name><surname>Bourgeois</surname><given-names>FT</given-names></name>, <name><surname>Corsmo</surname><given-names>J</given-names></name>, <name><surname>Dauber</surname><given-names>A</given-names></name>, <etal/>, <year>2020</year>. <article-title>The genomics research and innovation network: creating an interoperable, federated, genomics learning system</article-title>. <source>Genet. Med</source><volume>22</volume>, <fpage>371</fpage>–<lpage>380</lpage>.<pub-id pub-id-type="pmid">31481752</pub-id></mixed-citation>
    </ref>
    <ref id="R40">
      <mixed-citation publication-type="journal"><name><surname>McMahan</surname><given-names>B</given-names></name>, <name><surname>Moore</surname><given-names>E</given-names></name>, <name><surname>Ramage</surname><given-names>D</given-names></name>, <name><surname>Hampson</surname><given-names>S</given-names></name>, <name><surname>Arcas</surname><given-names>BA</given-names></name>, <year>2017</year>. <article-title>Communication-efficient learning of deep networks from decentralized data</article-title>. <source>Artif. Intell. Stat</source><volume>54</volume>, <fpage>1273</fpage>–<lpage>1282</lpage>.</mixed-citation>
    </ref>
    <ref id="R41">
      <mixed-citation publication-type="journal"><name><surname>Mobadersany</surname><given-names>P</given-names></name>, <name><surname>Yousefi</surname><given-names>S</given-names></name>, <name><surname>Amgad</surname><given-names>M</given-names></name>, <name><surname>Gutman</surname><given-names>DA</given-names></name>, <name><surname>Barnholtz-Sloan</surname><given-names>JS</given-names></name>, <name><surname>Vega</surname><given-names>JEV</given-names></name>, <name><surname>Brat</surname><given-names>DJ</given-names></name>, <name><surname>Cooper</surname><given-names>LA</given-names></name>, <year>2018</year>. <article-title>Predicting cancer outcomes from histology and genomics using convolutional networks</article-title>. <source>Proc. Natl. Acad. Sci</source><volume>115</volume>, <fpage>E2970</fpage>–<lpage>E2979</lpage>.<pub-id pub-id-type="pmid">29531073</pub-id></mixed-citation>
    </ref>
    <ref id="R42">
      <mixed-citation publication-type="confproc"><name><surname>Muhammad</surname><given-names>H</given-names></name>, <name><surname>Sigel</surname><given-names>CS</given-names></name>, <name><surname>Campanella</surname><given-names>G</given-names></name>, <name><surname>Boerner</surname><given-names>T</given-names></name>, <name><surname>Pak</surname><given-names>LM</given-names></name>, <name><surname>Buttner</surname><given-names>S</given-names></name>, <name><surname>IJzermans</surname><given-names>JN</given-names></name>, <name><surname>Koerkamp</surname><given-names>BG</given-names></name>, <name><surname>Doukas</surname><given-names>M</given-names></name>, <name><surname>Jarnagin</surname><given-names>WR</given-names></name>, <etal/>, <year>2019</year>. <source>Unsupervised subtyping of cholangiocarcinoma using a deep clustering convolutional autoencoder</source>. In: <conf-name>Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention</conf-name>. <publisher-name>Springer</publisher-name>, pp. <fpage>604</fpage>–<lpage>612</lpage>.</mixed-citation>
    </ref>
    <ref id="R43">
      <mixed-citation publication-type="journal"><name><surname>Nabi</surname><given-names>J</given-names></name>, <year>2018</year>. <article-title>Artificial intelligence can augment global pathology initiatives</article-title>. <source>Lancet</source><volume>392</volume>, <fpage>2351</fpage>–<lpage>2352</lpage>.<pub-id pub-id-type="pmid">30527613</pub-id></mixed-citation>
    </ref>
    <ref id="R44">
      <mixed-citation publication-type="journal"><name><surname>Niazi</surname><given-names>MKK</given-names></name>, <name><surname>Parwani</surname><given-names>AV</given-names></name>, <name><surname>Gurcan</surname><given-names>MN</given-names></name>, <year>2019</year>. <article-title>Digital pathology and artificial intelligence</article-title>. <source>Lancet Oncol</source>. <volume>20</volume>, <fpage>e253</fpage>–<lpage>e261</lpage>.<pub-id pub-id-type="pmid">31044723</pub-id></mixed-citation>
    </ref>
    <ref id="R45">
      <mixed-citation publication-type="journal"><name><surname>Pell</surname><given-names>R</given-names></name>, <name><surname>Oien</surname><given-names>K</given-names></name>, <name><surname>Robinson</surname><given-names>M</given-names></name>, <name><surname>Pitman</surname><given-names>H</given-names></name>, <name><surname>Rajpoot</surname><given-names>N</given-names></name>, <name><surname>Rittscher</surname><given-names>J</given-names></name>, <name><surname>Snead</surname><given-names>D</given-names></name>, <name><surname>Verrill</surname><given-names>C</given-names></name>, <name><surname>Driskell</surname><given-names>OJ</given-names></name>, <etal/><collab>quality assurance working group, U.N.C.R.I.N.C.M.P.C.P.</collab>, <year>2019</year>. <article-title>The use of digital pathology and image analysis in clinical trials</article-title>. <source>J. Pathol. Clin. Res</source><volume>5</volume>, <fpage>81</fpage>–<lpage>90</lpage>.<pub-id pub-id-type="pmid">30767396</pub-id></mixed-citation>
    </ref>
    <ref id="R46">
      <mixed-citation publication-type="journal"><name><surname>Rehm</surname><given-names>HL</given-names></name>, <year>2017</year>. <article-title>Evolving health care through personal genomics</article-title>. <source>Nat. Rev. Genet</source><volume>18</volume>, <fpage>259</fpage>–<lpage>267</lpage>.<pub-id pub-id-type="pmid">28138143</pub-id></mixed-citation>
    </ref>
    <ref id="R47">
      <mixed-citation publication-type="journal"><name><surname>Rieke</surname><given-names>N</given-names></name>, <name><surname>Hancox</surname><given-names>J</given-names></name>, <name><surname>Li</surname><given-names>W</given-names></name>, <name><surname>Milletari</surname><given-names>F</given-names></name>, <name><surname>Roth</surname><given-names>HR</given-names></name>, <name><surname>Albarqouni</surname><given-names>S</given-names></name>, <name><surname>Bakas</surname><given-names>S</given-names></name>, <name><surname>Galtier</surname><given-names>MN</given-names></name>, <name><surname>Landman</surname><given-names>BA</given-names></name>, <name><surname>Maier-Hein</surname><given-names>K</given-names></name>, <etal/>, <year>2020</year>. <article-title>The future of digital health with federated learning</article-title>. <source>NPJ Digit. Med</source><volume>3</volume>, <fpage>1</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">31934645</pub-id></mixed-citation>
    </ref>
    <ref id="R48">
      <mixed-citation publication-type="journal"><name><surname>Rocher</surname><given-names>L</given-names></name>, <name><surname>Hendrickx</surname><given-names>JM</given-names></name>, <name><surname>De Montjoye</surname><given-names>YA</given-names></name>, <year>2019</year>. <article-title>Estimating the success of re-i- dentifications in incomplete datasets using generative models</article-title>. <source>Nat. Commun</source><volume>10</volume>, <fpage>1</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">30602773</pub-id></mixed-citation>
    </ref>
    <ref id="R49">
      <mixed-citation publication-type="journal"><name><surname>Roy</surname><given-names>AG</given-names></name>, <name><surname>Siddiqui</surname><given-names>S</given-names></name>, <name><surname>Po ¨lsterl</surname><given-names>S</given-names></name>, <name><surname>Navab</surname><given-names>N</given-names></name>, <name><surname>Wachinger</surname><given-names>C</given-names></name>, <year>2019</year>. <article-title>Braintorrent: a peer-to-peer environment for decentralized federated learning</article-title>. <source>arXiv preprint arXiv</source>: 1905.06731.</mixed-citation>
    </ref>
    <ref id="R50">
      <mixed-citation publication-type="journal"><name><surname>Schapiro</surname><given-names>D</given-names></name>, <name><surname>Jackson</surname><given-names>HW</given-names></name>, <name><surname>Raghuraman</surname><given-names>S</given-names></name>, <name><surname>Fischer</surname><given-names>JR</given-names></name>, <name><surname>Zanotelli</surname><given-names>VR</given-names></name>, <name><surname>Schulz</surname><given-names>D</given-names></name>, <name><surname>Giesen</surname><given-names>C</given-names></name>, <name><surname>Catena</surname><given-names>R</given-names></name>, <name><surname>Varga</surname><given-names>Z</given-names></name>, <name><surname>Bodenmiller</surname><given-names>B</given-names></name>, <year>2017</year>. <article-title>Histocat: analysis of cell phenotypes and interactions in multiplex image cytometry data</article-title>. <source>Nat. Methods</source><volume>14</volume>, <fpage>873</fpage>.<pub-id pub-id-type="pmid">28783155</pub-id></mixed-citation>
    </ref>
    <ref id="R51">
      <mixed-citation publication-type="journal"><name><surname>Scheibner</surname><given-names>J</given-names></name>, <name><surname>Ienca</surname><given-names>M</given-names></name>, <name><surname>Kechagia</surname><given-names>S</given-names></name>, <name><surname>Troncoso-Pastoriza</surname><given-names>JR</given-names></name>, <name><surname>Raisaro</surname><given-names>JL</given-names></name>, <name><surname>Hubaux</surname><given-names>JP</given-names></name>, <name><surname>Fellay</surname><given-names>J</given-names></name>, <name><surname>Vayena</surname><given-names>E</given-names></name>, <year>2020</year>. <article-title>Data protection and ethics requirements for multisite research with health data: a comparative examination of legislative governance frameworks and the role of data protection technologies</article-title>. <source>J. Law Biosci</source><volume>7</volume>, <fpage>1</fpage>.</mixed-citation>
    </ref>
    <ref id="R52">
      <mixed-citation publication-type="confproc"><name><surname>Sheller</surname><given-names>MJ</given-names></name>, <name><surname>Reina</surname><given-names>GA</given-names></name>, <name><surname>Edwards</surname><given-names>B</given-names></name>, <name><surname>Martin</surname><given-names>J</given-names></name>, <name><surname>Bakas</surname><given-names>S</given-names></name>, <year>2018</year>. <source>Multi-institutional deep learning modeling without sharing patient data: a feasibility study on brain tumor segmentation</source>. In: <conf-name>Proceedings of the International MICCAI Brain- Lesion Workshop</conf-name>. <publisher-name>Springer</publisher-name>, pp. <fpage>92</fpage>–<lpage>104</lpage>.</mixed-citation>
    </ref>
    <ref id="R53">
      <mixed-citation publication-type="confproc"><name><surname>Shokri</surname><given-names>R</given-names></name>, <name><surname>Shmatikov</surname><given-names>V</given-names></name>, <year>2015</year>. <source>Privacy-preserving deep learning</source>. In: <conf-name>Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security</conf-name>, pp. <fpage>1310</fpage>–<lpage>1321</lpage>.</mixed-citation>
    </ref>
    <ref id="R54">
      <mixed-citation publication-type="confproc"><name><surname>Silva</surname><given-names>S</given-names></name>, <name><surname>Gutman</surname><given-names>BA</given-names></name>, <name><surname>Romero</surname><given-names>E</given-names></name>, <name><surname>Thompson</surname><given-names>PM</given-names></name>, <name><surname>Altmann</surname><given-names>A</given-names></name>, <name><surname>Lorenzi</surname><given-names>M</given-names></name>, <year>2019</year>. <source>Federated learning in distributed medical databases: meta-analysis of large-scale subcortical brain data</source>. <conf-name>In: Proceedings of the IEEE 16th International Symposium on Biomedical Imaging (ISBI)</conf-name>. <publisher-name>IEEE</publisher-name>, pp. <fpage>270</fpage>–<lpage>274</lpage>.</mixed-citation>
    </ref>
    <ref id="R55">
      <mixed-citation publication-type="book"><name><surname>Tutz</surname><given-names>G</given-names></name>, <name><surname>Schmid</surname><given-names>M</given-names></name>, <etal/>, <year>2016</year>. <source>Modeling Discrete Time-to-Event Data</source>. <publisher-name>Springer</publisher-name>.</mixed-citation>
    </ref>
    <ref id="R56">
      <mixed-citation publication-type="confproc"><name><surname>Wang</surname><given-names>J</given-names></name>, <name><surname>Chen</surname><given-names>RJ</given-names></name>, <name><surname>Lu</surname><given-names>MY</given-names></name>, <name><surname>Baras</surname><given-names>A</given-names></name>, <name><surname>Mahmood</surname><given-names>F</given-names></name>, <year>2020</year>. <source>Weakly supervised prostate tma classification via graph convolutional networks</source>. <conf-name>In: Proceedings of the IEEE 17th International Symposium on Biomedical Imaging (ISBI)</conf-name>. <publisher-name>IEEE</publisher-name>, pp. <fpage>239</fpage>–<lpage>243</lpage>.</mixed-citation>
    </ref>
    <ref id="R57">
      <mixed-citation publication-type="confproc"><name><surname>Wang</surname><given-names>Z</given-names></name>, <name><surname>Song</surname><given-names>M</given-names></name>, <name><surname>Zhang</surname><given-names>Z</given-names></name>, <name><surname>Song</surname><given-names>Y</given-names></name>, <name><surname>Wang</surname><given-names>Q</given-names></name>, <name><surname>Qi</surname><given-names>H</given-names></name>, <year>2019</year>. <source>Beyond inferring class representatives: user-level privacy leakage from federated learning</source>. <conf-name>In: Proceedings of the IEEE INFOCOM IEEE Conference on Computer Communications</conf-name>, pp. <fpage>2512</fpage>–<lpage>2520</lpage>.</mixed-citation>
    </ref>
    <ref id="R58">
      <mixed-citation publication-type="book"><name><surname>Xiao</surname><given-names>L</given-names></name>, <name><surname>Yu</surname><given-names>JG</given-names></name>, <name><surname>Liu</surname><given-names>Z</given-names></name>, <name><surname>Ou</surname><given-names>J</given-names></name>, <name><surname>Deng</surname><given-names>S</given-names></name>, <name><surname>Yang</surname><given-names>Z</given-names></name>, <name><surname>Li</surname><given-names>Y</given-names></name>, <year>2020</year>. <article-title>Censoring-aware deep ordinal regression for survival prediction from pathological images</article-title>. <source>In: Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention</source>. <publisher-name>Springer</publisher-name>, pp. <fpage>449</fpage>–<lpage>458</lpage>.</mixed-citation>
    </ref>
    <ref id="R59">
      <mixed-citation publication-type="journal"><name><surname>Yamamoto</surname><given-names>Y</given-names></name>, <name><surname>Tsuzuki</surname><given-names>T</given-names></name>, <name><surname>Akatsuka</surname><given-names>J</given-names></name>, <name><surname>Ueki</surname><given-names>M</given-names></name>, <name><surname>Morikawa</surname><given-names>H</given-names></name>, <name><surname>Numata</surname><given-names>Y</given-names></name>, <name><surname>Taka- hara</surname><given-names>T</given-names></name>, <name><surname>Tsuyuki</surname><given-names>T</given-names></name>, <name><surname>Tsutsumi</surname><given-names>K</given-names></name>, <name><surname>Nakazawa</surname><given-names>R</given-names></name>, <etal/>, <year>2019</year>. <article-title>Automated acquisition of explainable knowledge from unannotated histopathology images</article-title>. <source>Nat. Commun</source><volume>10</volume>, <fpage>1</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">30602773</pub-id></mixed-citation>
    </ref>
    <ref id="R60">
      <mixed-citation publication-type="journal"><name><surname>Yang</surname><given-names>Q</given-names></name>, <name><surname>Liu</surname><given-names>Y</given-names></name>, <name><surname>Chen</surname><given-names>T</given-names></name>, <name><surname>Tong</surname><given-names>Y</given-names></name>, <year>2019</year>. <article-title>Federated machine learning: concept and applications</article-title>. <source>ACM Trans. Intell. Syst. Technol. (TIST)</source><volume>10</volume>, <fpage>1</fpage>–<lpage>19</lpage>.</mixed-citation>
    </ref>
    <ref id="R61">
      <mixed-citation publication-type="journal"><name><surname>Zadeh</surname><given-names>SG</given-names></name>, <name><surname>Schmid</surname><given-names>M</given-names></name>, <year>2020</year>. <article-title>Bias in cross-entropy-based training of deep survival networks</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell</source><volume>43</volume>, <fpage>3126</fpage>–<lpage>3137</lpage> 9.</mixed-citation>
    </ref>
    <ref id="R62">
      <mixed-citation publication-type="confproc"><name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Jia</surname><given-names>R</given-names></name>, <name><surname>Pei</surname><given-names>H</given-names></name>, <name><surname>Wang</surname><given-names>W</given-names></name>, <name><surname>Li</surname><given-names>B</given-names></name>, <name><surname>Song</surname><given-names>D</given-names></name>, <year>2020</year>. <source>The secret revealer: generative model-inversion attacks against deep neural networks</source>. <conf-name>In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</conf-name>, pp. <fpage>253</fpage>–<lpage>261</lpage>.</mixed-citation>
    </ref>
    <ref id="R63">
      <mixed-citation publication-type="confproc"><name><surname>Zhou</surname><given-names>Y</given-names></name>, <name><surname>Graham</surname><given-names>S</given-names></name>, <name><surname>Alemi Koohbanani</surname><given-names>N</given-names></name>, <name><surname>Shaban</surname><given-names>M</given-names></name>, <name><surname>Heng</surname><given-names>PA</given-names></name>, <name><surname>Rajpoot</surname><given-names>N</given-names></name>, <year>2019</year>. <source>CGC-Net: cell graph convolutional network for grading of colorectal cancer histology images</source>. <conf-name>In: Proceedings of the IEEE International Conference on Computer Vision Workshops</conf-name> 0–0.</mixed-citation>
    </ref>
    <ref id="R64">
      <mixed-citation publication-type="book"><name><surname>Zhu</surname><given-names>L</given-names></name>, <name><surname>Liu</surname><given-names>Z</given-names></name>, <name><surname>Han</surname><given-names>S</given-names></name>, <year>2019</year>. <part-title>Deep leakage from gradients</part-title>. <source>In: Advances in Neural Information Processing Systems</source>. <publisher-name>Curran Associates, Inc.</publisher-name>, pp. <fpage>14774</fpage>–<lpage>14784</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig position="float" id="F1">
    <label>Fig. 1.</label>
    <caption>
      <p id="P63">Overview of the weakly-supervised multiple instance learning in a federated learning framework. At each client site, for each WSI, the tissue regions are first automatically segmented and image patches are extracted from the segmented foreground regions. Then all patches are embedded into a low-dimension feature representation using a pretrained CNN as the encoder. Each client site trains a model using weakly-supervised learning on local data (requires only the slide-level or patient-level labels) and sends the model weights each epoch to a central server. Random noise can be added to the weight parameters before communicating with the central hub for differential privacy preservation. On the central server, the global model is updated by averaging the model weights retrieved from all client sites. After the federated averaging, the updated weights of the global model is then sent to each client model for synchronization prior to starting the next federated round.</p>
    </caption>
    <graphic xlink:href="nihms-1763910-f0001" position="float"/>
  </fig>
  <fig position="float" id="F2">
    <label>Fig. 2.</label>
    <caption>
      <p id="P64">Performance, comparative analysis and loss curves. a-c, d-f The classification performance and loss curves of BRCA histologic subtyping and RCC histological subtyping, respectively. Top: ROC curves are generated on the test sets for models trained using a centralized database, federated learning (with different levels of Gaussian random noise added during federated weight averaging) and using training data local to each institution individually. The AUC score (averaged over 5-fold cross-validation, s.d.) is reported for each experiment; macro-averaging is used for the multi-class classification of RCC subytping. Using multiinstitutional data and federated learning, we achieved a mean test AUC between 0.833 and 0.862 on BRCA histologic subtyping and an AUC of between 0.974 and 0.976 on RCC histologic subtyping respectively. Middle: Balanced accuracy score and the sensitivity (recall) for each class (IDC: Invasive Ductal Carcinoma, ILC: Invasive Lobular Carcinoma for BRCA subtyping; CHRCC: Chromophobe Renal Cell Carcinoma, CCRCC: Clear Cell Renal Cell Carcinoma, PRCC: Papillary Renal Cell Carcinoma for RCC subtyping) is plotted for all experiments to assess model performance when accounting for class-imbalance in the respective test set. Error bars show s.d. from 5-fold cross-validation. Bottom: For each experiment, the training loss and validation loss is monitored over each epoch before early stopping is triggered (see <xref rid="S12" ref-type="sec">Section 3.2</xref>). Loss curves are shown for a single cross-validation fold from each task. Federated learning is observed to converge to a higher training and validation loss value in both tasks.</p>
    </caption>
    <graphic xlink:href="nihms-1763910-f0002" position="float"/>
  </fig>
  <fig position="float" id="F3">
    <label>Fig. 3.</label>
    <caption>
      <p id="P65">Interpretability and visualization for weakly-supervised federated classification. In order to interpret and validate the morphological features learned by the model for RCC and BRCA histologic subtype classification, for randomly selected WSIs in the respective test set, the model trained with privacy-preserving federated learning (<italic toggle="yes">α</italic>= 0.01) is used to generate attention heatmaps using 256 × 256 sized tissue patches tiled at the 20 × magnification with a 90% spatial overlap. For each WSI, the attention scores predicted for all patches in the slide are normalized to the range of [0, 1] by converting them to percentiles. For subtype classification, patches with high attention refers to image regions of high diagnostic relevance used for class prediction. The normalized scores are then mapped to their respective spatial location in the slide. Finally, an RGB colormap is applied (red: high attention, blue: low attention), and the heatmap is overlaid on top of the original H&amp;E image for display. For BRCA, patches of the most highly attended regions (red border) exhibited well-known tumor morphology of invasive ductal carcinoma (round cells with varying degrees of polymorphism arranged in tubules, nests, or papillae) and invasive lobular carcinoma (round and signet-ring cells with intracellular lumina and targetoid cytoplasmic mucin arranged in a single-file or trabecular pattern). For RCC, highly attended regions exhibited well-known tumor morphology of chromophobe RCC (large, round to polygonal cells with abundant, finely-reticulated to granular cytoplasm and perinuclear halos), clear cell RCC (large, round to polygonal cells with clear cytoplasm and distinct, but delicate cell borders), and papillary RCC (round to cuboidal cells with prominent papillary or tubulopapillary architecture with fibrovascular cores). (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</p>
    </caption>
    <graphic xlink:href="nihms-1763910-f0003" position="float"/>
  </fig>
  <fig position="float" id="F4">
    <label>Fig. 4.</label>
    <caption>
      <p id="P66">Patient stratification and interpretability for weakly-supervised federated survival prediction. Patients in the test set were stratified into high risk and low risk groups using the median (50% percentile) of the model’s predicted risk score distribution as the cutoff and the log-rank test was used to assess the statistical significance between survival distributions of the resulting risk groups. Top: increasing <italic toggle="yes">α</italic> by over two orders of magnitude for stronger guarantees on differential privacy did not eliminate the model’s ability to stratify patients into statistically significantly (<italic toggle="yes">p</italic> -value &lt; 0.05) different risk groups. Bottom: exemplars of Clear Cell Renal Cell Carcinoma patients predicted as high-risk and low-risk respectively by the model, the original H&amp;E (left), attention-based heatmap (center), and highest-attention patches (right). As compared to the subtyping classification problem, since survival analysis is an ordinal regression problem, the high attention patches correspond to regions with high prognostic relevance in stratifying patients into low versus high risk groups. The highest attention patches for the high-risk case focus predominantly on the tumor cells themselves, while the highest attention patches for the low risk case focus predominantly on lymphocytes within the stroma and directly interfacing with tumor cells, which corroborates with the known prognostic relevance of tumor-immune co-localization in pathology.</p>
    </caption>
    <graphic xlink:href="nihms-1763910-f0004" position="float"/>
  </fig>
  <fig position="float" id="F5">
    <label>Fig. 5.</label>
    <caption>
      <p id="P67">Performance comparison between simple averaging vs. weighted aggregation. Performance in terms of AUC ROC for classification and c-index for survival prediction is shown for federated averaging across different levels of <italic toggle="yes">α</italic>. Error bars show s.d. from 5-fold cross-validation.</p>
    </caption>
    <graphic xlink:href="nihms-1763910-f0005" position="float"/>
  </fig>
  <table-wrap position="float" id="T2">
    <label>Table 1</label>
    <caption>
      <p id="P68">Partition for BRCA subtyping (number of WSIs).</p>
    </caption>
    <table frame="hsides" rules="none">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="left" valign="middle" rowspan="1" colspan="1"/>
          <th align="left" valign="middle" rowspan="1" colspan="1">ILC</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">IDC</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Total</th>
        </tr>
        <tr>
          <th colspan="4" align="center" valign="bottom" rowspan="1">
            <hr/>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">TCGA Site 1</td>
          <td align="left" valign="top" rowspan="1" colspan="1">56</td>
          <td align="left" valign="top" rowspan="1" colspan="1">155</td>
          <td align="left" valign="top" rowspan="1" colspan="1">211</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">TCGA Site 2</td>
          <td align="left" valign="top" rowspan="1" colspan="1">46</td>
          <td align="left" valign="top" rowspan="1" colspan="1">268</td>
          <td align="left" valign="top" rowspan="1" colspan="1">314</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">TCGA Site 3</td>
          <td align="left" valign="top" rowspan="1" colspan="1">109</td>
          <td align="left" valign="top" rowspan="1" colspan="1">422</td>
          <td align="left" valign="top" rowspan="1" colspan="1">531</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">BWH</td>
          <td align="left" valign="top" rowspan="1" colspan="1">158</td>
          <td align="left" valign="top" rowspan="1" colspan="1">912</td>
          <td align="left" valign="top" rowspan="1" colspan="1">1070</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Total</td>
          <td align="left" valign="top" rowspan="1" colspan="1">369</td>
          <td align="left" valign="top" rowspan="1" colspan="1">1757</td>
          <td align="left" valign="top" rowspan="1" colspan="1">2126</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="T3">
    <label>Table 2</label>
    <caption>
      <p id="P69">Partition for RCC subtyping (number of WSIs).</p>
    </caption>
    <table frame="hsides" rules="none">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="left" valign="middle" rowspan="1" colspan="1"/>
          <th align="left" valign="middle" rowspan="1" colspan="1">CCRCC</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">PRCC</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">CHRCC</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Total</th>
        </tr>
        <tr>
          <th colspan="5" align="center" valign="bottom" rowspan="1">
            <hr/>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">TCGA Site 1</td>
          <td align="left" valign="top" rowspan="1" colspan="1">108</td>
          <td align="left" valign="top" rowspan="1" colspan="1">120</td>
          <td align="left" valign="top" rowspan="1" colspan="1">39</td>
          <td align="left" valign="top" rowspan="1" colspan="1">267</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">TCGA Site 2</td>
          <td align="left" valign="top" rowspan="1" colspan="1">78</td>
          <td align="left" valign="top" rowspan="1" colspan="1">100</td>
          <td align="left" valign="top" rowspan="1" colspan="1">31</td>
          <td align="left" valign="top" rowspan="1" colspan="1">209</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">TCGA Site 3</td>
          <td align="left" valign="top" rowspan="1" colspan="1">333</td>
          <td align="left" valign="top" rowspan="1" colspan="1">77</td>
          <td align="left" valign="top" rowspan="1" colspan="1">51</td>
          <td align="left" valign="top" rowspan="1" colspan="1">461</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">BWH</td>
          <td align="left" valign="top" rowspan="1" colspan="1">184</td>
          <td align="left" valign="top" rowspan="1" colspan="1">40</td>
          <td align="left" valign="top" rowspan="1" colspan="1">23</td>
          <td align="left" valign="top" rowspan="1" colspan="1">247</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Total</td>
          <td align="left" valign="top" rowspan="1" colspan="1">703</td>
          <td align="left" valign="top" rowspan="1" colspan="1">337</td>
          <td align="left" valign="top" rowspan="1" colspan="1">144</td>
          <td align="left" valign="top" rowspan="1" colspan="1">1184</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="T4">
    <label>Table 3</label>
    <caption>
      <p id="P70">Partition for CCRCC survival prediction (number of cases).</p>
    </caption>
    <table frame="hsides" rules="none">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="left" valign="middle" rowspan="1" colspan="1"/>
          <th align="left" valign="middle" rowspan="1" colspan="1">Uncensored</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Censored</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Total</th>
        </tr>
        <tr>
          <th colspan="4" align="center" valign="bottom" rowspan="1">
            <hr/>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">TCGA Site 1</td>
          <td align="left" valign="top" rowspan="1" colspan="1">16</td>
          <td align="left" valign="top" rowspan="1" colspan="1">88</td>
          <td align="left" valign="top" rowspan="1" colspan="1">104</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">TCGA Site 2</td>
          <td align="left" valign="top" rowspan="1" colspan="1">27</td>
          <td align="left" valign="top" rowspan="1" colspan="1">49</td>
          <td align="left" valign="top" rowspan="1" colspan="1">76</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">TCGA Site 3</td>
          <td align="left" valign="top" rowspan="1" colspan="1">128</td>
          <td align="left" valign="top" rowspan="1" colspan="1">203</td>
          <td align="left" valign="top" rowspan="1" colspan="1">331</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Total</td>
          <td align="left" valign="top" rowspan="1" colspan="1">171</td>
          <td align="left" valign="top" rowspan="1" colspan="1">340</td>
          <td align="left" valign="top" rowspan="1" colspan="1">511</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="T5" orientation="landscape">
    <label>Table 4</label>
    <caption>
      <p id="P71">BRCA subtyping test performance reported as five-fold mean (s.d.).</p>
    </caption>
    <table frame="hsides" rules="none">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="left" valign="middle" rowspan="1" colspan="1"/>
          <th align="left" valign="middle" rowspan="1" colspan="1">AUC ↑</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Error ↓</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">bACC ↑</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">F1 ↑</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">mAP ↑</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Cohen’s <italic toggle="yes">κ</italic> ↑</th>
        </tr>
        <tr>
          <th colspan="7" align="center" valign="bottom" rowspan="1">
            <hr/>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 1 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.819±0.018</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.169±0.015</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.667±0.054</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.453±0.092</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.508±0.026</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.359±0.083</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 2 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.752±0.066</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.178±0.018</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.684±0.053</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.478±0.074</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.454±0.075</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.373±0.079</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 3 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.698±0.070</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.180±0.015</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.639±0.055</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.405±0.107</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.386±0.065</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.305±0.105</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 4 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.788±0.017</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.190±0.029</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.691±0.009</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.490±0.013</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.441±0.050</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.375±0.031</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Centralized</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.919±0.013</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.104±0.012</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.792±0.025</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.684±0.032</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.761±0.043</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.623±0.037</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.862±0.025</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.149±0.023</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.736±0.023</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.575±0.043</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.610±0.076</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.485±0.057</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated, <italic toggle="yes">α</italic> = 0.001</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.836±0.021</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.166±0.023</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.744±0.016</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.568±0.032</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.537±0.049</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.467±0.045</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated, <italic toggle="yes">α</italic> = 0.01</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.833±0.023</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.173±0.028</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.739±0.021</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.557±0.036</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.535±0.048</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.451±0.052</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated, <italic toggle="yes">α</italic> = 0.1</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.842±0.022</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.159±0.021</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.756±0.026</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.585±0.036</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.550±0.053</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.488±0.048</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated, <italic toggle="yes">α</italic> = 1</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.657±0.033</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.426±0.210</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.582±0.051</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.337±0.046</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.294±0.038</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.127±0.076</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="T6" orientation="landscape">
    <label>Table 5</label>
    <caption>
      <p id="P72">RCC subtyping test performance reported as five-fold mean (s.d.).</p>
    </caption>
    <table frame="hsides" rules="none">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="left" valign="middle" rowspan="1" colspan="1"/>
          <th align="left" valign="middle" rowspan="1" colspan="1">AUC ↑</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Error ↓</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">bACC ↑</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">F1 ↑</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">mAP ↑</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Cohen’s <italic toggle="yes">κ</italic> ↑</th>
        </tr>
        <tr>
          <th colspan="7" align="center" valign="bottom" rowspan="1">
            <hr/>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 1 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.947±0.017</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.165±0.013</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.802±0.033</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.813±0.021</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.903±0.026</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.704±0.029</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 2 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.939±0.008</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.185±0.012</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.812±0.036</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.805±0.023</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.898±0.019</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.685±0.027</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 3 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.894±0.024</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.219±0.038</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.772±0.049</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.762±0.050</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.817±0.035</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.625±0.063</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 4 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.943±0.015</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.163±0.032</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.825±0.037</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.815±0.039</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.899±0.028</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.715±0.057</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Centralized</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.985±0.004</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.081±0.018</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.912±0.023</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.910±0.019</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.970±0.009</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.856±0.033</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.976±0.007</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.106±0.012</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.890±0.028</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.881±0.015</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.956±0.015</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.815±0.025</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated, <italic toggle="yes">α</italic> = 0.001</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.976±0.007</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.107±0.025</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.896±0.034</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.883±0.030</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.956±0.014</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.814±0.046</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated, <italic toggle="yes">α</italic> = 0.01</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.976±0.006</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.105±0.017</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.896±0.027</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.885±0.021</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.954±0.015</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.818±0.033</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated, <italic toggle="yes">α</italic> = 0.1</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.974±0.007</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.101±0.010</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.900±0.020</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.891±0.009</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.953±0.014</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.823±0.020</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated, <italic toggle="yes">α</italic> = 1</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.789±0.062</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.553±0.180</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.402±0.090</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.266±0.102</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.661±0.077</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.068±0.071</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="T7">
    <label>Table 6</label>
    <caption>
      <p id="P73">CCRCC survival prediction test performance reported as five-fold mean (±s.d.).</p>
    </caption>
    <table frame="hsides" rules="none">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="left" valign="middle" rowspan="1" colspan="1"/>
          <th align="left" valign="middle" rowspan="1" colspan="1">c-Index</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">AUC</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">P-Value</th>
        </tr>
        <tr>
          <th colspan="4" align="center" valign="bottom" rowspan="1">
            <hr/>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 1 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.502±0.018</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.513±0.032</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.937</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 2 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.506±0.017</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.520±0.022</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.662</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 3 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.645±0.064</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.674±0.077</td>
          <td align="left" valign="top" rowspan="1" colspan="1">9.14 × 10<sup>−4</sup></td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Centralized</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.692±0.043</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.729±0.046</td>
          <td align="left" valign="top" rowspan="1" colspan="1">1.39 × 10<sup>−8</sup></td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated, <italic toggle="yes">α</italic> = 0</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.683±0.064</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.719±0.070</td>
          <td align="left" valign="top" rowspan="1" colspan="1">2.86 × 10<sup>−8</sup></td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated, <italic toggle="yes">α</italic> = 0.001</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.639±0.090</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.664±0.103</td>
          <td align="left" valign="top" rowspan="1" colspan="1">1.52 × 10<sup>−5</sup></td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated, <italic toggle="yes">α</italic> = 0.01</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.648±0.099</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.676±0.111</td>
          <td align="left" valign="top" rowspan="1" colspan="1">2.39 × 10<sup>−5</sup></td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated, <italic toggle="yes">α</italic> = 0.1</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.647±0.085</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.672±0.098</td>
          <td align="left" valign="top" rowspan="1" colspan="1">2.52 × 10<sup>−9</sup></td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated, <italic toggle="yes">α</italic> = 1</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.508±0.036</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.504±0.044</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.805</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="T8" orientation="landscape">
    <label>Table 7</label>
    <caption>
      <p id="P74">BRCA subtyping performance tested on intra vs. inter-site test data, reported as five-fold mean (±s.d.).</p>
    </caption>
    <table frame="hsides" rules="none">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="left" valign="middle" rowspan="1" colspan="1"/>
          <th align="left" valign="middle" rowspan="1" colspan="1">Site 1</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Site 2</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Site 3</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Site 4</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">All (Macro-avg)</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">All (Micro-avg)</th>
        </tr>
        <tr>
          <th colspan="7" align="center" valign="bottom" rowspan="1">
            <hr/>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Centralized</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.929±0.034</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.883±0.055</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.887±0.060</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.938±0.022</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.909±0.013</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.919±0.013</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 1 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.841±0.026</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.776±0.063</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.786±0.074</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.853±0.023</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.814±0.022</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.819±0.018</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 2 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.703±0.143</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.739±0.050</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.782±0.045</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.847±0.039</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.768±0.052</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.752±0.066</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 3 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.620±0.108</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.713±0.132</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.772±0.084</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.798±0.077</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.726±0.085</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.698±0.070</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 4 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.806±0.026</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.704±0.048</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.828±0.045</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.853±0.042</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.798±0.031</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.788±0.017</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.859±0.046</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.838±0.077</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.837±0.041</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.919±0.024</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.863±0.024</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.862±0.025</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="T9" orientation="landscape">
    <label>Table 8</label>
    <caption>
      <p id="P75">RCC subtyping performance tested on intra vs. inter-site test data, reported as five-fold mean (±s.d.).</p>
    </caption>
    <table frame="hsides" rules="none">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="left" valign="middle" rowspan="1" colspan="1"/>
          <th align="left" valign="middle" rowspan="1" colspan="1">Site 1</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Site 2</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Site 3</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Site 4</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">All (Macro-avg)</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">All (Micro-avg)</th>
        </tr>
        <tr>
          <th colspan="7" align="center" valign="bottom" rowspan="1">
            <hr/>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Centralized</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.992±0.007</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.978±0.012</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.982±0.015</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.983±0.005</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.984±0.007</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.985±0.004</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 1 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.981±0.019</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.928±0.023</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.975±0.016</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.947±0.018</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.958±0.012</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.947±0.017</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 2 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.932±0.032</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.976±0.021</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.872±0.021</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.950±0.015</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.933±0.009</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.939±0.008</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 3 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.943±0.020</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.846±0.057</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.980±0.021</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.877±0.050</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.911±0.026</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.894±0.024</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 4 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.958±0.021</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.914±0.032</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.922±0.036</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.984±0.006</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.945±0.016</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.943±0.015</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.990±0.008</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.967±0.013</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.971±0.016</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.985±0.004</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.978±0.007</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.976±0.007</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="T10" orientation="landscape">
    <label>Table 9</label>
    <caption>
      <p id="P76">CCRCC survival prediction performance tested on intra vs. inter-site test data, reported as five-fold mean (±s.d.).</p>
    </caption>
    <table frame="hsides" rules="none">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="left" valign="middle" rowspan="1" colspan="1"/>
          <th align="left" valign="middle" rowspan="1" colspan="1">Site 1</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Site 2</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">Site 3</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">All (Micro-avg)</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">All (Macro-avg)</th>
        </tr>
        <tr>
          <th colspan="6" align="center" valign="bottom" rowspan="1">
            <hr/>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Centralized</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.577±0.185</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.653±0.148</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.709±0.067</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.692±0.043</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.646±0.068</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 1 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.463±0.132</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.449±0.070</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.522±0.039</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.502±0.018</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.478±0.055</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 2 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.475±0.076</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.566±0.062</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.491±0.029</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.506±0.017</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.511±0.028</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Site 3 only</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.651±0.119</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.573±0.119</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.685±0.067</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.645±0.064</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.636±0.061</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Federated</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.594±0.200</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.596±0.177</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.729±0.062</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.683±0.064</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.640±0.097</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="T11">
    <label>Table 10</label>
    <caption>
      <p id="P77">Federated learning performance for difference communication pace.</p>
    </caption>
    <table frame="hsides" rules="none">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <tbody>
        <tr>
          <td colspan="5" align="left" valign="top" rowspan="1">A. BRCA subtyping performance for different communication pace</td>
        </tr>
        <tr>
          <td colspan="5" align="center" valign="bottom" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1"/>
          <td align="left" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">E</italic>=1</td>
          <td align="left" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">E</italic>=2</td>
          <td align="left" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">E</italic>=4</td>
          <td align="left" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">E</italic>=8</td>
        </tr>
        <tr>
          <td colspan="5" align="center" valign="bottom" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">AUC</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.862±0.025</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.869±0.024</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.865±0.027</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.867±0.024</td>
        </tr>
        <tr>
          <td colspan="5" align="left" valign="middle" rowspan="1">B. RCC subtyping performance for different communication pace</td>
        </tr>
        <tr>
          <td colspan="5" align="center" valign="bottom" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1"/>
          <td align="left" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">E</italic>=1</td>
          <td align="left" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">E</italic>=2</td>
          <td align="left" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">E</italic>=4</td>
          <td align="left" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">E</italic>=8</td>
        </tr>
        <tr>
          <td colspan="5" align="center" valign="bottom" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">AUC</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.976±0.007</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.975±0.006</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.975±0.007</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.973±0.009</td>
        </tr>
        <tr>
          <td colspan="5" align="left" valign="middle" rowspan="1">C. CCRCC survival prediction performance for different communication pace</td>
        </tr>
        <tr>
          <td colspan="5" align="center" valign="bottom" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1"/>
          <td align="left" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">E</italic>=1</td>
          <td align="left" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">E</italic>=2</td>
          <td align="left" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">E</italic>=4</td>
          <td align="left" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">E</italic>=8</td>
        </tr>
        <tr>
          <td colspan="5" align="center" valign="bottom" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">c-index</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.683±0.064</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.686±0.053</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.664±0.083</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.655±0.074</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="T12">
    <label>Table 11</label>
    <caption>
      <p id="P78">Survival prediction performance for different choices of <italic toggle="yes">R</italic> and comparison with existing approaches, reported as five-fold mean (±s.d.).</p>
    </caption>
    <table frame="hsides" rules="none">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="left" valign="middle" rowspan="1" colspan="1"/>
          <th align="left" valign="middle" rowspan="1" colspan="1">c-Index</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">AUC</th>
          <th align="left" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">P</italic>-Value</th>
        </tr>
        <tr>
          <th colspan="4" align="center" valign="bottom" rowspan="1">
            <hr/>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Grade</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.648±0.047</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.668±0.058</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.272</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Grade + Age + Gender</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.693±0.050</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.716±0.065</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.193</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic toggle="yes">R</italic> = 2</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.681±0.031</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.708±0.044</td>
          <td align="left" valign="top" rowspan="1" colspan="1">1.28 × 10<sup>−8</sup></td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic toggle="yes">R</italic> = 4</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.685±0.020</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.723±0.022</td>
          <td align="left" valign="top" rowspan="1" colspan="1">6.38 × 10<sup>−6</sup></td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic toggle="yes">R</italic> = 6</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.678±0.033</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.713±0.033</td>
          <td align="left" valign="top" rowspan="1" colspan="1">7.58 × 10<sup>−8</sup></td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic toggle="yes">R</italic> = 8</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.692±0.043</td>
          <td align="left" valign="top" rowspan="1" colspan="1">0.732±0.048</td>
          <td align="left" valign="top" rowspan="1" colspan="1">1.39 × 10<sup>−8</sup></td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</floats-group>
