<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9477526</article-id>
    <article-id pub-id-type="pmid">35876792</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac508</article-id>
    <article-id pub-id-type="publisher-id">btac508</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>BioADAPT-MRC: adversarial learning-based domain adaptation improves biomedical machine reading comprehension task</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3422-9650</contrib-id>
        <name>
          <surname>Mahbub</surname>
          <given-names>Maria</given-names>
        </name>
        <aff><institution>Department of Electrical Engineering and Computer Science, University of Tennessee</institution>, Knoxville, TN 37996, <country country="US">USA</country></aff>
        <aff><institution>Cyber Resilience and Intelligence Division, Oak Ridge National Laboratory</institution>, Oak Ridge, TN 37830, <country country="US">USA</country></aff>
        <xref rid="btac508-cor1" ref-type="corresp"/>
        <!--mmahbub@vols.utk.edu-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Srinivasan</surname>
          <given-names>Sudarshan</given-names>
        </name>
        <aff><institution>Cyber Resilience and Intelligence Division, Oak Ridge National Laboratory</institution>, Oak Ridge, TN 37830, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Begoli</surname>
          <given-names>Edmon</given-names>
        </name>
        <aff><institution>Cyber Resilience and Intelligence Division, Oak Ridge National Laboratory</institution>, Oak Ridge, TN 37830, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Peterson</surname>
          <given-names>Gregory D</given-names>
        </name>
        <aff><institution>Department of Electrical Engineering and Computer Science, University of Tennessee</institution>, Knoxville, TN 37996, <country country="US">USA</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Lu</surname>
          <given-names>Zhiyong</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btac508-cor1">To whom correspondence should be addressed. Email: <email>mmahbub@vols.utk.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>15</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-07-25">
      <day>25</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>25</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <volume>38</volume>
    <issue>18</issue>
    <fpage>4369</fpage>
    <lpage>4379</lpage>
    <history>
      <date date-type="received">
        <day>25</day>
        <month>2</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>31</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>02</day>
        <month>7</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>10</day>
        <month>8</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac508.pdf"/>
    <abstract>
      <title>ABSTRACT</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Biomedical machine reading comprehension (biomedical-MRC) aims to comprehend complex biomedical narratives and assist healthcare professionals in retrieving information from them. The high performance of modern neural network-based MRC systems depends on high-quality, large-scale, human-annotated training datasets. In the biomedical domain, a crucial challenge in creating such datasets is the requirement for domain knowledge, inducing the scarcity of labeled data and the need for transfer learning from the labeled general-purpose (source) domain to the biomedical (target) domain. However, there is a discrepancy in marginal distributions between the general-purpose and biomedical domains due to the variances in topics. Therefore, direct-transferring of learned representations from a model trained on a general-purpose domain to the biomedical domain can hurt the model’s performance.</p>
      </sec>
      <sec id="s3">
        <title>Results</title>
        <p>We present an adversarial learning-based domain adaptation framework for the biomedical machine reading comprehension task (BioADAPT-MRC), a neural network-based method to address the discrepancies in the marginal distributions between the general and biomedical domain datasets. BioADAPT-MRC relaxes the need for generating pseudo labels for training a well-performing biomedical-MRC model. We extensively evaluate the performance of BioADAPT-MRC by comparing it with the best existing methods on three widely used benchmark biomedical-MRC datasets—BioASQ-7b, BioASQ-8b and BioASQ-9b. Our results suggest that without using any synthetic or human-annotated data from the biomedical domain, BioADAPT-MRC can achieve state-of-the-art performance on these datasets.</p>
      </sec>
      <sec id="s4">
        <title>Availability and implementation</title>
        <p>BioADAPT-MRC is freely available as an open-source project at <ext-link xlink:href="https://github.com/mmahbub/BioADAPT-MRC" ext-link-type="uri">https://github.com/mmahbub/BioADAPT-MRC</ext-link>.</p>
      </sec>
      <sec id="s6">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Department of Veterans Affairs, VHA Office of Mental Health and Suicide Prevention</institution>
          </institution-wrap>
        </funding-source>
        <award-id>DE- AC05-00OR22725</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>US Department of Energy</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="11"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>During the consultation phase of primary patient care, for every two patients, healthcare professionals raise at least one question (<xref rid="btac508-B13" ref-type="bibr">Del Fiol <italic toggle="yes">et al.</italic>, 2014</xref>). Even though they can successfully find answers to 78% of the pursued questions, they never pursue half of their questions because of time constraints and the suspicion that helpful answers do not exist, notwithstanding the availability of ample evidence (<xref rid="btac508-B5" ref-type="bibr">Bastian <italic toggle="yes">et al.</italic>, 2010</xref>; <xref rid="btac508-B13" ref-type="bibr">Del Fiol <italic toggle="yes">et al.</italic>, 2014</xref>). Additionally, searching existing resources for reliable, relevant and high-quality information poses an inconvenience for the clinicians on account of time limitation. This phenomenon elicits the dependency on general-information electronic resources that are simple to use, such as Google (<xref rid="btac508-B23" ref-type="bibr">Hider <italic toggle="yes">et al.</italic>, 2009</xref>). Apart from the healthcare professionals, there is also a growing public interest in learning about their medical conditions online (<xref rid="btac508-B16" ref-type="bibr">Fox and Duggan, 2013</xref>). Nevertheless, the criteria for ranking search results by general-purpose search engines does not conform directly to the fundamentals of evidence-based medicine and thus lacks rigor, reliability and quality (<xref rid="btac508-B23" ref-type="bibr">Hider <italic toggle="yes">et al.</italic>, 2009</xref>).</p>
    <p>While traditional information retrieval (IR) systems somewhat mitigate this issue, it still requires 4 h for a healthcare-information professional to find answers to queries related to complex biomedical resources (<xref rid="btac508-B48" ref-type="bibr">Russell-Rose and Chamberlain, 2017</xref>). Compared to the IR systems that usually provide the users (general population or healthcare professionals) a group of documents to interpret and find the exact answers, biomedical machine reading comprehension (biomedical-MRC) systems can provide exact answers to user inquiries, saving both time and effort.</p>
    <p>Machine reading comprehension (MRC) is a challenging task in natural language processing (NLP), aiming to teach and evaluate the machines to understand user-defined questions, read and comprehend input contexts (namely, context) and return answers from them. The datasets in the MRC task consist of context–question–answer triplets where the question–answer pairs are considered labels. With the development and availability of efficient computing hardware resources, researchers have developed several state-of-the-art (SOTA) neural network-based (NN-based) MRC systems capable of achieving analogous or superior to human-level performance on several benchmark MRC datasets (<xref rid="btac508-B14" ref-type="bibr">Devlin <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac508-B28" ref-type="bibr">Joshi <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac508-B46" ref-type="bibr">Rajpurkar <italic toggle="yes">et al.</italic>, 2016</xref>). However, this achievement is highly dependent on a large amount of high-quality human-annotated datasets that are used to train these systems (<xref rid="btac508-B46" ref-type="bibr">Rajpurkar <italic toggle="yes">et al.</italic>, 2016</xref>). For domain-specific MRC tasks, especially biomedical-MRC, building a high-quality labeled dataset, specifically, the question–answer pairs residing in the dataset requires undeniable effort and knowledge of subject matter experts. This requirement leads to smaller biomedical-MRC datasets and, consequently, unreliably poor performance on the MRC task itself (<xref rid="btac508-B44" ref-type="bibr">Pergola <italic toggle="yes">et al.</italic>, 2021</xref>). Hence, developing an approach that can effectively leverage unlabeled or small-scale labeled datasets in training the biomedical-MRC model is crucial for improving performance.</p>
    <p>Researchers have addressed this issue by using transfer learning, a learning process to transfer knowledge from a source domain to a target domain (<xref rid="btac508-B42" ref-type="bibr">Pan and Yang, 2010</xref>). In domain-specific MRC problems, such as biomedical-MRC, the source domain is usually a general-purpose domain where a large-scale human-annotated MRC dataset is available. The target domain, in this case, is the biomedical domain. In this work, we focus on transferring the knowledge from an MRC model trained on a labeled general-purpose-domain dataset to the biomedical domain where only <italic toggle="yes">unlabeled contexts</italic> are available. Unlabeled contexts refer to only contexts in the MRC dataset with no question–answer pairs.</p>
    <p>Often, directly transferring the knowledge representations (learned by an MRC model) from the source to the target domain can hurt the performance of the model because of the distributional discrepancies between the data seen at train and test time (<xref rid="btac508-B17" ref-type="bibr">Ganin and Lempitsky, 2015</xref>). Domain adaptation, a sub-setting of transfer learning (<xref rid="btac508-B42" ref-type="bibr">Pan and Yang, 2010</xref>), aims at mitigating these discrepancies through <italic toggle="yes">simultaneous generation of feature representations that are discriminative from the viewpoint of the MRC task in the source domain and indiscriminative from the perspective of the shift in the marginal distributions between the source and target domains</italic> (<xref rid="btac508-B17" ref-type="bibr">Ganin and Lempitsky, 2015</xref>).</p>
    <p>We propose <bold>A</bold>dversarial learning-based <bold>D</bold>omain ad<bold>APT</bold>ation framework for <bold>Bio</bold>medical <bold>M</bold>achine <bold>R</bold>eading <bold>C</bold>omprehension (BioADAPT-MRC), a new framework that uses adversarial learning to generate domain-invariant feature representations for better domain adaptation in biomedical-MRC models. In an adversarial learning framework, we train two adversaries (feature generator and discriminator) alternately or jointly against one another to generate domain-invariant features. Domain-invariant features imply that the feature representations extracted from the source- and the target-domain samples are closer in the embedding space.</p>
    <p>While other recent domain adaptation approaches for the MRC task focus on generating pseudo question–answer pairs to augment the training data (<xref rid="btac508-B19" ref-type="bibr">Golub <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac508-B56" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019</xref>), we utilize only the unlabeled contexts from the target domain. This property makes our framework more suitable in cases where not only human-annotated dataset is scarce but also the generation of synthetic question–answer pairs is computationally expensive, and needs further validation from domain-experts (due to the sensitivity to the correctness of the domain knowledge).</p>
    <p>We validate our proposed framework on three widely used benchmark datasets from the cornerstone challenge on biomedical question answering and semantic indexing, BioASQ (<xref rid="btac508-B52" ref-type="bibr">Tsatsaronis <italic toggle="yes">et al.</italic>, 2015</xref>), using their recommended evaluation metrics. We empirically demonstrate that with the presence of no labeled data from the biomedical domain—synthetic or human-annotated—our framework can achieve SOTA performance on these datasets. We further evaluate the domain adaptation capability of our framework by using clustering and dimensionality reduction techniques. Additionally, we extend our framework to a semi-supervised setting and use varying ratios of labeled target-domain data for evaluation. Last but not least, we perform a thorough error analysis of our proposed framework to demonstrate its strengths and weaknesses.</p>
    <p>The primary contributions of the article are as follows: (i) we propose BioADAPT-MRC, an adversarial learning-based domain adaptation framework that incorporates a domain-similarity discriminator with an auxiliary task layer and aims at reducing the domain shift between high-resource general-purpose domain and low-resource biomedical domain. (ii) We leverage the unlabeled contexts from the biomedical domain and thus relax the need for synthetic or human-annotated labels for target-domain data. (iii) We further extend the learning paradigm of BioADAPT-MRC to a semi-supervised setting. We show that our framework can be successfully employed to improve the performance of a pre-trained language model (PLM) in the presence of varying ratios of labeled target-domain data. (iv) Through comprehensive evaluations and analyses on several benchmark datasets, we demonstrate the effectiveness of our proposed framework and its domain adaptation capability for biomedical-MRC.</p>
  </sec>
  <sec>
    <title>2 Background and related work</title>
    <p>In this article, we focus on the biomedical-MRC task using the adversarial learning-based domain adaptation technique. Thus, our work is in the confluence of two main research areas: biomedical-MRC and domain adaptation using adversarial learning.</p>
    <p><italic toggle="yes">Biomedical-MRC</italic>. In the biomedical-MRC task, the goal is to extract an answer span, given a user-defined question and a biomedical context. In NN-based biomedical-MRC systems, the question–context pairs are converted from discrete textual form to continuous high-dimensional vector form using word-embedding algorithms, such as word2vec (<xref rid="btac508-B36" ref-type="bibr">Mikolov <italic toggle="yes">et al.</italic>, 2013</xref>), GloVe (<xref rid="btac508-B43" ref-type="bibr">Pennington <italic toggle="yes">et al.</italic>, 2014</xref>), FastText (<xref rid="btac508-B6" ref-type="bibr">Bojanowski <italic toggle="yes">et al.</italic>, 2017</xref>) and Bidirectional Encoder Representations from Transformers (BERT) (<xref rid="btac508-B14" ref-type="bibr">Devlin <italic toggle="yes">et al.</italic>, 2019</xref>), etc. Among numerous architectural varieties of these NN-based MRC systems, the transformer-based PLMs, such as BERT, are the current SOTA (<xref rid="btac508-B21" ref-type="bibr">Gu <italic toggle="yes">et al.</italic>, 2021</xref>). The original BERT model is pre-trained on general-purpose English corpora. Considering the semantic and syntactic uniqueness of the biomedical text, researchers have developed different variants of BERT models for the biomedical domain that are pre-trained on several biomedical corpora, such as PMC full articles, PubMed abstracts and MIMIC datasets. Some examples of such PLMs are BioBERT (<xref rid="btac508-B34" ref-type="bibr">Lee <italic toggle="yes">et al.</italic>, 2020</xref>), PubMedBERT (<xref rid="btac508-B21" ref-type="bibr">Gu <italic toggle="yes">et al.</italic>, 2021</xref>) and BioElectra (<xref rid="btac508-B45" ref-type="bibr">Raj Kanakarajan <italic toggle="yes">et al.</italic>, 2021</xref>), which reportedly outperform the original BERT model in various biomedical NLP tasks. These PLMs are used as trainable encoding modules (encoders) in downstream biomedical NLP tasks, such as biomedical named entity recognition (NER) (<xref rid="btac508-B37" ref-type="bibr">Naseem <italic toggle="yes">et al.</italic>, 2021</xref>), clinical-note classification (<xref rid="btac508-B1" ref-type="bibr">Agnikula Kshatriya <italic toggle="yes">et al.</italic>, 2021</xref>), MRC (<xref rid="btac508-B26" ref-type="bibr">Jeong <italic toggle="yes">et al.</italic>, 2020</xref>), etc. Usually, to accomplish the downstream tasks, such as biomedical-MRC by transferring the knowledge from the PLMs, researchers add a few task-specific layers, commonly feed-forward neural network layers, at the end of the encoders (<xref rid="btac508-B25" ref-type="bibr">Hosein <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac508-B26" ref-type="bibr">Jeong <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac508-B34" ref-type="bibr">Lee <italic toggle="yes">et al.</italic>, 2020</xref>).</p>
    <p><italic toggle="yes">Transfer learning</italic>. Transfer learning is an approach to transfer knowledge representations acquired from a widely explored domain/task (source), to a new or less explored domain/task (target) (<xref rid="btac508-B42" ref-type="bibr">Pan and Yang, 2010</xref>). Adopting the notations provided by <xref rid="btac508-B42" ref-type="bibr">Pan and Yang (2010)</xref>, a domain <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mi mathvariant="script">D</mml:mi></mml:math></inline-formula> consists of a feature space <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mi mathvariant="script">X</mml:mi></mml:math></inline-formula> (different from the feature representation learned by the network) and a marginal distribution of the learning samples <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>X</mml:mi><mml:mo> </mml:mo><mml:mo>∈</mml:mo><mml:mi mathvariant="script">X</mml:mi></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">p</italic>(<italic toggle="yes">X</italic>). In NLP, the marginal distributions are different when the languages are the same but the topics are different in the source and target domains (<xref rid="btac508-B4" ref-type="bibr">Bashath <italic toggle="yes">et al.</italic>, 2022</xref>). Considering a label space <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mi mathvariant="script">Y</mml:mi></mml:math></inline-formula>, for a given domain <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mi mathvariant="script">D</mml:mi></mml:math></inline-formula>, a task <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mi mathvariant="script">T</mml:mi></mml:math></inline-formula> can be described as <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">Y</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a predictor function learned from the training data <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">Y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
    <p>Data scarcity in the target domain is often an impediment to the model’s performance while training for a target task. Transfer learning tackles this issue by aiming to improve generalizability on a target task using acquired knowledge from a source domain <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, a target domain <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> along with their respective associated tasks <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">T</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">T</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. For this work, we use <italic toggle="yes">transductive transfer learning</italic>, which uses labeled source domain, unlabeled target domain, identical source and target tasks and different source and target domains. Depending on the similarity in the feature spaces, there are two cases of transductive transfer learning: (i) different feature spaces for the source and target domains, e.g. cross-lingual transfer learning and (ii) identical feature spaces, but different marginal probability distributions for the source- and target-domain samples, e.g. transfer learning between two domains with the same language but different topics (<xref rid="btac508-B4" ref-type="bibr">Bashath <italic toggle="yes">et al.</italic>, 2022</xref>). In this article, we use the latter case of transductive transfer learning to train the biomedical-MRC system, otherwise known as domain adaptation (<xref rid="btac508-B42" ref-type="bibr">Pan and Yang, 2010</xref>).</p>
    <p><italic toggle="yes">Domain adaptation</italic>. Domain adaptation aims at increasing the generalizability of machine learning models when posed with unlabeled or very few labeled data from the target domain by generating domain-invariant representation (<xref rid="btac508-B18" ref-type="bibr">Glorot <italic toggle="yes">et al.</italic>, 2011</xref>). One can enforce the learning of domain-invariant features in machine learning models by implementing the adversarial learning framework (<xref rid="btac508-B17" ref-type="bibr">Ganin and Lempitsky, 2015</xref>; <xref rid="btac508-B53" ref-type="bibr">Tzeng <italic toggle="yes">et al.</italic>, 2017</xref>). In the adversarial setting, usually, a domain discriminator is incorporated into the MRC framework where besides performing the MRC task, the goal is to attempt at fooling the discriminator by generating domain-invariant features (<xref rid="btac508-B56" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019</xref>). Researchers have successfully applied domain adaptation in many tasks, such as sentiment classification (<xref rid="btac508-B18" ref-type="bibr">Glorot <italic toggle="yes">et al.</italic>, 2011</xref>), speech recognition (<xref rid="btac508-B49" ref-type="bibr">Sun <italic toggle="yes">et al.</italic>, 2017</xref>), neural machine translation (<xref rid="btac508-B51" ref-type="bibr">Thompson <italic toggle="yes">et al.</italic>, 2019</xref>), NER (<xref rid="btac508-B55" ref-type="bibr">Vu <italic toggle="yes">et al.</italic>, 2020</xref>) and image segmentation (<xref rid="btac508-B22" ref-type="bibr">Guan <italic toggle="yes">et al.</italic>, 2021</xref>). However, compared to these tasks, the application of domain adaptation to the MRC task poses one additional challenge apart from missing answers—the missing questions in the target domain. Over recent years, researchers have proposed various methods to generate synthetic question–answer pairs from unlabeled contexts. For example, <xref rid="btac508-B56" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> (2019)</xref> used NER and Bi-LSTM, <xref rid="btac508-B19" ref-type="bibr">Golub <italic toggle="yes">et al.</italic> (2017)</xref> used conditional probability, IOB tagger and Bi-LSTM and <xref rid="btac508-B63" ref-type="bibr">Yue <italic toggle="yes">et al.</italic> (2021)</xref> used seq2seq model with an attention mechanism to generate pseudo question–answer pairs. A multi-task learning approach has also been used for domain adaptation in MRC tasks (<xref rid="btac508-B39" ref-type="bibr">Nishida <italic toggle="yes">et al.</italic>, 2020</xref>).</p>
    <p>Among these works in MRC and domain adaptation, the AdaMRC model proposed by <xref rid="btac508-B56" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> (2019)</xref> focuses on learning domain-invariant features in an adversarial setting as ours. However, the main differences between BioADAPT-MRC and AdaMRC are as follows: (i) while AdaMRC uses synthetically generated question–answer pairs to augment the target-domain dataset, BioADAPT-MRC directly uses the unlabeled contexts and thus relaxes the need for synthetic question–answer pairs. In later sections, we show that although synthetic questions can improve the performance of MRC tasks for various target domains, such as Wikipedia, web search log and news (<xref rid="btac508-B56" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019</xref>), they can hurt the performance of the MRC task for the biomedical domain. (ii) While AdaMRC uses the binary classification loss, BioADAPT-MRC uses triplet loss to minimize the domain shift between the source and target domains. Unlike binary classification loss, triplet loss considers both similarity and dissimilarity between two samples for gradient update and is known to be successful in deep metric learning where the aim is to map semantically similar instances closer in the embedding space and <italic toggle="yes">vice versa</italic> (<xref rid="btac508-B10" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2018b</xref>; <xref rid="btac508-B29" ref-type="bibr">Kaya and Bilge, 2019</xref>; <xref rid="btac508-B30" ref-type="bibr">Kim <italic toggle="yes">et al.</italic>, 2018</xref>). Moreover, triplet loss makes BioADAPT-MRC directly applicable to domain adaptation among more than two domains. While multiple prior works in computer vision have successfully used triplet loss for domain adaptation in numerous applications (<xref rid="btac508-B33" ref-type="bibr">Laiz <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac508-B59" ref-type="bibr">Wen <italic toggle="yes">et al.</italic>, 2018</xref>), to the best of our knowledge, ours is the first in the application of the MRC task in NLP. (iii) To improve performance and stabilize the training process in the adversarial domain adaptation framework, BioADAPT-MRC uses an auxiliary task layer, similar to AC-GAN (<xref rid="btac508-B40" ref-type="bibr">Odena <italic toggle="yes">et al.</italic>, 2017</xref>).</p>
  </sec>
  <sec>
    <title>3 Materials and methods</title>
    <p>In this section, we discuss our adversarial learning-based domain adaptation framework for the biomedical-MRC task.</p>
    <sec>
      <title>3.1 Problem definition</title>
      <p>Given an unlabeled target domain <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and a labeled source domain <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> along with their respective learning tasks <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">T</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">T</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, we assume that <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">T</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">T</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> because of <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="script">X</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≠</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="script">X</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the marginal probability distribution, <italic toggle="yes">X<sub>t</sub></italic> and <italic toggle="yes">X<sub>s</sub></italic> are learning samples from the target and source domains, respectively. Thus, while the tasks are identical, the domains are different due to different marginal probability distributions in their data.</p>
      <p>In this work, <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the biomedical domain where only unlabeled biomedical contexts are available, and <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the general-purpose domain where large-scale labeled data are available. As mentioned in Section 2, despite having the same language, differences in the topics between two domains cause the domains to be different because of the dissimilarities in <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. In this work, we consider that the general-purpose and the biomedical domains have different topics. Thus, we assume that <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≠</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
      <p>The task for both domains is extractive MRC. Given a question <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> and a context <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, extractive MRC predicts the start and end positions <italic toggle="yes">a</italic><sup>start</sup> and <italic toggle="yes">a</italic><sup>end</sup>, respectively, of the answer span <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">start</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">end</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> in <italic toggle="yes">C</italic> such that there exists one and only one answer span consisting of continuous tokens in the context. Here, <italic toggle="yes">q<sub>i</sub></italic> denotes the <italic toggle="yes">i</italic>th token in the question, <italic toggle="yes">c<sub>i</sub></italic> denotes the <italic toggle="yes">i</italic>th token in the context and <italic toggle="yes">n</italic>, <italic toggle="yes">m</italic>, respectively, denote the number of tokens in <italic toggle="yes">Q</italic> and <italic toggle="yes">C</italic>.</p>
    </sec>
    <sec>
      <title>3.2 BioADAPT-MRC</title>
      <p>Given the labeled and unlabeled inputs, respectively, from the source and target domains, our proposed framework BioADAPT-MRC aims at achieving the following two objectives: (i) predicting the answer spans from the provided contexts and (ii) addressing the discrepancies in the marginal distributions between the inputs in the source and target domains by generating domain-invariant features. <xref rid="btac508-F1" ref-type="fig">Figure 1</xref> demonstrates the three primary components of the BioADAPT-MRC framework:</p>
      <fig position="float" id="btac508-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>BioADAPT-MRC: an BioADAPT-MRC task. The framework has three main components: (i) feature extractor <italic toggle="yes">M<sub>F</sub></italic>, (ii) MRC-module <italic toggle="yes">M<sub>Q</sub></italic> and (iii) domain-similarity discriminator <italic toggle="yes">D</italic></p>
        </caption>
        <graphic xlink:href="btac508f1" position="float"/>
      </fig>
      <list list-type="bullet">
        <list-item>
          <p><italic toggle="yes">Feature extractor</italic> accepts a text sequence and encodes it into a high-dimensional continuous vector representation.</p>
        </list-item>
        <list-item>
          <p><italic toggle="yes">MRC-module</italic> accepts the encoded representation from either the source domain (training time) or the target domain (test time), then predicts the start and end positions of the answer span <italic toggle="yes">A</italic> in <italic toggle="yes">C</italic>.</p>
        </list-item>
        <list-item>
          <p><italic toggle="yes">Domain-similarity discriminator</italic> accepts the encoded representations from the source and target domains and learns to distinguish between them.</p>
        </list-item>
      </list>
      <sec>
        <label>3.2.1</label>
        <title>Feature extractor</title>
        <p>Given an input sample from either domain, the feature extractor <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mi>F</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> maps it to a common feature space <italic toggle="yes">F</italic>:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mi>F</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>Here, <italic toggle="yes">f<sub>i</sub></italic> is the extracted feature for the <italic toggle="yes">i</italic>th input sample <italic toggle="yes">X<sub>i</sub></italic> from either <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> or <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. We utilize the encoder of the PLM BioELECTRA (<xref rid="btac508-B45" ref-type="bibr">Raj Kanakarajan <italic toggle="yes">et al.</italic>, 2021</xref>) as the feature extractor. We choose BioELECTRA for the following reason: while biomedical domain-specific BERT models, such as BioBERT, SciBERT outperform the original BERT models in several biomedical NLP tasks (<xref rid="btac508-B2" ref-type="bibr">Alsentzer <italic toggle="yes">et al.</italic>, 2019</xref>), BioELECTRA has the best performance scores on the <italic toggle="yes">Biomedical Language Understanding and Reasoning Benchmark</italic> (<xref rid="btac508-B21" ref-type="bibr">Gu <italic toggle="yes">et al.</italic>, 2021</xref>).</p>
        <p>As mentioned in Section 2, the features in this task are trainable, high-dimensional word embeddings extracted from the question–context pairs. To generate these word embeddings, the BioELECTRA model utilizes the transformer-based architecture from one of the BERT-variants, ELECTRA. The ELECTRA model has 12 layers, 768 hidden size, 3072 feed-forward network (FFN) inner hidden size and 12 attention heads per layer (<xref rid="btac508-B11" ref-type="bibr">Clark <italic toggle="yes">et al.</italic>, 2020</xref>). The pre-training corpora for BioELECTRA are 3.2 million PubMed Central full-text articles and 22 million PubMed abstracts, and the pre-training task is the replaced token prediction task. BioELECTRA has a vocabulary of size 30 522. The maximum number of tokens per input can be 512, where the embedding dimension of each token is 768. For each pair, the final tokenized input of the BioELECTRA model is <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">SEP</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">SEP</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. Here, <italic toggle="yes">Q</italic> and <italic toggle="yes">C</italic> are, respectively, the tokens from the question and the context, <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> is a special token that can be considered to have an accumulated representation of the input sequence (<xref rid="btac508-B14" ref-type="bibr">Devlin <italic toggle="yes">et al.</italic>, 2019</xref>) and used for classification tasks, <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">SEP</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> is another special token that separates two consecutive sequences. Note that, since the samples in the target domain are unlabeled, in place of the question tokens <italic toggle="yes">Q</italic>, we use a special token <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">MASK</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> to maintain consistency in the structure of the tokenized samples.</p>
      </sec>
      <sec>
        <label>3.2.2</label>
        <title>MRC-module</title>
        <p>As the MRC-module <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, we add a simple fully connected layer with hidden size <italic toggle="yes">H </italic>=<italic toggle="yes"> </italic>768 on top of the feature extractor <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mi>F</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and use the softmax activation function to generate probability distributions for start and end token positions following <xref rid="E2" ref-type="disp-formula">Equation (2)</xref>.
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="italic">start</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:msup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">start</mml:mi></mml:mrow></mml:msup><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">seq</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:msup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">start</mml:mi></mml:mrow></mml:msup><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>;</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="italic">end</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:msup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">end</mml:mi></mml:mrow></mml:msup><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">seq</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:msup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">end</mml:mi></mml:mrow></mml:msup><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>Here, <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="italic">start</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="italic">end</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> are the probabilities of the <italic toggle="yes">l</italic>th token to be predicted as <italic toggle="yes">start</italic> and <italic toggle="yes">end</italic>, respectively, <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> is the hidden representation vector of the <italic toggle="yes">l</italic>th token, <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">start</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">end</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> are two trainable weight matrices, <italic toggle="yes">n</italic><sub>seq</sub> is the input sequence length. We use the cross-entropy loss <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> on the predicted answer positions as the objective function for the <italic toggle="yes">M<sub>Q</sub></italic>. Since for each answer span prediction, we get two predicted outputs for the start and end positions, we average the total cross-entropy loss as shown in <xref rid="E3" ref-type="disp-formula">Equation (3)</xref>.
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">log</mml:mi><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">start</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="italic">start</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="italic">log</mml:mi><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">end</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="italic">end</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>Here, the golden answer’s start and end token positions are represented by <italic toggle="yes">y</italic><sup>start</sup> and <italic toggle="yes">y</italic><sup>end</sup>, respectively. During test phase, the predicted answer span is selected based on the positions of the highest probabilities from <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">seq</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="italic">start</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">seq</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="italic">end</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p>
      </sec>
      <sec>
        <label>3.2.3</label>
        <title>Domain-similarity discriminator</title>
        <p>The domain-similarity discriminator <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> addresses the domain variance between two domains (caused by the discrepancies in the marginal probability distributions), as follows: in the adversarial setting, <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> learns to distinguish between the feature representations of the source- and target-domain samples generated by the feature extractor. <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> then penalizes the feature extractor for producing domain-variant feature representations and thus promotes the generation of domain-invariant features. <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> uses cosine distance between the feature representations of the input samples to distinguish between the domains. We consider that two samples are closer in the embedding space and thus have a greater chance to be in the same domain if their feature representations have a smaller cosine distance between them and <italic toggle="yes">vice versa</italic>. The input of <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a triplet <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>s</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> are, respectively, the feature representations of the <italic toggle="yes">k</italic>th sample <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> from the target domain and <italic toggle="yes">i</italic>th sample <inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> and <italic toggle="yes">j</italic>th sample <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>s</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> from the source domain extracted by <inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mi>F</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. The triplet is then split into two distinct pairs, consisting of <inline-formula id="IE58"><mml:math id="IM58" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE59"><mml:math id="IM59" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. As indicated in <xref rid="btac508-F1" ref-type="fig">Figure 1</xref>, upon receiving each triplet, <italic toggle="yes">D</italic> accomplishes two tasks: (i) measures the similarity between <inline-formula id="IE60"><mml:math id="IM60" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and dissimilarity between <inline-formula id="IE61"><mml:math id="IM61" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and (ii) performs MRC task similar to <italic toggle="yes">M<sub>Q</sub></italic> for the source sample <inline-formula id="IE62"><mml:math id="IM62" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p>
        <p>For the first task, we introduce a Siamese network (<xref rid="btac508-B7" ref-type="bibr">Bromley <italic toggle="yes">et al.</italic>, 1993</xref>) <italic toggle="yes">D<sub>e</sub></italic> with a single transformer encoder layer. <italic toggle="yes">D<sub>e</sub></italic> acts as a function that helps estimate the similarity and dissimilarity between the received pairs. Considering the success of the <italic toggle="yes">BERT</italic> models in many NLP tasks, for the Siamese network, we adopt the same architecture as any encoder layer in the <italic toggle="yes">BERT<sub>Base</sub></italic> model, which has 12 attention heads, 768 embedding dimensions, 3072 FFN inner hidden size with 10% dropout rate and ‘GeLU’ activation function. We encode the input pairs <inline-formula id="IE63"><mml:math id="IM63" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE64"><mml:math id="IM64" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, using the same encoder network <italic toggle="yes">D<sub>e</sub></italic>. Considering the role of the special token <inline-formula id="IE65"><mml:math id="IM65" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> as explained in Section 3.2.1, to let <inline-formula id="IE66"><mml:math id="IM66" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> differentiate whether the pairs are from the same domain or not, we extract the <inline-formula id="IE67"><mml:math id="IM67" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> token representations from <italic toggle="yes">D<sub>e</sub></italic> for <inline-formula id="IE68"><mml:math id="IM68" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE69"><mml:math id="IM69" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>s</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>. We then use these <inline-formula id="IE70"><mml:math id="IM70" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> token representations to calculate the domain similarity and dissimilarity via triplet loss function (<xref rid="btac508-B58" ref-type="bibr">Weinberger <italic toggle="yes">et al.</italic>, 2005</xref>) and use it as the learning objective of the discriminator <inline-formula id="IE71"><mml:math id="IM71" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> as shown in <xref rid="E4" ref-type="disp-formula">Equation (4)</xref>.
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="italic">triplet</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="italic">max</mml:mi><mml:mo>{</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>k</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo>α</mml:mo><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>Here, <inline-formula id="IE72"><mml:math id="IM72" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>k</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> are, respectively, the <inline-formula id="IE73"><mml:math id="IM73" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> token representations of <italic toggle="yes">i</italic>th and <italic toggle="yes">j</italic>th samples from the source domain and the <italic toggle="yes">k</italic>th sample from the target domain where <inline-formula id="IE74"><mml:math id="IM74" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="italic">CosSim</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the cosine distance where <inline-formula id="IE75"><mml:math id="IM75" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">CosSim</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the cosine similarity, <italic toggle="yes">α</italic> is the non-negative margin representing the minimum difference between <inline-formula id="IE76"><mml:math id="IM76" display="inline" overflow="scroll"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE77"><mml:math id="IM77" display="inline" overflow="scroll"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>k</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> that is required for the triplet loss to be zero. To optimize <inline-formula id="IE78"><mml:math id="IM78" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="italic">triplet</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> aims at minimizing <inline-formula id="IE79"><mml:math id="IM79" display="inline" overflow="scroll"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> between the samples from the source domain and maximizing <inline-formula id="IE80"><mml:math id="IM80" display="inline" overflow="scroll"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> between the samples from the source and target domains. Using triplet loss, our discriminator efficiently employs both similar and dissimilar information extracted by the feature extractor component of the model.</p>
        <p>While using triplet loss in the adversarial setting, we also consider that the triplet loss might make representations from the source-domain dissimilar. Therefore, as an additional experiment, we try optimizing the discriminator by minimizing a distance-based loss, which is equivalent to just minimizing the distance <inline-formula id="IE81"><mml:math id="IM81" display="inline" overflow="scroll"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> between the source- and the target-domain sample representations in the adversarial setting. We demonstrate the comparison between these two approaches in Section 4.5.1.</p>
        <p>Adversarial learning for domain adaptation is known to be unstable (<xref rid="btac508-B47" ref-type="bibr">Rios <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac508-B60" ref-type="bibr">Wulfmeier <italic toggle="yes">et al.</italic>, 2017</xref>). To stabilize the training process, we use the concept of AC-GAN (<xref rid="btac508-B40" ref-type="bibr">Odena <italic toggle="yes">et al.</italic>, 2017</xref>). AC-GAN uses an auxiliary task layer on top of the discriminator and appears to stabilize the adversarial learning procedure and improve the performance (<xref rid="btac508-B40" ref-type="bibr">Odena <italic toggle="yes">et al.</italic>, 2017</xref>).</p>
        <p>Following this concept, for the second task of <inline-formula id="IE82"><mml:math id="IM82" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, we introduce an MRC-module <italic toggle="yes">D<sub>q</sub></italic> similar to <italic toggle="yes">M<sub>Q</sub></italic> on top of <italic toggle="yes">D<sub>e</sub></italic> as an auxiliary task layer. <italic toggle="yes">D<sub>q</sub></italic> enforces that the discriminator does not lose task-specific information while learning to encode domain-variant features. Later in Sections 4.4 and 4.5.2, we demonstrate the effectiveness of the auxiliary layer by performing an ablation study and a stability analysis. The input of <italic toggle="yes">D<sub>q</sub></italic> is the output of <italic toggle="yes">D<sub>e</sub></italic> for <inline-formula id="IE83"><mml:math id="IM83" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> and the output is the probability distributions for the start and end token positions of the answer span, similar to <inline-formula id="IE84"><mml:math id="IM84" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mi mathvariant="italic">start</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mi mathvariant="italic">end</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Thus, the loss function <inline-formula id="IE85"><mml:math id="IM85" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="italic">aux</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> for <italic toggle="yes">D<sub>q</sub></italic> is the same as <inline-formula id="IE86"><mml:math id="IM86" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. The final loss function <inline-formula id="IE87"><mml:math id="IM87" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for <inline-formula id="IE88"><mml:math id="IM88" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is shown in <xref rid="E5" ref-type="disp-formula">Equation (5)</xref>.
<disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="italic">triplet</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="italic">aux</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec>
        <label>3.2.4</label>
        <title>Cost function</title>
        <p>To eliminate domain shift by learning domain-invariant features, we integrate <inline-formula id="IE89"><mml:math id="IM89" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mi>F</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE90"><mml:math id="IM90" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> into adversarial learning framework, where we update <italic toggle="yes">M<sub>F</sub></italic> and <italic toggle="yes">M<sub>Q</sub></italic> to maximize <inline-formula id="IE91"><mml:math id="IM91" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and minimize <inline-formula id="IE92"><mml:math id="IM92" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> while updating <italic toggle="yes">D</italic> to minimize <inline-formula id="IE93"><mml:math id="IM93" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Thus, the cost function <inline-formula id="IE94"><mml:math id="IM94" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">total</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> of the BioADAPT-MRC framework consists of <inline-formula id="IE95"><mml:math id="IM95" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE96"><mml:math id="IM96" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as shown in <xref rid="E6" ref-type="disp-formula">Equation (6)</xref> and is optimized end-to-end:
<disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">total</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo>λ</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>Here, <italic toggle="yes">λ</italic> is a regularization parameter to balance <inline-formula id="IE97"><mml:math id="IM97" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE98"><mml:math id="IM98" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Unlike the original adversarial learning framework proposed in GAN, where the adversaries are updated alternately (<xref rid="btac508-B20" ref-type="bibr">Goodfellow <italic toggle="yes">et al.</italic>, 2014</xref>), we perform joint optimization for all three components of our model using the gradient-reversal layer (<xref rid="btac508-B17" ref-type="bibr">Ganin and Lempitsky, 2015</xref>), as suggested by <xref rid="btac508-B9" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> (2018a</xref>).</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Results and discussion</title>
    <p>We perform an extensive study to evaluate the proposed framework and compare with the SOTA biomedical-MRC methods on a collection of publicly available and widely used benchmark biomedical-MRC datasets.</p>
    <sec>
      <title>4.1 Dataset</title>
      <p>To demonstrate the effectiveness of our framework, we evaluate BioADAPT-MRC and compare it with the SOTA methods on three biomedical-MRC datasets from the BioASQ annual challenge (<xref rid="btac508-B52" ref-type="bibr">Tsatsaronis <italic toggle="yes">et al.</italic>, 2015</xref>). The BioASQ competition has been organized since 2013 and consists of two large-scale biomedical NLP tasks, one of which is question answering (task B). Among four types of questions in task B, the factoid questions resemble the extractive biomedical-MRC task. As such, we utilize only the factoid MRC data from the BioASQ challenges held in 2019 (BioASQ-7b), 2020 (BioASQ-8b) and 2021 (BioASQ-9b) as the target-domain datasets to verify our model. These datasets were created from the search engine for biomedical literature, PubMed, with the help of domain-experts. Note that, for training, our framework requires only unlabeled contexts in the target domain. As such, we only consider the contexts in the BioASQ-7b, 8b and 9b training sets and disregard the question–answer pairs. The details on the availability of the training data and the pre-processing steps are provided in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S1</xref>. At test time, we use the golden enriched test sets—BioASQ-7b, 8b and 9b—from the BioASQ challenges.</p>
      <p>Similar to the previous studies (<xref rid="btac508-B26" ref-type="bibr">Jeong <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac508-B62" ref-type="bibr">Yoon <italic toggle="yes">et al.</italic>, 2020</xref>), as the source-domain dataset, we use SQuAD-1.1 (<xref rid="btac508-B46" ref-type="bibr">Rajpurkar <italic toggle="yes">et al.</italic>, 2016</xref>), which was developed from Wikipedia articles by crowd-workers. <xref rid="btac508-T1" ref-type="table">Table 1</xref> shows the basic statistical information of all datasets used in the experiments. As shown, the number of training data samples in the source domain is noticeably higher than that of the target domain. The details on experimental setup and training configurations are provided in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S2</xref>.</p>
      <table-wrap position="float" id="btac508-T1">
        <label>Table 1.</label>
        <caption>
          <p>Statistics of the datasets used in the experiments</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Dataset</th>
              <th rowspan="1" colspan="1">Training set</th>
              <th rowspan="1" colspan="1">Training set</th>
              <th rowspan="1" colspan="1">Target to source</th>
              <th rowspan="1" colspan="1">Test set</th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">name</th>
              <th rowspan="1" colspan="1">(raw)</th>
              <th rowspan="1" colspan="1">(pre-processed)</th>
              <th rowspan="1" colspan="1">ratio in training set</th>
              <th rowspan="1" colspan="1"/>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SQuAD-1.1</td>
              <td rowspan="1" colspan="1">87 599</td>
              <td rowspan="1" colspan="1">87 599</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioASQ-7b</td>
              <td rowspan="1" colspan="1">779</td>
              <td rowspan="1" colspan="1">5537</td>
              <td rowspan="1" colspan="1">∼1:16</td>
              <td rowspan="1" colspan="1">162</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioASQ-8b</td>
              <td rowspan="1" colspan="1">941</td>
              <td rowspan="1" colspan="1">10 147</td>
              <td rowspan="1" colspan="1">∼1:9</td>
              <td rowspan="1" colspan="1">151</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioASQ-9b</td>
              <td rowspan="1" colspan="1">1092</td>
              <td rowspan="1" colspan="1">13 178</td>
              <td rowspan="1" colspan="1">∼1:7</td>
              <td rowspan="1" colspan="1">163</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>4.2 Metrics</title>
      <p>For evaluation, we use three metrics used in the MRC task in the official BioASQ challenge: strict accuracy (SAcc), lenient accuracy (LAcc) and mean reciprocal rank (MRR). The BioASQ challenge requires the participant systems to predict the five best-matched answer spans extracted from the context(s) in a decreasing order based on confidence score. In the test set, for each question, the biomedical experts in the BioASQ team provided one golden answer extracted from the context. Both golden answers and predicted answer spans are used to calculate the SAcc, LAcc and MRR scores, as shown in <xref rid="E7" ref-type="disp-formula">Equation (7)</xref>. SAcc shows the models’ capability to find exact answer location, LAcc determines the models’ understanding of predicted answers’ range and MRR reflects the quality of the predicted answer spans (<xref rid="btac508-B52" ref-type="bibr">Tsatsaronis <italic toggle="yes">et al.</italic>, 2015</xref>):
<disp-formula id="E7"><label>(7)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">SAcc</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">test</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>;</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="italic">LAcc</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mn>5</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">test</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>;</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="italic">MRR</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">test</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">test</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>Here, <italic toggle="yes">c</italic><sub>1</sub> is the number of questions correctly answered by the predicted answer span with the highest confidence score, <italic toggle="yes">c</italic><sub>5</sub> is the number of questions answered correctly by any of the five predicted answer spans, <italic toggle="yes">n</italic><sub>test</sub> is the number of questions in the test set and <italic toggle="yes">r</italic>(<italic toggle="yes">i</italic>) is the rank of the golden answer among all five predicted answer spans for the <italic toggle="yes">i</italic>th question. If the golden answer does not belong to the five predicted answer spans, we consider <inline-formula id="IE99"><mml:math id="IM99" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. We implement these metrics by leveraging the publicly available tools provided by the official BioASQ challenge at <ext-link xlink:href="https://github.com/BioASQ/Evaluation-Measures" ext-link-type="uri">https://github.com/BioASQ/Evaluation-Measures</ext-link>.</p>
    </sec>
    <sec>
      <title>4.3 Method comparison</title>
      <p>We compare the test-time performance of BioADAPT-MRC on BioASQ-7b and 8b with six best-performing models selected based on related published articles: Google (<xref rid="btac508-B25" ref-type="bibr">Hosein <italic toggle="yes">et al.</italic>, 2019</xref>), BioBERT (<xref rid="btac508-B62" ref-type="bibr">Yoon <italic toggle="yes">et al.</italic>, 2020</xref>), UNCC (<xref rid="btac508-B50" ref-type="bibr">Telukuntla <italic toggle="yes">et al.</italic>, 2019</xref>), Umass (<xref rid="btac508-B31" ref-type="bibr">Kommaraju <italic toggle="yes">et al.</italic>, 2020</xref>), KU-DMIS-2020 (<xref rid="btac508-B26" ref-type="bibr">Jeong <italic toggle="yes">et al.</italic>, 2020</xref>) and BioQAExternalFeatures (<xref rid="btac508-B61" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>). For BioASQ-9b, we pick the best-performing system Ir_sys2 from the BioASQ-9b leaderboard (available at: <ext-link xlink:href="http://participants-area.bioasq.org/results/9b/phaseB/" ext-link-type="uri">http://participants-area.bioasq.org/results/9b/phaseB/</ext-link>).</p>
      <p>We also consider a hypothetical system that we would get for BioASQ-9b if that system would achieve the highest SAcc, LAcc and MRR scores on the leaderboard in all five batches of this test set. Note that, in reality, no individual system in the competition achieved the highest scores for all three metrics in all the batches (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S3</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S11</xref> for details).</p>
      <p>In addition to these models, we also compare the performance of BioADAPT-MRC with AdaMRC (<xref rid="btac508-B56" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019</xref>), a SOTA domain adaptation method for the MRC task. We provide brief descriptions of these aforementioned models in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S3</xref>.</p>
    </sec>
    <sec>
      <title>4.4 Experimental results</title>
      <p><xref rid="btac508-T2" ref-type="table">Table 2</xref> shows the comparison of BioADAPT-MRC with the SOTA biomedical-MRC methods on BioASQ-7b, 8b and 9b. As shown, BioADAPT-MRC improves on both LAcc and MRR when tested on all three BioASQ test sets and achieves the best performance. We also notice that while our model achieves the highest SAcc score for BioASQ-9b, it achieves the second-best SAcc scores for BioASQ-7b and 8b. The higher SAcc and LAcc scores imply that our model is able to correctly extract complete answers from the given contexts more frequently than the previous methods. The higher MRR scores, on the other hand, reflect our model’s ability to extract complete answers with higher probability than the previous methods. In contrast to the previous works, our method uses no label information (question–answer pairs) during the training process and has still been able to achieve good performance, implying the effectiveness of our proposed framework.</p>
      <table-wrap position="float" id="btac508-T2">
        <label>Table 2.</label>
        <caption>
          <p>Performance of BioADAPT-MRC compared with the best scores on BioASQ-7b, BioASQ-8b and BioASQ-9b test sets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Model</th>
              <th colspan="3" rowspan="1">BioASQ-7b<hr/></th>
              <th colspan="3" rowspan="1">BioASQ-8b<hr/></th>
              <th colspan="3" rowspan="1">BioASQ-9b<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">SAcc</th>
              <th rowspan="1" colspan="1">LAcc</th>
              <th rowspan="1" colspan="1">MRR</th>
              <th rowspan="1" colspan="1">SAcc</th>
              <th rowspan="1" colspan="1">LAcc</th>
              <th rowspan="1" colspan="1">MRR</th>
              <th rowspan="1" colspan="1">SAcc</th>
              <th rowspan="1" colspan="1">LAcc</th>
              <th rowspan="1" colspan="1">MRR</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Google (<xref rid="btac508-B25" ref-type="bibr">Hosein <italic toggle="yes">et al.</italic>, 2019</xref>)</td>
              <td rowspan="1" colspan="1">0.4201</td>
              <td rowspan="1" colspan="1">0.5822</td>
              <td rowspan="1" colspan="1">0.4798</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioBERT (<xref rid="btac508-B62" ref-type="bibr">Yoon <italic toggle="yes">et al.</italic>, 2020</xref>)</td>
              <td rowspan="1" colspan="1">0.4367</td>
              <td rowspan="1" colspan="1">0.6274</td>
              <td rowspan="1" colspan="1">0.5115</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">UNCC (<xref rid="btac508-B50" ref-type="bibr">Telukuntla <italic toggle="yes">et al.</italic>, 2019</xref>)</td>
              <td rowspan="1" colspan="1">0.3554</td>
              <td rowspan="1" colspan="1">0.4922</td>
              <td rowspan="1" colspan="1">0.4063</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Umass (<xref rid="btac508-B31" ref-type="bibr">Kommaraju <italic toggle="yes">et al.</italic>, 2020</xref>)</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">0.3133</td>
              <td rowspan="1" colspan="1">0.4798</td>
              <td rowspan="1" colspan="1">0.3780</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">KU-DMIS-2020 (<xref rid="btac508-B26" ref-type="bibr">Jeong <italic toggle="yes">et al.</italic>, 2020</xref>)</td>
              <td rowspan="1" colspan="1">
                <bold>0.4510</bold>
              </td>
              <td rowspan="1" colspan="1">0.6245</td>
              <td rowspan="1" colspan="1">0.5163</td>
              <td rowspan="1" colspan="1">0.3819</td>
              <td rowspan="1" colspan="1">0.5719</td>
              <td rowspan="1" colspan="1">0.4593</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioQAExternalFeatures (<xref rid="btac508-B61" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>)*</td>
              <td rowspan="1" colspan="1">0.4444</td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.6419</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.5165</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.3937</bold>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.6098</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.4688</italic>
              </td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioASQ-9b Challenge—Best system (Ir_sys2)</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">0.5031</td>
              <td rowspan="1" colspan="1">0.6626</td>
              <td rowspan="1" colspan="1">0.5667</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioASQ-9b Challenge—Hypothetical system</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">
                <bold>0.5399</bold>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.7300</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.6017</italic>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AdaMRC (<xref rid="btac508-B56" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019</xref>)</td>
              <td rowspan="1" colspan="1">0.4321</td>
              <td rowspan="1" colspan="1">0.6235</td>
              <td rowspan="1" colspan="1">0.5136</td>
              <td rowspan="1" colspan="1">0.3510</td>
              <td rowspan="1" colspan="1">0.5828</td>
              <td rowspan="1" colspan="1">0.4455</td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.5337</italic>
              </td>
              <td rowspan="1" colspan="1">0.7117</td>
              <td rowspan="1" colspan="1">0.6001</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioADAPT-MRC</td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.4506</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.6420</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.5289</bold>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.3841</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.6225</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.4749</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.5399</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.7423</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.6187</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic toggle="yes">Note</italic>: The best and the second-best scores are respectively highlighted in bold and italic.</p>
          </fn>
          <fn id="tblfn2">
            <p>‘—’ indicates that the corresponding source did not report the scores. *denotes previously best-performing method for BioASQ-7B and BioASQ-8B.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>As explained in Section 3, in the framework, we propose a domain-similarity discriminator with an auxiliary task layer that aims at promoting the generation of domain-invariant features in the feature extractor and thus improving the performance of the model. To show the effectiveness of the discriminator and the auxiliary task layer, we perform an ablation study and report the experimental results in <xref rid="btac508-T3" ref-type="table">Table 3</xref>. For a fair comparison, we perform all experiments under the same hyper-parameter settings. The baseline model shown in <xref rid="btac508-T3" ref-type="table">Table 3</xref> consists of only the feature extractor and the MRC-module and was trained on the labeled source-domain dataset, SQuAD. For the remaining two models, we use the labeled SQuAD and the unlabeled BioASQ training datasets simultaneously. The addition of the discriminator enables the feature extractor in the baseline model to use the unlabeled BioASQ training datasets for generating domain-invariant feature representations. This is achieved by using the dissimilarity measurements between the feature representations of the SQuAD and BioASQ training data. As shown, after adding only the discriminator without the auxiliary task layer, the performance of the model improves from the baseline, suggesting the influence of the discriminator. We explain this influence on the feature extractor more elaborately later in Section 4.5.6. For the final experiment in the ablation study (<xref rid="btac508-T3" ref-type="table">Table 3</xref>), we use our whole model consisting of the domain-similarity discriminator with the auxiliary task layer and notice an even further performance improvement. The auxiliary task layer, in this study, constrains the changes in the task-relevant features in the domain-similarity discriminator during training. Thus, the improvement in model performance after incorporating the auxiliary task layer suggests that with the task layer, the domain-similarity discriminator can better promote the generation of domain-invariant features that are simultaneously discriminative from the viewpoint of the MRC task in the source domain. Moreover, as explained in Section 3.2.3, we further demonstrate the stabilizing capability of the auxiliary task layer in Section 4.5.2.</p>
      <table-wrap position="float" id="btac508-T3">
        <label>Table 3.</label>
        <caption>
          <p>Test scores for ablation experiments of BioADAPT-MRC</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Model</th>
              <th colspan="3" align="center" rowspan="1">BioASQ-7b<hr/></th>
              <th colspan="3" align="center" rowspan="1">BioASQ-8b<hr/></th>
              <th colspan="3" align="center" rowspan="1">BioASQ-9b<hr/></th>
            </tr>
            <tr>
              <th align="center" rowspan="1" colspan="1"/>
              <th align="center" rowspan="1" colspan="1">SAcc</th>
              <th align="center" rowspan="1" colspan="1">LAcc</th>
              <th align="center" rowspan="1" colspan="1">MRR</th>
              <th align="center" rowspan="1" colspan="1">SAcc</th>
              <th align="center" rowspan="1" colspan="1">LAcc</th>
              <th align="center" rowspan="1" colspan="1">MRR</th>
              <th align="center" rowspan="1" colspan="1">SAcc</th>
              <th align="center" rowspan="1" colspan="1">LAcc</th>
              <th align="center" rowspan="1" colspan="1">MRR</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Baseline</td>
              <td rowspan="1" colspan="1">0.4136</td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.6296</italic>
              </td>
              <td rowspan="1" colspan="1">0.5056</td>
              <td rowspan="1" colspan="1">0.3642</td>
              <td rowspan="1" colspan="1">0.5960</td>
              <td rowspan="1" colspan="1">0.4602</td>
              <td rowspan="1" colspan="1">0.5092</td>
              <td rowspan="1" colspan="1">0.7362</td>
              <td rowspan="1" colspan="1">0.6010</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioADAPT-MRC (no auxiliary layer)</td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.4259</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.6296</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.5146</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.3775</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.6026</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.4679</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.5276</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.7485</bold>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.6142</italic>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BioADAPT-MRC</td>
              <td rowspan="1" colspan="1">
                <bold>0.4506</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.6420</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.5289</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.3841</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.6225</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.4749</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.5399</bold>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">0.7423</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.6187</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <p><italic toggle="yes">Note</italic>: The best and the second-best scores are respectively highlighted in bold and italic.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>4.5 Analysis</title>
      <p>In this section, we analyze different components of the proposed framework. We also study the domain adaptation capability and the strengths and weaknesses of the BioADAPT-MRC model.</p>
      <sec>
        <label>4.5.1</label>
        <title>Triplet versus distance-based loss</title>
        <p>BioADPT-MRC uses triplet loss to optimize the discriminator. As explained in Section 3.2.3, we also consider using distance-based loss in place of triplet loss.</p>
        <p><xref rid="btac508-T4" ref-type="table">Table 4</xref> shows the results of the contrastive experiments of loss functions—triplet loss and distance-based loss. As shown in <xref rid="btac508-T4" ref-type="table">Table 4</xref>, the model with triplet loss outperforms the one with the distance-based loss with higher mean SAcc, LAcc, MRR and lower standard deviation.</p>
        <table-wrap position="float" id="btac508-T4">
          <label>Table 4.</label>
          <caption>
            <p>Average test scores with standard deviations (across three different seeds) for the contrastive experiments of discriminator loss functions—triplet loss and distance-based loss</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Discriminator loss</th>
                <th colspan="3" rowspan="1">BioASQ-9b<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1">SAcc</th>
                <th rowspan="1" colspan="1">LAcc</th>
                <th rowspan="1" colspan="1">MRR</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">Distance-based</td>
                <td rowspan="1" colspan="1">0.5256 ± 0.0202</td>
                <td rowspan="1" colspan="1">0.7219 ± 0.0104</td>
                <td rowspan="1" colspan="1">0.6038 ± 0.0105</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Triplet</td>
                <td rowspan="1" colspan="1">
                  <bold>0.5358 ± 0.0029</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.7321 ± 0.0077</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.6140 ± 0.0035</bold>
                </td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn4">
              <p><italic toggle="yes">Note</italic>: The best scores are highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>To further analyze this performance gap, we examine the trend of distance between source-domain training sample pairs and between source- and target-domain training sample pairs per epoch across 50 training epochs (<xref rid="btac508-F2" ref-type="fig">Fig. 2</xref>).</p>
        <fig position="float" id="btac508-F2">
          <label>Fig. 2.</label>
          <caption>
            <p>Per-epoch cosine distance between source-domain training sample pairs and source- and target-domain training sample pairs across 50 epochs</p>
          </caption>
          <graphic xlink:href="btac508f2" position="float"/>
        </fig>
        <p>Note that both experiments in <xref rid="btac508-F2" ref-type="fig">Figure 2</xref> are performed under the same seed. As shown in <xref rid="btac508-F2" ref-type="fig">Figure 2</xref>, when we use distance-based loss, the cosine distance between either source-domain training sample pairs or source- and target-domain training sample pairs tends to be higher than when we use the triplet loss. It may happen because in the adversarial framework, while distance-based loss focuses only on minimizing the distance between the source- and target-domain training samples without considering the distance between the source samples, triplet loss focuses on balancing both (<xref rid="btac508-B8" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac508-B57" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2017</xref>). As a result, triplet loss can minimize the domain shift to a greater extent than the distance-based loss and thus enable our framework to achieve higher performance.</p>
      </sec>
      <sec>
        <label>4.5.2</label>
        <title>Stability analysis</title>
        <p>We examine the stability of BioADAPT-MRC and perform an error analysis of its performance by repeating the experiments for three different random seeds (10, 42 and 2018). <xref rid="btac508-T5" ref-type="table">Table 5</xref> shows the test scores averaged across three seeds with standard deviations for BioASQ-7b, 8b and 9b. We also report the average scores with standard deviations for our baseline, the BioADAPT-MRC model with no auxiliary layer, and a SOTA method AdaMRC to compare model stability. As shown in <xref rid="btac508-T5" ref-type="table">Table 5</xref>, BioADAPT-MRC outperforms the other models with lower standard deviations, indicating higher stability of our framework. Moreover, the scores from the BioADAPT-MRC models with and without the auxiliary layer indicate that the auxiliary task layer helps increase both performance and overall model stability.</p>
        <table-wrap position="float" id="btac508-T5">
          <label>Table 5.</label>
          <caption>
            <p>Average test scores with standard deviations across experiments with three random seeds (10, 42 and 2018) for initialization, to measure and compare the stability of BioADAPT-MRC</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Model</th>
                <th colspan="3" rowspan="1">BioASQ-7b<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1">SAcc</th>
                <th rowspan="1" colspan="1">LAcc</th>
                <th rowspan="1" colspan="1">MRR</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">AdaMRC</td>
                <td rowspan="1" colspan="1">
                  <italic toggle="yes">0.4300 ± 0.0029</italic>
                </td>
                <td rowspan="1" colspan="1">0.6152 ± 0.0116</td>
                <td rowspan="1" colspan="1">
                  <italic toggle="yes">0.5083 ± 0.0076</italic>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Baseline</td>
                <td rowspan="1" colspan="1">0.4156 ± 0.0127</td>
                <td rowspan="1" colspan="1">0.6173 ± 0.0101</td>
                <td rowspan="1" colspan="1">0.5038 ± 0.0033</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">BioADAPT-MRC (no auxiliary layer)</td>
                <td rowspan="1" colspan="1">0.4177 ± 0.0058</td>
                <td rowspan="1" colspan="1">
                  <italic toggle="yes">0.6193 ± 0.0105</italic>
                </td>
                <td rowspan="1" colspan="1">0.5038 ± 0.0076</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">BioADAPT-MRC</td>
                <td rowspan="1" colspan="1">
                  <bold>0.4465 ± 0.0029</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.6379 ± 0.0029</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.5237 ± 0.0037</bold>
                </td>
              </tr>
              <tr>
                <td colspan="4" rowspan="1">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Model</td>
                <td colspan="3" rowspan="1">BioASQ-8b</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td colspan="3" rowspan="1">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">SAcc</td>
                <td rowspan="1" colspan="1">LAcc</td>
                <td rowspan="1" colspan="1">MRR</td>
              </tr>
              <tr>
                <td colspan="4" rowspan="1">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">AdaMRC</td>
                <td rowspan="1" colspan="1">0.3422 ± 0.0083</td>
                <td rowspan="1" colspan="1">0.5960 ± 0.0143</td>
                <td rowspan="1" colspan="1">0.4425 ± 0.0031</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Baseline</td>
                <td rowspan="1" colspan="1">0.3554 ± 0.0125</td>
                <td rowspan="1" colspan="1">0.5960 ± 0.0162</td>
                <td rowspan="1" colspan="1">0.4547 ± 0.0152</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">BioADAPT-MRC (no auxiliary layer)</td>
                <td rowspan="1" colspan="1">
                  <italic toggle="yes">0.3664 ± 0.0113</italic>
                </td>
                <td rowspan="1" colspan="1">
                  <italic toggle="yes">0.5982 ± 0.0031</italic>
                </td>
                <td rowspan="1" colspan="1">
                  <italic toggle="yes">0.4618 ± 0.0080</italic>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">BioADAPT-MRC</td>
                <td rowspan="1" colspan="1">
                  <bold>0.3797 ± 0.0031</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.6137 ± 0.0083</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.4750 ± 0.0024</bold>
                </td>
              </tr>
              <tr>
                <td colspan="4" rowspan="1">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Model</td>
                <td colspan="3" rowspan="1">BioASQ-9b</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td colspan="3" rowspan="1">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">SAcc</td>
                <td rowspan="1" colspan="1">LAcc</td>
                <td rowspan="1" colspan="1">MRR</td>
              </tr>
              <tr>
                <td colspan="4" rowspan="1">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">AdaMRC</td>
                <td rowspan="1" colspan="1">0.5276 ± 0.0050</td>
                <td rowspan="1" colspan="1">0.7239 ± 0.0100</td>
                <td rowspan="1" colspan="1">0.6068 ± 0.0062</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Baseline</td>
                <td rowspan="1" colspan="1">0.5174 ± 0.0058</td>
                <td rowspan="1" colspan="1">0.7198 ± 0.0126</td>
                <td rowspan="1" colspan="1">0.6018 ± 0.0011</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">BioADAPT-MRC (no auxiliary layer)</td>
                <td rowspan="1" colspan="1">
                  <italic toggle="yes">0.5337 ± 0.0050</italic>
                </td>
                <td rowspan="1" colspan="1">
                  <italic toggle="yes">0.7280 ± 0.0153</italic>
                </td>
                <td rowspan="1" colspan="1">
                  <italic toggle="yes">0.6127 ± 0.0012</italic>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">BioADAPT-MRC</td>
                <td rowspan="1" colspan="1">
                  <bold>0.5358 ± 0.0029</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.7321 ± 0.0077</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.6140 ± 0.0035</bold>
                </td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn5">
              <p><italic toggle="yes">Note</italic>: The best and the second-best scores are respectively highlighted in bold and italic.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <label>4.5.3</label>
        <title>Masked versus synthetic questions</title>
        <p>Recall that, BioADAPT-MRC uses a special token <inline-formula id="IE100"><mml:math id="IM100" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">MASK</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> in place of the question tokens <italic toggle="yes">Q</italic> for the unlabeled target-domain training samples. The <inline-formula id="IE101"><mml:math id="IM101" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">MASK</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> tokens are used to inform the encoder model that the question tokens are missing and maintain consistency in the structure of the tokenized samples. Another approach to address the issue of missing questions in the target-domain training samples is to use synthetic questions (<xref rid="btac508-B56" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019</xref>). In <xref rid="btac508-T6" ref-type="table">Table 6</xref>, we present the results of the contrastive experiments of these two approaches—masked and synthetic questions. Inspired by the success of the AdaMRC question-generator in various target domains, such as news, Wikipedia and web search log, we use it to generate the synthetic questions.</p>
        <table-wrap position="float" id="btac508-T6">
          <label>Table 6.</label>
          <caption>
            <p>Average test scores with standard deviations (across three different seeds) for experiments using synthetic questions and masked questions in the target-domain training dataset</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Questions</th>
                <th colspan="3" rowspan="1">BioASQ-9b<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1">SAcc</th>
                <th rowspan="1" colspan="1">LAcc</th>
                <th rowspan="1" colspan="1">MRR</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">Synthetic</td>
                <td rowspan="1" colspan="1">
                  <italic toggle="yes">0.5337 ± 0.0087</italic>
                </td>
                <td rowspan="1" colspan="1">
                  <italic toggle="yes">0.7198 ± 0.0126</italic>
                </td>
                <td rowspan="1" colspan="1">
                  <italic toggle="yes">0.6069 ± 0.0059</italic>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Masked</td>
                <td rowspan="1" colspan="1">
                  <bold>0.5358 ± 0.0029</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.7321 ± 0.0077</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.6140 ± 0.0035</bold>
                </td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn6">
              <p><italic toggle="yes">Note</italic>: The best and the second-best scores are respectively highlighted in bold and italic.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p><xref rid="btac508-T6" ref-type="table">Table 6</xref> shows the average test scores for BioASQ-9b with standard deviations across three seeds. We find that although the synthetic questions can noticeably improve performance over the baseline (see results for ‘Baseline’ in <xref rid="btac508-T5" ref-type="table">Table 5</xref>), BioADAPT-MRC with synthetic questions is unable to achieve better performance than with masked questions. It may happen because the biomedical domain differs from other domains, such as news or Wikipedia, in many linguistic dimensions, such as syntax, lexicon and semantics (<xref rid="btac508-B34" ref-type="bibr">Lee <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac508-B54" ref-type="bibr">Verspoor <italic toggle="yes">et al.</italic>, 2009</xref>). As a result, while the question-generator can generate meaningful questions for domains, such as web, news and movie reviews (<xref rid="btac508-B56" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019</xref>), it mostly generates incoherent questions for the biomedical domain (as shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4</xref>), which can eventually hurt the performance of the model. Moreover, synthetic-question generation also requires additional computational time—generating questions from around 10 000 contexts using a trained question-generator took ∼3 h with our computational resources (see configurations in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S2</xref>). Given the findings, we think that generating synthetic questions for the biomedical domain requires more attention and consider it as a future study.</p>
      </sec>
      <sec>
        <label>4.5.4</label>
        <title>Semi-supervised setting</title>
        <p>As an additional experiment, we evaluate the BioADAPT-MRC framework under a semi-supervised setting, where we combine labeled and unlabeled target-domain training data. We perform four experiments where the ratios of labeled target-domain training samples are 0%, 10%, 50% and 80% of the total target-domain training data. Note that we choose the labeled target-domain data by random sampling. <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S5</xref> shows the test scores on BioASQ-9b when trained with varying ratios of labeled target-domain data. As shown, with increased ratio of labeled samples in the target-domain training data, the performance scores also increase, which is expected. These results suggest that our proposed framework is also effective in a semi-supervised setting.</p>
        <p>Note that although multiple labeled datasets in various sub-domains of biomedical-MRC (such as scientific literature and clinical notes) have been made available in the past few years (<xref rid="btac508-B41" ref-type="bibr">Pampari <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac508-B52" ref-type="bibr">Tsatsaronis <italic toggle="yes">et al.</italic>, 2015</xref>), there is still a severe scarcity of labeled data in some other sub-domains that are linguistically different (e.g. consumer health biomedical-MRC) (<xref rid="btac508-B27" ref-type="bibr">Jin <italic toggle="yes">et al.</italic>, 2023</xref>; <xref rid="btac508-B38" ref-type="bibr">Nguyen, 2019</xref>).</p>
      </sec>
      <sec>
        <label>4.5.5</label>
        <title>Results on emrQA</title>
        <p>We further validate our framework on another type of biomedical-MRC dataset, emrQA (<xref rid="btac508-B41" ref-type="bibr">Pampari <italic toggle="yes">et al.</italic>, 2018</xref>), built using unstructured textual electronic health records (EHRs) with questions reflecting the inquiries made by clinicians about patients’ EHRs. The dataset contains five subsets, three of which are extractive MRC datasets—heart disease risk, relations and medications. For our experiments, we use the heart disease risk dataset as the target-domain dataset. We randomly sample 10% of the dataset as the test set. To measure the performance, we use the widely used metrics for the extractive MRC task: Exact Match (EM) and <italic toggle="yes">F</italic>1-score (<xref rid="btac508-B3" ref-type="bibr">Baradaran <italic toggle="yes">et al.</italic>, 2020</xref>). We compare the test scores with our baseline and the AdaMRC model. <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S6</xref> shows that BioADAPT-MRC improves the performance scores over baseline (9.67% in EM and 10.86% in <italic toggle="yes">F</italic>1) and AdaMRC (2.08% in EM and 2.16% in <italic toggle="yes">F</italic>1). This experiment validates that BioADAPT-MRC can be applied to different types of biomedical-MRC datasets.</p>
        <p>We want to emphasize the fact that researchers have identified the unstructured clinical notes as inherently noisy and long with long-term textual dependencies (<xref rid="btac508-B12" ref-type="bibr">Cohen <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btac508-B35" ref-type="bibr">Mahbub <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac508-B41" ref-type="bibr">Pampari <italic toggle="yes">et al.</italic>, 2018</xref>). We suspect that these phenomena may lead to an overall low EM and <italic toggle="yes">F</italic>1 score (<xref rid="btac508-B28" ref-type="bibr">Joshi <italic toggle="yes">et al.</italic>, 2017</xref>). Hence, we think that achieving higher scores in an MRC task on EHRs requires additional and rigorous data pre-processing and leave it as a future work.</p>
      </sec>
      <sec>
        <label>4.5.6</label>
        <title>Domain adaptation</title>
        <p>We show the influence of the domain-similarity discriminator by plotting (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S7</xref>) all samples from the BioASQ-9b test set and a set of random samples from the SQuAD training set. We pick random samples from the SQuAD training set to match the number of samples in the BioASQ-9b test set. As explained in Section 3.2.1, we use the feature representation of the <inline-formula id="IE102"><mml:math id="IM102" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> token as an accumulated representation of the whole input sequence. Each feature representation of the <inline-formula id="IE103"><mml:math id="IM103" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> token has a dimension of 768. To reduce these dimensions into two for visualization, we use multidimensional scaling (MDS) (<xref rid="btac508-B32" ref-type="bibr">Kruskal, 1964</xref>). We use MDS because it reduces the dimensions by preserving the dissimilarities between two data points in the original high-dimensional space. Since we use cosine distance in the discriminator to measure the dissimilarity between two domains, as the dissimilarity measure in the MDS, we use the pairwise cosine distance. The feature representations of the <inline-formula id="IE104"><mml:math id="IM104" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> token on the left plot and the right plot in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S7</xref> are generated by the feature extractors from the baseline model and the BioADAPT-MRC model, respectively. For a fair comparison, the selection of random SQuAD training samples is the same for the baseline and BioADAPT-MRC models. As shown, the features generated by the baseline model create two separate clusters for SQuAD and BioASQ-9b. The features generated by the BioADAPT-MRC model, on the other hand, form two overlapping clusters implying the reduced dissimilarities between the source and target domains. Interestingly, we notice that the data points from the BioASQ are closer to its cluster than those from the SQuAD. It may be because, unlike SQuAD, the data in the BioASQ originate from one single domain, and thus the feature representations are more similar to one another.</p>
        <p>To further analyze the quality of the clusters before and after introducing the domain-similarity discriminator to the framework and thus to quantify the effect of domain adaptation, we perform DBSCAN clustering (<xref rid="btac508-B15" ref-type="bibr">Ester <italic toggle="yes">et al.</italic>, 1996</xref>). We perform clustering on the MDS components of the features for the <inline-formula id="IE105"><mml:math id="IM105" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">CLS</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> tokens for the samples in the BioASQ test sets and the random samples from the SQuAD training set. Considering the bias of random sampling, for each BioASQ test set, we select five sets of random samples from the SQuAD training set and report the mean accuracy and silhouette scores with standard deviation in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S9</xref> and <xref rid="btac508-F3" ref-type="fig">Figure 3</xref>. We use the DBSCAN clustering because it views clusters as high-density regions where the distance between the samples is measured by a distance metric, providing flexibility in shapes and numbers of clusters. We describe the selected hyperparameters for the DBSCAN algorithm implementation in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S8</xref>.</p>
        <fig position="float" id="btac508-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>Mean accuracy scores (left) and mean silhouette scores (right) with standard deviations for DBSCAN clustering on BioASQ test sets and SQuAD</p>
          </caption>
          <graphic xlink:href="btac508f3" position="float"/>
        </fig>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary Table S9</xref> and <xref rid="btac508-F3" ref-type="fig">Figure 3</xref> show that DBSCAN can identify two clusters with high accuracy when the features of the samples are extracted from the baseline model. The accuracy goes down when the features of the same samples are extracted from the BioADAPT-MRC model as they form a single cluster. Moreover, we analyze the silhouette scores to understand the separation distance between clusters. The range of silhouette score is <inline-formula id="IE106"><mml:math id="IM106" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. A score of one indicates that the clusters are highly dense and clearly distinguishable from each other whereas −1 refers to incorrect clustering. A score of zero or near zero indicates indistinguishable or overlapping clusters. As shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S9</xref> and <xref rid="btac508-F3" ref-type="fig">Figure 3</xref>, in this case, the high silhouette scores (closer to one) for the baseline model reflect that the feature representations of the samples from the same domain are very similar to its own cluster compared to the other one. On contrary, the low silhouette scores (closer to zero) for the BioADAPT-MRC model indicate that the feature representations of the samples from both domains are very similar to one another. These results show the effectiveness of the domain-similarity discriminator in the BioADAPT-MRC framework. Considering the variability of the predicted answers in an MRC task, we present a motivating example to demonstrate how the word importance may impact the answer predictions and thus the performance of the biomedical-MRC task (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S10</xref>). The example shows the effectiveness of BioADAPT-MRC over the baseline model for the given sample.</p>
      </sec>
      <sec>
        <label>4.5.7</label>
        <title>Error analysis</title>
        <p>We analyze the strengths and weaknesses of our approach by performing 2-fold error analysis. We focus on two aspects of the MRC dataset—types of questions and answers. Through this error analysis, we aim to answer the following questions: (i) what types of questions can be answered after domain adaptation that could not be answered before? (ii) What types of answers can be identified by the proposed approach after domain adaptation? (iii) What types of items does the model struggle with, even with the domain adaptation component?</p>
        <p>We use the SAcc score to perform the error analysis since the ultimate goal for any MRC system is to predict correct answer spans with the highest probability, reflected in the SAcc score. We categorize the test sets based on the following types of questions: <italic toggle="yes">which, what, how, where, when</italic> and <italic toggle="yes">name</italic> (an example question for <italic toggle="yes">name</italic> –‘Name a CFL2 mutation which is associated with nemaline myopathy?’). We find that the most prevalent question types in the test sets are <italic toggle="yes">what</italic> (43%) and <italic toggle="yes">which</italic> (44%) (embedded in <xref rid="btac508-F4" ref-type="fig">Fig. 4</xref>). We also find that after adding the domain adaptation module, the SAcc score increases by 52%, 20%, 17% and 4% for question types—<italic toggle="yes">when, name, what</italic> and <italic toggle="yes">which</italic>, respectively (<xref rid="btac508-F4" ref-type="fig">Fig. 4</xref>). It indicates that the domain adaptation module can help increase the model’s capability to answer these types of questions with higher probability. For question types <italic toggle="yes">how</italic> and <italic toggle="yes">where</italic>, we do not notice further improvement, even with the domain adaptation module.</p>
        <fig position="float" id="btac508-F4">
          <label>Fig. 4.</label>
          <caption>
            <p>Error analysis of BioADAPT-MRC, in comparison with the baseline model, depending on the types of questions in the BioASQ test sets</p>
          </caption>
          <graphic xlink:href="btac508f4" position="float"/>
        </fig>
        <p>To analyze the types of answers that can be identified after introducing the domain adaptation module, we categorize the test sets based on the named entities in the answers. We use NER algorithms from the widely used spaCy library (<xref rid="btac508-B24" ref-type="bibr">Honnibal and Montani, 2017</xref>).</p>
        <p><xref rid="btac508-F5" ref-type="fig">Figure 5</xref> shows that the answers in the test sets mainly consist of entities, such as <italic toggle="yes">GENE (23%), DISEASE (18%), CHEMICAL (16%), CELL/TISSUE (8%)</italic> and <italic toggle="yes">CARDINAL/DATE/PERCENT (7%)</italic>. As shown in <xref rid="btac508-F5" ref-type="fig">Figure 5</xref>, after adding the domain adaptation module, the model has been able to identify the <italic toggle="yes">CHEMICAL, CELL/TISSUE</italic> entities with the highest SAcc scores (improvement by 13% from the baseline). We also notice an improvement in the SAcc scores for <italic toggle="yes">GENE</italic> and <italic toggle="yes">DISEASE</italic> entities. However, we notice no improvement in the SAcc scores for <italic toggle="yes">CARDINAL/DATE/PERCENT, PERSON, DNA/RNA, ORGANISM, ORGAN and PROTEIN</italic> entities even after adding the domain adaptation module. Given the results, we would like to emphasize that in both of the aforementioned analyses, for some categories, we do not have a large enough sample set to draw a definite conclusion about the effectiveness of the domain adaptation module and hence requires further future investigation.</p>
        <fig position="float" id="btac508-F5">
          <label>Fig. 5.</label>
          <caption>
            <p>Error analysis of BioADAPT-MRC, in comparison with the baseline model, depending on the types of answers in the BioASQ test sets</p>
          </caption>
          <graphic xlink:href="btac508f5" position="float"/>
        </fig>
        <p>To provide further evidence about what the model learned, we present eight example question–answer pairs demonstrating the strengths and weaknesses of the BioADAPT-MRC model over the baseline model (<xref rid="btac508-F6" ref-type="fig">Fig. 6</xref>).</p>
        <fig position="float" id="btac508-F6">
          <label>Fig. 6.</label>
          <caption>
            <p>Example question–answer pairs from the test sets demonstrating the strengths and weaknesses of the BioADAPT-MRC model over the baseline model. The green and red colors show correctly and incorrectly predicted answers, respectively (A color version of this figure appears in the online version of this article.)</p>
          </caption>
          <graphic xlink:href="btac508f6" position="float"/>
        </fig>
        <p>We randomly select two examples from each of the following four categories: (i) mispredicted by baseline, correctly predicted by BioADAPT-MRC, (ii) incompletely predicted by baseline, correctly predicted by BioADAPT-MRC, (iii) correctly predicted by both baseline and BioADAPT-MRC and (iv) mispredicted by both baseline and BioADAPT-MRC. In Examples 1–8, the answer spans respectively contain GENE, CARDINAL, DISEASE, CELL, CHEMICAL, CARDINAL, ORGAN and DISEASE entities. As shown in Examples 1–6, BioADAPT-MRC model can identify the answer span better than the baseline model with higher probability score. However, the probability scores (i.e. the prediction capability) can be further improved. Moreover, Examples 7 and 8 provide additional motivation for future investigation of the reason behind the misprediction of the model.</p>
        <p>The results from the overall error analysis indicate that while the BioADAPT-MRC model does well under various scenarios, there is still significant room for potential improvement.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>5 Conclusion</title>
    <p>Biomedical-MRC is a crucial and emerging task in the biomedical domain pertaining to NLP. Biomedical-MRC aims at perceiving complex contexts from the biomedical domain and helping medical professionals to extract information from them. Most MRC methods rely on a high volume of human-annotated data for near or similar to human-level performance. However, acquiring a labeled MRC dataset in the biomedical domain is expensive in terms of domain expertise, time and effort, creating the need for transfer learning from a source domain to a target domain. Due to variance between two domains, directly transferring an MRC model to the target domain often negatively affects its performance. We propose a framework for biomedical-MRC, BioADAPT-MRC, addressing the issue of domain shift by using a domain adaptation technique in an adversarial learning setting. We use a labeled MRC dataset from a general-purpose domain (source domain) along with unlabeled contexts from the biomedical domain (target domain) as our training data. We introduce a domain-similarity discriminator, aiming to reduce the domain shift between the general-purpose domain and biomedical domain to help boost the performance of the biomedical-MRC model. We validate our proposed framework on three widely used benchmark datasets from the biomedical question answering and semantic indexing challenge, BioASQ. We comprehensively demonstrate that without any label information in the target domain during training, the BioADAPT-MRC framework can achieve SOTA performance on these datasets. We perform an extensive quantitative study on the domain adaptation capability using dimensionality reduction and clustering techniques and show that our framework can learn domain-invariant feature representations. Additionally, we extend our framework to a semi-supervised setting and demonstrate that our framework can be efficiently applied even with varying ratios of labeled data. We perform a 2-fold error analysis to investigate the shortcomings of our framework and provide motivation for further future investigation and improvement.</p>
    <p>We conclude that BioADAPT-MRC may be beneficial in healthcare systems as a tool to efficiently retrieve information from complex narratives and thus save valuable time and effort of the healthcare professionals.</p>
    <p>The following are some future research directions that can originate from this work: (i) developing a synthetic question–answer generator specializing in the biomedical domain. (ii) Focusing on rigorous data pre-processing for the MRC task on unstructured clinical notes. (iii) Performing further investigation on the cases where BioADAPT-MRC struggles to improve over the baseline model. (iv) Applying BioADPT-MRC to other NLP applications in the biomedical domain that suffer from labeled-data-scarcity issues. Such applications are biomedical NER, clinical negation detection, etc. (v) Analyzing the robustness of the domain-invariant feature representations learned by the BioADAPT-MRC model against meticulously crafted adversarial attack scenarios that may leverage syntactic and lexical knowledge-base from the dataset.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac508_Supplementary_Data</label>
      <media xlink:href="btac508_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We thank the anonymous reviewers for their insightful comments and suggestions.</p>
    <sec>
      <title>Author contributions</title>
      <p>Conception, design, implementations, analysis, data pre-processing, interpretation, result analysis and original draft: M.M. Review and editing: M.M., S.S., E.B. and G.D.P. Supervision: E.B. and G.D.P.</p>
    </sec>
    <sec>
      <title>Funding</title>
      <p>This work was supported by Department of Veterans Affairs, VHA Office of Mental Health and Suicide Prevention. This work has been authored by UT-Battelle, LLC under Contract No. [DE- AC05-00OR22725] with the US Department of Energy.</p>
      <p>This research used resources of the Knowledge Discovery Infrastructure at the Oak Ridge National Laboratory, which is supported by the Office of Science of the US Department of Energy under Contract No. [DE-AC05-00OR22725]; and the Department of Veterans Affairs Office of Information Technology Inter-Agency Agreement with the Department of Energy under IAA No. [VA118-16-M-1062].</p>
      <p><italic toggle="yes">Conflict of interest:</italic> The authors declare that there is no conflict of interest.</p>
    </sec>
    <sec>
      <title>Disclaimer</title>
      <p>The views and opinions expressed in this manuscript are those of the authors and do not necessarily represent those of the Department of Veterans Affairs, Department of Energy, or the United States Government. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p>
    </sec>
  </ack>
  <sec>
    <title> </title>
    <p><bold>Notice of Copyright:</bold> This manuscript has been authored by UT-Battelle, LLC, under contract DE-AC05-00OR22725 with the US Department of Energy (DOE). The US government retains and the publisher, by accepting the article for publication, acknowledges that the US government retains a nonexclusive, paid-up, irrevocable, worldwide license to publish or reproduce the published form of this manuscript, or allow others to do so, for US government purposes. DOE will provide public access to these results of federally sponsored research in accordance with the DOE Public Access Plan (<ext-link xlink:href="http://energy.gov/downloads/doe-public-access-plan" ext-link-type="uri">http://energy.gov/downloads/doe-public-access-plan</ext-link>).</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data Availability</title>
    <p>The data underlying this article are available in the BioASQ challenge website, at <ext-link xlink:href="http://participants-area.bioasq.org/datasets/" ext-link-type="uri">http://participants-area.bioasq.org/datasets/</ext-link>, and in the emrQA GitHub repository, at <ext-link xlink:href="https://github.com/panushri25/emrQA#download-dataset" ext-link-type="uri">https://github.com/panushri25/emrQA#download-dataset</ext-link>.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac508-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Agnikula Kshatriya</surname><given-names>B.S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Identification of asthma control factor in clinical notes using a hybrid deep learning model</article-title>. <source>BMC Med. Inform. Decis. Mak</source>., <volume>21</volume>, <fpage>1</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">33388057</pub-id></mixed-citation>
    </ref>
    <ref id="btac508-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Alsentzer</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) Publicly available clinical BERT embeddings. In: Proceedings of the 2nd Clinical Natural Language Processing Workshop, Minneapolis, Minnesota, USA, Association for Computational Linguistics, pp. 72–78.</mixed-citation>
    </ref>
    <ref id="btac508-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baradaran</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>A survey on machine reading comprehension systems</article-title>. <italic toggle="yes">Natural Language Engineering</italic>, First View, pp. <fpage>1</fpage>–<lpage>50</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bashath</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2022</year>) <article-title>A data-centric review of deep transfer learning with applications to text data</article-title>. <source>Inf. Sci</source>., <volume>585</volume>, <fpage>498</fpage>–<lpage>528</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bastian</surname><given-names>H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2010</year>) <article-title>Seventy-five trials and eleven systematic reviews a day: how will we ever keep up?</article-title>  <source>PLoS Med</source>., <volume>7</volume>, <fpage>e1000326</fpage>.<pub-id pub-id-type="pmid">20877712</pub-id></mixed-citation>
    </ref>
    <ref id="btac508-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bojanowski</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Enriching word vectors with subword information</article-title>. <source>TACL</source>, <volume>5</volume>, <fpage>135</fpage>–<lpage>146</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bromley</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1993</year>) <part-title>Signature verification using a “siamese” time delay neural network</part-title>. In: <source>Advances in Neural Information Processing Systems</source>. Vol. <volume>6</volume>.</mixed-citation>
    </ref>
    <ref id="btac508-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) Beyond triplet loss: a deep quadruplet network for person re-identification. In: <italic toggle="yes">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA</italic>, pp. <fpage>403</fpage>–<lpage>412</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>X.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018a</year>) <article-title>Adversarial deep averaging networks for cross-lingual sentiment classification</article-title>. <source>TACL</source>, <volume>6</volume>, <fpage>557</fpage>–<lpage>570</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018b</year>) DarkRank: accelerating deep metric learning via cross sample similarities transfer. In: Proceedings of the AAAI Conference on Artificial Intelligence. Vol. <volume>32</volume>.</mixed-citation>
    </ref>
    <ref id="btac508-B11">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Clark</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) ELECTRA: pre-training text encoders as discriminators rather than generators. In: <italic toggle="yes">8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020</italic>.</mixed-citation>
    </ref>
    <ref id="btac508-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cohen</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>Redundancy in electronic health record corpora: analysis, impact on text mining performance and mitigation strategies</article-title>. <source>BMC Bioinformatics</source>, <volume>14</volume>, <fpage>10</fpage>–<lpage>15</lpage>.<pub-id pub-id-type="pmid">23323800</pub-id></mixed-citation>
    </ref>
    <ref id="btac508-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Del Fiol</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Clinical questions raised by clinicians at the point of care: a systematic review</article-title>. <source>JAMA Intern. Med</source>., <volume>174</volume>, <fpage>710</fpage>–<lpage>718</lpage>.<pub-id pub-id-type="pmid">24663331</pub-id></mixed-citation>
    </ref>
    <ref id="btac508-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Devlin</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) BERT: pre-training of deep bidirectional transformers for language understanding. In: <italic toggle="yes">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), Minneapolis, Minnesota, USA</italic>, Association for Computational Linguistics, pp. <fpage>4171</fpage>–<lpage>4186</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ester</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1996</year>) <article-title>A density-based algorithm for discovering clusters in large spatial databases with noise</article-title>. <source>KDD</source>, <volume>96</volume>, <fpage>226</fpage>–<lpage>231</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fox</surname><given-names>S.</given-names></string-name>, <string-name><surname>Duggan</surname><given-names>M.</given-names></string-name></person-group> (<year>2013</year>) <article-title>Health online 2013</article-title>. <source>Health</source>, <volume>2013</volume>, <fpage>1</fpage>–<lpage>55</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B17">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Ganin</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Lempitsky</surname><given-names>V.</given-names></string-name></person-group> (<year>2015</year>) <part-title>Unsupervised domain adaptation by backpropagation</part-title>. In: <italic toggle="yes">International Conference on Machine Learning, Lille, France</italic>. PMLR, pp. <fpage>1180</fpage>–<lpage>1189</lpage>. <publisher-name>Oxford University Press</publisher-name></mixed-citation>
    </ref>
    <ref id="btac508-B18">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Glorot</surname><given-names>X.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) Domain adaptation for large-scale sentiment classification: a deep learning approach. In: <italic toggle="yes">Proceedings of the 28 th International Conference on Machine Learning, Bellevue, WA, USA, 2011</italic>.</mixed-citation>
    </ref>
    <ref id="btac508-B19">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Golub</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <part-title>Two-stage synthesis networks for transfer learning in machine comprehension</part-title>. In: <source>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</source>, pp. <fpage>835</fpage>–<lpage>844</lpage>. <publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Copenhagen, Denmark</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btac508-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goodfellow</surname><given-names>I.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <part-title>Generative adversarial nets</part-title>. In: <source>Advances in Neural Information Processing Systems, Montréal, Canada</source>. Vol. <volume>27</volume>.</mixed-citation>
    </ref>
    <ref id="btac508-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gu</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Domain-specific language model pretraining for biomedical natural language processing</article-title>. <source>ACM Trans. Comput. Healthcare (HEALTH)</source>, <volume>3</volume>, <fpage>1</fpage>–<lpage>23</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guan</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Scale variance minimization for unsupervised domain adaptation in image segmentation</article-title>. <source>Pattern Recognit</source>., <volume>112</volume>, <fpage>107764</fpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hider</surname><given-names>P.N.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2009</year>) <article-title>The information-seeking behavior of clinical staff in a large health care organization</article-title>. <source>J. Med. Libr. Assoc</source>., <volume>97</volume>, <fpage>47</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">19159006</pub-id></mixed-citation>
    </ref>
    <ref id="btac508-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Honnibal</surname><given-names>M.</given-names></string-name>, <string-name><surname>Montani</surname><given-names>I.</given-names></string-name></person-group> (<year>2017</year>) <article-title>SpaCy 2: natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing</article-title>. <source>Appear</source>, <volume>7</volume>, <fpage>411</fpage>–<lpage>420</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B25">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Hosein</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <part-title>Measuring domain portability and error propagation in biomedical QA</part-title>. In: <source>Joint European Conference on Machine Learning and Knowledge Discovery in Databases, Würzburg, Germany</source>, pp. <fpage>686</fpage>–<lpage>694</lpage>. <publisher-name>Springer</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btac508-B26">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jeong</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) Transferability of natural language inference to biomedical question answering. In: <italic toggle="yes">Working Notes of CLEF 2020 Conference and Labs of the Evaluation Forum, Thessaloniki, Greece</italic>.</mixed-citation>
    </ref>
    <ref id="btac508-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jin</surname><given-names>Q.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2023</year>) <article-title>Biomedical question answering: a survey of approaches and challenges</article-title>. <source>ACM Comput. Surv</source>., <volume>55</volume>, <fpage>1</fpage>–<lpage>36</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B28">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Joshi</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <part-title>TriviaQA: a large scale distantly supervised challenge dataset for reading comprehension</part-title>. In: <source>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</source>, pp. <fpage>1601</fpage>–<lpage>1611</lpage>. <publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Vancouver, Canada</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btac508-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kaya</surname><given-names>M.</given-names></string-name>, <string-name><surname>Bilge</surname><given-names>H.Ş.</given-names></string-name></person-group> (<year>2019</year>) <article-title>Deep metric learning: a survey</article-title>. <source>Symmetry</source>, <volume>11</volume>, <fpage>1066</fpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B30">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) Attention-based ensemble for deep metric learning. In: <italic toggle="yes">Proceedings of the European Conference on Computer Vision (ECCV), Munich, Germany</italic>, pp. <fpage>736</fpage>–<lpage>751</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B31">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kommaraju</surname><given-names>V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) Unsupervised pre-training for biomedical question answering. In: <italic toggle="yes">CLEF (Working Notes), Thessaloniki, Greece</italic>.</mixed-citation>
    </ref>
    <ref id="btac508-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kruskal</surname><given-names>J.B.</given-names></string-name></person-group> (<year>1964</year>) <article-title>Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis</article-title>. <source>Psychometrika</source>, <volume>29</volume>, <fpage>1</fpage>–<lpage>27</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B33">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Laiz</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) Using the triplet loss for domain adaptation in WCE. In: <italic toggle="yes">Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops, Seoul, Korea (South)</italic>.</mixed-citation>
    </ref>
    <ref id="btac508-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>1234</fpage>–<lpage>1240</lpage>.<pub-id pub-id-type="pmid">31501885</pub-id></mixed-citation>
    </ref>
    <ref id="btac508-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mahbub</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2022</year>) <article-title>Unstructured clinical notes within the 24 hours since admission predict short, mid &amp; long-term mortality in adult ICU patients</article-title>. <source>PLoS One</source>, <volume>17</volume>, <fpage>e0262182</fpage>.<pub-id pub-id-type="pmid">34990485</pub-id></mixed-citation>
    </ref>
    <ref id="btac508-B36">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Mikolov</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) Efficient estimation of word representations in vector space. In: <person-group person-group-type="editor"><string-name><surname>Bengio</surname><given-names>Y.</given-names></string-name>, <string-name><surname>LeCun</surname><given-names>Y.</given-names></string-name></person-group> (eds) 1st International Conference on Learning Representations, ICLR 2013, Scottsdale, Arizona, USA, <italic toggle="yes">May 2–4, 2013, Workshop Track Proceedings.</italic></mixed-citation>
    </ref>
    <ref id="btac508-B37">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Naseem</surname><given-names>U.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <part-title>BioALBERT: a simple and effective pre-trained language model for biomedical named entity recognition</part-title>. In: <source>2021 International Joint Conference on Neural Networks (IJCNN), Online</source>, pp. <fpage>1</fpage>–<lpage>7</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btac508-B38">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Nguyen</surname><given-names>V.</given-names></string-name></person-group> (<year>2019</year>) <part-title>Question answering in the biomedical domain</part-title>. In: <source>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, Florence, Italy</source>, pp. <fpage>54</fpage>–<lpage>63</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B39">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Nishida</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) Unsupervised domain adaptation of language models for reading comprehension. In: <italic toggle="yes">LREC, Marseille, France</italic>.</mixed-citation>
    </ref>
    <ref id="btac508-B40">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Odena</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <part-title>Conditional image synthesis with auxiliary classifier GANs</part-title>. In: <source>International Conference on Machine Learning, Sydney, Australia</source>, <publisher-name>PMLR</publisher-name>, pp. <fpage>2642</fpage>–<lpage>2651</lpage>. .</mixed-citation>
    </ref>
    <ref id="btac508-B41">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Pampari</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <part-title>emrQA: a large corpus for question answering on electronic medical records</part-title>. In: <source>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</source>, <publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Brussels, Belgium</publisher-loc>, pp. <fpage>2357</fpage>–<lpage>2368</lpage>, <publisher-loc>Brussels, Belgium</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btac508-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pan</surname><given-names>S.J.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Q.</given-names></string-name></person-group> (<year>2010</year>) <article-title>A survey on transfer learning</article-title>. <source>IEEE Trans. Knowl. Data Eng</source>., <volume>22</volume>, <fpage>1345</fpage>–<lpage>1359</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B43">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Pennington</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) GloVe: global vectors for word representation. In: <italic toggle="yes">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Doha, Qatar</italic>, pp. <fpage>1532</fpage>–<lpage>1543</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B44">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Pergola</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <part-title>Boosting low-resource biomedical QA via entity-aware masking strategies</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Merlo</surname><given-names>P.</given-names></string-name></person-group>  <italic toggle="yes">et al.</italic> (eds) <source>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021</source><italic toggle="yes">, April 19–23</italic>, <italic toggle="yes">2021, Online</italic>, <publisher-name>Association for Computational Linguistics</publisher-name>, pp. <fpage>1977</fpage>–<lpage>1985</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B45">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Raj Kanakarajan</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) BioELECTRA: pretrained biomedical text encoder using discriminators. In: <italic toggle="yes">Proceedings of the 20th Workshop on Biomedical Language Processing</italic>, pp. <fpage>143</fpage>–<lpage>154</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B46">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Rajpurkar</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <part-title>SQuAD: 100,000+ questions for machine comprehension of text</part-title>. In: <source>Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Austin, Texas</source>, <publisher-name>Association for Computational Linguistics</publisher-name>, pp. <fpage>2383</fpage>–<lpage>2392</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rios</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Generalizing biomedical relation classification with neural adversarial domain adaptation</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>2973</fpage>–<lpage>2981</lpage>.<pub-id pub-id-type="pmid">29590309</pub-id></mixed-citation>
    </ref>
    <ref id="btac508-B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Russell-Rose</surname><given-names>T.</given-names></string-name>, <string-name><surname>Chamberlain</surname><given-names>J.</given-names></string-name></person-group> (<year>2017</year>) <article-title>Expert search strategies: the information retrieval practices of healthcare information professionals</article-title>. <source>JMIR Med. Inform</source>., <volume>5</volume>, <fpage>e7680</fpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>An unsupervised deep domain adaptation approach for robust speech recognition</article-title>. <source>Neurocomputing</source>, <volume>257</volume>, <fpage>79</fpage>–<lpage>87</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B50">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Telukuntla</surname><given-names>S.K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <part-title>UNCC biomedical semantic question answering systems. BioASQ: Task-7B, Phase-B</part-title>. In: <source>Joint European Conference on Machine Learning and Knowledge Discovery in Databases, Würzburg, Germany</source>, <publisher-name>Springer</publisher-name>, pp. <fpage>695</fpage>–<lpage>710</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B51">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Thompson</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) Overcoming catastrophic forgetting during domain adaptation of neural machine translation. In: <italic toggle="yes">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), Minneapolis, Minnesota</italic>, pp. <fpage>2062</fpage>–<lpage>2068</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tsatsaronis</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition</article-title>. <source>BMC Bioinformatics</source>, <volume>16</volume>, <fpage>1</fpage>–<lpage>28</lpage>.<pub-id pub-id-type="pmid">25591917</pub-id></mixed-citation>
    </ref>
    <ref id="btac508-B53">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Tzeng</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) Adversarial discriminative domain adaptation. In: <italic toggle="yes">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, Hawaii</italic>, pp. <fpage>7167</fpage>–<lpage>7176</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Verspoor</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2009</year>) <article-title>The textual characteristics of traditional and open access scientific journals are similar</article-title>. <source>BMC Bioinformatics</source>, <volume>10</volume>, <fpage>183</fpage>.<pub-id pub-id-type="pmid">19527520</pub-id></mixed-citation>
    </ref>
    <ref id="btac508-B55">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Vu</surname><given-names>T.-T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) Effective unsupervised domain adaptation with adversarially trained language models, In <italic toggle="yes">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online</italic>, Association for Computational Linguistics, pp. 6163–6173. </mixed-citation>
    </ref>
    <ref id="btac508-B56">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <part-title>Adversarial domain adaptation for machine reading comprehension</part-title>. In: <source>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</source>, <publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Hong Kong, China</publisher-loc>, pp. <fpage>2510</fpage>–<lpage>2520</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B57">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) Deep metric learning with angular loss. In: <italic toggle="yes">Proceedings of the IEEE International Conference on Computer Vision, Venice, Italy</italic>, pp. <fpage>2593</fpage>–<lpage>2601</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B58">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weinberger</surname><given-names>K.Q.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2005</year>) <part-title>Distance metric learning for large margin nearest neighbor classification</part-title>. In: <source>Advances in Neural Information Processing Systems</source>. Vol. <volume>18</volume>, Vancouver, British Columbia, Canada.</mixed-citation>
    </ref>
    <ref id="btac508-B59">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wen</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Improving face recognition with domain adaptation</article-title>. <source>Neurocomputing</source>, <volume>287</volume>, <fpage>45</fpage>–<lpage>51</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B60">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Wulfmeier</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <part-title>Addressing appearance change in outdoor robotics with adversarial domain adaptation</part-title>. In: <source>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</source>, Vancouver, British Columbia, Canada, <publisher-name>IEEE</publisher-name>, pp. <fpage>1551</fpage>–<lpage>1558</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B61">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>External features enriched model for biomedical question answering</article-title>. <source>BMC Bioinformatics</source>, <volume>22</volume>, <fpage>1</fpage>–<lpage>19</lpage>.<pub-id pub-id-type="pmid">33388027</pub-id></mixed-citation>
    </ref>
    <ref id="btac508-B62">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Yoon</surname><given-names>W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <part-title>Pre-trained language model for biomedical question answering</part-title>. In: <source>Machine Learning and Knowledge Discovery in Databases - International Workshops of ECML PKDD 2019, Proceedings</source>, Würzburg, Germany, <publisher-name>Springer</publisher-name>, pp. <fpage>727</fpage>–<lpage>740</lpage>.</mixed-citation>
    </ref>
    <ref id="btac508-B63">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Yue</surname><given-names>X.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <part-title>CliniQG4QA: generating diverse questions for domain adaptation of clinical question answering</part-title>. In: <source>2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</source>, Online, pp. <fpage>580</fpage>–<lpage>587</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
