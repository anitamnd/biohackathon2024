<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_GPB734 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEmmc1 docx ?>
<?FILEmmc2 docx ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Genomics Proteomics Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Genomics Proteomics Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Genomics, Proteomics &amp; Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1672-0229</issn>
    <issn pub-type="epub">2210-3244</issn>
    <publisher>
      <publisher-name>Elsevier</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10928373</article-id>
    <article-id pub-id-type="pii">S1672-0229(23)00108-0</article-id>
    <article-id pub-id-type="doi">10.1016/j.gpb.2023.09.003</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Database</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>OBIA: An Open Biomedical Imaging Archive</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au005">
        <name>
          <surname>Jin</surname>
          <given-names>Enhui</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
        <xref rid="af020" ref-type="aff">4</xref>
        <xref rid="fn1" ref-type="fn">#</xref>
      </contrib>
      <contrib contrib-type="author" id="au010">
        <name>
          <surname>Zhao</surname>
          <given-names>Dongli</given-names>
        </name>
        <xref rid="af010" ref-type="aff">2</xref>
        <xref rid="fn1" ref-type="fn">#</xref>
      </contrib>
      <contrib contrib-type="author" id="au015">
        <name>
          <surname>Wu</surname>
          <given-names>Gangao</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
        <xref rid="af020" ref-type="aff">4</xref>
        <xref rid="fn1" ref-type="fn">#</xref>
      </contrib>
      <contrib contrib-type="author" id="au020">
        <name>
          <surname>Zhu</surname>
          <given-names>Junwei</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au025">
        <name>
          <surname>Wang</surname>
          <given-names>Zhonghuang</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
        <xref rid="af020" ref-type="aff">4</xref>
      </contrib>
      <contrib contrib-type="author" id="au030">
        <name>
          <surname>Wei</surname>
          <given-names>Zhiyao</given-names>
        </name>
        <xref rid="af010" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author" id="au035">
        <name>
          <surname>Zhang</surname>
          <given-names>Sisi</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au040">
        <name>
          <surname>Wang</surname>
          <given-names>Anke</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au045">
        <name>
          <surname>Tang</surname>
          <given-names>Bixia</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au050">
        <name>
          <surname>Chen</surname>
          <given-names>Xu</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au055">
        <name>
          <surname>Sun</surname>
          <given-names>Yanling</given-names>
        </name>
        <email>sunyanling@big.ac.cn</email>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <contrib contrib-type="author" id="au060">
        <name>
          <surname>Zhang</surname>
          <given-names>Zhe</given-names>
        </name>
        <email>tj.zhe.zhang@gmail.com</email>
        <xref rid="af025" ref-type="aff">5</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <contrib contrib-type="author" id="au065">
        <name>
          <surname>Zhao</surname>
          <given-names>Wenming</given-names>
        </name>
        <email>zhaowm@big.ac.cn</email>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
        <xref rid="af020" ref-type="aff">4</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <contrib contrib-type="author" id="au070">
        <name>
          <surname>Meng</surname>
          <given-names>Yuanguang</given-names>
        </name>
        <email>meng6512@vip.sina.com</email>
        <xref rid="af010" ref-type="aff">2</xref>
        <xref rid="af025" ref-type="aff">5</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <aff id="af005"><label>1</label>National Genomics Data Center, Beijing Institute of Genomics, Chinese Academy of Sciences and China National Center for Bioinformation, Beijing 100101, China</aff>
      <aff id="af010"><label>2</label>Chinese People’s Liberation Army (PLA) Medical School, Beijing 100853, China</aff>
      <aff id="af015"><label>3</label>CAS Key Laboratory of Genome Sciences and Information, Beijing Institute of Genomics, Chinese Academy of Sciences and China National Center for Bioinformation, Beijing 100101, China</aff>
      <aff id="af020"><label>4</label>University of Chinese Academy of Sciences, Beijing 100049, China</aff>
      <aff id="af025"><label>5</label>Department of Obstetrics and Gynecology, Seventh Medical Center of Chinese PLA General Hospital, Beijing 100700, China</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>⁎</label>Corresponding authors. <email>sunyanling@big.ac.cn</email><email>tj.zhe.zhang@gmail.com</email><email>zhaowm@big.ac.cn</email><email>meng6512@vip.sina.com</email></corresp>
      <fn id="fn1">
        <label>#</label>
        <p id="np010">Equal contribution.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>06</day>
      <month>10</month>
      <year>2023</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="ppub">
      <month>10</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>06</day>
      <month>10</month>
      <year>2023</year>
    </pub-date>
    <volume>21</volume>
    <issue>5</issue>
    <fpage>1059</fpage>
    <lpage>1065</lpage>
    <history>
      <date date-type="received">
        <day>28</day>
        <month>5</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>26</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>9</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 Beijing Institute of Genomics, Chinese Academy of Sciences / China National Center for Bioinformation and Genetics Society of China</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="ab005">
      <p>With the development of artificial intelligence (AI) technologies, <bold>biomedical imaging</bold> data play an important role in scientific research and clinical application, but the available resources are limited. Here we present <bold>Open Biomedical Imaging Archive</bold> (OBIA), a repository for archiving biomedical imaging and related clinical data. OBIA adopts five data objects (Collection, Individual, Study, Series, and Image) for data organization, and accepts the submission of biomedical images of multiple modalities, organs, and diseases. In order to protect personal privacy, OBIA has formulated a unified <bold>de-identification</bold> and <bold>quality control</bold> process. In addition, OBIA provides friendly and intuitive web interfaces for data submission, browsing, and retrieval, as well as image retrieval. As of September 2023, OBIA has housed data for a total of 937 individuals, 4136 studies, 24,701 series, and 1,938,309 images covering 9 modalities and 30 anatomical sites. Collectively, OBIA provides a reliable platform for biomedical imaging data management and offers free open access to all publicly available data to support research activities throughout the world. OBIA can be accessed at <ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/obia" id="ir005">https://ngdc.cncb.ac.cn/obia</ext-link>.</p>
    </abstract>
    <kwd-group id="kg005">
      <title>Keywords</title>
      <kwd>Open Biomedical Imaging Archive</kwd>
      <kwd>Database</kwd>
      <kwd>Biomedical imaging</kwd>
      <kwd>De-identification</kwd>
      <kwd>Quality control</kwd>
    </kwd-group>
  </article-meta>
  <notes>
    <p id="ms005">Handled by Yudong Zhang</p>
  </notes>
</front>
<body>
  <sec id="s0005">
    <title>Introduction</title>
    <p id="p0010">The introduction of advanced imaging technologies has greatly facilitated the development of non-invasive diagnoses. Currently, biomedical images can clearly depict the internal structure (anatomy), morphology, and physiological functions from the molecular scale to the cellular, organ, tissue, lesion, and even the entire organism <xref rid="b0005" ref-type="bibr">[1]</xref>, providing crucial evidence for diagnosis and treatment response assessment <xref rid="b0010" ref-type="bibr">[2]</xref>, <xref rid="b0015" ref-type="bibr">[3]</xref>. Imaging data generated during patient visits has formed a huge accumulation. However, incomplete sharing systems make it challenging for researchers and clinicians to collaborate on utilizing these images to gain significant insights into health and disease <xref rid="b0020" ref-type="bibr">[4]</xref>. Furthermore, the demand for rapid diagnosis promotes the application of artificial intelligence (AI) in biomedical imaging, and the development of reliable and robust AI algorithms requires sufficiently large and representative image datasets <xref rid="b0025" ref-type="bibr">[5]</xref>, <xref rid="b0030" ref-type="bibr">[6]</xref>. Thus, high-quality biomedical imaging data sharing plays an important role in promoting scientific discoveries and improving diagnostic accuracy.</p>
    <p id="p0015">The National Institutes of Health (NIH) in America sponsors several repositories. The Medical Imaging and Data Resource Center (MIDRC) <xref rid="b0035" ref-type="bibr">[7]</xref> serves as an open-access platform for COVID-19-related medical images and associated data. Image and Data Archive (IDA) <xref rid="b0040" ref-type="bibr">[8]</xref>, NITRC Image Repository (NITRC-IR) <xref rid="b0045" ref-type="bibr">[9]</xref>, Federal Interagency Traumatic Brain Injury Research (FITBIR) <xref rid="b0050" ref-type="bibr">[10]</xref>, OpenNeuro <xref rid="b0055" ref-type="bibr">[11]</xref>, and National Institute of Mental Health Data Archive (NDA) <xref rid="b0060" ref-type="bibr">[12]</xref> are dedicated to collecting neuro and brain imaging. The Cancer Imaging Archive (TCIA) <xref rid="b0065" ref-type="bibr">[13]</xref> and Imaging Data Commons (IDC) <xref rid="b0070" ref-type="bibr">[14]</xref> are cancer imaging repertories, with TCIA providing images locally and IDC affording collections in the Cancer Research Data Commons (CRDC) cloud environment. Regarding breast cancer, the Cancer Research United Kingdom (UK) funds the OPTIMAM Mammography Image Database (OMI-DB) <xref rid="b0075" ref-type="bibr">[15]</xref>, and the University of Porto in Portugal funds the Breast Cancer Digital Repository (BCDR) <xref rid="b0080" ref-type="bibr">[16]</xref>, providing annotated breast cancer images and clinical details. Most of these repositories support data de-identification and quality control, except NITRC-IR and IDC. Additionally, some universities or institutions provide open-source datasets, such as Open Access Series of Imaging Studies (OASIS) <xref rid="b0085" ref-type="bibr">[17]</xref>, EchoNet-Dynamic <xref rid="b0090" ref-type="bibr">[18]</xref>, Cardiac Acquisitions for Multi-structure Ultrasound Segmentation (CAMUS) project <xref rid="b0095" ref-type="bibr">[19]</xref>, Chest X-ray <xref rid="b0100" ref-type="bibr">[20]</xref>, and Structured Analysis of the Retina (STARE) <xref rid="b0105" ref-type="bibr">[21]</xref>. In China, the Huazhong University of Science and Technology provides an open resource named integrative Computed Tomography (CT) images and CFs for COVID-19 (iCTCF) <xref rid="b0110" ref-type="bibr">[22]</xref>, which includes CT images and clinical features of patients with pneumonia (including COVID-19 pneumonia). There is still a lack of databases that are dedicated to storing and accepting submissions for various diseases and modalities.</p>
    <p id="p0020">To address this issue, we established the Open Biomedical Imaging Archive (OBIA; <ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/obia" id="ir015">https://ngdc.cncb.ac.cn/obia</ext-link>), a repository for archiving biomedical imaging data and related clinical data. As a core database resource in the National Genomics Data Center (NGDC) <xref rid="b0115" ref-type="bibr">[23]</xref>, part of the China National Center for Bioinformation (CNCB; <ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/" id="ir020">https://ngdc.cncb.ac.cn/</ext-link>), OBIA accepts image submissions from all over the world and provides free open access to all publicly available data to support global research activities. OBIA supports de-identification, management, and quality control of imaging data, providing data services such as browsing, retrieval, and downloading, thus promoting the reuse of existing imaging data and clinical data.</p>
  </sec>
  <sec id="s0010">
    <title>Implementation</title>
    <sec id="s0015">
      <title>Database construction</title>
      <p id="p0025">OBIA is implemented using Spring Boot (a framework easy to create standalone Java applications; <ext-link ext-link-type="uri" xlink:href="https://spring.io/projects/spring-boot" id="ir025">https://spring.io/projects/spring-boot</ext-link>) as the backend framework. The frontend user interfaces are developed using Vue.js (an approachable, performant, and versatile framework for building web user interfaces; <ext-link ext-link-type="uri" xlink:href="https://vuejs.org/" id="ir030">https://vuejs.org/</ext-link>) and Element UI (a Vue 2.0-based component library for developers, designers, and product managers; <ext-link ext-link-type="uri" xlink:href="https://element.eleme.cn/" id="ir035">https://element.eleme.cn/</ext-link>). The charts on the web page are constructed using ECharts (an open-source JavaScript visualization library; <ext-link ext-link-type="uri" xlink:href="https://echarts.apache.org" id="ir040">https://echarts.apache.org</ext-link>). All metadata information is stored in MySQL (a free and popular relational database management system; <ext-link ext-link-type="uri" xlink:href="https://www.mysql.com/" id="ir045">https://www.mysql.com/</ext-link>).</p>
    </sec>
    <sec id="s0020">
      <title>Image retrieval</title>
      <p id="p0030">Deep learning-based methods, such as scale-invariant feature transform (SIFT) <xref rid="b0120" ref-type="bibr">[24]</xref>, local binary patterns (LBP) <xref rid="b0125" ref-type="bibr">[25]</xref>, and histogram of oriented gradient (HOG) <xref rid="b0130" ref-type="bibr">[26]</xref>, demonstrate better performance compared to traditional methods. Deep neural networks excel at extracting superior features for retrieving multimodal medical images of various body organs <xref rid="b0135" ref-type="bibr">[27]</xref> and enhancing ranking performance in the case of small sample sizes <xref rid="b0140" ref-type="bibr">[28]</xref>.</p>
      <p id="p0035">In OBIA, we leveraged TCIA multi-modal cancer data and utilized EfficientNet <xref rid="b0145" ref-type="bibr">[29]</xref> as the feature extractor. We trained the model using a triplet network and an attention module to compress the image into a discrete hash value (<xref rid="f0005" ref-type="fig">Figure 1</xref>). We subsequently convert the trained model into TensorRT format to accelerate inference performance and reduce inference latency. We converted the trained model into TensorRT format to enhance inference performance and reduce latency. To store the hash codes, we employed Faiss, a high-performance similarity search library developed by Facebook AI Research and commonly used in deep learning. We computed image similarity using the hamming distance and returned the most similar images to the query. Our model achieved a mean average precision (MAP) value that surpassed the performance of existing advanced image retrieval models on the TCIA dataset.<fig id="f0005"><label>Figure 1</label><caption><p><bold>Deep triplet hashing based on attention and layer fusion module</bold></p><p>The model uses EfficientNet-B6 as the backbone network and utilizes the CBAM attention module in Block 5 to obtain feature maps. Layer fusion is employed in the fully connected layers, and focal loss and triplet loss are used to generate hash code and class embedding. CBAM, convolutional block attention module.</p></caption><graphic xlink:href="gr1" id="lk00005"/></fig></p>
    </sec>
  </sec>
  <sec id="s0025">
    <title>Database content and usage</title>
    <sec id="s0030">
      <title>Data model</title>
      <p id="p0040">Imaging data in OBIA are organized into five objects: Collection, Individual, Study, Series, and Image (<xref rid="f0010" ref-type="fig">Figure 2</xref>). “Collection”, bearing an accession number prefixed with “OBIA”, provides an overall description for a complete submission. “Individual”, possessing an accession number prefixed with “I”, defines the characteristics of a human or non-human organism receiving, or registered to receive, healthcare services. “Study”, adopting an accession number prefixed with “S”, contains descriptive information about radiological examinations performed on an individual. A study may be divided into one or more “Series” according to different logics, such as body part or orientation. “Image” describes the pixel data of a single Digital Imaging and Communications in Medicine (DICOM) file, and an image is related to a single series within a single study. Based on these standardized data objects, OBIA connects the image structure defined by the DICOM standard with actual research projects, realizing data sharing and exchange. Besides, each collection in OBIA is linked to BioProject <xref rid="b0150" ref-type="bibr">[30]</xref> (<ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/bioproject/" id="ir050">https://ngdc.cncb.ac.cn/bioproject/</ext-link>) to provide descriptive metadata about the research project. And the individual in OBIA can be associated with GSA-Human <xref rid="b0155" ref-type="bibr">[31]</xref> (<ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/gsa-human/" id="ir055">https://ngdc.cncb.ac.cn/gsa-human/</ext-link>) by individual accession number, if available, which links imaging data with genomic data for researchers to perform multi-omics analysis.<fig id="f0010"><label>Figure 2</label><caption><p><bold>OBIA data model</bold></p><p>The Collection and Individual in OBIA can be linked to BioProject and GSA-Human, respectively. The accession numbers for data objects, including Collection, Individual, and Study, are indicated in the gray boxes. Collection accession numbers have a prefix of “OBIA” followed by four consecutive digits, Individual accession numbers have a prefix of “I” followed by six consecutive digits, and Study accession numbers have a prefix of “S” followed by eight consecutive digits. OBIA, Open Biomedical Imaging Archive.</p></caption><graphic xlink:href="gr2" id="lk00010"/></fig></p>
    </sec>
    <sec id="s0035">
      <title>De-identification and quality control</title>
      <p id="p0045">Images may contain protected health information (PHI) and require appropriate handling to minimize the risk of patient privacy breaches. In order to retain as much valuable scientific information as possible while removing PHI, OBIA provides a unified de-identification and quality control mechanism (<xref rid="f0015" ref-type="fig">Figure 3</xref>) based on the DICOM PS 3.15 Appendix E: Attribute Confidentiality Profile (<ext-link ext-link-type="uri" xlink:href="https://www.dicomstandard.org/" id="ir060">https://www.dicomstandard.org/</ext-link>). The key elements and rules we adopted include: (1) clean pixel data; (2) clean descriptors; (3) retain longitudinal temporal information modified dates; (4) retain patient characteristics; (5) retain device identity; and (6) retain safe private tags.<fig id="f0015"><label>Figure 3</label><caption><p><bold>OBIA de-identification and quality control mechanism</bold></p><p>Flowchart shows image submission, de-identification, and quality control steps. The de-identification steps include using CTP to process standard tags and PyDicom to handle private tags, and the problematic images will be isolated. The quality control steps include review of reports generated by TagSniffer and visual inspection of image pixels by OBIA staff. CTP, clinical trial processor.</p></caption><graphic xlink:href="gr3" id="lk00015"/></fig></p>
      <p id="p0050">OBIA utilizes the Radiological Society of North America (RSNA) MIRC clinical trial processor (CTP) (<ext-link ext-link-type="uri" xlink:href="https://mircwiki.rsna.org/index.php?title=MIRC_CTP" id="ir065">https://mircwiki.rsna.org/index.php?title=MIRC_CTP</ext-link>) for most of the de-identification work. We constructed a CTP pipeline and developed a common base de-identification script to remove or blank certain standard tags containing or potentially containing PHI. This script also maps local patient IDs to OBIA individual accessions. As for private tags, since they are vendor-specific and scanner-specific and can contain almost anything, we use PyDicom (<ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/pydicom/" id="ir070">https://pypi.org/project/pydicom/</ext-link>) to retain attributes that are purely numeric. Some studies determine private element definitions by reading manufacturers’ DICOM conformance statements <xref rid="b0160" ref-type="bibr">[32]</xref>. However, in our practice, the wide variety of image sources made this work too time-consuming, and some conformance statements were not available. In addition to metadata elements, ultrasounds or screen captures usually add some “burned-in” annotations in the pixels data to interpret the images, which may also contain PHI. We provide a filter stage to identify these images.</p>
      <p id="p0055">After the de-identification process is completed, OBIA runs a quality control procedure. Some problematic images are isolated, such as images with a blank header or missing patient ID, corrupted images, other patient images mixed in, <italic>etc</italic>. Submitters can provide relevant information to repair the images or discard them entirely. Duplicate images are removed, leaving only one. Then we use TagSniffer (<ext-link ext-link-type="uri" xlink:href="https://github.com/stlstevemoore/dicom-tag-sniffer" id="ir075">https://github.com/stlstevemoore/dicom-tag-sniffer</ext-link>) to generate a report for all images. All DICOM elements in the report are carefully reviewed to ensure that they are free of PHI, and certain values (<italic>e.g.</italic>, patient ID, study date) are modified as expected. In addition, we perform a visual inspection of each image series to ensure that no PHI is contained in the pixel values and that the images are visible and uncorrupted.</p>
    </sec>
    <sec id="s0040">
      <title>Data browse and retrieval</title>
      <p id="p0060">OBIA provides user-friendly web interfaces for data query and browsing. Users can browse data of interest by specifying non-image information (<italic>e.g.</italic>, age, gender, and disease) and/or the imaging data extracted from the DICOM header (<italic>e.g.</italic>, modality and anatomical site). Users can also search for data by entering the accession number. OBIA allows users to browse the basic information of collection (title, description, keywords, submitter, data accessibility, <italic>etc</italic>.), individual, study (study description, study age, study date, <italic>etc</italic>.), series (modality, anatomical site, series description, <italic>etc</italic>.), and view thumbnails of images.</p>
      <p id="p0065">OBIA also provides image retrieval functionality designed to find images similar to a query. Users can use this function by clicking the “Image Retrieval” button on the homepage. After uploading the image, the image retrieval model employs the hamming distance to return the top 30 images that are closest to the queried image, serving as the nearest neighbor images. Users have the option to click on these returned images and review their respective image metadata.</p>
    </sec>
    <sec id="s0045">
      <title>Data access and download</title>
      <p id="p0070">OBIA states that the data access policies are set by data submitters. There are two different types of data accessibility: open access and controlled access. Open access means that all data is public for global researchers if released, whereas controlled access means that data can be downloadable only after being authorized by the submitter. OBIA supports online data requests and reviews. Before applying, users need to register and log into OBIA via the Beijing Institute of Genomics (BIG) single sign-on (SSO; <ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/sso/" id="ir080">https://ngdc.cncb.ac.cn/sso/</ext-link>) system. Applicants shall provide their basic information, specify the scope of data usage, and promise not to attempt to restore the privacy information in the data. The download link will only be provided to the applicant if the data owner approves the request.</p>
    </sec>
    <sec id="s0050">
      <title>Data submission</title>
      <p id="p0075">OBIA accepts submissions of biomedical imaging data in DICOM format from clinical or specific research projects. To create a submission, users need to log in, fill in the basic information about the collection, and email the necessary clinical information. Image data will be transferred to OBIA offline after de-identification. Users can either use the de-identification process recommended by OBIA or apply their own methods to de-identify the image. Quality control will be conducted for all the data. OBIA will assign a unique accession number to each collection, individual, and study and arrange images into a standard organization. In order to ensure the security of submitted data, backup copies will be stored on physically separate disks. Finally, metadata will be extracted from the image file headers and stored in the database to support data queries.</p>
    </sec>
    <sec id="s0055">
      <title>Data statistics</title>
      <p id="p0080">As of September 2023, OBIA has housed a total of 937 individuals, 4136 studies, 24,701 series, and 1,938,309 images, covering 9 modalities and 30 anatomical sites. Representative imaging modalities are CT, magnetic resonance (MR), and digital radiography (DX) (<xref rid="s0085" ref-type="sec">Table S1</xref>). Anatomical sites include the abdomen, breast, chest, head, liver, and pelvis (<xref rid="s0085" ref-type="sec">Table S2</xref>). The first batch of collections submitted to OBIA came from the Chinese People’s Liberation Army (PLA) General Hospital, including imaging data of three major gynecological tumors: endometrial cancer, ovarian cancer, and cervical cancer. The data were divided into four collections, and <xref rid="t0005" ref-type="table">Table 1</xref> shows the number of individuals, studies, series, and images of each collection. In addition, we collected associated clinical metadata, such as demographic data, medical history, family history, diagnosis, pathological types, and treatment methods.<table-wrap position="float" id="t0005"><label>Table 1</label><caption><p>Number of individuals, studies, series, and images of each collection</p></caption><table frame="hsides" rules="groups"><thead><tr><th><bold>Accession No.</bold></th><th><bold>Disease</bold></th><th><bold>No. of individuals</bold></th><th><bold>No. of studies</bold></th><th><bold>No. of series</bold></th><th><bold>No. of images</bold></th></tr></thead><tbody><tr><td>OBIA0001</td><td>Endometrial cancer</td><td>316</td><td>1587</td><td>8941</td><td>779,171</td></tr><tr><td>OBIA0002</td><td>Ovarian cancer</td><td>202</td><td>1548</td><td>7151</td><td>548,174</td></tr><tr><td>OBIA0003</td><td>Cervical cancer</td><td>117</td><td>675</td><td>3943</td><td>307,101</td></tr><tr><td>OBIA0004</td><td>Endometrial cancer</td><td>302</td><td>326</td><td>4666</td><td>303,863</td></tr></tbody></table><table-wrap-foot><fn><p><italic>Note</italic>: The data statistics are up to September 2023.</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
  </sec>
  <sec id="s0060">
    <title>Perspectives and concluding remarks</title>
    <p id="p0085">OBIA is a centralized repository of de-identified biomedical imaging data. Different from existing related databases, OBIA is characterized by publishing imaging data and clinical information from a wide range of imaging modalities in a common DICOM format. Algorithm developers can convert and format as needed, and clinicians and researchers can combine clinical data with images for further analysis. Unlike the Health Insurance Portability and Accountability Act (HIPAA) in the United States and the General Data Protection Regulation (GDPR) in Europe, China has a Personal Information Protection Law (PIPL), a Data Security Law, and other regulations for medical records and health information, which include elements similar to HIPAA and GDPR. OBIA strictly follows Chinese legal regulations for data processing, quality control, and data sharing, especially for removing PHI. It also promotes data sharing among data submitters and users while ensuring compliance with these laws. As a core database resource within NGDC, OBIA is seamlessly integrated with BioProject and GSA-Human, facilitating the harmonious integration of imaging and genomic data to support multi-omics analysis. In essence, OBIA serves as a dependable platform for sharing clinically relevant imaging data among researchers from diverse institutions, effectively bridging the gap within China’s biomedical imaging database landscape.</p>
    <p id="p0090">In the future, we will continue to upgrade the infrastructure of OBIA and increase security protection measures to realize long-term secure storage, management, and access to a large volume of images. At the same time, we will collect more types of biomedical imaging data and gradually increase the corresponding genomic data to expand our data resources. To facilitate data submission and ensure privacy security, we will further optimize the image de-identification process and explore the use of the machine learning-based optical character recognition (OCR) <xref rid="b0165" ref-type="bibr">[33]</xref> method to remove PHI from image pixels. We will also improve quality control and background automatic review processes to speed up data submission. In compliance with applicable regulations and ethical norms, OBIA’s goal is to preserve as much effective image metadata as possible to provide researchers with high-quality imaging data. Furthermore, we plan to develop more intuitive and interactive web interfaces according to users’ needs, increase database functions, and integrate related online tools to help analyze biomedical images. In addition, we intend to optimize the image retrieval model to offer users more convenient and precise image retrieval services. Finally, we call for collaborators to collectively build OBIA, submit image data, break down data silos, catalyze new biomedical discoveries, and provide the possibility to create personalized treatments.</p>
  </sec>
  <sec id="s0065">
    <title>Ethical statement</title>
    <p id="p0095">The collection of human imaging data was approved by the Local Ethical Committees in the First Medical Center of the Chinese PLA General Hospital (Approval No. S2022-403). The written informed consent was obtained from the participating patients.</p>
  </sec>
  <sec sec-type="data-availability" id="ce.section_trv_lyv_pzb">
    <title>Data availability</title>
    <p id="p0516">OBIA is publicly available at <ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/obia" id="PC_linkl1ulLbDAle">https://ngdc.cncb.ac.cn/obia</ext-link>.</p>
  </sec>
  <sec sec-type="COI-statement" id="s0070">
    <title>Competing interests</title>
    <p id="p0100">The authors have declared no competing interests.</p>
  </sec>
  <sec id="s0075">
    <title>CRediT authorship contribution statement</title>
    <p id="p0105"><bold>Enhui Jin:</bold> Investigation, Methodology, Software, Writing – original draft. <bold>Dongli Zhao:</bold> Resources. <bold>Gangao Wu:</bold> Investigation, Methodology, Software, Writing – original draft. <bold>Junwei Zhu:</bold> Software. <bold>Zhonghuang Wang:</bold> Methodology. <bold>Zhiyao Wei:</bold> Resources. <bold>Sisi Zhang:</bold> Methodology. <bold>Anke Wang:</bold> Software, Writing – original draft. <bold>Bixia Tang:</bold> Resources. <bold>Xu Chen:</bold> Resources. <bold>Yanling Sun:</bold> Investigation, Methodology, Writing – review &amp; editing, Project administration. <bold>Zhe Zhang:</bold> Investigation, Methodology, Writing – review &amp; editing. <bold>Wenming Zhao:</bold> Conceptualization, Methodology, Writing – review &amp; editing, Supervision, Funding acquisition. <bold>Yuanguang Meng:</bold> Conceptualization, Methodology, Writing – review &amp; editing. All authors have read and approved the final manuscript.</p>
  </sec>
</body>
<back>
  <ref-list id="bi005">
    <title>References</title>
    <ref id="b0005">
      <label>1</label>
      <element-citation publication-type="journal" id="h0005">
        <person-group person-group-type="author">
          <name>
            <surname>Wallyn</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Anton</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Akram</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Vandamme</surname>
            <given-names>T.F.</given-names>
          </name>
        </person-group>
        <article-title>Biomedical imaging: principles, technologies, clinical aspects, contrast agents, limitations and future trends in nanomedicines</article-title>
        <source>Pharm Res</source>
        <volume>36</volume>
        <year>2019</year>
        <fpage>78</fpage>
        <pub-id pub-id-type="pmid">30945009</pub-id>
      </element-citation>
    </ref>
    <ref id="b0010">
      <label>2</label>
      <element-citation publication-type="journal" id="h0010">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>S.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Machine learning in electromagnetics with applications to biomedical imaging: a review</article-title>
        <source>IEEE Antennas Propag Mag</source>
        <volume>63</volume>
        <year>2021</year>
        <fpage>39</fpage>
        <lpage>51</lpage>
      </element-citation>
    </ref>
    <ref id="b0015">
      <label>3</label>
      <element-citation publication-type="journal" id="h0015">
        <person-group person-group-type="author">
          <name>
            <surname>Anwar</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Majid</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Qayyum</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Awais</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Alnowami</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>M.K.</given-names>
          </name>
        </person-group>
        <article-title>Medical image analysis using convolutional neural networks: a review</article-title>
        <source>J Med Syst</source>
        <volume>42</volume>
        <year>2018</year>
        <fpage>226</fpage>
        <pub-id pub-id-type="pmid">30298337</pub-id>
      </element-citation>
    </ref>
    <ref id="b0020">
      <label>4</label>
      <element-citation publication-type="journal" id="h0020">
        <person-group person-group-type="author">
          <name>
            <surname>Moody</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Perspective: the big picture</article-title>
        <source>Nature</source>
        <volume>502</volume>
        <year>2013</year>
        <fpage>S95</fpage>
        <pub-id pub-id-type="pmid">24187705</pub-id>
      </element-citation>
    </ref>
    <ref id="b0025">
      <label>5</label>
      <element-citation publication-type="journal" id="h0025">
        <person-group person-group-type="author">
          <name>
            <surname>Willemink</surname>
            <given-names>M.J.</given-names>
          </name>
          <name>
            <surname>Koszek</surname>
            <given-names>W.A.</given-names>
          </name>
          <name>
            <surname>Hardell</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Fleischmann</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Harvey</surname>
            <given-names>H.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Preparing medical imaging data for machine learning</article-title>
        <source>Radiology</source>
        <volume>295</volume>
        <year>2020</year>
        <fpage>4</fpage>
        <lpage>15</lpage>
        <pub-id pub-id-type="pmid">32068507</pub-id>
      </element-citation>
    </ref>
    <ref id="b0030">
      <label>6</label>
      <element-citation publication-type="journal" id="h0030">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Shrivastava</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Gupta</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Revisiting unreasonable effectiveness of data in deep learning era</article-title>
        <source>IEEE Int Conf Comput Vis</source>
        <year>2017</year>
        <fpage>843</fpage>
        <lpage>852</lpage>
      </element-citation>
    </ref>
    <ref id="b0035">
      <label>7</label>
      <element-citation publication-type="journal" id="h0035">
        <person-group person-group-type="author">
          <name>
            <surname>Baughan</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Whitney</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Drukker</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Sahiner</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>T.T.</given-names>
          </name>
          <name>
            <surname>Hyun</surname>
            <given-names>K.J.G.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Sequestration of imaging studies in MIDRC: a multi-institutional data commons</article-title>
        <source>Proc SPIE</source>
        <volume>12035</volume>
        <year>2022</year>
        <fpage>91</fpage>
        <lpage>98</lpage>
      </element-citation>
    </ref>
    <ref id="b0040">
      <label>8</label>
      <element-citation publication-type="journal" id="h0040">
        <person-group person-group-type="author">
          <name>
            <surname>Crawford</surname>
            <given-names>K.L.</given-names>
          </name>
          <name>
            <surname>Neu</surname>
            <given-names>S.C.</given-names>
          </name>
          <name>
            <surname>Toga</surname>
            <given-names>A.W.</given-names>
          </name>
        </person-group>
        <article-title>The image and data archive at the laboratory of neuro imaging</article-title>
        <source>Neuroimage</source>
        <volume>124</volume>
        <year>2016</year>
        <fpage>1080</fpage>
        <lpage>1083</lpage>
        <pub-id pub-id-type="pmid">25982516</pub-id>
      </element-citation>
    </ref>
    <ref id="b0045">
      <label>9</label>
      <element-citation publication-type="journal" id="h0045">
        <person-group person-group-type="author">
          <name>
            <surname>Kennedy</surname>
            <given-names>D.N.</given-names>
          </name>
          <name>
            <surname>Haselgrove</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Riehl</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Preuss</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Buccigrossi</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>The NITRC image repository</article-title>
        <source>Neuroimage</source>
        <volume>124</volume>
        <year>2016</year>
        <fpage>1069</fpage>
        <lpage>1073</lpage>
        <pub-id pub-id-type="pmid">26044860</pub-id>
      </element-citation>
    </ref>
    <ref id="b0050">
      <label>10</label>
      <element-citation publication-type="journal" id="h0050">
        <person-group person-group-type="author">
          <name>
            <surname>Thompson</surname>
            <given-names>H.J.</given-names>
          </name>
          <name>
            <surname>Vavilala</surname>
            <given-names>M.S.</given-names>
          </name>
          <name>
            <surname>Rivara</surname>
            <given-names>F.P.</given-names>
          </name>
        </person-group>
        <article-title>Common data elements and federal interagency traumatic brain injury research informatics system for TBI research</article-title>
        <source>Annu Rev Nurs Res</source>
        <volume>33</volume>
        <year>2015</year>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="pmid">25946381</pub-id>
      </element-citation>
    </ref>
    <ref id="b0055">
      <label>11</label>
      <element-citation publication-type="journal" id="h0055">
        <person-group person-group-type="author">
          <name>
            <surname>Markiewicz</surname>
            <given-names>C.J.</given-names>
          </name>
          <name>
            <surname>Gorgolewski</surname>
            <given-names>K.J.</given-names>
          </name>
          <name>
            <surname>Feingold</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Blair</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Halchenko</surname>
            <given-names>Y.O.</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>E.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The OpenNeuro resource for sharing of neuroscience data</article-title>
        <source>Elife</source>
        <volume>10</volume>
        <year>2021</year>
        <fpage>e71774</fpage>
        <pub-id pub-id-type="pmid">34658334</pub-id>
      </element-citation>
    </ref>
    <ref id="b0060">
      <label>12</label>
      <element-citation publication-type="journal" id="h0060">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Majumder</surname>
            <given-names>M.A.</given-names>
          </name>
        </person-group>
        <article-title>National institutes of mental health data archive: privacy, consent, and diversity considerations and options for improvement</article-title>
        <source>AJOB Neurosci</source>
        <volume>13</volume>
        <year>2022</year>
        <fpage>3</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="pmid">33834954</pub-id>
      </element-citation>
    </ref>
    <ref id="b0065">
      <label>13</label>
      <element-citation publication-type="journal" id="h0065">
        <person-group person-group-type="author">
          <name>
            <surname>Prior</surname>
            <given-names>F.W.</given-names>
          </name>
          <name>
            <surname>Clark</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Commean</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Freymann</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Jaffe</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Kirby</surname>
            <given-names>J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>TCIA: an information resource to enable open science</article-title>
        <source>Annu Int Conf IEEE Eng Med Biol Soc</source>
        <volume>2013</volume>
        <year>2013</year>
        <fpage>1282</fpage>
        <lpage>1285</lpage>
        <pub-id pub-id-type="pmid">24109929</pub-id>
      </element-citation>
    </ref>
    <ref id="b0070">
      <label>14</label>
      <element-citation publication-type="journal" id="h0070">
        <person-group person-group-type="author">
          <name>
            <surname>Fedorov</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Longabaugh</surname>
            <given-names>W.J.R.</given-names>
          </name>
          <name>
            <surname>Pot</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Clunie</surname>
            <given-names>D.A.</given-names>
          </name>
          <name>
            <surname>Pieper</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Aerts</surname>
            <given-names>H.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>NCI imaging data commons</article-title>
        <source>Cancer Res</source>
        <volume>81</volume>
        <year>2021</year>
        <fpage>4188</fpage>
        <lpage>4193</lpage>
        <pub-id pub-id-type="pmid">34185678</pub-id>
      </element-citation>
    </ref>
    <ref id="b0075">
      <label>15</label>
      <element-citation publication-type="journal" id="h0075">
        <person-group person-group-type="author">
          <name>
            <surname>Halling-Brown</surname>
            <given-names>M.D.</given-names>
          </name>
          <name>
            <surname>Warren</surname>
            <given-names>L.M.</given-names>
          </name>
          <name>
            <surname>Ward</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Lewis</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Mackenzie</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Wallis</surname>
            <given-names>M.G.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>OPTIMAM mammography image database: a large-scale resource of mammography images and clinical data</article-title>
        <source>Radiol Artif Intell</source>
        <volume>3</volume>
        <year>2021</year>
        <fpage>e200103</fpage>
        <pub-id pub-id-type="pmid">33937853</pub-id>
      </element-citation>
    </ref>
    <ref id="b0080">
      <label>16</label>
      <element-citation publication-type="journal" id="h0080">
        <person-group person-group-type="author">
          <name>
            <surname>Moura</surname>
            <given-names>D.C.</given-names>
          </name>
          <name>
            <surname>Guevara Lopez</surname>
            <given-names>M.A.</given-names>
          </name>
        </person-group>
        <article-title>An evaluation of image descriptors combined with clinical data for breast cancer diagnosis</article-title>
        <source>Int J Comput Assist Radiol Surg</source>
        <volume>8</volume>
        <year>2013</year>
        <fpage>561</fpage>
        <lpage>574</lpage>
        <pub-id pub-id-type="pmid">23580025</pub-id>
      </element-citation>
    </ref>
    <ref id="b0085">
      <label>17</label>
      <element-citation publication-type="journal" id="h0085">
        <person-group person-group-type="author">
          <name>
            <surname>Marcus</surname>
            <given-names>D.S.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>T.H.</given-names>
          </name>
          <name>
            <surname>Parker</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Csernansky</surname>
            <given-names>J.G.</given-names>
          </name>
          <name>
            <surname>Morris</surname>
            <given-names>J.C.</given-names>
          </name>
          <name>
            <surname>Buckner</surname>
            <given-names>R.L.</given-names>
          </name>
        </person-group>
        <article-title>Open access series of imaging studies (OASIS): cross-sectional MRI data in young, middle aged, nondemented, and demented older adults</article-title>
        <source>J Cogn Neurosci</source>
        <volume>19</volume>
        <year>2007</year>
        <fpage>1498</fpage>
        <lpage>1507</lpage>
        <pub-id pub-id-type="pmid">17714011</pub-id>
      </element-citation>
    </ref>
    <ref id="b0090">
      <label>18</label>
      <element-citation publication-type="journal" id="h0090">
        <person-group person-group-type="author">
          <name>
            <surname>Ouyang</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Ghorbani</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Ebinger</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Langlotz</surname>
            <given-names>C.P.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Video-based AI for beat-to-beat assessment of cardiac function</article-title>
        <source>Nature</source>
        <volume>580</volume>
        <year>2020</year>
        <fpage>252</fpage>
        <lpage>256</lpage>
        <pub-id pub-id-type="pmid">32269341</pub-id>
      </element-citation>
    </ref>
    <ref id="b0095">
      <label>19</label>
      <element-citation publication-type="journal" id="h0095">
        <person-group person-group-type="author">
          <name>
            <surname>Leclerc</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Smistad</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Pedrosa</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Ostvik</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Cervenansky</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Espinosa</surname>
            <given-names>F.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep learning for segmentation using an open large-scale dataset in 2D echocardiography</article-title>
        <source>IEEE Trans Med Imaging</source>
        <volume>38</volume>
        <year>2019</year>
        <fpage>2198</fpage>
        <lpage>2210</lpage>
        <pub-id pub-id-type="pmid">30802851</pub-id>
      </element-citation>
    </ref>
    <ref id="b0100">
      <label>20</label>
      <element-citation publication-type="journal" id="h0100">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>X.S.</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>Y.F.</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Z.Y.</given-names>
          </name>
          <name>
            <surname>Bagheri</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Summers</surname>
            <given-names>R.M.</given-names>
          </name>
        </person-group>
        <article-title>ChestX-ray8: hospital-scale chest X-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases</article-title>
        <source>Proc IEEE Conf Comput Vis Pattern Recognit</source>
        <volume>2017</volume>
        <year>2017</year>
        <fpage>3462</fpage>
        <lpage>3471</lpage>
      </element-citation>
    </ref>
    <ref id="b0105">
      <label>21</label>
      <element-citation publication-type="journal" id="h0105">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>DPN: detail-preserving network with high resolution representation for efficient segmentation of retinal vessels</article-title>
        <source>J Ambient Intell Humaniz Comput</source>
        <volume>14</volume>
        <year>2023</year>
        <fpage>5689</fpage>
        <lpage>5702</lpage>
      </element-citation>
    </ref>
    <ref id="b0110">
      <label>22</label>
      <element-citation publication-type="journal" id="h0110">
        <person-group person-group-type="author">
          <name>
            <surname>Ning</surname>
            <given-names>W.S.</given-names>
          </name>
          <name>
            <surname>Lei</surname>
            <given-names>S.J.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>J.J.</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>Y.K.</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>P.R.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Q.Q.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Open resource of clinical data from patients with pneumonia for the prediction of COVID-19 outcomes via deep learning</article-title>
        <source>Nat Biomed Eng</source>
        <volume>4</volume>
        <year>2020</year>
        <fpage>1197</fpage>
        <lpage>1207</lpage>
        <pub-id pub-id-type="pmid">33208927</pub-id>
      </element-citation>
    </ref>
    <ref id="b0115">
      <label>23</label>
      <element-citation publication-type="journal" id="h0115">
        <person-group person-group-type="author">
          <name>
            <surname>CNCB-NGDC Members and Partners</surname>
          </name>
        </person-group>
        <article-title>Database resources of the National Genomics Data Center, China National Center for Bioinformation in 2023</article-title>
        <source>Nucleic Acids Res</source>
        <volume>51</volume>
        <year>2023</year>
        <fpage>D18</fpage>
        <lpage>D28</lpage>
        <pub-id pub-id-type="pmid">36420893</pub-id>
      </element-citation>
    </ref>
    <ref id="b0120">
      <label>24</label>
      <element-citation publication-type="journal" id="h0120">
        <person-group person-group-type="author">
          <name>
            <surname>Lindeberg</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>Scale invariant feature transform</article-title>
        <source>Scholarpedia J</source>
        <volume>7</volume>
        <year>2012</year>
        <fpage>10491</fpage>
      </element-citation>
    </ref>
    <ref id="b0125">
      <label>25</label>
      <element-citation publication-type="journal" id="h0125">
        <person-group person-group-type="author">
          <name>
            <surname>Pietikäinen</surname>
            <given-names>M.J.S.</given-names>
          </name>
        </person-group>
        <article-title>Local binary patterns</article-title>
        <source>Scholarpedia J</source>
        <volume>5</volume>
        <year>2010</year>
        <fpage>9775</fpage>
      </element-citation>
    </ref>
    <ref id="b0130">
      <label>26</label>
      <element-citation publication-type="journal" id="h0130">
        <person-group person-group-type="author">
          <name>
            <surname>Dalal</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Triggs</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>Histograms of oriented gradients for human detection</article-title>
        <source>IEEE Comput Soc Conf Comput Vis Pattern Recognit</source>
        <volume>1</volume>
        <year>2005</year>
        <fpage>886</fpage>
        <lpage>893</lpage>
      </element-citation>
    </ref>
    <ref id="b0135">
      <label>27</label>
      <element-citation publication-type="journal" id="h0135">
        <person-group person-group-type="author">
          <name>
            <surname>Qayyum</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Anwar</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Awais</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Majid</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Medical image retrieval using deep convolutional neural network</article-title>
        <source>Neurocomputing</source>
        <volume>266</volume>
        <year>2017</year>
        <fpage>8</fpage>
        <lpage>20</lpage>
      </element-citation>
    </ref>
    <ref id="b0140">
      <label>28</label>
      <element-citation publication-type="journal" id="h0140">
        <person-group person-group-type="author">
          <name>
            <surname>Fang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Deep triplet hashing network for case-based medical image retrieval</article-title>
        <source>Med Image Anal</source>
        <volume>69</volume>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">101981</object-id>
      </element-citation>
    </ref>
    <ref id="b0145">
      <label>29</label>
      <element-citation publication-type="journal" id="h0145">
        <person-group person-group-type="author">
          <name>
            <surname>Tan</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>Q.</given-names>
          </name>
        </person-group>
        <article-title>Efficientnet: rethinking model scaling for convolutional neural networks</article-title>
        <source>Proc Mach Learn Res</source>
        <volume>97</volume>
        <year>2019</year>
        <fpage>6105</fpage>
        <lpage>6114</lpage>
      </element-citation>
    </ref>
    <ref id="b0150">
      <label>30</label>
      <element-citation publication-type="journal" id="h0150">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>T.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>GSA: Genome Sequence Archive</article-title>
        <source>Genomics Proteomics Bioinformatics</source>
        <volume>15</volume>
        <year>2017</year>
        <fpage>14</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="pmid">28387199</pub-id>
      </element-citation>
    </ref>
    <ref id="b0155">
      <label>31</label>
      <element-citation publication-type="journal" id="h0155">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>A.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The Genome Sequence Archive Family: toward explosive data growth and diverse data types</article-title>
        <source>Genomics Proteomics Bioinformatics</source>
        <volume>19</volume>
        <year>2021</year>
        <fpage>578</fpage>
        <lpage>583</lpage>
        <pub-id pub-id-type="pmid">34400360</pub-id>
      </element-citation>
    </ref>
    <ref id="b0160">
      <label>32</label>
      <element-citation publication-type="journal" id="h0160">
        <person-group person-group-type="author">
          <name>
            <surname>Moore</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Maffitt</surname>
            <given-names>D.R.</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>K.E.</given-names>
          </name>
          <name>
            <surname>Kirby</surname>
            <given-names>J.S.</given-names>
          </name>
          <name>
            <surname>Clark</surname>
            <given-names>K.W.</given-names>
          </name>
          <name>
            <surname>Freymann</surname>
            <given-names>J.B.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>De-identification of medical images with retention of scientific research value</article-title>
        <source>Radiographics</source>
        <volume>35</volume>
        <year>2015</year>
        <fpage>727</fpage>
        <lpage>735</lpage>
        <pub-id pub-id-type="pmid">25969931</pub-id>
      </element-citation>
    </ref>
    <ref id="b0165">
      <label>33</label>
      <element-citation publication-type="journal" id="h0165">
        <person-group person-group-type="author">
          <name>
            <surname>Monteiro</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Costa</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Oliveira</surname>
            <given-names>J.L.</given-names>
          </name>
        </person-group>
        <article-title>A de-identification pipeline for ultrasound medical images in dicom format</article-title>
        <source>J Med Syst</source>
        <volume>41</volume>
        <year>2017</year>
        <fpage>89</fpage>
        <pub-id pub-id-type="pmid">28405948</pub-id>
      </element-citation>
    </ref>
  </ref-list>
  <sec id="s0085" sec-type="supplementary-material">
    <title>Supplementary material</title>
    <p id="p0120">The following are the Supplementary material to this article:<supplementary-material content-type="local-data" id="m0010"><caption><title>Supplementary Table S1</title><p>Number of individuals, studies, series, and images of each imaging modality</p></caption><media xlink:href="mmc1.docx"/></supplementary-material></p>
    <p id="p0125">
      <supplementary-material content-type="local-data" id="m0005">
        <caption>
          <title>Supplementary Table S2</title>
          <p>Number of individuals, studies, series, and images of each anatomical site</p>
        </caption>
        <media xlink:href="mmc2.docx"/>
      </supplementary-material>
    </p>
  </sec>
  <ack id="ak005">
    <title>Acknowledgments</title>
    <p id="p0110">This work was supported by grants from the <funding-source id="gp005">Strategic Priority Research Program of the Chinese Academy of Sciences</funding-source> (Grant No. XDB38050300), the <funding-source id="gp010">Genomics Data Center Operation and Maintenance of Chinese Academy of Sciences</funding-source> (Grant No. CAS-WX2022SDC-XK05), and the <funding-source id="gp015">Key Technology Talent Program of the Chinese Academy of Sciences</funding-source>, China.</p>
  </ack>
  <fn-group>
    <fn id="d36e118">
      <p id="np005">Peer review under responsibility of Beijing Institute of Genomics, Chinese Academy of Sciences / China National Center for Bioinformation and Genetics Society of China.</p>
    </fn>
    <fn id="s0080" fn-type="supplementary-material">
      <p id="p0115">Supplementary data to this article can be found online at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.gpb.2023.09.003" id="ir085">https://doi.org/10.1016/j.gpb.2023.09.003</ext-link>.</p>
    </fn>
  </fn-group>
</back>
<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_GPB734 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEmmc1 docx ?>
<?FILEmmc2 docx ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Genomics Proteomics Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Genomics Proteomics Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Genomics, Proteomics &amp; Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1672-0229</issn>
    <issn pub-type="epub">2210-3244</issn>
    <publisher>
      <publisher-name>Elsevier</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10928373</article-id>
    <article-id pub-id-type="pii">S1672-0229(23)00108-0</article-id>
    <article-id pub-id-type="doi">10.1016/j.gpb.2023.09.003</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Database</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>OBIA: An Open Biomedical Imaging Archive</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au005">
        <name>
          <surname>Jin</surname>
          <given-names>Enhui</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
        <xref rid="af020" ref-type="aff">4</xref>
        <xref rid="fn1" ref-type="fn">#</xref>
      </contrib>
      <contrib contrib-type="author" id="au010">
        <name>
          <surname>Zhao</surname>
          <given-names>Dongli</given-names>
        </name>
        <xref rid="af010" ref-type="aff">2</xref>
        <xref rid="fn1" ref-type="fn">#</xref>
      </contrib>
      <contrib contrib-type="author" id="au015">
        <name>
          <surname>Wu</surname>
          <given-names>Gangao</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
        <xref rid="af020" ref-type="aff">4</xref>
        <xref rid="fn1" ref-type="fn">#</xref>
      </contrib>
      <contrib contrib-type="author" id="au020">
        <name>
          <surname>Zhu</surname>
          <given-names>Junwei</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au025">
        <name>
          <surname>Wang</surname>
          <given-names>Zhonghuang</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
        <xref rid="af020" ref-type="aff">4</xref>
      </contrib>
      <contrib contrib-type="author" id="au030">
        <name>
          <surname>Wei</surname>
          <given-names>Zhiyao</given-names>
        </name>
        <xref rid="af010" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author" id="au035">
        <name>
          <surname>Zhang</surname>
          <given-names>Sisi</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au040">
        <name>
          <surname>Wang</surname>
          <given-names>Anke</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au045">
        <name>
          <surname>Tang</surname>
          <given-names>Bixia</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au050">
        <name>
          <surname>Chen</surname>
          <given-names>Xu</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au055">
        <name>
          <surname>Sun</surname>
          <given-names>Yanling</given-names>
        </name>
        <email>sunyanling@big.ac.cn</email>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <contrib contrib-type="author" id="au060">
        <name>
          <surname>Zhang</surname>
          <given-names>Zhe</given-names>
        </name>
        <email>tj.zhe.zhang@gmail.com</email>
        <xref rid="af025" ref-type="aff">5</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <contrib contrib-type="author" id="au065">
        <name>
          <surname>Zhao</surname>
          <given-names>Wenming</given-names>
        </name>
        <email>zhaowm@big.ac.cn</email>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="af015" ref-type="aff">3</xref>
        <xref rid="af020" ref-type="aff">4</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <contrib contrib-type="author" id="au070">
        <name>
          <surname>Meng</surname>
          <given-names>Yuanguang</given-names>
        </name>
        <email>meng6512@vip.sina.com</email>
        <xref rid="af010" ref-type="aff">2</xref>
        <xref rid="af025" ref-type="aff">5</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <aff id="af005"><label>1</label>National Genomics Data Center, Beijing Institute of Genomics, Chinese Academy of Sciences and China National Center for Bioinformation, Beijing 100101, China</aff>
      <aff id="af010"><label>2</label>Chinese People’s Liberation Army (PLA) Medical School, Beijing 100853, China</aff>
      <aff id="af015"><label>3</label>CAS Key Laboratory of Genome Sciences and Information, Beijing Institute of Genomics, Chinese Academy of Sciences and China National Center for Bioinformation, Beijing 100101, China</aff>
      <aff id="af020"><label>4</label>University of Chinese Academy of Sciences, Beijing 100049, China</aff>
      <aff id="af025"><label>5</label>Department of Obstetrics and Gynecology, Seventh Medical Center of Chinese PLA General Hospital, Beijing 100700, China</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>⁎</label>Corresponding authors. <email>sunyanling@big.ac.cn</email><email>tj.zhe.zhang@gmail.com</email><email>zhaowm@big.ac.cn</email><email>meng6512@vip.sina.com</email></corresp>
      <fn id="fn1">
        <label>#</label>
        <p id="np010">Equal contribution.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>06</day>
      <month>10</month>
      <year>2023</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="ppub">
      <month>10</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>06</day>
      <month>10</month>
      <year>2023</year>
    </pub-date>
    <volume>21</volume>
    <issue>5</issue>
    <fpage>1059</fpage>
    <lpage>1065</lpage>
    <history>
      <date date-type="received">
        <day>28</day>
        <month>5</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>26</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>9</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 Beijing Institute of Genomics, Chinese Academy of Sciences / China National Center for Bioinformation and Genetics Society of China</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="ab005">
      <p>With the development of artificial intelligence (AI) technologies, <bold>biomedical imaging</bold> data play an important role in scientific research and clinical application, but the available resources are limited. Here we present <bold>Open Biomedical Imaging Archive</bold> (OBIA), a repository for archiving biomedical imaging and related clinical data. OBIA adopts five data objects (Collection, Individual, Study, Series, and Image) for data organization, and accepts the submission of biomedical images of multiple modalities, organs, and diseases. In order to protect personal privacy, OBIA has formulated a unified <bold>de-identification</bold> and <bold>quality control</bold> process. In addition, OBIA provides friendly and intuitive web interfaces for data submission, browsing, and retrieval, as well as image retrieval. As of September 2023, OBIA has housed data for a total of 937 individuals, 4136 studies, 24,701 series, and 1,938,309 images covering 9 modalities and 30 anatomical sites. Collectively, OBIA provides a reliable platform for biomedical imaging data management and offers free open access to all publicly available data to support research activities throughout the world. OBIA can be accessed at <ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/obia" id="ir005">https://ngdc.cncb.ac.cn/obia</ext-link>.</p>
    </abstract>
    <kwd-group id="kg005">
      <title>Keywords</title>
      <kwd>Open Biomedical Imaging Archive</kwd>
      <kwd>Database</kwd>
      <kwd>Biomedical imaging</kwd>
      <kwd>De-identification</kwd>
      <kwd>Quality control</kwd>
    </kwd-group>
  </article-meta>
  <notes>
    <p id="ms005">Handled by Yudong Zhang</p>
  </notes>
</front>
<body>
  <sec id="s0005">
    <title>Introduction</title>
    <p id="p0010">The introduction of advanced imaging technologies has greatly facilitated the development of non-invasive diagnoses. Currently, biomedical images can clearly depict the internal structure (anatomy), morphology, and physiological functions from the molecular scale to the cellular, organ, tissue, lesion, and even the entire organism <xref rid="b0005" ref-type="bibr">[1]</xref>, providing crucial evidence for diagnosis and treatment response assessment <xref rid="b0010" ref-type="bibr">[2]</xref>, <xref rid="b0015" ref-type="bibr">[3]</xref>. Imaging data generated during patient visits has formed a huge accumulation. However, incomplete sharing systems make it challenging for researchers and clinicians to collaborate on utilizing these images to gain significant insights into health and disease <xref rid="b0020" ref-type="bibr">[4]</xref>. Furthermore, the demand for rapid diagnosis promotes the application of artificial intelligence (AI) in biomedical imaging, and the development of reliable and robust AI algorithms requires sufficiently large and representative image datasets <xref rid="b0025" ref-type="bibr">[5]</xref>, <xref rid="b0030" ref-type="bibr">[6]</xref>. Thus, high-quality biomedical imaging data sharing plays an important role in promoting scientific discoveries and improving diagnostic accuracy.</p>
    <p id="p0015">The National Institutes of Health (NIH) in America sponsors several repositories. The Medical Imaging and Data Resource Center (MIDRC) <xref rid="b0035" ref-type="bibr">[7]</xref> serves as an open-access platform for COVID-19-related medical images and associated data. Image and Data Archive (IDA) <xref rid="b0040" ref-type="bibr">[8]</xref>, NITRC Image Repository (NITRC-IR) <xref rid="b0045" ref-type="bibr">[9]</xref>, Federal Interagency Traumatic Brain Injury Research (FITBIR) <xref rid="b0050" ref-type="bibr">[10]</xref>, OpenNeuro <xref rid="b0055" ref-type="bibr">[11]</xref>, and National Institute of Mental Health Data Archive (NDA) <xref rid="b0060" ref-type="bibr">[12]</xref> are dedicated to collecting neuro and brain imaging. The Cancer Imaging Archive (TCIA) <xref rid="b0065" ref-type="bibr">[13]</xref> and Imaging Data Commons (IDC) <xref rid="b0070" ref-type="bibr">[14]</xref> are cancer imaging repertories, with TCIA providing images locally and IDC affording collections in the Cancer Research Data Commons (CRDC) cloud environment. Regarding breast cancer, the Cancer Research United Kingdom (UK) funds the OPTIMAM Mammography Image Database (OMI-DB) <xref rid="b0075" ref-type="bibr">[15]</xref>, and the University of Porto in Portugal funds the Breast Cancer Digital Repository (BCDR) <xref rid="b0080" ref-type="bibr">[16]</xref>, providing annotated breast cancer images and clinical details. Most of these repositories support data de-identification and quality control, except NITRC-IR and IDC. Additionally, some universities or institutions provide open-source datasets, such as Open Access Series of Imaging Studies (OASIS) <xref rid="b0085" ref-type="bibr">[17]</xref>, EchoNet-Dynamic <xref rid="b0090" ref-type="bibr">[18]</xref>, Cardiac Acquisitions for Multi-structure Ultrasound Segmentation (CAMUS) project <xref rid="b0095" ref-type="bibr">[19]</xref>, Chest X-ray <xref rid="b0100" ref-type="bibr">[20]</xref>, and Structured Analysis of the Retina (STARE) <xref rid="b0105" ref-type="bibr">[21]</xref>. In China, the Huazhong University of Science and Technology provides an open resource named integrative Computed Tomography (CT) images and CFs for COVID-19 (iCTCF) <xref rid="b0110" ref-type="bibr">[22]</xref>, which includes CT images and clinical features of patients with pneumonia (including COVID-19 pneumonia). There is still a lack of databases that are dedicated to storing and accepting submissions for various diseases and modalities.</p>
    <p id="p0020">To address this issue, we established the Open Biomedical Imaging Archive (OBIA; <ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/obia" id="ir015">https://ngdc.cncb.ac.cn/obia</ext-link>), a repository for archiving biomedical imaging data and related clinical data. As a core database resource in the National Genomics Data Center (NGDC) <xref rid="b0115" ref-type="bibr">[23]</xref>, part of the China National Center for Bioinformation (CNCB; <ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/" id="ir020">https://ngdc.cncb.ac.cn/</ext-link>), OBIA accepts image submissions from all over the world and provides free open access to all publicly available data to support global research activities. OBIA supports de-identification, management, and quality control of imaging data, providing data services such as browsing, retrieval, and downloading, thus promoting the reuse of existing imaging data and clinical data.</p>
  </sec>
  <sec id="s0010">
    <title>Implementation</title>
    <sec id="s0015">
      <title>Database construction</title>
      <p id="p0025">OBIA is implemented using Spring Boot (a framework easy to create standalone Java applications; <ext-link ext-link-type="uri" xlink:href="https://spring.io/projects/spring-boot" id="ir025">https://spring.io/projects/spring-boot</ext-link>) as the backend framework. The frontend user interfaces are developed using Vue.js (an approachable, performant, and versatile framework for building web user interfaces; <ext-link ext-link-type="uri" xlink:href="https://vuejs.org/" id="ir030">https://vuejs.org/</ext-link>) and Element UI (a Vue 2.0-based component library for developers, designers, and product managers; <ext-link ext-link-type="uri" xlink:href="https://element.eleme.cn/" id="ir035">https://element.eleme.cn/</ext-link>). The charts on the web page are constructed using ECharts (an open-source JavaScript visualization library; <ext-link ext-link-type="uri" xlink:href="https://echarts.apache.org" id="ir040">https://echarts.apache.org</ext-link>). All metadata information is stored in MySQL (a free and popular relational database management system; <ext-link ext-link-type="uri" xlink:href="https://www.mysql.com/" id="ir045">https://www.mysql.com/</ext-link>).</p>
    </sec>
    <sec id="s0020">
      <title>Image retrieval</title>
      <p id="p0030">Deep learning-based methods, such as scale-invariant feature transform (SIFT) <xref rid="b0120" ref-type="bibr">[24]</xref>, local binary patterns (LBP) <xref rid="b0125" ref-type="bibr">[25]</xref>, and histogram of oriented gradient (HOG) <xref rid="b0130" ref-type="bibr">[26]</xref>, demonstrate better performance compared to traditional methods. Deep neural networks excel at extracting superior features for retrieving multimodal medical images of various body organs <xref rid="b0135" ref-type="bibr">[27]</xref> and enhancing ranking performance in the case of small sample sizes <xref rid="b0140" ref-type="bibr">[28]</xref>.</p>
      <p id="p0035">In OBIA, we leveraged TCIA multi-modal cancer data and utilized EfficientNet <xref rid="b0145" ref-type="bibr">[29]</xref> as the feature extractor. We trained the model using a triplet network and an attention module to compress the image into a discrete hash value (<xref rid="f0005" ref-type="fig">Figure 1</xref>). We subsequently convert the trained model into TensorRT format to accelerate inference performance and reduce inference latency. We converted the trained model into TensorRT format to enhance inference performance and reduce latency. To store the hash codes, we employed Faiss, a high-performance similarity search library developed by Facebook AI Research and commonly used in deep learning. We computed image similarity using the hamming distance and returned the most similar images to the query. Our model achieved a mean average precision (MAP) value that surpassed the performance of existing advanced image retrieval models on the TCIA dataset.<fig id="f0005"><label>Figure 1</label><caption><p><bold>Deep triplet hashing based on attention and layer fusion module</bold></p><p>The model uses EfficientNet-B6 as the backbone network and utilizes the CBAM attention module in Block 5 to obtain feature maps. Layer fusion is employed in the fully connected layers, and focal loss and triplet loss are used to generate hash code and class embedding. CBAM, convolutional block attention module.</p></caption><graphic xlink:href="gr1" id="lk00005"/></fig></p>
    </sec>
  </sec>
  <sec id="s0025">
    <title>Database content and usage</title>
    <sec id="s0030">
      <title>Data model</title>
      <p id="p0040">Imaging data in OBIA are organized into five objects: Collection, Individual, Study, Series, and Image (<xref rid="f0010" ref-type="fig">Figure 2</xref>). “Collection”, bearing an accession number prefixed with “OBIA”, provides an overall description for a complete submission. “Individual”, possessing an accession number prefixed with “I”, defines the characteristics of a human or non-human organism receiving, or registered to receive, healthcare services. “Study”, adopting an accession number prefixed with “S”, contains descriptive information about radiological examinations performed on an individual. A study may be divided into one or more “Series” according to different logics, such as body part or orientation. “Image” describes the pixel data of a single Digital Imaging and Communications in Medicine (DICOM) file, and an image is related to a single series within a single study. Based on these standardized data objects, OBIA connects the image structure defined by the DICOM standard with actual research projects, realizing data sharing and exchange. Besides, each collection in OBIA is linked to BioProject <xref rid="b0150" ref-type="bibr">[30]</xref> (<ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/bioproject/" id="ir050">https://ngdc.cncb.ac.cn/bioproject/</ext-link>) to provide descriptive metadata about the research project. And the individual in OBIA can be associated with GSA-Human <xref rid="b0155" ref-type="bibr">[31]</xref> (<ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/gsa-human/" id="ir055">https://ngdc.cncb.ac.cn/gsa-human/</ext-link>) by individual accession number, if available, which links imaging data with genomic data for researchers to perform multi-omics analysis.<fig id="f0010"><label>Figure 2</label><caption><p><bold>OBIA data model</bold></p><p>The Collection and Individual in OBIA can be linked to BioProject and GSA-Human, respectively. The accession numbers for data objects, including Collection, Individual, and Study, are indicated in the gray boxes. Collection accession numbers have a prefix of “OBIA” followed by four consecutive digits, Individual accession numbers have a prefix of “I” followed by six consecutive digits, and Study accession numbers have a prefix of “S” followed by eight consecutive digits. OBIA, Open Biomedical Imaging Archive.</p></caption><graphic xlink:href="gr2" id="lk00010"/></fig></p>
    </sec>
    <sec id="s0035">
      <title>De-identification and quality control</title>
      <p id="p0045">Images may contain protected health information (PHI) and require appropriate handling to minimize the risk of patient privacy breaches. In order to retain as much valuable scientific information as possible while removing PHI, OBIA provides a unified de-identification and quality control mechanism (<xref rid="f0015" ref-type="fig">Figure 3</xref>) based on the DICOM PS 3.15 Appendix E: Attribute Confidentiality Profile (<ext-link ext-link-type="uri" xlink:href="https://www.dicomstandard.org/" id="ir060">https://www.dicomstandard.org/</ext-link>). The key elements and rules we adopted include: (1) clean pixel data; (2) clean descriptors; (3) retain longitudinal temporal information modified dates; (4) retain patient characteristics; (5) retain device identity; and (6) retain safe private tags.<fig id="f0015"><label>Figure 3</label><caption><p><bold>OBIA de-identification and quality control mechanism</bold></p><p>Flowchart shows image submission, de-identification, and quality control steps. The de-identification steps include using CTP to process standard tags and PyDicom to handle private tags, and the problematic images will be isolated. The quality control steps include review of reports generated by TagSniffer and visual inspection of image pixels by OBIA staff. CTP, clinical trial processor.</p></caption><graphic xlink:href="gr3" id="lk00015"/></fig></p>
      <p id="p0050">OBIA utilizes the Radiological Society of North America (RSNA) MIRC clinical trial processor (CTP) (<ext-link ext-link-type="uri" xlink:href="https://mircwiki.rsna.org/index.php?title=MIRC_CTP" id="ir065">https://mircwiki.rsna.org/index.php?title=MIRC_CTP</ext-link>) for most of the de-identification work. We constructed a CTP pipeline and developed a common base de-identification script to remove or blank certain standard tags containing or potentially containing PHI. This script also maps local patient IDs to OBIA individual accessions. As for private tags, since they are vendor-specific and scanner-specific and can contain almost anything, we use PyDicom (<ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/pydicom/" id="ir070">https://pypi.org/project/pydicom/</ext-link>) to retain attributes that are purely numeric. Some studies determine private element definitions by reading manufacturers’ DICOM conformance statements <xref rid="b0160" ref-type="bibr">[32]</xref>. However, in our practice, the wide variety of image sources made this work too time-consuming, and some conformance statements were not available. In addition to metadata elements, ultrasounds or screen captures usually add some “burned-in” annotations in the pixels data to interpret the images, which may also contain PHI. We provide a filter stage to identify these images.</p>
      <p id="p0055">After the de-identification process is completed, OBIA runs a quality control procedure. Some problematic images are isolated, such as images with a blank header or missing patient ID, corrupted images, other patient images mixed in, <italic>etc</italic>. Submitters can provide relevant information to repair the images or discard them entirely. Duplicate images are removed, leaving only one. Then we use TagSniffer (<ext-link ext-link-type="uri" xlink:href="https://github.com/stlstevemoore/dicom-tag-sniffer" id="ir075">https://github.com/stlstevemoore/dicom-tag-sniffer</ext-link>) to generate a report for all images. All DICOM elements in the report are carefully reviewed to ensure that they are free of PHI, and certain values (<italic>e.g.</italic>, patient ID, study date) are modified as expected. In addition, we perform a visual inspection of each image series to ensure that no PHI is contained in the pixel values and that the images are visible and uncorrupted.</p>
    </sec>
    <sec id="s0040">
      <title>Data browse and retrieval</title>
      <p id="p0060">OBIA provides user-friendly web interfaces for data query and browsing. Users can browse data of interest by specifying non-image information (<italic>e.g.</italic>, age, gender, and disease) and/or the imaging data extracted from the DICOM header (<italic>e.g.</italic>, modality and anatomical site). Users can also search for data by entering the accession number. OBIA allows users to browse the basic information of collection (title, description, keywords, submitter, data accessibility, <italic>etc</italic>.), individual, study (study description, study age, study date, <italic>etc</italic>.), series (modality, anatomical site, series description, <italic>etc</italic>.), and view thumbnails of images.</p>
      <p id="p0065">OBIA also provides image retrieval functionality designed to find images similar to a query. Users can use this function by clicking the “Image Retrieval” button on the homepage. After uploading the image, the image retrieval model employs the hamming distance to return the top 30 images that are closest to the queried image, serving as the nearest neighbor images. Users have the option to click on these returned images and review their respective image metadata.</p>
    </sec>
    <sec id="s0045">
      <title>Data access and download</title>
      <p id="p0070">OBIA states that the data access policies are set by data submitters. There are two different types of data accessibility: open access and controlled access. Open access means that all data is public for global researchers if released, whereas controlled access means that data can be downloadable only after being authorized by the submitter. OBIA supports online data requests and reviews. Before applying, users need to register and log into OBIA via the Beijing Institute of Genomics (BIG) single sign-on (SSO; <ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/sso/" id="ir080">https://ngdc.cncb.ac.cn/sso/</ext-link>) system. Applicants shall provide their basic information, specify the scope of data usage, and promise not to attempt to restore the privacy information in the data. The download link will only be provided to the applicant if the data owner approves the request.</p>
    </sec>
    <sec id="s0050">
      <title>Data submission</title>
      <p id="p0075">OBIA accepts submissions of biomedical imaging data in DICOM format from clinical or specific research projects. To create a submission, users need to log in, fill in the basic information about the collection, and email the necessary clinical information. Image data will be transferred to OBIA offline after de-identification. Users can either use the de-identification process recommended by OBIA or apply their own methods to de-identify the image. Quality control will be conducted for all the data. OBIA will assign a unique accession number to each collection, individual, and study and arrange images into a standard organization. In order to ensure the security of submitted data, backup copies will be stored on physically separate disks. Finally, metadata will be extracted from the image file headers and stored in the database to support data queries.</p>
    </sec>
    <sec id="s0055">
      <title>Data statistics</title>
      <p id="p0080">As of September 2023, OBIA has housed a total of 937 individuals, 4136 studies, 24,701 series, and 1,938,309 images, covering 9 modalities and 30 anatomical sites. Representative imaging modalities are CT, magnetic resonance (MR), and digital radiography (DX) (<xref rid="s0085" ref-type="sec">Table S1</xref>). Anatomical sites include the abdomen, breast, chest, head, liver, and pelvis (<xref rid="s0085" ref-type="sec">Table S2</xref>). The first batch of collections submitted to OBIA came from the Chinese People’s Liberation Army (PLA) General Hospital, including imaging data of three major gynecological tumors: endometrial cancer, ovarian cancer, and cervical cancer. The data were divided into four collections, and <xref rid="t0005" ref-type="table">Table 1</xref> shows the number of individuals, studies, series, and images of each collection. In addition, we collected associated clinical metadata, such as demographic data, medical history, family history, diagnosis, pathological types, and treatment methods.<table-wrap position="float" id="t0005"><label>Table 1</label><caption><p>Number of individuals, studies, series, and images of each collection</p></caption><table frame="hsides" rules="groups"><thead><tr><th><bold>Accession No.</bold></th><th><bold>Disease</bold></th><th><bold>No. of individuals</bold></th><th><bold>No. of studies</bold></th><th><bold>No. of series</bold></th><th><bold>No. of images</bold></th></tr></thead><tbody><tr><td>OBIA0001</td><td>Endometrial cancer</td><td>316</td><td>1587</td><td>8941</td><td>779,171</td></tr><tr><td>OBIA0002</td><td>Ovarian cancer</td><td>202</td><td>1548</td><td>7151</td><td>548,174</td></tr><tr><td>OBIA0003</td><td>Cervical cancer</td><td>117</td><td>675</td><td>3943</td><td>307,101</td></tr><tr><td>OBIA0004</td><td>Endometrial cancer</td><td>302</td><td>326</td><td>4666</td><td>303,863</td></tr></tbody></table><table-wrap-foot><fn><p><italic>Note</italic>: The data statistics are up to September 2023.</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
  </sec>
  <sec id="s0060">
    <title>Perspectives and concluding remarks</title>
    <p id="p0085">OBIA is a centralized repository of de-identified biomedical imaging data. Different from existing related databases, OBIA is characterized by publishing imaging data and clinical information from a wide range of imaging modalities in a common DICOM format. Algorithm developers can convert and format as needed, and clinicians and researchers can combine clinical data with images for further analysis. Unlike the Health Insurance Portability and Accountability Act (HIPAA) in the United States and the General Data Protection Regulation (GDPR) in Europe, China has a Personal Information Protection Law (PIPL), a Data Security Law, and other regulations for medical records and health information, which include elements similar to HIPAA and GDPR. OBIA strictly follows Chinese legal regulations for data processing, quality control, and data sharing, especially for removing PHI. It also promotes data sharing among data submitters and users while ensuring compliance with these laws. As a core database resource within NGDC, OBIA is seamlessly integrated with BioProject and GSA-Human, facilitating the harmonious integration of imaging and genomic data to support multi-omics analysis. In essence, OBIA serves as a dependable platform for sharing clinically relevant imaging data among researchers from diverse institutions, effectively bridging the gap within China’s biomedical imaging database landscape.</p>
    <p id="p0090">In the future, we will continue to upgrade the infrastructure of OBIA and increase security protection measures to realize long-term secure storage, management, and access to a large volume of images. At the same time, we will collect more types of biomedical imaging data and gradually increase the corresponding genomic data to expand our data resources. To facilitate data submission and ensure privacy security, we will further optimize the image de-identification process and explore the use of the machine learning-based optical character recognition (OCR) <xref rid="b0165" ref-type="bibr">[33]</xref> method to remove PHI from image pixels. We will also improve quality control and background automatic review processes to speed up data submission. In compliance with applicable regulations and ethical norms, OBIA’s goal is to preserve as much effective image metadata as possible to provide researchers with high-quality imaging data. Furthermore, we plan to develop more intuitive and interactive web interfaces according to users’ needs, increase database functions, and integrate related online tools to help analyze biomedical images. In addition, we intend to optimize the image retrieval model to offer users more convenient and precise image retrieval services. Finally, we call for collaborators to collectively build OBIA, submit image data, break down data silos, catalyze new biomedical discoveries, and provide the possibility to create personalized treatments.</p>
  </sec>
  <sec id="s0065">
    <title>Ethical statement</title>
    <p id="p0095">The collection of human imaging data was approved by the Local Ethical Committees in the First Medical Center of the Chinese PLA General Hospital (Approval No. S2022-403). The written informed consent was obtained from the participating patients.</p>
  </sec>
  <sec sec-type="data-availability" id="ce.section_trv_lyv_pzb">
    <title>Data availability</title>
    <p id="p0516">OBIA is publicly available at <ext-link ext-link-type="uri" xlink:href="https://ngdc.cncb.ac.cn/obia" id="PC_linkl1ulLbDAle">https://ngdc.cncb.ac.cn/obia</ext-link>.</p>
  </sec>
  <sec sec-type="COI-statement" id="s0070">
    <title>Competing interests</title>
    <p id="p0100">The authors have declared no competing interests.</p>
  </sec>
  <sec id="s0075">
    <title>CRediT authorship contribution statement</title>
    <p id="p0105"><bold>Enhui Jin:</bold> Investigation, Methodology, Software, Writing – original draft. <bold>Dongli Zhao:</bold> Resources. <bold>Gangao Wu:</bold> Investigation, Methodology, Software, Writing – original draft. <bold>Junwei Zhu:</bold> Software. <bold>Zhonghuang Wang:</bold> Methodology. <bold>Zhiyao Wei:</bold> Resources. <bold>Sisi Zhang:</bold> Methodology. <bold>Anke Wang:</bold> Software, Writing – original draft. <bold>Bixia Tang:</bold> Resources. <bold>Xu Chen:</bold> Resources. <bold>Yanling Sun:</bold> Investigation, Methodology, Writing – review &amp; editing, Project administration. <bold>Zhe Zhang:</bold> Investigation, Methodology, Writing – review &amp; editing. <bold>Wenming Zhao:</bold> Conceptualization, Methodology, Writing – review &amp; editing, Supervision, Funding acquisition. <bold>Yuanguang Meng:</bold> Conceptualization, Methodology, Writing – review &amp; editing. All authors have read and approved the final manuscript.</p>
  </sec>
</body>
<back>
  <ref-list id="bi005">
    <title>References</title>
    <ref id="b0005">
      <label>1</label>
      <element-citation publication-type="journal" id="h0005">
        <person-group person-group-type="author">
          <name>
            <surname>Wallyn</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Anton</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Akram</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Vandamme</surname>
            <given-names>T.F.</given-names>
          </name>
        </person-group>
        <article-title>Biomedical imaging: principles, technologies, clinical aspects, contrast agents, limitations and future trends in nanomedicines</article-title>
        <source>Pharm Res</source>
        <volume>36</volume>
        <year>2019</year>
        <fpage>78</fpage>
        <pub-id pub-id-type="pmid">30945009</pub-id>
      </element-citation>
    </ref>
    <ref id="b0010">
      <label>2</label>
      <element-citation publication-type="journal" id="h0010">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>S.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Machine learning in electromagnetics with applications to biomedical imaging: a review</article-title>
        <source>IEEE Antennas Propag Mag</source>
        <volume>63</volume>
        <year>2021</year>
        <fpage>39</fpage>
        <lpage>51</lpage>
      </element-citation>
    </ref>
    <ref id="b0015">
      <label>3</label>
      <element-citation publication-type="journal" id="h0015">
        <person-group person-group-type="author">
          <name>
            <surname>Anwar</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Majid</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Qayyum</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Awais</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Alnowami</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>M.K.</given-names>
          </name>
        </person-group>
        <article-title>Medical image analysis using convolutional neural networks: a review</article-title>
        <source>J Med Syst</source>
        <volume>42</volume>
        <year>2018</year>
        <fpage>226</fpage>
        <pub-id pub-id-type="pmid">30298337</pub-id>
      </element-citation>
    </ref>
    <ref id="b0020">
      <label>4</label>
      <element-citation publication-type="journal" id="h0020">
        <person-group person-group-type="author">
          <name>
            <surname>Moody</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Perspective: the big picture</article-title>
        <source>Nature</source>
        <volume>502</volume>
        <year>2013</year>
        <fpage>S95</fpage>
        <pub-id pub-id-type="pmid">24187705</pub-id>
      </element-citation>
    </ref>
    <ref id="b0025">
      <label>5</label>
      <element-citation publication-type="journal" id="h0025">
        <person-group person-group-type="author">
          <name>
            <surname>Willemink</surname>
            <given-names>M.J.</given-names>
          </name>
          <name>
            <surname>Koszek</surname>
            <given-names>W.A.</given-names>
          </name>
          <name>
            <surname>Hardell</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Fleischmann</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Harvey</surname>
            <given-names>H.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Preparing medical imaging data for machine learning</article-title>
        <source>Radiology</source>
        <volume>295</volume>
        <year>2020</year>
        <fpage>4</fpage>
        <lpage>15</lpage>
        <pub-id pub-id-type="pmid">32068507</pub-id>
      </element-citation>
    </ref>
    <ref id="b0030">
      <label>6</label>
      <element-citation publication-type="journal" id="h0030">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Shrivastava</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Gupta</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Revisiting unreasonable effectiveness of data in deep learning era</article-title>
        <source>IEEE Int Conf Comput Vis</source>
        <year>2017</year>
        <fpage>843</fpage>
        <lpage>852</lpage>
      </element-citation>
    </ref>
    <ref id="b0035">
      <label>7</label>
      <element-citation publication-type="journal" id="h0035">
        <person-group person-group-type="author">
          <name>
            <surname>Baughan</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Whitney</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Drukker</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Sahiner</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>T.T.</given-names>
          </name>
          <name>
            <surname>Hyun</surname>
            <given-names>K.J.G.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Sequestration of imaging studies in MIDRC: a multi-institutional data commons</article-title>
        <source>Proc SPIE</source>
        <volume>12035</volume>
        <year>2022</year>
        <fpage>91</fpage>
        <lpage>98</lpage>
      </element-citation>
    </ref>
    <ref id="b0040">
      <label>8</label>
      <element-citation publication-type="journal" id="h0040">
        <person-group person-group-type="author">
          <name>
            <surname>Crawford</surname>
            <given-names>K.L.</given-names>
          </name>
          <name>
            <surname>Neu</surname>
            <given-names>S.C.</given-names>
          </name>
          <name>
            <surname>Toga</surname>
            <given-names>A.W.</given-names>
          </name>
        </person-group>
        <article-title>The image and data archive at the laboratory of neuro imaging</article-title>
        <source>Neuroimage</source>
        <volume>124</volume>
        <year>2016</year>
        <fpage>1080</fpage>
        <lpage>1083</lpage>
        <pub-id pub-id-type="pmid">25982516</pub-id>
      </element-citation>
    </ref>
    <ref id="b0045">
      <label>9</label>
      <element-citation publication-type="journal" id="h0045">
        <person-group person-group-type="author">
          <name>
            <surname>Kennedy</surname>
            <given-names>D.N.</given-names>
          </name>
          <name>
            <surname>Haselgrove</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Riehl</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Preuss</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Buccigrossi</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>The NITRC image repository</article-title>
        <source>Neuroimage</source>
        <volume>124</volume>
        <year>2016</year>
        <fpage>1069</fpage>
        <lpage>1073</lpage>
        <pub-id pub-id-type="pmid">26044860</pub-id>
      </element-citation>
    </ref>
    <ref id="b0050">
      <label>10</label>
      <element-citation publication-type="journal" id="h0050">
        <person-group person-group-type="author">
          <name>
            <surname>Thompson</surname>
            <given-names>H.J.</given-names>
          </name>
          <name>
            <surname>Vavilala</surname>
            <given-names>M.S.</given-names>
          </name>
          <name>
            <surname>Rivara</surname>
            <given-names>F.P.</given-names>
          </name>
        </person-group>
        <article-title>Common data elements and federal interagency traumatic brain injury research informatics system for TBI research</article-title>
        <source>Annu Rev Nurs Res</source>
        <volume>33</volume>
        <year>2015</year>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="pmid">25946381</pub-id>
      </element-citation>
    </ref>
    <ref id="b0055">
      <label>11</label>
      <element-citation publication-type="journal" id="h0055">
        <person-group person-group-type="author">
          <name>
            <surname>Markiewicz</surname>
            <given-names>C.J.</given-names>
          </name>
          <name>
            <surname>Gorgolewski</surname>
            <given-names>K.J.</given-names>
          </name>
          <name>
            <surname>Feingold</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Blair</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Halchenko</surname>
            <given-names>Y.O.</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>E.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The OpenNeuro resource for sharing of neuroscience data</article-title>
        <source>Elife</source>
        <volume>10</volume>
        <year>2021</year>
        <fpage>e71774</fpage>
        <pub-id pub-id-type="pmid">34658334</pub-id>
      </element-citation>
    </ref>
    <ref id="b0060">
      <label>12</label>
      <element-citation publication-type="journal" id="h0060">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Majumder</surname>
            <given-names>M.A.</given-names>
          </name>
        </person-group>
        <article-title>National institutes of mental health data archive: privacy, consent, and diversity considerations and options for improvement</article-title>
        <source>AJOB Neurosci</source>
        <volume>13</volume>
        <year>2022</year>
        <fpage>3</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="pmid">33834954</pub-id>
      </element-citation>
    </ref>
    <ref id="b0065">
      <label>13</label>
      <element-citation publication-type="journal" id="h0065">
        <person-group person-group-type="author">
          <name>
            <surname>Prior</surname>
            <given-names>F.W.</given-names>
          </name>
          <name>
            <surname>Clark</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Commean</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Freymann</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Jaffe</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Kirby</surname>
            <given-names>J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>TCIA: an information resource to enable open science</article-title>
        <source>Annu Int Conf IEEE Eng Med Biol Soc</source>
        <volume>2013</volume>
        <year>2013</year>
        <fpage>1282</fpage>
        <lpage>1285</lpage>
        <pub-id pub-id-type="pmid">24109929</pub-id>
      </element-citation>
    </ref>
    <ref id="b0070">
      <label>14</label>
      <element-citation publication-type="journal" id="h0070">
        <person-group person-group-type="author">
          <name>
            <surname>Fedorov</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Longabaugh</surname>
            <given-names>W.J.R.</given-names>
          </name>
          <name>
            <surname>Pot</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Clunie</surname>
            <given-names>D.A.</given-names>
          </name>
          <name>
            <surname>Pieper</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Aerts</surname>
            <given-names>H.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>NCI imaging data commons</article-title>
        <source>Cancer Res</source>
        <volume>81</volume>
        <year>2021</year>
        <fpage>4188</fpage>
        <lpage>4193</lpage>
        <pub-id pub-id-type="pmid">34185678</pub-id>
      </element-citation>
    </ref>
    <ref id="b0075">
      <label>15</label>
      <element-citation publication-type="journal" id="h0075">
        <person-group person-group-type="author">
          <name>
            <surname>Halling-Brown</surname>
            <given-names>M.D.</given-names>
          </name>
          <name>
            <surname>Warren</surname>
            <given-names>L.M.</given-names>
          </name>
          <name>
            <surname>Ward</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Lewis</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Mackenzie</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Wallis</surname>
            <given-names>M.G.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>OPTIMAM mammography image database: a large-scale resource of mammography images and clinical data</article-title>
        <source>Radiol Artif Intell</source>
        <volume>3</volume>
        <year>2021</year>
        <fpage>e200103</fpage>
        <pub-id pub-id-type="pmid">33937853</pub-id>
      </element-citation>
    </ref>
    <ref id="b0080">
      <label>16</label>
      <element-citation publication-type="journal" id="h0080">
        <person-group person-group-type="author">
          <name>
            <surname>Moura</surname>
            <given-names>D.C.</given-names>
          </name>
          <name>
            <surname>Guevara Lopez</surname>
            <given-names>M.A.</given-names>
          </name>
        </person-group>
        <article-title>An evaluation of image descriptors combined with clinical data for breast cancer diagnosis</article-title>
        <source>Int J Comput Assist Radiol Surg</source>
        <volume>8</volume>
        <year>2013</year>
        <fpage>561</fpage>
        <lpage>574</lpage>
        <pub-id pub-id-type="pmid">23580025</pub-id>
      </element-citation>
    </ref>
    <ref id="b0085">
      <label>17</label>
      <element-citation publication-type="journal" id="h0085">
        <person-group person-group-type="author">
          <name>
            <surname>Marcus</surname>
            <given-names>D.S.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>T.H.</given-names>
          </name>
          <name>
            <surname>Parker</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Csernansky</surname>
            <given-names>J.G.</given-names>
          </name>
          <name>
            <surname>Morris</surname>
            <given-names>J.C.</given-names>
          </name>
          <name>
            <surname>Buckner</surname>
            <given-names>R.L.</given-names>
          </name>
        </person-group>
        <article-title>Open access series of imaging studies (OASIS): cross-sectional MRI data in young, middle aged, nondemented, and demented older adults</article-title>
        <source>J Cogn Neurosci</source>
        <volume>19</volume>
        <year>2007</year>
        <fpage>1498</fpage>
        <lpage>1507</lpage>
        <pub-id pub-id-type="pmid">17714011</pub-id>
      </element-citation>
    </ref>
    <ref id="b0090">
      <label>18</label>
      <element-citation publication-type="journal" id="h0090">
        <person-group person-group-type="author">
          <name>
            <surname>Ouyang</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Ghorbani</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Ebinger</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Langlotz</surname>
            <given-names>C.P.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Video-based AI for beat-to-beat assessment of cardiac function</article-title>
        <source>Nature</source>
        <volume>580</volume>
        <year>2020</year>
        <fpage>252</fpage>
        <lpage>256</lpage>
        <pub-id pub-id-type="pmid">32269341</pub-id>
      </element-citation>
    </ref>
    <ref id="b0095">
      <label>19</label>
      <element-citation publication-type="journal" id="h0095">
        <person-group person-group-type="author">
          <name>
            <surname>Leclerc</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Smistad</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Pedrosa</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Ostvik</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Cervenansky</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Espinosa</surname>
            <given-names>F.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep learning for segmentation using an open large-scale dataset in 2D echocardiography</article-title>
        <source>IEEE Trans Med Imaging</source>
        <volume>38</volume>
        <year>2019</year>
        <fpage>2198</fpage>
        <lpage>2210</lpage>
        <pub-id pub-id-type="pmid">30802851</pub-id>
      </element-citation>
    </ref>
    <ref id="b0100">
      <label>20</label>
      <element-citation publication-type="journal" id="h0100">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>X.S.</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>Y.F.</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Z.Y.</given-names>
          </name>
          <name>
            <surname>Bagheri</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Summers</surname>
            <given-names>R.M.</given-names>
          </name>
        </person-group>
        <article-title>ChestX-ray8: hospital-scale chest X-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases</article-title>
        <source>Proc IEEE Conf Comput Vis Pattern Recognit</source>
        <volume>2017</volume>
        <year>2017</year>
        <fpage>3462</fpage>
        <lpage>3471</lpage>
      </element-citation>
    </ref>
    <ref id="b0105">
      <label>21</label>
      <element-citation publication-type="journal" id="h0105">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>DPN: detail-preserving network with high resolution representation for efficient segmentation of retinal vessels</article-title>
        <source>J Ambient Intell Humaniz Comput</source>
        <volume>14</volume>
        <year>2023</year>
        <fpage>5689</fpage>
        <lpage>5702</lpage>
      </element-citation>
    </ref>
    <ref id="b0110">
      <label>22</label>
      <element-citation publication-type="journal" id="h0110">
        <person-group person-group-type="author">
          <name>
            <surname>Ning</surname>
            <given-names>W.S.</given-names>
          </name>
          <name>
            <surname>Lei</surname>
            <given-names>S.J.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>J.J.</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>Y.K.</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>P.R.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Q.Q.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Open resource of clinical data from patients with pneumonia for the prediction of COVID-19 outcomes via deep learning</article-title>
        <source>Nat Biomed Eng</source>
        <volume>4</volume>
        <year>2020</year>
        <fpage>1197</fpage>
        <lpage>1207</lpage>
        <pub-id pub-id-type="pmid">33208927</pub-id>
      </element-citation>
    </ref>
    <ref id="b0115">
      <label>23</label>
      <element-citation publication-type="journal" id="h0115">
        <person-group person-group-type="author">
          <name>
            <surname>CNCB-NGDC Members and Partners</surname>
          </name>
        </person-group>
        <article-title>Database resources of the National Genomics Data Center, China National Center for Bioinformation in 2023</article-title>
        <source>Nucleic Acids Res</source>
        <volume>51</volume>
        <year>2023</year>
        <fpage>D18</fpage>
        <lpage>D28</lpage>
        <pub-id pub-id-type="pmid">36420893</pub-id>
      </element-citation>
    </ref>
    <ref id="b0120">
      <label>24</label>
      <element-citation publication-type="journal" id="h0120">
        <person-group person-group-type="author">
          <name>
            <surname>Lindeberg</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>Scale invariant feature transform</article-title>
        <source>Scholarpedia J</source>
        <volume>7</volume>
        <year>2012</year>
        <fpage>10491</fpage>
      </element-citation>
    </ref>
    <ref id="b0125">
      <label>25</label>
      <element-citation publication-type="journal" id="h0125">
        <person-group person-group-type="author">
          <name>
            <surname>Pietikäinen</surname>
            <given-names>M.J.S.</given-names>
          </name>
        </person-group>
        <article-title>Local binary patterns</article-title>
        <source>Scholarpedia J</source>
        <volume>5</volume>
        <year>2010</year>
        <fpage>9775</fpage>
      </element-citation>
    </ref>
    <ref id="b0130">
      <label>26</label>
      <element-citation publication-type="journal" id="h0130">
        <person-group person-group-type="author">
          <name>
            <surname>Dalal</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Triggs</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>Histograms of oriented gradients for human detection</article-title>
        <source>IEEE Comput Soc Conf Comput Vis Pattern Recognit</source>
        <volume>1</volume>
        <year>2005</year>
        <fpage>886</fpage>
        <lpage>893</lpage>
      </element-citation>
    </ref>
    <ref id="b0135">
      <label>27</label>
      <element-citation publication-type="journal" id="h0135">
        <person-group person-group-type="author">
          <name>
            <surname>Qayyum</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Anwar</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Awais</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Majid</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Medical image retrieval using deep convolutional neural network</article-title>
        <source>Neurocomputing</source>
        <volume>266</volume>
        <year>2017</year>
        <fpage>8</fpage>
        <lpage>20</lpage>
      </element-citation>
    </ref>
    <ref id="b0140">
      <label>28</label>
      <element-citation publication-type="journal" id="h0140">
        <person-group person-group-type="author">
          <name>
            <surname>Fang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Deep triplet hashing network for case-based medical image retrieval</article-title>
        <source>Med Image Anal</source>
        <volume>69</volume>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">101981</object-id>
      </element-citation>
    </ref>
    <ref id="b0145">
      <label>29</label>
      <element-citation publication-type="journal" id="h0145">
        <person-group person-group-type="author">
          <name>
            <surname>Tan</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>Q.</given-names>
          </name>
        </person-group>
        <article-title>Efficientnet: rethinking model scaling for convolutional neural networks</article-title>
        <source>Proc Mach Learn Res</source>
        <volume>97</volume>
        <year>2019</year>
        <fpage>6105</fpage>
        <lpage>6114</lpage>
      </element-citation>
    </ref>
    <ref id="b0150">
      <label>30</label>
      <element-citation publication-type="journal" id="h0150">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>T.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>GSA: Genome Sequence Archive</article-title>
        <source>Genomics Proteomics Bioinformatics</source>
        <volume>15</volume>
        <year>2017</year>
        <fpage>14</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="pmid">28387199</pub-id>
      </element-citation>
    </ref>
    <ref id="b0155">
      <label>31</label>
      <element-citation publication-type="journal" id="h0155">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>A.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The Genome Sequence Archive Family: toward explosive data growth and diverse data types</article-title>
        <source>Genomics Proteomics Bioinformatics</source>
        <volume>19</volume>
        <year>2021</year>
        <fpage>578</fpage>
        <lpage>583</lpage>
        <pub-id pub-id-type="pmid">34400360</pub-id>
      </element-citation>
    </ref>
    <ref id="b0160">
      <label>32</label>
      <element-citation publication-type="journal" id="h0160">
        <person-group person-group-type="author">
          <name>
            <surname>Moore</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Maffitt</surname>
            <given-names>D.R.</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>K.E.</given-names>
          </name>
          <name>
            <surname>Kirby</surname>
            <given-names>J.S.</given-names>
          </name>
          <name>
            <surname>Clark</surname>
            <given-names>K.W.</given-names>
          </name>
          <name>
            <surname>Freymann</surname>
            <given-names>J.B.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>De-identification of medical images with retention of scientific research value</article-title>
        <source>Radiographics</source>
        <volume>35</volume>
        <year>2015</year>
        <fpage>727</fpage>
        <lpage>735</lpage>
        <pub-id pub-id-type="pmid">25969931</pub-id>
      </element-citation>
    </ref>
    <ref id="b0165">
      <label>33</label>
      <element-citation publication-type="journal" id="h0165">
        <person-group person-group-type="author">
          <name>
            <surname>Monteiro</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Costa</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Oliveira</surname>
            <given-names>J.L.</given-names>
          </name>
        </person-group>
        <article-title>A de-identification pipeline for ultrasound medical images in dicom format</article-title>
        <source>J Med Syst</source>
        <volume>41</volume>
        <year>2017</year>
        <fpage>89</fpage>
        <pub-id pub-id-type="pmid">28405948</pub-id>
      </element-citation>
    </ref>
  </ref-list>
  <sec id="s0085" sec-type="supplementary-material">
    <title>Supplementary material</title>
    <p id="p0120">The following are the Supplementary material to this article:<supplementary-material content-type="local-data" id="m0010"><caption><title>Supplementary Table S1</title><p>Number of individuals, studies, series, and images of each imaging modality</p></caption><media xlink:href="mmc1.docx"/></supplementary-material></p>
    <p id="p0125">
      <supplementary-material content-type="local-data" id="m0005">
        <caption>
          <title>Supplementary Table S2</title>
          <p>Number of individuals, studies, series, and images of each anatomical site</p>
        </caption>
        <media xlink:href="mmc2.docx"/>
      </supplementary-material>
    </p>
  </sec>
  <ack id="ak005">
    <title>Acknowledgments</title>
    <p id="p0110">This work was supported by grants from the <funding-source id="gp005">Strategic Priority Research Program of the Chinese Academy of Sciences</funding-source> (Grant No. XDB38050300), the <funding-source id="gp010">Genomics Data Center Operation and Maintenance of Chinese Academy of Sciences</funding-source> (Grant No. CAS-WX2022SDC-XK05), and the <funding-source id="gp015">Key Technology Talent Program of the Chinese Academy of Sciences</funding-source>, China.</p>
  </ack>
  <fn-group>
    <fn id="d36e118">
      <p id="np005">Peer review under responsibility of Beijing Institute of Genomics, Chinese Academy of Sciences / China National Center for Bioinformation and Genetics Society of China.</p>
    </fn>
    <fn id="s0080" fn-type="supplementary-material">
      <p id="p0115">Supplementary data to this article can be found online at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.gpb.2023.09.003" id="ir085">https://doi.org/10.1016/j.gpb.2023.09.003</ext-link>.</p>
    </fn>
  </fn-group>
</back>
