<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Brief Bioinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Brief Bioinform</journal-id>
    <journal-id journal-id-type="publisher-id">bib</journal-id>
    <journal-title-group>
      <journal-title>Briefings in Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1467-5463</issn>
    <issn pub-type="epub">1477-4054</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9851331</article-id>
    <article-id pub-id-type="pmid">36573492</article-id>
    <article-id pub-id-type="doi">10.1093/bib/bbac583</article-id>
    <article-id pub-id-type="publisher-id">bbac583</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Problem Solving Protocol</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>EVlncRNA-Dpred: improved prediction of experimentally validated lncRNAs by deep learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-4824-347X</contrib-id>
        <name>
          <surname>Zhou</surname>
          <given-names>Bailing</given-names>
        </name>
        <!--blzhou@126.com-->
        <aff><institution>Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University</institution>, <addr-line>Dezhou 253023</addr-line>, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ding</surname>
          <given-names>Maolin</given-names>
        </name>
        <!--dingmlin3@mail2.sysu.edu.cn-->
        <aff><institution>School of Computer Science and Engineering, Sun Yat-sen University</institution>, <addr-line>Guangzhou 510000</addr-line>, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Feng</surname>
          <given-names>Jing</given-names>
        </name>
        <!--2873760656@qq.com-->
        <aff><institution>Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University</institution>, <addr-line>Dezhou 253023</addr-line>, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ji</surname>
          <given-names>Baohua</given-names>
        </name>
        <!--jbh1971@126.com-->
        <aff><institution>Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University</institution>, <addr-line>Dezhou 253023</addr-line>, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Huang</surname>
          <given-names>Pingping</given-names>
        </name>
        <!--hpp1443461935@163.com-->
        <aff><institution>Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University</institution>, <addr-line>Dezhou 253023</addr-line>, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Junye</given-names>
        </name>
        <!--zhxy-1234@163.com-->
        <aff><institution>Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University</institution>, <addr-line>Dezhou 253023</addr-line>, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yu</surname>
          <given-names>Xue</given-names>
        </name>
        <!--yuxuefish@163.com-->
        <aff><institution>Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University</institution>, <addr-line>Dezhou 253023</addr-line>, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cao</surname>
          <given-names>Zanxia</given-names>
        </name>
        <!--qiayilai@mail.ustc.edu.cn-->
        <aff><institution>Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University</institution>, <addr-line>Dezhou 253023</addr-line>, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yang</surname>
          <given-names>Yuedong</given-names>
        </name>
        <!--yangyd25@mail.sysu.edu.cn-->
        <aff><institution>School of Computer Science and Engineering, Sun Yat-sen University</institution>, <addr-line>Guangzhou 510000</addr-line>, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Zhou</surname>
          <given-names>Yaoqi</given-names>
        </name>
        <!--zhouyq@szbl.ac.cn-->
        <aff><institution>Institute for Systems and Physical Biology, Shenzhen Bay Laboratory</institution>, <addr-line>Shenzhen 518055</addr-line>, <country country="CN">China</country></aff>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Wang</surname>
          <given-names>Jihua</given-names>
        </name>
        <!--jhw25336@126.com-->
        <aff><institution>Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University</institution>, <addr-line>Dezhou 253023</addr-line>, <country country="CN">China</country></aff>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="cor1">Corresponding authors: Yaoqi Zhou, Institute for Systems and Physical Biology, Shenzhen Bay Laboratory, Shenzhen 518055, China. Tel.: +86 (755) 6275 2684; E-mail: <email>zhouyq@szbl.ac.cn</email>; Jihua Wang, Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University, Dezhou 253023, China. Tel.: +86 (534) 898 5933; E-mail: <email>jhw25336@126.com</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-12-27">
      <day>27</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>27</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <volume>24</volume>
    <issue>1</issue>
    <elocation-id>bbac583</elocation-id>
    <history>
      <date date-type="received">
        <day>14</day>
        <month>9</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>2</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>11</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="bbac583.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>Long non-coding RNAs (lncRNAs) played essential roles in nearly every biological process and disease. Many algorithms were developed to distinguish lncRNAs from mRNAs in transcriptomic data and facilitated discoveries of more than 600 000 of lncRNAs. However, only a tiny fraction (&lt;1%) of lncRNA transcripts (~4000) were further validated by low-throughput experiments (EVlncRNAs). Given the cost and labor-intensive nature of experimental validations, it is necessary to develop computational tools to prioritize those potentially functional lncRNAs because many lncRNAs from high-throughput sequencing (HTlncRNAs) could be resulted from transcriptional noises. Here, we employed deep learning algorithms to separate EVlncRNAs from HTlncRNAs and mRNAs. For overcoming the challenge of small datasets, we employed a three-layer deep-learning neural network (DNN) with a K-mer feature as the input and a small convolutional neural network (CNN) with one-hot encoding as the input. Three separate models were trained for human (h), mouse (m) and plant (p), respectively. The final concatenated models (EVlncRNA-Dpred (h), EVlncRNA-Dpred (m) and EVlncRNA-Dpred (p)) provided substantial improvement over a previous model based on support-vector-machines (EVlncRNA-pred). For example, EVlncRNA-Dpred (h) achieved 0.896 for the area under receiver-operating characteristic curve, compared with 0.582 given by sequence-based EVlncRNA-pred model. The models developed here should be useful for screening lncRNA transcripts for experimental validations. EVlncRNA-Dpred is available as a web server at <ext-link xlink:href="https://www.sdklab-biophysics-dzu.net/EVlncRNA-Dpred/index.html" ext-link-type="uri">https://www.sdklab-biophysics-dzu.net/EVlncRNA-Dpred/index.html</ext-link>, and the data and source code can be freely available along with the web server.</p>
    </abstract>
    <kwd-group>
      <kwd>experimentally validated lncRNAs</kwd>
      <kwd>deep learning</kwd>
      <kwd>prediction</kwd>
    </kwd-group>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>62071085</award-id>
        <award-id>61801081</award-id>
        <award-id>61671107</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Youth Talent Introduction and Education Program of Shandong Educational Committee</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Natural Science Foundation of Shandong Province</institution>
            <institution-id institution-id-type="DOI">10.13039/501100007129</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>ZR2021QF143</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Talent Introduction Project of Dezhou University</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2020xjrc216</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Enterprise Project</institution>
          </institution-wrap>
        </funding-source>
        <award-id>HXKT2022003</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec3">
    <title>Introduction</title>
    <p>Long non-coding RNAs (lncRNAs) are non-coding transcripts composed of more than 200 nucleotides. They have been found to play important roles in many biological processes and diseases [<xref rid="ref1" ref-type="bibr">1</xref>]. Rapid advances in transcriptomics facilitate the discovery of more than 600 000 of lncRNAs [<xref rid="ref2" ref-type="bibr">2</xref>] that were inferred by computational predictors such as CNIT [<xref rid="ref3" ref-type="bibr">3</xref>], CPC2 [<xref rid="ref4" ref-type="bibr">4</xref>] and CPAT [<xref rid="ref5" ref-type="bibr">5</xref>] and annotated in several databases such as NONCODE [<xref rid="ref2" ref-type="bibr">2</xref>], GENCODE [<xref rid="ref6" ref-type="bibr">6</xref>], Ensembl [<xref rid="ref7" ref-type="bibr">7</xref>] and RefSeq [<xref rid="ref8" ref-type="bibr">8</xref>]. However, it is unknown how many of these lncRNAs are biologically active or resulted from transcriptional errors [<xref rid="ref9" ref-type="bibr">9</xref>]. High cost of function determination led to fewer than 1% of lncRNA transcripts from high-throughput experiments that are validated by low-throughput experiments [<xref rid="ref10" ref-type="bibr">10</xref>]. The huge gap between sequenced and validated lncRNAs demands development of computational techniques to screen and prioritize lncRNAs that can be validated by low-throughput experiments.</p>
    <p>Most previous computational efforts, however, were developed for separating lncRNAs from mRNAs only. These methods include machine-learning models such as CNIT [<xref rid="ref3" ref-type="bibr">3</xref>], CPC2 [<xref rid="ref4" ref-type="bibr">4</xref>] and CPAT [<xref rid="ref5" ref-type="bibr">5</xref>], and more recently, deep-learning techniques such as lncRNA_Mdeep [<xref rid="ref11" ref-type="bibr">11</xref>], lncRNAnet [<xref rid="ref12" ref-type="bibr">12</xref>] and LncADeep [<xref rid="ref13" ref-type="bibr">13</xref>] with increasingly higher accuracy. However, it did not address the question if these lncRNAs are functional.</p>
    <p>One direct way to predict lncRNA function is to infer from sequence similarity or high-throughput experimental data [<xref rid="ref14" ref-type="bibr">14</xref>], such as RNA-seq, Chip-Seq and CLIP-seq. These data allows the construction of lncRNA-DNA/miRNA/mRNA/protein co-expression or interaction network for functional inference [<xref rid="ref14" ref-type="bibr">14</xref>]. For example, lnc-GFP employed a bi-colored network [<xref rid="ref15" ref-type="bibr">15</xref>], KATZLGO utilized a global network [<xref rid="ref16" ref-type="bibr">16</xref>] and lnCaNet inferred from a co-expression network of lncRNA and non-neighboring cancer gene [<xref rid="ref17" ref-type="bibr">17</xref>]. However, these experimental data are often limited to specific experimental conditions, such as a particular cell line or tissue, or a particular cancer. Thus, a wider application of these methods for function inference is not possible.</p>
    <p>Previously, we developed a method called EVlncRNA-pred [<xref rid="ref18" ref-type="bibr">18</xref>] to separate those experimentally validated lncRNAs (EVlncRNA) from those obtained from high-throughput sequencing (HTlncRNAs). Using an SVM model, we demonstrated that EVlncRNA is predictable with an estimate that 30% human HTlncRNAs is functional. Recently, deep learning algorithms have been demonstrated increasingly powerful in improving the performance of bioinformatics tools including the success in protein structure prediction [<xref rid="ref19" ref-type="bibr">19</xref>]. Here, we investigate if and how a deep learning technique can be employed to further improve the performance of EVlncRNA-pred.</p>
    <p>Using the largest collection of EVlncRNA available [<xref rid="ref10" ref-type="bibr">10</xref>], we trained several deep learning models to distinguish EVlncRNAs from function-unknown lncRNAs obtained from high-throughput sequencing (HTlncRNAs) and mRNAs. By comparing the performance of different features (K-mer features, one-hot encoding, word2vec model, conservation and secondary structure features) and model architectures [convolutional neural network (CNN), deep neural network (DNN), Transformer], we found that simple sequence features and simple network models worked best, due to the small size of the available training set. Moreover, species-specific models work better for specific species. The online server of EVlncRNA-Dpred and the source code are freely available at <ext-link xlink:href="https://www.sdklab-biophysics-dzu.net/EVlncRNA-Dpred/index.html" ext-link-type="uri">https://www.sdklab-biophysics-dzu.net/EVlncRNA-Dpred/index.html</ext-link>.</p>
  </sec>
  <sec id="sec4">
    <title>Materials and methods</title>
    <p>The flow chart for developing EVlncRNA-Dpred is shown in <xref rid="f1" ref-type="fig">Figure 1</xref>. It involves the collection for both positive and negative data from EVLncRNAs and GENCODE, respectively. The network architecture consists of separate training of two separate models (CNN and DNN), which are concatenated for final prediction. More specific details can be found below.</p>
    <fig position="float" id="f1">
      <label>Figure 1</label>
      <caption>
        <p>The flow chart for developing EVlncRNA-Dpred. (<bold>A</bold>) Positive and negative datasets were obtained from the databases of EVLncRNAs and GENCODE, respectively. (<bold>B</bold>) The network architecture of EVlncRNADpred consists of separate training of two separate models (CNN and DNN), which are concatenated for final prediction. EVlncRNAs: experimentally validated functional lncRNAs; HTlncRNAs: functional unknown lncRNAs obtained from high-throughput sequencing.</p>
      </caption>
      <graphic xlink:href="bbac583f1" position="float"/>
    </fig>
    <sec id="sec5">
      <title>Training and test datasets for human lncRNAs</title>
      <p>The datasets were constructed as in our previous work [<xref rid="ref18" ref-type="bibr">18</xref>] but expanded by using the largest collection of experimentally validated functional lncRNAs (EVlncRNAs) available in EVLncRNAs 2.0 database [<xref rid="ref10" ref-type="bibr">10</xref>]. This collection of human EVlncRNAs is considered as the positive set. After removing the redundant sequences by CD-HIT [<xref rid="ref20" ref-type="bibr">20</xref>] with 80% sequence identity, we randomly selected 80% for training and 20% for test. After excluding the positive dataset and removing the redundant sequences by CD-HIT, we randomly selected an equal number of high-throughput lncRNAs (HTlncRNAs) and an equal number of mRNAs from the GENCODE V38 as a combined negative set. The final human training dataset contains 2831 EVlncRNAs (positive), 2831 HTlncRNAs and 2831 mRNAs (negative), respectively. The human test set contains 707 EVlncRNAs (positive), 707 HTlncRNAs and 707 mRNAs (negative), respectively. A 5-fold cross validation was performed in training.</p>
    </sec>
    <sec id="sec6">
      <title>Training and test datasets for mouse and plant lncRNAs</title>
      <p>The training and test datasets for mouse and plant lncRNAs were constructed as above. After removing the redundancy within itself, we obtained 365 mouse EVlncRNAs and 162 plant EVlncRNAs (including 128 arabidopsis lncRNAs, 16 maize lncRNAs, 4 wheat lncRNAs, 2 rice lncRNAs and 12 lncRNAs of other plants). Corresponding negative sets were also obtained from GENCODE M27 for mouse and Ensembl Plants [<xref rid="ref21" ref-type="bibr">21</xref>]. In particular, considering that arabidopsis, maize, wheat and rice are the most studied model plants, we randomly selected 141 arabidopsis HTlncRNAs/mRNAs, 16 maize HTlncRNAs/mRNAs, 4 wheat HTlncRNAs/mRNAs and 1 rice HTlncRNA/mRNAs from Ensembl Plants as the negative dataset. The final mouse training dataset contains 292 EVlncRNAs (positive), 292 HTlncRNAs and 292 mRNAs (negative), respectively. The mouse test set contains 73 EVlncRNAs (positive), 73 HTlncRNAs and 73 mRNAs (negative), respectively. The final plant training dataset contains 130 EVlncRNAs (positive), 130 HTlncRNAs and 130 mRNAs (negative), respectively. The plant test set contains 32 EVlncRNAs (positive), 32 HTlncRNAs and 32 mRNAs (negative), respectively. It is clear that both mouse and plant datasets are substantially smaller than the human datasets.</p>
    </sec>
    <sec id="sec7">
      <title>Methods overview</title>
      <p>Deep learning methods have been widely used in biological study [<xref rid="ref22" ref-type="bibr">22–26</xref>]. Compared with traditional machine-learning algorithms, deep learning methods have powerful representation learning capability and can automatically extract and screen the input information layer by layer without extensive data pre-processing or manual feature extraction. This character makes it a suitable tool to analyze complex structures of high-dimensional data [<xref rid="ref27" ref-type="bibr">27</xref>, <xref rid="ref28" ref-type="bibr">28</xref>]. The CNN could learn the spatial information [<xref rid="ref29" ref-type="bibr">29</xref>, <xref rid="ref30" ref-type="bibr">30</xref>]. Therefore, we employed deep learning methods to mine the essential features in functional lncRNA sequences without human intervention.</p>
      <p>After experimenting different model architectures (CNN, DNN and Transformer), we found that simple neural networks worked best for our small dataset. Moreover, examining the performance of K-mer features, one-hot encoding, word2vec model, conservation and secondary structure features (see <xref rid="sec25" ref-type="sec">Discussions</xref>) led us to choose k-mer features and one-hot encoding to build a three-layer DNN and a CNN models, separately. The two models were then combined into a concatenate layer and a fully connected layer to make the final selection of EVlncRNAs from HTlncRNAs and mRNAs. The same network architecture was used for the mouse lncRNA (EVlncRNA-Dpred (m)) and the plant lncRNA (EVlncRNA-Dpred (p)), respectively. Considering the relatively small size of dataset, we employed a variety of techniques to prevent overfitting: early stopping, dropout, batch normalization, simplified the neural network and reduced learning rate, in addition to make training and test sets nonredundant from each other. The details were shown in the corresponding section below.</p>
    </sec>
    <sec id="sec8">
      <title>K-mer descriptor</title>
      <p>For a given RNA sequence, we can calculate the frequencies of each <italic toggle="yes">k</italic> neighboring bases. These frequencies are stored in a vector of dimension 4<italic toggle="yes"><sup>K</sup></italic>. To prevent overfitting, we employed a simple 3-layer DNN model consisted of an input layer, two hidden layers and an output layer. At the same time, dropout layers were added after each layer (<xref rid="f2" ref-type="fig">Figure 2</xref>). The rectified linear unit (ReLU) was used as the activation function. This model was trained for predicting EVlncRNAs. When training the model, we used low learning rate and stopped training when three epochs of training do not lead to improvement. For the final concatenated model, the last hidden layer of this DNN model was used as the input feature.</p>
      <fig position="float" id="f2">
        <label>Figure 2</label>
        <caption>
          <p>The architecture of EVlncRNA-Dpred.</p>
        </caption>
        <graphic xlink:href="bbac583f2" position="float"/>
      </fig>
    </sec>
    <sec id="sec9">
      <title>One-hot encoding descriptor</title>
      <p>One-hot encoding transformed the four nucleotides A, C, G and U to binary vectors of (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0) and (0, 0, 0, 1), respectively. Thus, the transcript of length L was represented by 4 × L matrix. We employed a simple CNN model made of one convolution layer, one batch normalization, one pooling and one output layer. Batch normalization layer and dropout layer were added to prevent overfitting (<xref rid="f2" ref-type="fig">Figure 2</xref>). ReLU was used as the activation function. This model was trained for predicting EVlncRNAs. Low learning rate and early stopping were used to prevent overfitting. As the convolution layer requires a fixed-length input, we set a parameter of <italic toggle="yes">maxlen</italic>. If the length <italic toggle="yes">L</italic> of a sequence is shorter than the <italic toggle="yes">maxlen</italic>, it will be patched with (0, 0, 0, 0) × (<italic toggle="yes">maxlen</italic>-L) matrix, and if the sequence length is longer than the <italic toggle="yes">maxlen</italic>, the excess sequence region is ignored. For the final concatenated model, the last hidden layer of this CNN model was used as the input feature. A <italic toggle="yes">maxlen</italic> of 4000 nt was chosen after examining the performance dependence on the sequence length.</p>
    </sec>
    <sec id="sec10">
      <title>Model fusion</title>
      <p>We firstly separately trained the DNN model for the k-mer feature and the CNN model for the one-hot encoding. Then, the last hidden layers of the DNN and CNN models were used as inputs and were fed into a concatenate layer. Batch normalization layer and dropout layer were added to prevent overfitting, and the sigmoid function was applied on the last layer for final prediction (<xref rid="f2" ref-type="fig">Figure 2</xref>). When training the fused model, low learning rate and early stopping were used to prevent overfitting.</p>
    </sec>
    <sec id="sec11">
      <title>Performance evaluation</title>
      <p>The method performance was evaluated by area under the ROC curve (AUROC), area under the precision-recall curve (AUPRC), accuracy, Matthews correlation coefficient (MCC), sensitivity, specificity and F1_score as shown by the equations below.<disp-formula id="deqn01"><label>(1)</label><tex-math notation="LaTeX" id="DmEquation1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{Accuracy}=\frac{\mathrm{TP}+\mathrm{TN}}{\mathrm{TP}+\mathrm{TN}+\mathrm{FP}+\mathrm{FN}} \end{equation*}\end{document}</tex-math></disp-formula><disp-formula id="deqn02"><label>(2)</label><tex-math notation="LaTeX" id="DmEquation2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{MCC}=\frac{\left(\mathrm{TP}\times \mathrm{TN}-\mathrm{FP}\times \mathrm{FN}\right)}{\sqrt{\left(\mathrm{TP}+\mathrm{FP}\right)\times \left(\mathrm{TP}+\mathrm{FN}\right)\times \left(\mathrm{TN}+\mathrm{FP}\right)\times \left(\mathrm{TN}+\mathrm{FN}\right)}} \end{equation*}\end{document}</tex-math></disp-formula><disp-formula id="deqn03"><label>(3)</label><tex-math notation="LaTeX" id="DmEquation3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{Sensitivity}=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}} \end{equation*}\end{document}</tex-math></disp-formula><disp-formula id="deqn04"><label>(4)</label><tex-math notation="LaTeX" id="DmEquation4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{Specificity}=\frac{\mathrm{TN}}{\mathrm{FP}+\mathrm{TN}} \end{equation*}\end{document}</tex-math></disp-formula><disp-formula id="deqn05"><label>(5)</label><tex-math notation="LaTeX" id="DmEquation5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{F}1\_\mathrm{score}=\frac{2\mathrm{TP}}{2\mathrm{TP}+\mathrm{FP}+\mathrm{FN}}, \end{equation*}\end{document}</tex-math></disp-formula>where TP and TN represent positive and negative samples that have been correctly predicted, respectively, and FP and FN represent positive and negative samples that have been falsely predicted, respectively. MCC is essentially a correlation coefficient between predicted and actual binary classifications with values between −1 and 1 with zero for random prediction. It is a balanced measure for unequal-sized positive and negative samples. Sensitivity is the fraction of predicted true EVlncRNAs in all true EVlncRNAs. Specificity is the fraction of predicted true negatives in all true negatives. Precision is the fraction of true EVlncRNAs in all predicted EVlncRNAs.</p>
    </sec>
    <sec sec-type="data-availability" id="sec12">
      <title>Data and software availability</title>
      <p>EVlncRNA-Dpred was implemented in Python 3 using Keras 2.2.5 with the backend of Tensorflow-gpu 1.14.0. The models were trained on a NVIDIA TITAN RTX. EVlncRNA-Dpred is available as a web server at <ext-link xlink:href="https://www.sdklab-biophysics-dzu.net/EVlncRNA-Dpred/index.html" ext-link-type="uri">https://www.sdklab-biophysics-dzu.net/EVlncRNA-Dpred/index.html</ext-link>. The data and source code are freely available at the web server for download.</p>
    </sec>
  </sec>
  <sec id="sec13">
    <title>Results</title>
    <sec id="sec14">
      <title>Performance of EVlncRNA-Dpred (h) for human datasets</title>
      <sec id="sec15">
        <title>Setting the parameters</title>
        <p>The dependence of the performance on <italic toggle="yes">k</italic> in the k-mer descriptor was evaluated. The results are shown in <xref rid="f3" ref-type="fig">Figure 3A</xref>. The AUROC of the 5-fold CV increases from <italic toggle="yes">k</italic> = 1 to 8 and kept the same at <italic toggle="yes">k</italic> = 9. However, at <italic toggle="yes">k</italic> = 8, the variation from the performance in 5-folds is the smallest. Moreover, using <italic toggle="yes">k</italic> = 8 requires less computing time than using <italic toggle="yes">k</italic> = 9. Thus, we set the <italic toggle="yes">k</italic> as 8 for the final model. <xref rid="f3" ref-type="fig">Figure 3B</xref> shows the dependence of the performance on <italic toggle="yes">maxlen</italic> in one-hot encoding. The overall dependence on <italic toggle="yes">maxlen</italic> is small. As 95% human lncRNAs are shorter than 4000 in length in GENCODE [<xref rid="ref12" ref-type="bibr">12</xref>], we set the <italic toggle="yes">maxlen</italic> as 4000.</p>
        <fig position="float" id="f3">
          <label>Figure 3</label>
          <caption>
            <p>Performance of 5-fold cross-validation on human training set (<bold>A</bold>) for the k-mer DNN model as a function of <italic toggle="yes">k</italic> and (<bold>B</bold>) for the one-hot encoding CNN model as a function of <italic toggle="yes">maxlen</italic>.</p>
          </caption>
          <graphic xlink:href="bbac583f3" position="float"/>
        </fig>
      </sec>
      <sec id="sec16">
        <title>Comparison between individual and combined models</title>
        <p><xref rid="TB1" ref-type="table">Table 1</xref> compares the performance of the individual models (the k-mer DNN and one-hot-encoding CNN models) with those of their combined models. The average AUROC of 5-fold CV of the DNN model and CNN model were 0.839 and 0.717, respectively. A simple average of DNN and CNN models further improves the performance to AUROC = 0.849, whereas a concatenated model provides a slight further improvement with an AUROC of 0.858. Similar trend was observed for other performance measures such as AUPRC, AUPRC, ACC, MCC and F1_score. Thus, we employed the concatenated model as our final model for EVlncRNA-Dpred (h).</p>
        <table-wrap position="float" id="TB1">
          <label>Table 1</label>
          <caption>
            <p>Performance comparison for individual models and combined models in 5-fold cross validations on human training set</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Model</th>
                <th align="left" rowspan="1" colspan="1">AUROC</th>
                <th align="left" rowspan="1" colspan="1">AUPRC</th>
                <th align="left" rowspan="1" colspan="1">ACC</th>
                <th align="left" rowspan="1" colspan="1">MCC</th>
                <th align="left" rowspan="1" colspan="1">Sensitivity</th>
                <th align="left" rowspan="1" colspan="1">Specificity</th>
                <th align="left" rowspan="1" colspan="1">F1_score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>DNN</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.839 ± 0.004</td>
                <td align="left" rowspan="1" colspan="1">0.777 ± 0.015</td>
                <td align="left" rowspan="1" colspan="1">0.808 ± 0.013</td>
                <td align="left" rowspan="1" colspan="1">0.552 ± 0.029</td>
                <td align="left" rowspan="1" colspan="1">0.594 ± 0.035</td>
                <td align="left" rowspan="1" colspan="1">0.914 ± 0.030</td>
                <td align="left" rowspan="1" colspan="1">0.673 ± 0.016</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>CNN</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.717 ± 0.024</td>
                <td align="left" rowspan="1" colspan="1">0.538 ± 0.062</td>
                <td align="left" rowspan="1" colspan="1">0.686 ± 0.020</td>
                <td align="left" rowspan="1" colspan="1">0.157 ± 0.111</td>
                <td align="left" rowspan="1" colspan="1">0.089 ± 0.099</td>
                <td align="left" rowspan="1" colspan="1">0.985 ± 0.021</td>
                <td align="left" rowspan="1" colspan="1">0.144 ± 0.153</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Average</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.849 ± 0.008</td>
                <td align="left" rowspan="1" colspan="1">0.782 ± 0.017</td>
                <td align="left" rowspan="1" colspan="1">0.798 ± 0.007</td>
                <td align="left" rowspan="1" colspan="1">0.530 ± 0.019</td>
                <td align="left" rowspan="1" colspan="1">0.462 ± 0.036</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.966 ± 0.016</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.603 ± 0.024</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Concatenated</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.858 ± 0.006</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.807 ± 0.014</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.816 ± 0.008</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.574 ± 0.021</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.598 ± 0.061</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.925 ± 0.039</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.683 ± 0.017</bold>
                </td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec id="sec17">
        <title>Comparison with the previous method</title>
        <p>To the best of our knowledge, our previous SVM-based EVlncRNA-pred [<xref rid="ref18" ref-type="bibr">18</xref>] is the only one that predicts potential functional lncRNAs. Due to the overlap between the current test set and the previous training set for EVlncRNA-pred, we employed the current human training set to retrain an SVM model so that both have the same training and test sets. <xref rid="TB2" ref-type="table">Table 2</xref> shows the performance comparison on the human test set between SVM (EVlncRNA-pred sequence-only model) and EVlncRNA-Dpred. The AUROC, AUPRC, accuracy and MCC for SVM (EVlncRNA-pred) was 0.582, 0.404, 0.657 and 0.077, respectively, compared with 0.896, 0.850, 0.852 and 0.617, respectively, given by EVlncRNA-Dpred. Other traditional machine learning methods (random forest, decision tree and k-nearest neighbor) were examined with the same training and test sets. Their performance is worse than the SVM model, as shown in <xref rid="TB2" ref-type="table">Table 2</xref>.</p>
        <table-wrap position="float" id="TB2">
          <label>Table 2</label>
          <caption>
            <p>Performance of EVlncRNA-Dpred, the previous SVM model and other traditional machine learning methods on the human test set</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Model</th>
                <th align="left" rowspan="1" colspan="1">AUROC</th>
                <th align="left" rowspan="1" colspan="1">AUPRC</th>
                <th align="left" rowspan="1" colspan="1">ACC</th>
                <th align="left" rowspan="1" colspan="1">MCC</th>
                <th align="left" rowspan="1" colspan="1">Sensitivity</th>
                <th align="left" rowspan="1" colspan="1">Specificity</th>
                <th align="left" rowspan="1" colspan="1">F1_score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>EVlncRNA-Dpred (h)</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.896</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.850</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.852</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.617</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.564</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.968</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.693</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>SVM</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.582</td>
                <td align="left" rowspan="1" colspan="1">0.404</td>
                <td align="left" rowspan="1" colspan="1">0.657</td>
                <td align="left" rowspan="1" colspan="1">0.077</td>
                <td align="left" rowspan="1" colspan="1">0.122</td>
                <td align="left" rowspan="1" colspan="1">0.925</td>
                <td align="left" rowspan="1" colspan="1">0.191</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Random Forest</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.530</td>
                <td align="left" rowspan="1" colspan="1">0.442</td>
                <td align="left" rowspan="1" colspan="1">0.653</td>
                <td align="left" rowspan="1" colspan="1">0.087</td>
                <td align="left" rowspan="1" colspan="1">0.156</td>
                <td align="left" rowspan="1" colspan="1">0.901</td>
                <td align="left" rowspan="1" colspan="1">0.234</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Decision Tree</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.527</td>
                <td align="left" rowspan="1" colspan="1">0.476</td>
                <td align="left" rowspan="1" colspan="1">0.577</td>
                <td align="left" rowspan="1" colspan="1">0.053</td>
                <td align="left" rowspan="1" colspan="1">0.376</td>
                <td align="left" rowspan="1" colspan="1">0.677</td>
                <td align="left" rowspan="1" colspan="1">0.372</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>K-Nearest Neighbors</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.532</td>
                <td align="left" rowspan="1" colspan="1">0.468</td>
                <td align="left" rowspan="1" colspan="1">0.670</td>
                <td align="left" rowspan="1" colspan="1">0.116</td>
                <td align="left" rowspan="1" colspan="1">0.117</td>
                <td align="left" rowspan="1" colspan="1">0.947</td>
                <td align="left" rowspan="1" colspan="1">0.192</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>For completeness, we also compared to the current lncRNA prediction methods focused on separating lncRNAs from mRNAs only. <xref rid="f4" ref-type="fig">Figure 4</xref> compares the ROC curves and PRC curves given by EVlncRNA-Dpred, several deep learning methods (lncRNA_Mdeep [<xref rid="ref11" ref-type="bibr">11</xref>], lncRNAnet [<xref rid="ref12" ref-type="bibr">12</xref>], LncADeep [<xref rid="ref13" ref-type="bibr">13</xref>]) and traditional machine learning methods (CNCI [<xref rid="ref31" ref-type="bibr">31</xref>], CPC2 [<xref rid="ref4" ref-type="bibr">4</xref>], PLEK [<xref rid="ref32" ref-type="bibr">32</xref>]) on our human test set. This comparison was not to illustrate the improvement of our method over previous techniques but to highlight the difference in the prediction goals. These methods trained the models with lncRNAs in GENCODE (could contain both EVlncRNAs and HTlncRNAs) as positives and mRNAs as negatives. As a result, the AUROCs of lncRNA_Mdeep [<xref rid="ref11" ref-type="bibr">11</xref>], lncRNAnet [<xref rid="ref12" ref-type="bibr">12</xref>] and LncADeep [<xref rid="ref13" ref-type="bibr">13</xref>] on human test set all achieved 0.7 (&gt;0.5), the AUROCs of CNCI [<xref rid="ref31" ref-type="bibr">31</xref>], CPC2 [<xref rid="ref4" ref-type="bibr">4</xref>], PLEK [<xref rid="ref32" ref-type="bibr">32</xref>] on human test set all achieved 0.65 (&gt;0.5), but significantly worse than that of EVlncRNA-Dpred as expected (<xref rid="f4" ref-type="fig">Figure 4A</xref>). The same is true for AUPRCs (<xref rid="f4" ref-type="fig">Figure 4B</xref>).</p>
        <fig position="float" id="f4">
          <label>Figure 4</label>
          <caption>
            <p>Receiver operating characteristic curves (<bold>A</bold>) and precision-recall curves (<bold>B</bold>) on the human test set by EVlncRNA-Dpred (h), several deep learning methods and traditional machine learning methods for separating lncRNAs from mRNA on the human test set.</p>
          </caption>
          <graphic xlink:href="bbac583f4" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec id="sec18">
      <title>EVlncRNA-Dpred (m) for predicting mouse EVlncRNAs</title>
      <p>Similar to the development of human model EVlncRNA-Dpred, we established mouse model EVlncRNA-Dpred (m) using mouse datasets.</p>
      <sec id="sec19">
        <title>Performance of EVlncRNA-Dpred (m)</title>
        <p>The effects of the hyper-parameters in EVlncRNA-Dpred (m) were evaluated and the AUROC of the 5-fold CV test are shown in <xref rid="f5" ref-type="fig">Figure 5</xref>. Unlike EVlncRNA-Dpred (h), the performance is the best for the hyper-parameter <italic toggle="yes">k</italic> = 7. Like EVlncRNA-Dpred (h), the overall dependence on <italic toggle="yes">maxlen</italic> is small. Thus, <italic toggle="yes">maxlen</italic> was set to 4000 as in EVlncRNA-Dpred (h). The performance of the 5-fold CV results of the DNN model, the CNN model and their combination EVlncRNA-Dpred (m) are shown in <xref rid="TB3" ref-type="table">Table 3</xref>. The average AUROC values of 5-fold CV test of the DNN model and the CNN model were 0.782 and 0.685, respectively. The concatenation of the two models improved the AUROC value to 0.816.</p>
        <fig position="float" id="f5">
          <label>Figure 5</label>
          <caption>
            <p>Performance of 5-fold cross-validation on the mouse training set (<bold>A</bold>) for the k-mer DNN model as a function of <italic toggle="yes">k</italic> and (<bold>B</bold>) for the one-hot encoding CNN model as a function of <italic toggle="yes">maxlen</italic>.</p>
          </caption>
          <graphic xlink:href="bbac583f5" position="float"/>
        </fig>
        <table-wrap position="float" id="TB3">
          <label>Table 3</label>
          <caption>
            <p>Performance comparison for individual models and combined models in 5-fold cross validations on the mouse training set</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Model</th>
                <th align="left" rowspan="1" colspan="1">AUROC</th>
                <th align="left" rowspan="1" colspan="1">AUPRC</th>
                <th align="left" rowspan="1" colspan="1">ACC</th>
                <th align="left" rowspan="1" colspan="1">MCC</th>
                <th align="left" rowspan="1" colspan="1">Sensitivity</th>
                <th align="left" rowspan="1" colspan="1">Specificity</th>
                <th align="left" rowspan="1" colspan="1">F1_score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>DNN</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.782 ± 0.070</td>
                <td align="left" rowspan="1" colspan="1">0.726 ± 0.076</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.766 ± 0.050</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.463 ± 0.111</td>
                <td align="left" rowspan="1" colspan="1">0.596 ± 0.071</td>
                <td align="left" rowspan="1" colspan="1">0.851 ± 0.056</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.630 ± 0.071</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>CNN</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.685 ± 0.030</td>
                <td align="left" rowspan="1" colspan="1">0.569 ± 0.078</td>
                <td align="left" rowspan="1" colspan="1">0.688 ± 0.013</td>
                <td align="left" rowspan="1" colspan="1">0.182 ± 0.113</td>
                <td align="left" rowspan="1" colspan="1">0.068 ± 0.046</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.998 ± 0.004</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.124 ± 0.083</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>EVlncRNA-Dpred (m)</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.816 ± 0.026</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.769 ± 0.032</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.765 ± 0.054</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.482 ± 0.063</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.597 ± 0.142</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.849 ± 0.144</td>
                <td align="left" rowspan="1" colspan="1">0.627 ± 0.035</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec id="sec20">
        <title>Comparison on the mouse test dataset</title>
        <p>Our previous work did not train models for mouse and plant separately because the sizes of the datasets were too small. For comparison to a SVM-based model, we re-trained an SVM model with the present mouse training set and compared its performance on the mouse test set to EVlncRNA-Dpred (m) and EVlncRNA-Dpred (h) in <xref rid="TB4" ref-type="table">Table 4</xref>. The AUROC and AUPRC values were 0.830 and 0.790, respectively, by the EVlncRNA-Dpred (m). These values are substantially higher than the respective values of 0.604 and 0.419 by the SVM model. The direct application of EVlncRNA-Dpred (h) to the mouse test set yielded 0.652 for AUROC and 0.396 for AUPRC (<xref rid="TB4" ref-type="table">Table 4</xref>). This indicates that human-data-trained EVlncRNA-Dpred (h) retained some capability of distinguishing mouse EVlncRNAs.</p>
        <table-wrap position="float" id="TB4">
          <label>Table 4</label>
          <caption>
            <p>Performance of EVlncRNA-Dpred (m), the previous SVM model and EVlncRNA-Dpred (h) on the mouse test set</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Model</th>
                <th align="left" rowspan="1" colspan="1">AUROC</th>
                <th align="left" rowspan="1" colspan="1">AUPRC</th>
                <th align="left" rowspan="1" colspan="1">ACC</th>
                <th align="left" rowspan="1" colspan="1">MCC</th>
                <th align="left" rowspan="1" colspan="1">Sensitivity</th>
                <th align="left" rowspan="1" colspan="1">Specificity</th>
                <th align="left" rowspan="1" colspan="1">F1_score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>EVlncRNA-Dpred (m)</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.830</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.790</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.808</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.551</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.534</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.945</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.650</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>SVM</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.604</td>
                <td align="left" rowspan="1" colspan="1">0.419</td>
                <td align="left" rowspan="1" colspan="1">0.662</td>
                <td align="left" rowspan="1" colspan="1">0.135</td>
                <td align="left" rowspan="1" colspan="1">0.219</td>
                <td align="left" rowspan="1" colspan="1">0.884</td>
                <td align="left" rowspan="1" colspan="1">0.302</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>EVlncRNA-Dpred (h)</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.652</td>
                <td align="left" rowspan="1" colspan="1">0.396</td>
                <td align="left" rowspan="1" colspan="1">0.612</td>
                <td align="left" rowspan="1" colspan="1">0.294</td>
                <td align="left" rowspan="1" colspan="1">0.781</td>
                <td align="left" rowspan="1" colspan="1">0.527</td>
                <td align="left" rowspan="1" colspan="1">0.573</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
    </sec>
    <sec id="sec21">
      <title>EVlncRNA-Dpred (p) for predicting plant EVlncRNAs</title>
      <sec id="sec22">
        <title>Performance of EVlncRNA-Dpred (p)</title>
        <p>We set <italic toggle="yes">k</italic> = 6 and <italic toggle="yes">maxlen</italic> = 2000 for EVlncRNA-Dpred (p) after examining the performance dependence of the CNN and DNN models on <italic toggle="yes">maxlen</italic> and <italic toggle="yes">k</italic>, respectively, as for EVlncRNA-Dpred (h) and EVlncRNA-Dpred (m). <xref rid="TB5" ref-type="table">Table 5</xref> compared the performance of the 5-fold CV test of the CNN model, the DNN model and EVlncRNA-Dpred (p). The average AUROC values of the DNN model and CNN model were 0.730 and 0.696, respectively, compared with 0.786 by the combination of these two models: EVlncRNA-Dpred (p).</p>
        <table-wrap position="float" id="TB5">
          <label>Table 5</label>
          <caption>
            <p>Performance comparison for individual models and combined models in 5-fold cross validations on plant training set</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Model</th>
                <th align="left" rowspan="1" colspan="1">AUROC</th>
                <th align="left" rowspan="1" colspan="1">AUPRC</th>
                <th align="left" rowspan="1" colspan="1">ACC</th>
                <th align="left" rowspan="1" colspan="1">MCC</th>
                <th align="left" rowspan="1" colspan="1">Sensitivity</th>
                <th align="left" rowspan="1" colspan="1">Specificity</th>
                <th align="left" rowspan="1" colspan="1">F1_score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>DNN</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.730 ± 0.026</td>
                <td align="left" rowspan="1" colspan="1">0.590 ± 0.049</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.741 ± 0.025</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.388 ± 0.064</td>
                <td align="left" rowspan="1" colspan="1">0.485 ± 0.097</td>
                <td align="left" rowspan="1" colspan="1">0.869 ± 0.048</td>
                <td align="left" rowspan="1" colspan="1">0.551 ± 0.067</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>CNN</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.696 ± 0.041</td>
                <td align="left" rowspan="1" colspan="1">0.579 ± 0.045</td>
                <td align="left" rowspan="1" colspan="1">0.700 ± 0.031</td>
                <td align="left" rowspan="1" colspan="1">0.249 ± 0.101</td>
                <td align="left" rowspan="1" colspan="1">0.215 ± 0.100</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.942 ± 0.061</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.313 ± 0.117</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>EVlncRNA-Dpred (p)</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.786 ± 0.064</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.673 ± 0.106</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.738 ± 0.040</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.397 ± 0.067</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.500 ± 0.115</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.858 ± 0.106</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.558 ± 0.047</bold>
                </td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec id="sec23">
        <title>Comparison on plant test dataset</title>
        <p>Similarly, we trained an SVM model with the plant training set. Interestingly, now the SVM model has a similar performance as EVlncRNA-Dpred (p) on the plant test set as shown in <xref rid="TB6" ref-type="table">Table 6</xref>. This confirmed the discriminative power of an SVM model for a small dataset of 390 training sequences. The AUROC of the EVlncRNA-Dpred (p) on the plant test set was 0.813, compared with 0.829 given by the SVM model. We also tested the performance of EVlncRNA-Dpred (h) on the plant test set. It provides a reasonable performance despite the species difference.</p>
        <table-wrap position="float" id="TB6">
          <label>Table 6</label>
          <caption>
            <p>Performance of EVlncRNA-Dpred (p), the previous SVM model and EVlncRNA-Dpred on the plant test set</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
              <col align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Model</th>
                <th align="left" rowspan="1" colspan="1">AUROC</th>
                <th align="left" rowspan="1" colspan="1">AUPRC</th>
                <th align="left" rowspan="1" colspan="1">ACC</th>
                <th align="left" rowspan="1" colspan="1">MCC</th>
                <th align="left" rowspan="1" colspan="1">Sensitivity</th>
                <th align="left" rowspan="1" colspan="1">Specificity</th>
                <th align="left" rowspan="1" colspan="1">F1_score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>EVlncRNA-Dpred (p)</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.813</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.716</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.740</td>
                <td align="left" rowspan="1" colspan="1">0.474</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.781</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.719</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.667</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>SVM</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.829</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.692</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.792</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.510</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.563</td>
                <td align="left" rowspan="1" colspan="1">0.906</td>
                <td align="left" rowspan="1" colspan="1">0.643</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>EVlncRNA-Dpred (h)</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.666</td>
                <td align="left" rowspan="1" colspan="1">0.517</td>
                <td align="left" rowspan="1" colspan="1">0.740</td>
                <td align="left" rowspan="1" colspan="1">0.365</td>
                <td align="left" rowspan="1" colspan="1">0.344</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.938</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.468</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
    </sec>
    <sec id="sec24">
      <title>Case study</title>
      <p>Recently, Johnsson <italic toggle="yes">et al.</italic> [<xref rid="ref33" ref-type="bibr">33</xref>] studied transcriptional kinetics and molecular functions of lncRNAs. Based on the analysis of single-cell transcriptome data of mouse, the authors experimentally verified seven functional lncRNAs, which have predicted cell cycle expression patterns as measured by RT-qPCR. We applied EVlncRNA-Dpred (m) to the seven lncRNAs. Five of the seven lncRNAs were predicted as EVlncRNAs (positive). The remaining two lncRNAs were predicted with a probability of 0.47 and 0.48, respectively, close to the threshold of 0.5. This result confirms the usefulness of EVlncRNA-Dpred (m) for prioritizing potentially functional lncRNAs.</p>
    </sec>
  </sec>
  <sec id="sec25">
    <title>Discussion</title>
    <p>There is an urgent need for the prediction of potentially functional lncRNAs, which could speed up the screening and validation of functional lncRNAs. Due to a limited number of confirmed lncRNAs, we established EVlncRNA-Dpred with small networks and simple sequence features. To the best of our knowledge, EVlncRNA-Dpred is the first sequence-based deep-learning method that predicts potentially functional lncRNAs.</p>
    <p>During the development of the method, we have experimented additional features. These include the unpaired and paired bases from secondary structure predicted by RNAfold [<xref rid="ref34" ref-type="bibr">34</xref>], the solvent accessibility predicted by RNAsnap2 [<xref rid="ref35" ref-type="bibr">35</xref>]; the protein conservation score from BLASTx that searches a given nucleotide sequence against the protein sequence in the UniProt database [<xref rid="ref36" ref-type="bibr">36</xref>]; and RNA conservation score calculated with Infernal [<xref rid="ref37" ref-type="bibr">37</xref>] by searching Rfam databases [<xref rid="ref38" ref-type="bibr">38</xref>] for RNA structure and sequence similarities. The last two were used in our previous work EVlncRNA-pred. These features were combined with the last hidden layer of DNN model for predicting EVlncRNA. Although the performance for 5-fold cross validation in AUROC was improved from 0.858 ± 0.006 to 0.902 ± 0.007, the performance on the test set was decreased from 0.896 to 0.742, indicating an overtrained model. Thus, the final model only employed k-mer features.</p>
    <p>Thus, the new model employed much simpler features than the previous SVM-based EVlncRNA-pred did. EVlncRNA-pred employed GC contents, purine content and other sequence information. These sequence-based features, in principle, can be learned directly from deep neural networks. Moreover, unlike EVlncRNA-Dpred, the full EVlncRNA-pred model is based on conservation features, which are time-consuming to calculate, and high-throughput experimental features, which not all lncRNAs have. EVlncRNA-Dpred can predict faster and apply to all RNA sequences. In addition, EVlncRNA-Dpred have species-specific models for human, mouse and plant. This would allow more accurate species-specific prediction. Requiring species-specific models is consistent with the cumulative evidence suggesting that there is a large difference in the functions and regulatory mechanisms between mouse and human [<xref rid="ref39" ref-type="bibr">39–41</xref>], not to mention between plant and human.</p>
    <p>Our current models, however, are still limited due to the small number of known EVlncRNAs. This problem can be partially addressed by cumulative experimental validation of more and more EVlncRNAs and continuous update of the EVLncRNAs database [<xref rid="ref10" ref-type="bibr">10</xref>]. Moreover, we hope to develop better deep-learning models that can be learned from a few examples.</p>
    <boxed-text id="box01" position="float">
      <sec id="sec28y">
        <title>Key Points</title>
        <list list-type="bullet">
          <list-item>
            <p>To the best of our knowledge, EVlncRNA-Dpred is the first sequence-based deep-learning method that predicts potentially functional lncRNAs.</p>
          </list-item>
          <list-item>
            <p>EVlncRNA-Dpred have species-specific models for human, mouse and plant, and allow more accurate species-specific prediction</p>
          </list-item>
          <list-item>
            <p>The performance evaluations indicate that EVlncRNA-Dpred should be useful for screening lncRNA transcripts for experimental validations.</p>
          </list-item>
        </list>
      </sec>
    </boxed-text>
  </sec>
</body>
<back>
  <sec sec-type="data-availability" id="sec26">
    <title>Data availability</title>
    <p>EVlncRNA-Dpred is available as a web server at <ext-link xlink:href="https://www.sdklab-biophysics-dzu.net/EVlncRNA-Dpred/index.html" ext-link-type="uri">https://www.sdklab-biophysics-dzu.net/EVlncRNA-Dpred/index.html</ext-link>. The data and source code are freely available at the web server for download.</p>
  </sec>
  <sec id="sec29">
    <title>Funding</title>
    <p>National Natural Science Foundation of China (62071085, 61801081, 61671107); Youth Talent Introduction and Education Program of Shandong Educational Committee, Natural Science Foundation of Shandong Province (ZR2021QF143); Talent Introduction Project of Dezhou University (2020xjrc216); Enterprise project (HXKT2022003).</p>
  </sec>
  <notes id="bio3">
    <title>Author Biographies</title>
    <p><bold>Bailing Zhou</bold> is an associate professor at the Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University. Her research includes database construction, omics data mining, machine learning, deep learning and bioinformatics.</p>
    <sec sec-type="author-bio" id="sec31a">
      <p><bold>Maolin Ding</bold> is a graduate student at the School of Computer Science and Engineering, Sun Yat-sen University. He is interested in deep learning and artificial intelligence in bioinformatics.</p>
    </sec>
    <sec sec-type="author-bio" id="sec32a">
      <p><bold>Jing Feng</bold> is an undergraduate student at the Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University. She is interested in bioinformatics.</p>
    </sec>
    <sec sec-type="author-bio" id="sec33a">
      <p><bold>Baohua Ji</bold> is an associate professor at the Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University. His research includes database construction and bioinformatics.</p>
    </sec>
    <sec sec-type="author-bio" id="sec34a">
      <p><bold>Pingping Huang</bold> is a lecturer at the Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University. Her research includes omics data mining, bioinformatics and molecular functional study.</p>
    </sec>
    <sec sec-type="author-bio" id="sec35a">
      <p><bold>Junye Zhang</bold> is a lecturer at the Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University. Her research includes biosensors and bioinformatics.</p>
    </sec>
    <sec sec-type="author-bio" id="sec36a">
      <p><bold>Xue Yu</bold> is a lecturer at the Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University. Her research includes omics data mining, bioinformatics and molecular functional study.</p>
    </sec>
    <sec sec-type="author-bio" id="sec37a">
      <p><bold>Zanxia Cao</bold> is a professor at the Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University. Her research includes dynamic simulation and bioinformatics.</p>
    </sec>
    <sec sec-type="author-bio" id="sec38a">
      <p><bold>Yuedong Yang</bold> is a professor in the School of Computer Science and Engineering and the National Super Computer Center at Sun Yat-sen University. His research interests focus on computational biology, bioinformatics and artificial intelligence.</p>
    </sec>
    <sec sec-type="author-bio" id="sec39a">
      <p><bold>Yaoqi Zhou</bold> is a professor and senior principal investigator of the Institute for Systems and Physical Biology, Shenzhen Bay Laboratory, China. His research interests focus on computational biology, bioinformatics, biophysics and molecular biology.</p>
    </sec>
    <sec sec-type="author-bio" id="sec40a">
      <p><bold>Jihua Wang</bold> is the Director of the Shandong Provincial Key Laboratory of Biophysics, and he is a professor at the Institute of Biophysics, Dezhou University. His research interests focus on computational biology, bioinformatics, biophysics, biosensor and molecular biology.</p>
    </sec>
  </notes>
  <ref-list id="bib1">
    <title>References</title>
    <ref id="ref1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Statello</surname><given-names>L</given-names></string-name>, <string-name><surname>Guo</surname><given-names>C</given-names></string-name>, <string-name><surname>Chen</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Gene regulation by long non-coding RNAs and its biological functions</article-title>. <source>Nat Rev Mol Cell Biol</source><year>2021</year>;<volume>22</volume>:<fpage>96</fpage>–<lpage>118</lpage>.<pub-id pub-id-type="pmid">33353982</pub-id></mixed-citation>
    </ref>
    <ref id="ref2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname><given-names>L</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>NONCODEV6: an updated database dedicated to long non-coding RNA annotation in both animals and plants</article-title>. <source>Nucleic Acids Res</source><year>2021</year>;<volume>49</volume>:<fpage>D165</fpage>–<lpage>71</lpage>.<pub-id pub-id-type="pmid">33196801</pub-id></mixed-citation>
    </ref>
    <ref id="ref3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname><given-names>J-C</given-names></string-name>, <string-name><surname>Fang</surname><given-names>S-S</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CNIT: a fast and accurate web tool for identifying protein-coding and long non-coding transcripts based on intrinsic sequence composition</article-title>. <source>Nucleic Acids Res</source><year>2019</year>;<volume>47</volume>:<fpage>W516</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">31147700</pub-id></mixed-citation>
    </ref>
    <ref id="ref4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kang</surname><given-names>YJ</given-names></string-name>, <string-name><surname>Yang</surname><given-names>DC</given-names></string-name>, <string-name><surname>Kong</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CPC2: a fast and accurate coding potential calculator based on sequence intrinsic features</article-title>. <source>Nucleic Acids Res</source><year>2017</year>;<volume>45</volume>:<fpage>W12</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">28521017</pub-id></mixed-citation>
    </ref>
    <ref id="ref5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>L</given-names></string-name>, <string-name><surname>Park</surname><given-names>HJ</given-names></string-name>, <string-name><surname>Dasari</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CPAT: coding-potential assessment tool using an alignment-free logistic regression model</article-title>. <source>Nucleic Acids Res</source><year>2013</year>;<volume>41</volume>:<fpage>e74</fpage>.<pub-id pub-id-type="pmid">23335781</pub-id></mixed-citation>
    </ref>
    <ref id="ref6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Frankish</surname><given-names>A</given-names></string-name>, <string-name><surname>Diekhans</surname><given-names>M</given-names></string-name>, <string-name><surname>Jungreis</surname><given-names>I</given-names></string-name>, <etal>et al.</etal></person-group><article-title>GENCODE 2021</article-title>. <source>Nucleic Acids Res</source><year>2021</year>;<volume>49</volume>:<fpage>D916</fpage>–<lpage>23</lpage>.<pub-id pub-id-type="pmid">33270111</pub-id></mixed-citation>
    </ref>
    <ref id="ref7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cunningham</surname><given-names>F</given-names></string-name>, <string-name><surname>Allen</surname><given-names>JE</given-names></string-name>, <string-name><surname>Allen</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Ensembl 2022</article-title>. <source>Nucleic Acids Res</source><year>2022</year>;<volume>50</volume>:<fpage>D988</fpage>–<lpage>95</lpage>.<pub-id pub-id-type="pmid">34791404</pub-id></mixed-citation>
    </ref>
    <ref id="ref8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>W</given-names></string-name>, <string-name><surname>O'Neill</surname><given-names>KR</given-names></string-name>, <string-name><surname>Haft</surname><given-names>DH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RefSeq: expanding the prokaryotic genome annotation pipeline reach with protein family model curation</article-title>. <source>Nucleic Acids Res</source><year>2021</year>;<volume>49</volume>:<fpage>D1020</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">33270901</pub-id></mixed-citation>
    </ref>
    <ref id="ref9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Struhl</surname><given-names>K</given-names></string-name></person-group>. <article-title>Transcriptional noise and the fidelity of initiation by RNA polymerase II</article-title>. <source>Nat Struct Mol Biol</source><year>2007</year>;<volume>14</volume>:<fpage>103</fpage>–<lpage>5</lpage>.<pub-id pub-id-type="pmid">17277804</pub-id></mixed-citation>
    </ref>
    <ref id="ref10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>B</given-names></string-name>, <string-name><surname>Ji</surname><given-names>B</given-names></string-name>, <string-name><surname>Liu</surname><given-names>K</given-names></string-name>, <etal>et al.</etal></person-group><article-title>EVLncRNAs 2.0: an updated database of manually curated functional long non-coding RNAs validated by low-throughput experiments</article-title>. <source>Nucleic Acids Res</source><year>2021</year>;<volume>49</volume>:<fpage>D86</fpage>–<lpage>91</lpage>.<pub-id pub-id-type="pmid">33221906</pub-id></mixed-citation>
    </ref>
    <ref id="ref11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fan</surname><given-names>XN</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>SW</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>SY</given-names></string-name>, <etal>et al.</etal></person-group><article-title>lncRNA_Mdeep: an alignment-free predictor for distinguishing long non-coding RNAs from protein-coding transcripts by multimodal deep learning</article-title>. <source>Int J Mol Sci</source><year>2020</year>;<volume>21</volume>:5222.</mixed-citation>
    </ref>
    <ref id="ref12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baek</surname><given-names>J</given-names></string-name>, <string-name><surname>Lee</surname><given-names>B</given-names></string-name>, <string-name><surname>Kwon</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>LncRNAnet: long non-coding RNA identification using deep learning</article-title>. <source>Bioinformatics</source><year>2018</year>;<volume>34</volume>:<fpage>3889</fpage>–<lpage>97</lpage>.<pub-id pub-id-type="pmid">29850775</pub-id></mixed-citation>
    </ref>
    <ref id="ref13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>C</given-names></string-name>, <string-name><surname>Yang</surname><given-names>L</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>LncADeep: an ab initio lncRNA identification and functional annotation tool based on deep learning</article-title>. <source>Bioinformatics</source><year>2018</year>;<volume>34</volume>:<fpage>3825</fpage>–<lpage>34</lpage>.<pub-id pub-id-type="pmid">29850816</pub-id></mixed-citation>
    </ref>
    <ref id="ref14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>X</given-names></string-name>, <string-name><surname>Sun</surname><given-names>YZ</given-names></string-name>, <string-name><surname>Guan</surname><given-names>NN</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Computational models for lncRNA function prediction and functional similarity calculation</article-title>. <source>Brief Funct Genomics</source><year>2019</year>;<volume>18</volume>:<fpage>58</fpage>–<lpage>82</lpage>.<pub-id pub-id-type="pmid">30247501</pub-id></mixed-citation>
    </ref>
    <ref id="ref15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname><given-names>X</given-names></string-name>, <string-name><surname>Gao</surname><given-names>L</given-names></string-name>, <string-name><surname>Liao</surname><given-names>Q</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Long non-coding RNAs function annotation: a global prediction method based on bi-colored networks</article-title>. <source>Nucleic Acids Res</source><year>2013</year>;<volume>41</volume>:<fpage>e35</fpage>.<pub-id pub-id-type="pmid">23132350</pub-id></mixed-citation>
    </ref>
    <ref id="ref16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Fan</surname><given-names>C</given-names></string-name>, <etal>et al.</etal></person-group><article-title>KATZLGO: large-scale prediction of LncRNA functions by using the KATZ measure based on multiple networks</article-title>. <source>IEEE/ACM Trans Comput Biol Bioinform</source><year>2019</year>;<volume>16</volume>:<fpage>407</fpage>–<lpage>16</lpage>.<pub-id pub-id-type="pmid">28534780</pub-id></mixed-citation>
    </ref>
    <ref id="ref17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>M</given-names></string-name></person-group>. <article-title>lnCaNet: pan-cancer co-expression network for human lncRNA and cancer genes</article-title>. <source>Bioinformatics</source><year>2016</year>;<volume>32</volume>:<fpage>1595</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">26787663</pub-id></mixed-citation>
    </ref>
    <ref id="ref18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>B</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zhan</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Predicting functional long non-coding RNAs validated by low throughput experiments</article-title>. <source>RNA Biol</source><year>2019</year>;<volume>16</volume>:<fpage>1555</fpage>–<lpage>64</lpage>.<pub-id pub-id-type="pmid">31345106</pub-id></mixed-citation>
    </ref>
    <ref id="ref19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Senior</surname><given-names>AW</given-names></string-name>, <string-name><surname>Evans</surname><given-names>R</given-names></string-name>, <string-name><surname>Jumper</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Improved protein structure prediction using potentials from deep learning</article-title>. <source>Nature</source><year>2020</year>;<volume>577</volume>:<fpage>706</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">31942072</pub-id></mixed-citation>
    </ref>
    <ref id="ref20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>W</given-names></string-name>, <string-name><surname>Godzik</surname><given-names>A</given-names></string-name></person-group>. <article-title>Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences</article-title>. <source>Bioinformatics</source><year>2006</year>;<volume>22</volume>:<fpage>1658</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">16731699</pub-id></mixed-citation>
    </ref>
    <ref id="ref21">
      <label>21.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bolser</surname><given-names>D</given-names></string-name>, <string-name><surname>Staines</surname><given-names>DM</given-names></string-name>, <string-name><surname>Pritchard</surname><given-names>E</given-names></string-name>, <etal>et al.</etal></person-group><part-title>Ensembl plants: integrating tools for visualizing, mining, and analyzing plant genomics data</part-title>. In: <person-group person-group-type="editor"><string-name><prefix>van</prefix><surname>Dijk</surname><given-names>A</given-names></string-name></person-group> (ed). <source>Plant Genomics Databases. Methods in Molecular Biology</source>. <publisher-loc>New York</publisher-loc>:
<publisher-name>Humana Press</publisher-name>, <year>2016</year>, <fpage>115</fpage>–<lpage>40</lpage>.</mixed-citation>
    </ref>
    <ref id="ref22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Wang</surname><given-names>C</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Deep learning models for disease-associated circRNA prediction: a review</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:<fpage>bbac364</fpage>.<pub-id pub-id-type="pmid">36130259</pub-id></mixed-citation>
    </ref>
    <ref id="ref23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Luo</surname><given-names>M</given-names></string-name>, <string-name><surname>Lin</surname><given-names>W</given-names></string-name>, <etal>et al.</etal></person-group><article-title>DLpTCR: an ensemble deep learning framework for predicting immunogenic peptide recognized by T cell receptor</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>(<issue>6</issue>):<fpage>bbab335</fpage>.<pub-id pub-id-type="pmid">34415016</pub-id></mixed-citation>
    </ref>
    <ref id="ref24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>H</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Pan</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>ncRNAInter: a novel strategy based on graph neural network to discover interactions between lncRNA and miRNA</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:<fpage>bbac411</fpage>.<pub-id pub-id-type="pmid">36198065</pub-id></mixed-citation>
    </ref>
    <ref id="ref25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xuan</surname><given-names>P</given-names></string-name>, <string-name><surname>Wang</surname><given-names>S</given-names></string-name>, <string-name><surname>Cui</surname><given-names>H</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Learning global dependencies and multi-semantics within heterogeneous graph for predicting disease-related lncRNAs</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>(<issue>5</issue>):<fpage>bbac361</fpage>.<pub-id pub-id-type="pmid">36088549</pub-id></mixed-citation>
    </ref>
    <ref id="ref26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lipkova</surname><given-names>J</given-names></string-name>, <string-name><surname>Chen</surname><given-names>RJ</given-names></string-name>, <string-name><surname>Chen</surname><given-names>B</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Artificial intelligence for multimodal data integration in oncology</article-title>. <source>Cancer Cell</source><year>2022</year>;<volume>40</volume>:<fpage>1095</fpage>–<lpage>110</lpage>.<pub-id pub-id-type="pmid">36220072</pub-id></mixed-citation>
    </ref>
    <ref id="ref27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jin</surname><given-names>S</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>X</given-names></string-name>, <string-name><surname>Xia</surname><given-names>F</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Application of deep learning methods in biological networks</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:<fpage>1902</fpage>–<lpage>17</lpage>.<pub-id pub-id-type="pmid">32363401</pub-id></mixed-citation>
    </ref>
    <ref id="ref28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>JY</given-names></string-name>, <string-name><surname>Shen</surname><given-names>H</given-names></string-name>, <string-name><surname>Qu</surname><given-names>Q</given-names></string-name>, <etal>et al.</etal></person-group><article-title>The application of deep learning in electrocardiogram: where we came from and where we should go?</article-title><source>Int J Cardiol</source><year>2021</year>;<volume>337</volume>:<fpage>71</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">34000355</pub-id></mixed-citation>
    </ref>
    <ref id="ref29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>G</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A novel brain-computer interface based on audio-assisted visual evoked EEG and spatial-temporal attention CNN</article-title>. <source>Front Neurorobot</source><year>2022</year>;<volume>16</volume>:<fpage>995552</fpage>.<pub-id pub-id-type="pmid">36247357</pub-id></mixed-citation>
    </ref>
    <ref id="ref30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luo</surname><given-names>Z</given-names></string-name>, <string-name><surname>Su</surname><given-names>W</given-names></string-name>, <string-name><surname>Lou</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>DLm6Am: a deep-learning-based tool for identifying N6,2'-O-Dimethyladenosine sites in RNA sequences</article-title>. <source>Int J Mol Sci</source><year>2022</year>;<volume>23</volume>:11026.</mixed-citation>
    </ref>
    <ref id="ref31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>L</given-names></string-name>, <string-name><surname>Luo</surname><given-names>H</given-names></string-name>, <string-name><surname>Bu</surname><given-names>D</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Utilizing sequence intrinsic composition to classify protein-coding and long non-coding transcripts</article-title>. <source>Nucleic Acids Res</source><year>2013</year>;<volume>41</volume>:<fpage>e166</fpage>.<pub-id pub-id-type="pmid">23892401</pub-id></mixed-citation>
    </ref>
    <ref id="ref32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>A</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Z</given-names></string-name></person-group>. <article-title>PLEK: a tool for predicting long non-coding RNAs and messenger RNAs based on an improved k-mer scheme</article-title>. <source>BMC Bioinformatics</source><year>2014</year>;<volume>15</volume>:<fpage>311</fpage>.<pub-id pub-id-type="pmid">25239089</pub-id></mixed-citation>
    </ref>
    <ref id="ref33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnsson</surname><given-names>P</given-names></string-name>, <string-name><surname>Ziegenhain</surname><given-names>C</given-names></string-name>, <string-name><surname>Hartmanis</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Transcriptional kinetics and molecular functions of long noncoding RNAs</article-title>. <source>Nat Genet</source><year>2022</year>;<volume>54</volume>:<fpage>306</fpage>–<lpage>17</lpage>.<pub-id pub-id-type="pmid">35241826</pub-id></mixed-citation>
    </ref>
    <ref id="ref34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gruber</surname><given-names>AR</given-names></string-name>, <string-name><surname>Lorenz</surname><given-names>R</given-names></string-name>, <string-name><surname>Bernhart</surname><given-names>SH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>The Vienna RNA Websuite</article-title>. <source>Nucleic Acids Res</source><year>2008</year>;<volume>36</volume>:<fpage>W70</fpage>–<lpage>4</lpage>.<pub-id pub-id-type="pmid">18424795</pub-id></mixed-citation>
    </ref>
    <ref id="ref35">
      <label>35.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hanumanthappa</surname><given-names>AK</given-names></string-name>, <string-name><surname>Singh</surname><given-names>J</given-names></string-name>, <string-name><surname>Paliwal</surname><given-names>K</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Single-sequence and profile-based prediction of RNA solvent accessibility using dilated convolutional neural network</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>5169</fpage>–<lpage>76</lpage>.</mixed-citation>
    </ref>
    <ref id="ref36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>Consortium TU</collab></person-group>. <article-title>UniProt: the universal protein knowledgebase in 2021</article-title>. <source>Nucleic Acids Res</source><year>2021</year>;<volume>49</volume>:<fpage>D480</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">33237286</pub-id></mixed-citation>
    </ref>
    <ref id="ref37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nawrocki</surname><given-names>EP</given-names></string-name>, <string-name><surname>Eddy</surname><given-names>SR</given-names></string-name></person-group>. <article-title>Infernal 1.1: 100-fold faster RNA homology searches</article-title>. <source>Bioinformatics</source><year>2013</year>;<volume>29</volume>:<fpage>2933</fpage>–<lpage>5</lpage>.<pub-id pub-id-type="pmid">24008419</pub-id></mixed-citation>
    </ref>
    <ref id="ref38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kalvari</surname><given-names>I</given-names></string-name>, <string-name><surname>Nawrocki</surname><given-names>EP</given-names></string-name>, <string-name><surname>Ontiveros-Palacios</surname><given-names>N</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Rfam 14: expanded coverage of metagenomic, viral and microRNA families</article-title>. <source>Nucleic Acids Res</source><year>2021</year>;<volume>49</volume>:<fpage>D192</fpage>–<lpage>200</lpage>.<pub-id pub-id-type="pmid">33211869</pub-id></mixed-citation>
    </ref>
    <ref id="ref39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>J</given-names></string-name>, <string-name><surname>Liang</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Modeling hepatoblastoma development with human fetal liver organoids reveals YAP1 activation is sufficient for tumorigenesis</article-title>. <source>Protein Cell</source><year>2022</year>;<volume>13</volume>:<fpage>683</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">34893955</pub-id></mixed-citation>
    </ref>
    <ref id="ref40">
      <label>40.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Parker</surname><given-names>MD</given-names></string-name></person-group>. <article-title>Mouse models of SLC4-linked disorders of HCO(3)(−)-transporter dysfunction</article-title>. <source>Am J Physiol Cell Physiol</source><year>2018</year>;<volume>314</volume>:<fpage>C569</fpage>–<lpage>88</lpage>.<pub-id pub-id-type="pmid">29384695</pub-id></mixed-citation>
    </ref>
    <ref id="ref41">
      <label>41.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Puschhof</surname><given-names>J</given-names></string-name>, <string-name><surname>Pleguezuelos-Manzano</surname><given-names>C</given-names></string-name>, <string-name><surname>Clevers</surname><given-names>H</given-names></string-name></person-group>. <article-title>Organoids and organs-on-chips: insights into human gut-microbe interactions</article-title>. <source>Cell Host Microbe</source><year>2021</year>;<volume>29</volume>:<fpage>867</fpage>–<lpage>78</lpage>.<pub-id pub-id-type="pmid">34111395</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
