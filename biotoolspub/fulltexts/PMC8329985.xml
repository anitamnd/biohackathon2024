<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//APA//DTD APA Journal Archive DTD v1.0 20130715//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName APAjournal-archive.dtd?>
<?SourceDTD.Version 1.0?>
<?ConverterInfo.XSLTName apaja2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Psychol Methods</journal-id>
    <journal-id journal-id-type="iso-abbrev">Psychol Methods</journal-id>
    <journal-title-group>
      <journal-title>Psychological Methods</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1082-989X</issn>
    <issn pub-type="epub">1939-1463</issn>
    <publisher>
      <publisher-name>American Psychological Association</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8329985</article-id>
    <article-id pub-id-type="pmid">32673043</article-id>
    <article-id pub-id-type="publisher-id">met_26_3_295</article-id>
    <article-id pub-id-type="doi">10.1037/met0000337</article-id>
    <article-id pub-id-type="publisher-id">2020-52357-001</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Articles</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Power Contours: Optimising Sample Size and Precision in Experimental Psychology and Human Neuroscience</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="editor" corresp="no">
        <name>
          <surname>Steinley</surname>
          <given-names>Douglas</given-names>
        </name>
        <role>Editor</role>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0161-443X</contrib-id>
        <name>
          <surname>Baker</surname>
          <given-names>Daniel H.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="corr1" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author" corresp="no">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2011-5150</contrib-id>
        <name>
          <surname>Vilidaite</surname>
          <given-names>Greta</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="no">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8043-4866</contrib-id>
        <name>
          <surname>Lygo</surname>
          <given-names>Freya A.</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="no">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4584-5501</contrib-id>
        <name>
          <surname>Smith</surname>
          <given-names>Anika K.</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="no">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4115-4466</contrib-id>
        <name>
          <surname>Flack</surname>
          <given-names>Tessa R.</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">4</xref>
      </contrib>
      <contrib contrib-type="author" corresp="no">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0674-7829</contrib-id>
        <name>
          <surname>Gouws</surname>
          <given-names>André D.</given-names>
        </name>
        <xref rid="aff5" ref-type="aff">5</xref>
      </contrib>
      <contrib contrib-type="author" corresp="no">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8255-9120</contrib-id>
        <name>
          <surname>Andrews</surname>
          <given-names>Timothy J.</given-names>
        </name>
        <xref rid="aff6" ref-type="aff">6</xref>
      </contrib>
      <aff id="aff1"><label>1</label>Department of Psychology and York Biomedical Research Institute, University of York</aff>
      <aff id="aff2"><label>2</label>School of Psychology, University of Southampton</aff>
      <aff id="aff3"><label>3</label>Department of Psychology, University of York</aff>
      <aff id="aff4"><label>4</label>School of Psychology, University of Lincoln</aff>
      <aff id="aff5"><label>5</label>York Neuroimaging Centre, University of York</aff>
      <aff id="aff6"><label>6</label>Department of Psychology, University of York</aff>
    </contrib-group>
    <author-notes>
      <p>We are grateful to everyone involved in collection of the data sets reanalyzed here, and particularly to those who made their data publicly available. This work was supported in part by a Wellcome Trust (ref: 105624) grant, through the Centre for Chronic Diseases and Disorders (C2D2) at the University of York, awarded to Daniel H. Baker. Data collection and sharing for part of this project was provided by the Cambridge Centre for Ageing and Neuroscience (CamCAN). CamCAN funding was provided by the U.K. Biotechnology and Biological Sciences Research Council (Grant BB/H008217/1), together with support from the U.K. Medical Research Council and University of Cambridge, United Kingdom. We also thank Tom Hartley for helpful comments and for suggesting inclusion of the Iowa Gambling Task data set, and all those who offered constructive suggestions based on the preprint.</p>
      <fn id="fn1" fn-type="open-data">
        <label>open-data-small.gif</label>
        <p>The data are available at <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.17605/OSF.IO/EBHNK" specific-use="live">http://dx.doi.org/10.17605/OSF.IO/EBHNK</ext-link>.</p>
      </fn>
      <fn id="fn2" fn-type="open-materials">
        <label>open-materials-small.gif</label>
        <p>The analysis scripts are available at <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.17605/OSF.IO/EBHNK" specific-use="live">http://dx.doi.org/10.17605/OSF.IO/EBHNK</ext-link>.</p>
      </fn>
      <corresp id="corr1"><label>*</label>Correspondence concerning this article should be addressed to Daniel H. Baker, Department of Psychology, University of York, Heslington, York YO10 5DD, United Kingdom <email>daniel.baker@york.ac.uk</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>16</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <month>6</month>
      <year>2021</year>
    </pub-date>
    <volume>26</volume>
    <issue>3</issue>
    <fpage>295</fpage>
    <lpage>314</lpage>
    <history>
      <date date-type="received">
        <day>5</day>
        <month>3</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>5</day>
        <month>2</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>26</day>
        <month>5</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2020 The Author(s)</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>The Author(s)</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/3.0/</ali:license_ref>
        <license-p>This article has been published under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" specific-use="live" xlink:href="https://creativecommons.org/licenses/by/3.0/">http://creativecommons.org/licenses/by/3.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Copyright for this article is retained by the author(s). Author(s) grant(s) the American Psychological Association the exclusive right to publish the article and identify itself as the original publisher.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>When designing experimental studies with human participants, experimenters must decide how many trials each participant will complete, as well as how many participants to test. Most discussion of statistical power (the ability of a study design to detect an effect) has focused on sample size, and assumed sufficient trials. Here we explore the influence of both factors on statistical power, represented as a 2-dimensional plot on which iso-power contours can be visualized. We demonstrate the conditions under which the number of trials is particularly important, that is, when the within-participant variance is large relative to the between-participants variance. We then derive power contour plots using existing data sets for 8 experimental paradigms and methodologies (including reaction times, sensory thresholds, fMRI, MEG, and EEG), and provide example code to calculate estimates of the within- and between-participants variance for each method. In all cases, the within-participant variance was larger than the between-participants variance, meaning that the number of trials has a meaningful influence on statistical power in commonly used paradigms. An online tool is provided (<ext-link ext-link-type="uri" xlink:href="https://shiny.york.ac.uk/powercontours/" specific-use="live">https://shiny.york.ac.uk/powercontours/</ext-link>) for generating power contours, from which the optimal combination of trials and participants can be calculated when designing future studies.</p>
    </abstract>
    <abstract abstract-type="impact-statement">
      <title>Translational Abstract</title>
      <p>Many studies in neuroscience and experimental psychology involve testing human participants multiple times in a given condition, and averaging across these repetitions to get a more accurate estimate of the true response. Yet most researchers do not have a principled way to decide how many trials they should conduct, and decisions are often made using arbitrary criteria. This is an important issue because the number of trials has a direct effect on the statistical power of a study—the likelihood that it is able to detect a real effect. In the context of the recent “replication crisis” in psychology, researchers need tools to optimize the quality of their research designs to increase power. Here we propose a way to visualize the combined effect of sample size (the number of participants tested) and number of trials per participant on statistical power, using a two-dimensional contour plot. We show by subsampling eight existing data sets from a range of widely used methods (including reaction times, EEG, MEG, and fMRI) that these contours are curved, and permit estimation of an optimal number of participants and trials at the study design stage. All of the analysis scripts, as well as an online tool, are provided to permit others to tailor our methods to their own experimental paradigms. We anticipate that this approach will facilitate the design of experimental studies that are more efficient, and more likely to report real effects.</p>
    </abstract>
    <kwd-group>
      <kwd>statistical power</kwd>
      <kwd>sample size</kwd>
      <kwd>neuroscience</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <p>Statistical power is the ability of a study design with a given sample size to detect an effect of a particular magnitude. In recent years, the problems with low statistical power have been increasingly highlighted (<xref rid="c2" ref-type="bibr" id="cr2-1">Bishop, 2019</xref>). Low powered studies are less able to detect a true effect (and so make more Type II errors) compared with high powered studies. Nominally significant findings from low powered studies are less likely to reflect true effects (<xref rid="c9" ref-type="bibr" id="cr9-1">Button et al., 2013</xref>), and because of publication bias (whereby significant findings are more likely to be published than nonsignificant ones) published low powered studies will also have a high Type I error (false positive) rate. Furthermore, any real effects that are detected are likely to have inflated effect sizes (<xref rid="c13" ref-type="bibr" id="cr13-1">Colquhoun, 2014</xref>; <xref rid="c17" ref-type="bibr" id="cr17-1">Ioannidis, 2008</xref>). These problems are common across many scientific disciplines, and estimates of power across studies in the neurosciences (<xref rid="c9" ref-type="bibr" id="cr9-2">Button et al., 2013</xref>) yield power values in the range 8–30%, far below the desired level of ≥80%. The prevalence of low-powered studies has filled some areas of the literature with effects that fail to replicate and may well be spurious (<xref rid="c16" ref-type="bibr" id="cr16-1">Ioannidis, 2005</xref>; <xref rid="c27" ref-type="bibr" id="cr27-1">Open Science Collaboration, 2015</xref>). Most discussion of increasing statistical power has focused on recruiting larger sample sizes, because for a given effect size, power is a function of sample size (see <xref ref-type="fig" id="fgc1-1" rid="fig1">Figure 1d</xref>). However there is a second degree of freedom available to many experimenters at the study design stage—the number of repetitions (or trials) of a given experimental condition by each participant.<xref ref-type="fig-anchor" rid="fig1"/></p>
  <p>When the dependent variable of interest can be estimated with high precision, repeated measurements provide little benefit, and the main source of variance is between participants. This is illustrated by the distribution in <xref ref-type="fig" id="fgc1-2" rid="fig1">Figure 1a</xref>, where participants (points) differ according to a normal distribution (curve), but the variance of each individual point is negligible. A more realistic situation for many experimental paradigms is shown in <xref ref-type="fig" id="fgc1-3" rid="fig1">Figure 1b</xref>, where the variance of each individual estimate is large, as indicated by the horizontal standard error bars. This has the knock-on effect of increasing the overall standard deviation of the sample (σ<sub><italic>s</italic></sub> = 2 units in <xref ref-type="fig" id="fgc1-4" rid="fig1">Figure 1a</xref>, and σ<sub><italic>s</italic></sub> = 3 units in <xref ref-type="fig" id="fgc1-5" rid="fig1">Figure 1b</xref>). Such inflation of the sample standard deviation can be ameliorated by improving the accuracy of each participant’s estimated mean by increasing the number of measurements. This is demonstrated in <xref ref-type="fig" id="fgc1-6" rid="fig1">Figure 1c</xref>, where each participant’s mean is estimated from <italic>k</italic> = 200 trials (compared with <italic>k</italic> = 20 in <xref ref-type="fig" id="fgc1-7" rid="fig1">Figure 1b</xref>), and the standard deviation of the sample (curve) reduces substantially (to σ<sub><italic>s</italic></sub> = 2.1 units).</p>
  <p>Power is typically derived using effect size measures such as Cohen’s <italic>d</italic> (<xref rid="c12" ref-type="bibr" id="cr12-1">Cohen, 1988</xref>), which depends on the sample mean (or difference in means), and also the sample standard deviation (formally <italic>d</italic> = <italic>M</italic>/σ<sub><italic>s</italic></sub>). Under parametric assumptions, the number of trials per participant (<italic>k</italic>) influences the sample standard deviation (<xref ref-type="fig" id="fgc1-8" rid="fig1">Figure 1e</xref>), according to the equation:
<disp-formula id="eqn1"><alternatives><graphic xlink:href="met_26_3_295_eqn1a.jpg" id="eqn1a"/><mml:math id="M1"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mi>k</mml:mi></mml:mfrac></mml:mrow></mml:msqrt></mml:mrow></mml:math></alternatives><label>1</label></disp-formula>
where σ<sub><italic>b</italic></sub> and σ<sub><italic>w</italic></sub> are the between- and (average) within-participant standard deviations, and <italic>k</italic> is the number of trials per participant (see also <xref rid="c6" ref-type="bibr" id="cr6-1">Brandmaier et al., 2018</xref>). The sample standard deviation (σ<sub><italic>s</italic></sub>) determines the effect size, and subsequently the power (<xref ref-type="fig" id="fgc1-9" rid="fig1">Figure 1f</xref>). In domains where the dependent variable is subject to high within-participant variance (as is potentially the case in psychology and neuroscience studies), increasing the precision of the per-participant estimate can therefore greatly increase overall power, perhaps reducing the number of participants required for a study (see <xref rid="c11" ref-type="bibr" id="cr11-1">Cleary &amp; Linn, 1969</xref>; <xref rid="c28" ref-type="bibr" id="cr28-1">Phillips &amp; Jiang, 2016</xref>). Although most active researchers are intuitively aware of this fact (it is common knowledge that running lots of trials delivers “better” data), and the problem has received mathematical treatment (<xref rid="c19" ref-type="bibr" id="cr19-1">Kanyongo, Brook, Kyei-Blankson, &amp; Gocmen, 2007</xref>; <xref rid="c28" ref-type="bibr" id="cr28-2">Phillips &amp; Jiang, 2016</xref>; <xref rid="c30" ref-type="bibr" id="cr30-1">Rouder &amp; Haaf, 2018</xref>; <xref rid="c42" ref-type="bibr" id="cr42-1">Westfall, Kenny, &amp; Judd, 2014</xref>; <xref rid="c43" ref-type="bibr" id="cr43-1">Williams &amp; Zimmerman, 1989</xref>), there is no widely used procedure for quantitatively determining the appropriate number of trials to run. Instead, studies are typically designed using rules of thumb, prior precedent and guesswork.</p>
  <p>In this article, we advocate a useful representation, the <italic>power contour</italic> plot—a two-dimensional representation of power as the joint function of sample size (<italic>N</italic>) and number of trials (<italic>k</italic>). We provide an online tool for generating power contours in order to estimate the impact of measurement precision (the number of trials conducted) on statistical power. We then use a subsampling method to explore the joint effects of sample size and number of trials on real data sets using common methodologies and paradigms in psychology and neuroscience research. These measures include reaction times (RTs), psychophysical thresholds, event-related potentials, steady-state evoked potentials, and fMRI BOLD signals. We make computer code available to demonstrate how power contours were produced, and how estimates of the within- and between-participants variance were calculated for each example.</p>
  <sec id="s2">
    <title>Power Contours</title>
    <p>Consider first the situation described above, in which the dependent variable of interest can be estimated accurately from a single trial, but individuals all express different true values of the variable (formally, the within-participant variance is low, but the between-participants variance is high, σ<sub><italic>w</italic></sub> &lt;&lt; σ<sub><italic>b</italic></sub>). Examples might include variables such as age and height, for which there is low measurement error and minimal variation from moment to moment, or for which tools exist (such as tape measures) to facilitate accurate measurement. In these situations, statistical power is a function of sample size and effect size (<xref ref-type="fig" id="fgc1-10" rid="fig1">Figure 1d</xref>), where effect size is Cohen’s <italic>d</italic>. Clearly, in such a situation, testing each participant multiple times should confer no advantage. We can represent the power as a function of both sample size and number of trials using a two-dimensional plot such as the one shown in <xref ref-type="fig" id="fgc1-11" rid="fig1">Figure 1g</xref>. Here the lines trace iso-power contours—combinations of sample size and number of trials that result in the same statistical power (this property is sometimes referred to as power equivalence, see <xref rid="c25" ref-type="bibr" id="cr25-1">von Oertzen, 2010</xref>). For this example the power contours are vertical, showing no benefit of repeated testing.</p>
    <p>Next consider a more realistic scenario—a situation where the individual measurements are very noisy (high within-participant variance relative to the between-participants variance, σ<sub><italic>w</italic></sub> &gt; σ<sub><italic>b</italic></sub>). The sample standard deviation decreases as a function of the number of trials (<xref ref-type="fig" id="fgc1-12" rid="fig1">Figure 1e</xref>), as the estimated mean for each participant becomes more accurate with repeated measurements. Now power depends on both the number of trials and the sample size, and a series of curved iso-power contours are apparent (<xref ref-type="fig" id="fgc1-13" rid="fig1">Figure 1h</xref>; see recent work by <xref rid="c42" ref-type="bibr" id="cr42-2">Westfall et al., 2014</xref> and <xref rid="c44" ref-type="bibr" id="cr44-1">Xu, Adam, Fang, &amp; Vogel, 2018</xref> for related plots in different scenarios).</p>
    <p>These power contours offer a useful summary of the effect of possible experimental designs on statistical power. A given power (e.g., 80%, indicated by the thick blue curves on the power contour plots) can be obtained from multiple combinations of sample size and trial number. This is a useful insight, as study designs can then be optimized depending on other constraints. If relatively few participants are available (perhaps because of financial constraints, or testing of a clinical population) then the number of trials can be increased. Note, however, that beyond a particular number of trials (around <italic>k</italic> = 50 in <xref ref-type="fig" id="fgc1-14" rid="fig1">Figure 1h</xref>), the function asymptotes and further trials are not beneficial. Alternatively, if each participant must be tested very rapidly (e.g., for studies involving children), but many participants are available, the number of trials could be kept relatively low (here around <italic>k</italic> = 20), and a larger sample size tested. This is of potential value for large cohort studies, in which many participants each complete a large battery of various tasks. A more typical situation is one in which an experimenter wishes to minimize both sample size and testing time—here values around the knee-point of the power contour permit joint optimization of both parameters. Power contour plots can be produced for any combination of within- and between-participants variances and difference in means using an <italic>R</italic> script, which can be accessed through a web interface at: <ext-link ext-link-type="uri" xlink:href="https://shiny.york.ac.uk/powercontours/" specific-use="live">https://shiny.york.ac.uk/powercontours/</ext-link>.</p>
    <p>To have practical value in the design of experiments, it is necessary to establish empirically whether power does indeed vary with the number of trials in typically used experimental paradigms. To this end, we have reanalyzed data from eight studies, using a range of common methodologies from psychology and cognitive neuroscience, including RTs, proportional choices, sensory thresholds, EEG, MEG, and fMRI. We estimate power contours by subsampling the data, so we aimed to include data sets featuring large sample sizes, in which each participant completed many trials (though it was not always possible to satisfy both criteria). All of these analyses are based on one-sample or paired <italic>t</italic> tests, but the same principle applies to more sophisticated statistical techniques (see the Discussion section), and can be implemented using the subsampling technique we describe below. All analysis scripts are available on the project repository at <ext-link ext-link-type="uri" xlink:href="https://osf.io/ebhnk/" specific-use="live">https://osf.io/ebhnk/</ext-link> and data sets are provided either on the project page or referenced directly throughout the article to allow others to reproduce our analyses, and apply the methods to their own studies. We anticipate that these resources will be most valuable as a guide for performing related subsampling analyses for specific study designs, and suggest that readers short on time might find it most useful to skip ahead to the section reporting data from whichever paradigm they are most familiar.</p>
  </sec>
  <sec id="s3">
    <title>Reaction Times</title>
    <p>We first analyzed RT measures from a Posner-style attentional cueing experiment previously reported by <xref rid="c29" ref-type="bibr" id="cr29-1">Pirrone, Wen, Li, Baker, and Milne (2018)</xref>. Participants (<italic>N</italic> = 38) saw a central cue stimulus directing their attention to either the left or the right of fixation. A sine wave grating target was then presented either in the attended location (congruent condition) or the unattended location (incongruent condition). Each participant completed <italic>k</italic> = 600 congruent trials and <italic>k</italic> = 200 incongruent trials, with example RT distributions for one participant shown in <xref ref-type="fig" id="fgc2-1" rid="fig2">Figure 2a</xref>. At the group level, RTs were on average 51 ms slower in the incongruent condition (see <xref ref-type="fig" id="fgc2-2" rid="fig2">Figure 2b</xref>), and the standard deviation of the differences (σ<sub><italic>s</italic></sub>) was 42 ms. For the full data set, this yielded an effect size of <italic>d</italic> = 1.2. We also estimated the within participants standard deviation by pooling the variances for the incongruent and congruent RTs, and averaging across participants, for which σ<sub><italic>w</italic></sub> = 151 ms. Finally, to estimate σ<sub><italic>b</italic></sub> we rearranged <xref ref-type="disp-formula" id="eqnc1-1" rid="eqn1">Equation 1</xref> to give:
<disp-formula id="eqn2"><alternatives><graphic xlink:href="met_26_3_295_eqn2a.jpg" id="eqn2a"/><mml:math id="M2"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mi>k</mml:mi></mml:mfrac></mml:mrow></mml:msqrt><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives><label>2</label></disp-formula>
which produced a value of σ<sub><italic>b</italic></sub> = 41 ms.<xref ref-type="fig-anchor" rid="fig2"/></p>
    <p>We calculated statistical power by resampling random subsets of trials and participants from the data, and calculating the effect size and power using the mean and standard deviation, for a paired <italic>t</italic> test comparing to 0 (using the <italic>pwr.t.test</italic> function in the <italic>pwr</italic> package in <italic>R</italic>). Note that an alternative is simply to calculate a <italic>t</italic> test with the resampled data, and calculate the proportion of tests that are significant, but the direct estimation of power is computationally more efficient so we use this where possible. The subsampling procedure was repeated 10,000 times, and the averaged power estimates are shown in <xref ref-type="fig" id="fgc2-3" rid="fig2">Figure 2c</xref>. Just as predicted by our simulations (<xref ref-type="fig" id="fgc1-15" rid="fig1">Figure 1h</xref>), the iso-power contour for 80% power (shown by the thick blue line) is curved (we confirmed the subsampling result by using the summary statistics calculated above in the power contour <italic>Shiny</italic> app). High power can be obtained with either a large sample size (<italic>N</italic> &gt; 20) and small number of trials (<italic>k</italic> &lt; 10) or a large number of trials (<italic>k</italic> &gt; 50) and small sample size (<italic>N</italic> = 8). The knee-point of the function is around a sample size of <italic>N</italic> = 10, with each participant completing approximately <italic>k</italic> = 20 trials. Of course, this is for a relatively large effect size with a robust and well-established effect (attentional cueing). Other study designs with smaller sized effects will require larger sample sizes and/or more trials, but it is clear that the same basic pattern should apply for experiments of this type.</p>
  </sec>
  <sec id="s4">
    <title>Proportional Choices in the Iowa Gambling Task</title>
    <p>We next reanalyzed a data set comprising <italic>N</italic> = 504 participants in the Iowa Gambling Task, as reported by <xref rid="c35" ref-type="bibr" id="cr35-1">Steingroever et al. (2015)</xref>, and made available through that publication. In this task, participants choose cards from four decks. Two decks have a greater overall payoff (“good” decks), and the other two have a poorer payoff (“bad” decks). Participants must learn these contingencies during the course of the experiment, and attempt to maximize their payoff. As such performance changes throughout the experiment, and we discuss the consequences of this learning below, but begin with an analysis of the aggregated (e.g., unordered) trials. <xref ref-type="fig" id="fgc3-1" rid="fig3">Figure 3a</xref> shows summary data for a population of participants who each completed <italic>k</italic> = 100 trials of the task. Averaged across all trials, the mean probability of selecting a card from a “good” deck was 0.54 (sample <italic>SD</italic> of σ<sub><italic>s</italic></sub> = 0.16), an effect size of <italic>d</italic> = 0.24 when compared with the chance baseline of 0.5 (see <xref ref-type="fig" id="fgc3-2" rid="fig3">Figure 3a</xref>). We calculated the standard deviation of individual choices, and averaged across participants to give σ<sub><italic>w</italic></sub> = 0.47, implying (via <xref ref-type="disp-formula" id="eqnc2-1" rid="eqn2">Equation 2</xref>) a between-subjects standard deviation of σ<sub><italic>b</italic></sub> = 0.15.<xref ref-type="fig-anchor" rid="fig3"/></p>
    <p>We again calculated power by resampling random subsets of trials and participants from the data, and calculating the effect size and power using the mean and standard deviation, for a one-sample <italic>t</italic> test comparing to 0.5 (using the <italic>pwr.t.test</italic> function in the <italic>pwr</italic> package in <italic>R</italic>). This procedure was repeated 10,000 times, and the averaged power estimates are shown in <xref ref-type="fig" id="fgc3-3" rid="fig3">Figure 3b</xref>. Consistent with the simulations in <xref ref-type="fig" id="fgc1-16" rid="fig1">Figure 1h</xref>, power depends on both sample size and number of trials. With small numbers of trials (<italic>k</italic> &lt; 40), sample size can be dramatically reduced by increasing trial numbers. For example, by increasing from <italic>k</italic> = 5 to <italic>k</italic> = 40 trials, the sample size can be reduced from <italic>N</italic> = 400 to <italic>N</italic> = 200 while maintaining power. Alternatively, for a sample size of <italic>N</italic> = 200, there are few gains to be made by increasing from <italic>k</italic> = 40 to <italic>k</italic> = 100 trials, as the function has reached asymptote.</p>
    <p>In the Iowa Gambling Task, the trial contingencies are learned throughout the experiment. The black trace in <xref ref-type="fig" id="fgc3-4" rid="fig3">Figure 3a</xref> illustrates that at the start of the experiment participants are more likely to choose cards from the “bad” decks for around the first 20 trials. Their behavior then changes as they learn the task contingencies, and for the final 40 trials they are more likely to choose cards from the “good” decks. This information is lost by randomly sampling trials as we did to generate the power contour plot in <xref ref-type="fig" id="fgc3-5" rid="fig3">Figure 3b</xref>. An alternative is to retain the trial order, and resample only across participants. Power contours are shown for this analysis in <xref ref-type="fig" id="fgc3-6" rid="fig3">Figure 3c</xref>. Over the first 40 trials, power is high because the mean probability is significantly below 0.5 (see black curve in <xref ref-type="fig" id="fgc3-7" rid="fig3">Figure 3a</xref>). As participants start to learn the task contingencies, the mean probability passes through 0.5, and power falls to near zero around 60 trials. Then, as participants begin to reliably choose the “good” deck, the average probability becomes significantly above 0.5 and power increases again, reaching 80% by around 80 trials with the full sample of participants. This alternative visualization of the data could be valuable when planning studies using this task, as it shows explicitly how performance (and hence overall power) changes over time.</p>
  </sec>
  <sec id="s5">
    <title>Sensory Thresholds</title>
    <p>Psychophysical detection thresholds are typically measured using large numbers of binary trials across stimuli of different intensities. The proportion of correct trials increases monotonically with stimulus intensity, producing a psychometric function (see <xref ref-type="fig" id="fgc4-1" rid="fig4">Figure 4a</xref>). Threshold is then estimated at some criterion performance level (often 75% correct) by fitting a continuous ogival function such as a cumulative Gaussian or Weibull distribution. We reanalyzed data from a binocular summation experiment (reported by <xref rid="c1" ref-type="bibr" id="cr1-1">Baker, Lygo, Meese, &amp; Georgeson, 2018</xref>), in which contrast detection thresholds were measured in this way for sine wave grating stimuli shown either monocularly or binocularly using a stereo shutter goggle system. Example psychometric functions for a single participant are shown in <xref ref-type="fig" id="fgc4-2" rid="fig4">Figure 4a</xref> (fitted using the <italic>quickpsy</italic> package in <italic>R</italic>, see <xref rid="c20" ref-type="bibr" id="cr20-1">Linares &amp; López-Moliner, 2016</xref>), where it is clear that equivalent performance requires higher contrast for monocular presentation (blue) than for binocular presentation (yellow). At the group level (see <xref ref-type="fig" id="fgc4-3" rid="fig4">Figure 4b</xref>), this produces a ratio of monocular to binocular thresholds between <mml:math id="math1"><mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow></mml:math> and 2—the well-known binocular summation effect—which here had an effect size of <italic>d</italic> = 1.8. The mean effect was 6.6<italic>dB</italic>, with a sample standard deviation of σ<sub><italic>s</italic></sub> = 3.6<italic>dB</italic>.<xref ref-type="fig-anchor" rid="fig4"/></p>
    <p>We subsampled the data set to produce the power contour plot shown in <xref ref-type="fig" id="fgc4-4" rid="fig4">Figure 4c</xref>. Because each participant completed slightly different numbers of trials (due to the adaptive staircase procedure used to determine contrast levels for each trial), we subsampled at different percentages of trials for each participant, refitting the psychometric function each time. On average, each participant completed 225 trials for the binocular condition, and for the monocular conditions for each eye (left and right eyes were tested separately and their data combined). Summation estimates were rejected when they fell outside of a reasonable range (between factors of 0.12 and 32), as this indicated that something had gone wrong with the fitting procedure. As anticipated, power depended on both sample size and number of trials, and continued to improve over the ranges available in the data set (i.e., the function at 80% power was quite shallow, and did not asymptote over the ranges tested). Indeed, with all trials included, only around six participants were required to reach 80% power (consistent with previous estimates of power for this paradigm, see <xref rid="c1" ref-type="bibr" id="cr1-2">Baker et al., 2018</xref>). Conversely, when all 38 participants were included, only around 15% of trials were required (around 34 trials for each condition). Alternatively, 80% power could be maintained with a sample size of <italic>N</italic> = 12, with each participant completing around 30% of the total trials.</p>
    <p>For this paradigm, estimating the within-participant standard deviation was not straightforward because threshold were calculated by fitting a psychometric function. So, we generated power contour surfaces for a range of possible σ<sub><italic>w</italic></sub> values, and compared these numerically with the surface derived by subsampling (<xref ref-type="fig" id="fgc4-5" rid="fig4">Figure 4c</xref>). The best fitting value was σ<sub><italic>w</italic></sub> = 33.5 <italic>dB</italic>, which implies (via <xref ref-type="disp-formula" id="eqnc2-2" rid="eqn2">Equation 2</xref>) a between-participants standard deviation of σ<sub><italic>b</italic></sub> = 1.3 <italic>dB</italic>.</p>
  </sec>
  <sec id="s6">
    <title>EEG: Event-Related Potentials</title>
    <p>We next analyzed event-related potentials (ERPs) from a contrast discrimination experiment reported by <xref rid="c38" ref-type="bibr" id="cr38-1">Vilidaite, Marsh, and Baker (2019)</xref>, recorded using a 64-channel EEG cap. The stimuli were sine wave gratings with a contrast of 50%, presented sequentially in pairs for 100 ms each, with an interstimulus interval of 400–600 ms. These produced a typical response (see <xref ref-type="fig" id="fgc5-1" rid="fig5">Figure 5a</xref>) over occipital electrodes (see inset to <xref ref-type="fig" id="fgc5-2" rid="fig5">Figure 5a</xref>), with positive peaks at around 120 ms and 220 ms (marking stimulus onset and offset), and a later negative region with a trough around 600 ms. The first stimulus of each pair (yellow curve) produced a generally more positive response than the second stimulus (blue curve), in part as a consequence of differential overlap, though the precise cause of the differences are unimportant for this demonstration. Each trial was baselined by subtracting the mean voltage during the 200 ms before stimulus onset. The sample size for this experiment (<italic>N</italic> = 22) was modest (albeit typical for ERP research), but each participant completed a large number of trials (<italic>k</italic> = 600 stimulus pairs).<xref ref-type="fig-anchor" rid="fig5"/></p>
    <p>For each participant, we calculated the peak voltage and latency within three time windows, highlighted gray in <xref ref-type="fig" id="fgc5-3" rid="fig5">Figure 5a</xref>. These were 100–150 ms, 200–300 ms, and 500–700 ms, and corresponded to the P100, P200, and N600 components respectively. The peak voltages and latencies were compared between the two intervals using a repeated measures approach. The distributions of peak voltages and voltage differences across participants are shown in <xref ref-type="fig" id="fgc5-4" rid="fig5">Figure 5b–d</xref> for the three time windows, which produced effect sizes (Cohen’s <italic>d</italic>) of 1.18, 1.11, and 1.32. We performed similar calculations for the latencies, however, these were less convincing, with effect sizes of <italic>d</italic> = 0.21, 0.04, and 0.47 for the three time windows. We do not consider them further here, though power contours could be calculated for data sets with more robust latency differences.</p>
    <p>We calculated power contours for each of the three peak voltage differences by subsampling trials and participants, and reestimating the peak for each participant and condition on each of 10,000 iterations. These are shown in <xref ref-type="fig" id="fgc5-5" rid="fig5">Figure 5e–g</xref>, and had the expected format in all cases. For the P100 component, power continued to increase across all sample sizes and trial numbers tested. For the N600 component, power was largely determined by sample size, and only for relatively few trials (<italic>k</italic> &lt; 200) could sample size be materially reduced by adding more trials. This suggests that the limitations on statistical power in typical ERP experiments can depend on both sample size and number of trials, and that their relative contributions may depend on the size of the effect being studied. See also <xref rid="c3" ref-type="bibr" id="cr3-1">Boudewyn, Luck, Farrens, and Kappenman (2018)</xref> and <xref rid="c10" ref-type="bibr" id="cr10-1">Clayson and Miller (2017)</xref> for more detailed discussion of these issues in ERP studies. For this data set, estimates of standard deviations ranged from 12μ<italic>V</italic> to 21μ<italic>V</italic> for σ<sub><italic>w</italic></sub>, and from 1.1μ<italic>V</italic> to 5.3μ<italic>V</italic> for σ<sub><italic>b</italic></sub>.</p>
  </sec>
  <sec id="s7">
    <title>EEG: Steady-State Evoked Potentials</title>
    <p>An alternative EEG paradigm is the steady-state method, where a stimulus oscillates at a particular frequency, inducing entrained neural responses at that same frequency. In an experiment reported by <xref rid="c39" ref-type="bibr" id="cr39-1">Vilidaite et al. (2018)</xref>, sine wave gratings of different contrasts were flickered at 7 Hz, and shown to a sample of <italic>N</italic> = 100 participants. Each participant completed eight trials of 11 s per contrast level, from which the first 1 s of EEG data was discarded, and the remaining 10 s were divided into 10 epochs of 1 s each, yielding a total of <italic>k</italic> = 80 observations per condition. Each epoch was then Fourier transformed, and responses are evident both at the fundamental (flicker) frequency (7 Hz) and its second harmonic (14 Hz), as shown in <xref ref-type="fig" id="fgc6-1" rid="fig6">Figure 6a</xref>. For these visual stimuli, the responses are strongest at the occipital pole, near early visual cortex (see inset to <xref ref-type="fig" id="fgc6-2" rid="fig6">Figure 6a</xref>).<xref ref-type="fig-anchor" rid="fig6"/></p>
    <p>Responses at the fundamental frequency increase monotonically with maximum stimulus contrast (see <xref ref-type="fig" id="fgc6-3" rid="fig6">Figure 6b</xref>) at electrode <italic>Oz</italic>. For a stimulus contrast of 8% (marked by the blue circle), comparing absolute responses (i.e., removing the phase component before averaging) to the baseline condition (0% contrast, yellow circle) results in an effect size of <italic>d</italic> = 0.2. However this can be substantially increased (to <italic>d</italic> = 0.68) by using coherent averaging, in which both the amplitude and phase information are averaged across trials for each individual participant (and the absolute amplitudes are then averaged across participants). The improvement occurs because responses to the stimuli are phase-locked, and therefore should have the same phase on each trial. Any noise at the stimulus frequency has random phase, and so cancels out over multiple repetitions. Example Fourier spectra for both coherent (blue) and incoherent (red) averaging methods are shown in <xref ref-type="fig" id="fgc6-4" rid="fig6">Figure 6a</xref>, where it is clear that the coherent method greatly reduces the noise at off-target frequencies. Note in particular the increase in noise in the alpha band (8–12 Hz) is clear with incoherent averaging (red) but absent with coherent averaging (blue). In the contrast response function (<xref ref-type="fig" id="fgc6-5" rid="fig6">Figure 6b</xref>), coherent averaging (blue function) leads to lower amplitudes at low stimulus contrasts, whereas with incoherent averaging (red function) responses must overcome a much higher “noise floor” before they can be detected. Distributions of voltages for an example participant and for the population are shown in <xref ref-type="fig" id="fgc6-6" rid="fig6">Figure 6c</xref> and <xref ref-type="fig" id="fgc6-7" rid="fig6">6d</xref>.</p>
    <p>We calculated power contours via subsampling using both coherent (<xref ref-type="fig" id="fgc6-8" rid="fig6">Figure 6e</xref>) and incoherent (<xref ref-type="fig" id="fgc6-9" rid="fig6">Figure 6f</xref>) averaging, which further confirmed that coherent averaging results in substantially greater statistical power. The 80% power contour in the coherent condition (thick line in <xref ref-type="fig" id="fgc6-10" rid="fig6">Figure 6e</xref>) is relatively shallow, showing that both increasing sample size and adding more trials will improve power over most of the range explored here. For example, halving the sample size from <italic>N</italic> = 100 to <italic>N</italic> = 50 requires an increase from approximately <italic>k</italic> = 20 to <italic>k</italic> = 40 trials per participant to maintain power at 80%. We confirmed these general findings at the higher stimulus contrasts (not shown). Because the coherent averaging precludes typical calculation of within-participant standard deviations, we again fitted the power contour surfaces for a range of σ<sub><italic>w</italic></sub> to the power contours derived by subsampling. The best fitting values were σ<sub><italic>w</italic></sub> = 3.1μ<italic>V</italic> and σ<sub><italic>b</italic></sub> = 0.19μ<italic>V</italic>.</p>
  </sec>
  <sec id="s8">
    <title>fMRI: Event-Related Design</title>
    <p>A widely used fMRI paradigm is the event-related design, in which stimuli are presented briefly with a jittered interstimulus interval (ISI). We obtained data from the Cam-CAN repository (available at <ext-link ext-link-type="uri" xlink:href="http://www.mrc-cbu.cam.ac.uk/datasets/camcan/" specific-use="live">http://www.mrc-cbu.cam.ac.uk/datasets/camcan/</ext-link>) for an event-related fMRI experiment detailed by <xref rid="c32" ref-type="bibr" id="cr32-1">Shafto et al. (2014)</xref> and <xref rid="c37" ref-type="bibr" id="cr37-1">Taylor et al. (2017)</xref>. In brief, <italic>N</italic> = 625 participants viewed bilateral checkerboard patterns, presented for 30 <italic>ms</italic> and repeated <italic>k</italic> = 124 times. Some stimuli were accompanied by an auditory beep, but this was disregarded for the purposes of our analyses.</p>
    <p>We implemented a minimal preprocessing pipeline using FSL (<xref rid="c18" ref-type="bibr" id="cr18-1">Jenkinson, Beckmann, Behrens, Woolrich, &amp; Smith, 2012</xref>). This involved coregistering the functional data to an individual participant’s anatomical scan, and then to the standard MNI152 brain. We used the inverse of these transforms to project a probabilistic map of primary visual cortex (V1) obtained from <xref rid="c40" ref-type="bibr" id="cr40-1">Wang, Mruczek, Arcaro, and Kastner (2015)</xref> onto the functional data to use as a region of interest (see <xref ref-type="fig" id="fgc7-1" rid="fig7">Figure 7a</xref>). The functional data were corrected for slice timing and participant motion, and high pass filtered at 0.01 Hz. Then the time-course was averaged across the V1 region of interest (ROI) and exported for further analysis. While this anatomically defined ROI will necessarily include some voxels that were not responsive to the stimulus, we would expect noise from these voxels to average out and not adversely affect the results (e.g., <xref rid="c4" ref-type="bibr" id="cr4-1">Boynton, Engel, Glover, &amp; Heeger, 1996</xref>).<xref ref-type="fig-anchor" rid="fig7"/></p>
    <p>We then constructed general linear models (GLMs) for each data set using the individual trial timings. To simulate experiments with variable numbers of trials, each GLM split the data using random trial allocations into two arbitrary groups—a “target” condition and a “nontarget” condition. A third condition modeled four auditory-only trials which lacked any visual stimulus. A canonical double gamma hemodynamic response function (<xref ref-type="fig" id="fgc7-2" rid="fig7">Figure 7b</xref>) was convolved with each condition using the <italic>fmri.stimulus</italic> function (part of the <italic>fmri</italic> package in <italic>R</italic>, see <xref rid="c36" ref-type="bibr" id="cr36-1">Tabelow &amp; Polzehl, 2011</xref>), and orthogonal second order polynomial drift terms were included in the overall model. We then fit the GLM to determine a regression (beta) weight for the target condition to use as our dependent variable. By varying the number of trials allocated to the target and nontarget conditions, we were able to simulate experiments with different numbers of trials, while keeping the GLM design balanced (see <xref ref-type="fig" id="fgc7-3" rid="fig7">Figure 7c</xref>). To provide a null condition, we repeated the analysis using randomly determined events within the experiment time-course (i.e., not using the true event timings). This generated the sample distributions of beta weights shown in <xref ref-type="fig" id="fgc7-4" rid="fig7">Figure 7d</xref>, and resulted in an effect size of <italic>d</italic> = 0.9 for the full data set.</p>
    <p>We calculated effect sizes across participants for the difference between beta values for the true and null models with different numbers of trials (see <xref ref-type="fig" id="fgc7-5" rid="fig7">Figure 7c</xref>), and used these to estimate statistical power. As previously, simulations were repeated 10,000 times with different random sampling of trials and participants to generate power contours (see <xref ref-type="fig" id="fgc7-6" rid="fig7">Figure 7e</xref>). As with several previous data sets, power continued to increase across the full range of trial numbers, such that 80% power could be maintained for sample sizes from <italic>N</italic> = 20 to <italic>N</italic> = 600, simply by varying the number of trials. This flexibility allows event-related designs to achieve high statistical power even with relatively modest sample sizes, but it is critical that sufficient trials are included for each condition. It is also straightforward to design a severely underpowered study by including too few trials (here <italic>k</italic> &lt; 60). We estimated standard deviations by fitting to the subsampled power contour surface, yielding values of σ<sub><italic>w</italic></sub> = 515 and σ<sub><italic>b</italic></sub> = 32.2 (in β units).</p>
  </sec>
  <sec id="s9">
    <title>fMRI: Blocked Design</title>
    <p>Another popular fMRI paradigm is the blocked design, in which stimuli are presented for periods of several seconds, interleaved with periods of no stimulation. Typically, events are scheduled to coincide with the acquisition of functional volumes (the repetition time, or TR). Blocked designs generally have greater power than event-related designs because the stimulus timing is more closely aligned to the sluggish time constraints of hemodynamic activity, with the longer duration presentations (relative to event-related designs) allowing BOLD signals to sum over time (<xref rid="c4" ref-type="bibr" id="cr4-2">Boynton et al., 1996</xref>).</p>
    <p>We reanalyzed a data set comprising <italic>N</italic> = 83 participants, all of whom viewed a series of images of faces, objects, places, and scrambled images as part of a functional localizer described by <xref rid="c15" ref-type="bibr" id="cr15-1">Flack et al. (2015)</xref>. Stimuli were presented in blocks of 6 s, with a 9 s interblock interval during which the display was blank. Within each block, five images were shown sequentially for 1,000 ms each, with a 200-ms interstimulus interval. fMRI data were acquired with a TR of 3 s, so a complete cycle (one block plus interblock interval) lasted for 15 s, or five TRs. Each participant completed <italic>k</italic> = 35 blocks. Functional data were high pass filtered, detrended and converted to percent signal change, and aligned to the MNI152 brain. The timeseries was then averaged across the V1 ROI shown in <xref ref-type="fig" id="fgc7-7" rid="fig7">Figure 7a</xref>.</p>
    <p>A timeseries for an example participant is shown in <xref ref-type="fig" id="fgc8-1" rid="fig8">Figure 8a</xref>, and exhibits clear stimulus-driven modulations, with a period of 15 s matching that of the trial cycle. The BOLD response peaked 9 s after stimulus onset, as can be seen most clearly in <xref ref-type="fig" id="fgc8-2" rid="fig8">Figure 8b</xref>, which averages the response across all 35 blocks for the example participant. The distributions of BOLD responses at each time point (relative to the start of a block) are shown in <xref ref-type="fig" id="fgc8-3" rid="fig8">Figure 8c</xref>. Panels d–f of <xref ref-type="fig" id="fgc8-4" rid="fig8">Figure 8</xref> show comparable data for the population of <italic>N</italic> = 83 participants, displaying a similar pattern. In order to generate power contours for a range of effect sizes, we compared activity between sequential pairs of sample points. Effect sizes increased from <italic>d</italic> = 0.26 comparing 3 s and 0 s, to <italic>d</italic> = 1.7 comparing 6 s and 3 s. The range of standard deviations across these comparisons for σ<sub><italic>w</italic></sub> was 0.47–0.52%, and for σ<sub><italic>b</italic></sub> was 0.23–0.40%. Power contours (see <xref ref-type="fig" id="fgc8-5" rid="fig8">Figure 8g–j</xref>) approximately asymptoted for trial numbers above <italic>k</italic> = 15. This pattern is somewhat different from the event-related fMRI results discussed previously (see <xref ref-type="fig" id="fgc7-8" rid="fig7">Figure 7</xref>), where adding more trials continued to increase power across the entire range. For the larger effects (<xref ref-type="fig" id="fgc8-6" rid="fig8">Figure 8h–j</xref>), power was high even with the relatively small samples (<italic>N</italic> &lt; 20) typical of many neuroimaging studies (<xref rid="c9" ref-type="bibr" id="cr9-3">Button et al., 2013</xref>). Of course looking for responses to visual stimuli in V1 is guaranteed to produce large effect sizes—most fMRI studies are designed to test subtler effects which will inevitably be smaller than in the examples here.<xref ref-type="fig-anchor" rid="fig8"/></p>
  </sec>
  <sec id="s10">
    <title>MEG: Evoked Responses</title>
    <p>The Cam-CAN data set also contains MEG responses (<italic>k</italic> = 120 trials) to the same visual stimuli as described in the section on event-related fMRI, recorded using a <italic>VectorView</italic> system (Elekta Neuromag, Helsinki, Finland). We filtered (0.01–30 Hz bandpass), baselined and epoched the data from each participant, and then conducted one-sample <italic>t</italic> tests at a single sensor (see <xref ref-type="fig" id="fgc9-1" rid="fig9">Figure 9a</xref>) comparing activity to zero. We selected three time points very soon after stimulus onset (50, 54, and 58 ms) to leverage the power of this large (<italic>N</italic> = 637) dataset, and to explore effects of a similar magnitude to those investigated in typical experiments, where small differences in responses to different stimuli or mental states might be compared.<xref ref-type="fig-anchor" rid="fig9"/></p>
    <p>Evoked responses showed an initial polarization beginning around 50 ms, followed by a larger peak of opposite polarity at 130 ms (see <xref ref-type="fig" id="fgc9-2" rid="fig9">Figure 9a</xref>). Effect sizes at the three time points increased from d = 0.17 at 50 ms to d = 0.51 at 58 ms when including all trials and participants. As for previous examples, the within-participant variance (<xref ref-type="fig" id="fgc9-3" rid="fig9">Figure 9b</xref>) was clearly greater than the sample variance (<xref ref-type="fig" id="fgc9-4" rid="fig9">Figure 9c</xref>). Across the time window from 50 – 400<italic>ms</italic>, values of σ<sub><italic>w</italic></sub> ranged from 8.25 − 11.77<italic>pT</italic>/<italic>m</italic>, and values of σ<sub><italic>b</italic></sub> ranged from 0.87 − 6.61<italic>pT</italic>/<italic>m</italic>. Subsampled power contours showed the familiar form (see <xref ref-type="fig" id="fgc9-5" rid="fig9">Figure 9d–f</xref>), with power only reaching 80% for the 50 ms time-point when the full data set was used. At later time points, iso-power contours show constant power can be maintained, for example when reducing the sample size from <italic>N</italic> = 400 to <italic>N</italic> = 200 by increasing the number of trials from <italic>k</italic> = 20 to <italic>k</italic> = 60 (at 54 ms).</p>
  </sec>
  <sec id="s11">
    <title>Discussion</title>
    <p>We advocate a representation of statistical power as the joint function of sample size and number of trials—the power contour plot. Example power contours were generated by subsampling data sets from a number of widely used paradigms in experimental psychology and human neuroscience, covering a range of different sample sizes and trial numbers (summarized in <xref ref-type="fig" id="fgc10-1" rid="fig10">Figure 10a</xref>). In most cases, iso-power contours revealed situations where statistical power could be maintained with fewer participants, provided that each participant completed a larger number of trials. For some paradigms, power reached asymptote at a particular number of trials, beyond which further testing conferred no benefit for assessing statistical significance (though as we note below, additional trials may be informative in studies of individual differences). In other paradigms, particularly those where the dependent variable was derived by some form of model fit, power continued to improve with repeated testing, beyond the range that could be assessed with our data sets.<xref ref-type="fig-anchor" rid="fig10"/></p>
    <p>A practical guide to using the power contour approach for study design is as follows. If existing data are available on which to base an analysis, and where these data permit direct estimation of mean difference, σ<sub><italic>w</italic></sub> and σ<sub><italic>b</italic></sub> (using <xref ref-type="disp-formula" id="eqnc2-3" rid="eqn2">Equation 2</xref>), these values can be calculated (or estimated using bootstrapping methods, see <xref rid="c22" ref-type="bibr" id="cr22-1">Luck, Stewart, Simmons, &amp; Rhemtulla, 2019</xref>) and entered directly into the power contour web application. Where direct estimation of these values is not possible, power contours should be generated by subsampling, as we have done for the examples here (and as demonstrated in the code provided). If required, the effective values of σ<sub><italic>w</italic></sub> and σ<sub><italic>b</italic></sub> can then be estimated by fitting the subsampled power contour surface to simulated surfaces and finding the best fitting values. These methods will be of most use when planning replication studies, or when conducting a series of experiments using a single technique that build upon an initial finding in a well-powered sample. If no relevant data are available, power contours can still be informative if reasonable assumptions can be made about the likely effect size, and ratio of standard deviations. Just as it is common practice in power analysis to calculate power curves for a range of potential effect sizes, it might also prove instructive to compare power contour plots for a range of assumptions about the underlying effect size and variance measures. In all cases, the accuracy of the predictions will be limited by the extent to which the parameters generalize to the new experiment.</p>
    <p>In <xref rid="tbl1" ref-type="table">Table 1</xref>, we summarize the relevant variables from each paradigm, including the mean effect, and within- and between-participants and sample standard deviations. For several paradigms, including sensory thresholds, SSVEPs, and event-related fMRI, estimates of within-participant standard deviations were not directly available because the process by which trials were combined did not generate one. In these cases (as described above), we simulated power contour surfaces for a range of candidate standard deviations. The estimated value is the within-participant standard deviation (σ<sub><italic>w</italic></sub>) that produced the best fit. Although this has no direct relationship to the measured dependent variable, it can be thought of as the <italic>SD</italic> from an experimental design with identical power (a power equivalent model, see <xref rid="c25" ref-type="bibr" id="cr25-2">von Oertzen, 2010</xref>) but which uses traditional averaging across trials instead of more sophisticated analysis steps. We then calculated the between-participants standard deviation (σ<sub><italic>b</italic></sub>) using <xref ref-type="disp-formula" id="eqnc2-4" rid="eqn2">Equation 2</xref>. For the SSVEP and event-related fMRI data sets, <xref ref-type="disp-formula" id="eqnc2-5" rid="eqn2">Equation 2</xref> returned an imaginary number because the estimated within-participant <italic>SD</italic> was very large. Here we assumed that σ<sub><italic>b</italic></sub> = σ<sub><italic>s</italic></sub> for the purposes of completing <xref rid="tbl1" ref-type="table">Table 1</xref>. The analysis scripts used to perform these calculations are available on the project OSF repository (<ext-link ext-link-type="uri" xlink:href="https://osf.io/ebhnk/" specific-use="live">https://osf.io/ebhnk/</ext-link>), and we anticipate that readers might use these resources to perform similar analyses on their own data when planning future studies. However, we advise caution in the extent to which variance estimates can be assumed to generalize across different experimental set-ups, laboratories, and participant groups. Using the values estimated here to perform power analyses for studies using similar methods is likely to be highly inaccurate and we do not recommend it.<xref ref-type="table-anchor" rid="tbl1"/></p>
    <p>A further instructive analysis is to compare the within- and between-participants variances, as these provide insight into the likely gains that can be obtained by conducting more trials on each participant. A situation in which the within-participant variance is very small compared with the between-participants variance will result in a power contour like that shown in <xref ref-type="fig" id="fgc1-17" rid="fig1">Figure 1g</xref>, where repeated testing confers no benefit. <xref ref-type="fig" id="fgc10-2" rid="fig10">Figure 10b</xref> plots the variances expressed as Fano-factors (variance scaled by the mean) to permit comparison across paradigms with widely differing units. It is clear that for all paradigms considered here, the within-participant variance is substantially above the between-participants variance (all points appear above the diagonal). This property is not a given, and we anticipate that there may exist paradigms where within-participant variance is very low (due to accurate measurement, or consistency of responses across multiple repetitions; see <xref rid="c24" ref-type="bibr" id="cr24-1">Nesselroade, 1991</xref> for a discussion in the context of developmental research). We note that where multiple estimates were calculated for a single method (such as ERPs at different time points), the Fano-factors appear to cluster together, suggesting a consistent ratio of variances for a given paradigm. However, establishing a generic Fano factor for a particular methodology would require further investigation across multiple studies, and also across different laboratories and equipment (e.g., scanner models, sensor types, etc.), and would not necessarily apply to individual experiments.</p>
    <p>From <xref ref-type="disp-formula" id="eqnc1-2" rid="eqn1">Equation 1</xref>, the sample standard error can be expressed as:
<disp-formula id="eqn3"><alternatives><graphic xlink:href="met_26_3_295_eqn3a.jpg" id="eqn3a"/><mml:math id="M3"><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mi>k</mml:mi></mml:mfrac></mml:mrow><mml:mi>N</mml:mi></mml:mfrac></mml:mrow></mml:msqrt><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msqrt><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives><label>3</label></disp-formula></p>
    <p>These expressions make explicit the dependence of measurement precision (and hence power) on both <italic>N</italic> and <italic>k</italic>, regardless of effect size. In situations where σ<sub><italic>w</italic></sub> &gt; σ<sub><italic>b</italic></sub>, running many trials will materially reduce the overall standard error. In situations where σ<sub><italic>w</italic></sub> &lt; σ<sub><italic>b</italic></sub>, running many trials will confer less benefit, as the standard error is primarily determined by σ<sub><italic>b</italic></sub>, and increasing <italic>N</italic> is more profitable. In <xref rid="tbl1" ref-type="table">Table 1</xref> we also calculate the ratio of standard deviations (σ<sub><italic>w</italic></sub>/σ<sub><italic>b</italic></sub>) as this gives a useful indication of the likely influence that changing <italic>k</italic> will have on power. Paradigms with a small ratio (such as the blocked fMRI paradigm) produce power contours with the smallest gains from increasing numbers of trials (see <xref ref-type="fig" id="fgc8-7" rid="fig8">Figure 8</xref>).</p>
    <p>Up until this point, we have implicitly assumed that a fixed value of within-participant standard deviation (σ<sub><italic>w</italic></sub>) can be substituted for each participant’s individual value. Is this assumption justified, and what impact might different distributions of σ<sub><italic>w</italic></sub> have on statistical power? To address this, we simulated power curves assuming a fixed value of σ<sub><italic>w</italic></sub>, and both normal and skewed distributions of σ<sub><italic>w</italic></sub> (see <xref ref-type="fig" id="fgc11-1" rid="fig11">Figure 11a</xref>). The properties of these distributions were derived from the MEG data set (at 58 ms), as described in the <xref ref-type="fig" id="fgc11-2" rid="fig11">Figure 11</xref> caption, and compared with power estimates from the empirical data. For a range of sample sizes (<italic>N</italic>) and numbers of trials (<italic>k</italic>), the power estimates for all three artificial distributions were very similar (<xref ref-type="fig" id="fgc11-3" rid="fig11">Figure 11b</xref>). However, the power estimates derived from the empirical data are somewhat lower, especially with larger numbers of participants. This happens because a small number of outlier participants with higher standard deviations (those in the tail of the gray distribution in <xref ref-type="fig" id="fgc11-4" rid="fig11">Figure 11a</xref>) contribute disproportionately to the overall variance. We think that most analysis pipelines will reject such participants (or reject individual trials that are contributing to a noisy participant mean), meaning that the loss of power here is a “worst case” scenario (we avoided elaborate processing pipelines in the current article to maximize transparency). In general these simulations suggest that the simplifying assumption of a single within-participant standard deviation is reasonable. For prospective power analyses, the margin of error in estimating effect sizes and variances will most likely subsume any considerations due to non-normally distributed variances and outliers.<xref ref-type="fig-anchor" rid="fig11"/></p>
    <p>A further factor that influences statistical power in repeated measures designs is the covariance between the two measures. We performed simulations to quantify this, by generating synthetic data sets with different levels of covariance, and performing power calculations on the synthetic data for repeated measures <italic>t</italic> tests. The simulations in <xref ref-type="fig" id="fgc11-5" rid="fig11">Figure 11c–e</xref> show that when R = 0, there is no benefit from the repeated measures design, and power is determined by conventional factors (effect size, alpha level, sample size, and number of trials). As the level of correlation increases from zero, power also increases because the covariance between the two measures accounts for a greater proportion of the total variance, and it is discounted by the repeated measures analysis. However, the overall shape of the power contours is not affected by the change in covariance—the contours simply shift toward the origin. For paired <italic>t</italic> test designs, the covariance can be accounted for by taking the difference between the two measures for each participant, and using these difference scores in a one-sample <italic>t</italic> test (which is mathematically equivalent to a paired <italic>t</italic> test on the original data). Estimates of effect size and power calculated in this way will incorporate the covariance between repeated measures. For more sophisticated designs, calculating stochastic power contours using existing data, or simulating them with a range of plausible covariance levels, may be more appropriate.</p>
    <p>Of course, we are far from the first to appreciate that multiple measurements can increase effect sizes and power. In the domain of psychometric research, the Spearman-Brown prophecy formula (<xref rid="c7" ref-type="bibr" id="cr7-1">Brown, 1910</xref>; <xref rid="c34" ref-type="bibr" id="cr34-1">Spearman, 1910</xref>) predicts how the reliability of a test (such as a personality test, or an IQ test) increases as more items are added. <xref rid="c30" ref-type="bibr" id="cr30-2">Rouder and Haaf (2018)</xref> also consider the effects of sample size and number of trials on statistical power, in the context of “stochastic dominance”—the tendency for all participants in an experiment to have a true effect in the same direction. Under these conditions, the distribution of effects in the sample population is unlikely to be normal, and may instead be positively skewed with a mean and variance that are proportional (e.g., a gamma distribution). Simulations show that in this situation power can remain almost constant when trading off participants against trials. Our observation that Fano-factors for a given method appear to cluster together (see <xref ref-type="fig" id="fgc10-3" rid="fig10">Figure 10b</xref>) could be taken as evidence that dominance holds for some of the paradigms investigated here, because gamma distributions have a variance that increases in proportion to the mean. Strong empirical evidence to firmly establish the conditions when dominance occurs is currently lacking, although it appears entirely plausible for many tasks in sensory and cognitive research.</p>
    <p>Whereas most of the example data sets we consider here involve multiple repetitions of identical stimuli (six out of eight used simple patterns such as checkerboards or sine-wave gratings), it is more typical in some research areas to use different stimulus examples on each trial. For example in research on object processing, databases of object images are often used, with multiple examplars in each object category. This additional source of variability can also be estimated, and further complicates the underlying mathematics of power analysis, as described in detail by <xref rid="c42" ref-type="bibr" id="cr42-3">Westfall et al. (2014)</xref>. The power contour representation advocated here is also applicable to these situations (see Figures 2–6 of <xref rid="c42" ref-type="bibr" id="cr42-4">Westfall et al., 2014</xref>), and a linear mixed modeling approach can be used in which variances are explicitly represented at the participant, stimulus item and sample level (see also <xref rid="c8" ref-type="bibr" id="cr8-1">Brysbaert &amp; Stevens, 2018</xref>). In such “crossed” designs, the maximum power that can be achieved is limited by the item-level variance and number of stimulus examples, even for a hypothetically infinite sample size. For statistical procedures where the item-level variance is not explicitly modeled, it will be subsumed into the within- and between-participants variances, perhaps making power estimates less accurate.</p>
    <p>Some studies have used cost functions to attempt to derive a single optimal experimental design, by assuming specific costs (usually in units of experimenter time) required for recruitment and testing of each participant (e.g., <xref rid="c11" ref-type="bibr" id="cr11-2">Cleary &amp; Linn, 1969</xref>; <xref rid="c25" ref-type="bibr" id="cr25-3">von Oertzen, 2010</xref>; <xref rid="c26" ref-type="bibr" id="cr26-1">von Oertzen &amp; Brandmaier, 2013</xref>). In principle these methods might be used to determine a point on the power contour that specifies a particular sample size and number of trials. We have avoided being prescriptive about this here, as different studies will have different constraints and priorities, and the advantage of visualizing the entire power surface is that it permits the experimenter to trade off these two variables against each other without loss of power. However, we have built functionality into the <italic>Shiny</italic> web application to estimate an optimal combination of sample size and number of trials, based on the additional constraint of a per-participant “recruitment cost,” expressed as a notional number of trials. The optimal point is calculated by determining the smallest value of N*(<italic>k</italic> + cost) that achieves 80% power. We advise caution in the use of this feature.</p>
    <sec id="s12">
      <title>Application to Other Statistical Tests and Approaches</title>
      <p>Throughout all examples so far we have deliberately used a basic statistical test to determine power—the <italic>t</italic> test. However, the subsampling method we develop here can very easily be extended to more advanced statistical methods, including nonparametric statistics, analysis of variance (see <xref rid="c33" ref-type="bibr" id="cr33-1">Smith &amp; Little, 2018</xref>, for a related example), correlation, regression, and so on. The method of subsampling trials has no specific requirements about the form of the data (as with bootstrapping techniques), provided the assumptions for calculating the relevant test statistic are met. A recent study by <xref rid="c44" ref-type="bibr" id="cr44-2">Xu et al. (2018)</xref> calculated the reliability of working memory measures as a function of both sample size and number of trials, using a similar subsampling approach. This produced similar contour plots, but for Cronbach’s alpha, Spearman-Brown reliability and standard deviation instead of statistical power. In all cases, these showed a dependency on both sample size and number of trials, consistent with the examples here. Iso-power contours have also been calculated in work on optimal study design using structural equation modeling (e.g., <xref rid="c5" ref-type="bibr" id="cr5-1">Brandmaier, von Oertzen, Ghisletta, Hertzog, &amp; Lindenberger, 2015</xref>; <xref rid="c26" ref-type="bibr" id="cr26-2">von Oertzen &amp; Brandmaier, 2013</xref>).</p>
      <p>In <xref ref-type="fig" id="fgc12-1" rid="fig12">Figure 12</xref> we show power contour plots for repeated measures ANOVAs using two of the example data sets from the body of the article. We conducted a one-way repeated measures ANOVA across the latter three TR times of the blocked design MRI experiment (using all five TR times produced such a large effect that the power contour analysis was uninformative). With the full data set, this produced a substantial significant effect, <italic>F</italic>(2, 164) = 40.39, <italic>p</italic> &lt; 6 × 10<sup>−15</sup>, equivalent <italic>d</italic> = 1.4. We then subsampled the data 10,000 times, repeating the ANOVA on each subsampled data set and calculating the proportion of significant tests (i.e., the power) to generate power contours. <xref ref-type="fig" id="fgc12-2" rid="fig12">Figure 12a</xref> shows the power contour plot generated from this analysis, which closely resembles the power contour plots calculated for paired comparisons between these three conditions (<xref ref-type="fig" id="fgc8-8" rid="fig8">Figure 8i</xref> and <xref ref-type="fig" id="fgc8-9" rid="fig8">8j</xref>).<xref ref-type="fig-anchor" rid="fig12"/></p>
      <p>We next conducted a factorial repeated measures ANOVA on data from the SSVEP experiment. As shown in <xref ref-type="fig" id="fgc6-11" rid="fig6">Figure 6b</xref>, the experiment involved seven stimulus contrast levels. Participants also repeated all contrast conditions with an added orthogonal mask at high contrast. The two factors were therefore stimulus contrast (0–64%), which produced a highly significant effect, <italic>F</italic>(6, 1287) = 171.83, <italic>p</italic> &lt; 2 × 10<sup>−16</sup>, equivalent <italic>d</italic> = 1.78, and mask contrast (0 and 32%) which produced a smaller effect, <italic>F</italic>(1, 1287) = 12.89, <italic>p</italic> &lt; .0004, equivalent <italic>d</italic> = 0.19. The interaction between the two factors was also significant, <italic>F</italic>(6, 1287) = 7.74, <italic>p</italic> &lt; 4 × 10<sup>−8</sup>, equivalent <italic>d</italic> = 0.35. Power contours for both main effects and the interaction are shown in <xref ref-type="fig" id="fgc12-3" rid="fig12">Figure 12b–d</xref>. The main effect of stimulus contrast was so substantial that high power could be achieved with almost any combination of sample size and number of trials. The main effect of mask and the interaction were weaker, and again show the familiar tradeoff between <italic>N</italic> and <italic>k</italic>. In practical settings, one should design an experiment to detect the smallest effect of interest with the desired power. For this example, the main effect of mask has the smallest effect, and so a replication of this experiment could use values along the 80% contour in <xref ref-type="fig" id="fgc12-4" rid="fig12">Figure 12c</xref>: for example, 100 participants each completing 40 trials, or 75 participants each completing 80 trials. Alternatively, if only the interaction were of theoretical interest, one could base the design on the constraints shown in <xref ref-type="fig" id="fgc12-5" rid="fig12">Figure 12d</xref>.</p>
      <p>For time-varying data using EEG and MEG (see <xref ref-type="fig" id="fgc5-6" rid="fig5">Figures 5</xref> and <xref ref-type="fig" id="fgc9-6" rid="fig9">9</xref>), it is commonplace to use cluster correction algorithms to control for multiple comparisons (e.g., <xref rid="c23" ref-type="bibr" id="cr23-1">Maris &amp; Oostenveld, 2007</xref>). Informative power contours could in principle be constructed for significant clusters using either the number of trials (as here), or the number of time-points included within a cluster. Similar approaches might be applied to fMRI data, where the number of voxels included in a spatial cluster or a ROI will likely affect statistical power.</p>
      <p>One limitation of the methods presented here is that they assume that trials are random, and independent of each other. In many paradigms, participants might become better at a task with practice (e.g., they could become more accurate, or their RTs could speed up), or become fatigued after long testing sessions. This will place limits on the improvements gained by running additional trials, however, the likely impact will vary across paradigms (see <xref ref-type="fig" id="fgc3-8" rid="fig3">Figure 3c</xref> for an example). For large data sets it may be possible to estimate the nonstationarity of σ<sub><italic>w</italic></sub>, and the impact this has on power (see, e.g., <xref rid="c26" ref-type="bibr" id="cr26-3">von Oertzen &amp; Brandmaier, 2013</xref>). Other work has modeled multiple sources of variance in MRI studies explicitly using intraclass correlations (<xref rid="c6" ref-type="bibr" id="cr6-2">Brandmaier et al., 2018</xref>). This method permits dissociation of within-participant variance from various sources of measurement noise such as differences in variance between time of day, scanner model, and so on. Accurate estimates of relevant sources of variance will improve the overall accuracy of power analysis, which is particularly important given recent meta-analytic evidence (<xref rid="c14" ref-type="bibr" id="cr14-1">Elliott et al., 2020</xref>) that test–retest reliability for task-based fMRI is typically very low (mean intraclass correlation &lt; 0.4).</p>
      <p>An alternative to null hypothesis significance testing is the Bayesian approach. Bayesian alternatives to <italic>t</italic> tests often calculate a Bayes factor (<xref rid="c31" ref-type="bibr" id="cr31-1">Rouder, Speckman, Sun, Morey, &amp; Iverson, 2009</xref>) as a test statistic, which indicates the relative probabilities of the experimental and null hypotheses, given the observed data. For a given experimental design, one could calculate “Bayes factor contours” in an analogous manner to power contours, to estimate the number of trials and participants necessary to reach a specified level of evidence in support of one or other hypothesis. As Bayesian methods become more widespread, this may prove a useful alternative to traditional power analysis.</p>
      <p>Another Bayesian-inspired method is to adaptively deploy data collection in the direction required to supply useful evidence to inform the outcome (posterior). An early example is the <italic>Quest</italic> algorithm (<xref rid="c41" ref-type="bibr" id="cr41-1">Watson &amp; Pelli, 1983</xref>), used widely in psychophysics, which chooses the optimal stimulus level on each trial to provide the most information about the location of the threshold. Related methods have also been used to optimize data collection in fMRI experiments (<xref rid="c21" ref-type="bibr" id="cr21-1">Lorenz, Hampshire, &amp; Leech, 2017</xref>). Typically such approaches operate at a per-participant level, and will result in efficient use of the time available. If the ultimate aim is to combine results statistically across participants, then power contours might still be used to optimize the number of trials, in a similar fashion to that shown here for the contrast detection data (see <xref ref-type="fig" id="fgc4-6" rid="fig4">Figure 4</xref>), which also involved an adaptive (staircase) procedure. On the other hand, if the algorithm is designed to continue until particular conditions are met, traditional power analysis based only on sample size may be more appropriate.</p>
      <p>Most discussion of power analysis is focused on studies which involve statistically demonstrating the presence of some effect. However, an alternative approach common in perceptual and cognitive research is to explain and predict patterns of response across multiple conditions using a computational model. In this tradition, each participant can be considered an independent “replication” of the phenomena under study (see, e.g., <xref rid="c33" ref-type="bibr" id="cr33-2">Smith &amp; Little, 2018</xref>), and the emphasis is on improving data quality through conducting many trials for each participant. Power contours might not be especially helpful under such circumstances, though knowledge of the within-participant standard deviation will inform decisions about how many trials to conduct.</p>
      <p>Whereas experimental studies of the type we discuss here typically aim to reduce the sample variance (σ<sub><italic>s</italic></sub>) in order to increase effect size, studies using individual differences approaches aim to maximize meaningful variation between participants. However, it is important that the observed variation (σ<sub><italic>s</italic></sub>) is truly a result of individual differences (high σ<sub><italic>b</italic></sub>) and not merely a consequence of poor measurement (high σ<sub><italic>w</italic></sub> and low <italic>k</italic>). Traditional psychometric instruments, such as tests of personality and ability, typically have high test–retest reliability, which implies low within-participant variance (σ<sub><italic>w</italic></sub>), yet this may not be so for neuroscience and experimental psychology paradigms (e.g., <xref rid="c14" ref-type="bibr" id="cr14-2">Elliott et al., 2020</xref>; <xref rid="c45" ref-type="bibr" id="cr45-1">Zuo, Xu, &amp; Milham, 2019</xref>). Estimating these values explicitly (e.g., using <xref ref-type="disp-formula" id="eqnc2-6" rid="eqn2">Equation 2</xref>) may help individual differences researchers using such methods to optimize the number of trials and sample size to this end. We note that because σ<sub><italic>w</italic></sub> &gt; σ<sub><italic>b</italic></sub> for all estimates of these two parameters in the paradigms considered here (<xref rid="tbl1" ref-type="table">Table 1</xref> and <xref ref-type="fig" id="fgc10-4" rid="fig10">Figure 10b</xref>), individual differences studies will require sufficient trials to reduce the unwanted influence of intraindividual variability (σ<sub><italic>w</italic></sub>) on sample variance (σ<sub><italic>s</italic></sub>).</p>
    </sec>
    <sec id="s13">
      <title>Conclusions</title>
      <p>Here we present the rationale for incorporating the number of measurements (trials) into calculations of statistical power in experimental studies of psychology and human neuroscience. Power contour plots can be generated by subsampling existing data sets or using an online tool, and permit researchers to make informed choices about how many participants to test, and how long to test each one for, at the study design stage. However, as with all a priori power calculations, the true effect sizes and variances will remain speculative until data have been collected.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data">
      <object-id pub-id-type="doi">10.1037/met0000337.supp</object-id>
      <media id="suppmat1" xlink:href="met0000337_open-practices-disclosure-form.pdf" specific-use="live"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="c1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>D. H.</given-names></name>, <name><surname>Lygo</surname><given-names>F. A.</given-names></name>, <name><surname>Meese</surname><given-names>T. S.</given-names></name>, &amp; <name><surname>Georgeson</surname><given-names>M. A.</given-names></name></person-group> (<year>2018</year>). <article-title>Binocular summation revisited: Beyond <mml:math id="math2"><mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow></mml:math></article-title>. <source>Psychological Bulletin</source>, <volume>144</volume>, <fpage>1186</fpage>–<lpage>1199</lpage>. <pub-id pub-id-type="doi">10.1037/bul0000163</pub-id><pub-id pub-id-type="pmid">30102058</pub-id></mixed-citation>
    </ref>
    <ref id="c2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>D.</given-names></name></person-group> (<year>2019</year>). <article-title>Rein in the four horsemen of irreproducibility</article-title>. <source>Nature</source>, <volume>568</volume>, <fpage>435</fpage>. <pub-id pub-id-type="doi">10.1038/d41586-019-01307-2</pub-id><pub-id pub-id-type="pmid">31019328</pub-id></mixed-citation>
    </ref>
    <ref id="c3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boudewyn</surname><given-names>M. A.</given-names></name>, <name><surname>Luck</surname><given-names>S. J.</given-names></name>, <name><surname>Farrens</surname><given-names>J. L.</given-names></name>, &amp; <name><surname>Kappenman</surname><given-names>E. S.</given-names></name></person-group> (<year>2018</year>). <article-title>How many trials does it take to get a significant ERP effect? It depends</article-title>. <source>Psychophysiology</source>, <volume>55</volume>, <elocation-id>e13049</elocation-id>. <pub-id pub-id-type="doi">10.1111/psyp.13049</pub-id><pub-id pub-id-type="pmid">29266241</pub-id></mixed-citation>
    </ref>
    <ref id="c4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boynton</surname><given-names>G. M.</given-names></name>, <name><surname>Engel</surname><given-names>S. A.</given-names></name>, <name><surname>Glover</surname><given-names>G. H.</given-names></name>, &amp; <name><surname>Heeger</surname><given-names>D. J.</given-names></name></person-group> (<year>1996</year>). <article-title>Linear systems analysis of functional magnetic resonance imaging in human V1</article-title>. <source>Journal of Neuroscience</source>, <volume>16</volume>, <fpage>4207</fpage>–<lpage>4221</lpage>.<pub-id pub-id-type="pmid">8753882</pub-id></mixed-citation>
    </ref>
    <ref id="c5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brandmaier</surname><given-names>A. M.</given-names></name>, <name><surname>von Oertzen</surname><given-names>T.</given-names></name>, <name><surname>Ghisletta</surname><given-names>P.</given-names></name>, <name><surname>Hertzog</surname><given-names>C.</given-names></name>, &amp; <name><surname>Lindenberger</surname><given-names>U.</given-names></name></person-group> (<year>2015</year>). <article-title>Lifespan: A tool for the computer-aided design of longitudinal studies</article-title>. <source>Frontiers in Psychology</source>, <volume>6</volume>, <elocation-id>272</elocation-id>. <pub-id pub-id-type="doi">10.3389/fpsyg.2015.00272</pub-id><pub-id pub-id-type="pmid">25852596</pub-id></mixed-citation>
    </ref>
    <ref id="c6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brandmaier</surname><given-names>A. M.</given-names></name>, <name><surname>Wenger</surname><given-names>E.</given-names></name>, <name><surname>Bodammer</surname><given-names>N. C.</given-names></name>, <name><surname>Kühn</surname><given-names>S.</given-names></name>, <name><surname>Raz</surname><given-names>N.</given-names></name>, &amp; <name><surname>Lindenberger</surname><given-names>U.</given-names></name></person-group> (<year>2018</year>). <article-title>Assessing reliability in neuroimaging research through intra-class effect decomposition (ICED)</article-title>. <source>Elife</source>, <volume>7</volume>, <elocation-id>e35718</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.35718</pub-id><pub-id pub-id-type="pmid">29963984</pub-id></mixed-citation>
    </ref>
    <ref id="c7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>W.</given-names></name></person-group> (<year>1910</year>). <article-title>Some experimental results in the correlation of mental abilities</article-title>. <source>British Journal of Psychology</source>, <volume>3</volume>, <fpage>296</fpage>–<lpage>322</lpage>.</mixed-citation>
    </ref>
    <ref id="c8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brysbaert</surname><given-names>M.</given-names></name>, &amp; <name><surname>Stevens</surname><given-names>M.</given-names></name></person-group> (<year>2018</year>). <article-title>Power analysis and effect size in mixed effects models: A tutorial</article-title>. <source>Journal of Cognition</source>, <volume>9</volume>, <fpage>1</fpage>–<lpage>20</lpage>. <pub-id pub-id-type="doi">10.5334/joc.10</pub-id></mixed-citation>
    </ref>
    <ref id="c9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Button</surname><given-names>K. S.</given-names></name>, <name><surname>Ioannidis</surname><given-names>J. P. A.</given-names></name>, <name><surname>Mokrysz</surname><given-names>C.</given-names></name>, <name><surname>Nosek</surname><given-names>B. A.</given-names></name>, <name><surname>Flint</surname><given-names>J.</given-names></name>, <name><surname>Robinson</surname><given-names>E. S. J.</given-names></name>, &amp; <name><surname>Munafò</surname><given-names>M. R.</given-names></name></person-group> (<year>2013</year>). <article-title>Power failure: Why small sample size undermines the reliability of neuroscience</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>14</volume>, <fpage>365</fpage>–<lpage>376</lpage>. <pub-id pub-id-type="doi">10.1038/nrn3475</pub-id><pub-id pub-id-type="pmid">23571845</pub-id></mixed-citation>
    </ref>
    <ref id="c10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clayson</surname><given-names>P. E.</given-names></name>, &amp; <name><surname>Miller</surname><given-names>G. A.</given-names></name></person-group> (<year>2017</year>). <article-title>Psychometric considerations in the measurement of event-related brain potentials: Guidelines for measurement and reporting</article-title>. <source>International Journal of Psychophysiology</source>, <volume>111</volume>, <fpage>57</fpage>–<lpage>67</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijpsycho.2016.09.005</pub-id><pub-id pub-id-type="pmid">27619493</pub-id></mixed-citation>
    </ref>
    <ref id="c11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cleary</surname><given-names>T. A.</given-names></name>, &amp; <name><surname>Linn</surname><given-names>R. L.</given-names></name></person-group> (<year>1969</year>). <article-title>Error of measurement and the power of a statistical test</article-title>. <source>British Journal of Mathematical and Statistical Psychology</source>, <volume>22</volume>, <fpage>49</fpage>–<lpage>55</lpage>. <pub-id pub-id-type="doi">10.1111/j.2044-8317.1969.tb00419.x</pub-id></mixed-citation>
    </ref>
    <ref id="c12">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>J.</given-names></name></person-group> (<year>1988</year>). <source>Statistical power analysis for the behavioral sciences</source>. <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</mixed-citation>
    </ref>
    <ref id="c13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colquhoun</surname><given-names>D.</given-names></name></person-group> (<year>2014</year>). <article-title>An investigation of the false discovery rate and the misinterpretation of p-values</article-title>. <source>Royal Society Open Science</source>, <volume>1</volume>, <elocation-id>140216</elocation-id>. <pub-id pub-id-type="doi">10.1098/rsos.140216</pub-id><pub-id pub-id-type="pmid">26064558</pub-id></mixed-citation>
    </ref>
    <ref id="c14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elliott</surname><given-names>M. L.</given-names></name>, <name><surname>Knodt</surname><given-names>A. R.</given-names></name>, <name><surname>Ireland</surname><given-names>D.</given-names></name>, <name><surname>Morris</surname><given-names>M. L.</given-names></name>, <name><surname>Poulton</surname><given-names>R.</given-names></name>, <name><surname>Ramrakha</surname><given-names>S.</given-names></name>, <etal>. . .</etal><name><surname>Hariri</surname><given-names>A. R.</given-names></name></person-group> (<year>2020</year>). <article-title>What is the test-retest reliability of common task-functional MRI measures? New empirical evidence and a meta-analysis</article-title>. <source>Psychological Science</source>. <comment>Advance online publication</comment>. <pub-id pub-id-type="doi">10.1177/0956797620916786</pub-id></mixed-citation>
    </ref>
    <ref id="c15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flack</surname><given-names>T. R.</given-names></name>, <name><surname>Andrews</surname><given-names>T. J.</given-names></name>, <name><surname>Hymers</surname><given-names>M.</given-names></name>, <name><surname>Al-Mosaiwi</surname><given-names>M.</given-names></name>, <name><surname>Marsden</surname><given-names>S. P.</given-names></name>, <name><surname>Strachan</surname><given-names>J. W.</given-names></name>, <etal>. . .</etal><name><surname>Young</surname><given-names>A. W.</given-names></name></person-group> (<year>2015</year>). <article-title>Responses in the right posterior superior temporal sulcus show a feature-based response to facial expression</article-title>. <source>Cortex</source>, <volume>69</volume>, <fpage>14</fpage>–<lpage>23</lpage>. <pub-id pub-id-type="doi">10.1016/j.cortex.2015.03.002</pub-id><pub-id pub-id-type="pmid">25967084</pub-id></mixed-citation>
    </ref>
    <ref id="c16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ioannidis</surname><given-names>J. P. A.</given-names></name></person-group> (<year>2005</year>). <article-title>Why most published research findings are false</article-title>. <source>PLoS Med</source>, <volume>2</volume>, <elocation-id>e124</elocation-id>. <pub-id pub-id-type="doi">10.1371/journal.pmed.0020124</pub-id><pub-id pub-id-type="pmid">16060722</pub-id></mixed-citation>
    </ref>
    <ref id="c17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ioannidis</surname><given-names>J. P. A.</given-names></name></person-group> (<year>2008</year>). <article-title>Why most discovered true associations are inflated</article-title>. <source>Epidemiology</source>, <volume>19</volume>, <fpage>640</fpage>–<lpage>648</lpage>. <pub-id pub-id-type="doi">10.1097/EDE.0b013e31818131e7</pub-id><pub-id pub-id-type="pmid">18633328</pub-id></mixed-citation>
    </ref>
    <ref id="c18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M.</given-names></name>, <name><surname>Beckmann</surname><given-names>C. F.</given-names></name>, <name><surname>Behrens</surname><given-names>T. E. J.</given-names></name>, <name><surname>Woolrich</surname><given-names>M. W.</given-names></name>, &amp; <name><surname>Smith</surname><given-names>S. M.</given-names></name></person-group> (<year>2012</year>). <article-title>FSL</article-title>. <source>Neuroimage</source>, <volume>62</volume>, <fpage>782</fpage>–<lpage>790</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.09.015</pub-id><pub-id pub-id-type="pmid">21979382</pub-id></mixed-citation>
    </ref>
    <ref id="c19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanyongo</surname><given-names>G. Y.</given-names></name>, <name><surname>Brook</surname><given-names>G. P.</given-names></name>, <name><surname>Kyei-Blankson</surname><given-names>L.</given-names></name>, &amp; <name><surname>Gocmen</surname><given-names>G.</given-names></name></person-group> (<year>2007</year>). <article-title>Reliability and statistical power: How measurement fallibility affects power and required sample sizes for several parametric and nonparametric statistics</article-title>. <source>Journal of Modern Applied Statistical Methods</source>, <volume>6</volume>, <fpage>81</fpage>–<lpage>90</lpage>. <pub-id pub-id-type="doi">10.22237/jmasm/1177992480</pub-id></mixed-citation>
    </ref>
    <ref id="c20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linares</surname><given-names>D.</given-names></name>, &amp; <name><surname>López-Moliner</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>quickpsy: An R package to fit psychometric functions for multiple groups</article-title>. <source>The R Journal</source>, <volume>8</volume>, <fpage>122</fpage>–<lpage>131</lpage>. <pub-id pub-id-type="doi">10.32614/RJ-2016-008</pub-id></mixed-citation>
    </ref>
    <ref id="c21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lorenz</surname><given-names>R.</given-names></name>, <name><surname>Hampshire</surname><given-names>A.</given-names></name>, &amp; <name><surname>Leech</surname><given-names>R.</given-names></name></person-group> (<year>2017</year>). <article-title>Neuroadaptive Bayesian optimization and hypothesis testing</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>21</volume>, <fpage>155</fpage>–<lpage>167</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2017.01.006</pub-id><pub-id pub-id-type="pmid">28236531</pub-id></mixed-citation>
    </ref>
    <ref id="c22">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Luck</surname><given-names>S. J.</given-names></name>, <name><surname>Stewart</surname><given-names>A.</given-names></name>, <name><surname>Simmons</surname><given-names>A.</given-names></name>, &amp; <name><surname>Rhemtulla</surname><given-names>M.</given-names></name></person-group> (<year>2019</year>). <source>Standardized measurement error as a universal measure of data quality for event-related potentials: An overview</source>. <comment>PsyArXiv</comment>. <pub-id pub-id-type="doi">10.31234/osf.io/jc3sd</pub-id></mixed-citation>
    </ref>
    <ref id="c23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname><given-names>E.</given-names></name>, &amp; <name><surname>Oostenveld</surname><given-names>R.</given-names></name></person-group> (<year>2007</year>). <article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title>. <source>Journal of Neuroscience Methods</source>, <volume>164</volume>, <fpage>177</fpage>–<lpage>190</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id><pub-id pub-id-type="pmid">17517438</pub-id></mixed-citation>
    </ref>
    <ref id="c24">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nesselroade</surname><given-names>J. R.</given-names></name></person-group> (<year>1991</year>). <chapter-title>The warp and woof of the developmental fabric</chapter-title>. In <person-group person-group-type="editor"><name><surname>Downs</surname><given-names>R. M.</given-names></name>, <name><surname>Liben</surname><given-names>R. S.</given-names></name>, &amp; <name><surname>Palermo</surname><given-names>D. S.</given-names></name></person-group> (<role>Eds.</role>), <source>Visions of aesthetics, the environment &amp; development: The legacy of Joachim F. Wohlwill</source> (pp. <fpage>213</fpage>–<lpage>240</lpage>). <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>.</mixed-citation>
    </ref>
    <ref id="c27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>Open Science Collaboration</collab></person-group>. (<year>2015</year>). <article-title>Estimating the reproducibility of psychological science</article-title>. <source>Science</source>, <volume>349</volume>, <elocation-id>aac4716</elocation-id>. <pub-id pub-id-type="doi">10.1126/science.aac4716</pub-id><pub-id pub-id-type="pmid">26315443</pub-id></mixed-citation>
    </ref>
    <ref id="c28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phillips</surname><given-names>G.
W.</given-names></name>, &amp; <name><surname>Jiang</surname><given-names>T.</given-names></name></person-group> (<year>2016</year>).
<article-title>Measurement error and equating error in power analysis</article-title>.
<source>Practical Assessment, Research &amp; Evaluation</source>, <volume>21</volume>,
<elocation-id>9</elocation-id>. <pub-id pub-id-type="doi">10.7275/0snn-zm67</pub-id></mixed-citation>
    </ref>
    <ref id="c29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pirrone</surname><given-names>A.</given-names></name>, <name><surname>Wen</surname><given-names>W.</given-names></name>, <name><surname>Li</surname><given-names>S.</given-names></name>, <name><surname>Baker</surname><given-names>D. H.</given-names></name>, &amp; <name><surname>Milne</surname><given-names>E.</given-names></name></person-group> (<year>2018</year>). <article-title>Autistic traits in the neurotypical population do not predict increased response conservativeness in perceptual decision making</article-title>. <source>Perception</source>, <volume>47</volume>, <fpage>1081</fpage>–<lpage>1096</lpage>. <pub-id pub-id-type="doi">10.1177/0301006618802689</pub-id><pub-id pub-id-type="pmid">30284946</pub-id></mixed-citation>
    </ref>
    <ref id="c30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouder</surname><given-names>J. N.</given-names></name>, &amp; <name><surname>Haaf</surname><given-names>J. M.</given-names></name></person-group> (<year>2018</year>). <article-title>Power, dominance, and constraint: A Note on the appeal of different design traditions</article-title>. <source>Advances in Methods and Practices in Psychological Science</source>, <volume>1</volume>, <fpage>19</fpage>–<lpage>26</lpage>.</mixed-citation>
    </ref>
    <ref id="c31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouder</surname><given-names>J. N.</given-names></name>, <name><surname>Speckman</surname><given-names>P. L.</given-names></name>, <name><surname>Sun</surname><given-names>D.</given-names></name>, <name><surname>Morey</surname><given-names>R. D.</given-names></name>, &amp; <name><surname>Iverson</surname><given-names>G.</given-names></name></person-group> (<year>2009</year>). <article-title>Bayesian t tests for accepting and rejecting the null hypothesis</article-title>. <source>Psychonomic Bulletin &amp; Review</source>, <volume>16</volume>, <fpage>225</fpage>–<lpage>237</lpage>. <pub-id pub-id-type="doi">10.3758/pbr.16.2.225</pub-id><pub-id pub-id-type="pmid">19293088</pub-id></mixed-citation>
    </ref>
    <ref id="c32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shafto</surname><given-names>M. A.</given-names></name>, <name><surname>Tyler</surname><given-names>L. K.</given-names></name>, <name><surname>Dixon</surname><given-names>M.</given-names></name>, <name><surname>Taylor</surname><given-names>J. R.</given-names></name>, <name><surname>Rowe</surname><given-names>J. B.</given-names></name>, <name><surname>Cusack</surname><given-names>R.</given-names></name>, <etal>. . .</etal><collab>Cam-CAN</collab></person-group>. (<year>2014</year>). <article-title>The Cambridge Centre for Ageing and Neuroscience (Cam-CAN) study protocol: A cross-sectional, lifespan, multidisciplinary examination of healthy cognitive ageing</article-title>. <source>BMC Neurology</source>, <volume>14</volume>, <elocation-id>204</elocation-id>. <pub-id pub-id-type="doi">10.1186/s12883-014-0204-1</pub-id><pub-id pub-id-type="pmid">25412575</pub-id></mixed-citation>
    </ref>
    <ref id="c33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>P. L.</given-names></name>, &amp; <name><surname>Little</surname><given-names>D. R.</given-names></name></person-group> (<year>2018</year>). <article-title>Small is beautiful: In defense of the small-n design</article-title>. <source>Psychonomic Bulletin and Review</source>, <volume>25</volume>, <fpage>2083</fpage>–<lpage>2101</lpage>. <pub-id pub-id-type="doi">10.3758/s13423-018-1451-8</pub-id><pub-id pub-id-type="pmid">29557067</pub-id></mixed-citation>
    </ref>
    <ref id="c34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spearman</surname><given-names>C. C.</given-names></name></person-group> (<year>1910</year>). <article-title>Correlation calculated from faulty data</article-title>. <source>British Journal of Psychology</source>, <volume>3</volume>, <fpage>271</fpage>–<lpage>295</lpage>.</mixed-citation>
    </ref>
    <ref id="c35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steingroever</surname><given-names>H.</given-names></name>, <name><surname>Fridberg</surname><given-names>D. J.</given-names></name>, <name><surname>Horstmann</surname><given-names>A.</given-names></name>, <name><surname>Kjome</surname><given-names>K. L.</given-names></name>, <name><surname>Kumari</surname><given-names>V.</given-names></name>, <name><surname>Lane</surname><given-names>S. D.</given-names></name>, <etal>. . .</etal><name><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name></person-group> (<year>2015</year>). <article-title>Data from 617 healthy participants performing the Iowa Gambling Task: A “many labs” collaboration</article-title>. <source>Journal of Open Psychology Data</source>, <volume>3</volume>, <elocation-id>e5</elocation-id>. <pub-id pub-id-type="doi">10.5334/jopd.ak</pub-id></mixed-citation>
    </ref>
    <ref id="c36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tabelow</surname><given-names>K.</given-names></name>, &amp; <name><surname>Polzehl</surname><given-names>J.</given-names></name></person-group> (<year>2011</year>). <article-title>Statistical parametric maps for functional MRI experiments in R: The package fMRI</article-title>. <source>Journal of Statistical Software</source>, <volume>44</volume>, <fpage>1</fpage>–<lpage>21</lpage>. <pub-id pub-id-type="doi">10.18637/jss.v044.i11</pub-id></mixed-citation>
    </ref>
    <ref id="c37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>J. R.</given-names></name>, <name><surname>Williams</surname><given-names>N.</given-names></name>, <name><surname>Cusack</surname><given-names>R.</given-names></name>, <name><surname>Auer</surname><given-names>T.</given-names></name>, <name><surname>Shafto</surname><given-names>M. A.</given-names></name>, <name><surname>Dixon</surname><given-names>M.</given-names></name>, <etal>. . .</etal><name><surname>Henson</surname><given-names>R. N.</given-names></name></person-group> (<year>2017</year>). <article-title>The Cambridge Centre for Ageing and Neuroscience (Cam-CAN) data repository: Structural and functional MRI, MEG, and cognitive data from a cross-sectional adult lifespan sample</article-title>. <source>NeuroImage</source>, <volume>144</volume>, <fpage>262</fpage>–<lpage>269</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.09.018</pub-id><pub-id pub-id-type="pmid">26375206</pub-id></mixed-citation>
    </ref>
    <ref id="c38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vilidaite</surname><given-names>G.</given-names></name>, <name><surname>Marsh</surname><given-names>E.</given-names></name>, &amp; <name><surname>Baker</surname><given-names>D. H.</given-names></name></person-group> (<year>2019</year>). <article-title>Internal noise in contrast discrimination propagates forwards from early visual cortex</article-title>. <source>NeuroImage</source>, <volume>191</volume>, <fpage>503</fpage>–<lpage>517</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.02.049</pub-id><pub-id pub-id-type="pmid">30822470</pub-id></mixed-citation>
    </ref>
    <ref id="c39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vilidaite</surname><given-names>G.</given-names></name>, <name><surname>Norcia</surname><given-names>A. M.</given-names></name>, <name><surname>West</surname><given-names>R. J. H.</given-names></name>, <name><surname>Elliott</surname><given-names>C. J. H.</given-names></name>, <name><surname>Pei</surname><given-names>F.</given-names></name>, <name><surname>Wade</surname><given-names>A. R.</given-names></name>, &amp; <name><surname>Baker</surname><given-names>D. H.</given-names></name></person-group> (<year>2018</year>). <article-title>Autism sensory dysfunction in an evolutionarily conserved system</article-title>. <source>Proceedings of the Royal Society B</source>, <volume>285</volume>, <elocation-id>20182255</elocation-id>. <pub-id pub-id-type="doi">10.1098/rspb.2018.2255</pub-id><pub-id pub-id-type="pmid">30963913</pub-id></mixed-citation>
    </ref>
    <ref id="c25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von Oertzen</surname><given-names>T.</given-names></name></person-group> (<year>2010</year>). <article-title>Power equivalence in structural equation modelling</article-title>. <source>British Journal of Mathematical and Statistical Psychology</source>, <volume>63</volume>, <fpage>257</fpage>–<lpage>272</lpage>. <pub-id pub-id-type="doi">10.1348/000711009X441021</pub-id></mixed-citation>
    </ref>
    <ref id="c26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von Oertzen</surname><given-names>T.</given-names></name>, &amp; <name><surname>Brandmaier</surname><given-names>A. M.</given-names></name></person-group> (<year>2013</year>). <article-title>Optimal study design with identical power: An application of power equivalence to latent growth curve models</article-title>. <source>Psychology and Aging</source>, <volume>28</volume>, <fpage>414</fpage>–<lpage>428</lpage>. <pub-id pub-id-type="doi">10.1037/a0031844</pub-id><pub-id pub-id-type="pmid">23586357</pub-id></mixed-citation>
    </ref>
    <ref id="c40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L.</given-names></name>, <name><surname>Mruczek</surname><given-names>R. E. B.</given-names></name>, <name><surname>Arcaro</surname><given-names>M. J.</given-names></name>, &amp; <name><surname>Kastner</surname><given-names>S.</given-names></name></person-group> (<year>2015</year>). <article-title>Probabilistic maps of visual topography in human cortex</article-title>. <source>Cerebral Cortex</source>, <volume>25</volume>, <fpage>3911</fpage>–<lpage>3931</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhu277</pub-id><pub-id pub-id-type="pmid">25452571</pub-id></mixed-citation>
    </ref>
    <ref id="c41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>A. B.</given-names></name>, &amp; <name><surname>Pelli</surname><given-names>D. G.</given-names></name></person-group> (<year>1983</year>). <article-title>QUEST: A Bayesian adaptive psychometric method</article-title>. <source>Perception and Psychophysics</source>, <volume>33</volume>, <fpage>113</fpage>–<lpage>120</lpage>.<pub-id pub-id-type="pmid">6844102</pub-id></mixed-citation>
    </ref>
    <ref id="c42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westfall</surname><given-names>J.</given-names></name>, <name><surname>Kenny</surname><given-names>D. A.</given-names></name>, &amp; <name><surname>Judd</surname><given-names>C. M.</given-names></name></person-group> (<year>2014</year>). <article-title>Statistical power and optimal design in experiments in which samples of participants respond to samples of stimuli</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>143</volume>, <fpage>2020</fpage>–<lpage>2045</lpage>. <pub-id pub-id-type="doi">10.1037/xge0000014</pub-id><pub-id pub-id-type="pmid">25111580</pub-id></mixed-citation>
    </ref>
    <ref id="c43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>R. H.</given-names></name>, &amp; <name><surname>Zimmerman</surname><given-names>D. W.</given-names></name></person-group> (<year>1989</year>). <article-title>Statistical power analysis and reliability of measurement</article-title>. <source>The Journal of General Psychology</source>, <volume>116</volume>, <fpage>359</fpage>–<lpage>369</lpage>. <pub-id pub-id-type="doi">10.1080/00221309.1989.9921123</pub-id></mixed-citation>
    </ref>
    <ref id="c44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Z.</given-names></name>, <name><surname>Adam</surname><given-names>K. C. S.</given-names></name>, <name><surname>Fang</surname><given-names>X.</given-names></name>, &amp; <name><surname>Vogel</surname><given-names>E. K.</given-names></name></person-group> (<year>2018</year>). <article-title>The reliability and stability of visual working memory capacity</article-title>. <source>Behavior Research Methods</source>, <volume>50</volume>, <fpage>576</fpage>–<lpage>588</lpage>. <pub-id pub-id-type="doi">10.3758/s13428-017-0886-6</pub-id><pub-id pub-id-type="pmid">28389852</pub-id></mixed-citation>
    </ref>
    <ref id="c45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zuo</surname><given-names>X.-N.</given-names></name>, <name><surname>Xu</surname><given-names>T.</given-names></name>, &amp; <name><surname>Milham</surname><given-names>M. P.</given-names></name></person-group> (<year>2019</year>). <article-title>Harnessing reliability for neuroscience research</article-title>. <source>Nature Human Behavior</source>, <volume>3</volume>, <fpage>768</fpage>–<lpage>771</lpage>. <pub-id pub-id-type="doi">10.1038/s41562-019-0655-x</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <table-wrap id="tbl1" position="float" orientation="portrait">
    <label>Table 1</label>
    <caption>
      <title>Summary of Means, Standard Deviations, and Effect Sizes for Different Paradigms</title>
    </caption>
    <alternatives>
      <graphic id="tbl1a" xlink:href="met_26_3_295_tbl1a"/>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col span="1"/>
          <col span="1"/>
          <col span="1"/>
          <col span="1"/>
          <col char="." span="1"/>
          <col span="1"/>
          <col char="." span="1"/>
        </colgroup>
        <thead>
          <tr valign="bottom">
            <th rowspan="1" colspan="1">Paradigm</th>
            <th rowspan="1" colspan="1">Mean effect</th>
            <th rowspan="1" colspan="1">σ<sub><italic>w</italic></sub></th>
            <th rowspan="1" colspan="1">σ<sub><italic>b</italic></sub></th>
            <th rowspan="1" colspan="1"><italic>SD</italic> ratio</th>
            <th rowspan="1" colspan="1">σ<sub><italic>s</italic></sub></th>
            <th rowspan="1" colspan="1">Effect size (<italic>d</italic>)</th>
          </tr>
        </thead>
        <tfoot>
          <tr valign="top">
            <td colspan="7" rowspan="1"><italic>Note</italic>. The <italic>SD</italic> ratio is defined as σ<sub><italic>w</italic></sub>/σ<sub><italic>b</italic></sub>.</td>
          </tr>
          <tr valign="top">
            <td colspan="7" rowspan="1">* Estimated = To estimate a within-participant <italic>SD</italic>, we ran simulations to optimize the value of this parameter using the full power contour surface (see text for details).</td>
          </tr>
        </tfoot>
        <tbody valign="top">
          <tr valign="top">
            <td rowspan="1" colspan="1">Reaction times</td>
            <td rowspan="1" colspan="1">51 <italic>ms</italic></td>
            <td rowspan="1" colspan="1">151 <italic>ms</italic></td>
            <td rowspan="1" colspan="1">41 <italic>ms</italic></td>
            <td rowspan="1" colspan="1">3.6</td>
            <td rowspan="1" colspan="1">42 <italic>ms</italic></td>
            <td rowspan="1" colspan="1">1.2</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">Iowa Gambling Task</td>
            <td rowspan="1" colspan="1">0.04</td>
            <td rowspan="1" colspan="1">0.47</td>
            <td rowspan="1" colspan="1">0.15</td>
            <td rowspan="1" colspan="1">3.1</td>
            <td rowspan="1" colspan="1">0.16</td>
            <td rowspan="1" colspan="1">0.24</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">Sensory thresholds</td>
            <td rowspan="1" colspan="1">6.6 dB</td>
            <td rowspan="1" colspan="1">33.5 dB*</td>
            <td rowspan="1" colspan="1">1.3 dB</td>
            <td rowspan="1" colspan="1">11.9</td>
            <td rowspan="1" colspan="1">3.6 dB</td>
            <td rowspan="1" colspan="1">1.8</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">ERP P100</td>
            <td rowspan="1" colspan="1">1.47 μV</td>
            <td rowspan="1" colspan="1">12.0 μV*</td>
            <td rowspan="1" colspan="1">1.14 μV</td>
            <td rowspan="1" colspan="1">10.5</td>
            <td rowspan="1" colspan="1">1.25 μV</td>
            <td rowspan="1" colspan="1">1.2</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">ERP P200</td>
            <td rowspan="1" colspan="1">1.93 μV</td>
            <td rowspan="1" colspan="1">13.8 μV*</td>
            <td rowspan="1" colspan="1">1.64 μV</td>
            <td rowspan="1" colspan="1">8.4</td>
            <td rowspan="1" colspan="1">1.74 μV</td>
            <td rowspan="1" colspan="1">1.1</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">ERP N600</td>
            <td rowspan="1" colspan="1">7.84 μV</td>
            <td rowspan="1" colspan="1">21.1 μV*</td>
            <td rowspan="1" colspan="1">5.27 μV</td>
            <td rowspan="1" colspan="1">4.0</td>
            <td rowspan="1" colspan="1">5.34 μV</td>
            <td rowspan="1" colspan="1">1.5</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">SSVEP 8% vs 0%</td>
            <td rowspan="1" colspan="1">0.25 μV</td>
            <td rowspan="1" colspan="1">3.1 μV*</td>
            <td rowspan="1" colspan="1">0.19 μV</td>
            <td rowspan="1" colspan="1">16.3</td>
            <td rowspan="1" colspan="1">0.19 μV</td>
            <td rowspan="1" colspan="1">0.7</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">Event-related fMRI</td>
            <td rowspan="1" colspan="1">β = 28.6</td>
            <td rowspan="1" colspan="1">β = 515*</td>
            <td rowspan="1" colspan="1">β = 32.2</td>
            <td rowspan="1" colspan="1">16.0</td>
            <td rowspan="1" colspan="1">β = 32.2</td>
            <td rowspan="1" colspan="1">0.9</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">Blocked fMRI 3 s versus 0 s</td>
            <td rowspan="1" colspan="1">0.09%</td>
            <td rowspan="1" colspan="1">0.49%</td>
            <td rowspan="1" colspan="1">0.32%</td>
            <td rowspan="1" colspan="1">1.5</td>
            <td rowspan="1" colspan="1">0.33%</td>
            <td rowspan="1" colspan="1">0.26</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">Blocked fMRI 6 s versus 3 s</td>
            <td rowspan="1" colspan="1">0.59%</td>
            <td rowspan="1" colspan="1">0.50%</td>
            <td rowspan="1" colspan="1">0.34%</td>
            <td rowspan="1" colspan="1">1.5</td>
            <td rowspan="1" colspan="1">0.35%</td>
            <td rowspan="1" colspan="1">1.70</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">Blocked fMRI 9 s versus 6 s</td>
            <td rowspan="1" colspan="1">0.31%</td>
            <td rowspan="1" colspan="1">0.47%</td>
            <td rowspan="1" colspan="1">0.23%</td>
            <td rowspan="1" colspan="1">2.1</td>
            <td rowspan="1" colspan="1">0.24%</td>
            <td rowspan="1" colspan="1">1.29</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">Blocked fMRI 9 s versus 12 s</td>
            <td rowspan="1" colspan="1">0.37%</td>
            <td rowspan="1" colspan="1">0.52%</td>
            <td rowspan="1" colspan="1">0.40%</td>
            <td rowspan="1" colspan="1">1.3</td>
            <td rowspan="1" colspan="1">0.41%</td>
            <td rowspan="1" colspan="1">0.91</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">MEG 50 ms</td>
            <td rowspan="1" colspan="1">0.20 <italic>p</italic>T/<italic>m</italic></td>
            <td rowspan="1" colspan="1">8.25 <italic>p</italic>T/<italic>m</italic></td>
            <td rowspan="1" colspan="1">0.87 <italic>p</italic>T/<italic>m</italic></td>
            <td rowspan="1" colspan="1">9.5</td>
            <td rowspan="1" colspan="1">1.15 <italic>p</italic>T/<italic>m</italic></td>
            <td rowspan="1" colspan="1">0.17</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">MEG 54 ms</td>
            <td rowspan="1" colspan="1">0.42 <italic>p</italic>T/<italic>m</italic></td>
            <td rowspan="1" colspan="1">8.32 <italic>p</italic>T/<italic>m</italic></td>
            <td rowspan="1" colspan="1">1.03 <italic>p</italic>T/<italic>m</italic></td>
            <td rowspan="1" colspan="1">8.1</td>
            <td rowspan="1" colspan="1">1.28 <italic>p</italic>T/<italic>m</italic></td>
            <td rowspan="1" colspan="1">0.32</td>
          </tr>
          <tr valign="top">
            <td rowspan="1" colspan="1">MEG 58 ms</td>
            <td rowspan="1" colspan="1">0.72 <italic>p</italic>T/<italic>m</italic></td>
            <td rowspan="1" colspan="1">8.38 <italic>p</italic>T/<italic>m</italic></td>
            <td rowspan="1" colspan="1">1.18 <italic>p</italic>T/<italic>m</italic></td>
            <td rowspan="1" colspan="1">7.1</td>
            <td rowspan="1" colspan="1">1.41 <italic>p</italic>T/<italic>m</italic></td>
            <td rowspan="1" colspan="1">0.51</td>
          </tr>
        </tbody>
      </table>
    </alternatives>
  </table-wrap>
  <fig id="fig1" position="float">
    <label>Figure 1</label>
    <caption>
      <p>Simulations of standard deviation and statistical power. Panel (a) shows simulated data for 50 individuals, generated using a population mean of <italic>M</italic> = 0, a within-participants standard deviation of σ<sub><italic>w</italic></sub> = 0, a between-participants standard deviation of σ<sub><italic>b</italic></sub> = 2, and a sample standard deviation of σ<sub><italic>s</italic></sub> = 2. Individual data points have a random vertical offset for display purposes. In panel (b) the within-participant standard deviation was increased to σ<sub><italic>w</italic></sub> = 10, and each point is the mean of 20 trials, with horizontal error bars indicating ±1 SEM. Panel (c) shows the effect of increasing to 200 trials per participant. Panel (d) plots traditional power curves for different effect sizes (Cohen’s <italic>d</italic>) as a function of sample size (<italic>N</italic>). The dashed horizontal line indicates a power of 80%, which is generally considered acceptable. Panel (e) shows how the sample standard deviation (σ<sub><italic>s</italic></sub>) depends on the number of trials per participant (<italic>k</italic>) for a range of within-participant standard deviations (see legend), and a between-participants standard deviation of σ<sub><italic>b</italic></sub> = 2. Panel (f) shows the statistical power resulting from the values in panel (e), for a sample size of <italic>N</italic> = 200 and an underlying mean of <italic>M</italic> = 0.5. Panels (g, h) show power contours for different combinations of σ<sub><italic>w</italic></sub> and σ<sub><italic>b</italic></sub>, as described in the text, and a group mean of <italic>M</italic> = 1. Simulations used normally distributed random numbers, and statistical power was calculated for a two-sided, one-sample <italic>t</italic> test comparing to a mean of 0.</p>
    </caption>
    <graphic id="fig1a" xlink:href="met_26_3_295_fig1a"/>
  </fig>
  <fig id="fig2" position="float">
    <label>Figure 2</label>
    <caption>
      <p>Summary of RT data. Panel (a) shows RT distributions for an example participant, with vertical lines giving the means. Panel (b) shows the group level data for mean RTs across the sample of 38 participants. Panel (c) shows a power contour plot, in which color represents statistical power (see legend). The thick blue line indicates combinations of sample size and trial number with a power of 80%. The <italic>y</italic>-axis represents the number of trials in the incongruent condition (the congruent condition contained three times as many trials).</p>
    </caption>
    <graphic id="fig2a" xlink:href="met_26_3_295_fig2a"/>
  </fig>
  <fig id="fig3" position="float">
    <label>Figure 3</label>
    <caption>
      <p>Summary of proportion data from the Iowa Gambling task. Panel (a) shows a density plot of the mean probability of choosing a card from a “good” deck for the population of <italic>N</italic> = 504 participants, each averaged across <italic>k</italic> = 100 trials. The vertical yellow line shows the grand mean, and the dashed vertical line is the probability expected by chance. The black curve (with gray shading showing ±1 <italic>SE</italic>) shows the mean probability across all participants on each trial (1 to 100). Panel (b) shows power contours for one-sample <italic>t</italic> tests comparing the mean probability to the chance baseline (0.5). For these simulations, trials were randomly subsampled. Panel (c) shows power contours when trials were included sequentially.</p>
    </caption>
    <graphic id="fig3a" xlink:href="met_26_3_295_fig3a"/>
  </fig>
  <fig id="fig4" position="float">
    <label>Figure 4</label>
    <caption>
      <p>Summary of threshold psychophysics data. Panel (a) shows psychometric functions for a single participant, with symbol size proportional to the number of trials at each target contrast level. Curves are fitted cumulative Gaussian functions, used to interpolate thresholds at 75% correct (dashed line). Data for the monocular condition (blue) were pooled across the left and right eye conditions before fitting. Panel (b) shows distributions of monocular (blue) and binocular (yellow) detection thresholds across a group of <italic>N</italic> = 38 participants with normal vision. Panel (c) shows the power contours derived by subsampling the data and refitting the psychometric functions.</p>
    </caption>
    <graphic id="fig4a" xlink:href="met_26_3_295_fig4a"/>
  </fig>
  <fig id="fig5" position="float">
    <label>Figure 5</label>
    <caption>
      <p>Summary of ERP results. Panel (a) shows grand mean ERPs in response to central presentation of a 50% contrast sine wave grating in two intervals of each trial. Shaded regions surrounding each trace show ±1 <italic>SE</italic> across participants (<italic>N</italic> = 22), and the gray rectangles illustrate the time windows used to estimate peaks. The inset shows the distribution of voltages across the scalp at 226 ms after stimulus onset and black symbol mark the electrodes (<italic>Oz, O1, O2, POz, PO3–PO8</italic>) over which ERPs were averaged. Panels (b–d) show average peak voltages across a group of <italic>N</italic> = 22 participants in each time window, for both intervals and their difference. Panels (e–g) show power contours for the peak voltage within each time window.</p>
    </caption>
    <graphic id="fig5a" xlink:href="met_26_3_295_fig5a"/>
  </fig>
  <fig id="fig6" position="float">
    <label>Figure 6</label>
    <caption>
      <p>Summary of SSVEP data. Panel (a) shows Fourier spectra for full 10 s long trials, using either coherent (blue) or incoherent (red) averaging, and the scalp distribution of activity at 7 Hz (inset). Panel (b) shows contrast response functions for both types of averaging. Panel (c) shows the distribution of amplitudes for an example participant, and panel (d) shows averages for the population. Panels (e) and (f) show power contours for coherent and incoherent averaging, respectively.</p>
    </caption>
    <graphic id="fig6a" xlink:href="met_26_3_295_fig6a"/>
  </fig>
  <fig id="fig7" position="float">
    <label>Figure 7</label>
    <caption>
      <p>Summary of event-related fMRI analysis and results. Panel (a) shows the V1 region of interest on the medial surface of the standard (MNI152) brain, highlighted in blue. Panel (b) shows the canonical double gamma hemodynamic response function used in our general linear models. Panel (c) shows an example time-course from the V1 ROI for one participant (blue), and a general linear model constructed to predict this time-course (black) based on stimulus events (red). The green and purple traces show example GLM components with random subsets of trials. Panel (d) shows the population distributions of beta weights for the full GLM modeling all stimulus events (yellow) or randomly simulated times (blue). Panel (e) shows the power contour plot for these event-related fMRI data.</p>
    </caption>
    <graphic id="fig7a" xlink:href="met_26_3_295_fig7a"/>
  </fig>
  <fig id="fig8" position="float">
    <label>Figure 8</label>
    <caption>
      <p>Summary of blocked design fMRI data. Panel (a) shows an fMRI time-course for an example individual, averaged across the V1 ROI (see <xref ref-type="fig" id="fgc7-9" rid="fig7">Figure 7a</xref>). Shaded gray regions at the foot of the panel indicate blocks when stimuli were presented. Panel (b) shows the data from panel (a) aligned to each block onset and averaged across all <italic>k</italic> = 35 blocks (with error bars showing ±1 <italic>SD</italic>). The gray shaded regions at the foot of the panel indicate the presentations of individual stimuli within a block. Panel (c) shows distributions of BOLD activity at each time point. Panels d–f mirror panels a–c but for the sample of <italic>N</italic> = 83 participants. Panels g–j show power contours for the fMRI data, comparing activity at successive time points.</p>
    </caption>
    <graphic id="fig8a" xlink:href="met_26_3_295_fig8a"/>
  </fig>
  <fig id="fig9" position="float">
    <label>Figure 9</label>
    <caption>
      <p>Summary of MEG results. Panel (a) shows a butterfly plot of evoked responses from 204 planar gradiometers, averaged across all participants (<italic>N</italic> = 637). The MEG montage is depicted in the upper left inset, where planar gradiometers of orthogonal orientations are indicated in blue and red, and magnetometer locations are shown in gray. The upper right inset shows the distribution of field strengths across a subset of 102 gradiometers with consistent orientation at 130 ms (the peak of the black curve), and the black dot indicates the location of the sensor used for the analysis. Colored points highlighted on the black curve indicate time points used for power analysis. Panel (b) shows distributions of field strengths at each of the three target time points for an individual participant. Panel (c) shows the same but for the sample population of <italic>N</italic> = 637 participants. Panels (d–f) show power contours for different time-points.</p>
    </caption>
    <graphic id="fig9a" xlink:href="met_26_3_295_fig9a"/>
  </fig>
  <fig id="fig10" position="float">
    <label>Figure 10</label>
    <caption>
      <p>Summary of sample sizes, trial numbers, and Fano-factors across experimental paradigms. Each rectangle in (a) covers the range of sample sizes and trial numbers for one of the studies analyzed here, with colors defined in the legend in panel (b). Panel (b) plots Fano-factors (variance divided by the mean) derived from the within- and between-participants standard deviations given in <xref rid="tbl1" ref-type="table">Table 1</xref>. Note the log-scaled axes for both panels.</p>
    </caption>
    <graphic id="fig10a" xlink:href="met_26_3_295_fig10a"/>
  </fig>
  <fig id="fig11" position="float">
    <label>Figure 11</label>
    <caption>
      <p>Summary of the influence on power of the distribution of within-participant standard deviations, and the correlation between repeated measures. Panel (a) illustrates possible distributions of within-participant standard deviations. The gray curve shows an empirical distribution derived from the MEG data set (<italic>N</italic> = 637 at 58 ms). The dashed line gives a fixed value, which is the mean of the empirical distribution excluding values &gt;15 <italic>pT/m</italic>. The blue curve shows a normal distribution, with mean and <italic>SD</italic> derived from the empirical distribution (<italic>M</italic> = 6.99, <italic>SD</italic> = 2.17). The yellow curve shows the gamma distribution that best fits the empirical distribution (shape = 17.64, scale = 0.36). Panel (b) shows statistical power as a function of the number of trials for a range of sample sizes, using the four distributions shown in (a). Panels (c–e) show simulated power contours for repeated measures designs as a function of the correlation (R) between the two conditions. For these simulations we assumed a group mean difference of 0.5, between participants standard deviation of 2, and within participant standard deviation of 10. The total variance remained constant across the range of correlations.</p>
    </caption>
    <graphic id="fig11a" xlink:href="met_26_3_295_fig11a"/>
  </fig>
  <fig id="fig12" position="float">
    <label>Figure 12</label>
    <caption>
      <p>Example power contours for one-way and factorial ANOVAs. Panel (a) shows a power contour plot for a one-way repeated measures ANOVA using three levels from the blocked fMRI data (summarized in <xref ref-type="fig" id="fgc8-10" rid="fig8">Figure 8</xref>). Panels (b–d) show power contours for the main effects of contrast (b) and mask level (c), as well as their interaction (d) in a 7 × 2 repeated measures ANOVA design using the SSVEP data set (summarized in <xref ref-type="fig" id="fgc6-12" rid="fig6">Figure 6</xref>).</p>
    </caption>
    <graphic id="fig12a" xlink:href="met_26_3_295_fig12a"/>
  </fig>
</floats-group>
