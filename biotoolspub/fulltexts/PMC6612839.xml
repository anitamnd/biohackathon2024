<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6612839</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btz330</article-id>
    <article-id pub-id-type="publisher-id">btz330</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Ismb/Eccb 2019 Conference Proceedings</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Macromolecular Sequence, Structure, and Function</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepLigand: accurate prediction of MHC class I ligands using peptide embedding</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Zeng</surname>
          <given-names>Haoyang</given-names>
        </name>
        <xref ref-type="aff" rid="btz330-aff1">1</xref>
        <xref ref-type="aff" rid="btz330-aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gifford</surname>
          <given-names>David K</given-names>
        </name>
        <xref ref-type="aff" rid="btz330-aff1">1</xref>
        <xref ref-type="aff" rid="btz330-aff2">2</xref>
        <xref ref-type="corresp" rid="btz330-cor1"/>
        <!--<email>gifford@mit.edu</email>-->
      </contrib>
    </contrib-group>
    <aff id="btz330-aff1"><label>1</label>Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA</aff>
    <aff id="btz330-aff2"><label>2</label>Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA, USA</aff>
    <author-notes>
      <corresp id="btz330-cor1">To whom correspondence should be addressed. <email>gifford@mit.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-07-05">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>35</volume>
    <issue>14</issue>
    <fpage>i278</fpage>
    <lpage>i283</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btz330.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>The computational modeling of peptide display by class I major histocompatibility complexes (MHCs) is essential for peptide-based therapeutics design. Existing computational methods for peptide-display focus on modeling the peptide-MHC-binding affinity. However, such models are not able to characterize the sequence features for the other cellular processes in the peptide display pathway that determines MHC ligand selection.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We introduce a semi-supervised model, DeepLigand that outperforms the state-of-the-art models in MHC Class I ligand prediction. DeepLigand combines a peptide language model and peptide binding affinity prediction to score MHC class I peptide presentation. The peptide language model characterizes sequence features that correspond to secondary factors in MHC ligand selection other than binding affinity. The peptide embedding is learned by pre-training on natural ligands, and can discriminate between ligands and non-ligands in the absence of binding affinity prediction. Although conventional affinity-based models fail to classify peptides with moderate affinities, DeepLigand discriminates ligands from non-ligands with consistently high accuracy.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>We make DeepLigand available at <ext-link ext-link-type="uri" xlink:href="https://github.com/gifford-lab/DeepLigand">https://github.com/gifford-lab/DeepLigand</ext-link>.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">National Institute of Health</named-content>
        </funding-source>
        <award-id>R01CA218094</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="6"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>The major histocompatibility complex (MHC) Class I molecules play a central role in the acquired immune system of vertebrates by presenting intracellular peptides on the cell surface for recognition by T cells (<xref rid="btz330-B4" ref-type="bibr">Castellino <italic>et al.</italic>, 1997</xref>; <xref rid="btz330-B8" ref-type="bibr">Janeway Jr <italic>et al.</italic>, 2001</xref>). The choice of which peptides are displayed is in part controlled by an individual’s MHC genotype. MHC genes are highly polymorphic and thus peptide presentation varies from individual to individual (<xref rid="btz330-B10" ref-type="bibr">Jin and Wang, 2003</xref>; <xref rid="btz330-B32" ref-type="bibr">Williams, 2001</xref>). Modeling the individual-specific preference of peptide presentation by the MHC is important for designing efficient peptide-based immuno-therapeutics for individuals (<xref rid="btz330-B17" ref-type="bibr">Kreiter <italic>et al.</italic>, 2015</xref>; <xref rid="btz330-B27" ref-type="bibr">Ott <italic>et al.</italic>, 2017</xref>; <xref rid="btz330-B31" ref-type="bibr">Verdegaal <italic>et al.</italic>, 2016</xref>).</p>
    <p>Class I MHCs present peptides derived from cytosolic proteins that are degraded by a proteasome. The degraded peptides are internalized by the transporter associated with antigen processing (TAP) channel in the endoplasmic reticulum to be potentially associated with class I MHC molecules. The formation of a MHC-peptide complex thus depends on multiple factors, including the proteasome cleavage preference of a peptide (<xref rid="btz330-B24" ref-type="bibr">Nielsen <italic>et al.</italic>, 2005</xref>), TAP transport efficiency (<xref rid="btz330-B29" ref-type="bibr">Peters <italic>et al.</italic>, 2003</xref>) and the MHC-peptide binding affinity (<xref rid="btz330-B22" ref-type="bibr">Nielsen and Andreatta, 2016</xref>).</p>
    <p>Most existing computational methods (<xref rid="btz330-B2" ref-type="bibr">Bhattacharya <italic>et al.</italic>, 2017</xref>; <xref rid="btz330-B6" ref-type="bibr">Han and Kim, 2017</xref>; <xref rid="btz330-B20" ref-type="bibr">Lundegaard <italic>et al.</italic>, 2008</xref>; <xref rid="btz330-B22" ref-type="bibr">Nielsen and Andreatta, 2016</xref>) for peptide presentation focus on modeling MHC-peptide binding affinity based on curated affinity datasets from the immunology epitope database (IEDB). Although binding affinity is essential for the formation of peptide-MHC complex, models trained only on peptide-MHC affinity are unable to characterize other factors that determine peptide display. Recent advances in mass spectrometry technology have enabled the high-throughput experimental identification of displayed peptides. Two recent computational models incorporate natural ligand datasets from mass spectrometry data in their models. MHCflurry (<xref rid="btz330-B26" ref-type="bibr">O’Donnell <italic>et al.</italic>, 2018</xref>) only considers the natural ligands as peptides that also have high binding affinity to the MHCs, and thus it remains an affinity model that doesn’t consider other peptide features that influence peptide presentation. NetMHCpan4.0 (<xref rid="btz330-B11" ref-type="bibr">Jurtz <italic>et al.</italic>, 2017</xref>) is a modified affinity model that includes an additional output node for training on natural ligand observations from mass spectrometry data. However, it assumes that affinity and uncorrelated display selection processes share the same sequence features.</p>
    <p>Here we introduce DeepLigand, a semi-supervised approach to predicting natural MHC ligands with improved accuracy. We explicitly frame the identity of displayed ligands as a function of (i) MHC-peptide binding affinity and (ii) a vector embedding of the peptide that characterizes sequence patterns potentially associated with footprints of proteasome cleavage, TAP transport efficiency, and motifs relevant to other processes. For model element (i) we model MHC-binding affinity by a deep residual network that predicts affinity from the amino acid sequence of the MHC and peptide. For model element (ii) we learn an embedding of peptide sequences by performing unsupervised learning on the natural ligands of all MHCs. We show that DeepLigand improves the performance in natural MHC ligand prediction comparing to existing published methods as well as similar models that don’t use the contextualized embedding of peptides. DeepLigand can identify MHC ligands from candidate peptides with moderate MHC-binding affinities, a challenging task where conventional affinity-based models struggle. Moreover, we demonstrate that the peptide embedding alone is highly predictive of natural ligands, indicating that meaningful patterns associated with ligand selection are captured in the embedding.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>We used the MHC class I dataset curated by <xref rid="btz330-B26" ref-type="bibr">O’Donnell <italic>et al.</italic> (2018)</xref>. This dataset consists of 525 672 binding affinity and mass spectrometry measurements collected from IEDB, <xref rid="btz330-B1" ref-type="bibr">Abelin <italic>et al.</italic> (2017)</xref> and <xref rid="btz330-B14" ref-type="bibr">Kim <italic>et al.</italic> (2014</xref>). This dataset also contains 2 541 370 non-ligand sequences (decoys) sampled from the protein-coding transcripts that also contained the mass spectrometry-identified peptides (hits) based on protein sequences in the UCSC hg19 proteome and transcript quantification from RNA sequencing of the relevant cell line (B721.221). As described in Abelin <italic>et al.</italic>, for an allele with n hits, 100n decoys of length 8–15 were sampled, weighting transcripts by the number of hits.</p>
      <p>Every peptide training example is labeled by binding affinity and presence/absence in mass spectrometry data. Some of the examples in the binding affinity and mass spectrometry datasets have only qualitative affinity measurements, represented as positive, positive-high, positive-intermediate, positive-low or negative. For such examples, O’Donnell <italic>et al.</italic> assigned a quantitative value and a relation of ‘&gt;’ or ‘&lt;’ for each class of qualitative labels to denote the corresponding range of affinity. Examples with quantitative affinity were assigned a relation of ‘=’. We further assigned an ‘unknown’ affinity to the non-ligand peptides. As is standard practice in the peptide-display literature (<xref rid="btz330-B11" ref-type="bibr">Jurtz <italic>et al.</italic>, 2017</xref>; <xref rid="btz330-B22" ref-type="bibr">Nielsen and Andreatta, 2016</xref>; <xref rid="btz330-B26" ref-type="bibr">O’Donnell <italic>et al.</italic>, 2018</xref>), we normalized the original affinity measurements in nano-molar (nM) by capping them between 1 and 50 000 nM and transforming with <inline-formula id="IE1"><mml:math id="IM1"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>nM</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>50</mml:mn><mml:mo> </mml:mo><mml:mn>000</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> such that the resulting normalized affinities fall between zero and one. Aside from binding affinity, we also created a ligand label for each example. We labeled the ligands identified by mass spectrometry as positive, the non-ligand peptides as negative, and the other peptides as ‘unknown’. We further removed MHC alleles for which the pseudo-sequence of MHC amino acids in contact with the peptide is not available from the literature (<xref rid="btz330-B11" ref-type="bibr">Jurtz <italic>et al.</italic>, 2017</xref>). The final dataset consists of 3 052 388 examples covering 219 MHC Class I alleles (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S1</xref>, <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S2</xref>).</p>
      <p>Consistent with previous work (<xref rid="btz330-B9" ref-type="bibr">Jensen <italic>et al.</italic>, 2018</xref>; <xref rid="btz330-B22" ref-type="bibr">Nielsen and Andreatta, 2016</xref>) we constructed a 5-fold cross-validation (CV) benchmark to avoid over-estimation of model performance. The benchmark minimizes the 8-mer overlap between different folds using a <xref rid="btz330-B7" ref-type="bibr">Hobohm <italic>et al.</italic> (1992)</xref> inspired algorithm described in <xref rid="btz330-B25" ref-type="bibr">Nielsen <italic>et al.</italic> (2007)</xref>. The performance on a data point was evaluated by the prediction made from a model trained on the four CV-folds that don’t contain the data point.</p>
    </sec>
    <sec>
      <title>2.2 Model structure</title>
      <p>DeepLigand consists of two modules, a binding affinity prediction module and a peptide embedding module (<xref ref-type="fig" rid="btz330-F1">Fig. 1</xref>). The peptide embedding module embeds each peptide into a vector representation. Given a pair of MHC and peptide, we make the assumption that the measured binding affinity is the sum of the true affinity and a Gaussian noise with zero mean, and thus the measured affinity follows a Gaussian distribution with a mean at the true affinity. The affinity prediction module predicts the mean and variance of the Gaussian distribution which respectively characterizes the strength of affinity and the estimated level of observational noise associated with the input. Similar techniques have been used to characterize the observational noise in various types of data (aleatoric uncertainty) (<xref rid="btz330-B13" ref-type="bibr">Kendall and Gal, 2017</xref>; <xref rid="btz330-B18" ref-type="bibr">Lakshminarayanan <italic>et al.</italic>, 2017</xref>). Using the predicted affinity mean and variance as well as the peptide embedding as input features, we used one fully connected layer with sigmoid activation to predict whether the input peptide is a natural ligand of the input MHC. The peptide embedding module was trained on the natural ligands in the training set before it was used to generate peptide embedding for all training examples. Then the affinity module and the combining layer were jointly trained with the training loss calculated as the sum of the cross-entropy loss from ligand prediction and the log probability of the observed affinity under the predicted Gaussian affinity distribution. For both types of loss, examples with a ‘unknown’ label were not included in the calculation. As was adopted in O’Donnell <italic>et al.</italic>, for examples with an inequality relation for their affinity measurement, the loss was only included when the inequality is violated.
</p>
      <fig id="btz330-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>Schematics of DeepLigand. DeepLigand consists of a binding affinity prediction module and a peptide embedding module. The affinity prediction module takes as input a pair of MHC and peptide sequence and predicts the mean and variance their binding affinity using a deep residual network. The peptide embedding module is a deep language model (ELMo) that embeds each peptide into a vector representation. The outputs from the two modules are concatenated and provided as input to one fully connected (FC) layer with sigmoid activation to predict whether the input peptide is a natural ligand of the input MHC. As a pre-training step, the embedding module is trained on the natural ligands in the training set for a given CV split. Then the affinity prediction module and the combining layer is jointly trained on all training examples taking as input the MHC and peptide sequences as well as the peptide embeddings produced by the pre-trained embedding module</p>
        </caption>
        <graphic xlink:href="btz330f1"/>
      </fig>
      <sec>
        <title>2.2.1 Binding affinity prediction module</title>
        <p>The binding affinity prediction module is a deep residual network that takes as input the amino sequence of a peptide and the pseudo-sequence of a MHC molecule. As defined in the previous literature (<xref rid="btz330-B11" ref-type="bibr">Jurtz <italic>et al.</italic>, 2017</xref>), the pseudo-sequence of a MHC allele is the amino acid residues in 34 polymorphic positions where the residues are within 4.0 Å of the peptide in the structure of one or more of major MHC alleles. We represent each amino acid sequence by a 40-dimension feature vector concatenated from two encodings: a 20-dimension one-hot encoding and the 20-dimension BLOSUM50 (<xref rid="btz330-B23" ref-type="bibr">Nielsen <italic>et al.</italic>, 2003</xref>) matrix scores vector that depicts the evolutionary similarities between amino acids. All peptides are padded to 40 amino acids. For the padding amino acid, an all-zero vector was used for the one-hot encoding and a vector full of the lowest substation score was used for the evolutional encoding. This featurization leads to a 40 × 34 feature matrix for each MHC and a 40 × 40 feature matrix for each peptide. The MHC feature matrix (40 × 34) was then reshaped into a 1360 × 1 vector and appended to the peptide matrix (40 × 40) along its first dimension, resulting in a final feature matrix of 1400 × 40 for each MHC-peptide pair.</p>
        <p>The binding affinity residual network consists of one initial convolutional block, five residual blocks and two branches of fully connected layers. Each residual block has two convolutional layers that fit the residual between the input and the output. Each convolutional layers in the network has 256 convolutional kernels with a stride of 1 and a kernel size of 3. Batch normalization was used after each convolutional layer. The output of the last residual block was flattened and concatenated with the sigmoid-transformed peptide length <inline-formula id="IE2"><mml:math id="IM2"><mml:mi>L</mml:mi></mml:math></inline-formula> and <inline-formula id="IE3"><mml:math id="IM3"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula> as the input to the last two branches of fully connected layers, respectively to predict a Gaussian mean and variance of the binding affinity between the input MHC and peptide. Each branch consists of one layer of 64 neurons and one layer of 1 neuron. ReLU was used throughout the network as non-linearity and Adam (<xref rid="btz330-B15" ref-type="bibr">Kingma and Ba, 2014</xref>) was used as the optimizer. For each CV split, a random 1/9 of the training set was held out as the validation set. All hyper-parameters, including training epochs and optimizer parameters, were chosen according to the performance on the validation set. Using the peptide sequence, MHC pseudo-sequence, and the peptide embedding produced by the pre-trained peptide embedding module as input, this module was jointly trained with the last layer of DeepLigand for 50 epochs with early stopping when no improvement on the validation loss was observed for 10 epochs.</p>
      </sec>
      <sec>
        <title>2.2.2 Peptide embedding module</title>
        <p>In the peptide embedding module, we used ELMo (<xref rid="btz330-B30" ref-type="bibr">Peters <italic>et al.</italic>, 2018</xref>) to learn a context-dependent embedding of amino acids. Considering each peptide sequence as a sentence and each amino acid as a word, ELMo trains a deep bi-directional language model on the corpus (all natural ligand sequences). The ELMo embedding of each word in a sentence is the average of the hidden states of all layers in the language model for that word, which takes into account both the word and the semantic context. The language model used in this work is reduced in size compared with Peters <italic>et al.</italic> to accommodate the smaller corpus in this study. The details of the model structure can be found in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref>. For a given CV split, a ELMo model was trained on all the natural ligands in the training set. The resulting model was then used to embed each peptide into a 64 × 40 matrix where 64 is the embedding dimension and 40 is the maximum length of the peptides in our dataset. The embedding matrix was then reshaped into an embedding vector of size 2560 as the final output of this module for a given peptide.</p>
      </sec>
    </sec>
    <sec>
      <title>2.3 Implementation of alternative learning strategies</title>
      <p>We implemented the two alternative learning strategies Affinity-Only and Two-Task (Section 3) by modifying the model structure of DeepLigand. Affinity-Only was implemented as the same structure as the affinity prediction module in DeepLigand. For Two-Task, we changed DeepLigand’s affinity prediction module structure by adding an additional set of two fully connected layers with a sigmoid output to predict whether the input peptide is a ligand of the input MHC. This new branch has the same structure as the original two fully connected layers that predicts affinity, and also shares the same input features produced by the previous residual blocks. Embedding-Only was implemented as the last layer of DeepLigand with only the peptide embedding as input features.</p>
    </sec>
    <sec>
      <title>2.4 Comparison with NetMHCpan4.0 and MHCflurry</title>
      <p>The standalone version of NetMHCpan4.0 was downloaded from <ext-link ext-link-type="uri" xlink:href="http://www.cbs.dtu.dk/services/NetMHCpan/">http://www.cbs.dtu.dk/services/NetMHCpan/</ext-link>. MHCflurry version 1.2.2 was installed as instructed on <ext-link ext-link-type="uri" xlink:href="https://github.com/openvax/mhcflurry">https://github.com/openvax/mhcflurry</ext-link> and the pre-trained ‘models_class1_trained_with_mass_spec’ model (<ext-link ext-link-type="uri" xlink:href="https://github.com/openvax/mhcflurry/releases/download/pre-1.2.1/models">https://github.com/openvax/mhcflurry/releases/download/pre-1.2.1/models</ext-link> _class1_trained_with_mass_spec.20180228.tar.bz2) was downloaded by ‘mhcflurry-downloads fetch models_class1_rained_with_mass_spec’. Both methods only support certain MHC alleles. Only test set examples for which both methods can process were used in the model evaluation.</p>
    </sec>
    <sec>
      <title>2.5 Sufficient Input Subsets analysis</title>
      <p>The Sufficient Input Subset (SIS) software was downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/google-research/google-research/tree/master/sufficient_input_subsets">https://github.com/google-research/google-research/tree/master/sufficient_input_subsets</ext-link>. To accommodate the computation efficiency of SIS, we randomly sampled 10 000 MHC ligands with 9 amino acids and performed SIS on each ligand sequence to identify the minimal subset of residuals for the Embedding-Only model to predict the input sequence as ligand with &gt;95% probability. The first layer of the language model in Embedding-Only represents each amino acid as a vector. As suggested by Carter et al., we used the average of the vector representations for all 20 amino acids to represent the ‘mask’ residual that SIS uses to iteratively replace the original residuals in search for the minimally sufficient subset. The resulting SISs were clustered into six non-noise groups using DBSCAN in Scikit-Learn (<xref rid="btz330-B28" ref-type="bibr">Pedregosa <italic>et al.</italic>, 2011</xref>) with pre-computed Levenshtein distance as metric and hyper-parameters eps = 1 and min_samples = 50. WebLogo (<xref rid="btz330-B5" ref-type="bibr">Crooks <italic>et al.</italic>, 2004</xref>; <ext-link ext-link-type="uri" xlink:href="http://weblogo.threeplusone.com">http://weblogo.threeplusone.com</ext-link>) was used to aggregate the SISs in each cluster into a sequence logo.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 DeepLigand improves the state-of-the-art accuracy in MHC ligand prediction</title>
      <p>We trained and evaluated DeepLigand on a curated dataset of peptide-MHC-binding affinity measurements, mass spectrometry measurements, and non-ligand peptides collected by O’Donnell <italic>et al</italic>. (Section 2). As is standard practice in the peptide-display literature (<xref rid="btz330-B9" ref-type="bibr">Jensen <italic>et al.</italic>, 2018</xref>; <xref rid="btz330-B22" ref-type="bibr">Nielsen and Andreatta, 2016</xref>; <xref rid="btz330-B25" ref-type="bibr">Nielsen <italic>et al.</italic>, 2007</xref>), we constructed a 5-fold CV benchmark while minimizing the 8-mer overlap between different folds (Section 2).</p>
      <p>We evaluated DeepLigand against NetMHCpan4.0 and MHCflurry. These two alternative models can only make predictions for select MHC alleles. We limited our test set samples to examples that all methods could process. We note that, while the test set is completely held out from DeepLigand, MHCflurry’s training set contains all the ligands in our test set, making the benchmark biased towards MHCflurry. NetMHCpan4.0 was trained on unreleased datasets and we do not know the overlap with our test set.</p>
      <p>We found that DeepLigand outperforms previous state-of-the-art models at the task of predicting peptide presentation, despite the potential train-test set overlap advantages of previous methods (<xref ref-type="fig" rid="btz330-F2">Fig. 2A</xref>). DeepLigand accurately predicts MHC ligands with an area under receiver operating characteristic curve (auROC) of 0.979 and an area under precision recall curve (auPRC) of 0.887, compared with an auROC of 0.937 (MHCflurry) and auPRC of 0.821 (NetMHCpan4.0) for the best previous state-of-the-art models. In therapeutic design, a high true positive rate at a low false positive rate and high recall with high precision are often more important metrics. DeepLigand outperforms the competing methods with a true positive rate of 91.0% at a false positive rate of 5% and 83.5% recall at 80% precision (<xref ref-type="fig" rid="btz330-F2">Fig. 2B</xref>). The best alternative method (NetMHCpan4.0) produces a true positive rate of 83.7% at a false positive rate of 5%, and 78.2% recall at 80% precision.
</p>
      <fig id="btz330-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Performance comparison with published state-of-the-art methods for peptide display. The evaluation was performed on test set examples that all three methods can process. <bold>(A)</bold> DeepLigand achieved higher auROC (left) and auPRC (right). <bold>(B)</bold> DeepLigand achieved a higher true positive rate at 5% false positive rate (left) and higher recall at 80% precision (right)</p>
        </caption>
        <graphic xlink:href="btz330f2"/>
      </fig>
    </sec>
    <sec>
      <title>3.2 DeepLigand outperforms alternative learning strategies for MHC ligand prediction</title>
      <p>We next compared DeepLigand and alternative formulations of MHC ligand models with a controlled training set. MHCflurry only treats natural ligands identified by mass spectrometry as additional peptides with high binding affinity, and we refer to this strategy as <italic>Affinity-Only</italic>. NetMHCpan4.0 treats binding affinity and ligand presentation as two separate tasks that share all intermediate features, and we refer to this strategy as <italic>Two-Task</italic>. We implemented Affinity-Only and Two-Task by modifying the affinity prediction module in DeepLigand (Section 2). We trained and tested these models on the same datasets as DeepLigand, and thus excluded confounding factors such as training dataset mismatch to more precisely examine the power of different strategies for modeling MHC ligand. Note that unlike the comparison with published methods, here we were able to use the whole test set for evaluation.</p>
      <p>We found that DeepLigand outperforms the alternative model formulations with an auROC of 0.984, an auPRC of 0.912, a true positive rate of 93.2% at a false positive rate of 5%, and 87.6% recall at 80% precision (<xref ref-type="fig" rid="btz330-F3">Fig. 3</xref>). The best alternative model (Affinity-Only) achieved an auROC of 0.924, an auPRC of 0.637, a true positive rate of 69.5% at a false positive rate of 5% and 31.4% recall at 80% precision. Interestingly, our Two-Task implementation showed inferior performance compared with NetMHCpan4.0 which uses the same modeling strategy. Aside from the difference in the training set, this could arise from the fact that the non-ligand to ligand ratio in our benchmark dataset (100×) is much higher than the dataset that NetMHCpan4.0 was trained on (10×), which makes joint learning of both tasks more challenging.
</p>
      <fig id="btz330-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>Performance comparison with alternative learning strategies trained on the same dataset as DeepLigand. The evaluation was performed on all test set examples. <bold>(A)</bold> DeepLigand achieved higher auROC (left) and auPRC (right). <bold>(B)</bold> DeepLigand achieved a higher true positive rate at 5% false positive rate (left) and higher recall at 80% precision (right)</p>
        </caption>
        <graphic xlink:href="btz330f3"/>
      </fig>
      <p>Affinity-Only represents the modeling strategy of most peptide-display models used in therapeutic vaccine design to select for MHC-binding peptides [predicted affinity ≤500 nM; <xref rid="btz330-B27" ref-type="bibr">Ott <italic>et al.</italic> (2017)</xref>; <xref rid="btz330-B19" ref-type="bibr">Łuksza <italic>et al.</italic> (2017)</xref>]. Therefore, we examined the performance of Affinity-Only and DeepLigand for MHC ligand prediction. We observed that the two formulations agree on low-affinity peptides. However, the predictions are much less consistent on peptides with medium to high predicted affinities (<xref ref-type="fig" rid="btz330-F4">Fig. 4A</xref>). Evaluated on different subsets of peptides predicted to bind to the corresponding MHC, the predictive performance of Affinity-Only model degenerates fast towards random as we focused more on medium binders, while DeepLigand accurately discriminates ligands from non-ligands with consistently high auROCs and auPRCs above 0.9 (<xref ref-type="fig" rid="btz330-F4">Fig. 4B</xref>).
</p>
      <fig id="btz330-F4" orientation="portrait" position="float">
        <label>Fig. 4.</label>
        <caption>
          <p>Comparison between Affinity-Only and DeepLigand. <bold>(A)</bold> The scatter plot of affinity prediction from Affinity-Only (x-axis) and ligand prediction from DeepLigand (y-axis). Each point is a pair of peptide-MHC colored by whether the peptide is a ligand of the MHC as determined by mass spectrometry. <bold>(B)</bold> auROC (left) and auPRC (right) of DeepLigand and Affinity-Only when considering peptides with predicted affinities in different ranges. To obtain practically meaningful thresholds, affinities were converted to nM unit and affinity of lower nano-molar is stronger</p>
        </caption>
        <graphic xlink:href="btz330f4"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 Peptide embedding encapsulates sequences patterns predictive of natural ligands</title>
      <p>We further examined the relative importance of DeepLigand’s peptide embedding in its MHC ligand prediction task. We removed the affinity prediction module in DeepLigand such that ligand prediction is made by a one-layer neural network using solely the peptide embedding as its features (Section 2). We refer to this strategy as <italic>Embedding-Only</italic>. We observed that the Embedding-Only model achieved high accuracy in MHC Class I ligand prediction (<xref ref-type="fig" rid="btz330-F3">Fig. 3</xref>). As Embedding-Only takes no MHC information as input, the high predictive performance suggests that the embedding that DeepLigand learned from natural MHC ligands in an unsupervised fashion captures important sequence features shared across the ligands of different MHCs. These sequence features, which have been largely ignored by existing models, are highly discriminative of ligands and non-ligands even without knowledge about the affinity to the MHC molecule.</p>
      <p>We applied Sufficient Input Subset (SIS) analysis (<xref rid="btz330-B3" ref-type="bibr">Carter <italic>et al.</italic>, 2018</xref>) to interpret the sequence features the Embedding-Only model has learned to identify MHC ligands. On 10 000 random samples of all MHC ligands of 9 amino acids in our dataset, we performed SIS to locate the minimal subset of residuals for the Embedding-Only model to predict a peptide as MHC ligand with a probability &gt;95% (Section 2). Using DBSCAN as suggested by Carter <italic>et al.</italic>, the resulting SISs can be clustered into six groups. The sequence logos of these six groups suggest that the residuals at positions 1, 2, 4 and 9 of a peptide are most essential for the discrimination of ligands from non-ligands (<xref ref-type="fig" rid="btz330-F5">Fig. 5A</xref>). Moreover, the motifs manifested by the SISs clusters characterize similar amino acid preferences as the known proteasome cleavage motif (<xref ref-type="fig" rid="btz330-F1">Fig. 1</xref> in <xref rid="btz330-B12" ref-type="bibr">Keşmir <italic>et al.</italic>, 2002</xref>; the upside down letters mean depletion), such as R/K/A at position 1, R/L/A/I/P at position 2, D/P/E at position 4 and L/Y/F/V at position 9.
</p>
      <fig id="btz330-F5" orientation="portrait" position="float">
        <label>Fig. 5.</label>
        <caption>
          <p>The sequence logos of each of the six clusters of SISs identified from 10 000 random samples of MHC ligands of 9 amino acids. The x-axis denotes the position on the peptide and the y-axis denotes the information content</p>
        </caption>
        <graphic xlink:href="btz330f5"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>Existing computational efforts to model peptide presentation by MHC class I molecules have been focused on predicting the binding affinity between MHC molecules and peptides. However, additional factors determine which peptides in the proteome become natural MHC ligands, including the abundance of their transcripts, their proteasome cleavage motifs, and TAP-mediated peptide transport efficiency. Without considering these auxiliary factors, affinity-based models could lead to false positives when designing MHC-presenting peptides in therapeutic design.</p>
    <p>We presented a new semi-supervised model for the presentation of peptides by MHC Class I molecules. Our method DeepLigand explicitly frames the identity of MHC ligand as a function of binding affinity prediction and a sequence representation that characterizes auxiliary factors in ligand determination. We show that by employing a contextual word embedding algorithm trained on ligands in an unsupervised manner, we can embed peptides in a predictive vector representation. Even though only positive ligands were used during training, the resulting embedding alone is highly discriminative of natural ligands and non-ligands. Leveraging a published method for model interpretation, we find that the sequence patterns for which the embedding is highly indicative of ligands recapitulate the known proteasome cleavage motif, suggesting the sequence determinants of important factors in MHC ligand selection other than binding affinity have been learned. Combining the peptide embedding with binding affinity predicted from the MHC and peptide sequence, DeepLigand improved the accuracy in natural MHC ligand prediction compared previously published state-of-the-art.</p>
    <p>We observe that widely used affinity-based models have a high false positive rate when prioritizing natural ligands from peptides that have medium binding affinities. By point of comparison, the ligand prediction from DeepLigand, which uses the peptide embedding obtained from unsupervised learning on natural ligands, can still accurately discriminate held-out ligands from non-ligands.</p>
    <p>With DeepLigand’s improved false positive rate, we envision DeepLigand can be used to design effective neo-antigen vaccine formulations. In neo-antigen vaccine design, cancer-specific peptides are prioritized for MHC presentation. Most of the cancer-specific peptides have low to medium binding affinity to the MHC molecules in the patient, and the number of administered peptides to be designed is highly limited (<xref rid="btz330-B27" ref-type="bibr">Ott <italic>et al.</italic>, 2017</xref>). Thus reducing the false positive rate will reduce the number of administered peptides that are not disease related.</p>
    <p>Mass spectrometry is currently the most direct measure of natural MHC ligand presentation, and in this work we equate the read out from mass spectrometry with the collection of natural ligands. We note that certain biases (<xref rid="btz330-B16" ref-type="bibr">Klont <italic>et al.</italic>, 2018</xref>; <xref rid="btz330-B21" ref-type="bibr">Mahoney <italic>et al.</italic>, 2011</xref>) are known to exist in the sequences identified from mass spectrometry, which could limit the power of computational models trained on such datasets. With the future advance of biotechnology, we envision our approach can be further improved to deliver more accurate natural MHC ligand predictions.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btz330_Supplementary_Data</label>
      <media xlink:href="btz330_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We thank Brooke Huisman for helpful discussions. We also thank Brandon Carter for the guidance on running Sufficient Input Subsets analysis.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by National Institute of Health [R01CA218094].</p>
      <p><italic>Conflict of Interest</italic>: D.K.G. is a founder of Think Therapeutics, a company that uses machine learning for therapeutic design.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btz330-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Abelin</surname><given-names>J.G.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Mass spectrometry profiling of HLA-associated peptidomes in mono-allelic cells enables more accurate epitope prediction</article-title>. <source>Immunity</source>, <volume>46</volume>, <fpage>315</fpage>–<lpage>326</lpage>.<pub-id pub-id-type="pmid">28228285</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Bhattacharya</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) Evaluation of machine learning methods to predict peptide binding to MHC Class I proteins. <italic>bioRxiv</italic>, 154757.</mixed-citation>
    </ref>
    <ref id="btz330-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Carter</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>). What made you do this? understanding black-box decisions with sufficient input subsets. In <italic>Proceedings of Machine Learning Research</italic>, pp. <fpage>567</fpage>–<lpage>576</lpage>.</mixed-citation>
    </ref>
    <ref id="btz330-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Castellino</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>1997</year>) 
<article-title>Antigen presentation by MHC class II molecules: invariant chain function, protein trafficking, and the molecular basis of diverse determinant capture</article-title>. <source>Hum. Immunol</source>., <volume>54</volume>, <fpage>159</fpage>–<lpage>169</lpage>.<pub-id pub-id-type="pmid">9297534</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Crooks</surname><given-names>G.E.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) 
<article-title>Weblogo: a sequence logo generator</article-title>. <source>Genome Res</source>., <volume>14</volume>, <fpage>1188</fpage>–<lpage>1190</lpage>.<pub-id pub-id-type="pmid">15173120</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Han</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Kim</surname><given-names>D.</given-names></name></person-group> (<year>2017</year>) 
<article-title>Deep convolutional neural networks for pan-specific peptide-MHC class I binding prediction</article-title>. <source>BMC Bioinformatics</source>, <volume>18</volume>, <fpage>585</fpage>.<pub-id pub-id-type="pmid">29281985</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hobohm</surname><given-names>U.</given-names></name></person-group><etal>et al</etal> (<year>1992</year>) 
<article-title>Selection of representative protein data sets</article-title>. <source>Protein Sci</source>., <volume>1</volume>, <fpage>409</fpage>–<lpage>417</lpage>.<pub-id pub-id-type="pmid">1304348</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Janeway</surname><given-names>C.A.</given-names><suffix>Jr.</suffix></name></person-group><etal>et al</etal> (<year>2001</year>). The major histocompatibility complex and its functions. In <italic>Immunobiology: The Immune System in Health and Disease</italic>, 5th edn. Garland Science.</mixed-citation>
    </ref>
    <ref id="btz330-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Jensen</surname><given-names>K.K.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>). Improved methods for predicting peptide binding affinity to MHC class II molecules. <italic>Immunology.</italic></mixed-citation>
    </ref>
    <ref id="btz330-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jin</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>E.</given-names></name></person-group> (<year>2003</year>). Polymorphism in clinical immunology-From HLA typing to immunogenetic profiling. <italic>J. Transl. Med</italic>, <volume>1</volume>, <fpage>8</fpage>.</mixed-citation>
    </ref>
    <ref id="btz330-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jurtz</surname><given-names>V.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>). 
<article-title>NetMHCpan-4.0: improved peptide––MHC class I interaction predictions integrating eluted ligand and peptide binding affinity data</article-title>. <source>J. Immunol</source>., ji1700893.</mixed-citation>
    </ref>
    <ref id="btz330-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Keşmir</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2002</year>) 
<article-title>Prediction of proteasome cleavage motifs by neural networks</article-title>. <source>Protein Eng</source>., <volume>15</volume>, <fpage>287</fpage>–<lpage>296</lpage>.<pub-id pub-id-type="pmid">11983929</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Kendall</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Gal</surname><given-names>Y.</given-names></name></person-group> (<year>2017</year>) What uncertainties do we need in Bayesian deep learning for computer vision? In: <person-group person-group-type="editor"><name name-style="western"><surname>Guyon</surname><given-names>I.</given-names></name></person-group><etal>et al</etal>, (eds) <italic>Advances in Neural Information Processing Systems</italic> Curran Associates, Inc., pp. <fpage>5574</fpage>–<lpage>5584</lpage>.</mixed-citation>
    </ref>
    <ref id="btz330-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kim</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Dataset size and composition impact the reliability of performance benchmarks for peptide-MHC binding predictions</article-title>. <source>BMC Bioinformatics</source>, <volume>15</volume>, <fpage>241.</fpage><pub-id pub-id-type="pmid">25017736</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Kingma</surname><given-names>D.P.</given-names></name>, <name name-style="western"><surname>Ba</surname><given-names>J.</given-names></name></person-group> (<year>2014</year>). Adam: A method for stochastic optimization. <italic>arXiv preprint arXiv: 1412.6980.</italic></mixed-citation>
    </ref>
    <ref id="btz330-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Klont</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Assessment of sample preparation bias in mass spectrometry-based proteomics</article-title>. <source>Anal. Chem</source>., <volume>90</volume>, <fpage>5405</fpage>–<lpage>5413</lpage>.<pub-id pub-id-type="pmid">29608294</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kreiter</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Mutant MHC class II epitopes drive therapeutic immune responses to cancer</article-title>. <source>Nature</source>, <volume>520</volume>, <fpage>692</fpage>–<lpage>696</lpage>.<pub-id pub-id-type="pmid">25901682</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B18">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Lakshminarayanan</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) Simple and scalable predictive uncertainty estimation using deep ensembles. In: <person-group person-group-type="editor"><name name-style="western"><surname>Guyon</surname><given-names>I.</given-names></name></person-group><etal>et al</etal> (eds) <italic>Advances in Neural Information Processing Systems</italic>
<publisher-name>Curran Associates, Inc</publisher-name>, pp. <fpage>6402</fpage>–<lpage>6413</lpage>.</mixed-citation>
    </ref>
    <ref id="btz330-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Łuksza</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>A neoantigen fitness model predicts tumour response to checkpoint blockade immunotherapy</article-title>. <source>Nature</source>, <volume>551</volume>, <fpage>517.</fpage><pub-id pub-id-type="pmid">29132144</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lundegaard</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>NetMHC-3.0: accurate web accessible predictions of human, mouse and monkey MHC class I affinities for peptides of length 8––11</article-title>. <source>Nucleic Acids Res</source>., <volume>36</volume>, <fpage>W509</fpage>–<lpage>W512</lpage>.<pub-id pub-id-type="pmid">18463140</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mahoney</surname><given-names>D.W.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Relative quantification: characterization of bias, variability and fold changes in mass spectrometry data from iTRAQ-labeled peptides</article-title>. <source>J. Proteome Res</source>., <volume>10</volume>, <fpage>4325</fpage>–<lpage>4333</lpage>.<pub-id pub-id-type="pmid">21755926</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nielsen</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Andreatta</surname><given-names>M.</given-names></name></person-group> (<year>2016</year>) 
<article-title>NetMHCpan-3.0; improved prediction of binding to MHC class I molecules integrating information from multiple receptor and peptide length datasets</article-title>. <source>Genome Med</source>., <volume>8</volume>, <fpage>33</fpage>.<pub-id pub-id-type="pmid">27029192</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nielsen</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2003</year>) 
<article-title>Reliable prediction of T-cell epitopes using neural networks with novel sequence representations</article-title>. <source>Protein Sci</source>., <volume>12</volume>, <fpage>1007</fpage>–<lpage>1017</lpage>.<pub-id pub-id-type="pmid">12717023</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nielsen</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2005</year>) 
<article-title>The role of the proteasome in generating cytotoxic T-cell epitopes: insights obtained from improved predictions of proteasomal cleavage</article-title>. <source>Immunogenetics</source>, <volume>57</volume>, <fpage>33</fpage>–<lpage>41</lpage>.<pub-id pub-id-type="pmid">15744535</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nielsen</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>NetMHCpan, a method for quantitative predictions of peptide binding to any HLA-A and -B locus protein of known sequence</article-title>. <source>PLoS One</source>, <volume>2</volume>, <fpage>e796.</fpage><pub-id pub-id-type="pmid">17726526</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>O’Donnell</surname><given-names>T.J.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>MHCflurry: open-source class I MHC binding affinity prediction</article-title>. <source>Cell Syst</source>., <volume>7</volume>, <fpage>129</fpage>–<lpage>132</lpage>.<pub-id pub-id-type="pmid">29960884</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ott</surname><given-names>P.A.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>An immunogenic personal neoantigen vaccine for patients with melanoma</article-title>. <source>Nature</source>, <volume>547</volume>, <fpage>217</fpage>–<lpage>221</lpage>.<pub-id pub-id-type="pmid">28678778</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pedregosa</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Scikit-learn: machine learning in python</article-title>. <source>J. Mach. Learn. Res</source>., <volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="btz330-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Peters</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2003</year>) 
<article-title>Identifying MHC class I epitopes by predicting the TAP transport efficiency of epitope precursors</article-title>. <source>J. Immunol</source>., <volume>171</volume>, <fpage>1741</fpage>–<lpage>1749</lpage>.<pub-id pub-id-type="pmid">12902473</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B30">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Peters</surname><given-names>M.E.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) Deep contextualized word representations. In: <italic>Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies</italic>, Volume 1 (Long Papers), pp. 2227–2237. Association for Computational Linguistics, New Orleans, Louisiana.</mixed-citation>
    </ref>
    <ref id="btz330-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Verdegaal</surname><given-names>E.M.E.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Neoantigen landscape dynamics during human melanoma––T cell interactions</article-title>. <source>Nature</source>, <volume>536</volume>, <fpage>91</fpage>–<lpage>95</lpage>.<pub-id pub-id-type="pmid">27350335</pub-id></mixed-citation>
    </ref>
    <ref id="btz330-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Williams</surname><given-names>T.M.</given-names></name></person-group> (<year>2001</year>) 
<article-title>Human leukocyte antigen gene polymorphism and the histocompatibility laboratory</article-title>. <source>J. Mol. Diagn</source>., <volume>3</volume>, <fpage>98</fpage>–<lpage>104</lpage>.<pub-id pub-id-type="pmid">11486048</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
