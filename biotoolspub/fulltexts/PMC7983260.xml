<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7983260</article-id>
    <article-id pub-id-type="publisher-id">4073</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-021-04073-z</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A representation learning model based on variational inference and graph autoencoder for predicting lncRNA-disease associations</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Shi</surname>
          <given-names>Zhuangwei</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Zhang</surname>
          <given-names>Han</given-names>
        </name>
        <address>
          <email>zhanghan@nankai.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jin</surname>
          <given-names>Chen</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Quan</surname>
          <given-names>Xiongwen</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yin</surname>
          <given-names>Yanbin</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.216938.7</institution-id><institution-id institution-id-type="ISNI">0000 0000 9878 7032</institution-id><institution>College of Artificial Intelligence, </institution><institution>Nankai University, </institution></institution-wrap>Tongyan Road, 300350 Tianjin, China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.216938.7</institution-id><institution-id institution-id-type="ISNI">0000 0000 9878 7032</institution-id><institution>College of Computer Science, </institution><institution>Nankai University, </institution></institution-wrap>Tongyan Road, 300350 Tianjin, China </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.24434.35</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 0060</institution-id><institution>Department of Food Science and Technology, Nebraska Food for Health Center, </institution><institution>University of Nebraska-Lincoln, </institution></institution-wrap>1400 R Street, Lincoln, NE 68588 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>21</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>21</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>22</volume>
    <elocation-id>136</elocation-id>
    <history>
      <date date-type="received">
        <day>28</day>
        <month>1</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>11</day>
        <month>3</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Numerous studies have demonstrated that long non-coding RNAs are related to plenty of human diseases. Therefore, it is crucial to predict potential lncRNA-disease associations for disease prognosis, diagnosis and therapy. Dozens of machine learning and deep learning algorithms have been adopted to this problem, yet it is still challenging to learn efficient low-dimensional representations from high-dimensional features of lncRNAs and diseases to predict unknown lncRNA-disease associations accurately.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">We proposed an end-to-end model, VGAELDA, which integrates variational inference and graph autoencoders for lncRNA-disease associations prediction. VGAELDA contains two kinds of graph autoencoders. Variational graph autoencoders (VGAE) infer representations from features of lncRNAs and diseases respectively, while graph autoencoders propagate labels via known lncRNA-disease associations. These two kinds of autoencoders are trained alternately by adopting variational expectation maximization algorithm. The integration of both the VGAE for graph representation learning, and the alternate training via variational inference, strengthens the capability of VGAELDA to capture efficient low-dimensional representations from high-dimensional features, and hence promotes the robustness and preciseness for predicting unknown lncRNA-disease associations. Further analysis illuminates that the designed co-training framework of lncRNA and disease for VGAELDA solves a geometric matrix completion problem for capturing efficient low-dimensional representations via a deep learning approach.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p id="Par3">Cross validations and numerical experiments illustrate that VGAELDA outperforms the current state-of-the-art methods in lncRNA-disease association prediction. Case studies indicate that VGAELDA is capable of detecting potential lncRNA-disease associations. The source code and data are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/zhanglabNKU/VGAELDA">https://github.com/zhanglabNKU/VGAELDA</ext-link>.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12859-021-04073-z.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Variational inference</kwd>
      <kwd>Graph autoencoder</kwd>
      <kwd>lncRNA-disease association</kwd>
      <kwd>Representation learning</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>61973174</award-id>
        <principal-award-recipient>
          <name>
            <surname>Zhang</surname>
            <given-names>Han</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2021</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par25">LncRNAs are RNAs longer than 200 nucleotides thus losing the function of encoding, while they can still influence a series of biological processes, such as gene transcription, cell apoptosis, hormonal regulation, and immune response. Hence, lncRNAs are closely linked to plenty of human diseases [<xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR3">3</xref>]. For instance, lncRNA PANDAR is a novel biomarker of breast cancer, which upregulates proliferation of breast cancer cells [<xref ref-type="bibr" rid="CR4">4</xref>]. Sun et al. [<xref ref-type="bibr" rid="CR5">5</xref>] found that the downregulation of lncRNA MEG3 promotes proliferation of gastric cancer cells. Faghihi et al. [<xref ref-type="bibr" rid="CR6">6</xref>] reported that lncRNA BACE1-AS can regulate mRNA BACE1, while BACE1 is associated with the generation of beta-amyloid, which can cause Alzheimer’s disease. Therefore, it is essential to predict potential lncRNA-disease associations for disease prevention, detection, diagnosis and treatment. However, there are only a small number of lncRNA-disease associations that have been discovered so far, and it would be ideal to predict more potential lncRNA-disease associations using computational approaches. Generally, computational methods, especially machine learning algorithms, are more time-efficient and cost-effective to detect potential lncRNA-disease associations compared with experimental methods.</p>
    <p id="Par26">Previous machine learning approaches for predicting lncRNA-disease associations can be categorized into three types. The first type of methods is based on matrix analysis. Two commonly used matrix analysis methods for predicting lncRNA-disease associations are manifold regularization [<xref ref-type="bibr" rid="CR7">7</xref>] and matrix completion [<xref ref-type="bibr" rid="CR8">8</xref>], which suggest that lncRNA-disease association matrix follow manifold constraint or low-rank constraint, respectively. Manifold regularization based methods have been widely adopted for link prediction of biological entities [<xref ref-type="bibr" rid="CR9">9</xref>–<xref ref-type="bibr" rid="CR11">11</xref>]. Laplacian regularized least square (LRLS) method [<xref ref-type="bibr" rid="CR7">7</xref>] integrates manifold regularization and basic least square method. Chen and Yan [<xref ref-type="bibr" rid="CR12">12</xref>] proposed LRLSLDA that applied LRLS to the lncRNA-disease associations prediction, after the construction of an lncRNA graph and a disease graph through computing feature similarity respectively. Based on LRLSLDA, several methods were proposed to improve the performance of LRLS by integrating different types of feature similarities [<xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR14">14</xref>]. In addition, lncRNA-disease associations can be viewed as links on an lncRNA-disease bipartite graph. Matrix completion algorithm [<xref ref-type="bibr" rid="CR8">8</xref>] can solve link prediction problem by applying low-rank constraint to association matrix, and have been commonly applied to forecast associations among biological entities [<xref ref-type="bibr" rid="CR15">15</xref>–<xref ref-type="bibr" rid="CR17">17</xref>]. Lu et al. [<xref ref-type="bibr" rid="CR18">18</xref>] proposed a matrix completion based method for predicting lncRNA-disease associations. Geometric matrix completion [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR20">20</xref>] incorporates manifold regularization into the matrix completion problem, and Lu et al. [<xref ref-type="bibr" rid="CR21">21</xref>] proposed a geometric matrix completion based framework for predicting lncRNA-disease associations.</p>
    <p id="Par27">The second type of methods focuses on the integration of heterogeneous features. Applying multi-source features to learn better representations is an efficient technique for predicting associations among biological entities [<xref ref-type="bibr" rid="CR22">22</xref>, <xref ref-type="bibr" rid="CR23">23</xref>]. Lan et al. [<xref ref-type="bibr" rid="CR24">24</xref>] developed a web server for lncRNA-disease association prediction by integrating multiple features of lncRNAs and diseases to construct lncRNA similarity network and disease similarity network. Fu et al. [<xref ref-type="bibr" rid="CR25">25</xref>] integrated heterogeneous data for lncRNA-disease associations prediction by matrix factorization with low-rank constraint. Ding et al. [<xref ref-type="bibr" rid="CR26">26</xref>] inferred links on lncRNA-disease bipartite graph via lncRNA-disease-gene tripartite graph. Yao et al. [<xref ref-type="bibr" rid="CR27">27</xref>] adopted random forest for feature selection in lncRNA-disease associations prediction.</p>
    <p id="Par28">The third type is deep learning approaches. Neural networks are competent to capture efficient low-dimensional representations from high-dimensional features of biological entities, and deep learning based methods were proposed for detecting potentional associations among biological entities [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR22">22</xref>, <xref ref-type="bibr" rid="CR28">28</xref>]. Thus, several deep learning models applying autoencoders for representation learning of lncRNA features and disease features were proposed [<xref ref-type="bibr" rid="CR29">29</xref>, <xref ref-type="bibr" rid="CR30">30</xref>]. Graph neural networks (GNN) [<xref ref-type="bibr" rid="CR31">31</xref>] were proposed in deep learning on graphs. Hence, there are some recent approaches for lncRNA-disease associations prediction based on GNN. Xuan et al. [<xref ref-type="bibr" rid="CR32">32</xref>] integrated graph convolutional networks (GCN) [<xref ref-type="bibr" rid="CR33">33</xref>] and CNN to learn representations from features of lncRNAs and diseases. GCN is applicable for link prediction on bipartite graph [<xref ref-type="bibr" rid="CR34">34</xref>], and Wu et al. [<xref ref-type="bibr" rid="CR35">35</xref>] adopted graph autoencoder to predict lncRNA-disease associations on lncRNA-disease bipartite graph.</p>
    <p id="Par29">In this paper, we proposed a method, VGAELDA, that integrates variational inference and graph autoencoders to improve the performance of lncRNA-disease associations prediction. In previous works, feature inference and label propagation are two separated stages in these methods, and hence label propagation procedure may fail to make the full use of low-dimensional representations learned from high-dimensional features. Using deep learning approaches, our method proposed an end-to-end framework, which fuses feature inference and label propagation under the variational inference algorithm of Graph Markov Neural Networks (GMNN) [<xref ref-type="bibr" rid="CR36">36</xref>]. Specifically, the feature inference network in VGAELDA is designed as a variational graph autoencoder (VGAE) [<xref ref-type="bibr" rid="CR37">37</xref>] that learns representations from feature matrices of lncRNAs and diseases respectively. Furthermore, the label propagation network in our model is a graph autoencoder (GAE) [<xref ref-type="bibr" rid="CR37">37</xref>] that estimates the score of unknown lncRNA-disease pairs from known ones. These two graph autoencoders learn from feature and propagate label alternately, which are trained by variational EM algorithm, and are implemented as a representation learning framework. This framework minimizes the difference of the representations learned by two autoencoders respectively. Therefore, VGAELDA has the following advantages. (i) VGAE is preferable to infer low-dimensional representations from high-dimensional features in a graph, and these representations can better depict similarities and dependencies among nodes. This would significantly enhance the robustness and preciseness of prediction without handcrafted feature similarities. (ii) VGAELDA implements the variational EM algorithm as a representation learning framework, by training the feature inference autoencoder and the label propagation autoencoder alternately. (iii) VGAELDA provides a useful solution to the geometric matrix completion problem via deep learning, because autoencoders tend to minimize the rank of outputs, and we suggest that manifold regularization can be obtained via the alternate training of two graph autoencoders. (iv) VGAELDA implements an efficient way to integrate information from lncRNA space and disease space. Experiments illustrate that VGAELDA is superior to the current state-of-the-art methods, and case studies on several diseases illustrate the capability of VGAELDA to detect new lncRNA-disease associations.</p>
  </sec>
  <sec id="Sec2">
    <title>Results</title>
    <sec id="Sec3">
      <title>Datasets</title>
      <p id="Par30">In this paper, we adopted two datasets for evaluation. Dataset1 is an lncRNA-disease association dataset from [<xref ref-type="bibr" rid="CR26">26</xref>], including 540 associations among 115 lncRNAs and 178 diseases. Dataset2 is an lncRNA-disease association dataset from [<xref ref-type="bibr" rid="CR25">25</xref>], including 2697 associations among 240 lncRNAs and 412 diseases. Both of them were collected from LncRNADisease [<xref ref-type="bibr" rid="CR38">38</xref>] Database.</p>
      <p id="Par31">For each lncRNA, we adopted Word2Vec to compute the feature vector. Word2Vec [<xref ref-type="bibr" rid="CR39">39</xref>] is an efficient method to learn the embedding vectors of natural language, and BioVec [<xref ref-type="bibr" rid="CR40">40</xref>] (<ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/biovec/">https://pypi.org/project/biovec/</ext-link>) applied Word2Vec for representation learning of biological sequences, including protein sequences or nucleotide sequences. In VGAELDA, the length of each vector was set at 300. We downloaded lncRNA sequences from the Nucleotide Database of NCBI.</p>
      <p id="Par32">For each disease, we adopted its associations with 1415 genes as the feature vector on Dataset1. Dataset2 includes disease associated with 15527 genes. After removing genes that are not associated with any diseases, 10146 genes remain and are used as the feature vector on Dataset2. Information with respect to diseases was collected from DisGeNet [<xref ref-type="bibr" rid="CR41">41</xref>] and Disease Ontology [<xref ref-type="bibr" rid="CR42">42</xref>].</p>
    </sec>
    <sec id="Sec4">
      <title>Comparison with other methods</title>
      <p id="Par33">
        <fig id="Fig1">
          <label>Fig. 1</label>
          <caption>
            <p>ROC and PR curves of different methods on Dataset1. In AUROC, VGAELDA (AUROC = 0.9680) outperforms GAMCLDA (0.9299), SKFLDA (0.9154), TPGLDA (0.7936), SIMCLDA (0.8293) and LRLSLDA (0.8157). In AUPR, VGAELDA (AUPR = 0.8380) outperforms GAMCLDA (0.5794), SKFLDA (0.4024), TPGLDA (0.5308), SIMCLDA (0.5357) and LRLSLDA (0.2035)</p>
          </caption>
          <graphic xlink:href="12859_2021_4073_Fig1_HTML" id="MO1"/>
        </fig>
        <fig id="Fig2">
          <label>Fig. 2</label>
          <caption>
            <p>ROC and PR curves of different methods on Dataset2. In AUROC, VGAELDA (AUROC = 0.9692) outperforms GAMCLDA (0.8841), SKFLDA (0.8524), TPGLDA (0.8771), SIMCLDA (0.8146) and LRLSLDA (0.8627). In AUPR, VGAELDA (AUPR = 0.8203) outperforms GAMCLDA (0.3798), SKFLDA (0.2831), TPGLDA (0.3192), SIMCLDA (0.1189) and LRLSLDA (0.1812)</p>
          </caption>
          <graphic xlink:href="12859_2021_4073_Fig2_HTML" id="MO2"/>
        </fig>
      </p>
      <sec id="Sec5">
        <title>Cross validation</title>
        <p id="Par34">We compared our proposed method, VGAELDA, with other five state-of-the-art methods:<list list-type="bullet"><list-item><p id="Par35">LRLSLDA: Chen and Yan [<xref ref-type="bibr" rid="CR12">12</xref>] proposed a Laplacian regularized least square (LRLS) method [<xref ref-type="bibr" rid="CR7">7</xref>] based framework to predict lncRNA-disease associations.</p></list-item><list-item><p id="Par36">SIMCLDA: Lu et al. [<xref ref-type="bibr" rid="CR18">18</xref>] proposed a computational method for predicting lncRNA-disease associations based on speedup inductive matrix completion (SIMC) [<xref ref-type="bibr" rid="CR43">43</xref>].</p></list-item><list-item><p id="Par37">TPGLDA: Ding et al. [<xref ref-type="bibr" rid="CR26">26</xref>] integrated heterogeneous features by constructing lncRNA-disease-gene tripartite graph for lncRNA-disease associations prediction.</p></list-item><list-item><p id="Par38">SKFLDA: Xie et al. [<xref ref-type="bibr" rid="CR14">14</xref>] proposed SKFLDA that applied kernel fusion trick for different types of similarities to improve the preciseness of lncRNA-disease associations prediction.</p></list-item><list-item><p id="Par39">GAMCLDA: Wu et al. [<xref ref-type="bibr" rid="CR35">35</xref>] implemented GAMCLDA, adopting graph autoencoders to predict lncRNA-disease associations on lncRNA-disease bipartite graph.</p></list-item></list>We adopted 5-fold cross validation to obtain the result, and the metrics were listed below.<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Sensitivity= &amp; {} \frac{TP}{TP+FN}=TPR=Recall, \end{aligned}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Specificity= &amp; {} \frac{TN}{TN+FP}=1-FPR, \end{aligned}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Accuracy= &amp; {} \frac{TN+TP}{TN+TP+FN+FP}, \end{aligned}$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Precision= &amp; {} \frac{TP}{TP+FP}, \end{aligned}$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} F1= &amp; {} \frac{2\times Precision\times Recall}{Precision + Recall}, \end{aligned}$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Mcc= &amp; {} \frac{TP \times TN-FP \times FN}{\sqrt{(TP+FN) \times (TP+FP) \times (TN+FN) \times (TN+FP)}}, \end{aligned}$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>M</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:msqrt><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where TP denotes true positive, FN denotes false negative, TN denotes true negative, FP denotes false negative, TPR denotes true positive rate, FPR denotes false positive rate, and Mcc denotes Matthews correlation coefficient. The receiver operating characteristic (ROC) curve can be plotted by TPR and FPR, while the area under ROC curve (AUROC) and the area under precision-recall curve (AUPR) are important metrics to measure the performance of a binary classification model.</p>
        <p id="Par40">We plotted the ROC curves and PR curves of Dataset1 and Dataset2 on Figs. <xref rid="Fig1" ref-type="fig">1</xref> and <xref rid="Fig2" ref-type="fig">2</xref>, respectively. We ran our experiments for 5 times, and the mean values and standard deviations of AUROC and AUPR are listed on Table <xref rid="Tab1" ref-type="table">1</xref>. The AUROC and AUPR values of VGAELDA in 5 times are listed in Additional file <xref rid="MOESM1" ref-type="media">1</xref>.</p>
        <p id="Par41">The results show that VGAELDA outperforms the other five state-of-the-art methods in both AUROC and AUPR, on both datasets. Specifically, for the AUPR values obtained by other five state-of-the-art methods, GAMCLDA performs best in 5-fold CV on both Dataset1 and Dataset2, which gives AUPR values at 0.5794 and 0.3798 respectively. Compared with these AUPR values, VGAELDA significantly outperforms these previous methods by increasing the AUPR values 45% in 5-fold CV on Dataset1, and 116% in 5-fold CV on Dataset2.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Mean values and standard deviations of AUROC and AUPR on Dataset1 and Dataset2, compared with different methods</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Method</th><th align="left" colspan="2">Dataset1</th><th align="left" colspan="2">Dataset2</th></tr><tr><th align="left">AUROC</th><th align="left">AUPR</th><th align="left">AUROC</th><th align="left">AUPR</th></tr></thead><tbody><tr><td align="left">LRLSLDA</td><td align="left">0.8157 ± 0.0005</td><td align="left">0.2035 ± 0.0001</td><td align="left">0.8627 ± 0.0017</td><td align="left">0.1812 ± 0.0021</td></tr><tr><td align="left">SIMCLDA</td><td align="left">0.8293 ± 0.0023</td><td align="left">0.5357 ± 0.0011</td><td align="left">0.8146 ± 0.0042</td><td align="left">0.1189 ± 0.0076</td></tr><tr><td align="left">TPGLDA</td><td align="left">0.7936 ± 0.0054</td><td align="left">0.5308 ± 0.0028</td><td align="left">0.8771 ± 0.0053</td><td align="left">0.3192 ± 0.0058</td></tr><tr><td align="left">SKFLDA</td><td align="left">0.9154 ± 0.0013</td><td align="left">0.4024 ± 0.0017</td><td align="left">0.8524 ± 0.0066</td><td align="left">0.2831 ± 0.0085</td></tr><tr><td align="left">GAMCLDA</td><td align="left">0.9299 ± 0.0033</td><td align="left">0.5794 ± 0.0143</td><td align="left">0.8841 ± 0.0110</td><td align="left">0.3798 ± 0.0154</td></tr><tr><td align="left">VGAELDA</td><td align="left"><bold>0.9680</bold> ± 0.0042</td><td align="left"><bold>0.8380</bold> ± 0.0041</td><td align="left"><bold>0.9692</bold> ± 0.0080</td><td align="left"><bold>0.8203</bold> ± 0.0139</td></tr></tbody></table><table-wrap-foot><p>The bold number is the highest value of each column, which is achieved by our method, VGAELDA. The bold clarifies the superiority of our method</p></table-wrap-foot></table-wrap></p>
      </sec>
      <sec id="Sec6">
        <title>Evaluation on imbalanced data</title>
        <p id="Par42">As the datasets are imbalanced, i.e., the number of negative samples is far more than positive samples, it is essential to evaluate the capability to retrieve true positive samples from predicted positive ones. In our experiments, the evaluation was implemented through the following two ways. In summary, VGAELDA performs the best in both evaluation ways.</p>
        <p id="Par43">Firstly, we evaluated the performance of our model at high stringency level of specificity according to Eq. (<xref rid="Equ2" ref-type="">2</xref><xref rid="Equ3" ref-type="">3</xref><xref rid="Equ4" ref-type="">4</xref><xref rid="Equ5" ref-type="">5</xref><xref rid="Equ6" ref-type="">6</xref>). We fixed specificity at 0.95 and 0.99, and then computed sensitivity, accuracy, precision, F1-score and Mcc. The results of Dataset1 and Dataset2 are listed on Additional file <xref rid="MOESM2" ref-type="media">2</xref> and Table <xref rid="Tab2" ref-type="table">2</xref>, respectively, which illustrate that VGAELDA outperforms other five methods at all five metrics, and in both datasets. Matthews correlation coefficient (Mcc) is a comprehensive metric in binary classification on imbalanced data [<xref ref-type="bibr" rid="CR44">44</xref>]. For the Mcc values obtained by the other five state-of-the-art methods, SKFLDA performs the best at <inline-formula id="IEq1"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sp=0.95$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq1.gif"/></alternatives></inline-formula> on Dataset1, which obtains 0.4637, GAMCLDA performs the best at <inline-formula id="IEq2"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sp=0.99$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.99</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq2.gif"/></alternatives></inline-formula> on Dataset1 and both <inline-formula id="IEq3"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sp=0.95$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq3.gif"/></alternatives></inline-formula> and 0.99 on Dataset2, which obtains 0.5804, 0.3855 and 0.4860 respectively. VGAELDA outperforms these methods by improving the Mcc values 13% and 28% at <inline-formula id="IEq4"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sp=0.95$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq4.gif"/></alternatives></inline-formula> and 0.99 on Dataset1, and 42% and 49% at <inline-formula id="IEq5"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sp=0.95$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq5.gif"/></alternatives></inline-formula> and 0.99 on Dataset2.</p>
        <p id="Par44">Secondly, we evaluated recall score (i.e. sensitivity) via counting the number of true positive samples at different top-<italic>k</italic> cutoffs, according to Eq. (<xref rid="Equ1" ref-type="">1</xref>), where <inline-formula id="IEq6"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k\in \{20,40,60,80,100\}$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mn>20</mml:mn><mml:mo>,</mml:mo><mml:mn>40</mml:mn><mml:mo>,</mml:mo><mml:mn>60</mml:mn><mml:mo>,</mml:mo><mml:mn>80</mml:mn><mml:mo>,</mml:mo><mml:mn>100</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq6.gif"/></alternatives></inline-formula>. The bar charts depicting the number of true positive samples at different top-<italic>k</italic> cutoffs on Dataset1 and Dataset2 are shown on Additional file <xref rid="MOESM3" ref-type="media">3</xref> and Fig. <xref rid="Fig3" ref-type="fig">3</xref>, respectively. VGAELDA retrieves the most true positive samples at all 5 cutoffs on both Dataset1 and Dataset2.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Binary classification metrics of different methods on Dataset2</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Sp</th><th align="left">Method</th><th align="left">Sn</th><th align="left">Acc</th><th align="left">Pre</th><th align="left">F1</th><th align="left">Mcc</th></tr></thead><tbody><tr><td align="left" rowspan="6">0.95</td><td align="left">LRLSLDA</td><td align="left">0.4572</td><td align="left">0.9369</td><td align="left">0.2051</td><td align="left">0.2831</td><td align="left">0.2777</td></tr><tr><td align="left">SIMCLDA</td><td align="left">0.2128</td><td align="left">0.9299</td><td align="left">0.1066</td><td align="left">0.1421</td><td align="left">0.1169</td></tr><tr><td align="left">TPGLDA</td><td align="left">0.5565</td><td align="left">0.9394</td><td align="left">0.2384</td><td align="left">0.3338</td><td align="left">0.3380</td></tr><tr><td align="left">SKFLDA</td><td align="left">0.5284</td><td align="left">0.9385</td><td align="left">0.2286</td><td align="left">0.3191</td><td align="left">0.3206</td></tr><tr><td align="left">GAMCLDA</td><td align="left">0.6377</td><td align="left">0.9415</td><td align="left">0.2635</td><td align="left">0.3729</td><td align="left">0.3855</td></tr><tr><td align="left">VGAELDA</td><td align="left"><bold>0.9329</bold></td><td align="left"><bold>0.9495</bold></td><td align="left"><bold>0.3434</bold></td><td align="left"><bold>0.5020</bold></td><td align="left"><bold>0.5490</bold></td></tr><tr><td align="left" rowspan="6">0.99</td><td align="left">LRLSLDA</td><td align="left">0.1591</td><td align="left">0.9676</td><td align="left">0.3145</td><td align="left">0.2113</td><td align="left">0.2086</td></tr><tr><td align="left">SIMCLDA</td><td align="left">0.1020</td><td align="left">0.9658</td><td align="left">0.2223</td><td align="left">0.1398</td><td align="left">0.1348</td></tr><tr><td align="left">TPGLDA</td><td align="left">0.2673</td><td align="left">0.9703</td><td align="left">0.4279</td><td align="left">0.3291</td><td align="left">0.3238</td></tr><tr><td align="left">SKFLDA</td><td align="left">0.2354</td><td align="left">0.9694</td><td align="left">0.3976</td><td align="left">0.2958</td><td align="left">0.2913</td></tr><tr><td align="left">GAMCLDA</td><td align="left">0.4472</td><td align="left">0.9752</td><td align="left">0.5558</td><td align="left">0.4956</td><td align="left">0.4860</td></tr><tr><td align="left">VGAELDA</td><td align="left"><bold>0.7831</bold></td><td align="left"><bold>0.9843</bold></td><td align="left"><bold>0.6868</bold></td><td align="left"><bold>0.7318</bold></td><td align="left"><bold>0.7254</bold></td></tr></tbody></table><table-wrap-foot><p>The bold number is the highest value of each column, which is achieved by our method, VGAELDA. The bold clarifies the superiority of our method</p><p><italic>Sp</italic> specificity, <italic>Sn</italic> sensitivity, <italic>Acc</italic> accuracy, <italic>Pre</italic> precision, <italic>F1</italic> F1-score, <italic>Mcc</italic> Matthews correlation coefficient</p></table-wrap-foot></table-wrap></p>
        <p id="Par45">
          <fig id="Fig3">
            <label>Fig. 3</label>
            <caption>
              <p>True positive samples at different cutoffs on Dataset2</p>
            </caption>
            <graphic xlink:href="12859_2021_4073_Fig3_HTML" id="MO9"/>
          </fig>
        </p>
      </sec>
    </sec>
    <sec id="Sec7">
      <title>Case studies</title>
      <p id="Par46">To further evaluate the capability for detecting unknown lncRNA-disease associations of VGAELDA, case studies were adopted. We predicted the unknown disease-related lncRNAs of some specific diseases on the datasets, which can be validated by PubMed literature. The unknown disease-related lncRNAs of a disease are ranked by VGAELDA-predicted score. In this paper, we adopted case studies on lncRNAs associated with breast cancer and colon cancer.</p>
      <p id="Par47">On Dataset 1, the top 10 VGAELDA-predicted lncRNAs associated with breast cancer and colon cancer were listed in Tables <xref rid="Tab3" ref-type="table">3</xref> and <xref rid="Tab4" ref-type="table">4</xref>, respectively. PMID denotes the PubMed ID of the supporting literature for the corresponding disease-related lncRNAs detected by VGAELDA. Table <xref rid="Tab3" ref-type="table">3</xref> indicates that all the top 10 VGAELDA-predicted lncRNAs associated with breast cancer have been confirmed by previous literature. Table <xref rid="Tab4" ref-type="table">4</xref> indicates that 8 of the top 10 VGAELDA-predicted lncRNAs associated with colon cancer have been confirmed as well.</p>
      <p id="Par48">On Dataset 2, the top 10 VGAELDA-predicted lncRNAs associated with breast cancer and colon cancer were listed in Additional files <xref rid="MOESM4" ref-type="media">4</xref> and <xref rid="MOESM5" ref-type="media">5</xref>. Additional file <xref rid="MOESM4" ref-type="media">4</xref> demonstrates that 8 of the top 10 VGAELDA-predicted lncRNAs associated with breast cancer have been confirmed by previous literature. Additional file <xref rid="MOESM5" ref-type="media">5</xref>demonstrates that 9 of the top 10 VGAELDA-predicted lncRNAs associated with colon cancer have been confirmed.</p>
      <p id="Par49">Breast cancer is the most commonly diagnosed cancer and the main threat of health among females worldwide [<xref ref-type="bibr" rid="CR45">45</xref>]. VGAELDA has been applied to predict potential lncRNAs related to breast cancer. For instance, DNM3OS downregulates Vitamin D receptor (VDR), and VDR is capable of upregulating Suppressor of fused gene (SuFu), while SuFu is an inhibitor of progression of breast cancer [<xref ref-type="bibr" rid="CR46">46</xref>]. CCAT1 promotes proliferation and migration of triple-negative breast cancer cells via downregulating miRNA miR-218 and activating the expression of protein ZFX [<xref ref-type="bibr" rid="CR47">47</xref>]. BANCR is significantly correlated to the growth of breast cancer cells [<xref ref-type="bibr" rid="CR48">48</xref>].</p>
      <p id="Par50">Colon cancer is a major malignant cancer in digestive system [<xref ref-type="bibr" rid="CR45">45</xref>]. Among the top 10 lncRNAs predicted by VGAELDA, UCA1 facilitates the progression of colon cancer through upregulating miRNA miR-28-5p and HOXB3 [<xref ref-type="bibr" rid="CR49">49</xref>]. It is found that GAS5 is positively correlated to colon cancer as well [<xref ref-type="bibr" rid="CR50">50</xref>]. Also, previous research suggests that PVT1 can sponge miRNA miR-26b and promote proliferation and metastasis of colon cancer [<xref ref-type="bibr" rid="CR51">51</xref>].</p>
      <p id="Par51">Besides, we listed the predictions of potential lncRNA-disease associations with respect to all diseases of Dataset1 and Dataset2 in Additional files <xref rid="MOESM6" ref-type="media">6</xref> and <xref rid="MOESM7" ref-type="media">7</xref>, respectively.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Top 10 predicted lncRNAs associated with breast cancer on Dataset1</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Rank</th><th align="left">lncRNA name</th><th align="left">PMID</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">DNM3OS</td><td align="left">27693451</td></tr><tr><td align="left">2</td><td align="left">CCAT1</td><td align="left">31310241</td></tr><tr><td align="left">3</td><td align="left">BANCR</td><td align="left">29565494</td></tr><tr><td align="left">4</td><td align="left">PANDAR</td><td align="left">26927017</td></tr><tr><td align="left">5</td><td align="left">MNX1-AS1</td><td align="left">30697072</td></tr><tr><td align="left">6</td><td align="left">FOXCUT</td><td align="left">25516208</td></tr><tr><td align="left">7</td><td align="left">WRAP53</td><td align="left">26460974</td></tr><tr><td align="left">8</td><td align="left">TUG1</td><td align="left">30098551</td></tr><tr><td align="left">9</td><td align="left">MIR17HG</td><td align="left">25680407</td></tr><tr><td align="left">10</td><td align="left">IGF2-AS</td><td align="left">33175607</td></tr></tbody></table></table-wrap><table-wrap id="Tab4"><label>Table 4</label><caption><p>Top 10 predicted lncRNAs associated with colon cancer on Dataset1</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Rank</th><th align="left">lncRNA name</th><th align="left">PMID</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">UCA1</td><td align="left">30652355</td></tr><tr><td align="left">2</td><td align="left">GAS5</td><td align="left">27951730</td></tr><tr><td align="left">3</td><td align="left">PVT1</td><td align="left">30504754</td></tr><tr><td align="left">4</td><td align="left">SNHG16</td><td align="left">31502038</td></tr><tr><td align="left">5</td><td align="left">XIST</td><td align="left">29679755</td></tr><tr><td align="left">6</td><td align="left">DNM3OS</td><td align="left">Unconfirmed</td></tr><tr><td align="left">7</td><td align="left">TUG1</td><td align="left">27634385</td></tr><tr><td align="left">8</td><td align="left">IGF2-AS</td><td align="left">28534511</td></tr><tr><td align="left">9</td><td align="left">HULC</td><td align="left">30551459</td></tr><tr><td align="left">10</td><td align="left">SPRY4-IT1</td><td align="left">Unconfirmed</td></tr></tbody></table></table-wrap></p>
    </sec>
  </sec>
  <sec id="Sec8">
    <title>Discussion</title>
    <p id="Par52">Previous methods for predicting lncRNA-disease associations modeled dependent relationship from features based on some handcrafted measurements of similarity, then propagated labels of samples on the graph constructed via feature similarities. However, it is difficult for those measurements to capture similarities among high-dimensional features directly. Hence, the hyperparameters in these measurements would significantly affect the performance of prediction, which decreases the preciseness of label propagation.</p>
    <p id="Par53">To address this issue, VGAELDA designed representation learning framework that fuses the feature inference network and the label propagation network, to solve graph semi-supervised learning Problem <xref ref-type="sec" rid="FPar1">1</xref> (see Methods). Our Assumption <xref ref-type="sec" rid="FPar2">1</xref> (see Methods) clarifies the capability of an autoencoder to obtain low-rank solution. Based on Assumption <xref ref-type="sec" rid="FPar2">1</xref>, an autoencoder with manifold loss as we defined in Definition <xref ref-type="sec" rid="FPar3">1</xref> (see Methods), is competent to obtain the optimal solution of geometric matrix completion problem. Considering the manifold constraint and low-rank constraint that the lncRNA-disease association matrix should satisfy, we adopted VGAE to implement feature inference network GNNq, and GAE to implement label propagation network GNNp. With the alternate training via variational EM algorithm, two GAEs with manifold loss to measure the smoothness of manifold, would significantly strengthen the robustness and preciseness of label propagation through the representations learned by VGAE. Hence the feature similarities, i.e. the topological relationship of the graph, only need to be estimated roughly. The experiments demonstrate that VGAELDA outperforms various kinds of matrix completion based or manifold regularization based methods.</p>
    <p id="Par54">Furthermore, VGAELDA provides an efficient way to integrate information from lncRNA space and disease space. By applying co-training loss as we defined in Definition <xref ref-type="sec" rid="FPar4">2</xref> (see Methods), information from lncRNA space and disease space are captured collaboratively. Finally, the association matrix <inline-formula id="IEq7"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_l$$\end{document}</tex-math><mml:math id="M26"><mml:msub><mml:mi>F</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq7.gif"/></alternatives></inline-formula> computed from lncRNA space and <inline-formula id="IEq8"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_d$$\end{document}</tex-math><mml:math id="M28"><mml:msub><mml:mi>F</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq8.gif"/></alternatives></inline-formula> computed from disease space, can be integrated simply, since Assumption <xref ref-type="sec" rid="FPar2">1</xref> suggest that both <inline-formula id="IEq9"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_l$$\end{document}</tex-math><mml:math id="M30"><mml:msub><mml:mi>F</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq9.gif"/></alternatives></inline-formula> and <inline-formula id="IEq10"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_d$$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mi>F</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq10.gif"/></alternatives></inline-formula> follow low-rank property.</p>
  </sec>
  <sec id="Sec9">
    <title>Conclusion</title>
    <p id="Par55">The prediction of potential lncRNA-disease associations is of great importance to disease prognosis, diagnosis and treatment. In this paper, we proposed a deep learning model, VGAELDA, which integrates variational inference and graph autoencoders to detect potential lncRNA-disease associations. VGAELDA designed a representation learning framework to fuse the feature inference network and the label propagation network. Specifically, VGAELDA adopts variational graph autoencoder GNNq for feature inference, and graph autoencoder GNNp for label propagation. These two graph autoencoders are trained alternately in end-to-end manner via variational EM algorithm. This has significantly improved the efficiency of feature representation learning and label propagation. Further discussion demonstrates the validity of VGAELDA to find an optimal solution to the geometric matrix completion problem, and to integrate information from both lncRNA space and disease space. Experiments illustrate that VGAELDA is superior to the current state-of-the-art prediction methods, and case studies indicate that VGAELDA is competent in detecting potential lncRNA-disease associations. The results of evaluation demonstrate that VGAELDA is competent to capture efficient low-dimensional representations from high-dimensional features of both lncRNAs and diseases, and predict unknown lncRNA-disease associations robustly and precisely.</p>
    <p id="Par56">Compared to previous lncRNA-disease associations prediction methods, VGAELDA adopts an end-to-end framework based on variational inference in graph neural networks. VGAELDA is a data-driven end-to-end deep learning approach with a high flexibility. Therefore, VGAELDA is competent to be a general model for graph semi-supervised learning and association prediction tasks for other biological entities.</p>
  </sec>
  <sec id="Sec10">
    <title>Methods</title>
    <sec id="Sec11">
      <title>Problem formulation</title>
      <p id="Par57">Suppose the number of lncRNAs and diseases are <italic>m</italic> and <italic>n</italic> respectively, and <inline-formula id="IEq11"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Y_{m\times n}$$\end{document}</tex-math><mml:math id="M34"><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq11.gif"/></alternatives></inline-formula> denotes the association matrix. <inline-formula id="IEq12"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Y_{ij}=1$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq12.gif"/></alternatives></inline-formula> if the association between lncRNA <italic>i</italic> and disease <italic>j</italic> is known, otherwise <inline-formula id="IEq13"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Y_{ij}=0$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq13.gif"/></alternatives></inline-formula>. An algorithm predicting lncRNA-disease associations requires <italic>Y</italic> and corresponding feature matrix <italic>X</italic> as input, then outputs a score for each pair of lncRNA and disease. <italic>F</italic> denotes the score matrix, <inline-formula id="IEq14"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_{ij}\in [0,1]$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq14.gif"/></alternatives></inline-formula>, i.e. the prediction result.</p>
      <p id="Par58">In the view of machine learning, an lncRNA-disease pair is labeled if it has been proved to be associated. Usually, there are only few samples labeled in an lncRNA-disease dataset, and the other tremendous amount of associations need to be detected. Therefore, the prediction for lncRNA-disease associations can be viewed as propagating labels to plenty of unlabeled pairs from few labeled ones, which is classified as semi-supervised learning.</p>
    </sec>
    <sec id="Sec12">
      <title>Variational inference for graph semi-supervised learning</title>
      <sec id="Sec13">
        <title>Graph semi-supervised learning</title>
        <p id="Par59">Semi-supervised learning is based on manifold assumption [<xref ref-type="bibr" rid="CR52">52</xref>]. Manifold assumption clarifies that samples are distributed on a manifold, samples with higher feature similarities are closer on the manifold, and tend to share the same labels. The manifold of data can be depicted by graph structure constructed through feature matrix, which leads to graph semi-supervised learning. This type of methods first computes adjacency matrix from features to construct a graph, then propagate labels from labeled samples to unlabeled ones on this graph iteratively [<xref ref-type="bibr" rid="CR53">53</xref>, <xref ref-type="bibr" rid="CR54">54</xref>].</p>
        <p id="Par60">Suppose <italic>L</italic> denotes normalized Laplacian matrix of the graph, minimizing <inline-formula id="IEq15"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm {trace}(F^TLF)$$\end{document}</tex-math><mml:math id="M42"><mml:mrow><mml:mi mathvariant="normal">trace</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>L</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq15.gif"/></alternatives></inline-formula> can obtain the label matrix <italic>F</italic> following manifold assumption [<xref ref-type="bibr" rid="CR52">52</xref>, <xref ref-type="bibr" rid="CR55">55</xref>]. Belkin et al. [<xref ref-type="bibr" rid="CR7">7</xref>] added this manifold constraint to least square problem, then derived Laplacian regularized least square (LRLS) method<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \min _F \,\, \Vert F-Y\Vert _F^2+\eta \mathrm {trace}(F^TLF), \end{aligned}$$\end{document}</tex-math><mml:math id="M44" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo movablelimits="true">min</mml:mo><mml:mi>F</mml:mi></mml:munder><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:msubsup><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mi>F</mml:mi><mml:mo>-</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:mi mathvariant="normal">trace</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>L</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq16"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Vert \cdot \Vert _F$$\end{document}</tex-math><mml:math id="M46"><mml:msub><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mi>F</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq16.gif"/></alternatives></inline-formula> denotes Frobenius norm of a matrix, and <inline-formula id="IEq17"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\eta$$\end{document}</tex-math><mml:math id="M48"><mml:mi>η</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq17.gif"/></alternatives></inline-formula> is a hyperparameter. Eq. (<xref rid="Equ7" ref-type="">7</xref>) is a trade-off between the accuracy based on labeled data, and the smoothness of the manifold. This is classified as manifold regularization [<xref ref-type="bibr" rid="CR7">7</xref>]. Label propagation follows the framework of manifold regularization as Eq. (<xref rid="Equ7" ref-type="">7</xref>) [<xref ref-type="bibr" rid="CR53">53</xref>, <xref ref-type="bibr" rid="CR54">54</xref>]. Xia et al. [<xref ref-type="bibr" rid="CR9">9</xref>] derived that association matrix <italic>F</italic> follows manifold assumption, and can be obtained via solving Eq. (<xref rid="Equ7" ref-type="">7</xref>).<fig id="Fig4"><label>Fig. 4</label><caption><p>Framework of VGAELDA. Step 1: lncRNA features <inline-formula id="IEq18"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_l$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mi>X</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq18.gif"/></alternatives></inline-formula> are embeddings of lncRNA sequences computed by Word2Vec, while disease features <inline-formula id="IEq19"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_d$$\end{document}</tex-math><mml:math id="M52"><mml:msub><mml:mi>X</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq19.gif"/></alternatives></inline-formula> are associations with genes. Step 2: constructing graph <inline-formula id="IEq20"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G_l$$\end{document}</tex-math><mml:math id="M54"><mml:msub><mml:mi>G</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq20.gif"/></alternatives></inline-formula> and <inline-formula id="IEq21"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G_d$$\end{document}</tex-math><mml:math id="M56"><mml:msub><mml:mi>G</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq21.gif"/></alternatives></inline-formula> through Eq. (<xref rid="Equ16" ref-type="">16</xref>) for lncRNAs and diseases, respectively. Step 3: GNNql and GNNpl are applied to <inline-formula id="IEq22"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G_l$$\end{document}</tex-math><mml:math id="M58"><mml:msub><mml:mi>G</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq22.gif"/></alternatives></inline-formula>, that they require <inline-formula id="IEq23"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_l$$\end{document}</tex-math><mml:math id="M60"><mml:msub><mml:mi>X</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq23.gif"/></alternatives></inline-formula> and <italic>Y</italic> as inputs, while GNNqd and GNNpd applied to <inline-formula id="IEq24"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G_d$$\end{document}</tex-math><mml:math id="M62"><mml:msub><mml:mi>G</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq24.gif"/></alternatives></inline-formula> require <inline-formula id="IEq25"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_d$$\end{document}</tex-math><mml:math id="M64"><mml:msub><mml:mi>X</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq25.gif"/></alternatives></inline-formula> and <inline-formula id="IEq26"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Y^T$$\end{document}</tex-math><mml:math id="M66"><mml:msup><mml:mi>Y</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq26.gif"/></alternatives></inline-formula> as inputs. Step 4: training GNNq and GNNp alternately via variational EM algorithm, while training GNNql and GNNqd collaboratively. Step 5: final result fusion by Eq. (<xref rid="Equ28" ref-type="">28</xref>)</p></caption><graphic xlink:href="12859_2021_4073_Fig4_HTML" id="MO11"/></fig></p>
      </sec>
      <sec id="Sec14">
        <title>Graph Markov neural networks</title>
        <p id="Par61">The motivation of VGAELDA is begun with graph semi-supervised learning from probabilistic perspective. Through this perspective, label propagation can be viewed as maximizing <inline-formula id="IEq27"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p(y_u|y_l,x_v)$$\end{document}</tex-math><mml:math id="M68"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq27.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="CR56">56</xref>], where <inline-formula id="IEq28"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_u$$\end{document}</tex-math><mml:math id="M70"><mml:msub><mml:mi>y</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq28.gif"/></alternatives></inline-formula> and <inline-formula id="IEq29"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_l$$\end{document}</tex-math><mml:math id="M72"><mml:msub><mml:mi>y</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq29.gif"/></alternatives></inline-formula> denote labels from unlabeled and labeled nodes respectively, and <inline-formula id="IEq30"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_v$$\end{document}</tex-math><mml:math id="M74"><mml:msub><mml:mi>x</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq30.gif"/></alternatives></inline-formula> denotes attributes of objects on the graph. As the number of <inline-formula id="IEq31"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_u$$\end{document}</tex-math><mml:math id="M76"><mml:msub><mml:mi>y</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq31.gif"/></alternatives></inline-formula> is often much larger than <inline-formula id="IEq32"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_l$$\end{document}</tex-math><mml:math id="M78"><mml:msub><mml:mi>y</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq32.gif"/></alternatives></inline-formula>, it is difficult to maximize <inline-formula id="IEq33"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p(y_u|y_l,x_v)$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq33.gif"/></alternatives></inline-formula>. Qu et al. [<xref ref-type="bibr" rid="CR36">36</xref>] proposed Graph Markov Neural Networks (GMNN), suggesting that variational inference for graph semi-supervised learning leads to Problem <xref ref-type="sec" rid="FPar1">1</xref>.</p>
        <sec id="FPar1">
          <title>Problem 1</title>
          <p id="Par62"><italic>Variational inference for graph semi-supervised learning adopts the variational distribution</italic><inline-formula id="IEq34"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$q(y_u|x_v)$$\end{document}</tex-math><mml:math id="M82"><mml:mrow><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq34.gif"/></alternatives></inline-formula><italic>to approximate</italic><inline-formula id="IEq35"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p(y_u|y_l,x_v)$$\end{document}</tex-math><mml:math id="M84"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq35.gif"/></alternatives></inline-formula>, <italic>which leads to optimize evidence lower bound</italic> (ELBO)<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathbb {E}}_{q(y_u|x_v)}[\log q(y_u|x_v)-\log p(y_l,y_u|x_v)]. \end{aligned}$$\end{document}</tex-math><mml:math id="M86" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>log</mml:mo><mml:mi>q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mo>log</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula></p>
          <p>Remark of Problem <xref ref-type="sec" rid="FPar1">1</xref> is in the Additional file <xref rid="MOESM8" ref-type="media">8</xref>. Since labeled and unlabeled samples are observations and latent variables in conditional random field (CRF), and according to Markov property in CRF, the label of an unlabeled node is only related to its neighborhood. Hence, label propagation procedure aggregates messages from neighborhood, which is intrinsically related to graph neural networks [<xref ref-type="bibr" rid="CR33">33</xref>].</p>
          <p>GMNN adopted two GNNs, GNNq and GNNp, to depict <inline-formula id="IEq36"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$q(y_u|x_v)$$\end{document}</tex-math><mml:math id="M88"><mml:mrow><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq36.gif"/></alternatives></inline-formula> and <inline-formula id="IEq37"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p(y_l,y_u|x_v)$$\end{document}</tex-math><mml:math id="M90"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq37.gif"/></alternatives></inline-formula> respectively, since GNNs are successfully adopted in graph semi-supervised learning [<xref ref-type="bibr" rid="CR33">33</xref>]. Problem <xref ref-type="sec" rid="FPar1">1</xref> can be solved by variational EM (expectation maximization) algorithm [<xref ref-type="bibr" rid="CR57">57</xref>] (see Additional file <xref rid="MOESM8" ref-type="media">8</xref>), GNNq and GNNp are trained by variational EM algorithm, which executes the following two steps alternately until convergence.<list list-type="bullet"><list-item><p id="Par65">E-step: fix GNNp, and train GNNq by attributes of objects, to obtain the pseudo-labels,</p></list-item><list-item><p id="Par66">M-step: fix GNNq, and input pseudo-labels into GNNp for training.</p></list-item></list></p>
        </sec>
      </sec>
    </sec>
    <sec id="Sec15">
      <title>Geometric matrix completion</title>
      <p id="Par67">Except for manifold assumption, the association matrix also follows the low-rank assumption that it lies in a smaller subspace, this leads to the matrix completion [<xref ref-type="bibr" rid="CR8">8</xref>] problem.<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \min _F\,\, \mathrm {rank}(F)\quad \mathrm {s.t.}\,\, {\mathcal {P}}_\Omega (F)={\mathcal {P}}_\Omega (Y), \end{aligned}$$\end{document}</tex-math><mml:math id="M92" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo movablelimits="true">min</mml:mo><mml:mi>F</mml:mi></mml:munder><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mi mathvariant="normal">rank</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mspace width="1em"/><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:msub><mml:mi mathvariant="script">P</mml:mi><mml:mi mathvariant="normal">Ω</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="script">P</mml:mi><mml:mi mathvariant="normal">Ω</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq38"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Omega$$\end{document}</tex-math><mml:math id="M94"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq38.gif"/></alternatives></inline-formula> is the set of all known lncRNA-disease associations. The projection operator <inline-formula id="IEq39"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal {P}}_\Omega (\cdot ):{\mathbb {R}}^{m\times n}\rightarrow {\mathbb {R}}^{m\times n}$$\end{document}</tex-math><mml:math id="M96"><mml:mrow><mml:msub><mml:mi mathvariant="script">P</mml:mi><mml:mi mathvariant="normal">Ω</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq39.gif"/></alternatives></inline-formula> of matrix <italic>M</italic> is defined as<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathcal {P}}_\Omega (M)_{ij}={\left\{ \begin{array}{ll} M_{ij} &amp;{} (i,j)\in \Omega \\ 0 &amp;{} \mathrm {otherwise} \end{array}\right. }. \end{aligned}$$\end{document}</tex-math><mml:math id="M98" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="script">P</mml:mi><mml:mi mathvariant="normal">Ω</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mi mathvariant="normal">otherwise</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>Eq. (<xref rid="Equ9" ref-type="">9</xref>) is an NP-hard and nonconvex problem, thus it is usually relaxed as the following convex surrogate<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \min _F\,\, \Vert F\Vert _*+\mu \Vert {\mathcal {P}}_\Omega (F-Y)\Vert _F^2. \end{aligned}$$\end{document}</tex-math><mml:math id="M100" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo movablelimits="true">min</mml:mo><mml:mi>F</mml:mi></mml:munder><mml:msub><mml:mrow><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mo stretchy="false">‖</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>μ</mml:mi><mml:msubsup><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mi mathvariant="script">P</mml:mi><mml:mi mathvariant="normal">Ω</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>F</mml:mi><mml:mo>-</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq40"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Vert \cdot \Vert _*$$\end{document}</tex-math><mml:math id="M102"><mml:msub><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq40.gif"/></alternatives></inline-formula> denotes nuclear norm, i.e. the sum of singular values of a matrix.</p>
      <p id="Par68">Geometric matrix completion [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR20">20</xref>] incorporates manifold constraint <inline-formula id="IEq41"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm {trace}(F^TLF)$$\end{document}</tex-math><mml:math id="M104"><mml:mrow><mml:mi mathvariant="normal">trace</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>L</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq41.gif"/></alternatives></inline-formula> into low-rank constraint, that is to solve<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \min _F\,\,\Vert F\Vert _*+\mu \Vert {\mathcal {P}}_\Omega (F-Y)\Vert _F^2+\eta \mathrm {trace}(F^TLF). \end{aligned}$$\end{document}</tex-math><mml:math id="M106" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo movablelimits="true">min</mml:mo><mml:mi>F</mml:mi></mml:munder><mml:msub><mml:mrow><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mo stretchy="false">‖</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>μ</mml:mi><mml:msubsup><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mi mathvariant="script">P</mml:mi><mml:mi mathvariant="normal">Ω</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>F</mml:mi><mml:mo>-</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:mi mathvariant="normal">trace</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>L</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec16">
      <title>VGAELDA</title>
      <sec id="Sec17">
        <title>Method overview</title>
        <p id="Par69">We proposed our model, VGAELDA, which designed representation learning framework to fuse the feature inference network and the label propagation network, and is trained through variational EM algorithm using GMNN [<xref ref-type="bibr" rid="CR36">36</xref>] that integrated variational inference and GNN. VGAELDA executes the following two steps alternately until convergence.<list list-type="bullet"><list-item><p id="Par70">E-step (feature inference): fix GNNp, and train GNNq by high-dimensional features, to obtain low-dimensional representations,</p></list-item><list-item><p id="Par71">M-step (label propagation): fix GNNq, and input lncRNA-disease association matrix into GNNp for training.</p></list-item></list>In VGAELDA, feature inference network GNNq is a variational graph autoencoder (VGAE) [<xref ref-type="bibr" rid="CR37">37</xref>], and label propagation network GNNp is a graph autoencoder (GAE) [<xref ref-type="bibr" rid="CR37">37</xref>]. Assumption <xref ref-type="sec" rid="FPar2">1</xref> and Definition <xref ref-type="sec" rid="FPar3">1</xref> suggest that the application of these two autoencoders solves the geometric matrix completion problem Eq. (<xref rid="Equ12" ref-type="">12</xref>), for capturing efficient low-dimensional representations via VGAELDA. Furthermore, VGAELDA adopts co-training [<xref ref-type="bibr" rid="CR58">58</xref>] that integrates information from lncRNA space and disease space. The framework of our model is shown on Fig. <xref rid="Fig4" ref-type="fig">4</xref>.</p>
      </sec>
      <sec id="Sec18">
        <title>Implementing graph autoencoders</title>
        <p id="Par72">Each layer of a graph autoencoder is graph convolutional layer. The formula of the <italic>l</italic>-th <inline-formula id="IEq42"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(l&gt;0)$$\end{document}</tex-math><mml:math id="M108"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq42.gif"/></alternatives></inline-formula> graph convolutional [<xref ref-type="bibr" rid="CR33">33</xref>] layer is<disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} H^{(l)}=\rho ({\tilde{D}}^{-1/2}{\tilde{A}} \tilde{D}^{-1/2}H^{(l-1)}\Theta ^{(l)}), \end{aligned}$$\end{document}</tex-math><mml:math id="M110" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:msup><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq43"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\tilde{A}}$$\end{document}</tex-math><mml:math id="M112"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq43.gif"/></alternatives></inline-formula> is adjacency matrix with self-loop, i.e. <inline-formula id="IEq44"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tilde{A}=A+I$$\end{document}</tex-math><mml:math id="M114"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq44.gif"/></alternatives></inline-formula>. <inline-formula id="IEq45"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\tilde{D}}$$\end{document}</tex-math><mml:math id="M116"><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq45.gif"/></alternatives></inline-formula> is a diagonal matrix called degree matrix, <inline-formula id="IEq46"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\tilde{D}}_{ii}=\sum _j{\tilde{A}}_{ij}$$\end{document}</tex-math><mml:math id="M118"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ii</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq46.gif"/></alternatives></inline-formula>, <inline-formula id="IEq47"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\rho (\cdot )$$\end{document}</tex-math><mml:math id="M120"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq47.gif"/></alternatives></inline-formula> denotes nonlinear activation function, <inline-formula id="IEq48"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Theta ^{(l)}$$\end{document}</tex-math><mml:math id="M122"><mml:msup><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq48.gif"/></alternatives></inline-formula> denotes weight of the <italic>l</italic>-th layer of network, and <inline-formula id="IEq49"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H^{(0)}$$\end{document}</tex-math><mml:math id="M124"><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq49.gif"/></alternatives></inline-formula> is the initial input feature matrix.</p>
        <sec id="FPar2">
          <title>Assumption 1</title>
          <p id="Par73">Autoencoder GNNp with <italic>Y</italic> as input and <italic>F</italic> as output can obtain the optimal solution of Eq. (<xref rid="Equ11" ref-type="">11</xref>).</p>
        </sec>
        <sec id="FPar3">
          <title>Definition 1</title>
          <p id="Par74">(manifold loss) Suppose <italic>Z</italic> and <inline-formula id="IEq50"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Z'$$\end{document}</tex-math><mml:math id="M126"><mml:msup><mml:mi>Z</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq50.gif"/></alternatives></inline-formula> are representations of autoencoder GNNq and GNNp, respectively, then, to optimize manifold constraint <inline-formula id="IEq51"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm {trace}(F^TLF)$$\end{document}</tex-math><mml:math id="M128"><mml:mrow><mml:mi mathvariant="normal">trace</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>L</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq51.gif"/></alternatives></inline-formula> can be viewed as optimizing the following manifold loss<disp-formula id="Equ14"><label>14</label><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_m=\frac{1}{2}\Vert Z-Z'\Vert _F^2. \end{aligned}$$\end{document}</tex-math><mml:math id="M130" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mi>Z</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mi>Z</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ14.gif" position="anchor"/></alternatives></disp-formula></p>
          <p>Remarks of Assumption <xref ref-type="sec" rid="FPar2">1</xref> and Definition <xref ref-type="sec" rid="FPar3">1</xref> are in Additional file <xref rid="MOESM8" ref-type="media">8</xref>. In the view of the alternating direction method of multipliers (ADMM) [<xref ref-type="bibr" rid="CR59">59</xref>], solving the geometric matrix completion problem Eq. (<xref rid="Equ12" ref-type="">12</xref>) can be viewed as optimizing Eq. (<xref rid="Equ7" ref-type="">7</xref>) and Eq. (<xref rid="Equ11" ref-type="">11</xref>) alternately. Therefore, autoencoder GNNp with the addition of manifold loss as we defined in Definition <xref ref-type="sec" rid="FPar3">1</xref>, obtains the solution of Eq. (<xref rid="Equ12" ref-type="">12</xref>).</p>
          <p>However, to enhance the efficiency of adding manifold loss Eq. (<xref rid="Equ14" ref-type="">14</xref>), we implemented a variational graph autoencoder as GNNq to capture representation <italic>Z</italic>. Suppose the feature matrix of the graph is <italic>X</italic>, the encoder learns mean <inline-formula id="IEq52"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu$$\end{document}</tex-math><mml:math id="M132"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq52.gif"/></alternatives></inline-formula> and standard deviation <inline-formula id="IEq53"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M134"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq53.gif"/></alternatives></inline-formula>. The representation <italic>Z</italic> can be computed by applying reparameterization trick [<xref ref-type="bibr" rid="CR60">60</xref>], which means<disp-formula id="Equ15"><label>15</label><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Z=\mu +\sigma \epsilon , \end{aligned}$$\end{document}</tex-math><mml:math id="M136" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:mi>μ</mml:mi><mml:mo>+</mml:mo><mml:mi>σ</mml:mi><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ15.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq54"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon$$\end{document}</tex-math><mml:math id="M138"><mml:mi>ϵ</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq54.gif"/></alternatives></inline-formula> is sampled from standard Gaussian distribution. Then, the decoder reconstructs a feature matrix <inline-formula id="IEq55"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X'$$\end{document}</tex-math><mml:math id="M140"><mml:msup><mml:mi>X</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq55.gif"/></alternatives></inline-formula>.</p>
          <p>The adjacency matrix of graph <italic>G</italic> can be constructed simply in this way. Firstly, sort the Euclidean distances among different feature vectors of nodes. Secondly, for each node <italic>i</italic>, select the 10-nearest nodes except itself. Thirdly, suppose the set of these nodes for node <italic>i</italic> is <inline-formula id="IEq56"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal {N}}(i)$$\end{document}</tex-math><mml:math id="M142"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq56.gif"/></alternatives></inline-formula>, matrix <italic>C</italic> satisfies that <inline-formula id="IEq57"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C_{ij}=1$$\end{document}</tex-math><mml:math id="M144"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq57.gif"/></alternatives></inline-formula> if <inline-formula id="IEq58"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j\in {\mathcal {N}}(i)$$\end{document}</tex-math><mml:math id="M146"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq58.gif"/></alternatives></inline-formula>, otherwise <inline-formula id="IEq59"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C_{ij}=0$$\end{document}</tex-math><mml:math id="M148"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq59.gif"/></alternatives></inline-formula>. The adjacency matrix with self-loop of the constructed graph <italic>G</italic> is<disp-formula id="Equ16"><label>16</label><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\tilde{A}}=C^T\odot C+I, \end{aligned}$$\end{document}</tex-math><mml:math id="M150" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mi>C</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⊙</mml:mo><mml:mi>C</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ16.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq60"><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\odot$$\end{document}</tex-math><mml:math id="M152"><mml:mo>⊙</mml:mo></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq60.gif"/></alternatives></inline-formula> denotes Hadamard product.</p>
          <p>Network structures of GNNq and GNNp are shown on Additional file <xref rid="MOESM9" ref-type="media">9</xref>. As shown on Additional file <xref rid="MOESM9" ref-type="media">9</xref>, GNNp is a basic GAE that takes initial label matrix <italic>Y</italic> as input, the dimension of hidden vector is 256, output of hidden layer is <inline-formula id="IEq61"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Z'$$\end{document}</tex-math><mml:math id="M154"><mml:msup><mml:mi>Z</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq61.gif"/></alternatives></inline-formula>, and output of decoder is prediction <italic>F</italic>. GNNq is a VGAE, that each layer of the variational autoencoder [<xref ref-type="bibr" rid="CR60">60</xref>] is a graph convolutional layer, the dimension of output vectors of each hidden layers in GNNq are 256.</p>
        </sec>
      </sec>
      <sec id="Sec19">
        <title>Variational EM algorithm</title>
        <p id="Par79">The variational EM algorithm is implemented through minimizing the losses of GNNq and GNNp alternately. Similar to other variational graph autoencoders, the loss function of GNNq is the sum of reconstruction error <inline-formula id="IEq62"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{qr}$$\end{document}</tex-math><mml:math id="M156"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">qr</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq62.gif"/></alternatives></inline-formula>, and KL divergence <inline-formula id="IEq63"><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{KL}$$\end{document}</tex-math><mml:math id="M158"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">KL</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq63.gif"/></alternatives></inline-formula>.<disp-formula id="Equ17"><label>17</label><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_q=L_{qr}+L_{KL}. \end{aligned}$$\end{document}</tex-math><mml:math id="M160" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">qr</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">KL</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ17.gif" position="anchor"/></alternatives></disp-formula>Kingma and Welling [<xref ref-type="bibr" rid="CR60">60</xref>] derived that in a variational autoencoder:<list list-type="bullet"><list-item><p id="Par80">If the features follow Gaussian distribution, the reconstruction error is mean square error. <disp-formula id="Equ18"><label>18</label><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_{qr}=\frac{1}{2}\Vert X-X'\Vert _F^2, \end{aligned}$$\end{document}</tex-math><mml:math id="M162" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">qr</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mi>X</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ18.gif" position="anchor"/></alternatives></disp-formula></p></list-item><list-item><p id="Par81">If the features follow Bernoulli distribution, the reconstruction error is cross entropy loss. <disp-formula id="Equ19"><label>19</label><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_{qr}=-\sum _{i,j}X_{ij}\log X'_{ij}. \end{aligned}$$\end{document}</tex-math><mml:math id="M164" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">qr</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>log</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ19.gif" position="anchor"/></alternatives></disp-formula></p></list-item><list-item><p id="Par82">KL divergence loss can be computed through <disp-formula id="Equ20"><label>20</label><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_{KL}=-\sum _{i,j}\frac{1}{2}(1+2\log \sigma _{ij}-\mu _{ij}^2-\sigma _{ij}^2). \end{aligned}$$\end{document}</tex-math><mml:math id="M166" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">KL</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo>log</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ20.gif" position="anchor"/></alternatives></disp-formula></p></list-item></list>In VGAELDA, the features of lncRNAs are computed from sequences by Word2Vec [<xref ref-type="bibr" rid="CR39">39</xref>], and features of diseases are computed through associations with disease-related genes. Thus, lncRNA features follow Gaussian distribution, and disease features follow Bernoulli distribution. Therefore, <inline-formula id="IEq64"><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{qr}$$\end{document}</tex-math><mml:math id="M168"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">qr</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq64.gif"/></alternatives></inline-formula> in GNNql and GNNqd are computed by Eq. (<xref rid="Equ18" ref-type="">18</xref>) and Eq. (<xref rid="Equ19" ref-type="">19</xref>), respectively.</p>
        <p id="Par83">The outputs of encoder and decoder are scaled into (0,1) through applying sigmoid activation function. Meanwhile, following Eq. (<xref rid="Equ7" ref-type="">7</xref>) , the loss function of GNNp is the sum of reconstruction error and manifold loss.<disp-formula id="Equ21"><label>21</label><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_p=L_{pr}+\gamma L_m. \end{aligned}$$\end{document}</tex-math><mml:math id="M170" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">pr</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ21.gif" position="anchor"/></alternatives></disp-formula>The reconstruction error of GNNp is the cross entropy between prediction and true label<disp-formula id="Equ22"><label>22</label><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_{pr}=-\sum _{i,j}Y_{ij}\log F_{ij}. \end{aligned}$$\end{document}</tex-math><mml:math id="M172" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">pr</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>log</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ22.gif" position="anchor"/></alternatives></disp-formula>Then, <italic>F</italic> is obtained after adopting variational EM algorithm to train GNNq and GNNp alternately until convergence, and is finally scaled into interval [0, 1] by<disp-formula id="Equ23"><label>23</label><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} F_{ij}\leftarrow \frac{F_{ij}-F_{min}}{F_{max}-F_{min}}, \end{aligned}$$\end{document}</tex-math><mml:math id="M174" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ23.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq65"><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_{min}$$\end{document}</tex-math><mml:math id="M176"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq65.gif"/></alternatives></inline-formula> and <inline-formula id="IEq66"><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_{max}$$\end{document}</tex-math><mml:math id="M178"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq66.gif"/></alternatives></inline-formula> denote minimum and maximum element in matrix <italic>F</italic>.</p>
      </sec>
      <sec id="Sec20">
        <title>Integrating information from lncRNA space and disease space</title>
        <p id="Par84">As shown on Fig. <xref rid="Fig4" ref-type="fig">4</xref>, the constructed lncRNA graph <inline-formula id="IEq67"><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G_l$$\end{document}</tex-math><mml:math id="M180"><mml:msub><mml:mi>G</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq67.gif"/></alternatives></inline-formula> and disease graph <inline-formula id="IEq68"><alternatives><tex-math id="M181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G_d$$\end{document}</tex-math><mml:math id="M182"><mml:msub><mml:mi>G</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq68.gif"/></alternatives></inline-formula> are different. Eq. (<xref rid="Equ17" ref-type="">17</xref>) and Eq. (<xref rid="Equ21" ref-type="">21</xref>) can compute loss from <inline-formula id="IEq69"><alternatives><tex-math id="M183">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G_l$$\end{document}</tex-math><mml:math id="M184"><mml:msub><mml:mi>G</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq69.gif"/></alternatives></inline-formula> and <inline-formula id="IEq70"><alternatives><tex-math id="M185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G_d$$\end{document}</tex-math><mml:math id="M186"><mml:msub><mml:mi>G</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq70.gif"/></alternatives></inline-formula> respectively, but it is important to integrate the information capturing from lncRNA space and disease space. Therefore, we adopt co-training [<xref ref-type="bibr" rid="CR58">58</xref>] to train GNNql and GNNqd collaboratively.</p>
        <sec id="FPar4">
          <title>Definition 2</title>
          <p id="Par85">(co-training loss) Suppose <inline-formula id="IEq71"><alternatives><tex-math id="M187">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Z_l$$\end{document}</tex-math><mml:math id="M188"><mml:msub><mml:mi>Z</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq71.gif"/></alternatives></inline-formula> and <inline-formula id="IEq72"><alternatives><tex-math id="M189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Z_d$$\end{document}</tex-math><mml:math id="M190"><mml:msub><mml:mi>Z</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq72.gif"/></alternatives></inline-formula> are representations learned from lncRNA space and disease space, respectively, then co-training loss<disp-formula id="Equ24"><label>24</label><alternatives><tex-math id="M191">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_c=\frac{1}{2}\Vert Z_lZ_d^T-Y\Vert _F^2. \end{aligned}$$\end{document}</tex-math><mml:math id="M192" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msubsup><mml:mi>Z</mml:mi><mml:mi>d</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ24.gif" position="anchor"/></alternatives></disp-formula>can measure the performance of co-training.</p>
          <p>Remark of Definition <xref ref-type="sec" rid="FPar4">2</xref> is in Additional file <xref rid="MOESM8" ref-type="media">8</xref>. Then GNNql and GNNqd are trained simultaneously by optimizing the total loss of GNNq<disp-formula id="Equ25"><label>25</label><alternatives><tex-math id="M193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathcal {L}}_q=\alpha L_{ql}+(1-\alpha )L_{qd}+\beta L_c, \end{aligned}$$\end{document}</tex-math><mml:math id="M194" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">ql</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">qd</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ25.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq73"><alternatives><tex-math id="M195">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{ql}$$\end{document}</tex-math><mml:math id="M196"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">ql</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq73.gif"/></alternatives></inline-formula> and <inline-formula id="IEq74"><alternatives><tex-math id="M197">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{qd}$$\end{document}</tex-math><mml:math id="M198"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">qd</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq74.gif"/></alternatives></inline-formula> denote losses of GNNql and GNNqd computed through Eq. (<xref rid="Equ17" ref-type="">17</xref>) respectively, and <inline-formula id="IEq75"><alternatives><tex-math id="M199">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha \in (0,1)$$\end{document}</tex-math><mml:math id="M200"><mml:mrow><mml:mi>α</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq75.gif"/></alternatives></inline-formula> is the weight parameter that balances information capturing from lncRNA space and disease space. Similarly, the total loss of GNNp is<disp-formula id="Equ26"><label>26</label><alternatives><tex-math id="M201">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathcal {L}}_p=\alpha L_{pl}+(1-\alpha )L_{pd}, \end{aligned}$$\end{document}</tex-math><mml:math id="M202" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">pl</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">pd</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ26.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq76"><alternatives><tex-math id="M203">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{pl}$$\end{document}</tex-math><mml:math id="M204"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">pl</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq76.gif"/></alternatives></inline-formula> and <inline-formula id="IEq77"><alternatives><tex-math id="M205">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{pd}$$\end{document}</tex-math><mml:math id="M206"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">pd</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq77.gif"/></alternatives></inline-formula> denote losses of GNNpl and GNNpd computed through Eq. (<xref rid="Equ21" ref-type="">21</xref>) respectively. Then, the variational EM algorithm is implemented through optimizing <inline-formula id="IEq78"><alternatives><tex-math id="M207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal {L}}_q$$\end{document}</tex-math><mml:math id="M208"><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq78.gif"/></alternatives></inline-formula> and <inline-formula id="IEq79"><alternatives><tex-math id="M209">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal {L}}_p$$\end{document}</tex-math><mml:math id="M210"><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq79.gif"/></alternatives></inline-formula> alternately. After training procedure, GNNpl outputs <inline-formula id="IEq80"><alternatives><tex-math id="M211">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_l$$\end{document}</tex-math><mml:math id="M212"><mml:msub><mml:mi>F</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq80.gif"/></alternatives></inline-formula> while GNNpd outputs <inline-formula id="IEq81"><alternatives><tex-math id="M213">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_d$$\end{document}</tex-math><mml:math id="M214"><mml:msub><mml:mi>F</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq81.gif"/></alternatives></inline-formula>. Since both <inline-formula id="IEq82"><alternatives><tex-math id="M215">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_l\in {\mathbb {R}}^{m\times n}$$\end{document}</tex-math><mml:math id="M216"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq82.gif"/></alternatives></inline-formula> and <inline-formula id="IEq83"><alternatives><tex-math id="M217">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_d\in {\mathbb {R}}^{n\times m}$$\end{document}</tex-math><mml:math id="M218"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq83.gif"/></alternatives></inline-formula> are low-rank provided by autoencoders, and through the rank-sum inequality that<disp-formula id="Equ27"><label>27</label><alternatives><tex-math id="M219">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \mathrm {rank}(aF_l+ bF_d^T) \le \mathrm {rank}(F_l) + \mathrm {rank}(F_d^T),\forall a,b, \end{aligned}$$\end{document}</tex-math><mml:math id="M220" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="normal">rank</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:msubsup><mml:mi>F</mml:mi><mml:mi>d</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mi mathvariant="normal">rank</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">rank</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mi>d</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>∀</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ27.gif" position="anchor"/></alternatives></disp-formula>the final result<disp-formula id="Equ28"><label>28</label><alternatives><tex-math id="M221">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} F=\alpha F_l+(1-\alpha )F_d^T. \end{aligned}$$\end{document}</tex-math><mml:math id="M222" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mi>d</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2021_4073_Article_Equ28.gif" position="anchor"/></alternatives></disp-formula>is low-rank.</p>
          <p>The procedure of VGAELDA is summarized in Algorithm 1, where <inline-formula id="IEq84"><alternatives><tex-math id="M223">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X',Z\leftarrow \mathrm {GNN}(G,X)$$\end{document}</tex-math><mml:math id="M224"><mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>Z</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mi mathvariant="normal">GNN</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq84.gif"/></alternatives></inline-formula> summarizes the computing procedure of a GAE.</p>
          <graphic position="anchor" xlink:href="12859_2021_4073_Figa_HTML" id="MO33"/>
        </sec>
      </sec>
    </sec>
    <sec id="Sec21">
      <title>Hyperparameters tuning</title>
      <p id="Par88">In VGAELDA, there are three hyperparameters, <inline-formula id="IEq85"><alternatives><tex-math id="M225">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha ,\beta$$\end{document}</tex-math><mml:math id="M226"><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq85.gif"/></alternatives></inline-formula> and <inline-formula id="IEq86"><alternatives><tex-math id="M227">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma$$\end{document}</tex-math><mml:math id="M228"><mml:mi>γ</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq86.gif"/></alternatives></inline-formula>, that need to be tuned. Hyperparameter <inline-formula id="IEq87"><alternatives><tex-math id="M229">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math><mml:math id="M230"><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq87.gif"/></alternatives></inline-formula> depicts a balance between lncRNA space and disease space. However, after evaluating our model at each <inline-formula id="IEq88"><alternatives><tex-math id="M231">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha \in \{0.1,0.3,0.5,0.7,0.9\}$$\end{document}</tex-math><mml:math id="M232"><mml:mrow><mml:mi>α</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.3</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>0.7</mml:mn><mml:mo>,</mml:mo><mml:mn>0.9</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq88.gif"/></alternatives></inline-formula>, we found that VGAELDA is robust to the choice of <inline-formula id="IEq89"><alternatives><tex-math id="M233">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math><mml:math id="M234"><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq89.gif"/></alternatives></inline-formula>, and the results are shown on Additional file <xref rid="MOESM10" ref-type="media">10</xref>. Hence we simply set <inline-formula id="IEq90"><alternatives><tex-math id="M235">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha =0.5$$\end{document}</tex-math><mml:math id="M236"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq90.gif"/></alternatives></inline-formula>.</p>
      <p id="Par89">Since manifold loss <inline-formula id="IEq91"><alternatives><tex-math id="M237">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_m$$\end{document}</tex-math><mml:math id="M238"><mml:msub><mml:mi>L</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq91.gif"/></alternatives></inline-formula> and co-training loss <inline-formula id="IEq92"><alternatives><tex-math id="M239">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_c$$\end{document}</tex-math><mml:math id="M240"><mml:msub><mml:mi>L</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq92.gif"/></alternatives></inline-formula> depend on the computation of representations of GNNql and GNNqd, the capabilities of manifold constraint and co-training constraint are related to the effectiveness of representation capturing by GNNq. Hence, we need to set hyperparameter <inline-formula id="IEq93"><alternatives><tex-math id="M241">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\beta$$\end{document}</tex-math><mml:math id="M242"><mml:mi>β</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq93.gif"/></alternatives></inline-formula> in Eq. (<xref rid="Equ25" ref-type="">25</xref>) and <inline-formula id="IEq94"><alternatives><tex-math id="M243">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma$$\end{document}</tex-math><mml:math id="M244"><mml:mi>γ</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq94.gif"/></alternatives></inline-formula> in Eq. (<xref rid="Equ21" ref-type="">21</xref>), increasing as training goes, to enhance the robustness of representation learning, and the convergence of EM algorithm. So here we set <inline-formula id="IEq95"><alternatives><tex-math id="M245">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\beta =\gamma =e/e_n$$\end{document}</tex-math><mml:math id="M246"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq95.gif"/></alternatives></inline-formula> at <italic>e</italic>-th epoch, where <inline-formula id="IEq96"><alternatives><tex-math id="M247">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_n=500$$\end{document}</tex-math><mml:math id="M248"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq96.gif"/></alternatives></inline-formula> denotes the number of epochs.</p>
      <p id="Par90">We adopted PyTorch [<xref ref-type="bibr" rid="CR61">61</xref>] (<ext-link ext-link-type="uri" xlink:href="https://pytorch.org/">https://pytorch.org/</ext-link>) to construct VGAELDA, and applied Adam optimizer [<xref ref-type="bibr" rid="CR62">62</xref>], where learning rate is 0.01, weight decay is <inline-formula id="IEq97"><alternatives><tex-math id="M249">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$10^{-5}$$\end{document}</tex-math><mml:math id="M250"><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2021_4073_Article_IEq97.gif"/></alternatives></inline-formula>, and we set dropout=0.5 [<xref ref-type="bibr" rid="CR63">63</xref>]. Our model was trained on a single NVIDIA GeForce GTX 2070 GPU with 8GB memory. we evaluated the performance of VGAELDA through varying learning rate in {0.001,0.01,0.1,1}, and the results are shown on Additional file <xref rid="MOESM11" ref-type="media">11</xref>. The figure depicts that the best value of learning rate is 0.01.</p>
      <p id="Par91">Moreover, we evaluated our model at different dimension of hidden vectors, and the results are shown on Additional file <xref rid="MOESM12" ref-type="media">12</xref>. The figure depicts that the performance of our model is enhanced with the increase of hidden vector dimension. However, when the dimension is more than 256, there is little increment and the performance remains stable. Hence, we set the hidden vector dimension at 256 to save the time and space cost of our model.</p>
      <p id="Par92">Besides, we also evaluated our model at different dimension of lncRNA embedding vectors adopted by Word2Vec, and the results are shown on Additional file <xref rid="MOESM13" ref-type="media">13</xref>. The figure shows that a larger dimension of lncRNA embedding vectors tends to perform better. However, when the dimension is more than 150, there is little increment and the performance remains stable. Hence, we simply set the dimension of lncRNA embedding vectors at 300.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec22">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2021_4073_MOESM1_ESM.xlsx">
            <caption>
              <p><bold>Additional file 1.</bold> AUROC and AUPR values of VGAELDA in 5 times</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="12859_2021_4073_MOESM2_ESM.pdf">
            <caption>
              <p><bold>Additional file 2.</bold> Binary classification metrics of different methods on Dataset1</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="12859_2021_4073_MOESM3_ESM.pdf">
            <caption>
              <p><bold>Additional file 3.</bold> True positive samples at different cutoffs on Dataset1</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM4">
          <media xlink:href="12859_2021_4073_MOESM4_ESM.pdf">
            <caption>
              <p><bold>Additional file 4.</bold> Case study for breast cancer on Dataset2</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM5">
          <media xlink:href="12859_2021_4073_MOESM5_ESM.pdf">
            <caption>
              <p><bold>Additional file 5.</bold> Case study for colon cancer on Dataset2</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM6">
          <media xlink:href="12859_2021_4073_MOESM6_ESM.xlsx">
            <caption>
              <p><bold>Additional file 6.</bold> Predictions of potential lncRNA-disease association on Dataset1</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM7">
          <media xlink:href="12859_2021_4073_MOESM7_ESM.xlsx">
            <caption>
              <p><bold>Additional file 7.</bold> Predictions of potential lncRNA-disease association on Dataset2</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM8">
          <media xlink:href="12859_2021_4073_MOESM8_ESM.pdf">
            <caption>
              <p><bold>Additional file 8.</bold> Remarks</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM9">
          <media xlink:href="12859_2021_4073_MOESM9_ESM.pdf">
            <caption>
              <p><bold>Additional file 9.</bold> Network structures</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM10">
          <media xlink:href="12859_2021_4073_MOESM10_ESM.pdf">
            <caption>
              <p><bold>Additional file 10.</bold> AUPR at different <italic>α</italic></p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM11">
          <media xlink:href="12859_2021_4073_MOESM11_ESM.pdf">
            <caption>
              <p><bold>Additional file 11.</bold> AUPR at different learning rate</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM12">
          <media xlink:href="12859_2021_4073_MOESM12_ESM.pdf">
            <caption>
              <p><bold>Additional file 12.</bold> AUPR at different dimension of hidden vectors</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM13">
          <media xlink:href="12859_2021_4073_MOESM13_ESM.pdf">
            <caption>
              <p><bold>Additional file 13.</bold> AUPR at different dimension of embedding vectors of lncRNA</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>Acc</term>
        <def>
          <p id="Par4">Accuracy</p>
        </def>
      </def-item>
      <def-item>
        <term>AUPR</term>
        <def>
          <p id="Par5">Area under precision-recall curve</p>
        </def>
      </def-item>
      <def-item>
        <term>AUROC</term>
        <def>
          <p id="Par6">Area under ROC curve</p>
        </def>
      </def-item>
      <def-item>
        <term>EM</term>
        <def>
          <p id="Par7">Expectation maximization</p>
        </def>
      </def-item>
      <def-item>
        <term>FN</term>
        <def>
          <p id="Par8">False negative</p>
        </def>
      </def-item>
      <def-item>
        <term>FP</term>
        <def>
          <p id="Par9">False positive</p>
        </def>
      </def-item>
      <def-item>
        <term>GAE</term>
        <def>
          <p id="Par10">Graph autoencoder</p>
        </def>
      </def-item>
      <def-item>
        <term>GCN</term>
        <def>
          <p id="Par11">Graph convolutional networks</p>
        </def>
      </def-item>
      <def-item>
        <term>GNN</term>
        <def>
          <p id="Par12">Graph neural networks</p>
        </def>
      </def-item>
      <def-item>
        <term>Mcc</term>
        <def>
          <p id="Par13">Matthews correlation coefficient</p>
        </def>
      </def-item>
      <def-item>
        <term>LDA</term>
        <def>
          <p id="Par14">lncRNA-disease association</p>
        </def>
      </def-item>
      <def-item>
        <term>LncRNA</term>
        <def>
          <p id="Par15">Long non-encoding RNA</p>
        </def>
      </def-item>
      <def-item>
        <term>LOOCV</term>
        <def>
          <p id="Par16">Leave-one-out cross validation</p>
        </def>
      </def-item>
      <def-item>
        <term>LRLS</term>
        <def>
          <p id="Par17">Laplacian regularized least square method</p>
        </def>
      </def-item>
      <def-item>
        <term>Pre</term>
        <def>
          <p id="Par18">Precision</p>
        </def>
      </def-item>
      <def-item>
        <term>ROC curve</term>
        <def>
          <p id="Par19">Receiver operating characteristic (ROC) curve</p>
        </def>
      </def-item>
      <def-item>
        <term>Sn</term>
        <def>
          <p id="Par20">Sensitivity</p>
        </def>
      </def-item>
      <def-item>
        <term>Sp</term>
        <def>
          <p id="Par21">Speciality</p>
        </def>
      </def-item>
      <def-item>
        <term>TN</term>
        <def>
          <p id="Par22">True negative</p>
        </def>
      </def-item>
      <def-item>
        <term>TP</term>
        <def>
          <p id="Par23">True positive</p>
        </def>
      </def-item>
      <def-item>
        <term>VGAE</term>
        <def>
          <p id="Par24">Variational graph autoencoder</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors' contributions</title>
    <p>Han Zhang conceived the research. Zhuangwei Shi, Han Zhang, Chen Jin, Xiongwen Quan and Yanbin Yin designed the research. Zhuangwei Shi and Chen Jin implemented the research. Zhuangwei Shi, Han Zhang, Chen Jin and Yanbin Yin wrote the manuscript. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This research was funded by the National Natural Science Foundation of China Grant No. 61973174.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>All the data using in our paper are collected from the following public datasets. Dataset1 can be downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/USTC-HIlab/TPGLDA">https://github.com/USTC-HIlab/TPGLDA</ext-link>. Dataset2 can be downloaded from <ext-link ext-link-type="uri" xlink:href="http://mlda.swu.edu.cn/codes.php?name=MFLDA">http://mlda.swu.edu.cn/codes.php?name=MFLDA</ext-link>. Both of them were collected from LncRNADisease Database (<ext-link ext-link-type="uri" xlink:href="http://www.cuilab.cn/lncrnadisease">http://www.cuilab.cn/lncrnadisease</ext-link>). In VGAELDA, the information of lncRNA sequences was downloaded from the Nucleotide Database of NCBI (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/nuccore">https://www.ncbi.nlm.nih.gov/nuccore</ext-link>), and the information of diseases was downloaded from DisGeNet (<ext-link ext-link-type="uri" xlink:href="https://www.disgenet.org/home/">https://www.disgenet.org/home/</ext-link>) and Disease Ontology (<ext-link ext-link-type="uri" xlink:href="https://disease-ontology.org/">https://disease-ontology.org/</ext-link>). The source code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/zhanglabNKU/VGAELDA">https://github.com/zhanglabNKU/VGAELDA</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar6">
      <title>Ethics approval and consent to participate</title>
      <p id="Par93">Not applicable.</p>
    </notes>
    <notes id="FPar7">
      <title>Consent for publication</title>
      <p id="Par94">Not applicable.</p>
    </notes>
    <notes id="FPar8" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par95">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wapinski</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>HY</given-names>
          </name>
        </person-group>
        <article-title>Long noncoding RNAs and human disease</article-title>
        <source>Trends Cell Biol</source>
        <year>2011</year>
        <volume>21</volume>
        <issue>6</issue>
        <fpage>354</fpage>
        <lpage>361</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tcb.2011.04.001</pub-id>
        <?supplied-pmid 21550244?>
        <pub-id pub-id-type="pmid">21550244</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jalali</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kapoor</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sivadas</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bhartiya</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Scaria</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Computational approaches towards understanding human long non-coding RNA biology</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>31</volume>
        <issue>14</issue>
        <fpage>2241</fpage>
        <lpage>2251</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btv148</pub-id>
        <?supplied-pmid 25777523?>
        <pub-id pub-id-type="pmid">25777523</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>You</surname>
            <given-names>Z-H</given-names>
          </name>
        </person-group>
        <article-title>Long non-coding RNAs and complex diseases: from experimental results to computational models</article-title>
        <source>Brief Bioinform</source>
        <year>2016</year>
        <volume>18</volume>
        <issue>4</issue>
        <fpage>558</fpage>
        <lpage>576</lpage>
        <?supplied-pmid 5862301?>
        <pub-id pub-id-type="pmid">5862301</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>X-F</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Qian</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>L-M</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Lv</surname>
            <given-names>X-B</given-names>
          </name>
        </person-group>
        <article-title>LncRNA PANDAR regulates the g1/s transition of breast cancer cells by suppressing p16(INK4A) expression</article-title>
        <source>Sci Rep</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>22366</fpage>
        <pub-id pub-id-type="doi">10.1038/srep22366</pub-id>
        <?supplied-pmid 26927017?>
        <pub-id pub-id-type="pmid">26927017</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Xia</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>De</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Downregulated long noncoding RNA meg3 is associated with poor prognosis and promotes cell proliferation in gastric cancer</article-title>
        <source>Tumor Biol</source>
        <year>2014</year>
        <volume>35</volume>
        <fpage>1065</fpage>
        <lpage>1073</lpage>
        <pub-id pub-id-type="doi">10.1007/s13277-013-1142-z</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Faghihi</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Modarresi</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Khalil</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Wood</surname>
            <given-names>DE</given-names>
          </name>
          <name>
            <surname>Sahagan</surname>
            <given-names>BG</given-names>
          </name>
          <name>
            <surname>Morgan</surname>
            <given-names>TE</given-names>
          </name>
          <name>
            <surname>Finch</surname>
            <given-names>CE</given-names>
          </name>
          <name>
            <surname>St. Laurent III</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Kenny</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Wahlestedt</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Expression of a noncoding RNA is elevated in Alzheimer’s disease and drives rapid feed-forward regulation of beta-secretase</article-title>
        <source>Nat Med</source>
        <year>2008</year>
        <volume>14</volume>
        <issue>7</issue>
        <fpage>723</fpage>
        <lpage>730</lpage>
        <pub-id pub-id-type="doi">10.1038/nm1784</pub-id>
        <?supplied-pmid 18587408?>
        <pub-id pub-id-type="pmid">18587408</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Belkin</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Niyogi</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Sindhwani</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Manifold regularization: a geometric framework for learning from labeled and unlabeled examples</article-title>
        <source>J Mach Learn Res</source>
        <year>2006</year>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>2399</fpage>
        <lpage>2434</lpage>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Candès</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Recht</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Exact matrix completion via convex optimization</article-title>
        <source>Found Comput Math</source>
        <year>2009</year>
        <volume>9</volume>
        <issue>6</issue>
        <fpage>717</fpage>
        <pub-id pub-id-type="doi">10.1007/s10208-009-9045-5</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xia</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>LY</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wong</surname>
            <given-names>STC</given-names>
          </name>
        </person-group>
        <article-title>Semi-supervised drug-protein interaction prediction from heterogeneous biological spaces</article-title>
        <source>BMC Syst Biol</source>
        <year>2010</year>
        <volume>4</volume>
        <issue>Suppl 2</issue>
        <fpage>6</fpage>
        <pub-id pub-id-type="doi">10.1186/1752-0509-4-S2-S6</pub-id>
        <pub-id pub-id-type="pmid">20109182</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>You</surname>
            <given-names>Z-H</given-names>
          </name>
          <name>
            <surname>Lei</surname>
            <given-names>Y-K</given-names>
          </name>
          <name>
            <surname>Gui</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>D-S</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Using manifold embedding for assessing and predicting protein interactions from high-throughput experimental data</article-title>
        <source>Bioinformatics</source>
        <year>2010</year>
        <volume>26</volume>
        <issue>21</issue>
        <fpage>2744</fpage>
        <lpage>2751</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq510</pub-id>
        <?supplied-pmid 20817744?>
        <pub-id pub-id-type="pmid">20817744</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiao</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Cai</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>A graph regularized non-negative matrix factorization method for identifying microrna-disease associations</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>2</issue>
        <fpage>239</fpage>
        <lpage>248</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx545</pub-id>
        <?supplied-pmid 28968779?>
        <pub-id pub-id-type="pmid">28968779</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>G-Y</given-names>
          </name>
        </person-group>
        <article-title>Novel human lncRNA-disease association inference based on lncRNA expression profiles</article-title>
        <source>Bioinformatics</source>
        <year>2013</year>
        <volume>29</volume>
        <issue>20</issue>
        <fpage>2617</fpage>
        <lpage>2624</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btt426</pub-id>
        <?supplied-pmid 24002109?>
        <pub-id pub-id-type="pmid">24002109</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>Constructing lncRNA functional similarity network based on lncRNA-disease associations and disease semantic similarity</article-title>
        <source>Sci Rep</source>
        <year>2015</year>
        <volume>5</volume>
        <issue>1</issue>
        <fpage>11338</fpage>
        <pub-id pub-id-type="doi">10.1038/srep11338</pub-id>
        <?supplied-pmid 26061969?>
        <pub-id pub-id-type="pmid">26061969</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xie</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>SKF-LDA: similarity kernel fusion for predicting lncRNA-disease association</article-title>
        <source>Mol Ther Nucl Acids</source>
        <year>2019</year>
        <volume>18</volume>
        <issue>6</issue>
        <fpage>45</fpage>
        <lpage>55</lpage>
        <pub-id pub-id-type="doi">10.1016/j.omtn.2019.07.022</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Natarajan</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Dhillon</surname>
            <given-names>IS</given-names>
          </name>
        </person-group>
        <article-title>Inductive matrix completion for predicting gene-disease associations</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <issue>12</issue>
        <fpage>60</fpage>
        <lpage>68</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu269</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Qu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Guan</surname>
            <given-names>N-N</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J-Q</given-names>
          </name>
        </person-group>
        <article-title>Predicting miRNA-disease association based on inductive matrix completion</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>24</issue>
        <fpage>4256</fpage>
        <lpage>4265</lpage>
        <?supplied-pmid 29939227?>
        <pub-id pub-id-type="pmid">29939227</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ning</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Neural inductive matrix completion with graph convolutional networks for miRNA-disease association prediction</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>8</issue>
        <fpage>2538</fpage>
        <lpage>2546</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btz965</pub-id>
        <?supplied-pmid 31904845?>
        <pub-id pub-id-type="pmid">31904845</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>F-X</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Prediction of lncRNA-disease associations based on inductive matrix completion</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>19</issue>
        <fpage>3357</fpage>
        <lpage>3364</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty327</pub-id>
        <?supplied-pmid 29718113?>
        <pub-id pub-id-type="pmid">29718113</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Kalofolias V, Bresson X, Bronstein MM, Vandergheynst P. Matrix completion on graphs. arXiv preprint. 2014. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1408.1717">arXiv:1408.1717</ext-link></mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Monti</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Bronstein</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bresson</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Geometric matrix completion with recurrent multi-graph neural networks</article-title>
        <source>Adv Neural Inf Process Syst</source>
        <year>2017</year>
        <volume>30</volume>
        <fpage>3697</fpage>
        <lpage>3707</lpage>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Predicting human lncRNA-disease associations based on geometric matrix completion</article-title>
        <source>IEEE J Biomed Health</source>
        <year>2018</year>
        <volume>24</volume>
        <issue>8</issue>
        <fpage>2420</fpage>
        <lpage>2429</lpage>
        <pub-id pub-id-type="doi">10.1109/JBHI.2019.2958389</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>You</surname>
            <given-names>Z-H</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Y-A</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>D-S</given-names>
          </name>
          <name>
            <surname>Chan</surname>
            <given-names>KCC</given-names>
          </name>
        </person-group>
        <article-title>An efficient approach based on multi-sources information to predict circRNA-disease associations using deep convolutional neural network</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>36</volume>
        <issue>13</issue>
        <fpage>4038</fpage>
        <lpage>4046</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btz825</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Xiao Q, Zhang N, Luo J, Dai J, Tang X. Adaptive multi-source multi-view latent feature learning for inferring potential disease-associated miRNAs. Brief Bioinform. 2020.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lan</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>F-X</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>LDAP: a web server for lncRNA-disease association prediction</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>33</volume>
        <issue>3</issue>
        <fpage>458</fpage>
        <lpage>460</lpage>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Domeniconi</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Matrix factorization-based data fusion for the prediction of lncRNA-disease associations</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>34</volume>
        <issue>9</issue>
        <fpage>1529</fpage>
        <lpage>1537</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx794</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>TPGLDA: novel prediction of associations between lncRNAs and diseases via lncRNA-disease-gene tripartite graph</article-title>
        <source>Sci Rep</source>
        <year>2018</year>
        <volume>8</volume>
        <issue>1</issue>
        <fpage>1065</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-018-19357-3</pub-id>
        <?supplied-pmid 29348552?>
        <pub-id pub-id-type="pmid">29348552</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yao</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Zhan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Kwoh</surname>
            <given-names>CK</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>A random forest based computational model for predicting novel lncRNA-disease associations</article-title>
        <source>BMC Bioinform</source>
        <year>2020</year>
        <volume>21</volume>
        <fpage>126</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-020-3458-1</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Chen X, Li T-H, Zhao Y, Wang C-C, Zhu C-C. Deep-belief network for predicting potential miRNA-disease associations. Brief Bioinform. 2020.</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xuan</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Kong</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>Dual convolutional neural networks with attention mechanisms based method for predicting disease-related lncRNA genes</article-title>
        <source>Front Genet</source>
        <year>2019</year>
        <volume>10</volume>
        <fpage>416</fpage>
        <pub-id pub-id-type="doi">10.3389/fgene.2019.00416</pub-id>
        <?supplied-pmid 31130990?>
        <pub-id pub-id-type="pmid">31130990</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Sheng N, Cui H, Zhang T, Xuan P. Attentional multi-level representation encoding based on convolutional and variance autoencoders for lncRNA-disease association prediction. Brief Bioinform. 2020;1–14.</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scarselli</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Gori</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Tsoi</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Hagenbuchner</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Monfardini</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>The graph neural network model</article-title>
        <source>IEEE Trans Neural Netw</source>
        <year>2009</year>
        <volume>20</volume>
        <issue>1</issue>
        <fpage>61</fpage>
        <lpage>80</lpage>
        <pub-id pub-id-type="doi">10.1109/TNN.2008.2005605</pub-id>
        <?supplied-pmid 19068426?>
        <pub-id pub-id-type="pmid">19068426</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xuan</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Graph convolutional network and convolutional neural network based method for predicting lncRNA-disease associations</article-title>
        <source>Cells</source>
        <year>2019</year>
        <volume>8</volume>
        <issue>9</issue>
        <fpage>1012</fpage>
        <pub-id pub-id-type="doi">10.3390/cells8091012</pub-id>
        <?supplied-pmid 6769579?>
        <pub-id pub-id-type="pmid">6769579</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Kipf TN, Welling M. Semi-supervised classification with graph convolutional networks. In: Proceedings of the international conference on learning representations (ICLR);2017.</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <mixed-citation publication-type="other">Berg R, Kipf T, Welling M. Graph convolutional matrix completion. In: Proceedings of KDD;2018.</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Lan</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Dong</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Inferring lncRNA-disease associations based on graph autoencoder matrix completion</article-title>
        <source>Comput Biol Chem</source>
        <year>2020</year>
        <volume>87</volume>
        <fpage>107282</fpage>
        <pub-id pub-id-type="doi">10.1016/j.compbiolchem.2020.107282</pub-id>
        <?supplied-pmid 32502934?>
        <pub-id pub-id-type="pmid">32502934</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Qu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>GMNN: graph Markov neural networks</article-title>
        <source>Proc Mach Learn Res</source>
        <year>2019</year>
        <volume>97</volume>
        <fpage>5241</fpage>
        <lpage>5250</lpage>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Kipf TN, Welling M. Variational graph auto-encoders. In: NeurIPS Workshop on Bayesian Deep Learning;2016.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>LncRNADisease: a database for long-non-coding RNA-associated diseases</article-title>
        <source>Nucleic Acids Res</source>
        <year>2012</year>
        <volume>41</volume>
        <issue>D1</issue>
        <fpage>983</fpage>
        <lpage>986</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gks1099</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Le</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Mikolov</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Distributed representations of sentences and documents</article-title>
        <source>Proc Mach Learn Res</source>
        <year>2014</year>
        <volume>32</volume>
        <fpage>1188</fpage>
        <lpage>1196</lpage>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Asgari</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Mofrad</surname>
            <given-names>MRK</given-names>
          </name>
        </person-group>
        <article-title>Protvec: a continuous distributed representation of biological sequences</article-title>
        <source>PLoS ONE</source>
        <year>2015</year>
        <volume>10</volume>
        <issue>11</issue>
        <fpage>0141287</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0141287</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Piñero</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bravo</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Queralt-Rosinach</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Gutiérrez-Sacristán</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Deu-Pons</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Centeno</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>García-García</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sanz</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Furlong</surname>
            <given-names>LI</given-names>
          </name>
        </person-group>
        <article-title>DisGeNET: a comprehensive platform integrating information on human disease-associated genes and variants</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>45</volume>
        <issue>D1</issue>
        <fpage>833</fpage>
        <lpage>839</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw943</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schriml</surname>
            <given-names>LM</given-names>
          </name>
          <name>
            <surname>Mitraka</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Munro</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Tauber</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Schor</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Nickle</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Felix</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Jeng</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Bearer</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Lichenstein</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Bisordi</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Campion</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hyman</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Kurland</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Oates</surname>
            <given-names>CP</given-names>
          </name>
          <name>
            <surname>Kibbey</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sreekumar</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Giglio</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Greene</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Human disease ontology 2018 update: classification, content and workflow expansion</article-title>
        <source>Nucleic Acids Res</source>
        <year>2018</year>
        <volume>47</volume>
        <issue>D1</issue>
        <fpage>955</fpage>
        <lpage>962</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky1032</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Xu M, Jin R, Zhou Z-H. Speedup matrix completion with side information: application to multi-label learning. In: Advances in neural information processing systems, 2013;2301–2309.</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chicco</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Jurman</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>The advantages of the Matthews correlation coefficient (mcc) over f1 score and accuracy in binary classification evaluation</article-title>
        <source>BMC Genom</source>
        <year>2020</year>
        <volume>21</volume>
        <fpage>6</fpage>
        <pub-id pub-id-type="doi">10.1186/s12864-019-6413-7</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bray</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Ferlay</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Soerjomataram</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Siegel</surname>
            <given-names>R.L</given-names>
          </name>
          <name>
            <surname>Torre</surname>
            <given-names>L.A</given-names>
          </name>
          <name>
            <surname>Jemal</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Global cancer statistics 2018: Globocan estimates of incidence and mortality worldwide for 36 cancers in 185 countries</article-title>
        <source>CA Cancer J Clin</source>
        <year>2018</year>
        <volume>68</volume>
        <issue>6</issue>
        <fpage>394</fpage>
        <lpage>424</lpage>
        <pub-id pub-id-type="doi">10.3322/caac.21492</pub-id>
        <?supplied-pmid 30207593?>
        <pub-id pub-id-type="pmid">30207593</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alimirah</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Gupta</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Welsh</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cleary</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Mehta</surname>
            <given-names>RG</given-names>
          </name>
        </person-group>
        <article-title>Crosstalk between the vitamin d receptor (VDR) and miR-214 in regulating SuFu, a hedgehog pathway inhibitor in breast cancer cells</article-title>
        <source>Exp Cell Res</source>
        <year>2016</year>
        <volume>349</volume>
        <issue>1</issue>
        <fpage>15</fpage>
        <lpage>22</lpage>
        <pub-id pub-id-type="doi">10.1016/j.yexcr.2016.08.012</pub-id>
        <?supplied-pmid 27693451?>
        <pub-id pub-id-type="pmid">27693451</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Han</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Yin</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Ccat1 promotes triple-negative breast cancer progression by suppressing mir-218/zfx signaling</article-title>
        <source>Aging (Albany NY)</source>
        <year>2019</year>
        <volume>11</volume>
        <issue>14</issue>
        <fpage>4858</fpage>
        <lpage>4875</lpage>
        <pub-id pub-id-type="doi">10.18632/aging.102080</pub-id>
        <pub-id pub-id-type="pmid">31310241</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lou</surname>
            <given-names>K-X</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Z-H</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X-L</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>H-X</given-names>
          </name>
        </person-group>
        <article-title>Long non-coding RNA BANCR indicates poor prognosis for breast cancer and promotes cell proliferation and invasion</article-title>
        <source>Eur Rev Med Pharmacol Sci</source>
        <year>2018</year>
        <volume>22</volume>
        <issue>5</issue>
        <fpage>1358</fpage>
        <lpage>1365</lpage>
        <?supplied-pmid 29565494?>
        <pub-id pub-id-type="pmid">29565494</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cui</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>LncRNA-uca1 modulates progression of colon cancer through regulating the mir-28-5p/hoxb3 axis</article-title>
        <source>J Cell Biochem</source>
        <year>2019</year>
        <volume>120</volume>
        <issue>5</issue>
        <fpage>6926</fpage>
        <lpage>6936</lpage>
        <pub-id pub-id-type="doi">10.1002/jcb.27630</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Poursheikhani</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Abbaszadegan</surname>
            <given-names>MR</given-names>
          </name>
          <name>
            <surname>Nokhandani</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Kerachian</surname>
            <given-names>MA</given-names>
          </name>
        </person-group>
        <article-title>Integration analysis of long non-coding RNA (lncRNA) role in tumorigenesis of colon adenocarcinoma</article-title>
        <source>BMC Med Genomics</source>
        <year>2020</year>
        <volume>13</volume>
        <fpage>108</fpage>
        <pub-id pub-id-type="doi">10.1186/s12920-020-00757-2</pub-id>
        <?supplied-pmid 32727450?>
        <pub-id pub-id-type="pmid">32727450</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Shang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Long noncoding RNA plasmacytoma variant translocation 1 (pvt1) promotes colon cancer progression via endogenous sponging mir-26b</article-title>
        <source>Med Sci Monitor</source>
        <year>2018</year>
        <volume>24</volume>
        <fpage>8685</fpage>
        <lpage>8692</lpage>
        <pub-id pub-id-type="doi">10.12659/MSM.910955</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Belkin</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Niyogi</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Laplacian eigenmaps and spectral techniques for embedding and clustering</article-title>
        <source>Adv Neural Inf Process Syst</source>
        <year>2002</year>
        <volume>15</volume>
        <fpage>585</fpage>
        <lpage>591</lpage>
      </element-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Bousquet</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Lal</surname>
            <given-names>TN</given-names>
          </name>
          <name>
            <surname>Weston</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Schölkopf</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Learning with local and global consistency</article-title>
        <source>Adv Neural Inf Process Syst</source>
        <year>2004</year>
        <volume>16</volume>
        <fpage>321</fpage>
        <lpage>328</lpage>
      </element-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Label propagation through linear neighborhoods</article-title>
        <source>IEEE Trans Knowl Data Eng</source>
        <year>2008</year>
        <volume>20</volume>
        <issue>1</issue>
        <fpage>55</fpage>
        <lpage>67</lpage>
        <pub-id pub-id-type="doi">10.1109/TKDE.2007.190672</pub-id>
      </element-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Johnson</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>On the effectiveness of Laplacian normalization for graph semi-supervised learning</article-title>
        <source>J Mach Learn Res</source>
        <year>2007</year>
        <volume>8</volume>
        <issue>53</issue>
        <fpage>1489</fpage>
        <lpage>1517</lpage>
      </element-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>HC</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Quan</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Linear neighborhood propagation and its applications</article-title>
        <source>IEEE Trans Pattern Anal Mach Intell</source>
        <year>2009</year>
        <volume>31</volume>
        <issue>9</issue>
        <fpage>1600</fpage>
        <lpage>1615</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2008.216</pub-id>
        <?supplied-pmid 19574621?>
        <pub-id pub-id-type="pmid">19574621</pub-id>
      </element-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <mixed-citation publication-type="other">Neal R, Hinton G. A view of the em algorithm that justifies incremental, sparse, and other variants, 1998;355–368. Springer, Dordrecht.</mixed-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <mixed-citation publication-type="other">Blum A, Mitchell T. Combining labeled and unlabeled data with co-training. In: Proceedings of the annual conference on computational learning theory, vol. 11, pp. 92–100; 1998.</mixed-citation>
    </ref>
    <ref id="CR59">
      <label>59.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boyd</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Parikh</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Chu</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Peleato</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Eckstein</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Distributed optimization and statistical learning via the alternating direction method of multipliers</article-title>
        <source>Found Trends Mach Learn</source>
        <year>2011</year>
        <volume>3</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>122</lpage>
        <pub-id pub-id-type="doi">10.1561/2200000016</pub-id>
      </element-citation>
    </ref>
    <ref id="CR60">
      <label>60.</label>
      <mixed-citation publication-type="other">Kingma DP, Welling M. Auto-encoding variational bayes. In: Proceedings of the international conference on learning representations. 2014; ICLR.</mixed-citation>
    </ref>
    <ref id="CR61">
      <label>61.</label>
      <mixed-citation publication-type="other">Paszke A, Gross S, Massa F, Lerer A, Bradbury J, Chanan G, Killeen T, Lin Z, Gimelshein N, Antiga L, Desmaison A, Kopf A, Yang E, DeVito Z, Raison M, Tejani A, Chilamkurthy S, Steiner B, Fang L, Bai J, Chintala S. Pytorch: an imperative style, high-performance deep learning library. In: Advances in neural information processing systems, 2019;pp. 8026–8037.</mixed-citation>
    </ref>
    <ref id="CR62">
      <label>62.</label>
      <mixed-citation publication-type="other">Kingma DP, Ba JA. A method for stochastic optimization. In: Proceedings of the international conference on learning representations. 2015; ICLR.</mixed-citation>
    </ref>
    <ref id="CR63">
      <label>63.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
        <source>J Mach Learn Res</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
  </ref-list>
</back>
