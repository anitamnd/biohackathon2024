<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//ACS//DTD ACS Journal DTD v1.02 20061031//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName ACSJournal-v102.dtd?>
<?SourceDTD.Version 1.02?>
<?ConverterInfo.XSLTName acs2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Chem Inf Model</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Chem Inf Model</journal-id>
    <journal-id journal-id-type="publisher-id">ci</journal-id>
    <journal-id journal-id-type="coden">jcisd8</journal-id>
    <journal-title-group>
      <journal-title>Journal of Chemical Information and Modeling</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1549-9596</issn>
    <issn pub-type="epub">1549-960X</issn>
    <publisher>
      <publisher-name>American Chemical Society</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9710516</article-id>
    <article-id pub-id-type="pmid">36108142</article-id>
    <article-id pub-id-type="doi">10.1021/acs.jcim.2c00733</article-id>
    <article-categories>
      <subj-group>
        <subject>Application Note</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MolMiner: You Only
Look Once for Chemical Structure
Recognition</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes" id="ath1">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-8022-6194</contrib-id>
        <name>
          <surname>Xu</surname>
          <given-names>Youjun</given-names>
        </name>
        <xref rid="cor1" ref-type="other">*</xref>
        <xref rid="aff1" ref-type="aff">†</xref>
      </contrib>
      <contrib contrib-type="author" id="ath2">
        <name>
          <surname>Xiao</surname>
          <given-names>Jinchuan</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">†</xref>
      </contrib>
      <contrib contrib-type="author" id="ath3">
        <name>
          <surname>Chou</surname>
          <given-names>Chia-Han</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">†</xref>
      </contrib>
      <contrib contrib-type="author" id="ath4">
        <name>
          <surname>Zhang</surname>
          <given-names>Jianhang</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">†</xref>
      </contrib>
      <contrib contrib-type="author" id="ath5">
        <name>
          <surname>Zhu</surname>
          <given-names>Jintao</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">‡</xref>
      </contrib>
      <contrib contrib-type="author" id="ath6">
        <name>
          <surname>Hu</surname>
          <given-names>Qiwan</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">‡</xref>
      </contrib>
      <contrib contrib-type="author" id="ath7">
        <name>
          <surname>Li</surname>
          <given-names>Hemin</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">†</xref>
      </contrib>
      <contrib contrib-type="author" id="ath8">
        <name>
          <surname>Han</surname>
          <given-names>Ningsheng</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">†</xref>
      </contrib>
      <contrib contrib-type="author" id="ath9">
        <name>
          <surname>Liu</surname>
          <given-names>Bingyu</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">†</xref>
      </contrib>
      <contrib contrib-type="author" id="ath10">
        <name>
          <surname>Zhang</surname>
          <given-names>Shuaipeng</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">†</xref>
      </contrib>
      <contrib contrib-type="author" id="ath11">
        <name>
          <surname>Han</surname>
          <given-names>Jinyu</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">†</xref>
      </contrib>
      <contrib contrib-type="author" id="ath12">
        <name>
          <surname>Zhang</surname>
          <given-names>Zhen</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">†</xref>
      </contrib>
      <contrib contrib-type="author" id="ath13">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-0301-5983</contrib-id>
        <name>
          <surname>Zhang</surname>
          <given-names>Shuhao</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">†</xref>
      </contrib>
      <contrib contrib-type="author" id="ath14">
        <name>
          <surname>Zhang</surname>
          <given-names>Weilin</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">†</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes" id="ath15">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-8343-7587</contrib-id>
        <name>
          <surname>Lai</surname>
          <given-names>Luhua</given-names>
        </name>
        <xref rid="cor2" ref-type="other">*</xref>
        <xref rid="aff2" ref-type="aff">‡</xref>
        <xref rid="aff3" ref-type="aff">§</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes" id="ath16">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-8482-1185</contrib-id>
        <name>
          <surname>Pei</surname>
          <given-names>Jianfeng</given-names>
        </name>
        <xref rid="cor3" ref-type="other">*</xref>
        <xref rid="aff2" ref-type="aff">‡</xref>
      </contrib>
      <aff id="aff1"><label>†</label><institution>Infinite
Intelligence Pharma</institution>, Beijing, <country>China</country> 100083</aff>
      <aff id="aff2"><label>‡</label>Center
for Quantitative Biology, <institution>Peking University</institution>, Beijing, <country>China</country> 100871</aff>
      <aff id="aff3"><label>§</label>BNLMS,
Peking-Tsinghua Center for Life Sciences at the College of Chemistry
and Molecular Engineering, <institution>Peking University</institution>, Beijing, <country>China</country> 100871</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>*</label>Email: <email>xuyj@iipharma.cn</email>.</corresp>
      <corresp id="cor2"><label>*</label>Email: <email>lhlai@pku.edu.cn</email>. Fax: <fax>(+86)10-62751725</fax>. (L. Lai).</corresp>
      <corresp id="cor3"><label>*</label>Email: <email>jfpei@pku.edu.cn</email>. Fax: <fax>(+86)10-62759595</fax>. (J. Pei).</corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>15</day>
      <month>09</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <day>28</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>15</day>
      <month>09</month>
      <year>2023</year>
    </pub-date>
    <volume>62</volume>
    <issue>22</issue>
    <fpage>5321</fpage>
    <lpage>5328</lpage>
    <history>
      <date date-type="received">
        <day>09</day>
        <month>06</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 The Authors. Published by American Chemical Society</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>The Authors</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>Permits non-commercial access and re-use, provided that author attribution and integrity are maintained; but does not permit creation of adaptations or other derivative works (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">https://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>).</license-p>
      </license>
    </permissions>
    <abstract>
      <p content-type="toc-graphic">
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci2c00733_0005" id="ab-tgr1"/>
      </p>
      <p>Molecular structures are commonly depicted in 2D printed
forms
in scientific documents such as journal papers and patents. However,
these 2D depictions are not machine readable. Due to a backlog of
decades and an increasing amount of printed literatures, there is
a high demand for translating printed depictions into machine-readable
formats, which is known as Optical Chemical Structure Recognition
(OCSR). Most OCSR systems developed over the last three decades use
a rule-based approach, which vectorizes the depiction based on the
interpretation of vectors and nodes as bonds and atoms. Here, we present
a practical software called MolMiner, which is primarily built using
deep neural networks originally developed for semantic segmentation
and object detection to recognize atom and bond elements from documents.
These recognized elements can be easily connected as a molecular graph
with a distance-based construction algorithm. MolMiner gave state-of-the-art
performance on four benchmark data sets and a self-collected external
data set from scientific papers. As MolMiner performed similarly well
in real-world OCSR tasks with a user-friendly interface, it is a useful
and valuable tool for daily applications. The free download links
of Mac and Windows versions are available at <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/iipharma/pharmamind-molminer">https://github.com/iipharma/pharmamind-molminer</uri>.</p>
    </abstract>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution>Infinite Intelligence Pharma Ltd</institution>
            <institution-id institution-id-type="doi">NA</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>NA</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>document-id-old-9</meta-name>
        <meta-value>ci2c00733</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>document-id-new-14</meta-name>
        <meta-value>ci2c00733</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>ccc-price</meta-name>
        <meta-value/>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Introduction</title>
    <p>Chemical products are a vast amount of
priceless wealth and are
making our lives and health better. Much efforts on chemical research
and development have been made and published as primary scientific
literature. During the past decade, researchers have developed various
machine learning and deep learning models to solve a series of predictive
and generative tasks in the fields of chemistry and biology.<sup><xref ref-type="bibr" rid="ref1">1</xref>−<xref ref-type="bibr" rid="ref3">3</xref></sup> It is obvious that well-performed computational models cannot be
separated from data accumulation, especially experimental data, for
example, chemical reaction data and biological active data.</p>
    <p>Several well-known databases have played vital roles in scientific
research. For example, the Protein Data Bank database is an important
undertaking to make protein crystal structural data publicly available,
which has greatly facilitated research efforts and knowledge developments
on protein structure–function studies and structure predictions.<sup><xref ref-type="bibr" rid="ref4">4</xref></sup> Several large comprehensive biomedical databases
like ChEMBL have been constructed and updated. These data sets offer
necessary basis and opportunity to develop various practical advanced
technologies.<sup><xref ref-type="bibr" rid="ref5">5</xref></sup> Recently, there has been
a renewed interest in structurally collating experimental data sets
and building their interrelationships and intrarelationships to enhance
various downstream predictions and recommendations. The Open Reaction
Database aims to collect and share chemical reaction data from journal
articles, patents, and even electronic laboratory notebooks.<sup><xref ref-type="bibr" rid="ref6">6</xref></sup> Due to the rapidly increasing number of literature
resources, it becomes both laborious and time consuming to integrate
diverse kinds of experimental data into a comprehensive and professional
knowledge database.</p>
    <p>Automatic computational methods provide
a potential option to handle
various forms of valuable chemical and biological information. Named
Entity Recognition tools have been applied to extract chemical textual
information from literatures to create structured data.<sup><xref ref-type="bibr" rid="ref7">7</xref></sup> In addition to text-like objects, researchers
have also developed Optical Chemical Structure Recognition (OCSR)
tools with the intention of decoding a graphical chemical depiction
into a machine-readable molecular format. However, it remains challenging
to accurately recognize chemical structures from 2D printed images.</p>
    <p>Since 1990, several commercial and open-source OCSR systems have
been established based on similar rule-based implementations involving
image vectorization, image thinning, line enhancement, text-based
Optical Character Recognition (OCR), and graph reconstruction. A representative
system, Chemical Literature Data Extraction (CLiDE), is a commercial
OCSR toolkit developed by Keymodule,<sup><xref ref-type="bibr" rid="ref8">8</xref></sup> which
has been integrated into the ChemAxon software.<sup><xref ref-type="bibr" rid="ref9">9</xref></sup> Generally, most of the commercial OCSR systems were unavailable
to academic researchers. In 2009, Filippov and Nicklaus published
the first open-source system called Optical Structure Recognition
Application (OSRA),<sup><xref ref-type="bibr" rid="ref10">10</xref></sup> which is kept active
and upgraded for improved recognition. Imago and MolVec have also
been developed as open-source systems to offer researchers optional
tools for molecular structure recognition.<sup><xref ref-type="bibr" rid="ref11">11</xref>,<xref ref-type="bibr" rid="ref12">12</xref></sup> A recent review summarized the currently available OCSR systems.<sup><xref ref-type="bibr" rid="ref13">13</xref></sup></p>
    <p>Dramatic developments in deep learning
(DL) frameworks and hardware
have been achieved in image recognition technologies in recent years.
Bristol-Myers Squibb held a competition for molecular translation
in Kaggle.<sup><xref ref-type="bibr" rid="ref14">14</xref></sup> The architecture of the CNN-Transformer
plays an essential role in translating chemical images to InChI strings.<sup><xref ref-type="bibr" rid="ref15">15</xref></sup> Based on this, DECIMER has been reported for
translating various chemical images to SELFIES strings with acceptable
precision.<sup><xref ref-type="bibr" rid="ref16">16</xref></sup> Similarly, Bayer researchers
have developed another translation method called Img2Mol, exhibiting
a potential ability of recognizing hand-drawn molecules.<sup><xref ref-type="bibr" rid="ref17">17</xref></sup> Inspired by image segmentation technologies,
ChemGrapher uses atom-based, bond-based, and charge-based segmentation
neural networks to predict the probabilities of each pixel for a chemical
image and then constructs a chemical graph.<sup><xref ref-type="bibr" rid="ref18">18</xref></sup> Following this work, ABC-Net applied a divide-and-conquer segmentation
strategy to significantly improve recognition performance.<sup><xref ref-type="bibr" rid="ref19">19</xref></sup> Although these DL-based works present a promising
and potential application value, they are short of rigorous evaluations
on benchmark data sets, especially on real-world data tasks.</p>
    <p>Taking the substantial strengths of DL into consideration,<sup><xref ref-type="bibr" rid="ref20">20</xref></sup> we developed a practical DL-based system, MolMiner,
for real-world OCSR tasks. MolMiner can rapidly and accurately extract
chemical images and recognize chemical structures from PDF-format
documents. MolMiner performed better than the three existing open-source
OCSR systems on the benchmark data sets. To demonstrate its practicability,
we further collected 3040 images from scientific papers. MolMiner
performed similarly well in this real-world OCSR task, while other
methods did not work well. We also integrated functionalities like
a real-time correction function and a screenshot function into MolMiner
to provide a user-friendly interface. MolMiner is freely available
with daily permission to all registered users at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://molminer-cdn.iipharma.cn/pharma-mind/artifact/latest/win/PharmaMind-win-latest-setup.exe">Windows link</ext-link> and <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://molminer-cdn.iipharma.cn/pharma-mind/artifact/latest/mac/PharmaMind-mac-latest-setup.dmg">Mac link</ext-link>, respectively.</p>
  </sec>
  <sec id="sec2">
    <title>MolMiner Recognition System</title>
    <sec id="sec2.1">
      <title>Module Implementation</title>
      <p>MolMiner is a rule-free learning
system. It aims to transform the vectorization problem into object
detection tasks. That means it is able to extract chemical elements
in an object detection manner by training well-labeled data sets with
atom and bond annotations. It was implemented by five main modules
as follows:</p>
      <p>
        <list list-type="bullet">
          <list-item>
            <p>The data generation and annotation module aims to automatically
generate various styles of well-annotated chemical images based on
the RDKit v2021.09.1 toolkit.<sup><xref ref-type="bibr" rid="ref21">21</xref></sup> It supports
several augmentation operations, such as rotation, thinning, thickness,
noise, and supergroup. More augmentation operations (e.g., hand-drawn
lines) will be added into this module in the future, which is well-suited
for various real application scenarios.</p>
          </list-item>
          <list-item>
            <p>The chemical image detection (MolMiner-ImgDet) module
is a fully DL-driven image segmentation module and is implemented
by lightweight model MobileNetV2.<sup><xref ref-type="bibr" rid="ref22">22</xref></sup> It
is used to extract printed chemical representations from PDF-format
documents. Labeled data are generated by the first module with several
predefined templates such as journal style and patent style. The two
categorical annotations are adopted to train this model with cross
entropy loss of background class and compound class. The key performance
of recall is 95.5%.</p>
          </list-item>
          <list-item>
            <p>The chemical image
recognition (MolMiner-ImgRec) module
is the key module for rapid and accurate chemical structure recognition.
It is implemented based on the popular one-stage YOLOv5 architecture.<sup><xref ref-type="bibr" rid="ref23">23</xref></sup> After a series of evaluations on MaskRCNN,<sup><xref ref-type="bibr" rid="ref24">24</xref></sup> FastRCNN,<sup><xref ref-type="bibr" rid="ref25">25</xref></sup> and EfficientDet,<sup><xref ref-type="bibr" rid="ref26">26</xref></sup> we empirically found the YOLOv5 model could
significantly outperform other object detection architectures just
for this recognition task. The atom labels include “Si”,
“N”, “Br”, “S”, “I”,
“Cl”, “H”, “P”, “O”,
“C”, “B”, “F”, and “Text”.
The bond labels include “Single”, “Double”,
“Triple”, “Wedge”, “Dash”,
and “Wavy”. The whole predicted mAP@.5 is 97.5%. Labeled
data are automatically generated by the first module with several
image-level augmentation operations.</p>
          </list-item>
          <list-item>
            <p>The text-based OCR (optical character recognition) (MolMiner-TextOCR)
module is used to recognize chemistry text images with atom characters
and super groups. This OCR model is implemented by fine-tuning a pretrained
EasyOCR model<sup><xref ref-type="bibr" rid="ref27">27</xref></sup> with specifically cropped
chemical texts from the first module. The accuracy performance is
about 96.4%.</p>
          </list-item>
          <list-item>
            <p>The chemical element construction
and evaluation module
contains a distance-based graph construction algorithm accompanied
by a supergroup parser and an automatic evaluation module for performing
fair comparisons on benchmark data sets. The supergroup dictionary
is collected from the RDKit toolkit, ChemAxon, OSRA, and scientific
journals. The evaluation results are discussed in the <xref rid="sec3.2" ref-type="other">Benchmark Evaluation</xref> section.</p>
          </list-item>
        </list>
      </p>
      <p>Details of the five module implementations are described
in the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.jcim.2c00733/suppl_file/ci2c00733_si_001.pdf">Supporting Information</ext-link>. In comparison
to rule-based
systems, MolMiner has several advantages: (i) Batch GPU-based inference
can make the speed of element recognition faster than rule-based algorithms.
(ii) It implicitly learns the rules from a large amount of automatically
generated data sets or other manual annotated data sets, without designing
explicit rules. This characteristic can be simply extended to new
scenes. (iii) It supports rapid synchronous recognition of multiple
large-sized images. (iv) It provides additional user-friendly interfaces
for ease of use.</p>
    </sec>
    <sec id="sec2.2">
      <title>MolMiner User Interface</title>
      <p>The user interface has integrated
several frequently used functions, including screenshot recognition,
batch PDF recognition, real-time molecular editing, molecule collection,
and SDF/XLSX file download. <xref rid="fig1" ref-type="fig">Figure <xref rid="fig1" ref-type="fig">1</xref></xref> presents an overview of the real-time molecular edit
interface. Using this interface, users can check and correctly recognized
molecules one-by-one to reach the perfect accuracy of 100%. After
a simple test on 1000 images of non-Markush organic medicinal molecules,
it takes about 5–10 s for one person with simple training to
process one molecule with a series of operations (such as check, correct,
and save). Other functional modules can be easily found in the MolMiner
software. For details, please refer to the MolMiner User Manual (<uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/iipharma/pharmamind-molminer/tree/main/docs">https://github.com/iipharma/pharmamind-molminer/tree/main/docs</uri>).</p>
      <fig id="fig1" position="float">
        <label>Figure 1</label>
        <caption>
          <p>Editing interface with five rectangle parts (in blue): (A) User’s
account information. (B) MolMiner module. (C) PDF viewer (supported
by PDF.js v2.14<sup><xref ref-type="bibr" rid="ref28">28</xref></sup>). (D) cropped molecular
image and (D1) three buttons. The “Add” is to add another
cropped image of interest. The “Adjust Cropping” is
to adjust the boundaries of the cropped images. The “Delete”
is to remove the selected cropped image. (E) Real-time molecular edit
(supported by Ketcher v2.4<sup><xref ref-type="bibr" rid="ref29">29</xref></sup>). E1 contains
the four basic functions of Copy, Save, Favorites, and Next.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci2c00733_0001" id="gr1" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec id="sec3">
    <title>MolMiner Evaluation</title>
    <sec id="sec3.1">
      <title>Metrics</title>
      <p>We used the accuracies of the IUPAC International
Chemical Identifier (InChI) and maximum common substructure (MCS)
to evaluate the recognition performance. An InChI string is one kind
of unified string with multilayer representation. InChI-based accuracy
is the metric to evaluate the identity of the two InChI strings retrieved
from molecular structures. MCS-based accuracy is used to evaluate
the identity of both atom level and bond level based on graph matching
algorithms. Compared to the InChI-based accuracy, the MCS-based accuracy
offers a point-to-point comparison of the recognized molecular structures
and ground truth structures. The retrieved InChI string would often
overunderlie chemical information like <italic>cis</italic>/<italic>trans</italic>/<italic>either</italic> double bonds and chirality
checking, making the strings from the predicted molecular graphs slightly
different from the target strings. We took two examples from the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.jcim.2c00733/suppl_file/ci2c00733_si_001.pdf">Supporting Information</ext-link> to explain these differences,
shown in Figure S1 and Figure S2. In our opinion, it is enough for
graph-level identity to evaluate the recognized accuracy of chemical
image data.</p>
    </sec>
    <sec id="sec3.2">
      <title>Benchmark Evaluation</title>
      <p>We tested four benchmark data
sets (USPTO, UOB, CLEF2012, and JPO) referred to by Rajan et al.,<sup><xref ref-type="bibr" rid="ref13">13</xref></sup> shown in <xref rid="tbl1" ref-type="other">Table <xref rid="tbl1" ref-type="other">1</xref></xref>. The four benchmark data sets can be downloaded at <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/Kohulan/OCSR_Review/tree/master/assets/images">https://github.com/Kohulan/OCSR_Review/tree/master/assets/images</uri>. These raw images were directly recognized by the MolMiner-ImgRec
API service, in which we designed a general strategy to depict these
images. For large images with <italic>max</italic>(<italic>width</italic>, <italic>height</italic>) &gt; 2559 or small images with <italic>max</italic>(<italic>width</italic>, <italic>height</italic>) &lt;
640, these
images are resized to <italic>max</italic>(<italic>width</italic>, <italic>height</italic>) = 2560 or <italic>max</italic>(<italic>width</italic>, <italic>height</italic>) = 640, respectively. Those images with <italic>max</italic>(<italic>width</italic>, <italic>height</italic>) in
the ranges of (640, 1280], (1280,1920], and (1920, 2560] are padded
to the corresponding upper bounds with an RGB value of (255, 255,
255). For example, a 1000 × 2000 image will be padded to 2560
× 2560. For the line-thick images, we implemented a pixel-based
algorithm to roughly estimate the median line width of each image,
followed by applying a dilation function from OpenCV v4.5.5<sup><xref ref-type="bibr" rid="ref30">30</xref></sup> (cv2.dilate) using a 3 × 3 or 2 ×
2 kernel size depending on the estimated line width. These general
depictions aim to make the input image styles suitable for the application
domain of MolMiner-ImgRec.</p>
      <table-wrap id="tbl1" position="float">
        <label>Table 1</label>
        <caption>
          <title>Summary of Benchmark Evaluation on
Runtime, InChI-Based, and MCS-Based Accuracies (acc.) with Data Set
Sizes (s) and Molecular Weight Averages (μ) and Standard Deviations
(σ)</title>
        </caption>
        <table frame="hsides" rules="groups" border="0">
          <colgroup>
            <col align="center"/>
            <col align="center"/>
            <col align="center"/>
            <col align="center"/>
            <col align="center"/>
            <col align="center"/>
            <col align="center"/>
            <col align="center"/>
          </colgroup>
          <thead>
            <tr>
              <th colspan="3" align="center">Data sets</th>
              <th style="border:none;" align="center"> </th>
              <th style="border:none;" align="center">Molvec</th>
              <th style="border:none;" align="center">Imago</th>
              <th style="border:none;" align="center">Osra</th>
              <th style="border:none;" align="center">MolMiner</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td colspan="3" align="center">USPTO</td>
              <td style="border:none;" align="center">InChI acc. ↑</td>
              <td style="border:none;" align="center">88.6%</td>
              <td style="border:none;" align="center">88.9%</td>
              <td style="border:none;" align="center">87.9%</td>
              <td style="border:none;" align="center">
                <bold>89.9%</bold>
              </td>
            </tr>
            <tr>
              <td style="border:none;" align="center">
                <italic>s</italic>
              </td>
              <td style="border:none;" align="center">μ</td>
              <td style="border:none;" align="center">σ</td>
              <td style="border:none;" align="center">MCS acc. ↑</td>
              <td style="border:none;" align="center">88.9%</td>
              <td style="border:none;" align="center">88.8%</td>
              <td style="border:none;" align="center">16.9%</td>
              <td style="border:none;" align="center">
                <bold>93.3%</bold>
              </td>
            </tr>
            <tr>
              <td style="border:none;" align="center">5719</td>
              <td style="border:none;" align="center">440.3</td>
              <td style="border:none;" align="center">160.8</td>
              <td style="border:none;" align="center">Runtime
↓</td>
              <td style="border:none;" align="center">29 min</td>
              <td style="border:none;" align="center">73 min</td>
              <td style="border:none;" align="center">148 min</td>
              <td style="border:none;" align="center">
                <bold>7 min</bold>
              </td>
            </tr>
            <tr>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
            </tr>
            <tr>
              <td colspan="3" align="center">UOB</td>
              <td style="border:none;" align="center">InChI acc. ↑</td>
              <td style="border:none;" align="center">88.0%</td>
              <td style="border:none;" align="center">66.2%</td>
              <td style="border:none;" align="center">87.4%</td>
              <td style="border:none;" align="center">
                <bold>90.0%</bold>
              </td>
            </tr>
            <tr>
              <td style="border:none;" align="center">
                <italic>s</italic>
              </td>
              <td style="border:none;" align="center">μ</td>
              <td style="border:none;" align="center">σ</td>
              <td style="border:none;" align="center">MCS acc. ↑</td>
              <td style="border:none;" align="center">49.5%</td>
              <td style="border:none;" align="center">42.7%</td>
              <td style="border:none;" align="center">27.0%</td>
              <td style="border:none;" align="center">
                <bold>62.7%</bold>
              </td>
            </tr>
            <tr>
              <td style="border:none;" align="center">5740</td>
              <td style="border:none;" align="center">213.5</td>
              <td style="border:none;" align="center">57.3</td>
              <td style="border:none;" align="center">Runtime
↓</td>
              <td style="border:none;" align="center">28 min</td>
              <td style="border:none;" align="center">153 min</td>
              <td style="border:none;" align="center">126 min</td>
              <td style="border:none;" align="center">
                <bold>6 min</bold>
              </td>
            </tr>
            <tr>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
            </tr>
            <tr>
              <td colspan="3" align="center">CLEF2012</td>
              <td style="border:none;" align="center">InChI acc. ↑</td>
              <td style="border:none;" align="center">78.1%</td>
              <td style="border:none;" align="center">59.7%</td>
              <td style="border:none;" align="center">
                <bold>84.6%</bold>
              </td>
              <td style="border:none;" align="center">
                <bold>84.6%</bold>
              </td>
            </tr>
            <tr>
              <td style="border:none;" align="center">
                <italic>s</italic>
              </td>
              <td style="border:none;" align="center">μ</td>
              <td style="border:none;" align="center">σ</td>
              <td style="border:none;" align="center">MCS acc.
↑</td>
              <td style="border:none;" align="center">77.3%</td>
              <td style="border:none;" align="center">59.7%</td>
              <td style="border:none;" align="center">20.0%</td>
              <td style="border:none;" align="center">
                <bold>86.5%</bold>
              </td>
            </tr>
            <tr>
              <td style="border:none;" align="center">992</td>
              <td style="border:none;" align="center">400.9</td>
              <td style="border:none;" align="center">144.0</td>
              <td style="border:none;" align="center">Runtime ↓</td>
              <td style="border:none;" align="center">4 min</td>
              <td style="border:none;" align="center">16 min</td>
              <td style="border:none;" align="center">21 min</td>
              <td style="border:none;" align="center">
                <bold>1 min</bold>
              </td>
            </tr>
            <tr>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
              <td style="border:none;" align="center"> </td>
            </tr>
            <tr>
              <td colspan="3" align="center">JPO</td>
              <td style="border:none;" align="center">InChI acc. ↑</td>
              <td style="border:none;" align="center">66.9%</td>
              <td style="border:none;" align="center">48.6%</td>
              <td style="border:none;" align="center">67.1%</td>
              <td style="border:none;" align="center">
                <bold>72.2%</bold>
              </td>
            </tr>
            <tr>
              <td style="border:none;" align="center">
                <italic>s</italic>
              </td>
              <td style="border:none;" align="center">μ</td>
              <td style="border:none;" align="center">σ</td>
              <td style="border:none;" align="center">MCS acc. ↑</td>
              <td style="border:none;" align="center">31.8%</td>
              <td style="border:none;" align="center">26.2%</td>
              <td style="border:none;" align="center">19.8%</td>
              <td style="border:none;" align="center">
                <bold>34.8%</bold>
              </td>
            </tr>
            <tr>
              <td style="border:none;" align="center">450</td>
              <td style="border:none;" align="center">360.3</td>
              <td style="border:none;" align="center">185.0</td>
              <td style="border:none;" align="center">Runtime ↓</td>
              <td style="border:none;" align="center">8 min</td>
              <td style="border:none;" align="center">23 min</td>
              <td style="border:none;" align="center">17 min</td>
              <td style="border:none;" align="center">&lt;<bold>1 min</bold></td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>We compared MolMiner-ImgRec’s runtime and accuracy
performance
with other existing open-source OCSR tools including MolVec v0.9.8,<sup><xref ref-type="bibr" rid="ref12">12</xref></sup> OSRA v2.1.0,<sup><xref ref-type="bibr" rid="ref10">10</xref></sup> and
Imago v2.0<sup><xref ref-type="bibr" rid="ref11">11</xref></sup> on these four data sets. We
reviewed the consistency of InChI strings that are mentioned in Rajan
et al.<sup><xref ref-type="bibr" rid="ref13">13</xref></sup> Considering the atom-level evaluation
method from Imago,<sup><xref ref-type="bibr" rid="ref31">31</xref></sup> we found that the
atom-level and bond-level consistency indexes of MCS should be appropriate
metrics for evaluating this task. It comprehensively measures the
accuracy of atom level and bond level. In <xref rid="tbl1" ref-type="other">Table <xref rid="tbl1" ref-type="other">1</xref></xref>, we compared InChI-based accuracy and MCS-based
accuracy and found some significant differences due to the count of
“None” value, bond misplacement in aromatic rings, chirality
reassignment, and RDKit-based InChI export. Here, MCS-based accuracy
is deemed a more rigorous indicator to monitor the fine-grained accuracy
of atoms and bonds. Successively, we analyzed the runtime (Ubuntu
20.04, Intel Xeon(R) Gold 6230R CPU@2.10 GHz) and MCS-based (both
atom level and bond level) accuracy between our recognized molecules
and ground truth molecules. The results are summarized in <xref rid="tbl1" ref-type="other">Table <xref rid="tbl1" ref-type="other">1</xref></xref>, showing that MolMiner
performs better than the open-source tools both in runtimes and MCS-based
accuracies for the four data sets of USPTO, UOB, CLEF2012, and JPO.
We also tested the five representative failure cases from the MolVec
GitHub issue (<uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/ncats/molvec/issues/18">https://github.com/ncats/molvec/issues/18</uri>), and MolMiner gave
a much better performance as illustrated in <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.jcim.2c00733/suppl_file/ci2c00733_si_001.pdf">Figure S3</ext-link>. These comparisons suggest that MolMiner has a better capacity
to deal with diverse-styled images.</p>
      <p>Using the rule-based approach,
CLiDE Pro is a popular and professional
commercial software. Unfortunately, we do not have access to it and
could not perform a fair comparison. According to the reported USPTO
results from ChemAxon,<sup><xref ref-type="bibr" rid="ref32">32</xref></sup> the reported accuracy
(93.8%) is slightly better than our MCS-based accuracy (93.3%). One
of the possible reasons is the issue of crossing bonds. As previously
mentioned, since MolMiner is based on deep learning object detection
models, it is difficult for crossing bonds to be well recognized just
by these simple atom and bond annotations. More elegant designs can
be integrated into our models in the future. We are also trying to
solve this issue with several unavoidable rules or coarse-grained
annotations. Currently, manual correction is recommended in the interactive
plugin of Ketcher.<sup><xref ref-type="bibr" rid="ref29">29</xref></sup></p>
    </sec>
    <sec id="sec3.3">
      <title>Real-World Data Set Collection and Evaluation</title>
      <p>To further
validate the generalization capability of MolMiner, we have collected
a real-world external test set with 3040 images from 239 scientific
papers published in various journals. The new data set (MW avg., 496.8;
MW std., 280.1) can be downloaded at <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://zenodo.org/record/6973361">https://zenodo.org/record/6973361</uri>. We used these four tools to test this data set, and the results
are summarized in <xref rid="tbl2" ref-type="other">Table <xref rid="tbl2" ref-type="other">2</xref></xref>. MolMiner gave comparable recognition performance compared to the
four benchmark data sets used in training and validation, while the
other three methods performed much worse, demonstrating the applicability
of MolMiner in real-world OCSR tasks. Although there is still space
to reach 100% perfect recognition for real-world chemical images,
MolMiner provides a useful and robust tool for the OCSR applications.
In future work, a large-scale data set could be constructed to perform
comprehensive fair assessments and comparisons for real-world application
scenarios and to serve as the foundation for ongoing progress.</p>
      <table-wrap id="tbl2" position="float">
        <label>Table 2</label>
        <caption>
          <title>Performance on a Self-Collected Real-World
Data Set (3040 images) from Different Scientific Journals</title>
        </caption>
        <table frame="hsides" rules="groups" border="0">
          <colgroup>
            <col align="center"/>
            <col align="center"/>
            <col align="center"/>
          </colgroup>
          <thead>
            <tr>
              <th style="border:none;" align="center">Tool</th>
              <th style="border:none;" align="center">InChI acc. (%)</th>
              <th style="border:none;" align="center">MCS acc. (%)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="border:none;" align="center">MolVec</td>
              <td style="border:none;" align="center">62.6</td>
              <td style="border:none;" align="center">50.1</td>
            </tr>
            <tr>
              <td style="border:none;" align="center">Imago</td>
              <td style="border:none;" align="center">10.8</td>
              <td style="border:none;" align="center">10.3</td>
            </tr>
            <tr>
              <td style="border:none;" align="center">OSRA</td>
              <td style="border:none;" align="center">64.5</td>
              <td style="border:none;" align="center">8.9</td>
            </tr>
            <tr>
              <td style="border:none;" align="center">MolMiner</td>
              <td style="border:none;" align="center">
                <bold>88.9</bold>
              </td>
              <td style="border:none;" align="center">
                <bold>87.8</bold>
              </td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="sec3.4">
      <title>Application Case Illustration</title>
      <p>The current version of
MolMiner focuses on processing organic medicinal molecules (non-Markush
structures) from scientific documents. As the recognized molecular
images are not 100% correct (with some errors like crossing bonds,
noise, and supergroup parser), minor manual corrections are necessary.
MolMiner provides an interactive plugin of Ketcher to do this. In
the following, we we illustrate how MolMiner works using three application
cases.</p>
      <p>
        <list list-type="bullet">
          <list-item>
            <p>We took a screenshot of a large-sized image (size, 3000
× 2068; dpi, 300) of palytoxin to make a test. It took approximately
3 s to return one well-recognized molecular structure without any
manual corrections in the Ketcher plugin (shown in <xref rid="fig2" ref-type="fig">Figure <xref rid="fig2" ref-type="fig">2</xref></xref>).</p>
          </list-item>
          <list-item>
            <p>A scanned PDF page from a scientific journal<sup><xref ref-type="bibr" rid="ref33">33</xref></sup> (machine, HP M1210 MFP; dpi, 300; brightness,
128; contrast, 124) was tested by MolMiner, shown in <xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>. The recognized results are
satisfactory and achieve 100% accuracy under a set of appropriate
scanning parameters. We also tried some sets of scanning parameters,
which more or less could influence the recognized results.</p>
          </list-item>
          <list-item>
            <p>We tested a challenging case of hand-drawn
images from
Clevert et al.<sup><xref ref-type="bibr" rid="ref17">17</xref></sup> In <xref rid="fig4" ref-type="fig">Figure <xref rid="fig4" ref-type="fig">4</xref></xref>, although there are still some errors including
“N”, “Cl”, wedge bonds, and aromatic rings,
without training on any similar data, MolMiner could recognize simple
hand-drawn images (<xref rid="fig4" ref-type="fig">Figure <xref rid="fig4" ref-type="fig">4</xref></xref> (right)), and main skeletons and their positions of complex
images (<xref rid="fig4" ref-type="fig">Figure <xref rid="fig4" ref-type="fig">4</xref></xref> (left)).
The MolMiner recognition results of complex images serve as a good
starting point for users to check and make necessary corrections easily.</p>
          </list-item>
        </list>
      </p>
      <fig id="fig2" position="float">
        <label>Figure 2</label>
        <caption>
          <p>Large-sized (3000 × 2068) case of palytoxin.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci2c00733_0002" id="gr2" position="float"/>
      </fig>
      <fig id="fig3" position="float">
        <label>Figure 3</label>
        <caption>
          <p>Case of one scanned journal page from Wang.<sup><xref ref-type="bibr" rid="ref33">33</xref></sup></p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci2c00733_0003" id="gr3" position="float"/>
      </fig>
      <fig id="fig4" position="float">
        <label>Figure 4</label>
        <caption>
          <p>Case for recognizing hand-drawn images from Clevert et
al.<sup><xref ref-type="bibr" rid="ref17">17</xref></sup> Some errors are highlighted in red,
including
“N”, “Cl”, wedge bonds, and aromatic rings.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci2c00733_0004" id="gr4" position="float"/>
      </fig>
    </sec>
    <sec id="sec3.5">
      <title>Limitations</title>
      <p>The current version of MolMiner is weak
at dealing with crowded layout segmentation, colorful backgrounds,
crossing and irregular bonds, Markush structures or polymers, blurred
images, and extremely long supergroups. MolMiner provides an interactive
plugin of Ketcher for users to carry out necessary manual corrections.</p>
    </sec>
  </sec>
  <sec id="sec4">
    <title>Conclusion</title>
    <p>We have developed a practical OCSR software,
MolMiner, based on
advanced deep learning technologies including MobileNetv2, YOLOv5,
and EasyOCRv1.4. We also developed an automatic data generation module
to satisfy the data volume requirements of DL models. The benchmark
and external evaluations suggest that MolMiner outperforms the open-source
OCSR tools (including MolVec, OSRA, and Imago) on both accuracy and
runtime. Although there is still room to reach 100% perfect recognition
for real-world chemical images, MolMiner provides a useful tool for
the OCSR tasks. Currently, MolMiner supports several frequently used
functionalities such as batch PDF recognition, snapshot recognition,
and real-time molecular editing. More application extensions will
be integrated into MolMiner in the future. Mac and Windows versions
are freely available here.<sup><xref ref-type="bibr" rid="ref34">34</xref></sup> We give free
daily access to all registered users to ensure daily use amount, and
we also provide additional business channels for limitless access.</p>
  </sec>
  <sec sec-type="data-availability" id="sec5">
    <title>Data and Software Availability</title>
    <p>The benchmark data sets
(USPTO, UOB, CLEF2012, JPO) are used from <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/Kohulan/OCSR_Review">https://github.com/Kohulan/OCSR_Review</uri>. The original molecular data are randomly selected from the ChEMBL29
data set.<sup><xref ref-type="bibr" rid="ref5">5</xref></sup> All the data sets that are used
to construct the deep learning models (MolMiner-ImgDet, MolMiner-ImgRec,
MolMiner-TextOCR) are automatically generated by open-source toolkits.
The annotations of elements and supergroups are automatically generated
using the <italic>MolDraw</italic>2<italic>D</italic>SVG and <italic>CondenseMolAbbreviations</italic> functions of RDKit v2021.09.1.<sup><xref ref-type="bibr" rid="ref21">21</xref></sup> The MolMiner-ImgDet data are automatically generated
using ReportLab Open Source v3.5.0.<sup><xref ref-type="bibr" rid="ref35">35</xref></sup> More
details are described in the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.jcim.2c00733/suppl_file/ci2c00733_si_001.pdf">Supporting Information, Supplementary Datasets and Methods</ext-link>. The Mac and Windows download
links for the latest MolMiner are freely available at <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://molminer-cdn.iipharma.cn/pharma-mind/artifact/latest/mac/PharmaMind-mac-latest-setup.dmg">https://molminer-cdn.iipharma.cn/pharma-mind/artifact/latest/mac/PharmaMind-mac-latest-setup.dmg</uri> and <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://molminer-cdn.iipharma.cn/pharma-mind/artifact/latest/win/PharmaMind-win-latest-setup.exe">https://molminer-cdn.iipharma.cn/pharma-mind/artifact/latest/win/PharmaMind-win-latest-setup.exe</uri>, respectively.</p>
  </sec>
</body>
<back>
  <notes id="notes-3" notes-type="si">
    <title>Supporting Information Available</title>
    <p>The Supporting Information
is available free of charge at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/10.1021/acs.jcim.2c00733?goto=supporting-info">https://pubs.acs.org/doi/10.1021/acs.jcim.2c00733</ext-link>.<list id="silist" list-type="simple"><list-item><p>Data sets and methods. Figure S1: Case about chirality
check. Figure S2: Case about double bonds with <italic>trans</italic>(<italic>E</italic>), <italic>cis</italic>(<italic>Z</italic>), and <italic>either</italic>(<italic>E</italic>/<italic>Z</italic>). Figure S3:
Representative failure cases from MolVec GitHub (<uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/ncats/molvec/issues/18">https://github.com/ncats/molvec/issues/18</uri>). (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.jcim.2c00733/suppl_file/ci2c00733_si_001.pdf">PDF</ext-link>)</p></list-item></list></p>
  </notes>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sifile1">
      <media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci2c00733_si_001.pdf">
        <caption>
          <p>ci2c00733_si_001.pdf</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <notes notes-type="" id="notes-1">
    <title>Author Contributions</title>
    <p>Y. Xu, J.
Xiao, and C.-H. Chou contributed equally.</p>
  </notes>
  <notes notes-type="COI-statement" id="NOTES-d14e849-autogenerated">
    <p>The
authors declare no
competing financial interest.</p>
  </notes>
  <ack>
    <title>Acknowledgments</title>
    <p>This work is supported by the funding from Infinite Intelligence
Pharma, Ltd.</p>
  </ack>
  <glossary id="dl1">
    <def-list>
      <title>Acronyms</title>
      <def-item>
        <term>YOLO</term>
        <def>
          <p>You look
only once</p>
        </def>
      </def-item>
      <def-item>
        <term>OCSR</term>
        <def>
          <p>Optical
chemical structure recognition</p>
        </def>
      </def-item>
      <def-item>
        <term>OCR</term>
        <def>
          <p>Optical character recognition</p>
        </def>
      </def-item>
      <def-item>
        <term>CLiDE</term>
        <def>
          <p>Chemical literature data extraction</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <ref-list>
    <title>References</title>
    <ref id="ref1">
      <mixed-citation publication-type="journal" id="cit1"><name><surname>Xu</surname><given-names>Y.</given-names></name>; <name><surname>Lin</surname><given-names>K.</given-names></name>; <name><surname>Wang</surname><given-names>S.</given-names></name>; <name><surname>Wang</surname><given-names>L.</given-names></name>; <name><surname>Cai</surname><given-names>C.</given-names></name>; <name><surname>Song</surname><given-names>C.</given-names></name>; <name><surname>Lai</surname><given-names>L.</given-names></name>; <name><surname>Pei</surname><given-names>J.</given-names></name><article-title>Deep learning for molecular generation</article-title>. <source>Future medicinal chemistry</source><year>2019</year>, <volume>11</volume>, <fpage>567</fpage>–<lpage>597</lpage>. <pub-id pub-id-type="doi">10.4155/fmc-2018-0358</pub-id>.<pub-id pub-id-type="pmid">30698019</pub-id></mixed-citation>
    </ref>
    <ref id="ref2">
      <mixed-citation publication-type="journal" id="cit2"><name><surname>Lavecchia</surname><given-names>A.</given-names></name><article-title>Deep learning
in drug discovery: opportunities, challenges and future prospects</article-title>. <source>Drug discovery today</source><year>2019</year>, <volume>24</volume>, <fpage>2017</fpage>–<lpage>2032</lpage>. <pub-id pub-id-type="doi">10.1016/j.drudis.2019.07.006</pub-id>.<pub-id pub-id-type="pmid">31377227</pub-id></mixed-citation>
    </ref>
    <ref id="ref3">
      <mixed-citation publication-type="journal" id="cit3"><name><surname>Tang</surname><given-names>B.</given-names></name>; <name><surname>Pan</surname><given-names>Z.</given-names></name>; <name><surname>Yin</surname><given-names>K.</given-names></name>; <name><surname>Khateeb</surname><given-names>A.</given-names></name><article-title>Recent advances
of deep learning
in bioinformatics and computational biology</article-title>. <source>Frontiers in genetics</source><year>2019</year>, <volume>10</volume>, <fpage>214</fpage><pub-id pub-id-type="doi">10.3389/fgene.2019.00214</pub-id>.<pub-id pub-id-type="pmid">30972100</pub-id></mixed-citation>
    </ref>
    <ref id="ref4">
      <mixed-citation publication-type="journal" id="cit4"><name><surname>Burley</surname><given-names>S. K.</given-names></name>; <name><surname>Bhikadiya</surname><given-names>C.</given-names></name>; <name><surname>Bi</surname><given-names>C.</given-names></name>; <name><surname>Bittrich</surname><given-names>S.</given-names></name>; <name><surname>Chen</surname><given-names>L.</given-names></name>; <name><surname>Crichlow</surname><given-names>G. V.</given-names></name>; <name><surname>Christie</surname><given-names>C. H.</given-names></name>; <name><surname>Dalenberg</surname><given-names>K.</given-names></name>; <name><surname>Di Costanzo</surname><given-names>L.</given-names></name>; <name><surname>Duarte</surname><given-names>J. M.</given-names></name>; et al. <article-title>RCSB Protein Data Bank:
powerful new tools for exploring 3D structures of biological macromolecules
for basic and applied research and education in fundamental biology,
biomedicine, biotechnology, bioengineering and energy sciences</article-title>. <source>Nucleic Acids Res.</source><year>2021</year>, <volume>49</volume>, <fpage>D437</fpage>–<lpage>D451</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkaa1038</pub-id>.<pub-id pub-id-type="pmid">33211854</pub-id></mixed-citation>
    </ref>
    <ref id="ref5">
      <mixed-citation publication-type="journal" id="cit5"><name><surname>Mendez</surname><given-names>D.</given-names></name>; <name><surname>Gaulton</surname><given-names>A.</given-names></name>; <name><surname>Bento</surname><given-names>A. P.</given-names></name>; <name><surname>Chambers</surname><given-names>J.</given-names></name>; <name><surname>De Veij</surname><given-names>M.</given-names></name>; <name><surname>Félix</surname><given-names>E.</given-names></name>; <name><surname>Magariños</surname><given-names>M. P.</given-names></name>; <name><surname>Mosquera</surname><given-names>J. F.</given-names></name>; <name><surname>Mutowo</surname><given-names>P.</given-names></name>; <name><surname>Nowotka</surname><given-names>M.</given-names></name>; et al. <article-title>ChEMBL: towards direct deposition of bioassay data</article-title>. <source>Nucleic Acids Res.</source><year>2019</year>, <volume>47</volume>, <fpage>D930</fpage>–<lpage>D940</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gky1075</pub-id>.<pub-id pub-id-type="pmid">30398643</pub-id></mixed-citation>
    </ref>
    <ref id="ref6">
      <mixed-citation publication-type="journal" id="cit6"><name><surname>Kearnes</surname><given-names>S. M.</given-names></name>; <name><surname>Maser</surname><given-names>M. R.</given-names></name>; <name><surname>Wleklinski</surname><given-names>M.</given-names></name>; <name><surname>Kast</surname><given-names>A.</given-names></name>; <name><surname>Doyle</surname><given-names>A. G.</given-names></name>; <name><surname>Dreher</surname><given-names>S. D.</given-names></name>; <name><surname>Hawkins</surname><given-names>J. M.</given-names></name>; <name><surname>Jensen</surname><given-names>K. F.</given-names></name>; <name><surname>Coley</surname><given-names>C. W.</given-names></name><article-title>The open
reaction database</article-title>. <source>J. Am. Chem. Soc.</source><year>2021</year>, <volume>143</volume>, <fpage>18820</fpage>–<lpage>18826</lpage>. <pub-id pub-id-type="doi">10.1021/jacs.1c09820</pub-id>.<pub-id pub-id-type="pmid">34727496</pub-id></mixed-citation>
    </ref>
    <ref id="ref7">
      <mixed-citation publication-type="journal" id="cit7"><name><surname>Eltyeb</surname><given-names>S.</given-names></name>; <name><surname>Salim</surname><given-names>N.</given-names></name><article-title>Chemical named entities
recognition: a review on approaches and applications</article-title>. <source>Journal of cheminformatics</source><year>2014</year>, <volume>6</volume>, <fpage>1</fpage>–<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1186/1758-2946-6-17</pub-id>.<pub-id pub-id-type="pmid">24397863</pub-id></mixed-citation>
    </ref>
    <ref id="ref8">
      <mixed-citation publication-type="journal" id="cit8"><name><surname>Valko</surname><given-names>A. T.</given-names></name>; <name><surname>Johnson</surname><given-names>A. P.</given-names></name><article-title>CLiDE Pro: the latest generation of CLiDE, a tool for
optical chemical structure recognition</article-title>. <source>J. Chem.
Inf. Model.</source><year>2009</year>, <volume>49</volume>, <fpage>780</fpage>–<lpage>787</lpage>. <pub-id pub-id-type="doi">10.1021/ci800449t</pub-id>.<pub-id pub-id-type="pmid">19298076</pub-id></mixed-citation>
    </ref>
    <ref id="ref9">
      <mixed-citation publication-type="weblink" id="cit9">ChemAxon
and Keymodule Announce Integration of CLiDE OCSR and Commercial Relationship. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.prnewswire.co.uk/news-releases/chemaxon-and-keymodule-announce-integration-of-clide-ocsr-and-commercial-relationship-258109351.html">https://www.prnewswire.co.uk/news-releases/chemaxon-and-keymodule-announce-integration-of-clide-ocsr-and-commercial-relationship-258109351.html</uri> (accessed 2022–05–18).</mixed-citation>
    </ref>
    <ref id="ref10">
      <mixed-citation publication-type="journal" id="cit10"><name><surname>Filippov</surname><given-names>I. V.</given-names></name>; <name><surname>Nicklaus</surname><given-names>M. C.</given-names></name><article-title>Optical Structure Recognition Software To Recover Chemical
Information: OSRA, An Open Source Solution</article-title>. <source>J. Chem. Inf. Model.</source><year>2009</year>, <volume>49</volume>, <fpage>740</fpage>–<lpage>743</lpage>. <pub-id pub-id-type="doi">10.1021/ci800067r</pub-id>.<pub-id pub-id-type="pmid">19434905</pub-id></mixed-citation>
    </ref>
    <ref id="ref11">
      <mixed-citation publication-type="weblink" id="cit11">Imago
OCR. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://lifescience.opensource.epam.com/imago/index.html">https://lifescience.opensource.epam.com/imago/index.html</uri> (accessed 2022–09–15).</mixed-citation>
    </ref>
    <ref id="ref12">
      <mixed-citation publication-type="weblink" id="cit12">MolVec
OCR. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/ncats/molvec">https://github.com/ncats/molvec</uri> (accessed 2022–05–18).</mixed-citation>
    </ref>
    <ref id="ref13">
      <mixed-citation publication-type="journal" id="cit13"><name><surname>Rajan</surname><given-names>K.</given-names></name>; <name><surname>Brinkhaus</surname><given-names>H. O.</given-names></name>; <name><surname>Zielesny</surname><given-names>A.</given-names></name>; <name><surname>Steinbeck</surname><given-names>C.</given-names></name><article-title>A review of
optical chemical structure recognition tools</article-title>. <source>Journal of Cheminformatics</source><year>2020</year>, <volume>12</volume>, <fpage>60</fpage><pub-id pub-id-type="doi">10.1186/s13321-020-00465-0</pub-id>.<pub-id pub-id-type="pmid">33372625</pub-id></mixed-citation>
    </ref>
    <ref id="ref14">
      <mixed-citation publication-type="weblink" id="cit14">Molecular
translation competition. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.kaggle.com/c/bms-molecular-translation">https://www.kaggle.com/c/bms-molecular-translation</uri> (accessed 2022–05–18).</mixed-citation>
    </ref>
    <ref id="ref15">
      <mixed-citation publication-type="journal" id="cit15"><name><surname>Heller</surname><given-names>S.</given-names></name>; <name><surname>McNaught</surname><given-names>A.</given-names></name>; <name><surname>Stein</surname><given-names>S.</given-names></name>; <name><surname>Tchekhovskoi</surname><given-names>D.</given-names></name>; <name><surname>Pletnev</surname><given-names>I.</given-names></name><article-title>InChI-the worldwide chemical structure identifier standard</article-title>. <source>Journal of cheminformatics</source><year>2013</year>, <volume>5</volume>, <fpage>1</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1186/1758-2946-5-7</pub-id>.<pub-id pub-id-type="pmid">23289532</pub-id></mixed-citation>
    </ref>
    <ref id="ref16">
      <mixed-citation publication-type="journal" id="cit16"><name><surname>Rajan</surname><given-names>K.</given-names></name>; <name><surname>Zielesny</surname><given-names>A.</given-names></name>; <name><surname>Steinbeck</surname><given-names>C.</given-names></name><article-title>DECIMER 1.0: deep learning for chemical
image recognition using transformers</article-title>. <source>Journal
of Cheminformatics</source><year>2021</year>, <volume>13</volume>, <fpage>1</fpage>–<lpage>16</lpage>. <pub-id pub-id-type="doi">10.1186/s13321-021-00538-8</pub-id>.<pub-id pub-id-type="pmid">33407901</pub-id></mixed-citation>
    </ref>
    <ref id="ref17">
      <mixed-citation publication-type="journal" id="cit17"><name><surname>Clevert</surname><given-names>D.-A.</given-names></name>; <name><surname>Le</surname><given-names>T.</given-names></name>; <name><surname>Winter</surname><given-names>R.</given-names></name>; <name><surname>Montanari</surname><given-names>F.</given-names></name><article-title>Img2Mol-accurate
SMILES recognition
from molecular graphical depictions</article-title>. <source>Chemical
science</source><year>2021</year>, <volume>12</volume>, <fpage>14174</fpage>–<lpage>14181</lpage>. <pub-id pub-id-type="doi">10.1039/D1SC01839F</pub-id>.<pub-id pub-id-type="pmid">34760202</pub-id></mixed-citation>
    </ref>
    <ref id="ref18">
      <mixed-citation publication-type="journal" id="cit18"><name><surname>Oldenhof</surname><given-names>M.</given-names></name>; <name><surname>Arany</surname><given-names>A.</given-names></name>; <name><surname>Moreau</surname><given-names>Y.</given-names></name>; <name><surname>Simm</surname><given-names>J.</given-names></name><article-title>ChemGrapher: optical
graph recognition of chemical compounds by deep learning</article-title>. <source>J. Chem. Inf. Model.</source><year>2020</year>, <volume>60</volume>, <fpage>4506</fpage>–<lpage>4517</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jcim.0c00459</pub-id>.<pub-id pub-id-type="pmid">32924466</pub-id></mixed-citation>
    </ref>
    <ref id="ref19">
      <mixed-citation publication-type="journal" id="cit19"><name><surname>Zhang</surname><given-names>X.-C.</given-names></name>; <name><surname>Yi</surname><given-names>J.-C.</given-names></name>; <name><surname>Yang</surname><given-names>G.-P.</given-names></name>; <name><surname>Wu</surname><given-names>C.-K.</given-names></name>; <name><surname>Hou</surname><given-names>T.-J.</given-names></name>; <name><surname>Cao</surname><given-names>D.-S.</given-names></name><article-title>ABC-Net: a divide-and-conquer based
deep learning architecture
for SMILES recognition from molecular images</article-title>. <source>Briefings in Bioinformatics</source><year>2022</year>, <volume>23</volume>, <fpage>bbac033</fpage><pub-id pub-id-type="doi">10.1093/bib/bbac033</pub-id>.<pub-id pub-id-type="pmid">35212357</pub-id></mixed-citation>
    </ref>
    <ref id="ref20">
      <mixed-citation publication-type="journal" id="cit20"><name><surname>LeCun</surname><given-names>Y.</given-names></name>; <name><surname>Bengio</surname><given-names>Y.</given-names></name>; <name><surname>Hinton</surname><given-names>G.</given-names></name><article-title>Deep learning</article-title>. <source>Nature</source><year>2015</year>, <volume>521</volume>, <fpage>436</fpage>–<lpage>444</lpage>. <pub-id pub-id-type="doi">10.1038/nature14539</pub-id>.<pub-id pub-id-type="pmid">26017442</pub-id></mixed-citation>
    </ref>
    <ref id="ref21">
      <mixed-citation publication-type="weblink" id="cit21">RDKit:
Open-source cheminformatics. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.rdkit.org">https://www.rdkit.org</uri> (accessed 2021–10–01).</mixed-citation>
    </ref>
    <ref id="ref22">
      <mixed-citation publication-type="conf-proc" id="cit22"><person-group><name><surname>Sandler</surname><given-names>M.</given-names></name>; <name><surname>Howard</surname><given-names>A.</given-names></name>; <name><surname>Zhu</surname><given-names>M.</given-names></name>; <name><surname>Zhmoginov</surname><given-names>A.</given-names></name>; <name><surname>Chen</surname><given-names>L.-C.</given-names></name></person-group><article-title>Mobilenetv2: Inverted residuals and linear bottlenecks</article-title>. <source>Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</source>, <year>2018</year>; pp <fpage>4510</fpage>–<lpage>4520</lpage>.</mixed-citation>
    </ref>
    <ref id="ref23">
      <mixed-citation publication-type="report" id="cit23"><person-group person-group-type="allauthors"><name><surname>Jocher</surname><given-names>G.</given-names></name></person-group><etal/><source>ultralytics/yolov5:
v5.0 - YOLOv5-P6 1280 models, AWS, Supervise.ly and YouTube integrations</source>; <publisher-name>Zendo</publisher-name>, <year>2021</year>.</mixed-citation>
    </ref>
    <ref id="ref24">
      <mixed-citation publication-type="conf-proc" id="cit24"><person-group><name><surname>He</surname><given-names>K.</given-names></name>; <name><surname>Gkioxari</surname><given-names>G.</given-names></name>; <name><surname>Dollár</surname><given-names>P.</given-names></name>; <name><surname>Girshick</surname><given-names>R.</given-names></name></person-group><article-title>Mask r-cnn</article-title>. <source>Proceedings of
the IEEE International Conference on Computer Vision</source>, <year>2017</year>; pp <fpage>2961</fpage>–<lpage>2969</lpage>.</mixed-citation>
    </ref>
    <ref id="ref25">
      <mixed-citation publication-type="conf-proc" id="cit25"><person-group><name><surname>Girshick</surname><given-names>R.</given-names></name></person-group><article-title>Fast r-cnn</article-title>. <source>Proceedings of the IEEE International Conference on Computer Vision</source>, <year>2015</year>; pp <fpage>1440</fpage>–<lpage>1448</lpage>.</mixed-citation>
    </ref>
    <ref id="ref26">
      <mixed-citation publication-type="conf-proc" id="cit26"><person-group><name><surname>Tan</surname><given-names>M.</given-names></name>; <name><surname>Pang</surname><given-names>R.</given-names></name>; <name><surname>Le</surname><given-names>Q. V.</given-names></name></person-group><article-title>Efficientdet: Scalable and efficient object detection</article-title>. <source>Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</source>, <year>2020</year>; pp <fpage>10781</fpage>–<lpage>10790</lpage>.</mixed-citation>
    </ref>
    <ref id="ref27">
      <mixed-citation publication-type="weblink" id="cit27">EasyOCR. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/JaidedAI/EasyOCR">https://github.com/JaidedAI/EasyOCR</uri> (accessed 2022–05–18).</mixed-citation>
    </ref>
    <ref id="ref28">
      <mixed-citation publication-type="weblink" id="cit28">PDF.js. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/mozilla/pdf.js/">https://github.com/mozilla/pdf.js/</uri> (accessed 2022–05–18).</mixed-citation>
    </ref>
    <ref id="ref29">
      <mixed-citation publication-type="weblink" id="cit29">Ketcher. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/epam/ketcher">https://github.com/epam/ketcher</uri> (accessed 2022–05–18).</mixed-citation>
    </ref>
    <ref id="ref30">
      <mixed-citation publication-type="weblink" id="cit30">OpenCV. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/opencv/opencv/releases/tag/4.5.5">https://github.com/opencv/opencv/releases/tag/4.5.5</uri> (accessed 2022–05–18).</mixed-citation>
    </ref>
    <ref id="ref31">
      <mixed-citation publication-type="weblink" id="cit31">Imago
report. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://lifescience.opensource.epam.com/downloads/imago-2.0.0/report.zip">https://lifescience.opensource.epam.com/downloads/imago-2.0.0/report.zip</uri> (accessed 2022–09–15).</mixed-citation>
    </ref>
    <ref id="ref32">
      <mixed-citation publication-type="weblink" id="cit32">ChemAxon
&amp; Keymodule report. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://chemaxon.com/app/uploads/2013/06/keymodule.pdf">https://chemaxon.com/app/uploads/2013/06/keymodule.pdf</uri> (accessed 2022–05–18).</mixed-citation>
    </ref>
    <ref id="ref33">
      <mixed-citation publication-type="journal" id="cit33"><name><surname>Wang</surname><given-names>Y.-H.</given-names></name><article-title>Traditional
uses and pharmacologically active constituents of Dendrobium plants
for dermatological disorders: a review</article-title>. <source>Natural
Products and Bioprospecting</source><year>2021</year>, <volume>11</volume>, <fpage>465</fpage>–<lpage>487</lpage>. <pub-id pub-id-type="doi">10.1007/s13659-021-00305-0</pub-id>.<pub-id pub-id-type="pmid">33880726</pub-id></mixed-citation>
    </ref>
    <ref id="ref34">
      <mixed-citation publication-type="weblink" id="cit34">MolMiner
download link. Mac <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://molminer-cdn.iipharma.cn/pharma-mind/artifact/latest/mac/PharmaMind-mac-latest-setup.dmg">https://molminer-cdn.iipharma.cn/pharma-mind/artifact/latest/mac/PharmaMind-mac-latest-setup.dmg</uri>; Windows <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://molminer-cdn.iipharma.cn/pharma-mind/artifact/latest/win/PharmaMind-win-latest-setup.exe">https://molminer-cdn.iipharma.cn/pharma-mind/artifact/latest/win/PharmaMind-win-latest-setup.exe</uri>; Github: <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/iipharma/pharmamind-molminer">https://github.com/iipharma/pharmamind-molminer</uri> (accessed 2022–09–15).</mixed-citation>
    </ref>
    <ref id="ref35">
      <mixed-citation publication-type="undeclared" id="cit35">ReportLab
Open Source. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://hg.reportlab.com/hg-public/reportlab">https://hg.reportlab.com/hg-public/reportlab</uri> (accessed 2022–05–18).</mixed-citation>
    </ref>
  </ref-list>
</back>
