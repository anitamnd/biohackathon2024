<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">JAMIA Open</journal-id>
    <journal-id journal-id-type="iso-abbrev">JAMIA Open</journal-id>
    <journal-id journal-id-type="publisher-id">jamiaoa</journal-id>
    <journal-title-group>
      <journal-title>JAMIA Open</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2574-2531</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8054032</article-id>
    <article-id pub-id-type="pmid">33898938</article-id>
    <article-id pub-id-type="doi">10.1093/jamiaopen/ooab025</article-id>
    <article-id pub-id-type="publisher-id">ooab025</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research and Applications</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01530</subject>
        <subject>AcademicSubjects/MED00010</subject>
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Annotation and initial evaluation of a large annotated German oncological corpus</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Kittner</surname>
          <given-names>Madeleine</given-names>
        </name>
        <xref rid="ooab025-aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lamping</surname>
          <given-names>Mario</given-names>
        </name>
        <xref rid="ooab025-aff2" ref-type="aff">2</xref>
        <xref rid="ooab025-aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rieke</surname>
          <given-names>Damian T</given-names>
        </name>
        <xref rid="ooab025-aff2" ref-type="aff">2</xref>
        <xref rid="ooab025-aff3" ref-type="aff">3</xref>
        <xref rid="ooab025-aff4" ref-type="aff">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Götze</surname>
          <given-names>Julian</given-names>
        </name>
        <xref rid="ooab025-aff5" ref-type="aff">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bajwa</surname>
          <given-names>Bariya</given-names>
        </name>
        <xref rid="ooab025-aff5" ref-type="aff">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jelas</surname>
          <given-names>Ivan</given-names>
        </name>
        <xref rid="ooab025-aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rüter</surname>
          <given-names>Gina</given-names>
        </name>
        <xref rid="ooab025-aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hautow</surname>
          <given-names>Hanjo</given-names>
        </name>
        <xref rid="ooab025-aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sänger</surname>
          <given-names>Mario</given-names>
        </name>
        <xref rid="ooab025-aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Habibi</surname>
          <given-names>Maryam</given-names>
        </name>
        <xref rid="ooab025-aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zettwitz</surname>
          <given-names>Marit</given-names>
        </name>
        <xref rid="ooab025-aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>de Bortoli</surname>
          <given-names>Till</given-names>
        </name>
        <xref rid="ooab025-aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ostermann</surname>
          <given-names>Leonie</given-names>
        </name>
        <xref rid="ooab025-aff5" ref-type="aff">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ševa</surname>
          <given-names>Jurica</given-names>
        </name>
        <xref rid="ooab025-aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Starlinger</surname>
          <given-names>Johannes</given-names>
        </name>
        <xref rid="ooab025-aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kohlbacher</surname>
          <given-names>Oliver</given-names>
        </name>
        <xref rid="ooab025-aff6" ref-type="aff">6</xref>
        <xref rid="ooab025-aff7" ref-type="aff">7</xref>
        <xref rid="ooab025-aff8" ref-type="aff">8</xref>
        <xref rid="ooab025-aff9" ref-type="aff">9</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Malek</surname>
          <given-names>Nisar P</given-names>
        </name>
        <xref rid="ooab025-aff5" ref-type="aff">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Keilholz</surname>
          <given-names>Ulrich</given-names>
        </name>
        <xref rid="ooab025-aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Leser</surname>
          <given-names>Ulf</given-names>
        </name>
        <xref rid="ooab025-aff1" ref-type="aff">1</xref>
        <xref rid="ooab025-cor1" ref-type="corresp"/>
        <!--leser@informatik.hu-berlin.de-->
      </contrib>
    </contrib-group>
    <aff id="ooab025-aff1"><label>1</label><institution>Knowledge Management for Bioinformatics, Humboldt Universität zu Berlin</institution>, Berlin, <country country="DE">Germany</country></aff>
    <aff id="ooab025-aff2"><label>2</label><institution>Department of Hematology, Oncology and Cancer Immunology, Campus Benjamin Franklin, Charité – Universitätsmedizin Berlin, corporate member of Freie Universität Berlin and Humboldt-Universität zu Berlin</institution>, Berlin, <country country="DE">Germany</country></aff>
    <aff id="ooab025-aff3"><label>3</label><institution>Charité Comprehensive Cancer Center, Charité – Universitätsmedizin Berlin, corporate member of Freie Universität Berlin and Humboldt-Universität zu Berlin</institution>, Berlin, <country country="DE">Germany</country></aff>
    <aff id="ooab025-aff4"><label>4</label><institution>Berlin Institute of Health at Charité – Universitätsmedizin Berlin</institution>, Berlin, <country country="DE">Germany</country></aff>
    <aff id="ooab025-aff5"><label>5</label><institution>Innere Medizin I, Universitätsklinikum Tübingen</institution>, Tübingen, <country country="DE">Germany</country></aff>
    <aff id="ooab025-aff6"><label>6</label><institution>Institut für Translationale Bioinformatik, Universitätsklinikum Tübingen</institution>, Tübingen, <country country="DE">Germany</country></aff>
    <aff id="ooab025-aff7"><label>7</label><institution>Institute for Bioinformatics and Medical Informatics, University of Tübingen</institution>, Tübingen, <country country="DE">Germany</country></aff>
    <aff id="ooab025-aff8"><label>8</label><institution>Department of Computer Science, University of Tübingen</institution>, Tübingen, <country country="DE">Germany</country></aff>
    <aff id="ooab025-aff9"><label>9</label><institution>Biomolecular Interactions, Max Planck Institute for Developmental Biology</institution>, Tübingen, <country country="DE">Germany</country></aff>
    <author-notes>
      <corresp id="ooab025-cor1"><bold>Corresponding Author:</bold> Dr. Ulf Leser, Humboldt-Universität zu Berlin, Institut für Informatik, Unter den Linden 6, 10099 Berlin, Germany; <email>leser@informatik.hu-berlin.de</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>4</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-04-19">
      <day>19</day>
      <month>4</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>19</day>
      <month>4</month>
      <year>2021</year>
    </pub-date>
    <volume>4</volume>
    <issue>2</issue>
    <elocation-id>ooab025</elocation-id>
    <history>
      <date date-type="received">
        <day>11</day>
        <month>1</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>08</day>
        <month>3</month>
        <year>2021</year>
      </date>
      <date date-type="editorial-decision">
        <day>09</day>
        <month>3</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>18</day>
        <month>3</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press on behalf of the American Medical Informatics Association.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ooab025.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Objective</title>
        <p>We present the Berlin-Tübingen-Oncology corpus (BRONCO), a large and freely available corpus of shuffled sentences from German oncological discharge summaries annotated with diagnosis, treatments, medications, and further attributes including negation and speculation. The aim of BRONCO is to foster reproducible and openly available research on Information Extraction from German medical texts.</p>
      </sec>
      <sec id="s2">
        <title>Materials and Methods</title>
        <p>BRONCO consists of 200 manually deidentified discharge summaries of cancer patients. Annotation followed a structured and quality-controlled process involving 2 groups of medical experts to ensure consistency, comprehensiveness, and high quality of annotations. We present results of several state-of-the-art techniques for different IE tasks as baselines for subsequent research.</p>
      </sec>
      <sec id="s3">
        <title>Results</title>
        <p>The annotated corpus consists of 11 434 sentences and 89 942 tokens, annotated with 11 124 annotations for medical entities and 3118 annotations of related attributes. We publish 75% of the corpus as a set of shuffled sentences, and keep 25% as held-out data set for unbiased evaluation of future IE tools. On this held-out dataset, our baselines reach depending on the specific entity types F1-scores of 0.72–0.90 for named entity recognition, 0.10–0.68 for entity normalization, 0.55 for negation detection, and 0.33 for speculation detection.</p>
      </sec>
      <sec id="s4">
        <title>Discussion</title>
        <p>Medical corpus annotation is a complex and time-consuming task. This makes sharing of such resources even more important.</p>
      </sec>
      <sec id="s5">
        <title>Conclusion</title>
        <p>To our knowledge, BRONCO is the first sizable and freely available German medical corpus. Our baseline results show that more research efforts are necessary to lift the quality of information extraction in German medical texts to the level already possible for English.</p>
      </sec>
    </abstract>
    <kwd-group>
      <kwd>medical information extraction</kwd>
      <kwd>German language</kwd>
      <kwd>corpus annotation</kwd>
    </kwd-group>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>German Bundesministerium für Bildung und Forschung (BMBF)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>031L0030B</award-id>
        <award-id>031L0023B</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Deutsche Forschungsgemeinschaft</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001659</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>LE1428/1-1</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Charité – Universitätsmedizin Berlin and the Berlin Institute of Health</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <boxed-text id="ooab025-BOX1" position="float">
    <caption>
      <p>LAY SUMMARY</p>
    </caption>
    <p>In this work we present the Berlin-Tübingen-Oncology (BRONCO) corpus, a German medical text corpus of 200 discharge summaries from the oncology departments of two hospitals. In the corpus mentions of diagnoses, treatments and medications are annotated together with a number of attributes as laterality, negation, and speculation. The corpus will be freely available for the research community for training and evaluating models for information extraction. To our knowledge, BRONCO will be the first freely available German medical corpus. To obey data protection law, we anonymized all documents and shuffled sentences in the publicly available version of the corpus. Consequently, applications are limited to the sentence level. We also provide baselines for named entity recognition, named entity normalization, and negation and speculation detection using state-of-the-art techniques.</p>
  </boxed-text>
  <sec sec-type="intro">
    <title>INTRODUCTION</title>
    <p>Clinical documentation contains a vast amount of patient-specific information, including disease etiology, family background, symptoms, examination results, and treatments. A systematic analysis of large quantities of documents can help to improve clinical care, to support clinical decision making, and to quality-control clinical pathways.<xref rid="ooab025-B1" ref-type="bibr"><sup>1</sup></xref> However, documentation is mostly available in free text format at least in Germany, and its retrospective analysis for a given research hypothesis requires reading and understanding often hundreds or thousands of long and complex texts. Clinical natural language processing (NLP) investigates methods for automated information extraction (IE) specifically designed to process clinical text containing incomplete sentences, complex syntax, medical vocabulary, and idiosyncratic abbreviations. The quality of clinical NLP tools depends on the availability of annotated medical corpora for training and evaluation. Thus, the sharing of annotated corpora is indispensable:<xref rid="ooab025-B2" ref-type="bibr"><sup>2</sup></xref> (1) The performance of different tools can be evaluated and compared, (2) reproducibility of previous results can be checked, and (3) machine-learning based NLP tools can be developed by groups world-wide without the time-consuming effort of corpus annotation, which furthermore requires high levels of medical knowledge.</p>
    <p>To secure patient privacy, sharing of medical reports is only allowed either with explicit patient consent or when texts are fully anonymized. In the United States, HIPAA (Health Insurance Portability and Accountability Act of 1996; <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.hipaajournal.com/de-identification-protected-health-information/" ext-link-type="uri">https://www.hipaajournal.com/de-identification-protected-health-information/</ext-link>) defines anonymization of medical data as the removal of 18 distinct Protected Health Information (PHI) identifiers. Based on these regulations, the NLP community developed tools for automatic deidentification of medical narratives,<xref rid="ooab025-B3" ref-type="bibr"><sup>3–5</sup></xref> which greatly eased the development and publication of annotated corpora, such as MIMIC<xref rid="ooab025-B6" ref-type="bibr"><sup>6</sup></xref> or corpora provided through shared tasks such as i2b2/n2c2 (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/" ext-link-type="uri">https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/</ext-link>), SemEval (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://alt.qcri.org/semeval2014/" ext-link-type="uri">http://alt.qcri.org/semeval2014/</ext-link>), and the CLEF ehealth lab series (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://clef-ehealth.org/" ext-link-type="uri">http://clef-ehealth.org/</ext-link>). The access to corpora, in turn, enabled the development of freely available high-quality IE tools, among them MetaMap and cTakes.<xref rid="ooab025-B7" ref-type="bibr"><sup>7</sup></xref><sup>,</sup><xref rid="ooab025-B8" ref-type="bibr"><sup>8</sup></xref></p>
    <p>Compared to English, development of clinical NLP tools processing German medical text is still in its infancy.<xref rid="ooab025-B9" ref-type="bibr"><sup>9–11</sup></xref> Similar to the United States, anonymized patient data can be shared in principle. However, there exists no clear definition of the PHI identifiers that need to be removed to obtain a fully anonymized medical document. Instead, the decision whether a certain approach achieves anonymization rests with the data protection officers at each institution. It is therefore extremely difficult to (1) obtain medical documents for NLP research outside of hospitals and (2) to share those data with other research groups. Consequently, although several annotation studies on German clinical corpora have been carried out previously, all those corpora are kept closed.<xref rid="ooab025-B12" ref-type="bibr"><sup>12–17</sup></xref> The most recent corpus is 3000PA containing 3000 documents from 3 clinical sites that has been annotated with medication parameters.<xref rid="ooab025-B15" ref-type="bibr"><sup>15</sup></xref> For German clinical texts, there are also no freely available IE or anonymization tools, and the reported quality of IE methods on closed corpora can neither be evaluated independently nor reproduced externally. <xref rid="sup1" ref-type="supplementary-material">Supplementary Table</xref><xref rid="sup1" ref-type="supplementary-material">S1</xref> gives key characteristics of selected clinical corpora used for IE for different languages, showing that several corpora for languages other than German are freely available for years, especially for English.</p>
    <p>In this work, we present the freely available Berlin-Tübingen-Oncology corpus (BRONCO). It consists of shuffled sentences from 200 German discharge summaries from cancer patients annotated with medical entities (BRONCO was created by the nationally funded project “Personalizing Oncology via Semantic Integration of Data” (PersOnS), see <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://persons-project.informatik.uni-tuebingen.de/" ext-link-type="uri">https://persons-project.informatik.uni-tuebingen.de/</ext-link>). The ultimate aim of BRONCO is to foster the development of high-quality NLP tools for extracting the precise disease history of cancer patients. As a first step toward this goal, we manually anonymized documents and annotated diagnoses, treatments, and medication. Additionally, medical entities were annotated with attributes (laterality, negation, speculation, and possible in the future). We also created baselines for a set of IE tasks using state-of-the-art technologies.</p>
    <p>To allow unbiased evaluation of IE tools, we randomly split the corpus in 2 parts: The larger subset, BRONCO150, contains 8976 sentences and 8760 annotations and is available under a liberal license for training and evaluation of IE tools (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www2.informatik.hu-berlin.de/~leser/bronco/index.html" ext-link-type="uri">https://www2.informatik.hu-berlin.de/∼leser/bronco/index.html</ext-link>). The second subset, BRONCO50, with 2458 sentences and 2364 annotations, is kept closed as held-out data. As a further mean to prevent deanonymization sentences in both corpora are randomly shuffled. In the future, we will offer the service to evaluate new IE tools on BRONCO50 in our lab.</p>
  </sec>
  <sec>
    <title>MATERIALS AND METHODS</title>
    <sec>
      <title>Corpus design and preprocessing</title>
      <p>We randomly selected 200 discharge summaries of patients suffering from hepatocellular carcinoma or melanoma treated between 2013 and 2016 at the university hospitals in Berlin or Tübingen. After careful anonymization the study on this data and publication of BRONCO was approved by the Data Protection Officers of both hospitals and the ethics committee of Charité (EA1/322/20). Documents were extracted from electronic patient records, converted to plain text, and manually anonymized by 1 or 2 clinicians at each hospital. Anonymization included removal of direct identifiers as names, age, contact details, IDs, and locations. Dates, persons, and hospital names were preannotated using regular expressions with the annotation tool <italic toggle="yes">Ellogon</italic> (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.ellogon.org/index.php/annotation-tool" ext-link-type="uri">http://www.ellogon.org/index.php/annotation-tool</ext-link>). All dates within each document were automatically modified by a fixed number of days to keep chronological order of events. The number of days was chosen randomly for each document.</p>
    </sec>
    <sec>
      <title>Annotation scope</title>
      <p>At first, we annotated section headings in all discharge summaries (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> for details). In specific sections, we annotated medical entities that are particularly important for the disease history of cancer patients, namely: diagnosis, treatment, and medication. As a common practice in NLP research, by “medical entities,” we mean linguistic entities, that is, word or phrases that designate objects or processes relevant in health, including expressions clinicians use to describe patient-related matters. For terminology grounding (normalization) of medical entities, we utilized terminologies commonly used in clinical practice in Germany. A diagnosis is a disease, a symptom or a medical observation that can be matched with the German Modification of the International Classification of Diseases (ICD10; <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.dimdi.de/dynamic/de/klassifikationen/icd/icd-10-gm/" ext-link-type="uri">www.dimdi.de/dynamic/de/klassifikationen/icd/icd-10-gm/</ext-link>). A treatment is a diagnostic procedure, an operation or a systemic cancer treatment that can be found in the Operationen und Prozedurenschlüssel (OPS; <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.dimdi.de/dynamic/de/klassifikationen/ops/" ext-link-type="uri">www.dimdi.de/dynamic/de/klassifikationen/ops/</ext-link>). A medication names a pharmaceutical substance or a drug that can be related to the Anatomical Therapeutic Chemical Classification System (ATC; <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.dimdi.de/dynamic/de/arzneimittel/atc-klassifikation/" ext-link-type="uri">www.dimdi.de/dynamic/de/arzneimittel/atc-klassifikation/</ext-link>). Examples for each entity type are shown in <xref rid="ooab025-F1" ref-type="fig">Figure 1</xref>. Whenever applicable, medical entities were annotated with laterality (right, left, and both sided), negation (e.g., a diagnosis is ruled out or a medication is paused), speculation (e.g., a diagnosis is unclear), or whether it is expressed as a possible future event (e.g., a procedure is planned for the future). Examples for each attribute are shown in lines 1–5 in <xref rid="ooab025-F1" ref-type="fig">Figure 1</xref>. We defined a number of rules in our annotation guideline (available on the BRONCO website) to clarify any ambiguous situation we encountered in our corpus. These rules are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Appendix</xref> A.</p>
      <fig position="float" id="ooab025-F1">
        <label>Figure 1.</label>
        <caption>
          <p>Exemplary excerpts from original discharge summaries and annotations, shown in BRAT visualization. Attributes in brackets have the following meaning: laterality right (R), negated entity (negative), speculative entity (speculative), and entity possible in the future (possibleFuture). Additionally, codes resulting from entity normalization are given in brackets.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ooab025f1" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>Annotation process</title>
      <p>The annotation process was conducted by an annotation leader who prepared documents for annotation, developed annotation guidelines together with the medical experts, and organized conflict resolution but did not perform any annotations. For organizational reasons, annotations were performed by 2 groups of annotators, group A (2 medical experts) and group B (3 medical experts and 3 medical students). Annotation guidelines were developed by the annotation leader and group A using 9 documents (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Appendix</xref> B); adaptations required by situations encountered only later were possible. An overview of the complete annotation process is illustrated in <xref rid="ooab025-F2" ref-type="fig">Figure 2</xref>. Technically, we used the Brat Rapid Annotation Tool (BRAT).<xref rid="ooab025-B18" ref-type="bibr"><sup>18</sup></xref></p>
      <fig position="float" id="ooab025-F2">
        <label>Figure 2.</label>
        <caption>
          <p>Annotation procedure including deidentification, annotation of section titles, and annotation of medical entities with attributes. Altogether, 1 annotation leader and 9 medical annotators were involved in different parts of the process.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ooab025f2" position="float"/>
      </fig>
      <p>Group A annotated 87 documents, of which 32 documents were double annotated for quality control. Differences in annotations were discussed with the annotation leader and resolved based on the guidelines and mutual agreement. To speed up annotation, we preannotated 59 documents with frequently annotated phrases, such as “<italic toggle="yes">CT Thorax/Abdomen/Becken”</italic> (computed tomography of thorax, abdomen, and pelvis), using exact matching. Annotators had to check and correct preannotations.</p>
      <p>Group B annotated 113 documents. Here, we used a different procedure because medical students performed differently well during training. First, 3 medical students double annotated all documents without preannotations. Then the 3 medical experts of group B resolved conflicts using BRAT as shown in <xref rid="ooab025-F3" ref-type="fig">Figure 3</xref>. Training of annotators and considerations that lead to this procedure are described in <xref rid="sup1" ref-type="supplementary-material">Supplementary Appendix</xref> B.</p>
      <fig position="float" id="ooab025-F3">
        <label>Figure 3.</label>
        <caption>
          <p>Visualization of mismatches between annotations of 2 annotators, shown in BRAT visualization. (A) One of the annotations misses Laterality R and (B) “Oberbauchsonographie” (sonography of the upper abdomen) is annotated only by 1 annotator and “Ausschluss von Leberfiliae” (exclusion of liver metastasis) is annotated with different text spans and only once with attribute possibleFuture.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ooab025f3" position="float"/>
      </fig>
      <p>Interannotator agreement (IAA) is calculated as microaveraged phrase-level F1-score<xref rid="ooab025-B19" ref-type="bibr"><sup>19</sup></xref> before conflict resolution. We used phrase-level IAA, because most diagnosis and treatment annotations comprise of multiple tokens like “<italic toggle="yes">hepatozelluläres Karzinom</italic>” (hepatocellular carcinoma). In such cases, phrase-level IAA is more suitable than token-level IAA as phrases with different boundaries are detected as disagreement and can be resolved during conflict resolution. We used average F1-score instead of Cohen’s <italic toggle="yes">κ</italic> as the number of negative (not marked) phrases is poorly defined.<xref rid="ooab025-B20" ref-type="bibr"><sup>20</sup></xref></p>
    </sec>
    <sec>
      <title>Corpus creation</title>
      <p>After annotation, the corpus was split in 2 parts containing only annotated sections of 150 and 50 documents, referred to as BRONCO150 and BRONCO50, respectively. In each part, sentences were split based on punctuation. To avoid splitting sentence after abbreviations like “Z.n.” (condition after), we used a list of common German medical abbreviations retrieved from Wikipedia (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://de.wikipedia.org/wiki/Medizinische_Abk%C3%BCrzungen" ext-link-type="uri">https://de.wikipedia.org/wiki/Medizinische_Abk%C3%BCrzungen</ext-link>) as exceptions. As an additional measure against potential deanonymization, we randomly shuffled sentences within each part of BRONCO. Finally, we further split BRONCO150 into 5 sets for allowing reproducible cross validation.</p>
      <p>We performed 2 analyses on BRONCO150 to evaluate the effect of shuffling sentences. First, we calculated similarity scores between sentences originating from the same document and those coming from different documents. Secondly, we tried to reconstruct the original documents through clustering of sentences. We performed hierarchical clustering to segment the sentences into 150 groups, that is, 1 group per original document. For each group, we measure from how many documents the sentences originate. For both analyses, we used cosine similarity over TF-IDF representations of the documents.</p>
    </sec>
    <sec>
      <title>Baseline methods for information extraction</title>
      <p>We developed baseline tools using state-of-the-art techniques for named entity recognition (NER), named entity normalization (NEN), and detection of negated and uncertain entities. Performances of all baselines were measured as microaveraged precision, recall and F1. To this end, both BRONCO corpora were tokenized and tagged with part-of-speech using JCORE models that have been trained on a closed German clinical corpus (FRAMED).<xref rid="ooab025-B21" ref-type="bibr"><sup>21</sup></xref><sup>,</sup><xref rid="ooab025-B22" ref-type="bibr"><sup>22</sup></xref> Gold standard annotations were used to convert the corpora to IOB format.</p>
      <sec>
        <title>Named entity recognition</title>
        <p>We applied the conditional random fields (CRF) implementation <italic toggle="yes">CRFsuite</italic><xref rid="ooab025-B23" ref-type="bibr"><sup>23</sup></xref> and a bidirectional long short-term memory network with a final CRF layer (LSTM-CRF),<xref rid="ooab025-B24" ref-type="bibr"><sup>24</sup></xref> respectively. For both, CRF and LSTM-CRF, we used default feature sets plus a number of further lexical and orthographic features. We also tested the impact of FastText embeddings trained on German Wikipedia articles.<xref rid="ooab025-B25" ref-type="bibr"><sup>25</sup></xref> CRF and LSTM-CRF models were evaluated with 5-fold cross validation on BRONCO150 and trained on the full BRONCO150 corpus for evaluation on the held-out corpus.</p>
      </sec>
      <sec>
        <title>Named entity normalization</title>
        <p>We implemented a simple approach using a dictionary lookup with Apache Solr 7.5.0 (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://lucene.apache.org/" ext-link-type="uri">https://lucene.apache.org/</ext-link>) followed by a reranking of candidates using the inference method from.<xref rid="ooab025-B26" ref-type="bibr"><sup>26</sup></xref> Additionally to the dictionaries used for annotation, we applied Rote Liste (Rote Liste, Service GmbH, 2/2019) for mentions of branded drug names. To evaluate NEN, gold standard entity annotations were extracted from the BRONCO corpora and subjected to normalization.</p>
      </sec>
      <sec>
        <title>Negation and speculation detection</title>
        <p>We applied <italic toggle="yes">NegEx</italic>,<xref rid="ooab025-B27" ref-type="bibr"><sup>27</sup></xref> which detects negated and uncertain (speculated) entities using a list of trigger terms and rules for defining their scope. We applied the original list of German trigger terms from<xref rid="ooab025-B28" ref-type="bibr"><sup>28</sup></xref> as well as an updated list from.<xref rid="ooab025-B29" ref-type="bibr"><sup>29</sup></xref> For evaluation, all sentences and gold standard entity annotations were fed into <italic toggle="yes">NegEx</italic>.</p>
        <p>More details on all applied methods are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Appendix</xref> C.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results">
    <title>RESULTS</title>
    <p>We first report on the estimated quality and frequency of annotated entities in BRONCO and both subsets. Next, we study whether shuffling of sentences in BRONCO150 actually prevents reconstruction of documents. Finally, we report, separately for both parts of BRONCO, on baseline results for information extraction using state-of-the-art techniques.</p>
    <sec>
      <title>Quality of annotations</title>
      <p>The quality of annotation is measured separately for annotation and normalization of medical entities and attributes for both groups of annotators (A and B). <xref rid="ooab025-T1" ref-type="table">Table 1</xref> shows the IAA for all double annotated documents for group A (32 documents) and group B (113 documents). Annotation of text spans reaches high agreement for all medical entities in group A (IAA 0.81–0.94). Agreement for normalization is also high with IAA 0.73–0.90. For both levels of annotation quality, text span and normalization, agreement increases from treatment to diagnosis to medication. Also, the agreement between annotations of attributes is high, especially for negation and laterality with IAA of 0.81 and 0.75, respectively. Agreement is generally lower for group B: 0.66–0.87 for text spans, 0.47–0.75 for normalization, and 0.37–0.53 for attributes. Note that all conflicting annotations were manually resolved in the final BRONCO.</p>
      <table-wrap position="float" id="ooab025-T1">
        <label>Table 1.</label>
        <caption>
          <p>Interannotator agreement (IAA) calculated as microaveraged phrase-level F1 for 2 corpus sets annotated by 2 groups of annotators (A, B)</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th colspan="3" align="center" rowspan="1">Group A<hr/></th>
              <th colspan="3" align="center" rowspan="1">Group B<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">Annotation type</th>
              <th rowspan="1" colspan="1">No. of instances</th>
              <th rowspan="1" colspan="1">Text span</th>
              <th rowspan="1" colspan="1">Code/attribute</th>
              <th rowspan="1" colspan="1">No. of instances</th>
              <th rowspan="1" colspan="1">Text span</th>
              <th rowspan="1" colspan="1">Code/attribute</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Diagnosis</td>
              <td rowspan="1" colspan="1">734</td>
              <td rowspan="1" colspan="1">0.88 (0.94)</td>
              <td rowspan="1" colspan="1">0.84</td>
              <td rowspan="1" colspan="1">2860</td>
              <td rowspan="1" colspan="1">0.69 (0.79)</td>
              <td rowspan="1" colspan="1">0.54</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Treatment</td>
              <td rowspan="1" colspan="1">522</td>
              <td rowspan="1" colspan="1">0.81 (0.93)</td>
              <td rowspan="1" colspan="1">0.73</td>
              <td rowspan="1" colspan="1">1730</td>
              <td rowspan="1" colspan="1">0.66 (0.77)</td>
              <td rowspan="1" colspan="1">0.47</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Medication</td>
              <td rowspan="1" colspan="1">300</td>
              <td rowspan="1" colspan="1">0.94 (0.96)</td>
              <td rowspan="1" colspan="1">0.90</td>
              <td rowspan="1" colspan="1">927</td>
              <td rowspan="1" colspan="1">0.87 (0.92)</td>
              <td rowspan="1" colspan="1">0.75</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Laterality</td>
              <td rowspan="1" colspan="1">104</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">0.75</td>
              <td rowspan="1" colspan="1">452</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">0.53</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Negation</td>
              <td rowspan="1" colspan="1">76</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">0.81</td>
              <td rowspan="1" colspan="1">319</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">0.50</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Speculation</td>
              <td rowspan="1" colspan="1">81</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">0.69</td>
              <td rowspan="1" colspan="1">288</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">0.44</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Possible Future</td>
              <td rowspan="1" colspan="1">37</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">0.68</td>
              <td rowspan="1" colspan="1">244</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">0.37</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic toggle="yes">Note:</italic> IAA was calculated before conflict resolution. For text spans, IAA is also given as (token level) Cohen’s <italic toggle="yes">κ</italic> in paratheses. Number of double annotated documents: group A (32) and group B (113).</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>Frequency of entities</title>
      <p>Corpus statistics and frequencies of annotated entities for both parts of BRONCO as well as for the complete corpus are shown in <xref rid="ooab025-T2" ref-type="table">Table 2</xref>. Overall, BRONCO contains 11 124 annotations of medical entities and 3118 annotations of attributes. Most frequent annotations are diagnosis (5245), followed by treatment (3866) and medication (2013). Judged by the number of unique instances (26–45% of all annotations), the vocabulary is quite versatile for each type of entity. Overall, 1256 medical entities (10%) are related to a specific laterality, and about 15% are either negated (630 entities), speculated (613 entities), or may possibly occur in the future (619 entities). Overall, 796 medical entities (7%) are noncontinuous.</p>
      <table-wrap position="float" id="ooab025-T2">
        <label>Table 2.</label>
        <caption>
          <p>Frequency of annotated medical entities and attributes in BRONCO and its 2 subsets, together with general statistics</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Annotation type</th>
              <th rowspan="1" colspan="1">BRONCO150</th>
              <th rowspan="1" colspan="1">BRONCO50</th>
              <th rowspan="1" colspan="1">BRONCO complete</th>
              <th rowspan="1" colspan="1">Unique instances</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Diagnosis</td>
              <td rowspan="1" colspan="1">4080</td>
              <td rowspan="1" colspan="1">1165</td>
              <td rowspan="1" colspan="1">5245</td>
              <td rowspan="1" colspan="1">2394</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Treatment</td>
              <td rowspan="1" colspan="1">3050</td>
              <td rowspan="1" colspan="1">816</td>
              <td rowspan="1" colspan="1">3866</td>
              <td rowspan="1" colspan="1">1101</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Medication</td>
              <td rowspan="1" colspan="1">1630</td>
              <td rowspan="1" colspan="1">383</td>
              <td rowspan="1" colspan="1">2013</td>
              <td rowspan="1" colspan="1">532</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Total medical entities</td>
              <td rowspan="1" colspan="1">8760</td>
              <td rowspan="1" colspan="1">2364</td>
              <td rowspan="1" colspan="1">11 124</td>
              <td rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Laterality</td>
              <td rowspan="1" colspan="1">1033</td>
              <td rowspan="1" colspan="1">223</td>
              <td rowspan="1" colspan="1">1256</td>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Negation</td>
              <td rowspan="1" colspan="1">503</td>
              <td rowspan="1" colspan="1">127</td>
              <td rowspan="1" colspan="1">630</td>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Speculation</td>
              <td rowspan="1" colspan="1">474</td>
              <td rowspan="1" colspan="1">139</td>
              <td rowspan="1" colspan="1">613</td>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Possible future</td>
              <td rowspan="1" colspan="1">479</td>
              <td rowspan="1" colspan="1">140</td>
              <td rowspan="1" colspan="1">619</td>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Total attributes</td>
              <td rowspan="1" colspan="1">2489</td>
              <td rowspan="1" colspan="1">629</td>
              <td rowspan="1" colspan="1">3118</td>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">#Documents</td>
              <td rowspan="1" colspan="1">150</td>
              <td rowspan="1" colspan="1">50</td>
              <td rowspan="1" colspan="1">200</td>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">#Sentences</td>
              <td rowspan="1" colspan="1">8976</td>
              <td rowspan="1" colspan="1">2458</td>
              <td rowspan="1" colspan="1">11 434</td>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">#Tokens</td>
              <td rowspan="1" colspan="1">70 572</td>
              <td rowspan="1" colspan="1">19 370</td>
              <td rowspan="1" colspan="1">89 942</td>
              <td rowspan="1" colspan="1"/>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic toggle="yes">Note:</italic> Unique instances are the number of unique mentions within the complete corpus.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>No reconstruction of documents</title>
      <p>First, we compared the similarity of sentences in BRONCO150. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref> shows the distributions of pairwise similarities for sentences of the same (left) and different original documents (right) having at least 1 word in common. There is almost no difference regarding in- and cross-document sentence pairs. Furthermore, about 90% of all sentence pairs do not share a single word and therefore have zero similarity in the 1-hot encoding we applied here (note that these pairs were excluded to create <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref>, since otherwise the boxplots degenerate to flat lines). Furthermore, we studied how much a hierarchical clustering of sentences (with cutoffs to create 150 clusters) reconstructs the original documents. <xref rid="ooab025-F4" ref-type="fig">Figure 4</xref> shows the distribution of numbers of documents per cluster. On average, clusters consist of 60 sentences originating from 22 different documents. There are only 3 clusters having sentences just from a single original document. These clusters contain only 10–13 sentences which cover 6–21% of a complete document. As there are also 18 clusters of similar sizes and similar average pairwise similarity between cluster members, we see no way of identifying pure (yet still very incomplete) clusters without knowledge of the original document.</p>
      <fig position="float" id="ooab025-F4">
        <label>Figure 4.</label>
        <caption>
          <p>Distribution of documents per cluster after hierarchical clustering of sentences in BRONCO150.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ooab025f4" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>Performance of IE baselines</title>
      <sec>
        <title>Named entity recognition</title>
        <p>We compared the performance of a CRF and a LSTM-CRF with and without using German (nonbiomedical) word embeddings. Results are listed in <xref rid="ooab025-T3" ref-type="table">Table 3</xref>. On the BRONCO150 subset, the CRF approach outperforms LSTM-CRF by ∼3pp F1 on diagnosis, by ∼1pp on treatment, and by ∼2pp on medication; differences are very similar on the BRONCO50 subset. Word embeddings have only marginal impact on the CRF, but considerably improve performance of the LSTM-CRF approach (+5pp, +3pp, and +3pp for diagnosis, treatment, and medication, respectively). A notable difference exists between the results for diagnosis and treatment on BRONCO150 versus BRONCO50 for both approaches, where F1 scores are lower for the held-out part. We attribute this drop to the fact that results for BRONCO150 are obtained using cross-validation over randomly shuffled sentences, which means that sentences from the same document often are contained in the training and the test data. This increases the chances that individual entities of the test split already have been seen in the training data. Though this might be considered as a form of information leakage, we decided against creating the folds in BRONCO150 at the level of documents, as this would make document reconstruction easier and reidentification of individuals possible. Clearly, results for the BRONCO50 subset should be considered as more realistic.</p>
        <table-wrap position="float" id="ooab025-T3">
          <label>Table 3.</label>
          <caption>
            <p>Performance for baseline methods for NEN and NER (CRF and LSTM-CRF) with and without pretrained word embeddings (WE)</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="(" span="1"/>
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="(" span="1"/>
              <col valign="top" align="char" char="(" span="1"/>
              <col valign="top" align="char" char="(" span="1"/>
              <col valign="top" align="char" char="(" span="1"/>
              <col valign="top" align="char" char="(" span="1"/>
              <col valign="top" align="char" char="(" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="2" colspan="1">Annotation type</th>
                <th rowspan="2" colspan="1">Task</th>
                <th rowspan="2" colspan="1">Method</th>
                <th colspan="3" align="center" rowspan="1">BRONCO150<hr/></th>
                <th colspan="3" align="center" rowspan="1">BRONCO50<hr/></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">P</td>
                <td rowspan="1" colspan="1">R</td>
                <td rowspan="1" colspan="1">F1</td>
                <td rowspan="1" colspan="1">P</td>
                <td rowspan="1" colspan="1">R</td>
                <td rowspan="1" colspan="1">F1</td>
              </tr>
              <tr>
                <td rowspan="5" colspan="1">Diagnosis</td>
                <td rowspan="4" colspan="1">NER</td>
                <td rowspan="1" colspan="1">CRF</td>
                <td rowspan="1" colspan="1"><bold>0.80</bold>(0.01)</td>
                <td rowspan="1" colspan="1"><bold>0.71</bold>(0.02)</td>
                <td rowspan="1" colspan="1"><bold>0.75</bold>(0.02)</td>
                <td rowspan="1" colspan="1">
                  <bold>0.79</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.67</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.72</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CRF+WE</td>
                <td rowspan="1" colspan="1">0.782(0.006)</td>
                <td rowspan="1" colspan="1">0.70(0.02)</td>
                <td rowspan="1" colspan="1">0.74(0.01)</td>
                <td rowspan="1" colspan="1">0.77</td>
                <td rowspan="1" colspan="1">
                  <bold>0.66</bold>
                </td>
                <td rowspan="1" colspan="1">0.71</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">LSTM</td>
                <td rowspan="1" colspan="1">0.75(0.03)</td>
                <td rowspan="1" colspan="1">0.69(0.03)</td>
                <td rowspan="1" colspan="1">0.72(0.01)</td>
                <td rowspan="1" colspan="1">0.78</td>
                <td rowspan="1" colspan="1">0.65</td>
                <td rowspan="1" colspan="1">0.71</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">LSTM+WE</td>
                <td rowspan="1" colspan="1"><bold>0.81</bold>(0.08)</td>
                <td rowspan="1" colspan="1"><bold>0.74</bold>(0.08)</td>
                <td rowspan="1" colspan="1"><bold>0.77</bold>(0.08)</td>
                <td rowspan="1" colspan="1">
                  <bold>0.79</bold>
                </td>
                <td rowspan="1" colspan="1">0.65</td>
                <td rowspan="1" colspan="1">
                  <bold>0.72</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">NEN</td>
                <td rowspan="1" colspan="1">Dictionary lookup</td>
                <td rowspan="1" colspan="1">0.58</td>
                <td rowspan="1" colspan="1">0.54</td>
                <td rowspan="1" colspan="1">0.56</td>
                <td rowspan="1" colspan="1">0.54</td>
                <td rowspan="1" colspan="1">0.50</td>
                <td rowspan="1" colspan="1">0.52</td>
              </tr>
              <tr>
                <td rowspan="5" colspan="1">Treatment</td>
                <td rowspan="4" colspan="1">NER</td>
                <td rowspan="1" colspan="1">CRF</td>
                <td rowspan="1" colspan="1"><bold>0.86</bold>(0.02)</td>
                <td rowspan="1" colspan="1">0.78(0.01)</td>
                <td rowspan="1" colspan="1"><bold>0.82</bold>(0.01)</td>
                <td rowspan="1" colspan="1">0.83</td>
                <td rowspan="1" colspan="1">
                  <bold>0.73</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.78</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CRF+WE</td>
                <td rowspan="1" colspan="1">0.85(0.02)</td>
                <td rowspan="1" colspan="1">0.78(0.01)</td>
                <td rowspan="1" colspan="1">0.81(0.01)</td>
                <td rowspan="1" colspan="1">
                  <bold>0.81</bold>
                </td>
                <td rowspan="1" colspan="1">0.73</td>
                <td rowspan="1" colspan="1">
                  <bold>0.76</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">LSTM</td>
                <td rowspan="1" colspan="1">0.83(0.04)</td>
                <td rowspan="1" colspan="1"><bold>0.79</bold>(0.03)</td>
                <td rowspan="1" colspan="1">0.81(0.02)</td>
                <td rowspan="1" colspan="1">
                  <bold>0.85</bold>
                </td>
                <td rowspan="1" colspan="1">0.69</td>
                <td rowspan="1" colspan="1">0.76</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">LSTM+WE</td>
                <td rowspan="1" colspan="1">0.85(0.06)</td>
                <td rowspan="1" colspan="1">0.82(0.07)</td>
                <td rowspan="1" colspan="1">0.84(0.06)</td>
                <td rowspan="1" colspan="1">0.76</td>
                <td rowspan="1" colspan="1">0.74</td>
                <td rowspan="1" colspan="1">0.75</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">NEN</td>
                <td rowspan="1" colspan="1">Dictionary lookup</td>
                <td rowspan="1" colspan="1">0.18</td>
                <td rowspan="1" colspan="1">0.13</td>
                <td rowspan="1" colspan="1">0.15</td>
                <td rowspan="1" colspan="1">0.15</td>
                <td rowspan="1" colspan="1">0.12</td>
                <td rowspan="1" colspan="1">0.13</td>
              </tr>
              <tr>
                <td rowspan="5" colspan="1">Medication</td>
                <td rowspan="4" colspan="1">NER</td>
                <td rowspan="1" colspan="1">CRF</td>
                <td rowspan="1" colspan="1"><bold>0.96</bold>(0.008)</td>
                <td rowspan="1" colspan="1">0.85(0.02)</td>
                <td rowspan="1" colspan="1"><bold>0.90</bold>(0.009)</td>
                <td rowspan="1" colspan="1">0.94</td>
                <td rowspan="1" colspan="1">
                  <bold>0.87</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.90</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CRF+WE</td>
                <td rowspan="1" colspan="1">0.96(0.004)</td>
                <td rowspan="1" colspan="1">0.84(0.009)</td>
                <td rowspan="1" colspan="1">0.90(0.006)</td>
                <td rowspan="1" colspan="1">
                  <bold>0.95</bold>
                </td>
                <td rowspan="1" colspan="1">0.85</td>
                <td rowspan="1" colspan="1">0.90</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">LSTM</td>
                <td rowspan="1" colspan="1">0.91(0.05)</td>
                <td rowspan="1" colspan="1"><bold>0.86</bold>(0.03)</td>
                <td rowspan="1" colspan="1">0.88(0.02)</td>
                <td rowspan="1" colspan="1">
                  <bold>0.95</bold>
                </td>
                <td rowspan="1" colspan="1">0.85</td>
                <td rowspan="1" colspan="1">0.89</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">LSTM+WE</td>
                <td rowspan="1" colspan="1">0.96(0.02)</td>
                <td rowspan="1" colspan="1"><bold>0.87</bold>(0.06)</td>
                <td rowspan="1" colspan="1"><bold>0.91</bold>(0.04)</td>
                <td rowspan="1" colspan="1">0.91</td>
                <td rowspan="1" colspan="1">
                  <bold>0.89</bold>
                </td>
                <td rowspan="1" colspan="1">0.90</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">NEN</td>
                <td rowspan="1" colspan="1">Dictionary lookup</td>
                <td rowspan="1" colspan="1">0.66</td>
                <td rowspan="1" colspan="1">0.68</td>
                <td rowspan="1" colspan="1">0.67</td>
                <td rowspan="1" colspan="1">0.64</td>
                <td rowspan="1" colspan="1">0.69</td>
                <td rowspan="1" colspan="1">0.66</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn3">
              <p><italic toggle="yes">Note:</italic> Results for BRONCO150 are averaged over 5-fold with standard deviation in brackets. Best (highest) values per entity type, corpus, and w/o WE are bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <title>Named entity normalization</title>
        <p>We applied a dictionary lookup approach combined with a candidate reranking. Results are listed in <xref rid="ooab025-T3" ref-type="table">Table 3</xref>. We find the best performance in terms of F1 for medication (0.67 and 0.66) followed by diagnosis (0.56 and 0.52) for BRONCO150 and BRONCO50, respectively. For treatment, performance only reaches F1 0.15 (BRONCO150) and F1 0.13 (BRONCO50).</p>
      </sec>
      <sec>
        <title>Negation and speculation detection</title>
        <p>We applied NegEx using 2 available lists of trigger terms, Chapman et al<xref rid="ooab025-B28" ref-type="bibr"><sup>28</sup></xref> and Cotik et al.<xref rid="ooab025-B29" ref-type="bibr"><sup>29</sup></xref> Using the Chapman list, negation detection reaches F1 0.44 (BRONCO150) and F1 0.37 (BRONCO50), as shown in <xref rid="ooab025-T4" ref-type="table">Table 4</xref>. Speculation detection is worse. F1 only reaches 0.02 and 0.09 on BRONCO150 and BRONCO50, respectively. The recently published Cotik list improves results, but F1 scores nevertheless do not exceed 0.55 for negation and 0.33 for speculation detection in both corpora.</p>
        <table-wrap position="float" id="ooab025-T4">
          <label>Table 4.</label>
          <caption>
            <p>Negation and speculation detection of entities using NegEx with 2 lists of German trigger terms: Chapman et al<xref rid="ooab025-B28" ref-type="bibr"><sup>28</sup></xref> and Cotik et al<xref rid="ooab025-B29" ref-type="bibr"><sup>29</sup></xref></p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1"/>
                <th colspan="4" rowspan="1">BRONCO150<hr/></th>
                <th colspan="4" rowspan="1">BRONCO50<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1">Annotation type</th>
                <th rowspan="1" colspan="1">Trigger list</th>
                <th rowspan="1" colspan="1">#GSC</th>
                <th rowspan="1" colspan="1">P</th>
                <th rowspan="1" colspan="1">R</th>
                <th rowspan="1" colspan="1">F1</th>
                <th rowspan="1" colspan="1">#GSC</th>
                <th rowspan="1" colspan="1">P</th>
                <th rowspan="1" colspan="1">R</th>
                <th rowspan="1" colspan="1">F1</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="2" colspan="1">Negation</td>
                <td rowspan="1" colspan="1">Chapman</td>
                <td rowspan="1" colspan="1">503</td>
                <td rowspan="1" colspan="1">0.57</td>
                <td rowspan="1" colspan="1">0.35</td>
                <td rowspan="1" colspan="1">0.44</td>
                <td rowspan="1" colspan="1">127</td>
                <td rowspan="1" colspan="1">0.45</td>
                <td rowspan="1" colspan="1">0.31</td>
                <td rowspan="1" colspan="1">0.37</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Cotik</td>
                <td rowspan="1" colspan="1">503</td>
                <td rowspan="1" colspan="1">
                  <bold>0.62</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.50</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.55</bold>
                </td>
                <td rowspan="1" colspan="1">127</td>
                <td rowspan="1" colspan="1">
                  <bold>0.52</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.55</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.54</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="2" colspan="1">Speculation</td>
                <td rowspan="1" colspan="1">Chapman</td>
                <td rowspan="1" colspan="1">474</td>
                <td rowspan="1" colspan="1">0.13</td>
                <td rowspan="1" colspan="1">0.01</td>
                <td rowspan="1" colspan="1">0.02</td>
                <td rowspan="1" colspan="1">139</td>
                <td rowspan="1" colspan="1">0.26</td>
                <td rowspan="1" colspan="1">0.06</td>
                <td rowspan="1" colspan="1">0.09</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Cotik</td>
                <td rowspan="1" colspan="1">474</td>
                <td rowspan="1" colspan="1">
                  <bold>0.54</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.24</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.33</bold>
                </td>
                <td rowspan="1" colspan="1">139</td>
                <td rowspan="1" colspan="1">
                  <bold>0.71</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.22</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.33</bold>
                </td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
    </sec>
  </sec>
  <sec sec-type="discussion">
    <title>DISCUSSION</title>
    <p>We present the BRONCO, a large and freely available corpus of German oncological discharge summaries. The corpus consists of shuffled sentences and is annotated with medical entities (diagnosis, treatment, medication) and their attributes (laterality, negation, speculation, possible in the future). Additionally, we developed baselines for NER, NEN, and negation and speculation detection and evaluated them on 2 subsets of the corpus. BRONCO150 will be published openly. Application of BRONCO is limited to sentence-level IE tasks. Nevertheless, we believe BRONCO can have a positive impact on German clinical NLP because it is the first sizable corpus that will become freely available.</p>
    <p>Some previously built German medical corpora for IE exceed the size of BRONCO. For instance, 3000PA, created by large German research consortium (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.medizininformatik-initiative.de/" ext-link-type="uri">https://www.medizininformatik-initiative.de/</ext-link>), contains 3000 documents annotated with medication and related parameters.<xref rid="ooab025-B15" ref-type="bibr"><sup>15</sup></xref> A subset of 3000PA annotated with diagnosis, findings, and symptoms contains 1.5M tokens.<xref rid="ooab025-B17" ref-type="bibr"><sup>17</sup></xref> However, none of these is publicly available. The main reason for this situation undoubtedly is the uncertainty among researchers and data protection officers when a corpus can be given the status of being “fully anonymized,” as required by German and European regulations. We reacted in 3 ways to this issue: first, the corpus was completely manually deidentified. This process was confirmed by Charité and UKT data protection officers. Second, we only annotate and publish certain sections of the discharge summaries, avoiding all sections containing mostly biographic information. Third, we shuffled all sentences in the 2 subcorpora to blur their order and relationships. We performed an attempt to break this shuffling using sentence clustering and showed that it failed. Our method for this attempt has, however, limitations. The most important one probably is that in our 1-hot encoding words must appear syntactically identical to be matched between sentences, ignoring their semantics. One could try to overcome the limitation by using precomputed language models.<xref rid="ooab025-B25" ref-type="bibr"><sup>25</sup></xref><sup>,</sup><xref rid="ooab025-B30" ref-type="bibr"><sup>30</sup></xref><sup>,</sup><xref rid="ooab025-B31" ref-type="bibr"><sup>31</sup></xref> However, extremely large and domain-specific corpora necessary to train good language models are either not available or kept closed. The same is true for any potentially existing language models.</p>
    <p>BRONCO provides high-quality annotations (1) because in all double annotated documents (145 out of 200) conflicts were dissolved in a controlled process and (2) because all single annotated documents were annotated by persons that achieved high IAA with their peers for all levels of annotation. The IAA for entity annotation (0.69–0.88 for diagnosis, 0.66–0.81 for treatment, and 0.87–0.94 for medication) is comparable to previous annotations studies:<xref rid="ooab025-B15" ref-type="bibr"><sup>15</sup></xref> achieved 0.88–0.99 for medication and<xref rid="ooab025-B17" ref-type="bibr"><sup>17</sup></xref> reached 0.637 for diagnosis. Annotation studies on English clinical corpora are in the range of 0.7–0.88 (F1) or 0.73 (Cohen’s <italic toggle="yes">κ</italic>) for entities like disorder, procedures, or chemicals and drugs.<xref rid="ooab025-B8" ref-type="bibr"><sup>8</sup></xref><sup>,</sup><xref rid="ooab025-B32" ref-type="bibr"><sup>32</sup></xref><sup>,</sup><xref rid="ooab025-B33" ref-type="bibr"><sup>33</sup></xref> As expected, normalization of entities was more difficult than merely finding entity mentions, especially for treatment concepts. Annotators were much less familiar with OPS (especially medical students) than with the other terminologies. Documentation officers, who create ICD10, OPS, and DRG coding as part of their professional activities, probably would have been a better fit for this task.</p>
    <p>The 2-step annotation process we used for group B achieved the best balance between work time/cost and annotation quality. For comparable medical annotation projects, we therefore recommend the following procedure: First, annotations should be performed by persons, preferably more senior medical students, specifically hired for the annotation task. Every document should be annotated at least twice, and annotators are asked to highlight phrases where they are not sure how to proceed. In a second step, trained staff members only correct such phrases and conflicting annotations which significantly reduces the time they have to invest. The first step may include preannotations of frequently annotated terms to further speed up the process. However, this procedure certainly is a challenge for building truly large corpora containing thousands of documents.</p>
    <p>Generally, recent years have shown that neural network based NER taggers outperform all other methods for biomedical texts, at least for English.<xref rid="ooab025-B34" ref-type="bibr"><sup>34</sup></xref> In recent NER studies on German clinical corpora, CRF and LSTM-CRF methods have been used. A CRF and a character-level Bi-LSTM-CRF was trained for several types of medical entities, including medical condition, treatments and medications on 627 clinical notes from nephrology annotated with UMLS.<xref rid="ooab025-B35" ref-type="bibr"><sup>35</sup></xref> Their F1-scores for treatment and medication are ∼5pp and ∼11pp worse for the CRF and ∼3pp and ∼2pp worse for the Bi-LSTM-CRF, when compared to BRONCO150 results (the precise setup for evaluation is not clear in the paper, but it certainly used a form of cross-validation. Therefore, we compare to BRONCO150 and not BRONCO50), though in their case the Bi-LSTM-CRF always outperformed the CRF. Their F1-scores for medical condition are ∼9pp and 13pp better for CRF and the Bi-LSTM-CRF, respectively. The rule-based system JUMEx extracted among other entities medication names from 3000PA reaching F1-scores of 0.65 compared to 0.90 for BRONCO50.<xref rid="ooab025-B15" ref-type="bibr"><sup>15</sup></xref> On the Jena subset of 3000PA the CRF-based JCORE pipeline extracted among other entities diagnosis mentions with F1-score of 0.48 compared to 0.72 for BRONCO50.<xref rid="ooab025-B17" ref-type="bibr"><sup>17</sup></xref> The latter 2 studies work on much larger corpora (more than 1.5M tokens) using 10-fold cross validation while for BRONCO150 we could only apply 5-fold. Additionally, 3000PA covers documents from a broader domain than BRONCO. Further progress in NER may be achieved by adding more fine-grained language models. For German medical texts, such models are not available, yet. However, it would be worth testing the German instance of the multilingual BERT language model.<xref rid="ooab025-B31" ref-type="bibr"><sup>31</sup></xref></p>
    <p>For NEN, we applied dictionary matching followed by a reranking of candidate terms. Results are mixed; whereas F1-scores for diagnosis and medication are somewhat encouraging (52% vs 66% on BRONCO50), the performance for treatments is very low (13%). These poor results can be related to the well-known vocabulary mismatch between the language of controlled vocabularies and the clinical jargon. Especially, OPS contains very complex concepts. Building interface terminologies may help to overcome this issue<xref rid="ooab025-B36" ref-type="bibr"><sup>36</sup></xref><sup>,</sup><xref rid="ooab025-B37" ref-type="bibr"><sup>37</sup></xref> as well as making German translations of rich terminologies such as SNOMED-CT augmented with proper synonym sets accessible to the research community. Abbreviations are often specific within organizations and thus notoriously difficult to include in general terminologies. Additionally, tools for abbreviation resolution, like,<xref rid="ooab025-B38" ref-type="bibr"><sup>38–40</sup></xref> might be worthwhile here to improve terminology grounding.</p>
    <p>Negation and speculation detection using NegEx showed diverse results. We achieved the best performance using trigger terms from Cotik et al.<xref rid="ooab025-B29" ref-type="bibr"><sup>29</sup></xref> F1-scores of 0.55 for negation can be considered as a promising basis for future improvements, yet a score of 0.33 for speculation is clearly not satisfying. Note that Cotik et al report F1-scores of 0.91 for negation and 0.55 for speculation on their corpus,<xref rid="ooab025-B29" ref-type="bibr"><sup>29</sup></xref> indicating the still highly corpus-specific nature of the trigger term lists. To improve negation and speculation detection, one could either largely extend the list of trigger terms and their scopes, or adapt other tools like ConText. a more advanced version of NegEx currently available only for English.<xref rid="ooab025-B41" ref-type="bibr"><sup>41</sup></xref> Also training of polarity models, as in,<xref rid="ooab025-B42" ref-type="bibr"><sup>42</sup></xref> could be tested.</p>
  </sec>
  <sec sec-type="conclusion">
    <title>CONCLUSION</title>
    <p>We provide the BRONCO, the first annotated German medical corpus freely available to the research community. This corpus offers the possibility to compare, evaluate, and train basic NLP tasks for the medical domain such as NER, NEN, and detection of different attributes of named entities.</p>
  </sec>
  <sec>
    <title>FUNDING</title>
    <p>This work was funded by the German Bundesministerium für Bildung und Forschung (BMBF), grants 031L0030B and 031L0023B, and the Deutsche Forschungsgemeinschaft, grant LE1428/1-1. D.T.R. is a participant in the BIH-Charité Clinician Scientist Program funded by the Charité – Universitätsmedizin Berlin and the Berlin Institute of Health.</p>
  </sec>
  <sec>
    <title>AUTHOR CONTRIBUTIONS</title>
    <p>U.L. and O.K. conceived the idea of the project. U.L., N.P.M., and U.K. supervised the work. M.K. organized the annotation process and performed data analysis, supported by M.S., H.H., J.Š., J.S., and M.H. M.L., D.T.R., I.J., G.R., M.Z., T.B., J.G., B.B., and L.O. anonymized and annotated the corpus. M.K. and U.L. wrote the manuscript with input from all authors.</p>
  </sec>
  <sec>
    <title>SUPPLEMENTARY MATERIAL</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref> is available at <italic toggle="yes">Journal of the American Medical Informatics Association</italic> online.</p>
  </sec>
  <sec>
    <title>CONFLICT OF INTEREST STATEMENT</title>
    <p>None declared.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>DATA AVAILABILITY</title>
    <p>The data underlying this article (BRONCO150) will be shared on reasonable request and based on a data usage agreement. Please visit <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www2.informatik.hu-berlin.de/~leser/bronco/index.html" ext-link-type="uri">https://www2.informatik.hu-berlin.de/∼leser/bronco/index.html</ext-link>.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>ooab025_Supplementary_Data</label>
      <media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ooab025_supplementary_data.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>REFERENCES</title>
    <ref id="ooab025-B1">
      <label>1</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jensen</surname><given-names>PB</given-names></string-name>, <string-name><surname>Jensen</surname><given-names>LJ</given-names></string-name>, <string-name><surname>Brunak</surname><given-names>S.</given-names></string-name></person-group><article-title>Mining electronic health records: towards better research applications and clinical care</article-title>. <source>Nat Rev Genet</source><year>2012</year>; <volume>13</volume> (<issue>6</issue>): <fpage>395</fpage>–<lpage>405</lpage>.<pub-id pub-id-type="pmid">22549152</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B2">
      <label>2</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chapman</surname><given-names>WW</given-names></string-name>, <string-name><surname>Nadkarni</surname><given-names>PM</given-names></string-name>, <string-name><surname>Hirschman</surname><given-names>L</given-names></string-name></person-group>, <etal>et al</etal><article-title>Overcoming barriers to NLP for clinical text: the role of shared tasks and the need for additional creative solutions</article-title>. <source>J Am Med Inform Assoc</source><year>2011</year>; <volume>18</volume> (<issue>5</issue>): <fpage>540</fpage>–<lpage>3</lpage>.<pub-id pub-id-type="pmid">21846785</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B3">
      <label>3</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dernoncourt</surname><given-names>F</given-names></string-name>, <string-name><surname>Lee</surname><given-names>JY</given-names></string-name>, <string-name><surname>Uzuner</surname><given-names>O</given-names></string-name></person-group>, <etal>et al</etal><article-title>De-identification of patient notes with recurrent neural networks</article-title>. <source>J Am Med Inform Assoc</source><year>2017</year>; <volume>24</volume> (<issue>3</issue>): <fpage>596</fpage>–<lpage>606</lpage>.<pub-id pub-id-type="pmid">28040687</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B4">
      <label>4</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Tang</surname><given-names>B</given-names></string-name>, <string-name><surname>Wang</surname><given-names>X</given-names></string-name></person-group>, <etal>et al</etal><article-title>De-identification of clinical notes via recurrent neural network and conditional random field</article-title>. <source>J Biomed Inform</source><year>2017</year>; <volume>75</volume>: <fpage>S34</fpage>–<lpage>42</lpage>.</mixed-citation>
    </ref>
    <ref id="ooab025-B5">
      <label>5</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stubbs</surname><given-names>A</given-names></string-name>, <string-name><surname>Filannino</surname><given-names>M</given-names></string-name>, <string-name><surname>Uzuner</surname><given-names>Ö.</given-names></string-name></person-group><article-title>De-identification of psychiatric intake records: overview of 2016 CEGS N-GRID shared tasks Track 1</article-title>. <source>J Biomed Inform</source><year>2017</year>; <volume>75</volume>: <fpage>S4</fpage>–<lpage>18</lpage>.</mixed-citation>
    </ref>
    <ref id="ooab025-B6">
      <label>6</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname><given-names>AE</given-names></string-name>, <string-name><surname>Pollard</surname><given-names>TJ</given-names></string-name>, <string-name><surname>Shen</surname><given-names>L</given-names></string-name></person-group>, <etal>et al</etal><article-title>MIMIC-III, a freely accessible critical care database</article-title>. <source>Sci Data</source><year>2016</year>; <volume>3</volume>: <fpage>160035</fpage>.<pub-id pub-id-type="pmid">27219127</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B7">
      <label>7</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aronson</surname><given-names>AR</given-names></string-name>, <string-name><surname>Lang</surname><given-names>F-M.</given-names></string-name></person-group><article-title>An overview of MetaMap: historical perspective and recent advances</article-title>. <source>J Am Med Inform Assoc</source><year>2010</year>; <volume>17</volume> (<issue>3</issue>): <fpage>229</fpage>–<lpage>36</lpage>.<pub-id pub-id-type="pmid">20442139</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B8">
      <label>8</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Savova</surname><given-names>GK</given-names></string-name>, <string-name><surname>Masanz</surname><given-names>JJ</given-names></string-name>, <string-name><surname>Ogren</surname><given-names>PV</given-names></string-name></person-group>, <etal>et al</etal><article-title>Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications</article-title>. <source>J Am Med Inform Assoc</source><year>2010</year>; <volume>17</volume> (<issue>5</issue>): <fpage>507</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">20819853</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B9">
      <label>9</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hellrich</surname><given-names>J</given-names></string-name>, <string-name><surname>Matthies</surname><given-names>F</given-names></string-name>, <string-name><surname>Faessler</surname><given-names>E</given-names></string-name></person-group>, <etal>et al</etal><article-title>Sharing models and tools for processing German clinical texts</article-title>. <source>Stud Health Technol Inform</source><year>2015</year>; <volume>210</volume>: <fpage>734</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">25991250</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B10">
      <label>10</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Starlinger</surname><given-names>J</given-names></string-name>, <string-name><surname>Kittner</surname><given-names>M</given-names></string-name>, <string-name><surname>Blankenstein</surname><given-names>O</given-names></string-name></person-group>, <etal>et al</etal><article-title>How to improve information extraction from German medical records</article-title>. <source>IT Inform Technol</source><year>2017</year>; <volume>59</volume>: <fpage>171</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="ooab025-B11">
      <label>11</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lohr</surname><given-names>C</given-names></string-name>, <string-name><surname>Buechel</surname><given-names>S</given-names></string-name>, <string-name><surname>Hahn</surname><given-names>U</given-names></string-name></person-group>. Sharing copies of synthetic clinical corpora without physical distribution—a case study to get around IPRs and Privacy Constraints Featuring the German JSYNCC Corpus. In: proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018); May 7–12, <year>2018</year>; Miyazaki, Japan.</mixed-citation>
    </ref>
    <ref id="ooab025-B12">
      <label>12</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Fette</surname><given-names>G</given-names></string-name>, <string-name><surname>Ertl</surname><given-names>M</given-names></string-name>, <string-name><surname>Wörner</surname><given-names>A</given-names></string-name></person-group>, <etal>et al</etal><article-title>Information extraction from unstructured electronic health records and integration into a data warehouse</article-title>. In: INFORMATIK 2012 – Proceedings 42 Jahrestagung Der Gesellschaft Für Informatik (GI); September 16–21, <year>2012</year>: <fpage>1237</fpage>–<lpage>51; Braunschweig, Germany</lpage>.</mixed-citation>
    </ref>
    <ref id="ooab025-B13">
      <label>13</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Toepfer</surname><given-names>M</given-names></string-name>, <string-name><surname>Corovic</surname><given-names>H</given-names></string-name>, <string-name><surname>Fette</surname><given-names>G</given-names></string-name></person-group>, <etal>et al</etal><article-title>Fine-grained information extraction from German transthoracic echocardiography reports</article-title>. <source>BMC Med Inform Decis Mak</source><year>2015</year>; <volume>15</volume>: <fpage>91</fpage>.<pub-id pub-id-type="pmid">26563260</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B14">
      <label>14</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Roller</surname><given-names>R</given-names></string-name>, <string-name><surname>Uszkoreit</surname><given-names>H</given-names></string-name>, <string-name><surname>Xu</surname><given-names>F</given-names></string-name></person-group>, <etal>et al</etal> A fine-grained corpus annotation schema of German nephrology records. In: proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP). Osaka, Japan: The COLING 2016 Organizing Committee; <year>2016</year>: <fpage>69</fpage>–<lpage>77</lpage>.</mixed-citation>
    </ref>
    <ref id="ooab025-B15">
      <label>15</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hahn</surname><given-names>U</given-names></string-name>, <string-name><surname>Matthies</surname><given-names>F</given-names></string-name>, <string-name><surname>Lohr</surname><given-names>C</given-names></string-name></person-group>, <etal>et al</etal><article-title>3000PA-towards a national reference corpus of German clinical language</article-title>. <source>Stud Health Technol Inform</source><year>2018</year>; <volume>247</volume>: <fpage>26</fpage>–<lpage>30</lpage>.<pub-id pub-id-type="pmid">29677916</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B16">
      <label>16</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lohr</surname><given-names>C</given-names></string-name>, <string-name><surname>Luther</surname><given-names>S</given-names></string-name>, <string-name><surname>Matthies</surname><given-names>F</given-names></string-name></person-group>, <etal>et al</etal> CDA-compliant section annotation of German-language discharge summaries: guideline development, annotation campaign, section classification. In: proceedings of the 2018 Annual Symposium of the American Medical Informatics Association. Data, Technology, and Innovation for Better Health; San Francisco, CA, USA; <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="ooab025-B17">
      <label>17</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lohr</surname><given-names>C</given-names></string-name>, <string-name><surname>Modersohn</surname><given-names>L</given-names></string-name>, <string-name><surname>Hellrich</surname><given-names>J</given-names></string-name>, <string-name><surname>Kolditz</surname><given-names>T</given-names></string-name>, <string-name><surname>Hahn</surname><given-names>U</given-names></string-name></person-group>. <article-title>An evolutionary approach to the annotation of discharge summaries</article-title>. <source>Stud Health Technol Inform</source><year>2020</year>; <volume>270</volume>: <fpage>28</fpage>–<lpage>32</lpage>.<pub-id pub-id-type="pmid">32570340</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B18">
      <label>18</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Stenetorp</surname><given-names>P</given-names></string-name>, <string-name><surname>Pyysalo</surname><given-names>S</given-names></string-name>, <string-name><surname>Topić</surname><given-names>G</given-names></string-name></person-group>, <etal>et al</etal> BRAT: a web-based tool for NLP-assisted text annotation. In: proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics. San Diego, CA: Association for Computational Linguistics; <year>2012</year>: <fpage>102</fpage>–<lpage>7</lpage>.</mixed-citation>
    </ref>
    <ref id="ooab025-B19">
      <label>19</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Uzuner</surname><given-names>Ö</given-names></string-name>, <string-name><surname>Solti</surname><given-names>I</given-names></string-name>, <string-name><surname>Xia</surname><given-names>F</given-names></string-name></person-group>, <etal>et al</etal><article-title>Community annotation experiment for ground truth generation for the i2b2 medication challenge</article-title>. <source>J Am Med Inform Assoc</source><year>2010</year>; <volume>17</volume> (<issue>5</issue>): <fpage>519</fpage>–<lpage>23</lpage>.<pub-id pub-id-type="pmid">20819855</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B20">
      <label>20</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hripcsak</surname><given-names>G</given-names></string-name>, <string-name><surname>Rothschild</surname><given-names>AS.</given-names></string-name></person-group><article-title>Agreement, the F-measure, and reliability in information retrieval</article-title>. <source>J Am Med Inform Assoc</source><year>2005</year>; <volume>12</volume> (<issue>3</issue>): <fpage>296</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">15684123</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B21">
      <label>21</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Hahn</surname><given-names>U</given-names></string-name>, <string-name><surname>Buyko</surname><given-names>E</given-names></string-name>, <string-name><surname>Landefeld</surname><given-names>R</given-names></string-name></person-group>, <etal>et al</etal> An overview of JCoRe, the JULIE lab UIMA component repository. In: proceedings of the Workshop “Towards Enhanced Interoperability for Large HLT Systems: UIMA for NLP,” Marrakech, Morocco, May 31, 2008: <fpage>1</fpage>–<lpage>7</lpage>.</mixed-citation>
    </ref>
    <ref id="ooab025-B22">
      <label>22</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wermter</surname><given-names>J</given-names></string-name>, <string-name><surname>Hahn</surname><given-names>U</given-names></string-name></person-group>. An annotated German-language medical text corpus as language resource. In: proceedings 4th International Conference on Language Resources and Evaluation; May 24–30, <year>2004</year>: <fpage>473</fpage>–<lpage>6</lpage>; Lisbon, Portugal.</mixed-citation>
    </ref>
    <ref id="ooab025-B23">
      <label>23</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Okazaki</surname><given-names>N</given-names></string-name></person-group>. CRFsuite: a fast implementation of conditional random fields (CRFs); <year>2007</year>. <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.chokkan.org/software/crfsuite/" ext-link-type="uri">http://www.chokkan.org/software/crfsuite/</ext-link> Accessed April 3, 2018.</mixed-citation>
    </ref>
    <ref id="ooab025-B24">
      <label>24</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lample</surname><given-names>G</given-names></string-name>, <string-name><surname>Ballesteros</surname><given-names>M</given-names></string-name>, <string-name><surname>Subramanian</surname><given-names>S</given-names></string-name></person-group>, <etal>et al</etal> Neural architectures for named entity recognition. In: proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. San Diego, CA: Association for Computational Linguistics; <year>2016</year>: <fpage>260</fpage>–<lpage>70</lpage>.</mixed-citation>
    </ref>
    <ref id="ooab025-B25">
      <label>25</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Mikolov</surname><given-names>T</given-names></string-name>, <string-name><surname>Grave</surname><given-names>E</given-names></string-name>, <string-name><surname>Bojanowski</surname><given-names>P</given-names></string-name></person-group>, <etal>et al</etal> Advances in pre-training distributed word representations. In: proceedings of the International Conference on Language Resources and Evaluation (LREC 2018); May 7–12, <year>2018</year>: <fpage>52</fpage>–<lpage>55</lpage>; Miyazaki, Japan.</mixed-citation>
    </ref>
    <ref id="ooab025-B26">
      <label>26</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Dogan</surname><given-names>R</given-names></string-name>, <string-name><surname>Lu</surname><given-names>Z</given-names></string-name></person-group>. An inference method for disease name normalization. In: AAAI Fall Symposium – Technical Report; November 2–4, <year>2012</year>: <fpage>8</fpage>–<lpage>13</lpage>; Arlington, Virginia.</mixed-citation>
    </ref>
    <ref id="ooab025-B27">
      <label>27</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chapman</surname><given-names>WW</given-names></string-name>, <string-name><surname>Bridewell</surname><given-names>W</given-names></string-name>, <string-name><surname>Hanbury</surname><given-names>P</given-names></string-name></person-group>, <etal>et al</etal><article-title>A simple algorithm for identifying negated findings and diseases in discharge summaries</article-title>. <source>J Biomed Inform</source><year>2001</year>; <volume>34</volume> (<issue>5</issue>): <fpage>301</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">12123149</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B28">
      <label>28</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chapman</surname><given-names>WW</given-names></string-name>, <string-name><surname>Hillert</surname><given-names>D</given-names></string-name>, <string-name><surname>Velupillai</surname><given-names>S</given-names></string-name></person-group>, <etal>et al</etal><article-title>Extending the NegEx lexicon for multiple languages</article-title>. <source>Stud Health Technol Inform</source><year>2013</year>; <volume>192</volume>: <fpage>677</fpage>–<lpage>81</lpage>.<pub-id pub-id-type="pmid">23920642</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B29">
      <label>29</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Cotik</surname><given-names>V</given-names></string-name>, <string-name><surname>Roller</surname><given-names>R</given-names></string-name>, <string-name><surname>Xu</surname><given-names>F</given-names></string-name></person-group>, <etal>et al</etal> Negation detection in clinical reports written in German. In: proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016); December 13–16, <year>2016</year>: <fpage>115</fpage>–<lpage>24; Osaka, Japan</lpage>.</mixed-citation>
    </ref>
    <ref id="ooab025-B30">
      <label>30</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Mikolov</surname><given-names>T</given-names></string-name>, <string-name><surname>Chen</surname><given-names>K</given-names></string-name>, <string-name><surname>Corrado</surname><given-names>G</given-names></string-name></person-group>, <etal>et al</etal> Efficient estimation of word representations in vector space. In: Workshop Proceedings of the 1st International Conference on Learning Representations; May 2–4, <year>2013</year>; Scottsdale, AZ, USA.</mixed-citation>
    </ref>
    <ref id="ooab025-B31">
      <label>31</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Devlin</surname><given-names>J</given-names></string-name>, <string-name><surname>Chang</surname><given-names>M-W</given-names></string-name>, <string-name><surname>Lee</surname><given-names>K</given-names></string-name></person-group>, <etal>et al</etal> Bert: pre-training of deep bidirectional transformers for language understanding. In: proceedings of the 2019 Conference of the North American Chapter of the Association for Computer Linguistics: Human Language Technologies. Minneapolis, MN: Association for Computational Linguistics; <year>2019</year>: <fpage>4171</fpage>–<lpage>86</lpage>.</mixed-citation>
    </ref>
    <ref id="ooab025-B32">
      <label>32</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Y</given-names></string-name></person-group>. Annotating and recognising named entities in clinical notes. In: proceedings of the ACL-IJCNLP 2009 Student Research Workshop;August 2–7, <year>2009</year>: <fpage>18</fpage>–<lpage>26; Suntec, Singapore</lpage>.</mixed-citation>
    </ref>
    <ref id="ooab025-B33">
      <label>33</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Albright</surname><given-names>D</given-names></string-name>, <string-name><surname>Lanfranchi</surname><given-names>A</given-names></string-name>, <string-name><surname>Fredriksen</surname><given-names>A</given-names></string-name></person-group>, <etal>et al</etal><article-title>Towards comprehensive syntactic and semantic annotations of the clinical narrative</article-title>. <source>J Am Med Inform Assoc</source><year>2013</year>; <volume>20</volume> (<issue>5</issue>): <fpage>922</fpage>–<lpage>30</lpage>.<pub-id pub-id-type="pmid">23355458</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B34">
      <label>34</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Habibi</surname><given-names>M</given-names></string-name>, <string-name><surname>Weber</surname><given-names>L</given-names></string-name>, <string-name><surname>Neves</surname><given-names>M</given-names></string-name></person-group>, <etal>et al</etal><article-title>Deep learning with word embeddings improves biomedical named entity recognition</article-title>. <source>Bioinformatics</source><year>2017</year>; <volume>33</volume> (<issue>14</issue>): <fpage>i37</fpage>–<lpage>48</lpage>.<pub-id pub-id-type="pmid">28881963</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B35">
      <label>35</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Roller</surname><given-names>R</given-names></string-name>, <string-name><surname>Rethmeier</surname><given-names>N</given-names></string-name>, <string-name><surname>Thomas</surname><given-names>P</given-names></string-name></person-group>, <etal>et al</etal> Detecting named entities and relations in German clinical reports. In: International Conference of the German Society for Computational Linguistics and Language Technology; September 13–14, <year>2017</year>: <fpage>146</fpage>–<lpage>54; Berlin, Germany</lpage>: Springer.</mixed-citation>
    </ref>
    <ref id="ooab025-B36">
      <label>36</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schulz</surname><given-names>S</given-names></string-name>, <string-name><surname>Rodrigues</surname><given-names>J-M</given-names></string-name>, <string-name><surname>Rector</surname><given-names>A</given-names></string-name></person-group>, <etal>et al</etal><article-title>Interface terminologies, reference terminologies and aggregation terminologies: a strategy for better integration</article-title>. <source>Stud Health Technol Inform</source><year>2017</year>; <volume>245</volume>: <fpage>940</fpage>–<lpage>4</lpage>.<pub-id pub-id-type="pmid">29295238</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B37">
      <label>37</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Schulz</surname><given-names>S</given-names></string-name>, <string-name><surname>Hammer</surname><given-names>L</given-names></string-name>, <string-name><surname>Hashemian-Nik</surname><given-names>D</given-names></string-name></person-group>, <etal>et al</etal> Localising the clinical terminology SNOMED CT by semi-automated creation of a German interface vocabulary. In: proceedings of the LREC 2020 Workshop on Multilingual Biomedical Text Processing (MultilingualBIO 2020). Marseille, France: European Language Resources Association; <year>2020</year>: <fpage>15</fpage>–<lpage>20</lpage>.</mixed-citation>
    </ref>
    <ref id="ooab025-B38">
      <label>38</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kreuzthaler</surname><given-names>M</given-names></string-name>, <string-name><surname>Oleynik</surname><given-names>M</given-names></string-name>, <string-name><surname>Avian</surname><given-names>A</given-names></string-name></person-group>, <etal>et al</etal> Unsupervised abbreviation detection in clinical narratives. In: proceedings of the clinical natural language processing workshop (ClinicalNLP); December 13–16, <volume>2016</volume>: <fpage>91</fpage>–<lpage>8</lpage>; Osaka, Japan.</mixed-citation>
    </ref>
    <ref id="ooab025-B39">
      <label>39</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Schwartz</surname><given-names>AS</given-names></string-name>, <string-name><surname>Hearst</surname><given-names>MA</given-names></string-name></person-group>. <chapter-title>A simple algorithm for identifying abbreviation definitions in biomedical text</chapter-title>. In: <person-group person-group-type="editor"><string-name><surname>Altman</surname><given-names>RB</given-names></string-name>, <string-name><surname>Dunker</surname><given-names>AK</given-names></string-name>, <string-name><surname>Hunter</surname><given-names>L</given-names></string-name>, <string-name><surname>Jung</surname><given-names>TA</given-names></string-name>, <string-name><surname>Klein</surname><given-names>TE</given-names></string-name></person-group>, eds. <source>Biocomputing 2003</source>. <publisher-loc>Singapore</publisher-loc>: <publisher-name>World Scientific</publisher-name>; <year>2002</year>: <fpage>451</fpage>–<lpage>62</lpage>.</mixed-citation>
    </ref>
    <ref id="ooab025-B40">
      <label>40</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Denny</surname><given-names>JC</given-names></string-name>, <string-name><surname>Trent Rosenbloom</surname><given-names>S</given-names></string-name></person-group>, <etal>et al</etal><article-title>A long journey to short abbreviations: developing an open-source framework for clinical abbreviation recognition and disambiguation (CARD)</article-title>. <source>J Am Med Inform Assoc</source><year>2017</year>; <volume>24</volume> (<issue>e1</issue>): <fpage>e79–86</fpage>–<lpage>e86</lpage>.<pub-id pub-id-type="pmid">27539197</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B41">
      <label>41</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harkema</surname><given-names>H</given-names></string-name>, <string-name><surname>Dowling</surname><given-names>JN</given-names></string-name>, <string-name><surname>Thornblade</surname><given-names>T</given-names></string-name></person-group>, <etal>et al</etal><article-title>ConText: an algorithm for determining negation, experiencer, and temporal status from clinical reports</article-title>. <source>J Biomed Inform</source><year>2009</year>; <volume>42</volume> (<issue>5</issue>): <fpage>839</fpage>–<lpage>51</lpage>.<pub-id pub-id-type="pmid">19435614</pub-id></mixed-citation>
    </ref>
    <ref id="ooab025-B42">
      <label>42</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>S</given-names></string-name>, <string-name><surname>Miller</surname><given-names>T</given-names></string-name>, <string-name><surname>Masanz</surname><given-names>J</given-names></string-name></person-group>, <etal>et al</etal><article-title>Negation’s not solved: generalizability versus optimizability in clinical natural language processing</article-title>. <source>PLOS One</source><year>2014</year>; <volume>9</volume> (<issue>11</issue>): <fpage>e112774</fpage>.<pub-id pub-id-type="pmid">25393544</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
