<?DTDIdentifier.IdentifierValue article.dtd?>
<?DTDIdentifier.IdentifierType system?>
<?SourceDTD.DTDName article.dtd?>
<?SourceDTD.Version 1.0?>
<?ConverterInfo.XSLTName bmc2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">3118166</article-id>
    <article-id pub-id-type="publisher-id">1471-2105-12-163</article-id>
    <article-id pub-id-type="pmid">21672185</article-id>
    <article-id pub-id-type="doi">10.1186/1471-2105-12-163</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Methodology Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Efficient alignment of pyrosequencing reads for re-sequencing applications</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes" id="A1">
        <name>
          <surname>Fernandes</surname>
          <given-names>Francisco</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>fjdf@kdbio.inesc-id.pt</email>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes" id="A2">
        <name>
          <surname>da Fonseca</surname>
          <given-names>Paulo GS</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <email>pgsf@kdbio.inesc-id.pt</email>
      </contrib>
      <contrib contrib-type="author" id="A3">
        <name>
          <surname>Russo</surname>
          <given-names>Luis MS</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>lsr@kdbio.inesc-id.pt</email>
      </contrib>
      <contrib contrib-type="author" id="A4">
        <name>
          <surname>Oliveira</surname>
          <given-names>Arlindo L</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>aml@inesc-id.pt</email>
      </contrib>
      <contrib contrib-type="author" corresp="yes" id="A5">
        <name>
          <surname>Freitas</surname>
          <given-names>Ana T</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>atf@inesc-id.pt</email>
      </contrib>
    </contrib-group>
    <aff id="I1"><label>1</label>Instituto de Engenharia de Sistemas e Computadores: Investigação e Desenvolvimento (INESC-ID), R. Alves Redol 9, 1000-029 Lisboa, Portugal</aff>
    <aff id="I2"><label>2</label>Instituto Superior Técnico-Universidade Técnica de Lisboa (IST/UTL), Av. Rovisco Pais, 1049-001 Lisboa, Portugal</aff>
    <pub-date pub-type="collection">
      <year>2011</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>16</day>
      <month>5</month>
      <year>2011</year>
    </pub-date>
    <volume>12</volume>
    <fpage>163</fpage>
    <lpage>163</lpage>
    <history>
      <date date-type="received">
        <day>16</day>
        <month>12</month>
        <year>2010</year>
      </date>
      <date date-type="accepted">
        <day>16</day>
        <month>5</month>
        <year>2011</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright ©2011 Fernandes et al; licensee BioMed Central Ltd.</copyright-statement>
      <copyright-year>2011</copyright-year>
      <copyright-holder>Fernandes et al; licensee BioMed Central Ltd.</copyright-holder>
      <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0">http://creativecommons.org/licenses/by/2.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="http://www.biomedcentral.com/1471-2105/12/163"/>
    <abstract>
      <sec>
        <title>Background</title>
        <p>Over the past few years, new massively parallel DNA sequencing technologies have emerged. These platforms generate massive amounts of data per run, greatly reducing the cost of DNA sequencing. However, these techniques also raise important computational difficulties mostly due to the huge volume of data produced, but also because of some of their specific characteristics such as read length and sequencing errors. Among the most critical problems is that of efficiently and accurately mapping reads to a reference genome in the context of re-sequencing projects.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>We present an efficient method for the local alignment of pyrosequencing reads produced by the GS FLX (454) system against a reference sequence. Our approach explores the characteristics of the data in these re-sequencing applications and uses state of the art indexing techniques combined with a flexible seed-based approach, leading to a fast and accurate algorithm which needs very little user parameterization. An evaluation performed using real and simulated data shows that our proposed method outperforms a number of mainstream tools on the quantity and quality of successful alignments, as well as on the execution time.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p>The proposed methodology was implemented in a software tool called TAPyR--Tool for the Alignment of Pyrosequencing Reads--which is publicly available from <ext-link ext-link-type="uri" xlink:href="http://www.tapyr.net">http://www.tapyr.net</ext-link>.</p>
      </sec>
    </abstract>
  </article-meta>
</front>
<body>
  <sec>
    <title>Background</title>
    <p>Sequencing by capillary electrophoresis, known as the Sanger method [<xref ref-type="bibr" rid="B1">1</xref>], has been employed in many historically significant large-scale sequencing projects and is regarded as the gold standard in terms of both read length and sequencing accuracy [<xref ref-type="bibr" rid="B2">2</xref>]. Several Massively Parallel DNA Sequencing (MPDS) technologies have recently emerged, including the Roche/454 GS FLX System, the Illumina/Solexa Genome Analyser, and the AB SOLiD System, which are able to generate a few orders of magnitude more bases per instrument run, being considerably less expensive than the Sanger method [<xref ref-type="bibr" rid="B2">2</xref>,<xref ref-type="bibr" rid="B3">3</xref>]. These technologies are enabling researchers and practitioners to efficiently sequence genomes, leading to very significant advances in biology and medicine. However, the huge volume of data produced by MPDS technologies creates important computational challenges [<xref ref-type="bibr" rid="B4">4</xref>]. Moreover, the different platform-specific data characteristics require different algorithmic approaches. For instance, some applications may use the 454 Titanium platform to produce reads 400 bases long, some other studies may employ a SOLiD system set to produce short reads of 35 bases, and yet other projects may use the Illumina system to produce 2 × 75 bases paired-end reads. Given their large variety, it would be rather difficult for a single algorithm to handle all kinds of data optimally.</p>
    <p>When sequencing a new organism, one is usually faced with the problem of assembling the sequence fragments (reads) together from scratch. However, when a sufficiently close sequence is already known, one may choose to use it as a reference and proceed by first mapping the reads to this reference and then determining the new sequence by extracting the consensus from the mapping results. The former strategy is called <italic>de novo </italic>sequencing, while the latter is known as <italic>re-sequencing</italic>. Several tools have recently been developed for generating assemblies from short reads, e.g [<xref ref-type="bibr" rid="B5">5</xref>,<xref ref-type="bibr" rid="B6">6</xref>]. Similarly, several methods have been proposed to address the problem of efficiently mapping MPDS reads to a reference sequence, like [<xref ref-type="bibr" rid="B7">7</xref>-<xref ref-type="bibr" rid="B12">12</xref>], to cite a few. As referred before, the sheer volume of data generated by MPDS technologies (to the order of hundreds of gigabases per run), and the need to align reads to large reference genomes limit the applicability of standard techniques. Indeed, in a typical application, we may have to align hundreds of millions of reads to a reference genome that can be as large as few gigabases, a job that cannot be efficiently achieved through standard dynamic programming procedures.</p>
    <p>One way to speed up the read alignment task is to resort to approximate indexing techniques. A first generation of aligners was based on hash tables of <italic>k</italic>-mers. Some of them, like SSAHA2 [<xref ref-type="bibr" rid="B13">13</xref>], build tables of <italic>k</italic>-mers of the target sequence, whilst others, like Newbler [<xref ref-type="bibr" rid="B14">14</xref>], index the reads, thus presumably requiring re-indexing for each new run. Recent developments in the field of compressed approximate indexes have led to a new family of alignment algorithms such as Segemehl [<xref ref-type="bibr" rid="B10">10</xref>], which uses an enhanced suffix array (see Implementation), and BWA-SW [<xref ref-type="bibr" rid="B11">11</xref>], which uses a FM-index (see Implementation) to accelerate Smith-Waterman alignments. Yet the number of aligners that support GS FLX pyrosequencing data is, as of today, relatively scarce compared to other technologies, most notably Illumina. Moreover, some of these tools find their origins in the days before the advent of the new sequencing technologies and only later were adapted to cope with new kinds of data [<xref ref-type="bibr" rid="B13">13</xref>], and some others target multiple kinds of data [<xref ref-type="bibr" rid="B10">10</xref>] being not optimized for pyrosequencing data. Given this state of affairs, we argue that there is still room for improvement in the realm of publicly available aligners specifically designed for high-throughput pyrosequencing data.</p>
    <p>In this paper we present a new method for the alignment of pyrosequencing reads, like those produced by the 454 GS FLX platform. By focusing on this specific technology, our procedure manages to explore its data characteristics to achieve improved performance over other mainstream methods. Like many of those methods, ours also builds an index of the target (reference) sequence to accelerate the alignment. It then employs a multiple seed heuristic to anchor the best candidate alignments. Contrary to other seed-based alignment tools, our strategy adds more flexibility by dispensing with the need of determining the number and length of the seeds beforehand. Our heuristic relies on some assumptions that can be reasonably expected to hold true for re-sequencing projects based on pyrosequencing data, namely, that the optimal alignments are mostly composed of relatively large chunks of exact matches interspersed by small, possibly gapped, divergent regions. A banded dynamic programming is used to finish up the candidate multiple seed alignments considering user-specified error constraints. A detailed description of the algorithm and data structures is given in the "Implementation" section. In the "Results and Discussion" section, we present a comparison between our method and a set of tools of widespread use for the local alignment of pyrosequencing reads. We base our discussion on results obtained with both real and simulated data.</p>
  </sec>
  <sec>
    <title>Implementation</title>
    <sec>
      <title>Compressed indexes</title>
      <p>The main data structure for sequence pattern matching is an index. Indexes reduce the time for matching a pattern because they restrict the search to the positions where it may occur instead of scanning the whole text. One of the most, if not the most, popular index structures is the <italic>suffix tree </italic>(ST), which is obtained by identifying common prefixes of the different suffixes of the represented text to nodes of a tree (see Figure <xref ref-type="fig" rid="F1">1(a</xref>) for an example). In such a structure, a pattern can be searched following edges with matching labels down from the root. Each leaf of the suffix tree represents a suffix of the text and, more generally, each node represents the subset of suffixes corresponding to the leaves of the subtree rooted at that node. The downside of indexes is that they need to be constructed <italic>a priori </italic>and have a bad reputation of using too much space. Despite providing for fast searching algorithms, suffix trees are particularly known for this bad characteristic. A popular alternative to suffix trees are <italic>suffix arrays </italic>(SA), that require asymptotically the same space, <italic>O</italic>(<italic>n</italic>) computer words for a text of size <italic>n</italic>, but with a smaller proportionality factor. Suffix arrays are obtained by ordering the suffixes of a text lexicographically. A correspondence can be established between nodes of the suffix tree and contiguous intervals of the suffix array. An example of a suffix array is shown in Figure <xref ref-type="fig" rid="F1">1(b</xref>). Detailed descriptions of string matching and indexes, including the ones mentioned here, are widely available [<xref ref-type="bibr" rid="B15">15</xref>].</p>
      <fig id="F1" position="float">
        <label>Figure 1</label>
        <caption>
          <p><bold>Indexes for the text <italic>abbbab</italic></bold>. (a) Suffix tree for the text <italic>abbbab</italic>, with the leaves numbered according to lexicographic order of the suffixes they represent. (b) The corresponding suffix array indicating the starting position of the sorted suffixes. (c) The equivalent BWT obtained by rotating and then sorting the text. Notice that the BWT is actually composed of only the last letter of the sorted rotations. Interestingly, this representation permits reconstructing the original text, and is also much more amenable to compression because it typically contains sequences of repeated characters. Notice, in addition, that every subtree of the suffix tree corresponds to an interval of the suffix array and, equivalently, of the BWT. In this example, the dashed boxes indicate the subtree/intervals corresponding to the suffixes that start with the common prefix <italic>b</italic>.</p>
        </caption>
        <graphic xlink:href="1471-2105-12-163-1"/>
      </fig>
      <p>Recent research on indexes has focused on the fact that pointer representations require <italic>O</italic>(<italic>n </italic>log <italic>n</italic>) bits whereas the original text (the target genome, in our case) requires only <italic>n </italic>log <italic>σ </italic>bits, where <italic>σ </italic>is the alphabet size, e.g. 4 for DNA and 20 for proteins. In an effort to reduce this gap, new indexes have been designed which became collectively known as <italic>compressed indexes </italic>[<xref ref-type="bibr" rid="B16">16</xref>] due to the fact that they rely heavily on data compression techniques. In spite of their reduced space, compressed indexes can be made to allow for an even broader range of operations than classical indexes, like generalized branching, that combines blocks of letters instead of just one letter at a time [<xref ref-type="bibr" rid="B17">17</xref>]. Our method uses an implementation of the FMIndex [<xref ref-type="bibr" rid="B18">18</xref>] optimized for the DNA alphabet. The FMIndex is a compressed index based on the Burrows-Wheeler transform (BWT) [<xref ref-type="bibr" rid="B19">19</xref>] requiring only <italic>O</italic>(<italic>n </italic>log <italic>σ</italic>) bits of memory space. The BWT of a text <italic>t </italic>is obtained by appending an extra symbol $ to <italic>t</italic>, and then sorting all cyclic permutations (rotations) of <italic>t</italic>$ according to the lexicographic order, with $ being the lowest symbol. Thus a BWT of a text is essentially equivalent to its suffix array. In fact, they are related through the formula BWT[<italic>i</italic>] = <italic>t</italic>[SA[<italic>i</italic>] - 1], for <italic>i </italic>= 1, . . . , | <italic>t </italic>|. An example of a BWT is given in Figure <xref ref-type="fig" rid="F1">1(c</xref>).</p>
    </sec>
    <sec>
      <title>The seed-based search approach</title>
      <p>Due to the relatively large size of the GS FLX reads, it is not practical to use a plain index-based exact matching algorithm. Some sort of backtracking strategy could be used to allow for errors but, since the number of possible comparisons increases exponentially with their number, this becomes rapidly inefficient. Instead, we propose a seed-based search heuristic that explores the characteristics of the pyrosequencing data and of the <italic>bona fide </italic>alignments that are likely to arise in the context of re-sequencing applications. Since the error rates are usually low [<xref ref-type="bibr" rid="B20">20</xref>], and the prevalent type of pyrosequencing errors are small indels, with mismatches being much less common, we conjecture that the optimal alignments are expected to be formed of large chunks of exact matches interspersed by divergent gapped regions. Moreover, since the read lengths are of a few hundred bases, we can expect the exact match regions to be large enough so we can use segments of them, called <italic>seeds</italic>, as a backbone to pin down the position of the alignment on the reference sequence, or at least reduce the amount of candidate positions to a manageable number of possibilities that can be tested individually. In this case, the optimal alignments can be obtained by expanding the candidate multiple seed matches into alignments of the whole read by filling up the remaining regions and selecting those with best overall scores.</p>
      <p>Our strategy for choosing the seeds consists in approximately partitioning the read into maximal exact match blocks in a greedy fashion. More precisely, let <italic>r </italic>= <italic>r</italic><sub>1 </sub>⋯ <italic>r<sub>m </sub></italic>be the read. The procedure starts at the first position of the read and uses the index to find the largest prefix of the read with exact occurrences in the reference sequence, say <italic>r</italic>[1 ⋯ <italic>l</italic>] = <italic>r</italic><sub>1 </sub>⋯ <italic>r<sub>l</sub></italic>. In practice we obtain the equivalent of an interval of the BWT which contains the positions of the reference sequence <italic>g </italic>at which <italic>r</italic>[1 ⋯ <italic>l</italic>] occurs. Obviously, by maximality, <italic>r</italic>[1 ⋯ <italic>l </italic>+ 1] does not occur in <italic>g</italic>. This happens because none of the occurrences of <italic>r</italic>[1 ⋯ <italic>l</italic>] is followed by <italic>r</italic><sub><italic>l</italic>+1 </sub>or, put another way, because there is a mismatch between <italic>r</italic><sub><italic>l</italic>+1 </sub>and the letter following each occurrence of <italic>r</italic>[1 ⋯ <italic>l</italic>] (or because it occurs at the very end of <italic>g</italic>). If <italic>r</italic><sub><italic>l</italic>+1 </sub>≠ <italic>r<sub>l</sub></italic>, then we set <italic>r</italic>[1 ⋯ <italic>l</italic>] as the first seed and proceed as above to find the next seed starting from position <italic>l </italic>+ 2. If, however, we have <italic>r</italic><sub><italic>l</italic>+1 </sub>= <italic>r<sub>l</sub></italic>, this means that the difference occurred in the middle of a homopolymer (contiguous subsequence of identical bases), most likely due to an insertion sequencing error. In this case, we set <italic>r</italic>[1 ⋯ <italic>l</italic>] as the first seed as before, but advance the cursor to the start of the next homopolymer, i.e. to the smallest <italic>l</italic>' &gt;<italic>l </italic>s.t. <italic>r</italic><sub><italic>l</italic>' </sub>≠ <italic>r</italic><sub><italic>l</italic>' </sub>- <sub>1</sub>. We repeat this process until the end of the read is reached.</p>
      <p>Once we have the set of seeds and their individual positions in the reference sequence, we need to identify subsets of occurrences of distinct seeds that are in accordance with their original order and spacing in the read, which can then serve as a support for the final alignments. More formally, let <italic>g </italic>be the reference sequence, and <italic>r </italic>be a read. Let also <italic>s</italic><sub>1</sub>, . . . , <italic>s<sub>k </sub></italic>be <italic>k </italic>substrings of <italic>r </italic>such that <italic>r </italic>= <italic>s</italic><sub>1</sub><italic>a</italic><sub>1</sub><italic>s</italic><sub>2</sub><italic>a</italic><sub>2 </sub>⋯ <italic>a</italic><sub><italic>k</italic>-1</sub><italic>s<sub>k</sub>a<sub>k</sub></italic>, where, for <italic>i </italic>= 1, . . . , <italic>k</italic>, <italic>s<sub>i </sub></italic>denote the seeds and <italic>a<sub>i </sub></italic>denote the substrings in between them. For each <italic>i </italic>= 1, . . . , <italic>k</italic>, let <italic>o<sub>i </sub></italic>≥ 0 be the number of exact occurrences of <italic>s<sub>i </sub></italic>in <italic>g</italic>. We then have <inline-formula><inline-graphic xlink:href="1471-2105-12-163-i1.gif"/></inline-formula> ways to choose a set containing one occurrence for each of the <italic>k </italic>substrings. Let <italic>p </italic>= (<italic>p</italic><sub>1</sub>, . . . , <italic>p<sub>k</sub></italic>) be one of such <italic>o </italic>tuples of distinct seed occurrences. If, for <italic>i </italic>= 1, . . . , <italic>k -</italic>1, we have <italic>p<sub>i </sub></italic>≤ <italic>p</italic><sub><italic>i</italic>+1 </sub>and |<italic>a<sub>i</sub></italic>| ∈<italic><sub>i </sub>p</italic><sub><italic>i</italic>+1 </sub>- (<italic>p<sub>i </sub></italic>+ |<italic>s<sub>i</sub></italic>|) |<italic>a<sub>i</sub></italic>| + ∈<italic><sub>i </sub></italic>for some given ∈<italic><sub>i </sub></italic>≥ 0, then we say that these occurrences are <italic>coherent</italic>. Hence, a coherent set of seed occurrences is composed of positions which respect the relative order of the corresponding seeds in the read and such that, for any two consecutive seeds, the distance between their occurrences lies within a restricted interval around the actual distance between those seeds in the read. For the sake of flexibility, we do not restrict ourselves to coherent sets containing occurrences of all the seeds. We also take partial sets containing occurrences of only some of those seeds as good candidates for further expansion.</p>
      <p>The set of seeds (<italic>s</italic><sub>1</sub>, . . . , <italic>s<sub>k</sub></italic>) and their occurrence positions in <italic>g </italic>can be obtained with the index in linear time. However, the number of combinations of occurrences of different seeds can be rather large, especially if some of them are short. This makes it impractical to test all possibilities for coherence. Nonetheless, most of these combinations will typically be non-coherent, and if we care to previously sort the set of occurrences of each seed, we can efficiently search for coherent combinations using, again, a greedy strategy, simply by scanning the seed matches in <italic>g </italic>from left to right, partitioning them into maximal non-overlapping sets of consecutive coherent matches. Although this might seem a rough approach at first glance, in fact this strategy has shown to be adequate because of the relatively large size of the seeds and small separation between them, which makes it difficult for occurrences of two consecutive seeds to be interspersed with an occurrence of a third one.</p>
      <p>Once the potential read occurrences indicated by coherent multiple-seed matches are found, the algorithm runs a banded Needleman-Wunsch dynamic programming procedure with Gotoh's modifications to align the non-seed segments of the read to their counterparts in the genome. That is, if we have a coherent set of occurrences of the seeds <italic>s</italic><sub><italic>j</italic>1</sub>, . . . , <italic>s</italic><sub><italic>jq </italic></sub>, s.t. the read decomposes into <italic>r </italic>= <italic>b</italic><sub>0</sub><italic>s</italic><sub><italic>j</italic>1</sub><italic>b</italic><sub>1</sub><italic>s</italic><sub><italic>j</italic>2 </sub><italic>b</italic><sub>2 </sub><italic>b</italic><sub><italic>q</italic>-1</sub><italic>s<sub>jq </sub>b<sub>q</sub></italic>, and the reference sequence into <italic>g </italic>= <italic>c</italic><sub>0</sub><italic>s</italic><sub><italic>j</italic>1</sub><italic>c</italic><sub>1</sub><italic>s</italic><sub><italic>j</italic>2 </sub><italic>c</italic><sub>2 </sub>⋯ <italic>c</italic><sub>q </sub><sub>1</sub><italic>s<sub>jq</sub>c<sub>q</sub></italic>, then we align each pair (<italic>b<sub>i</sub></italic>, <italic>c<sub>i</sub></italic>), for <italic>i </italic>= 0, . . . , <italic>q</italic>. Of course, for both ends, (<italic>b</italic><sub>0</sub>, <italic>c</italic><sub>0</sub>) and (<italic>b<sub>q</sub></italic>, <italic>c<sub>q</sub></italic>), we perform semi-global alignments. The largest candidate coherent multiple seed matches are extended this way and accepted as a read occurrence if either the overall alignment identity stays above a given threshold percentage <italic>t </italic>or, alternatively, if the sum of the errors in-between the seeds and at the extremes of the read do not exceed a pre-established number <italic>e</italic>. The algorithm can be chosen to report all the accepted occurrences or only the one(s) with the least errors. The strategy described above is illustrated in Figure <xref ref-type="fig" rid="F2">2</xref>.</p>
      <fig id="F2" position="float">
        <label>Figure 2</label>
        <caption>
          <p><bold>Sketch and example of the TAPyR procedure</bold>. (a) Sketch of the seed strategy employed by TAPyR. In this schema, three seeds are chosen, and seven matches of these seeds are found on the reference genome, three for the first seed, two for the second, and two for the third. These occurrences are ordered in the genome and scanned from left to right. Multiple seed matches are formed by extending current partial matches with the next occurrence if the coherence criteria are met. Otherwise, the current multiple match is stored as a potential candidate and a new one is started. In this example, we finish with five potential candidates for extension indicated by the dashed boxes. The largest candidate(s), i.e. the multiple seed occurrence that span most bases, are chosen for extension. In this case, that should be <inline-formula><inline-graphic xlink:href="1471-2105-12-163-i3.gif"/></inline-formula>. (b) A more concrete example, in which we have a sequence of length 15, which was originally read from position 101 of the genome, with one insertion at position 5 and one substitution at position 9. The algorithm starts searching from the beginning of the read in the index, but cannot continue beyond the fourth <italic>a </italic>character. At this point, we have the first seed <italic>s</italic><sub>1 </sub>= <italic>aaaa</italic>, which occurs at position 101 in the genome. The next character of the read is skipped, and the search continues from position 6, which is the beginning of the second seed. Seed <italic>s</italic><sub>2 </sub>= <italic>ccct </italic>happens to have an accidental occurrence at the position 201, which is not related to the actual read position in the genome. Again, we skip the next (mismatched) character of the read and restart at position 11. This time the search reaches the end of the read, and yields the last seed <italic>s</italic><sub>3 </sub>= <italic>gggtt</italic>, occurring at position 110. These three occurrences are now sorted according to their position in the genome, and it turns out that the occurrences of <italic>s</italic><sub>1 </sub>and <italic>s</italic><sub>3 </sub>form a coherent multiple seed occurrence of combined length 9. The other candidate would be composed of the occurrence <italic>s</italic><sub>2 </sub>alone which is not chosen for expansion since it is smaller. The space between the two seeds is then filled using dynamic programming, and the correct mapped position (101) is returned along with the final alignment.</p>
        </caption>
        <graphic xlink:href="1471-2105-12-163-2"/>
      </fig>
    </sec>
    <sec>
      <title>Synthetic data generation</title>
      <p>In order to evaluate the algorithms in a controlled setting, we generated artificial data sets with a procedure inspired by empirical studies on GS FLX data [<xref ref-type="bibr" rid="B20">20</xref>,<xref ref-type="bibr" rid="B21">21</xref>], and designed to yield reads with characteristics similar to real data. In our procedure, <italic>n </italic>random contiguous subsequences are extracted from a given 'source' sequence <italic>g</italic>. The lengths of these initial subsequences are drawn from a normal distribution with mean <italic>μ<sub>l </sub></italic>and standard deviation <italic>σ<sub>l</sub></italic>, also provided as input. Next, these subsequences are modified to simulate sequencing errors as follows. In the GS FLX high-throughput pyrosequencing procedure, the template molecules are sequenced one maximal homopolymer at a time (formally, a homopolymer can consist of a single base), as opposed to one base at a time in the traditional Sanger method. Hence, the most common type of error in pyrosequencing consist in the misinterpretation of the intensity of the signal that determines the length of the homopolymer being read, leading to an insertion or deletion of identical consecutive bases in the read, relative to the actual template sequence. Miscalled base errors (substitutions) also occur but they are comparatively much less frequent. Sequence quality is known to be non-uniform along the read, being lower at the extremes, particularly towards the 3' end. Also, errors tend to affect long homopolymers more than short ones. However, for the sake of simplification, we consider that errors are uniformly distributed along the read and that the prevalence and size of indels are not affected by the length of the homopolymers. More precisely, the procedure takes in three parameters <italic>p</italic><sub>sub</sub>, <italic>p</italic><sub>ins </sub>and <italic>p</italic><sub>del </sub>which correspond to the probabilities of having a substitution, an insertion or a deletion in any given homopolymer, regardless of its length and position in the read. Moreover, these events are considered to be mutually exclusive, that is, we assume that for any homopolymer being sequenced, there can either be a substitution error with probability <italic>p</italic><sub>sub</sub>, an insertion with probability <italic>p</italic><sub>ins</sub>, a deletion with probability <italic>p</italic><sub>del </sub>or it can be correctly sequenced with probability 1 - (<italic>p</italic><sub>sub </sub>+ <italic>p</italic><sub><italic>i</italic>ns </sub>+ <italic>p</italic><sub>del</sub>). Whenever a mismatch takes place, the miscalled base is randomly chosen according to substitution probabilities indicated in a matrix <italic>m</italic>, given as input. Each row/column of <italic>m </italic>corresponds to a nucleotide and the element <italic>m</italic>[<italic>a</italic>, <italic>b</italic>] indicates the probability for <italic>a </italic>to be miscalled as (replaced by) <italic>b</italic>. As for indels, the lengths of the gaps are drawn from Zipfian distributions, which are discrete power-law distributions with mass function <inline-formula><inline-graphic xlink:href="1471-2105-12-163-i2.gif"/></inline-formula>. In our case, <italic>ω </italic>is a positive integer parameter that corresponds to a maximum allowed gap size, and <italic>γ </italic>&gt; 0 controls the shape of the distribution: the greater its value the higher the prevalence of small gaps. We use specific exponent parameters, <italic>γ</italic><sub>ins </sub>and <italic>γ</italic><sub>del</sub>, for insertion and deletion operations, respectively.</p>
    </sec>
  </sec>
  <sec>
    <title>Results and Discussion</title>
    <p>We evaluated TAPyR against other mainstream mapping tools which are also able to deal with high-throughput pyrosequencing reads, namely BWA-SW [<xref ref-type="bibr" rid="B11">11</xref>], SSAHA2 [<xref ref-type="bibr" rid="B13">13</xref>], Segemehl [<xref ref-type="bibr" rid="B10">10</xref>], GASSST [<xref ref-type="bibr" rid="B12">12</xref>], and Newbler [<xref ref-type="bibr" rid="B14">14</xref>]. Our analyses were performed with real and simulated data sets, with the objective of assessing the efficiency and accuracy of the aforementioned tools in the context of re-sequencing projects.</p>
    <sec>
      <title>Results on real data</title>
      <p>The biological data sets we used, summarized in Table <xref ref-type="table" rid="T1">1</xref>, encompass a reasonable variety of organism types, including two bacteria (<italic>Streptococcus pneumoniae </italic>and <italic>Escherichia coli</italic>), one protozoan (<italic>Plasmodium falciparum</italic>), one nematode (<italic>Caenorhabditis elegans</italic>), one insect (<italic>Drosophila pseudoobscura</italic>), and one human chromosome. They also cover re-sequencing applications with reads from individuals of the same species (human), different and mutated strains of the same species (bacteria and worm), and different (sub-)species (fly).</p>
      <table-wrap id="T1" position="float">
        <label>Table 1</label>
        <caption>
          <p>Real data sets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left">Reference genome Source</th>
              <th align="left">Reference genome size</th>
              <th align="left">SRA accession and species</th>
              <th align="left">Total reads</th>
              <th align="left">Average read length</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left"><italic>S. pneumoniae</italic><break/>ATCC 700669 [GenBank: <ext-link ext-link-type="gen" xlink:href="FM211187">FM211187</ext-link>]</td>
              <td align="left">≈2.2 Mbp</td>
              <td align="left">○ SRR001327 <italic>S. pneumoniae </italic>CDC1873-00<break/>○ SRR001328 <italic>S. pneumoniae </italic>SP195<break/>○ SRR001329 <italic>S. pneumoniae </italic>CDC0288-04</td>
              <td align="left">646,724</td>
              <td align="left">253</td>
            </tr>
            <tr>
              <td colspan="5">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="left"><italic>E. coli </italic>0127:H6 E2348/69 [GenBank: <ext-link ext-link-type="gen" xlink:href="FM180568.1">FM180568.1</ext-link>]</td>
              <td align="left">≈4.96 Mbp</td>
              <td align="left">○ SRR000868 <italic>E. coli </italic>K-12<break/>○ SRR000870 <italic>E. coli </italic>K-12<break/>○ SRR031369 <italic>E. coli </italic>ETEC WS3080A<break/>○ SRR031370 <italic>E. coli </italic>ETEC TW03576</td>
              <td align="left">588,397</td>
              <td align="left">263</td>
            </tr>
            <tr>
              <td colspan="5">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="left"><italic>P. falciparum </italic>3D7 PlasmoDB rel 7.0</td>
              <td align="left">≈23.3 Mbp</td>
              <td align="left">○ SRR006911 <italic>P. falciparum </italic>3D7<break/>○ SRR006912 <italic>P. falciparum </italic>3D7<break/>○ SRR006913 <italic>P. falciparum </italic>3D7<break/>○ SRR006914 <italic>P. falciparum </italic>3D7<break/>○ SRR006915 <italic>P. falciparum </italic>3D7</td>
              <td align="left">203,196</td>
              <td align="left">223</td>
            </tr>
            <tr>
              <td colspan="5">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="left"><italic>C. elegans</italic><break/>WormDB rel.<break/>WS210</td>
              <td align="left">≈103 Mbp</td>
              <td align="left">○ SRR022943 <italic>C. elegans </italic>Lynch MA41 mutation-accumulation line derived from N2.</td>
              <td align="left">3,214,353</td>
              <td align="left">103</td>
            </tr>
            <tr>
              <td colspan="5">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="left"><italic>D. pseudoobscura </italic>FlyBase rel. 2.14</td>
              <td align="left">≈150 Mbp</td>
              <td align="left">○ SRR003807 <italic>D. pseudoobscura </italic>Flagstaff 1993<break/>○ SRR014458 <italic>D. pseudoobscura bogotana </italic>ER (white)<break/>○ SRR014459 <italic>D. pseudoobscura bogotana </italic>ER (white)<break/>○ SRR014460 <italic>D. miranda </italic>strain Mather 1993</td>
              <td align="left">834,659</td>
              <td align="left">239</td>
            </tr>
            <tr>
              <td colspan="5">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="left"><italic>H. sapiens </italic>Chr. 15 ENSEMBL ver. GRCh37</td>
              <td align="left">≈100 Mbp</td>
              <td align="left">○ SRR014420 Human individual NA15510<break/>○ SRR014421 Human individual NA15510<break/>○ SRR014422 Human individual NA15510<break/>○ SRR014423 Human individual NA15510<break/>○ SRR014424 Human individual NA15510<break/>○ SRR014425 Human individual NA15510</td>
              <td align="left">3,204</td>
              <td align="left">212</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>Biological data sets used for the evaluation of the algorithms. The read data sets were downloaded from the Sequence Read Archive (SRA) public repository.</p>
        </table-wrap-foot>
      </table-wrap>
      <p>In this experiment, we wanted to analyze the ability of the algorithms to produce high coverage mappings, which directly relates to the proportion of reads that can be successfully mapped. High coverage is essential to the successful completion of a re-sequencing project, with about 20-25× coverage being required for optimal results with the GS FLX technology [<xref ref-type="bibr" rid="B22">22</xref>]. Attaining such high levels depends naturally on the amount of available data, but equally on the capacity of the alignment tool to map the reads correctly, especially in the presence of inevitable sequencing errors and natural variation. The other aspect we wanted to assess was the efficiency of the algorithms in terms of computation time. Efficiency is a critical aspect for any algorithm in modern high-throughput data processing pipelines, given the rapid increase in the volume of data being produced.</p>
      <p>The results of our tests are shown in Table <xref ref-type="table" rid="T2">2</xref>. In that comparison, we included two lines corresponding to TAPyR being set to report alignments with at least 50% (TAPyR 50) and 85% (TAPyR 85) identity. These illustrative values match the default options of other tools: 85% for Segemehl, and 50% for SSAHA2. As can be seen, in almost all direct comparison scenarios, TAPyR has shown to be several times faster than the other tools. As for the number of successfully aligned reads (the "% reads" columns), we notice first that the other algorithms display quite similar figures, with no tool consistently aligning more reads that the others. With the minimum identity threshold set to 85% (TAPyR 85), our method aligns a smaller quantity of reads. However, if we investigate the number of errors (gaps and mismatches) of the reported alignments by computing the ratio between the number of base-pair matches and the number errors (the "bp/err" columns), we see that TAPyR is using a more conservative heuristic which tends to produce alignments of a higher identity level at the expense of dropping a slightly larger number of reads. Indeed, if we lower minimum identity requirement to 50% (TAPyR 50), then our tool aligns more reads than all the others in all data sets at comparable average error rates, and with a minimal time overhead.</p>
      <table-wrap id="T2" position="float">
        <label>Table 2</label>
        <caption>
          <p>Experimental results with real data</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th/>
              <th align="center" colspan="3">
                <italic>S. pneumoniae</italic>
              </th>
              <th align="center" colspan="3">
                <italic>E. coli</italic>
              </th>
              <th align="center" colspan="3">
                <italic>P. falciparum</italic>
              </th>
            </tr>
            <tr>
              <th/>
              <th align="center">
                <italic>time</italic>
              </th>
              <th align="center">% <italic>reads</italic></th>
              <th align="center">
                <italic>bp/err</italic>
              </th>
              <th align="center">
                <italic>time</italic>
              </th>
              <th align="center">% <italic>reads</italic></th>
              <th align="center">
                <italic>bp/err</italic>
              </th>
              <th align="center">
                <italic>time</italic>
              </th>
              <th align="center">% <italic>reads</italic></th>
              <th align="center">
                <italic>bp/err</italic>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left">BWA-SW</td>
              <td align="center">19m</td>
              <td align="center">92.86</td>
              <td align="center">40</td>
              <td align="center">16m</td>
              <td align="center">65.4</td>
              <td align="center">22</td>
              <td align="center">8m</td>
              <td align="center">95.98</td>
              <td align="center">56</td>
            </tr>
            <tr>
              <td align="left">SSAHA2</td>
              <td align="center">6m</td>
              <td align="center">92.86</td>
              <td align="center">41</td>
              <td align="center">5m</td>
              <td align="center">65.4</td>
              <td align="center">23</td>
              <td align="center">68m</td>
              <td align="center">98.45</td>
              <td align="center">57</td>
            </tr>
            <tr>
              <td align="left">Newbler</td>
              <td align="center">11m</td>
              <td align="center">92.95</td>
              <td align="center">47</td>
              <td align="center">11m</td>
              <td align="center">65.55</td>
              <td align="center">24</td>
              <td align="center">12m</td>
              <td align="center">97.72</td>
              <td align="center">60</td>
            </tr>
            <tr>
              <td align="left">Segemehl</td>
              <td align="center">181m</td>
              <td align="center">90.77</td>
              <td align="center">61</td>
              <td align="center">110m</td>
              <td align="center">62.95</td>
              <td align="center">32</td>
              <td align="center">90m</td>
              <td align="center">98.14</td>
              <td align="center">62</td>
            </tr>
            <tr>
              <td align="left">GASSST</td>
              <td align="center">6m</td>
              <td align="center">89.96</td>
              <td align="center">63</td>
              <td align="center">4m</td>
              <td align="center">62.71</td>
              <td align="center">32</td>
              <td align="center">3m</td>
              <td align="center">62.80</td>
              <td align="center">72</td>
            </tr>
            <tr>
              <td align="left">TAPyR 85</td>
              <td align="center">2m</td>
              <td align="center">88.37</td>
              <td align="center">70</td>
              <td align="center">13m</td>
              <td align="center">59.98</td>
              <td align="center">35</td>
              <td align="center">48s</td>
              <td align="center">95.30</td>
              <td align="center">66</td>
            </tr>
            <tr>
              <td align="left">TAPyR 50</td>
              <td align="center">3m</td>
              <td align="center">93.33</td>
              <td align="center">40</td>
              <td align="center">20m</td>
              <td align="center">66.80</td>
              <td align="center">20</td>
              <td align="center">51s</td>
              <td align="center">98.91</td>
              <td align="center">53</td>
            </tr>
            <tr>
              <td colspan="10">
                <hr/>
              </td>
            </tr>
            <tr>
              <td/>
              <td align="center" colspan="3">
                <bold>
                  <italic>C. elegans</italic>
                </bold>
              </td>
              <td align="center" colspan="3">
                <bold>
                  <italic>D. pseudoobscura</italic>
                </bold>
              </td>
              <td align="center" colspan="3">
                <bold>
                  <italic>H. sapiens</italic>
                </bold>
              </td>
            </tr>
            <tr>
              <td/>
              <td align="center">
                <bold>
                  <italic>time</italic>
                </bold>
              </td>
              <td align="center">
                <bold>% <italic>reads</italic></bold>
              </td>
              <td align="center">
                <bold>
                  <italic>bp/err</italic>
                </bold>
              </td>
              <td align="center">
                <bold>
                  <italic>time</italic>
                </bold>
              </td>
              <td align="center">
                <bold>% <italic>reads</italic></bold>
              </td>
              <td align="center">
                <bold>
                  <italic>bp/err</italic>
                </bold>
              </td>
              <td align="center">
                <bold>
                  <italic>time</italic>
                </bold>
              </td>
              <td align="center">
                <bold>% <italic>reads</italic></bold>
              </td>
              <td align="center">
                <bold>
                  <italic>bp/err</italic>
                </bold>
              </td>
            </tr>
            <tr>
              <td colspan="10">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="left">BWA-SW</td>
              <td align="center">51m</td>
              <td align="center">61.05</td>
              <td align="center">19</td>
              <td align="center">58m</td>
              <td align="center">95.80</td>
              <td align="center">19</td>
              <td align="center">6s</td>
              <td align="center">98.25</td>
              <td align="center">58</td>
            </tr>
            <tr>
              <td align="left">SSAHA2</td>
              <td align="center">513m</td>
              <td align="center">70.40</td>
              <td align="center">18</td>
              <td align="center">92m</td>
              <td align="center">97.30</td>
              <td align="center">18</td>
              <td align="center">16s</td>
              <td align="center">99.44</td>
              <td align="center">54</td>
            </tr>
            <tr>
              <td align="left">Newbler</td>
              <td align="center">45m</td>
              <td align="center">69.07</td>
              <td align="center">19</td>
              <td align="center">119m</td>
              <td align="center">96.86</td>
              <td align="center">23</td>
              <td align="center">1m</td>
              <td align="center">98.72</td>
              <td align="center">78</td>
            </tr>
            <tr>
              <td align="left">Segemehl</td>
              <td align="center">249m</td>
              <td align="center">68.10</td>
              <td align="center">23</td>
              <td align="center">339m</td>
              <td align="center">90.98</td>
              <td align="center">28</td>
              <td align="center">52s</td>
              <td align="center">96.41</td>
              <td align="center">89</td>
            </tr>
            <tr>
              <td align="left">GASSST</td>
              <td align="center">9m</td>
              <td align="center">58.50</td>
              <td align="center">27</td>
              <td align="center">22m</td>
              <td align="center">82.80</td>
              <td align="center">30</td>
              <td align="center">1m</td>
              <td align="center">83.61</td>
              <td align="center">93</td>
            </tr>
            <tr>
              <td align="left">TAPyR 85</td>
              <td align="center">31m</td>
              <td align="center">55.59</td>
              <td align="center">35</td>
              <td align="center">7m</td>
              <td align="center">85.91</td>
              <td align="center">30</td>
              <td align="center">1s</td>
              <td align="center">95.13</td>
              <td align="center">96</td>
            </tr>
            <tr>
              <td align="left">TAPyR 50</td>
              <td align="center">31m</td>
              <td align="center">73.30</td>
              <td align="center">15</td>
              <td align="center">7m</td>
              <td align="center">97.05</td>
              <td align="center">19</td>
              <td align="center">2s</td>
              <td align="center">99.63</td>
              <td align="center">60</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>Results of the experiments performed with real biological data. These tests were run on a Linux server with 16 Gb of RAM. TAPyR was tested under two configurations, requiring alignments with at least 50% and 85% identity, designated by TAPyR 50 and TAPyR 85, respectively. The other tools were run with their default options for 454 data, except for the following modifications. SSAHA2 and Segemehl were set to report only the best alignment for each read. For GASSST, we set the minimum identity to 85% (option <monospace>-p 85</monospace>) to match Segemehl. Newbler was set not to generate large files (option <monospace>-nobig</monospace>) and to load the index into the main memory (option <monospace>-m</monospace>). Reported times refer to the total number of CPU-seconds that the process used directly, as given by the Linux command <monospace>time -f "%U"</monospace>. The average base-pairs-per-error rates ("<italic>bp</italic>/<italic>err</italic>" columns) are computed based on the best reported alignment of each read only.</p>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>Results on synthetic data</title>
      <p>We also performed tests using simulated data produced according to the procedure described in the Methods section. We generated three data sets of <italic>N </italic>= 300,000 synthetic reads from the 250 Mbp sequence of the human chromosome 1 [GenBank: <ext-link ext-link-type="gen" xlink:href="NC_000001.10">NC_000001.10</ext-link>]. These data sets are supposed to mimic the data obtained in a typical run of the GS FLX instrument at different sequencing error levels. Hence, the first data set, hereafter referred to as HS1, was generated with the read generator parameters set as <italic>μ<sub>l </sub></italic>= 250, <italic>σ<sub>l </sub></italic>= 50, <italic>p</italic><sub>ins </sub>= <italic>p</italic><sub>del </sub>= <italic>p</italic><sub>sub </sub>= 0.01, <italic>ω </italic>= 10, <italic>γ</italic><sub>ins </sub>= <italic>γ</italic><sub>del </sub>= 3, and equiprobable substitution rates <italic>M</italic>[<italic>a</italic>, <italic>b</italic>] = 1/3, for <italic>a </italic>≠ <italic>b</italic>. In this setting, we have a 1% chance of each of the three kinds of error when reading a homopolymer. For the second data set, HS2, we increased the error levels of each kind to 5% by setting <italic>p</italic><sub>ins </sub>= <italic>p</italic><sub>del </sub>= <italic>p</italic><sub>sub </sub>= 0.05, and for the third data set, we added a considerable amount of noise by setting <italic>p</italic><sub>ins </sub>= <italic>p</italic><sub>del </sub>= <italic>p</italic><sub>sub </sub>= 0.10 (only 70% of chance for each homopolymer to be sequenced correctly). The purpose of this experiment was mainly to test accuracy of the procedures by computing the fraction of reads mapped back to their original positions, as well as to assess the robustness of the heuristic to different error levels.</p>
      <p>The results of the tests are shown in Table <xref ref-type="table" rid="T3">3</xref>. We notice that all algorithms give quite accurate results in all the tested conditions. In any case, TAPyR behaved among the best in terms of accuracy, mapping virtually all reads correctly, showing thus resilience to noise up the tested levels. Moreover, as in the previous experiments, our method has confirmed to be fastest by a comfortable margin.</p>
      <table-wrap id="T3" position="float">
        <label>Table 3</label>
        <caption>
          <p>Experimental results with synthetic data</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th/>
              <th align="center" colspan="2">HS1</th>
              <th align="center" colspan="2">HS2</th>
              <th align="center" colspan="2">HS3</th>
            </tr>
            <tr>
              <th/>
              <th align="center">
                <italic>time</italic>
              </th>
              <th align="center">% <italic>accuracy</italic></th>
              <th align="center">
                <italic>time</italic>
              </th>
              <th align="center">% <italic>accuracy</italic></th>
              <th align="center">
                <italic>time</italic>
              </th>
              <th align="center">% <italic>accuracy</italic></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left">BWA-SW</td>
              <td align="center">1358s</td>
              <td align="center">99.32</td>
              <td align="center">1269s</td>
              <td align="center">98.81</td>
              <td align="center">1212s</td>
              <td align="center">94.10</td>
            </tr>
            <tr>
              <td align="left">SSAHA2</td>
              <td align="center">5044s</td>
              <td align="center">99.86</td>
              <td align="center">4328s</td>
              <td align="center">99.86</td>
              <td align="center">4121s</td>
              <td align="center">99.18</td>
            </tr>
            <tr>
              <td align="left">Newbler</td>
              <td align="center">1192s</td>
              <td align="center">99.99</td>
              <td align="center">6066s</td>
              <td align="center">95.53</td>
              <td align="center">7260s</td>
              <td align="center">83.25</td>
            </tr>
            <tr>
              <td align="left">Segemehl</td>
              <td align="center">3824s</td>
              <td align="center">99.99</td>
              <td align="center">6823s</td>
              <td align="center">99.95</td>
              <td align="center">6299s</td>
              <td align="center">98.81</td>
            </tr>
            <tr>
              <td align="left">GASSST</td>
              <td align="center">855s</td>
              <td align="center">99.47</td>
              <td align="center">794s</td>
              <td align="center">99.27</td>
              <td align="center">693s</td>
              <td align="center">97.35</td>
            </tr>
            <tr>
              <td align="left">TAPyR 50</td>
              <td align="center">63s</td>
              <td align="center">99.99</td>
              <td align="center">113s</td>
              <td align="center">99.78</td>
              <td align="center">239s</td>
              <td align="center">98.20</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>Results of the experiments performed with synthetic data. The data sets were generated as described in the text. The tests were run under the same conditions as those with real data. Shown is the percentage of reads of each data set that were successfully aligned to their original positions in the reference sequence.</p>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>Memory usage</title>
      <p>We also measured the memory requirements of the evaluated tools in the tests with real data discussed above. The figures presented in Table <xref ref-type="table" rid="T4">4</xref> show the sizes of the index files on disk, when they exist, and the peak usage of main memory for the different data sets. As it can be seen, BWA displayed the smallest requirements in absolute terms, followed closely by TAPyR. The other tools, especially those based on <italic>k</italic>-mer tables, demand substantially more memory. As expected, TAPyR's index files scale linearly with the size of the indexed genomes (by a multiplicative factor of ≈ 1.6). Apart from the index, which is loaded into main memory, TAPyR uses only a small additional amount of space (mainly for the dynamic programming part), so that the total amount of required RAM also scales linearly with the indexed genome (by a factor of ≈ 2.5). These modest and predictable requirements make TAPyR suitable for large genomes with moderately-sized machines.</p>
      <table-wrap id="T4" position="float">
        <label>Table 4</label>
        <caption>
          <p>Memory requirements for real data</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th/>
              <th align="center" colspan="2">
                <italic>S. pneumoniae</italic>
              </th>
              <th align="center" colspan="2">
                <italic>E. coli</italic>
              </th>
              <th align="center" colspan="2">
                <italic>P. falciparum</italic>
              </th>
            </tr>
            <tr>
              <th/>
              <th align="center">
                <italic>index(Mb)</italic>
              </th>
              <th align="center">
                <italic>RAM(Mb)</italic>
              </th>
              <th align="center">
                <italic>index(Mb)</italic>
              </th>
              <th align="center">
                <italic>RAM(Mb)</italic>
              </th>
              <th align="center">
                <italic>index(Mb)</italic>
              </th>
              <th align="center">
                <italic>RAM(Mb)</italic>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left">BWA-SW</td>
              <td align="center">3</td>
              <td align="center">27</td>
              <td align="center">7</td>
              <td align="center">29</td>
              <td align="center">34</td>
              <td align="center">59</td>
            </tr>
            <tr>
              <td align="left">SSAHA2</td>
              <td align="center">517</td>
              <td align="center">788</td>
              <td align="center">521</td>
              <td align="center">773</td>
              <td align="center">552</td>
              <td align="center">717</td>
            </tr>
            <tr>
              <td align="left">Newbler</td>
              <td align="center">n/a</td>
              <td align="center">600</td>
              <td align="center">n/a</td>
              <td align="center">900</td>
              <td align="center">n/a</td>
              <td align="center">500</td>
            </tr>
            <tr>
              <td align="left">Segemehl</td>
              <td align="center">31</td>
              <td align="center">302</td>
              <td align="center">68</td>
              <td align="center">328</td>
              <td align="center">315</td>
              <td align="center">447</td>
            </tr>
            <tr>
              <td align="left">GASSST</td>
              <td align="center">n/a</td>
              <td align="center">2381</td>
              <td align="center">n/a</td>
              <td align="center">2479</td>
              <td align="center">n/a</td>
              <td align="center">2539</td>
            </tr>
            <tr>
              <td align="left">TAPyR 50</td>
              <td align="center">4</td>
              <td align="center">7</td>
              <td align="center">8</td>
              <td align="center">18</td>
              <td align="center">39</td>
              <td align="center">64</td>
            </tr>
            <tr>
              <td colspan="7">
                <hr/>
              </td>
            </tr>
            <tr>
              <td/>
              <td align="center" colspan="2">
                <bold>
                  <italic>C. elegans</italic>
                </bold>
              </td>
              <td align="center" colspan="2">
                <bold>
                  <italic>D. pseudoobscura</italic>
                </bold>
              </td>
              <td align="center" colspan="2">
                <bold>
                  <italic>H. sapiens</italic>
                </bold>
              </td>
            </tr>
            <tr>
              <td/>
              <td align="center">
                <bold>
                  <italic>index(Mb)</italic>
                </bold>
              </td>
              <td align="center">
                <bold>
                  <italic>RAM(Mb)</italic>
                </bold>
              </td>
              <td align="center">
                <bold>
                  <italic>index(Mb)</italic>
                </bold>
              </td>
              <td align="center">
                <bold>
                  <italic>RAM(Mb)</italic>
                </bold>
              </td>
              <td align="center">
                <bold>
                  <italic>index(Mb)</italic>
                </bold>
              </td>
              <td align="center">
                <bold>
                  <italic>RAM(Mb)</italic>
                </bold>
              </td>
            </tr>
            <tr>
              <td colspan="7">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="left">BWA-SW</td>
              <td align="center">144</td>
              <td align="center">149</td>
              <td align="center">210</td>
              <td align="center">208</td>
              <td align="center">118</td>
              <td align="center">103</td>
            </tr>
            <tr>
              <td align="left">SSAHA2</td>
              <td align="center">679</td>
              <td align="center">1559</td>
              <td align="center">755</td>
              <td align="center">1209</td>
              <td align="center">648</td>
              <td align="center">680</td>
            </tr>
            <tr>
              <td align="left">Newbler</td>
              <td align="center">n/a</td>
              <td align="center">5100</td>
              <td align="center">n/a</td>
              <td align="center">2300</td>
              <td align="center">n/a</td>
              <td align="center">500</td>
            </tr>
            <tr>
              <td align="left">Segemehl</td>
              <td align="center">1388</td>
              <td align="center">2439</td>
              <td align="center">2025</td>
              <td align="center">2643</td>
              <td align="center">1134</td>
              <td align="center">1299</td>
            </tr>
            <tr>
              <td align="left">GASSST</td>
              <td align="center">n/a</td>
              <td align="center">5657</td>
              <td align="center">n/a</td>
              <td align="center">6967</td>
              <td align="center">n/a</td>
              <td align="center">4752</td>
            </tr>
            <tr>
              <td align="left">TAPyR 50</td>
              <td align="center">168</td>
              <td align="center">270</td>
              <td align="center">244</td>
              <td align="center">394</td>
              <td align="center">137</td>
              <td align="center">220</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>Memory requirements for the real biological data sets of Table 1. Shown are the index file size (when applicable) and peak main memory usage as measured by the tool <monospace>tstime</monospace></p>
          <p><ext-link ext-link-type="uri" xlink:href="http://bitbucket.org/gsauthof/tstime">http://bitbucket.org/gsauthof/tstime</ext-link>, except for Newbler, whose overall memory demand was estimated through the Linux <monospace>htop</monospace> tool.</p>
        </table-wrap-foot>
      </table-wrap>
    </sec>
  </sec>
  <sec>
    <title>Conclusions</title>
    <p>The combination of state of the art indexing techniques and a seed-based search approach led to the development of a new read mapping method for high-throughput pyrosequencing data. By using an effective heuristic which explores the characteristics of this particular kind of data in the context of typical re-sequencing applications, our method manages to achieve convincing performance in terms of speed and in terms of the number and precision of aligned reads, as demonstrated by our tests with real and simulated data. In fact, our proposed solution has displayed class-leading CPU-time performance and excellent use of input reads in comparison to other mainstream tools. An added-value of our procedure comes from the fact that it requires almost no external parameterization. As a matter of fact, the main user options are end-of-the-chain cutoff parameters that concern the quality of the reported alignments in terms of minimal identity or maximal number of errors, having no consequence on the accuracy of the heuristic and only marginal impact on the overall execution time. Memory requirements are also on par with the best in this category of tools, being not only small in absolute terms but, more importantly, linearly proportional to the size of the input reference sequence by a small factor. Based on these results, we propose that TAPyR constitutes an advantageous alternative for re-sequencing projects based on pyrosequencing data.</p>
  </sec>
  <sec>
    <title>Availability and requirements</title>
    <p>Project name: TAPyR--Tool for the Alignment of Pyrosequencing Reads</p>
    <p>Project home page: <ext-link ext-link-type="uri" xlink:href="http://www.tapyr.net">http://www.tapyr.net</ext-link></p>
    <p>Operating system(s): multiple (requires a C compiler only)</p>
    <p>Programming language: C</p>
    <p>Other requirements: none (see Results section for an idea of memory usage)</p>
    <p>License: GNU GPL</p>
    <p>Restrictions to use by non-academics: none additional</p>
  </sec>
  <sec>
    <title>Authors' contributions</title>
    <p>AF and AO conceived the project. All authors have participated in the design and refinement of the method and in the analysis of the results. FF wrote most of the code, helped by LR and PF. FF and PF collected the data and performed the experiments. The authors collectively drafted the manuscript. PF, AF, and FF wrote most of the text. All authors revised and approved the final version.</p>
  </sec>
</body>
<back>
  <sec>
    <title>Acknowledgements</title>
    <p>We thank Ana Tereza Vasconcelos and her staff from LNCC, Brazil, for sharing their expertise with the GS FLX data and for granting us access to their platform.</p>
    <p><bold>Funding </bold>This work was supported by FCT (INESC-ID multiannual funding) through the PIDDAC Program funds, by the FCT PhD grant SFRH/BD/45586/2008 (FF), and by the PTDC program (project PTDC/EIA-EIA/112283/2009).</p>
  </sec>
  <ref-list>
    <ref id="B1">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Sanger</surname>
          <given-names>F</given-names>
        </name>
        <name>
          <surname>Nicklen</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Coulson</surname>
          <given-names>AR</given-names>
        </name>
        <article-title>DNA sequencing with chain-terminating inhibitors. 1977</article-title>
        <source>Biotechnology</source>
        <year>1992</year>
        <volume>24</volume>
        <fpage>104</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="pmid">1422003</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Bonetta</surname>
          <given-names>L</given-names>
        </name>
        <article-title>Genome sequencing in the fast lane</article-title>
        <source>Nat Methods</source>
        <year>2006</year>
        <volume>3</volume>
        <fpage>141</fpage>
        <lpage>147</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth0206-141</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Schuster</surname>
          <given-names>SC</given-names>
        </name>
        <article-title>Next-generation sequencing transforms today's biology</article-title>
        <source>Nat Methods</source>
        <year>2008</year>
        <volume>5</volume>
        <fpage>16</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth1156</pub-id>
        <pub-id pub-id-type="pmid">18165802</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Pop</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Salzberg</surname>
          <given-names>SL</given-names>
        </name>
        <article-title>Bioinformatics challenges of new sequencing technology</article-title>
        <source>Trends Genet</source>
        <year>2008</year>
        <volume>24</volume>
        <issue>3</issue>
        <fpage>142</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tig.2007.12.006</pub-id>
        <pub-id pub-id-type="pmid">18262676</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Chaisson</surname>
          <given-names>MJ</given-names>
        </name>
        <name>
          <surname>Pevzner</surname>
          <given-names>PA</given-names>
        </name>
        <article-title>Short read fragment assembly of bacterial genomes</article-title>
        <source>Genome Res</source>
        <year>2008</year>
        <volume>18</volume>
        <issue>2</issue>
        <fpage>324</fpage>
        <lpage>30</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.7088808</pub-id>
        <pub-id pub-id-type="pmid">18083777</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Zerbino</surname>
          <given-names>DR</given-names>
        </name>
        <name>
          <surname>Birney</surname>
          <given-names>E</given-names>
        </name>
        <article-title>Velvet: algorithms for de novo short read assembly using de Bruijn graphs</article-title>
        <source>Genome Res</source>
        <year>2008</year>
        <volume>18</volume>
        <issue>5</issue>
        <fpage>821</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.074492.107</pub-id>
        <pub-id pub-id-type="pmid">18349386</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Langmead</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Trapnell</surname>
          <given-names>C</given-names>
        </name>
        <name>
          <surname>Pop</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Salzberg</surname>
          <given-names>SL</given-names>
        </name>
        <article-title>Ultrafast and memory-efficient alignment of short DNA sequences to the human genome</article-title>
        <source>Genome Biol</source>
        <year>2009</year>
        <volume>10</volume>
        <issue>3</issue>
        <fpage>R25</fpage>
        <pub-id pub-id-type="doi">10.1186/gb-2009-10-3-r25</pub-id>
        <pub-id pub-id-type="pmid">19261174</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Li</surname>
          <given-names>H</given-names>
        </name>
        <name>
          <surname>Durbin</surname>
          <given-names>R</given-names>
        </name>
        <article-title>Fast and accurate short read alignment with Burrows-Wheeler transform</article-title>
        <source>Bioinformatics</source>
        <year>2009</year>
        <volume>25</volume>
        <issue>14</issue>
        <fpage>1754</fpage>
        <lpage>60</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btp324</pub-id>
        <pub-id pub-id-type="pmid">19451168</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Li</surname>
          <given-names>R</given-names>
        </name>
        <name>
          <surname>Yu</surname>
          <given-names>C</given-names>
        </name>
        <name>
          <surname>Li</surname>
          <given-names>Y</given-names>
        </name>
        <name>
          <surname>Lam</surname>
          <given-names>TW</given-names>
        </name>
        <name>
          <surname>Yiu</surname>
          <given-names>SM</given-names>
        </name>
        <name>
          <surname>Kristiansen</surname>
          <given-names>K</given-names>
        </name>
        <name>
          <surname>Wang</surname>
          <given-names>J</given-names>
        </name>
        <article-title>SOAP2: an improved ultrafast tool for short read alignment</article-title>
        <source>Bioinformatics</source>
        <year>2009</year>
        <volume>25</volume>
        <issue>15</issue>
        <fpage>1966</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btp336</pub-id>
        <pub-id pub-id-type="pmid">19497933</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Hoffmann</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Otto</surname>
          <given-names>C</given-names>
        </name>
        <name>
          <surname>Kurtz</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Sharma</surname>
          <given-names>CM</given-names>
        </name>
        <name>
          <surname>Khaitovich</surname>
          <given-names>P</given-names>
        </name>
        <name>
          <surname>Vogel</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Stadler</surname>
          <given-names>PF</given-names>
        </name>
        <name>
          <surname>Hackermüller</surname>
          <given-names>J</given-names>
        </name>
        <article-title>Fast mapping of short sequences with mismatches, insertions and deletions using index structures</article-title>
        <source>PLoS Comput Biol</source>
        <year>2009</year>
        <volume>5</volume>
        <issue>9</issue>
        <fpage>e1000502</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1000502</pub-id>
        <pub-id pub-id-type="pmid">19750212</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Li</surname>
          <given-names>H</given-names>
        </name>
        <name>
          <surname>Durbin</surname>
          <given-names>R</given-names>
        </name>
        <article-title>Fast and accurate long-read alignment with Burrows-Wheeler transform</article-title>
        <source>Bioinformatics</source>
        <year>2010</year>
        <volume>26</volume>
        <issue>5</issue>
        <fpage>589</fpage>
        <lpage>95</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btp698</pub-id>
        <pub-id pub-id-type="pmid">20080505</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Rizk</surname>
          <given-names>G</given-names>
        </name>
        <name>
          <surname>Lavenier</surname>
          <given-names>D</given-names>
        </name>
        <article-title>GASSST: global alignment short sequence search tool</article-title>
        <source>Bioinformatics</source>
        <year>2010</year>
        <volume>26</volume>
        <issue>20</issue>
        <fpage>2534</fpage>
        <lpage>40</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq485</pub-id>
        <pub-id pub-id-type="pmid">20739310</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Ning</surname>
          <given-names>Z</given-names>
        </name>
        <name>
          <surname>Cox</surname>
          <given-names>AJ</given-names>
        </name>
        <name>
          <surname>Mullikin</surname>
          <given-names>JC</given-names>
        </name>
        <article-title>SSAHA: a fast search method for large DNA databases</article-title>
        <source>Genome Res</source>
        <year>2001</year>
        <volume>11</volume>
        <issue>10</issue>
        <fpage>1725</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.194201</pub-id>
        <pub-id pub-id-type="pmid">11591649</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Droege</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Hill</surname>
          <given-names>B</given-names>
        </name>
        <article-title>The Genome Sequencer FLX System-longer reads, more applications, straight forward bioinformatics and more complete data sets</article-title>
        <source>J Biotechnol</source>
        <year>2008</year>
        <volume>136</volume>
        <issue>1-2</issue>
        <fpage>3</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jbiotec.2008.03.021</pub-id>
        <pub-id pub-id-type="pmid">18616967</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="book">
        <name>
          <surname>Gusfield</surname>
          <given-names>D</given-names>
        </name>
        <source>Algorithms on strings, trees, and sequences: computer science and computational biology</source>
        <year>1997</year>
        <publisher-name>Cambridge University Press, NY</publisher-name>
      </mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Navarro</surname>
          <given-names>G</given-names>
        </name>
        <name>
          <surname>Mäkinen</surname>
          <given-names>V</given-names>
        </name>
        <article-title>Compressed full-text indexes</article-title>
        <source>ACM Comp Surv</source>
        <year>2007</year>
        <volume>32</volume>
      </mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="other">
        <name>
          <surname>Russo</surname>
          <given-names>L</given-names>
        </name>
        <name>
          <surname>Navarro</surname>
          <given-names>G</given-names>
        </name>
        <name>
          <surname>Oliveira</surname>
          <given-names>A</given-names>
        </name>
        <article-title>Dynamic Fully-Compressed Suffix Trees</article-title>
        <source>Proceedings of the 19th Annual Symposium on Combinatorial Pattern Matching (CPM 2008), LNCS</source>
        <year>2008</year>
        <fpage>191</fpage>
        <lpage>203</lpage>
      </mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Ferragina</surname>
          <given-names>P</given-names>
        </name>
        <name>
          <surname>Manzini</surname>
          <given-names>G</given-names>
        </name>
        <name>
          <surname>Mäkinen</surname>
          <given-names>V</given-names>
        </name>
        <name>
          <surname>Navarro</surname>
          <given-names>G</given-names>
        </name>
        <article-title>Compressed representations of sequences and full-text indexes</article-title>
        <source>Transactions on Algorithms (TALG</source>
        <year>2007</year>
        <volume>3</volume>
        <issue>2</issue>
      </mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="other">
        <name>
          <surname>Burrows</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Wheeler</surname>
          <given-names>DJ</given-names>
        </name>
        <article-title>A Block-Sorting Lossless Data Compression Algorithm</article-title>
        <source>Technical report 124, Palo Alto, CA, Digital Equipment Corporation</source>
        <year>1994</year>
        <ext-link ext-link-type="uri" xlink:href="http://citeseer.ist.psu.edu/76182">http://citeseer.ist.psu.edu/76182</ext-link>
      </mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Huse</surname>
          <given-names>SM</given-names>
        </name>
        <name>
          <surname>Huber</surname>
          <given-names>JA</given-names>
        </name>
        <name>
          <surname>Morrison</surname>
          <given-names>HG</given-names>
        </name>
        <name>
          <surname>Sogin</surname>
          <given-names>ML</given-names>
        </name>
        <name>
          <surname>Welch</surname>
          <given-names>DM</given-names>
        </name>
        <article-title>Accuracy and quality of massively parallel DNA pyrosequencing</article-title>
        <source>Genome Biol</source>
        <year>2007</year>
        <volume>8</volume>
        <issue>7</issue>
        <fpage>R143</fpage>
        <pub-id pub-id-type="doi">10.1186/gb-2007-8-7-r143</pub-id>
        <pub-id pub-id-type="pmid">17659080</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Margulies</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Egholm</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Altman</surname>
          <given-names>WE</given-names>
        </name>
        <name>
          <surname>Attiya</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Bader</surname>
          <given-names>JS</given-names>
        </name>
        <name>
          <surname>Bemben</surname>
          <given-names>LA</given-names>
        </name>
        <name>
          <surname>Berka</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Braverman</surname>
          <given-names>MS</given-names>
        </name>
        <name>
          <surname>Chen</surname>
          <given-names>YJ</given-names>
        </name>
        <name>
          <surname>Chen</surname>
          <given-names>Z</given-names>
        </name>
        <name>
          <surname>Dewell</surname>
          <given-names>SB</given-names>
        </name>
        <name>
          <surname>Du</surname>
          <given-names>L</given-names>
        </name>
        <name>
          <surname>Fierro</surname>
          <given-names>JM</given-names>
        </name>
        <name>
          <surname>Gomes</surname>
          <given-names>XV</given-names>
        </name>
        <name>
          <surname>Godwin</surname>
          <given-names>BC</given-names>
        </name>
        <name>
          <surname>He</surname>
          <given-names>W</given-names>
        </name>
        <name>
          <surname>Helgesen</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Ho</surname>
          <given-names>CH</given-names>
        </name>
        <name>
          <surname>Ho</surname>
          <given-names>CH</given-names>
        </name>
        <name>
          <surname>Irzyk</surname>
          <given-names>GP</given-names>
        </name>
        <name>
          <surname>Jando</surname>
          <given-names>SC</given-names>
        </name>
        <name>
          <surname>Alenquer</surname>
          <given-names>MLI</given-names>
        </name>
        <name>
          <surname>Jarvie</surname>
          <given-names>TP</given-names>
        </name>
        <name>
          <surname>Jirage</surname>
          <given-names>KB</given-names>
        </name>
        <name>
          <surname>Kim</surname>
          <given-names>JB</given-names>
        </name>
        <name>
          <surname>Knight</surname>
          <given-names>JR</given-names>
        </name>
        <name>
          <surname>Lanza</surname>
          <given-names>JR</given-names>
        </name>
        <name>
          <surname>Leamon</surname>
          <given-names>JH</given-names>
        </name>
        <name>
          <surname>Lefkowitz</surname>
          <given-names>SM</given-names>
        </name>
        <name>
          <surname>Lei</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Li</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Lohman</surname>
          <given-names>KL</given-names>
        </name>
        <name>
          <surname>Lu</surname>
          <given-names>H</given-names>
        </name>
        <name>
          <surname>Makhijani</surname>
          <given-names>VB</given-names>
        </name>
        <name>
          <surname>McDade</surname>
          <given-names>KE</given-names>
        </name>
        <name>
          <surname>McKenna</surname>
          <given-names>MP</given-names>
        </name>
        <name>
          <surname>Myers</surname>
          <given-names>EW</given-names>
        </name>
        <name>
          <surname>Nickerson</surname>
          <given-names>E</given-names>
        </name>
        <name>
          <surname>Nobile</surname>
          <given-names>JR</given-names>
        </name>
        <name>
          <surname>Plant</surname>
          <given-names>R</given-names>
        </name>
        <name>
          <surname>Puc</surname>
          <given-names>BP</given-names>
        </name>
        <name>
          <surname>Ronan</surname>
          <given-names>MT</given-names>
        </name>
        <name>
          <surname>Roth</surname>
          <given-names>GT</given-names>
        </name>
        <name>
          <surname>Sarkis</surname>
          <given-names>GJ</given-names>
        </name>
        <name>
          <surname>Simons</surname>
          <given-names>JF</given-names>
        </name>
        <name>
          <surname>Simpson</surname>
          <given-names>JW</given-names>
        </name>
        <name>
          <surname>Srinivasan</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Tartaro</surname>
          <given-names>KR</given-names>
        </name>
        <name>
          <surname>Tomasz</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Vogt</surname>
          <given-names>KA</given-names>
        </name>
        <name>
          <surname>Volkmer</surname>
          <given-names>GA</given-names>
        </name>
        <name>
          <surname>Wang</surname>
          <given-names>SH</given-names>
        </name>
        <name>
          <surname>Wang</surname>
          <given-names>Y</given-names>
        </name>
        <name>
          <surname>Weiner</surname>
          <given-names>MP</given-names>
        </name>
        <name>
          <surname>Yu</surname>
          <given-names>P</given-names>
        </name>
        <name>
          <surname>Begley</surname>
          <given-names>RF</given-names>
        </name>
        <name>
          <surname>Rothberg</surname>
          <given-names>JM</given-names>
        </name>
        <article-title>Genome sequencing in microfabricated high-density picolitre reactors</article-title>
        <source>Nature</source>
        <year>2005</year>
        <volume>437</volume>
        <issue>7057</issue>
        <fpage>376</fpage>
        <lpage>80</lpage>
        <pub-id pub-id-type="pmid">16056220</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Aury</surname>
          <given-names>JM</given-names>
        </name>
        <name>
          <surname>Cruaud</surname>
          <given-names>C</given-names>
        </name>
        <name>
          <surname>Barbe</surname>
          <given-names>V</given-names>
        </name>
        <name>
          <surname>Rogier</surname>
          <given-names>O</given-names>
        </name>
        <name>
          <surname>Mangenot</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Samson</surname>
          <given-names>G</given-names>
        </name>
        <name>
          <surname>Poulain</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Anthouard</surname>
          <given-names>V</given-names>
        </name>
        <name>
          <surname>Scarpelli</surname>
          <given-names>C</given-names>
        </name>
        <name>
          <surname>Artiguenave</surname>
          <given-names>F</given-names>
        </name>
        <name>
          <surname>Wincker</surname>
          <given-names>P</given-names>
        </name>
        <article-title>High quality draft sequences for prokaryotic genomes using a mix of new sequencing technologies</article-title>
        <source>BMC Genomics</source>
        <year>2008</year>
        <volume>9</volume>
        <fpage>603</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2164-9-603</pub-id>
        <pub-id pub-id-type="pmid">19087275</pub-id>
      </mixed-citation>
    </ref>
  </ref-list>
</back>
