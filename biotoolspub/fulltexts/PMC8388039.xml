<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8388039</article-id>
    <article-id pub-id-type="pmid">33576802</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btab098</article-id>
    <article-id pub-id-type="publisher-id">btab098</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Systems Biology</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>NetQuilt: deep multispecies network-based protein function prediction using homology-informed network similarity</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7228-0644</contrib-id>
        <name>
          <surname>Barot</surname>
          <given-names>Meet</given-names>
        </name>
        <xref rid="btab098-cor1" ref-type="corresp"/>
        <aff><institution>Center for Data Science, New York University</institution>, New York, NY 10011, <country country="US">USA</country></aff>
        <!--mmb557@nyu.edu-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gligorijević</surname>
          <given-names>Vladimir</given-names>
        </name>
        <aff><institution>Center for Computational Biology, Flatiron Institute</institution>, New York, NY 10010, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cho</surname>
          <given-names>Kyunghyun</given-names>
        </name>
        <aff><institution>Center for Data Science, New York University</institution>, New York, NY 10011, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Bonneau</surname>
          <given-names>Richard</given-names>
        </name>
        <xref rid="btab098-cor1" ref-type="corresp"/>
        <aff><institution>Center for Data Science, New York University</institution>, New York, NY 10011, <country country="US">USA</country></aff>
        <aff><institution>Center for Computational Biology, Flatiron Institute</institution>, New York, NY 10010, <country country="US">USA</country></aff>
        <!--rb133@nyu.edu-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btab098-cor1">To whom correspondence should be addressed. <email>mmb557@nyu.edu</email> or <email>rb133@nyu.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>15</day>
      <month>8</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-02-12">
      <day>12</day>
      <month>2</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>12</day>
      <month>2</month>
      <year>2021</year>
    </pub-date>
    <volume>37</volume>
    <issue>16</issue>
    <fpage>2414</fpage>
    <lpage>2422</lpage>
    <history>
      <date date-type="received">
        <day>18</day>
        <month>8</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>04</day>
        <month>2</month>
        <year>2021</year>
      </date>
      <date date-type="editorial-decision">
        <day>07</day>
        <month>2</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>09</day>
        <month>2</month>
        <year>2021</year>
      </date>
      <date date-type="corrected-typeset">
        <day>27</day>
        <month>2</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits 
unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btab098.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Transferring knowledge between species is challenging: different species contain distinct proteomes and cellular architectures, which cause their proteins to carry out different functions via different interaction networks. Many approaches to protein functional annotation use sequence similarity to transfer knowledge between species. These approaches cannot produce accurate predictions for proteins without homologues of known function, as many functions require cellular context for meaningful prediction. To supply this context, network-based methods use protein-protein interaction (PPI) networks as a source of information for inferring protein function and have demonstrated promising results in function prediction. However, most of these methods are tied to a network for a single species, and many species lack biological networks.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>In this work, we integrate sequence and network information across multiple species by computing IsoRank similarity scores to create a meta-network profile of the proteins of multiple species. We use this integrated multispecies meta-network as input to train a maxout neural network with Gene Ontology terms as target labels. Our multispecies approach takes advantage of more training examples, and consequently leads to significant improvements in function prediction performance compared to two network-based methods, a deep learning sequence-based method and the BLAST annotation method used in the Critial Assessment of Functional Annotation. We are able to demonstrate that our approach performs well even in cases where a species has no network information available: when an organism’s PPI network is left out we can use our multi-species method to make predictions for the left-out organism with good performance.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The code is freely available at <ext-link xlink:href="https://github.com/nowittynamesleft/NetQuilt" ext-link-type="uri">https://github.com/nowittynamesleft/NetQuilt</ext-link>. The data, including sequences, PPI networks and GO annotations are available at <ext-link xlink:href="https://string-db.org/" ext-link-type="uri">https://string-db.org/</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Science Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>1922658</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NSF Chemical, Bioengineering, Environmental and Transport Systems</institution>
          </institution-wrap>
        </funding-source>
        <award-id>CBET-1728858</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>RM1HG011014</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NIH</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R01HD096770</award-id>
        <award-id>R01CA229235</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Sequences have been the primary source of information protein function prediction, mainly because of their abundance and the ease with which many models can incorporate large amounts of sequence data. However, for function prediction, sequence information fails to give the context of a protein in an organism; this context can be highly relevant in determining the protein’s function. Protein interaction networks, on the other hand, offer a way to understand how proteins function in cellular pathways, and thus have been a powerful source of information for inferring the functions of unannotated proteins (<xref rid="btab098-B2" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btab098-B3" ref-type="bibr">Cho <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btab098-B27" ref-type="bibr">Milenković and Pržulj, 2008</xref>; <xref rid="btab098-B28" ref-type="bibr">Mostafavi<italic toggle="yes">et al.</italic>, 2008</xref>;<xref rid="btab098-B37" ref-type="bibr">Sharan<italic toggle="yes">et al.</italic>, 2007</xref>).</p>
    <p>In community benchmarks, such as the Critical Assessment of Functional Annotation (CAFA), the best-performing methods rely on multiple complementary data sources—protein sequence, structure and network information—in order to make more accurate predictions (<xref rid="btab098-B33" ref-type="bibr">Radivojac<italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btab098-B34" ref-type="bibr">Rentzsch and Orengo, 2009</xref>; <xref rid="btab098-B46" ref-type="bibr">Zhou <italic toggle="yes">et al.</italic>, 2019</xref>). There are many reviews of protein function prediction methods in general (<xref rid="btab098-B9" ref-type="bibr">Friedberg, 2006</xref>; <xref rid="btab098-B19" ref-type="bibr">Kihara, 2016</xref>; <xref rid="btab098-B22" ref-type="bibr">Lee <italic toggle="yes">et al.</italic>, 2007</xref>; <xref rid="btab098-B34" ref-type="bibr">Rentzsch and Orengo, 2009</xref>). Most previous network-based approaches integrate different types of networks containing complementary information to achieve state-of-the-art performance (<xref rid="btab098-B3" ref-type="bibr">Cho <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btab098-B11" ref-type="bibr">Gligorijević<italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btab098-B28" ref-type="bibr">Mostafavi<italic toggle="yes">et al.</italic>, 2008</xref>), but are limited to training on and making predictions for a single organism’s proteins. Methods for sequence and structure-based function prediction are numerous (<xref rid="btab098-B5" ref-type="bibr">Cozzetto<italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btab098-B12" ref-type="bibr">Gligorijevic<italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab098-B13" ref-type="bibr">Gong <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btab098-B21" ref-type="bibr">Kulmanov and Hoehndorf, 2020</xref>); these methods are inherently able to predict functions for proteins of multiple organisms, and can have certain other advantages such as region specificity for predictions (<xref rid="btab098-B12" ref-type="bibr">Gligorijevic<italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab098-B20" ref-type="bibr">Koo and Bonneau, 2019</xref>; <xref rid="btab098-B40" ref-type="bibr">Vacic<italic toggle="yes">et al.</italic>, 2010</xref>). A remaining challenge is using the vast amounts of network information from multiple species in a single model.</p>
    <p>Our method, NetQuilt, accomplishes several important goals in function prediction. First, NetQuilt allows for the integration of sequences and networks, which allows the limited knowledge of the homology between proteins to be supplemented by knowledge of the network topology, and vice versa—incomplete protein-protein interaction networks are supplemented by homology. NetQuilt also creates protein features that are not tied to single species and that include evolutionary and functional information. As a result of the increased training examples in the multispecies setting compared to methods considering only single species, rarer Gene Ontology (GO) (<xref rid="btab098-B1" ref-type="bibr">Ashburner<italic toggle="yes">et al.</italic>, 2000</xref>) terms are able to be trained on. The much larger set of training examples also serves to improve prediction on more abundant terms. Most importantly, our method enables network-based function prediction even for species for which knowledge of their protein interaction networks is limited. We demonstrate the achievement of these goals in several settings. We compare the quality of protein features of a single organism in a single-species versus a multispecies setting. We show that multispecies features are more indicative of a protein’s function than single-species features. We also test the model’s ability to predict functions of a species whose entire PPI network is missing, with the model trained on all other species in the set being considered, in an approach termed ‘leave one species out’ (LOSO). We demonstrate that our model is capable of using information from other species to correctly infer functions of the missing species.</p>
  </sec>
  <sec>
    <title>2 Related work</title>
    <p>Protein function prediction using PPI networks is a node classification problem, the methods for which can be categorized into two groups: label-propagation methods, and classifiers trained on graph features. Label propagation methods propagate labels from labeled nodes to unlabeled nodes via random walks; this strategy is used to predict protein function in a method called GeneMANIA (<xref rid="btab098-B28" ref-type="bibr">Mostafavi<italic toggle="yes">et al.</italic>, 2008</xref>). Another approach, FunctionalFlow, uses the idea of network flow to propagate labels based on simple local rules (<xref rid="btab098-B29" ref-type="bibr">Nabieva<italic toggle="yes">et al.</italic>, 2005</xref>). The category of classifiers trained on graph features can be split further into two categories: those that manually engineer features from the network data, or those methods that learn network embeddings of nodes in order to be used in a classifier. The manually engineered graph features can be based on graph measures such as node degree, neighborhood size within some number of steps, number of shortest paths, etc. Other features that can be constructed over nodes include graphlets (<xref rid="btab098-B27" ref-type="bibr">Milenković and Pržulj, 2008</xref>; <xref rid="btab098-B32" ref-type="bibr">Pržulj, 2007</xref>; <xref rid="btab098-B40" ref-type="bibr">Vacic<italic toggle="yes">et al.</italic>, 2010</xref>), and random walk profiles of nodes within their graph, which have been extended and applied to heterogeneous and multiplex biological networks (<xref rid="btab098-B23" ref-type="bibr">Li and Patra, 2010</xref>; <xref rid="btab098-B41" ref-type="bibr">Valdeolivas<italic toggle="yes">et al.</italic>, 2019</xref>). Network embedding has been extensively used in protein functional analysis and includes methods based on matrix factorization (<xref rid="btab098-B3" ref-type="bibr">Cho <italic toggle="yes">et al.</italic>, 2016</xref>), graph kernels (<xref rid="btab098-B8" ref-type="bibr">Fan <italic toggle="yes">et al.</italic>, 2019</xref>) and deep learning (<xref rid="btab098-B11" ref-type="bibr">Gligorijević<italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btab098-B43" ref-type="bibr">Wan <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab098-B47" ref-type="bibr">Zitnik and Leskovec, 2017</xref>). A comprehensive review of network embedding in computational biology compared to other types of network-based algorithms for several applications can be found in <xref rid="btab098-B30" ref-type="bibr">Nelson <italic toggle="yes">et al.</italic> (2019)</xref>, and reviews of network representation learning methods in general can be found in <xref rid="btab098-B17" ref-type="bibr">Hamilton <italic toggle="yes">et al.</italic> (2017)</xref> and <xref rid="btab098-B15" ref-type="bibr">Goyal and Ferrara (2018)</xref>.</p>
    <p>Our previous study (<xref rid="btab098-B11" ref-type="bibr">Gligorijević<italic toggle="yes">et al.</italic>, 2018</xref>) introduced a method called deepNF (deep Network Fusion), which involves using a multimodal autoencoder to create embeddings of nodes from different types of protein-protein interaction networks of an organism. These embeddings are then used to train support vector machines (SVM) to predict GO terms. This method outperformed other methods using different types of interaction networks to predict function, including Mashup (<xref rid="btab098-B3" ref-type="bibr">Cho <italic toggle="yes">et al.</italic>, 2016</xref>) and GeneMANIA (<xref rid="btab098-B28" ref-type="bibr">Mostafavi<italic toggle="yes">et al.</italic>, 2008</xref>), all of which had access to six STRING network types {’experimental’, ’coexpression’, ’coocurrence’, ’neighborhood’, ’fusion’ and ’database’}. This work demonstrated that multimodal autoencoder neural networks could effectively extract functionally informative features from graphs with multiple edge types. Another method, STRING2GO, uses maxout neural networks in order to create functional representations of proteins from protein interaction networks of a single species (<xref rid="btab098-B43" ref-type="bibr">Wan <italic toggle="yes">et al.</italic>, 2019</xref>). The maxout network is trained to predict GO terms from Mashup or Node2Vec (<xref rid="btab098-B16" ref-type="bibr">Grover and Leskovec, 2016</xref>) node embeddings, and the representations of each protein is taken from the layer before the output predictions. These representations are then used to train SVMs to predict GO terms. The authors show that these representations are able to outperform the original Mashup and Node2Vec embeddings of PPI networks when used to train SVMs for the function prediction task. In <xref rid="btab098-B47" ref-type="bibr">Zitnik and Leskovec (2017)</xref>, an unsupervised neural network is used to learn embeddings from a tissue-specific multi-layer PPI graph. These task-independent embeddings are then used to predict multi-cellular function.</p>
    <p>However, these methods are limited to using information from single organisms for prediction, because they operate on a feature space common only to proteins of that organism. A better approach would be to take into account information from proteins of many different organisms at once in order to take advantage of large-scale training sets.</p>
    <p>A few methods make use of information from protein interaction networks of multiple species. One such method is NetGO, an ensemble learning-to-rank method that combines six component methods, one of which is a k-nearest-neighbors method that uses PPI networks of multiple species (<xref rid="btab098-B44" ref-type="bibr">You <italic toggle="yes">et al.</italic>, 2019</xref>). One drawback to this method is that it is unable to use the homology information in any way beyond direct transfer of annotation between homologues. Ideally, a protein function prediction method should be able to use homology information to supplement network information even on proteins whose sequences are not similar to the training set protein sequences. In addition, MetaGO (<xref rid="btab098-B45" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2018</xref>) is a method that combines scores of sequence homology, structure alignment and homologues of PPI network neighbors combined with logistic regression in order to transfer functional annotations. This method is unable to predict function for a protein without either a sequence homolog, a structurally similar protein in the training set or with a network neighbor with a training set homolog. Another method, MUNK, is a kernel-based method that produces functional embeddings used for predicting synthetic lethality for pairs of proteins of multiple species (<xref rid="btab098-B8" ref-type="bibr">Fan <italic toggle="yes">et al.</italic>, 2019</xref>); they additionally demonstrate that proteins close in this embedding space are similar in function. The key idea of their approach is that proteins from different species are embedded in the same vector space using graph kernels with landmark proteins in the networks of the two species that perform the same functions.</p>
    <p>The problem of network alignment is to find topological and functional similarities between nodes of different networks. Local network alignment algorithms aim to find subgraphs which are conserved between input networks, while the goal of global network alignment algorithms is to find mappings of all nodes between the input networks. Most network alignment methods focus on this latter goal (<xref rid="btab098-B10" ref-type="bibr">Gligorijević<italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btab098-B24" ref-type="bibr">Liao <italic toggle="yes">et al.</italic>, 2009</xref>; <xref rid="btab098-B25" ref-type="bibr">Malod-Dognin and Pržulj, 2015</xref>; <xref rid="btab098-B31" ref-type="bibr">Patro and Kingsford, 2012</xref>; <xref rid="btab098-B36" ref-type="bibr">Saraph and Milenković, 2014</xref>; <xref rid="btab098-B38" ref-type="bibr">Singh <italic toggle="yes">et al.</italic>, 2008</xref>; <xref rid="btab098-B42" ref-type="bibr">Vijayan<italic toggle="yes">et al.</italic>, 2015</xref>).IsoRank (<xref rid="btab098-B38" ref-type="bibr">Singh <italic toggle="yes">et al.</italic>, 2008</xref>) is a global network alignment algorithm used to align multiple PPI networks. This is done in two stages: first by solving an eigenvalue problem across all pairs of input networks to obtain protein similarity scores, and then by using k-partite matching to obtain the final alignment of all organisms, giving sets of functional orthologs across species. IsoRankN (<xref rid="btab098-B24" ref-type="bibr">Liao <italic toggle="yes">et al.</italic>, 2009</xref>) was developed as an improvement to the alignment extraction portion of IsoRank in which instead of k-partite matching, spectral clustering was applied to the meta-graph of all organisms’ proteins induced by the similarity scores given by the eigenvalue problem. More recent global network alignment algorithms include L-GRAAL (<xref rid="btab098-B25" ref-type="bibr">Malod-Dognin and Pržulj, 2015</xref>), which uses a graphlet similarity-scoring function used with a search heuristic based on Lagrangian relaxation, and GHOST, whose key step uses a signature of nodes based on the spectrum of the normalized Laplacian of local subgraphs; this signature is then used to measure topological similarity of networks (<xref rid="btab098-B31" ref-type="bibr">Patro and Kingsford, 2012</xref>). Fuse (<xref rid="btab098-B10" ref-type="bibr">Gligorijević<italic toggle="yes">et al.</italic>, 2016</xref>) is another network alignment method consisting of two steps. The first step calculates functional similarity between proteins using a weighted sum of scores from a non-negative matrix tri-factorization of all considered PPI networks and sequence similarity. The second step constructs an edge-weighted k-partite graph (where k is the number of PPI networks) from these similarities and then obtains the one-to-one network alignment using an approximate maximum weight k-partite matching solver. A comprehensive review of biological network alignment can be found in <xref rid="btab098-B7" ref-type="bibr">Faisal <italic toggle="yes">et al.</italic> (2015)</xref>. Other algorithms for network alignment include those that focus on finding small network region similarities conserved among networks, unconstrained by the assumption of one-to-one mapping of nodes. These algorithms fall into the local network alignment category. A comparison study of local and global network alignment methods can be found in <xref rid="btab098-B26" ref-type="bibr">Meng<italic toggle="yes">et al.</italic> (2016)</xref>, where it was found that network topology has additional biological knowledge compared to sequence data; additionally, global and local network alignment methods may give complementary information for protein function prediction.</p>
    <p>In this study, we use the first step of IsoRank to integrate sequence homology information with PPI network information to generate functionallyinformative similarity scores between species as well as within species themselves. We use these similarity scores for every protein as its feature representation to enable the training of a neural network with proteins coming from many different organisms’ PPI networks in the same input space.</p>
  </sec>
  <sec>
    <title>3 Materials and methods</title>
    <p>In this section, we describe the problem of protein function prediction from PPI network and homology information, define our performance measures and outline the components of our method, NetQuilt. These components are the global network alignment algorithm for creating both intranetwork (within-species) and internetwork (between proteins in different species) node-similarity profiles, and the maxout neural network, which uses the concatenated aligned-network vectors to predict Gene Ontology (GO) terms. See <xref rid="btab098-F1" ref-type="fig">Figure 1</xref>for an overview of the procedure.</p>
    <fig position="float" id="btab098-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>Overview of our method for running on two organisms (human and yeast). (<bold>A</bold>) For each taxonomy ID, download network, annotation and sequence files from the STRING-db static website (version 11). (<bold>B</bold>) Use BLAST to create sequence identity links between proteins of pairs of different species. (<bold>C</bold>) Compute IsoRank scores between proteins of different species, using BLAST sequence identity values and the organisms’ networks to create a combination of network and homology information. (<bold>D</bold>) Use BLAST to create sequence identity links among proteins of each individual species. (<bold>E</bold>) Compute IsoRank alignment scores between proteins of the same species, creating denser matrices <italic toggle="yes">S</italic><sub>11</sub> and <italic toggle="yes">S</italic><sub>22</sub> from weighted adjacency matrices <italic toggle="yes">A</italic><sub>11</sub> and <italic toggle="yes">A</italic><sub>22</sub> and sequence identity matrices <italic toggle="yes">R</italic><sub>11</sub> and <italic toggle="yes">R</italic><sub>22</sub>. (<bold>F</bold>) Concatenate all IsoRank matrices between all species to make the full S matrix. (<bold>G</bold>) Train maxout neural network with the S matrix as features and the annotation matrix as labels</p>
      </caption>
      <graphic xlink:href="btab098f1" position="float"/>
    </fig>
    <sec>
      <title>3.1 Problem specification</title>
      <p>Consider a set of <italic toggle="yes">N<sub>org</sub></italic> undirected graphs, where each graph is a protein-protein interaction network of a different organism. The graphs each have a set of nodes representing proteins for each organism, and a set of edges representing the interactions between these proteins. The graphs are represented by adjacency matrices <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">org</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. Consider further that we have a set <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">org</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">org</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">org</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> of edges representing homology links, between all proteins of all species. Our objective is to assign a predicted GO score vector <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> to each protein <italic toggle="yes">i</italic>, where <italic toggle="yes">c</italic> is the number of considered terms of a particular GO branch, and each entry <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> in <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a score between 0 and 1 representing the confidence of assigning the <italic toggle="yes">j</italic>th GO term to protein <italic toggle="yes">i</italic>.</p>
    </sec>
    <sec>
      <title>3.2 Evaluation metrics</title>
      <p>We evaluate our predictions with three function-centric measures; precision recall curve (AUPR) under macro and micro averaging, as well as function-centric F1-score, and two protein-centric measures; accuracy, and F-max score.</p>
      <p>Under macro averaging, AUPR is calculated for each GO term label in the prediction matrix, and then averaged across all terms. Under micro averaging, the label and prediction matrices are vectorized, and then AUPR is computed across the resulting label and prediction vectors. We calculate F-1 score as in <xref rid="btab098-B11" ref-type="bibr">Gligorijević<italic toggle="yes">et al.</italic> (2018)</xref> and as previously introduced in <xref rid="btab098-B3" ref-type="bibr">Cho <italic toggle="yes">et al.</italic> (2016)</xref>: we take the top three scoring terms for each protein as ‘positive’ predictions, and calculate the geometric mean of precision and recall under‘micro’ averaging for all terms. We have chosen AUPR, rather than the area under the ROC curve, because the ROC can mask poor classification performance in datasets where there is an imbalance of positive labels, which is the case in protein function prediction (<xref rid="btab098-B35" ref-type="bibr">Saito and Rehmsmeier, 2015</xref>).</p>
      <p>The remaining two, accuracy and F-max score, are protein-centric measures. We define accuracy to be the proportion of proteins that were assigned all of their correct GO terms, with no additional terms, using a threshold of 0.5 for assignment. F-max is calculated as in the CAFA competition (<xref rid="btab098-B46" ref-type="bibr">Zhou <italic toggle="yes">et al.</italic>, 2019</xref>): for each protein, calculate the precision and recall of all GO term predictions for a given threshold between 0 and 1, averaging across all proteins, and compute the F-1 score for all thresholds. F-max is then the maximum of these F-1 scores.</p>
    </sec>
    <sec>
      <title>3.3 Creating multispecies similarity profiles with IsoRank</title>
      <p>Our method computes profiles of the nodes in all species’ networks, creating a shared feature space for all proteins, which we then use to train a maxout neural network to predict protein function. We first compute similarity scores between proteins of different species in a way derived from the IsoRank method of multispecies network alignment (<xref rid="btab098-B38" ref-type="bibr">Singh <italic toggle="yes">et al.</italic>, 2008</xref>). The scores are given by the following recurrence equation: 
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>α</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo>α</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula>where:
</p>
      <list list-type="bullet">
        <list-item>
          <p><inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is the similarity matrix between networks (species) <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic> after <italic toggle="yes">t</italic> steps of diffusion;</p>
        </list-item>
        <list-item>
          <p><inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">eval</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the blast e-value similarity between protein <italic toggle="yes">k</italic> in network (species) <italic toggle="yes">i</italic> and protein <italic toggle="yes">l</italic> in network (species) <italic toggle="yes">j</italic>, with a maximum e-value cutoff of 1e-3 and with the log score scaled between 0 and 1.; and</p>
        </list-item>
        <list-item>
          <p><inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>are the row-normalized adjacency matrices of networks (species) <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic>.</p>
        </list-item>
      </list>
      <p>Starting with <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, we iterate this calculation (<xref rid="E1" ref-type="disp-formula">Equation 1</xref>) until convergence with respect to the norm of the difference between the previous matrix <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and the current matrix <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. We then calculate IsoRank similarity scores between proteins <italic toggle="yes">within</italic> each species. This computes‘alignment’ scores between a network and itself, integrating sequence homology scores computed using BLAST and protein-protein interactions.</p>
      <p>We can now construct a large symmetric matrix <bold>S</bold> in which the IsoRank similarity matrices of all species with themselves are placed along the diagonal, resulting in a block-diagonal matrix. Next, each interspecies protein similarity matrix <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is placed on the off-diagonal, comprising the submatrix with row indices of the proteins of species <italic toggle="yes">i</italic> and column indices of the proteins of species <italic toggle="yes">j</italic>. Refer to steps B, C, D, E and F in <xref rid="btab098-F1" ref-type="fig">Figure 1</xref> for a visual description of this matrix construction. <bold>S</bold> now contains the information from all the individual protein interaction networks as well as the links between them, integrated with sequence-similarity information. We finally use this matrix as input to a maxout neural network, with each row of the matrix <bold>S</bold> being used as a single training sample. We note that since the maxout neural network input depends on the dimensionality of <bold>S</bold>, the total number of proteins considered by the algorithm is limited by the available GPU memory to contain a batch of training samples.</p>
    </sec>
    <sec>
      <title>3.4 Using maxout neural networks to predict protein function from aligned Meta-network features</title>
      <p>Maxout neural networks, introduced in <xref rid="btab098-B14" ref-type="bibr">Goodfellow<italic toggle="yes">et al.</italic> (2013)</xref>, are neural networks whose layers have the maxout activation function. The maxout activation of a layer is the element-wise maximum of a set of affine transformations to the input of that layer. More explicitly, a maxout layer’s <italic toggle="yes">i</italic>th output value <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> given an input <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> is defined as: 
<disp-formula id="E2"><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula>where<inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo>:</mml:mo><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the <italic toggle="yes">i</italic>th element of the <italic toggle="yes">j</italic>th affine transformation of the input vector with learned parameters <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mi>W</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mi>b</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. Maxout activation functions are able to approximate arbitrary convex functions given a sufficient number of maxout units, (i.e. affine transformations), and therefore enable the neural network to learn not only relationships between hidden units but also the activation functions themselves. This provides additional flexibility, which enables the neural network to learn features that are more specifically tailored to a prediction task.</p>
      <p><xref rid="btab098-B14" ref-type="bibr">Goodfellow<italic toggle="yes">et al.</italic> (2013)</xref> also demonstrated that maxout networks more precisely approximate the average over all neural networks with randomly dropped out connections every iteration. This can be interpreted as a more effective approximation of an ensemble of these neural networks. This applies to the ReLU activation function as well: in fact, maxout activation can be seen as a generalization of ReLU, which is itself a piecewise linear function. However, maxout activation does not have the problem of output units ‘dying’—becoming and staying at 0 during optimization.</p>
      <p>The architectures for our models are listed in <xref rid="btab098-T1" ref-type="table">Table 1</xref> (see also part G in <xref rid="btab098-F1" ref-type="fig">Fig. 1</xref>). To avoid overfitting, we use early stopping with the criterion of improving AUPR calculated over a validation set consisting of 20% of the training data, with patience 30 (i.e. if the AUPR score does not improve in 30 consecutive epochs, the training is stopped).</p>
      <table-wrap position="float" id="btab098-T1">
        <label>Table 1.</label>
        <caption>
          <p>Model architectures for Eukaryote and Bacteria datasets (see Section 3.5 for a description of these datasets)</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Hyperparameters</th>
              <th rowspan="1" colspan="1">Bacteria</th>
              <th rowspan="1" colspan="1">Eukaryotes</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Hidden layer dimensions</td>
              <td rowspan="1" colspan="1">[500, 800, 800]</td>
              <td rowspan="1" colspan="1">[500, 800, 800]</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Maxout units</td>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">4</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Dropout</td>
              <td rowspan="1" colspan="1">0.2</td>
              <td rowspan="1" colspan="1">0.2</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Batch normalization</td>
              <td rowspan="1" colspan="1">True</td>
              <td rowspan="1" colspan="1">True</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Learning rate</td>
              <td rowspan="1" colspan="1">0.01</td>
              <td rowspan="1" colspan="1">0.01</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Batch size</td>
              <td rowspan="1" colspan="1">16</td>
              <td rowspan="1" colspan="1">32</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Max number of epochs</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">300</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Optimizer</td>
              <td rowspan="1" colspan="1">AdaGrad</td>
              <td rowspan="1" colspan="1">AdaGrad</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic toggle="yes">Note</italic>: ‘Maxout units’ refers to the number of separate weight matrices for a given layer; the element-wise max is computed over the product of the weight matrices with the outputs of the previous layer. Batch normalization (<xref rid="btab098-B18" ref-type="bibr">Ioffe and Szegedy, 2015</xref>) and AdaGrad (<xref rid="btab098-B6" ref-type="bibr">Duchi<italic toggle="yes">et al.</italic>, 2011</xref>) were used for both sets of species.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>The architectures were chosen using cross-validation performance on datasets for eukaryotes and bacteria using a previous version of the STRING (v10.5) database (<xref rid="btab098-B39" ref-type="bibr">Szklarczyk<italic toggle="yes">et al.</italic>, 2017</xref>) for annotations and network information. The hyperparameter search started with an architecture based on <xref rid="btab098-B43" ref-type="bibr">Wan <italic toggle="yes">et al.</italic> (2019)</xref>, with three rounds of random search, trying 1% of possible models each round. We include a list of hyperparameter ranges for these rounds, as well as a description of this process, in Supplementary Section S5. Empirically, maxout neural networks performed better than neural networks with sigmoid or ReLU activation functions for this task. Other benefits of maxout neural networks include fast gradient computations relative to other activation functions, e.g. sigmoid, and fewer choices of hyperparameters, since the activation function is learned. The models were implemented using Keras (<xref rid="btab098-B4" ref-type="bibr">Chollet<italic toggle="yes">et al.</italic>, 2015</xref>).</p>
    </sec>
    <sec>
      <title>3.5 Datasets</title>
      <p>We conduct our analyses on both a collection of eukaryote networks and a separate collection of bacteria networks. Each dataset consists of STRING PPI networks, of which we use only the ‘experimental’ category for our method, and Gene Ontology annotations of each organism retrieved from STRING version 11 (<xref rid="btab098-B39" ref-type="bibr">Szklarczyk<italic toggle="yes">et al.</italic>, 2017</xref>). The statistics on the organisms we include in our study are given in Supplementary Figures S1 and S2, which show the networks’ largest connected component ratios and the annotation percentages of proteins present in STRING. The numbers of nodes and experimental PPI edges, for bacteria and eukaryotes, are shown in Supplementary Tables S1 and S2, respectively. In order to select the value of the <italic toggle="yes">α</italic> parameter for our experiments for each set, we tested several values in a single-species cross-validation setting (see Supplementary Figs S3–S5 for the results of the search). The chosen organisms come from the set of organisms that were evaluated in CAFA 4. For the bacteria, all of the organisms from CAFA 4 were used in our pipeline; for the eukaryotes, we selected a subset to conserve memory when training our models (<italic toggle="yes">Caenorhabditis elegans</italic>, <italic toggle="yes">Drosophila melanogaster</italic>, <italic toggle="yes">Danio rerio</italic>, <italic toggle="yes">Homo sapiens</italic>, <italic toggle="yes">Sus scrofa</italic>, <italic toggle="yes">Mus musculus</italic> and <italic toggle="yes">Rattus norvegicus</italic>). We use GO terms that cover between 0.5% - 5% of the species’ proteins in its PPI network (including IEA annotations), and remove proteins without annotations of these GO terms from training and evaluation sets. We note that GO terms, organized in a hierarchy, are dependent on each other, and so average performance across all terms can be influenced by these relationships. A table of the number of GO terms that we consider for both cross-validation and leave-one-species-out validation for each organism can be found in Supplementary Table S3. However, by choosing specific GO terms, with annotations covering between 0.5%-5% of a given organism’s proteome, we reduce the influence of the hierarchy on the aggregated performance as a result of removing the more general terms.</p>
    </sec>
    <sec>
      <title>3.6 Cross-validation</title>
      <p>In our first set of evaluations, in order to compare with single-species methods, we perform cross-validation on a single test species at a time. The performance is averaged over 5 repetitions with 20% of data used as the test set. We train our models, as well as the BLAST baseline, on GO term annotations of any evidence code(<xref rid="btab098-B1" ref-type="bibr">Ashburner<italic toggle="yes">et al.</italic>, 2000</xref>), but evaluate our predictions with annotations of the evidence codes EXP, IDA, IPI, IMP, IGI, IEP, TAS and IC, as previously used in CAFA papers (<xref rid="btab098-B33" ref-type="bibr">Radivojac<italic toggle="yes">et al.</italic>, 2013</xref>). Since, realistically, our method has access to more training examples than the single-species methods, we include three benchmark versions of our method:
</p>
      <list list-type="order">
        <list-item>
          <p>NetQuilt trained on a subsampled set of multispecies annotations, where we randomly subsample training examples equal to the number of training examples we would have if only considering the species being tested on</p>
        </list-item>
        <list-item>
          <p>NetQuilt trained on single-organism annotations, in which we take only rows corresponding to the particular organism being evaluated from the original matrix <italic toggle="yes">S</italic> containing protein similarities among all organisms (for example, training the maxout neural network only on the rows corresponding to human proteins in the block <bold>S</bold> matrix represented in <xref rid="btab098-F1" ref-type="fig">Fig. 1B</xref>)</p>
        </list-item>
        <list-item>
          <p>Single-species Maxout, in which we take only the IsoRank-score matrix for integrating the single organism’s PPI network with sequence homology information from BLAST, but not including similarities to any other organisms’ proteins (for example, training the maxout neural network only on the <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> matrix for human proteins represented in <xref rid="btab098-F1" ref-type="fig">Fig. 1E</xref>)</p>
        </list-item>
      </list>
      <p>These benchmarks allow us to disentangle the effects that the number of training examples and the addition of new features have on performance. In addition to these, we also include deepNF, BLAST [propagating labels from training to test proteins based on sequence similarity as in CAFA (<xref rid="btab098-B33" ref-type="bibr">Radivojac<italic toggle="yes">et al.</italic>, 2013</xref>)], DeepGOPlus (<xref rid="btab098-B21" ref-type="bibr">Kulmanov and Hoehndorf, 2020</xref>) and MetaGO. deepNF includes information from STRING network types not used by our models: i.e. the coexpression, cooccurrence, neighborhood, fusion and database networks. BLAST, like our main multispecies model, uses proteins from all organisms in the set of chosen species to make predictions on the cross-validation test proteins. DeepGOPlus is a method combining predictions from a deep convolutional neural network and homology-based annotation transfer. DeepGOPlus was trained on its original training set described in <xref rid="btab098-B21" ref-type="bibr">Kulmanov and Hoehndorf (2020)</xref> with the default parameters, but with proteins present in our test sets removed for each evaluation. We also include the PPI-network and homology-based scoring pipelines of MetaGO, as a method that uses similar input data. These pipelines of MetaGO made predictions with the default settings for all evaluations. In order to make the comparison to our method fair we excluded the structure-based pipeline from MetaGO as our method uses only sequence and PPI information.</p>
    </sec>
    <sec>
      <title>3.7 Leave-one-species-out validation</title>
      <p>The next set of experiments we performed simulate a scenario in which we use the networks of multiple species in order to predict the functions of proteins of an organism with no PPI network available (a reasonably common occurrence for non-model species). An outline of the procedure is shown in <xref rid="btab098-F2" ref-type="fig">Figure 2</xref>.</p>
      <fig position="float" id="btab098-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Procedure for predicting a network to be used in the leave-one-species-out validation setting, where we assume no knowledge of the PPI network for one organism. First, BLAST connections (represented as purple dashed lines) between the proteins of the known network and the left-out network are created. IsoRank is then run for the interspecies matrix, using the known network <italic toggle="yes">A</italic><sub>1</sub> and the left-out network given by the identity matrix I, giving the IsoRank connections <italic toggle="yes">S</italic><sub>12</sub> depicted by the large green dashed lines. We finally obtain a predicted network by taking the one-mode projection of the IsoRank connections: <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>. In the case of multiple known organisms, we simply take the average of all organisms’ one-mode projections with the left-out organism</p>
        </caption>
        <graphic xlink:href="btab098f2" position="float"/>
      </fig>
      <p>We first take a single organism with its annotations left out from training and used as the test set, and leave out the network for that organism. In order to construct the features of the organism for use in the maxout neural network, we first need to obtain interspecies connections between the test organism and all other organisms in the dataset. To do this, we first calculate the sequence similarity between the test organisms’ proteins and all other organisms’ proteins, and run IsoRank in the previously described way, except that we use the identity matrix in place of the PPI network of the left-out organism. We obtain an <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> interspecies protein similarity matrix <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext>test</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> relating each species’ <italic toggle="yes">n<sub>i</sub></italic> proteins with the test species’ <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> proteins. We then perform a one-mode projection, given by <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext>test</mml:mtext></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext>test</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, which predicts connections between the nodes of the test species from their shared neighbors (through the IsoRank connections) in other species. Since we have a prediction matrix for every other species in the set besides the test species, we take the element-wise mean of these different matrices to get the predicted network <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Finally, using this matrix as a proxy for a real PPI network, we run IsoRank on the matrix with itself, combined with its own species’ BLAST connections, to obtain the matrix <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>test</mml:mtext><mml:mo>,</mml:mo><mml:mtext>test</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. In these LOSO evaluations, we did not remove any network information from MetaGO. It was run under default settings to predict function for the given organisms.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Results</title>
    <p>In the following sections, we present the performance of our method in two evaluation settings. The first setting is cross-validation over the annotations of a single species, in which we can compare our method to single-species network-based methods. The second setting is leave-one-species-out (LOSO) evaluation, in which we leave out both a species’ PPI network and its annotations while using the rest of the organisms to train, as outlined in the previous section.</p>
    <sec>
      <title>4.1 Cross validation over annotations of one species</title>
      <p>We present the performance of our method in cross-validation on <bold>human</bold>, <bold>fly</bold>, <bold>mouse</bold> and <italic toggle="yes">E.coli</italic>. We summarize our results using AUPR under micro and macro averaging, accuracy score (Acc), F1-score and F-max, as described in Section 3.2. We show results separately for the three different branches of Gene Ontology, molecular function (MF), biological process (BP) and cellular component (CC).</p>
      <p>In <xref rid="btab098-F3" ref-type="fig">Figures 3–5</xref>, we see that the NetQuilt network trained on model bacteria proteins outperforms the other methods across the three branches of Gene Ontology for E. coli, human and mouse, for macro and micro AUPRs, F1 score and F-max. This can primarily be attributed to the large number examples included in the training set compared to the benchmark versions of NetQuilt and deepNF, which can only run on a single organism. In addition, the diversity of training examples across multiple species also serves to increase performance, as indicated by the higher performance of the maxout network trained on subsampled sets of annotations from multiple species equal in size to the training set for a single species. As for the methods taking multiple species’ annotations into account, NetQuilt has several advantages allowing it to perform better. Compared to DeepGOPlus, NetQuilt has access to PPI information of several species, whereas DeepGOPlus only uses sequence information. Compared to MetaGO, NetQuilt’s high-capacity neural network is able to learn more complex dependencies between homology and network topology to predict function. However, for the accuracy measure, NetQuilt performs worse than the other methods. It is likely that the 0.5 cutoff, which we use to consider a GO term ‘predicted’ in the accuracy measure, is not optimal for NetQuilt, as its predictions are not necessarily calibrated for classification for that particular cutoff.</p>
      <fig position="float" id="btab098-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Performance comparison of NetQuilt method with baselines. Methods shown: NetQuilt trained on model bacteria annotations; NetQuilt trained on subsampled model bacteria annotations; NetQuilt trained only on <italic toggle="yes">E.coli</italic> str. K-12 substr. MG1655 examples; single-species NetQuilt (taking only the <italic toggle="yes">E.coli</italic>IsoRank matrix and annotations); deepNF (single-species, but integrating 6 STRING network types); DeepGOPlus (trained on original dataset with our test set proteins removed); MetaGO (predicted with PPI+homology pipelines only, using its default dataset of annotations); and CAFA BLAST annotation transfer method using all selected bacteria annotations</p>
        </caption>
        <graphic xlink:href="btab098f3" position="float"/>
      </fig>
      <fig position="float" id="btab098-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Performance comparison of NetQuilt method with baselines. Methods shown: NetQuilt trained on model eukaryote annotations; NetQuilt trained on subsampled model eukaryote annotations; NetQuilt trained only on human examples; single-species NetQuilt (taking only the human IsoRank matrix and annotations); deepNF (single-species, but integrating 6 STRING network types); DeepGOPlus (trained on original dataset with our test set proteins removed); MetaGO (predicted with PPI+homology pipelines only, using its default dataset of annotations); and CAFA BLAST annotation transfer method using all selected eukaryote annotations</p>
        </caption>
        <graphic xlink:href="btab098f4" position="float"/>
      </fig>
      <fig position="float" id="btab098-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>Performance comparison of NetQuilt method with baselines. Methods shown: NetQuilt trained on model eukaryote annotations; NetQuilt trained on subsampled model eukaryote annotations; NetQuilt trained only on <italic toggle="yes">Musmusculus</italic> examples; single-species NetQuilt (taking only the mouse IsoRank matrix and annotations); deepNF (single-species, but integrating 6 STRING network types); DeepGOPlus (trained on original dataset with our test set proteins removed); MetaGO (predicted with PPI+homology pipelines only, using its default dataset of annotations); and CAFA BLAST annotation transfer method using all selected eukaryote annotations</p>
        </caption>
        <graphic xlink:href="btab098f5" position="float"/>
      </fig>
      <p>For fly, shown in <xref rid="btab098-F6" ref-type="fig">Figure 6</xref>, deepNF outperforms our method in the biological process and cellular component branches for the macro and micro AUPR, accuracy and F1 scores. We note that deepNF has additional information—the coexpression, cooccurrence, neighborhood, fusion and database networks—in addition to the experimental PPI network from STRING, while our method incorporates only the experimental network and BLAST connections. The performance of the CAFA BLAST baseline method also performs poorly for fly, which reflects the smaller number and magnitude of BLAST connections between fly and the other organisms (see SupplementaryFig. S7 for network and homology comparisons between eukaryotes). Similarly, for biological process and cellular component, both DeepGOPlus and MetaGO perform relatively poorly compared to their performance in molecular function. This indicates that the homology of the organisms in the set does not give as much information as the other sources of information that deepNF takes into account for the fly protein function prediction task. Since our method also relies on homology information, we expect a corresponding decrease in performance when such information is not as salient to the classification task. We see this effect also in the maxout network trained in the subsampled setting, where homology information from the proteins of other organisms is included in the training data at the expense of other proteins in the fly network.</p>
      <fig position="float" id="btab098-F6">
        <label>Fig. 6.</label>
        <caption>
          <p>Performance comparison of NetQuilt method with baselines. Methods shown: NetQuilt trained on model eukaryote annotations; NetQuilt trained on subsampled model eukaryote annotations; NetQuilt trained only on <italic toggle="yes">D.melanogaster</italic> examples; single-species NetQuilt (taking only the fly IsoRank matrix and annotations); deepNF (single-species, but integrating 6 STRING network types); DeepGOPlus (trained on original dataset with our test set proteins removed); MetaGO (predicted with PPI+homology pipelines only, using its default dataset of annotations); and CAFA BLAST annotation transfer method using all selected eukaryote annotations</p>
        </caption>
        <graphic xlink:href="btab098f6" position="float"/>
      </fig>
      <p>For all organisms, NetQuilt trained only on a single species’ annotations performs similarly whether it uses multispecies features or single-species features.</p>
      <p>For <italic toggle="yes">E.coli</italic> and human, training on multispecies features gives slightly better performance with regard to the molecular function ontology than training on single-species features. However, for cross-validation on human in the biological process ontology, the multispecies features actually decrease performance.</p>
      <p>This is because adding a significantly larger number of features without increasing the number of training examples has limited benefits, with a higher number of parameters needing more samples to train on. On the other hand, both of these baseline models’ performances are comparable to that of deepNF for the molecular function ontology for all of the considered organisms. This suggests that the features based on PPI networks integrated with homology through our method can enable the neural network to have competitive performance even without large numbers of training examples.</p>
    </sec>
    <sec>
      <title>4.2 Leave-one-species-out validation</title>
      <p>In order to explore the performance of our method in a situation in which no PPI interaction network is known for an organism but homology information is present, we present results for E. coli and fly LOSO validation in <xref rid="btab098-F7" ref-type="fig">Figures 7</xref> and <xref rid="btab098-F8" ref-type="fig">8</xref>, and for human and mouse in Supplementary Figures S3 and S4. This setting often describes the case for many newly sequenced species; mass spectrometry or yeast two-hybrid data may not be available for such organisms.</p>
      <fig position="float" id="btab098-F7">
        <label>Fig. 7.</label>
        <caption>
          <p><italic toggle="yes">E.coli</italic> annotations. Training set included all other species listed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref> besides <italic toggle="yes">E.coli</italic> K-12 substr. MG1655, which was the test organism. No PPI network information of the test organism was used for NetQuilt, BLAST and DeepGOPlus.The PPI-network and homology-based scoring pipelines of MetaGO were used to make predictions with the default data and settings for all evaluations</p>
        </caption>
        <graphic xlink:href="btab098f7" position="float"/>
      </fig>
      <fig position="float" id="btab098-F8">
        <label>Fig. 8.</label>
        <caption>
          <p><italic toggle="yes">D.melanogaster</italic> annotations. Training set included all other species listed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref> besides <italic toggle="yes">D.melanogaster</italic>, which was the test organism. No PPI network information of the test organism was used for NetQuilt, BLAST and DeepGOPlus. The PPI-network and homology-based scoring pipelines of MetaGO were used to make predictions with the default data and settings for all evaluations</p>
        </caption>
        <graphic xlink:href="btab098f8" position="float"/>
      </fig>
      <p>For <italic toggle="yes">E.coli</italic>, we see that our model outperforms the CAFA BLAST labeling method, DeepGOPlus and MetaGO. There are annotations available from all other bacteria, including another well-annotated substrain of <italic toggle="yes">E.coli</italic> (K-12 substr. W3110; see SupplementaryFig. S2). BLAST can use these presumably useful homologs in transferring annotations to the <italic toggle="yes">E.coli</italic> K-12 substr. MG1655, our test organism. However, even with this information, our method outperforms BLAST by more than double in the macro-AUPR performance for biological process, and by similarly large margins in the molecular function and cellular component ontologies. MetaGO does do better than the other two benchmark methods, likely because the <italic toggle="yes">E.coli</italic> PPI network information, which was removed for NetQuilt, is quite relevant to the function prediction task. In addition, MetaGO has access to annotations of some test set proteins, given that the default dataset included with the method was not modified.</p>
      <p>For fly, we see NetQuilt generally outperforming the CAFA BLAST labeling method, though for cellular component, the improvement is not as significant. In terms of F-max score, NetQuilt outperforms all other benchmark methods, but MetaGO and DeepGOPlus outperform NetQuilt in the other measures. We note that for MetaGO, the PPI network for fly was not removed, as it was run with its default dataset and settings. This likely contributed to MetaGO’s performance, since NetQuilt outperformed MetaGO when both methods had access to the fly network in the cross-validation setting.</p>
      <p>On human and mouse (see Supplementary Figs S3 and S4), our model performs approximately as well as the CAFA BLAST labeling method. The BLAST labeling method performs much better for these organisms than it does for fly and <italic toggle="yes">E.coli</italic>. When homology information is highly informative, as is the case in human and mouse, BLAST is difficult to improve upon. However, in cases where homology is not as informative for the annotation task, the complementary PPI data used by our model allows for significant improvements in performance.</p>
      <p>We observe consistent underperformance of DeepGOPlus across E. coli, human and mouse organisms in LOSO which could be explained by the fact the DeepGOPlus was trained only on experimental annotations and the removal of the entire organism greatly impairs its performance. MetaGO, too, relies only on experimental evidence codes to transfer annotations to the test proteins. This could be one reason that both MetaGO and DeepGOPlus perform worse than NetQuilt and the BLAST baseline for human and mouse.</p>
      <p>These results show that our method of integrating multiple species’ PPI networks and their homology link information can be used effectively to annotate proteins for organisms for which neither PPI network nor annotations are available. In particular, it shows that we can outperform strictly homology-based predictions when there is PPI network information available for species related to the organism we want to annotate.</p>
    </sec>
  </sec>
  <sec>
    <title>5 Conclusion</title>
    <p>With the arrival of high-throughput experimental techniques came large PPI network datasets of thousands of organisms. Many function prediction algorithms use PPI information for function prediction using a single species at a time. In order to fully exploit this rich source of information, new protein function prediction algorithms should be designed so that multiple PPI networks can be integrated, along with the most abundant source of protein information: homology. We present here a method that is the first of its kind: a multispecies network-based deep learning method for protein function prediction that effectively integrates PPI network information and homology. The integration of multiple PPI networks is based on IsoRank, a PPI network alignment technique that uses homology to transfer topological similarity scores between nodes of different networks. We use the integrated similarity scores as input to a maxout neural network in order to accurately predict protein function. We demonstrate the superiority of our method in Gene Ontology term prediction to single-species network-based approaches, the homology transfer method from the Critical Assessment of Function Annotation (CAFA), the deep learning sequence-based method DeepGOPlus, and the PPI and homology-based pipeline of MetaGO using a cross-validation evaluation.</p>
    <p>The multispecies approach enables us not only to produce better predictions in situations involving completing the annotations of a single species using its PPI network, but also to make accurate network-informed predictions on species for which the organism has either an incomplete or an entirely non-existent PPI network. We show this capability through a leave-one-species-out validation whereby we leave out a species’ network and annotations and train our model on multiple other species, and then evaluate our function predictions on the left-out species. We show that our method can be at least as good as the CAFA homology transfer method in settings in which homology is very informative, and is a great improvement over the CAFA homology transfer method in settings in which homology information is not enough to produce accurate predictions. We show performance increase in most comparisons to DeepGOPlus and MetaGO under this setting as well.</p>
    <p>This method shows promise for training deep learning models on large multispecies PPI network datasets. In light of the informative representations learned by deep-learning algorithms trained on sequence datasets with millions of training examples, we have a vision of applying deep learning techniques similarly to the millions of nodes in all PPI networks. In future work, we hope to explore principled ways of integrating much larger numbers of PPI networks with homology information for function prediction.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btab098_Supplementary_Datay</label>
      <media xlink:href="btab098_supplementary_datay.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors thank Nicholas Carriero and Ian Fisk of the Flatiron Insitute for discussion and help with high performance computing.</p>
    <sec>
      <title>Funding</title>
      <p>R.B. and V.G. acknowledge funding from the Simons Foundation. M.B., K.C. and R.B. acknowledge funding from National Science Foundation (NSF) [1922658] and New York University. R.B. and M.B. acknowledge funding from NSF Chemical, Bioengineering, Environmental and Transport Systems (CBET)[CBET-1728858], National Institutes of Health (NIH) Centers for Excellence in Genomic Science [RM1HG011014], NIH [R01HD096770 and R01CA229235]. K.C. acknowledges funding from Samsung Research (Improving Deep Learning using Latent Structure).</p>
      <p><italic toggle="yes">Conflict of Interest:</italic> The authors declare that there is no conflict of interest regarding this work.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btab098-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ashburner</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2000</year>) <article-title>Gene Ontology: tool for the unification of biology</article-title>. <source>Nat. Genet</source>., <volume>25</volume>, <fpage>25</fpage>–<lpage>29</lpage>.<pub-id pub-id-type="pmid">10802651</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Identifying protein complexes and functional modules-from static PPI networks to dynamic PPI networks</article-title>. <source>Brief. Bioinf</source>., <volume>15</volume>, <fpage>177</fpage>–<lpage>194</lpage>.</mixed-citation>
    </ref>
    <ref id="btab098-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cho</surname><given-names>H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Compact integration of multi-network topology for functional analysis of genes</article-title>. <source>Cell Syst</source>., <volume>3</volume>, <fpage>540</fpage>–<lpage>548.e5</lpage>.<pub-id pub-id-type="pmid">27889536</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B4">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chollet</surname><given-names>F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) Keras. <ext-link xlink:href="https://keras.io" ext-link-type="uri">https://keras.io</ext-link> (accessed July 2020).</mixed-citation>
    </ref>
    <ref id="btab098-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cozzetto</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Ffpred 3: feature-based function prediction for all gene ontology domains</article-title>. <source>Sci. Rep</source>., <volume>6</volume>, <fpage>1</fpage>–<lpage>11</lpage>.<pub-id pub-id-type="pmid">28442746</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Duchi</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) <article-title>Adaptive subgradient methods for online learning and stochastic optimization</article-title>. <source>J. Mach. Learn. Res</source>., <volume>12</volume>, <fpage>2121</fpage>–<lpage>2159</lpage>.</mixed-citation>
    </ref>
    <ref id="btab098-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Faisal</surname><given-names>F.E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>The post-genomic era of biological network alignment</article-title>. <source>EURASIP J. Bioinf. Syst. Biol</source>., <volume>2015</volume>, <fpage>3</fpage>.</mixed-citation>
    </ref>
    <ref id="btab098-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fan</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Functional protein representations from biological networks enable diverse cross-species inference</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>e51</fpage>.<pub-id pub-id-type="pmid">30847485</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friedberg</surname><given-names>I.</given-names></string-name></person-group> (<year>2006</year>) <article-title>Automated protein function prediction-the genomic challenge</article-title>. <source>Brief. Bioinf</source>., <volume>7</volume>, <fpage>225</fpage>–<lpage>242</lpage>.</mixed-citation>
    </ref>
    <ref id="btab098-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gligorijević</surname><given-names>V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Fuse: multiple network alignment via data fusion</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>1195</fpage>–<lpage>1203</lpage>.<pub-id pub-id-type="pmid">26668003</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gligorijević</surname><given-names>V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>deepNF: deep network fusion for protein function prediction</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>3873</fpage>–<lpage>3881</lpage>.<pub-id pub-id-type="pmid">29868758</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gligorijevic</surname><given-names>V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) Structure-based function prediction using graph convolutional networks. <italic toggle="yes">bioRxiv.</italic> DOI: 10.1101/786236.</mixed-citation>
    </ref>
    <ref id="btab098-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gong</surname><given-names>Q.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Gofdr: a sequence alignment based method for predicting protein functions</article-title>. <source>Methods</source>, <volume>93</volume>, <fpage>3</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">26277418</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goodfellow</surname><given-names>I.J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) Maxout networks. International Conference on Machine Learning. PMLR <volume>28</volume>:<fpage>1319</fpage>–<lpage>1327</lpage>.</mixed-citation>
    </ref>
    <ref id="btab098-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goyal</surname><given-names>P.</given-names></string-name>, <string-name><surname>Ferrara</surname><given-names>E.</given-names></string-name></person-group> (<year>2018</year>) <article-title>Graph embedding techniques, applications, and performance: a survey</article-title>. <source>Knowledge Based Syst</source>., <volume>151</volume>, <fpage>78</fpage>–<lpage>94</lpage>.</mixed-citation>
    </ref>
    <ref id="btab098-B16">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Grover</surname><given-names>A.</given-names></string-name>, <string-name><surname>Leskovec</surname><given-names>J.</given-names></string-name></person-group> (<year>2016</year>) node2vec: scalable feature learning for networks. In <italic toggle="yes">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</italic>. San Francisco, California, USA: Association for Computing Machinery (ACM), pp. <fpage>855</fpage>–<lpage>864</lpage>.</mixed-citation>
    </ref>
    <ref id="btab098-B17">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Hamilton</surname><given-names>W.L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) Representation learning on graphs: methods and applications. <italic toggle="yes">IEEE Data Engineering Bulletin,</italic> New York, USA: IEEE, vol. 40, pp.52–74.</mixed-citation>
    </ref>
    <ref id="btab098-B18">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ioffe</surname><given-names>S.</given-names></string-name>, <string-name><surname>Szegedy</surname><given-names>C.</given-names></string-name></person-group> (<year>2015</year>) Batch normalization: accelerating deep network training by reducing internal covariate shift. International conference on machine learning. Lille, France: PMLR, vol. 37, pp. 448–456.</mixed-citation>
    </ref>
    <ref id="btab098-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kihara</surname><given-names>D.</given-names></string-name></person-group> (<year>2016</year>) <article-title>Computational protein function predictions</article-title>. <source>Methods</source>, <volume>93</volume>, <fpage>1</fpage>–<lpage>2</lpage>.<pub-id pub-id-type="pmid">26778120</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Koo</surname><given-names>D.C.E.</given-names></string-name>, <string-name><surname>Bonneau</surname><given-names>R.</given-names></string-name></person-group> (<year>2019</year>) <article-title>Towards region-specific propagation of protein functions</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>1737</fpage>–<lpage>1744</lpage>.<pub-id pub-id-type="pmid">30304483</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kulmanov</surname><given-names>M.</given-names></string-name>, <string-name><surname>Hoehndorf</surname><given-names>R.</given-names></string-name></person-group> (<year>2020</year>) <article-title>Deepgoplus: improved protein function prediction from sequence</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>422</fpage>–<lpage>429</lpage>.<pub-id pub-id-type="pmid">31350877</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2007</year>) <article-title>Predicting protein function from sequence and structure</article-title>. <source>Nat. Rev. Mol. Cell Biol</source>., <volume>8</volume>, <fpage>995</fpage>–<lpage>1005</lpage>.<pub-id pub-id-type="pmid">18037900</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Patra</surname><given-names>J.C.</given-names></string-name></person-group> (<year>2010</year>) <article-title>Genome-wide inferring gene–phenotype relationship by walking on the heterogeneous network</article-title>. <source>Bioinformatics</source>, <volume>26</volume>, <fpage>1219</fpage>–<lpage>1224</lpage>.<pub-id pub-id-type="pmid">20215462</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liao</surname><given-names>C.-S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2009</year>) <article-title>Isorankn: spectral methods for global alignment of multiple protein networks</article-title>. <source>Bioinformatics</source>, <volume>25</volume>, <fpage>i253</fpage>–<lpage>i258</lpage>.<pub-id pub-id-type="pmid">19477996</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Malod-Dognin</surname><given-names>N.</given-names></string-name>, <string-name><surname>Pržulj</surname><given-names>N.</given-names></string-name></person-group> (<year>2015</year>) <article-title>L-graal: Lagrangiangraphlet-based network aligner</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>2182</fpage>–<lpage>2189</lpage>.<pub-id pub-id-type="pmid">25725498</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meng</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Local versus global biological network alignment</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>3155</fpage>–<lpage>3164</lpage>.<pub-id pub-id-type="pmid">27357169</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Milenković</surname><given-names>T.</given-names></string-name>, <string-name><surname>Pržulj</surname><given-names>N.</given-names></string-name></person-group> (<year>2008</year>) <article-title>Uncovering biological network function via graphlet degree signatures</article-title>. <source>Cancer Inf</source>., <volume>6</volume>, <fpage>CIN.S680</fpage>.</mixed-citation>
    </ref>
    <ref id="btab098-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mostafavi</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2008</year>) <article-title>Genemania: a real-time multiple association network integration algorithm for predicting gene function</article-title>. <source>Genome Biol</source>., <volume>9</volume>, <fpage>S4</fpage>.</mixed-citation>
    </ref>
    <ref id="btab098-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nabieva</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2005</year>) <article-title>Whole-proteome prediction of protein function via graph-theoretic analysis of interaction maps</article-title>. <source>Bioinformatics</source>, <volume>21</volume>, <fpage>i302</fpage>–<lpage>i310</lpage>.<pub-id pub-id-type="pmid">15961472</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nelson</surname><given-names>W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>To embed or not: network embedding as a paradigm in computational biology</article-title>. <source>Front. Genet</source>., <volume>10</volume>, <fpage>381</fpage>.<pub-id pub-id-type="pmid">31118945</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Patro</surname><given-names>R.</given-names></string-name>, <string-name><surname>Kingsford</surname><given-names>C.</given-names></string-name></person-group> (<year>2012</year>) <article-title>Global network alignment using multiscale spectral signatures</article-title>. <source>Bioinformatics</source>, <volume>28</volume>, <fpage>3105</fpage>–<lpage>3114</lpage>.<pub-id pub-id-type="pmid">23047556</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pržulj</surname><given-names>N.</given-names></string-name></person-group> (<year>2007</year>) <article-title>Biological network comparison using graphlet degree distribution</article-title>. <source>Bioinformatics</source>, <volume>23</volume>, <fpage>e177</fpage>–<lpage>e183</lpage>.<pub-id pub-id-type="pmid">17237089</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Radivojac</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>A large-scale evaluation of computational protein function prediction</article-title>. <source>Nat. Methods</source>, <volume>10</volume>, <fpage>221</fpage>–<lpage>227</lpage>.<pub-id pub-id-type="pmid">23353650</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rentzsch</surname><given-names>R.</given-names></string-name>, <string-name><surname>Orengo</surname><given-names>C.A.</given-names></string-name></person-group> (<year>2009</year>) <article-title>Protein function prediction—the power of multiplicity</article-title>. <source>Trends Biotechnol</source>.,<volume>27</volume>, <fpage>210</fpage>–<lpage>219</lpage>.<pub-id pub-id-type="pmid">19251332</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Saito</surname><given-names>T.</given-names></string-name>, <string-name><surname>Rehmsmeier</surname><given-names>M.</given-names></string-name></person-group> (<year>2015</year>) <article-title>The precision-recall plot is more informative than the roc plot when evaluating binary classifiers on imbalanced datasets</article-title>. <source>PLoS One</source>, <volume>10</volume>, <fpage>e0118432</fpage>–<lpage>21</lpage>.<pub-id pub-id-type="pmid">25738806</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Saraph</surname><given-names>V.</given-names></string-name>, <string-name><surname>Milenković</surname><given-names>T.</given-names></string-name></person-group> (<year>2014</year>) <article-title>MAGNA: Maximizing Accuracy in Global Network Alignment</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>2931</fpage>–<lpage>2940</lpage>.<pub-id pub-id-type="pmid">25015987</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sharan</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2007</year>) <article-title>Network-based prediction of protein function</article-title>. <source>Mol. Syst. Biol</source>., <volume>3</volume>, <fpage>88</fpage>.<pub-id pub-id-type="pmid">17353930</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singh</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2008</year>) <article-title>Global alignment of multiple protein interaction networks with application to functional orthology detection</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>105</volume>, <fpage>12763</fpage>–<lpage>12768</lpage>.<pub-id pub-id-type="pmid">18725631</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Szklarczyk</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>The STRING database in 2017: quality-controlled protein–protein association networks, made broadly accessible</article-title>. <source>Nucleic Acids Res</source>., <volume>45</volume>, <fpage>D362</fpage>–<lpage>D368</lpage>.<pub-id pub-id-type="pmid">27924014</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vacic</surname><given-names>V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2010</year>) <article-title>Graphlet kernels for prediction of functional residues in protein structures</article-title>. <source>J. Comput. Biol</source>., <volume>17</volume>, <fpage>55</fpage>–<lpage>72</lpage>.<pub-id pub-id-type="pmid">20078397</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Valdeolivas</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Random walk with restart on multiplex and heterogeneous biological networks</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>497</fpage>–<lpage>505</lpage>.<pub-id pub-id-type="pmid">30020411</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vijayan</surname><given-names>V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>MAGNA++: Maximizing Accuracy in Global Network Alignment via both node and edge conservation</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>2409</fpage>–<lpage>2411</lpage>.<pub-id pub-id-type="pmid">25792552</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wan</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Using deep maxout neural networks to improve the accuracy of function prediction from protein interaction networks</article-title>. <source>PLoSOne</source>, <volume>14</volume>, <fpage>e0209958</fpage>.</mixed-citation>
    </ref>
    <ref id="btab098-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>You</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>NetGO: improving large-scale protein function prediction with massive network information</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>W379</fpage>–<lpage>W387</lpage>.<pub-id pub-id-type="pmid">31106361</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Metago: predicting gene ontology of non-homologous proteins through low-resolution protein structure prediction and protein–protein network mapping</article-title>. <source>J. Mol. Biol</source>., <volume>430</volume>, <fpage>2256</fpage>–<lpage>2265</lpage>.<pub-id pub-id-type="pmid">29534977</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>N.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>The cafa challenge reports improved protein function prediction and new functional annotations for hundreds of genes through experimental screens</article-title>. <source>Genome Biol</source>., <volume>20</volume>, <fpage>1</fpage>–<lpage>23</lpage>.<pub-id pub-id-type="pmid">30606230</pub-id></mixed-citation>
    </ref>
    <ref id="btab098-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zitnik</surname><given-names>M.</given-names></string-name>, <string-name><surname>Leskovec</surname><given-names>J.</given-names></string-name></person-group> (<year>2017</year>) <article-title>Predicting multicellular function through multi-layer tissue networks</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>i190</fpage>–<lpage>i198</lpage>.<pub-id pub-id-type="pmid">28881986</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
