<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10425188</article-id>
    <article-id pub-id-type="pmid">37540220</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btad495</article-id>
    <article-id pub-id-type="publisher-id">btad495</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Structural Bioinformatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CoCoNat: a novel method based on deep learning for coiled-coil prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Madeo</surname>
          <given-names>Giovanni</given-names>
        </name>
        <xref rid="btad495-FM1" ref-type="author-notes"/>
        <aff><institution>Biocomputing Group, Department of Pharmacy and Biotechnology, University of Bologna</institution>, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-7359-0633</contrib-id>
        <name>
          <surname>Savojardo</surname>
          <given-names>Castrense</given-names>
        </name>
        <xref rid="btad495-FM1" ref-type="author-notes"/>
        <aff><institution>Biocomputing Group, Department of Pharmacy and Biotechnology, University of Bologna</institution>, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-5479-1723</contrib-id>
        <name>
          <surname>Manfredi</surname>
          <given-names>Matteo</given-names>
        </name>
        <xref rid="btad495-FM1" ref-type="author-notes"/>
        <aff><institution>Biocomputing Group, Department of Pharmacy and Biotechnology, University of Bologna</institution>, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-0274-5669</contrib-id>
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <aff><institution>Biocomputing Group, Department of Pharmacy and Biotechnology, University of Bologna</institution>, <country country="IT">Italy</country></aff>
        <xref rid="btad495-cor1" ref-type="corresp"/>
        <!--pierluigi.martelli@unibo.it-->
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-7462-7039</contrib-id>
        <name>
          <surname>Casadio</surname>
          <given-names>Rita</given-names>
        </name>
        <aff><institution>Biocomputing Group, Department of Pharmacy and Biotechnology, University of Bologna</institution>, <country country="IT">Italy</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Elofsson</surname>
          <given-names>Arne</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btad495-cor1">Corresponding author. Biocomputing Group, Department of Pharmacy and Biotechnology, University of Bologna, via San Giacomo 9/2, 40126 Bologna, Italy. E-mail: <email>pierluigi.martelli@unibo.it</email></corresp>
      <fn id="btad495-FM1">
        <p>Giovanni Madeo and Castrense Savojardo Equal contribution.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="collection">
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-08-04">
      <day>04</day>
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>04</day>
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <volume>39</volume>
    <issue>8</issue>
    <elocation-id>btad495</elocation-id>
    <history>
      <date date-type="received">
        <day>11</day>
        <month>5</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>31</day>
        <month>7</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>01</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>03</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>14</day>
        <month>8</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btad495.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Coiled-coil domains (CCD) are widespread in all organisms and perform several crucial functions. Given their relevance, the computational detection of CCD is very important for protein functional annotation. State-of-the-art prediction methods include the precise identification of CCD boundaries, the annotation of the typical heptad repeat pattern along the coiled-coil helices as well as the prediction of the oligomerization state.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>In this article, we describe CoCoNat, a novel method for predicting coiled-coil helix boundaries, residue-level register annotation, and oligomerization state. Our method encodes sequences with the combination of two state-of-the-art protein language models and implements a three-step deep learning procedure concatenated with a Grammatical-Restrained Hidden Conditional Random Field for CCD identification and refinement. A final neural network predicts the oligomerization state. When tested on a blind test set routinely adopted, CoCoNat obtains a performance superior to the current state-of-the-art both for residue-level and segment-level CCD. CoCoNat significantly outperforms the most recent state-of-the-art methods on register annotation and prediction of oligomerization states.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>CoCoNat web server is available at <ext-link xlink:href="https://coconat.biocomp.unibo.it" ext-link-type="uri">https://coconat.biocomp.unibo.it</ext-link>. Standalone version is available on GitHub at <ext-link xlink:href="https://github.com/BolognaBiocomp/coconat" ext-link-type="uri">https://github.com/BolognaBiocomp/coconat</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Ministry of University and Research</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Coiled-coil domains (CCD) in proteins are structural motifs where α‐helices pack together in an arrangement called knobs into holes (<xref rid="btad495-B2" ref-type="bibr">Crick 1952</xref>, <xref rid="btad495-B3" ref-type="bibr">1953a</xref>, <xref rid="btad495-B4" ref-type="bibr">b</xref>). Since the first crystallographic observation in the structure of influenza virus hemagglutinin (<xref rid="btad495-B32" ref-type="bibr">Wilson <italic toggle="yes">et al.</italic> 1981</xref>), CCDs have been resolved in several proteins through all the kingdoms of life (<xref rid="btad495-B28" ref-type="bibr">Truebestein and Leonard 2016</xref>). CCDs are present, among others, in structural proteins, transcription factors, and enzymes (<xref rid="btad495-B28" ref-type="bibr">Truebestein and Leonard 2016</xref>, <xref rid="btad495-B18" ref-type="bibr">Lupas and Bassler 2017</xref>). CCDs act as molecular spacers, influence the organelle organization, constrain the distance of residues involved in binding and catalytic sites, mediate membrane fusion, and are involved in signal transduction and solute transport.</p>
    <p>Canonical CCDs include the interaction of two or more α‐helices, wound around each other and forming a supercoiled bundle. Each helix is characterized by the repetition of a seven-residue motif (heptad repeat) whose positions are referred to as registers and are labeled as <italic toggle="yes">abcdefg</italic>. Positions <italic toggle="yes">a</italic> and <italic toggle="yes">d</italic> are routinely occupied by hydrophobic residues and mediate the interaction between different helices in the domain. As a result of the formation of the supercoil bundle, the effective periodicity of α‐helices in CCDs changes from 3.6 to 3.5 residues per turn (<xref rid="btad495-B19" ref-type="bibr">Lupas and Gruber 2005</xref>, <xref rid="btad495-B20" ref-type="bibr">Lupas <italic toggle="yes">et al.</italic> 2017</xref>, <xref rid="btad495-B25" ref-type="bibr">Szczepaniak <italic toggle="yes">et al.</italic> 2020</xref>). This implies that residues in the same register lie on the same side of the helix surface. Therefore, the hydrophobic nature of residues in registers <italic toggle="yes">a</italic> and <italic toggle="yes">d</italic> confers a peculiar amphipathic character to the α‐helix. In CCDs, α‐helices interact with each other through their hydrophobic face (<xref rid="btad495-B19" ref-type="bibr">Lupas and Gruber 2005</xref>). CCDs can contain helices characterized by non-canonical repeats, longer than seven residues, i.e. hendecades, pentadecades, and nonadecades (<xref rid="btad495-B19" ref-type="bibr">Lupas and Gruber 2005</xref>, <xref rid="btad495-B25" ref-type="bibr">Szczepaniak <italic toggle="yes">et al.</italic> 2020</xref>). This article does not take into consideration these cases.</p>
    <p>CCDs are classified according to the number and orientation of the involved α‐helices, i.e. by their oligomerization state. CCDs based on the orientation of helices are classified as parallel or antiparallel and based on the number of helices as dimers, trimers, and tetramers.</p>
    <p>CCDs are routinely annotated starting from the protein 3D structure, adopting specialized software such as SOCKET (<xref rid="btad495-B31" ref-type="bibr">Walshaw and Woolfson 2001</xref>) and SamCC-Turbo (<xref rid="btad495-B25" ref-type="bibr">Szczepaniak <italic toggle="yes">et al.</italic> 2020</xref>). Annotations performed with the two methods are collected in the CC+ database (<ext-link xlink:href="http://coiledcoils.chm.bris.ac.uk/ccplus/search/" ext-link-type="uri">http://coiledcoils.chm.bris.ac.uk/ccplus/search/</ext-link>, <xref rid="btad495-B26" ref-type="bibr">Testa <italic toggle="yes">et al.</italic> 2009</xref>) and in the CCdb database (<ext-link xlink:href="https://lbs.cent.uw.edu.pl/ccdb" ext-link-type="uri">https://lbs.cent.uw.edu.pl/ccdb</ext-link>), respectively. Semi-manual annotations are also available in the SCOPe database (<xref rid="btad495-B9" ref-type="bibr">Fox <italic toggle="yes">et al.</italic> 2014</xref>).</p>
    <p>The relevance of CCDs in protein annotation requires the development of computational methods for predicting the presence and localization of CCDs (including registers), and their oligomerization state, starting from the protein sequence. Over the years, several methods have been proposed, addressing the different tasks of CCD prediction. Boundaries of α-helices involved in CCDs can be predicted with COILS (<xref rid="btad495-B17" ref-type="bibr">Lupas <italic toggle="yes">et al.</italic> 1991</xref>), PCOILS (<xref rid="btad495-B10" ref-type="bibr">Gruber <italic toggle="yes">et al.</italic> 2005</xref>), MARCOIL (<xref rid="btad495-B5" ref-type="bibr">Delorenzi and Speed 2002</xref>), Multicoil2 (<xref rid="btad495-B27" ref-type="bibr">Trigg <italic toggle="yes">et al.</italic> 2011</xref>), CCHMM_PROF (<xref rid="btad495-B1" ref-type="bibr">Bartoli <italic toggle="yes">et al.</italic> 2009</xref>), DeepCoil (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>), and CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>).The oligomeric state is predicted with PrOCoil (<xref rid="btad495-B22" ref-type="bibr">Mahrenholz <italic toggle="yes">et al.</italic> 2011</xref>), LOGICOIL (<xref rid="btad495-B30" ref-type="bibr">Vincent <italic toggle="yes">et al.</italic> 2013</xref>), and CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>). To date, methods predicting the registers along the heptad are MARCOIL (<xref rid="btad495-B5" ref-type="bibr">Delorenzi and Speed 2002</xref>), Multicoil2 (<xref rid="btad495-B27" ref-type="bibr">Trigg <italic toggle="yes">et al.</italic> 2011</xref>), DeepCoil2 (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>), and CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>).</p>
    <p>Recently protein language models improved sequence encoding procedures. Here we introduce CoCoNat which, for the first time, adopts a sequence encoding based on the combination of two state-of-the-art protein language models, ProtT5 (<xref rid="btad495-B6" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic> 2021</xref>) and ESM2 (<xref rid="btad495-B15" ref-type="bibr">Lin <italic toggle="yes">et al.</italic> 2023</xref>) and based on deep-learning computes: (i) the coiled-coil helix boundaries; (ii) the residue-level register annotation, and (iii) the CCD oligomerization state.</p>
    <p>We trained CoCoNat on a dataset comprising 2198 proteins containing CCDs and 9062 proteins without CCD (negative examples). When tested on a blind test set including 400 CCD and 318 non-CCD proteins, CoCoNat scores with a performance that is superior to the current state-of-the-art both for residue-level and segment-level CCD detection. Moreover, CoCoNat significantly outperforms other methods, on both register annotation and prediction of CCD oligomerization state.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>CoCoNat is trained and tested on the same datasets adopted in CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>). Numbers are summarized in <xref rid="btad495-T1" ref-type="table">Table 1</xref> and all datasets are available at the CoCoNat website (<ext-link xlink:href="https://coconat.biocomp.unibo.it" ext-link-type="uri">https://coconat.biocomp.unibo.it</ext-link>). Additional statistics on the oligomeric state classification of coiled-coil helices in the training and testing sets are reported in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 1</xref>.</p>
      <table-wrap position="float" id="btad495-T1">
        <label>Table 1.</label>
        <caption>
          <p>Training and testing set of CoCoNat.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Positive proteins</th>
              <th rowspan="1" colspan="1">Helices in CCDs</th>
              <th rowspan="1" colspan="1">Negative proteins</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Training set</td>
              <td rowspan="1" colspan="1">2191</td>
              <td rowspan="1" colspan="1">4342</td>
              <td rowspan="1" colspan="1">9040</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Blind test set</td>
              <td rowspan="1" colspan="1">400</td>
              <td rowspan="1" colspan="1">863</td>
              <td rowspan="1" colspan="1">318</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <sec>
        <title>2.1.1 Training dataset</title>
        <p>The positive training dataset contains 2191 proteins out of the 2337 included in CoCoPRED and deriving from 30,227 CCD-containing proteins annotated with SOCKET (<xref rid="btad495-B31" ref-type="bibr">Walshaw and Woolfson 2001</xref>) in the CC+ database (<xref rid="btad495-B26" ref-type="bibr">Testa <italic toggle="yes">et al.</italic> 2009</xref>).</p>
        <p>Briefly, proteins included in the positive training set of CoCoPRED have been selected with the following criteria: (i) protein structure resolution &lt; 4 Å, (ii) protein length between 25 and 700 residues, (iii) length of CCD helices ≥ 8 residues; (iv) absence of non-canonical (i.e. non-heptad based) CCDs; (v) CCD oligomeric state classified as parallel or antiparallel dimer, trimer, and tetramer; (vi) sequence pairwise identity lower than 30% with respect to proteins in the testing set (see below); and (vii) internal pairwise sequence identity lower than 50%.</p>
        <p>Since CoCoNat relies on full length proteins for the computation of sequence embeddings, we applied further filters to the CoCoPRED positive training dataset, removing: (i) proteins not mapped into UniProt; (ii) synthetic and fusion proteins; and (iii) proteins whose structure coverage with respect to the UniProt sequence is lower than 70%. After this screening, the positive dataset includes 2191 proteins with 4342 coiled-coil helices, whose length ranges from 8 to 145 residues. The number of coiled-coil helices per protein ranges from 1 to 19.</p>
        <p>The negative training set of CoCoNat includes 9040 proteins. This derives from the 9358 proteins of the negative set of CoCoPRED that was obtained from the negative set of DeepCoil (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>) after the exclusion of proteins with a sequence identity &gt; 30% with respect to the blind test set (see Section 2.1.2) and with a sequence identity &gt; 50% with respect to the positive training set. We filtered out proteins not mapped into UniProt.</p>
        <p>Proteins in the training set (both positive and negative examples) were split into 10 subsets for 10-fold cross-validation. To reduce the redundancy among cross-validation sets, proteins sharing more than 25% sequence identity at 50% coverage are clustered in the same set. Cross-validation sets were used to set all the hyperparameters.</p>
      </sec>
      <sec>
        <title>2.1.2 Blind test dataset</title>
        <p>To test and benchmark CoCoNat with other available methods, we adopted the 718 proteins included in the CoCoPRED test set. The CoCoPRED set shares less than 30% sequence identity with proteins in the training sets of CCHMM_PROF (<xref rid="btad495-B1" ref-type="bibr">Bartoli <italic toggle="yes">et al.</italic> 2009</xref>), MARCOIL (<xref rid="btad495-B5" ref-type="bibr">Delorenzi and Speed 2002</xref>), Multicoil2 (<xref rid="btad495-B27" ref-type="bibr">Trigg <italic toggle="yes">et al.</italic> 2011</xref>), CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>), and DeepCoil2 (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>).</p>
        <p>Since coiled-coil annotation for this dataset was not available from the CoCoPRED website, we ran SOCKET in house on the structure of the main biological assembly of each PDB included in the dataset. By this, 400 proteins are annotated as containing CCD while 318 do not contain any coiled-coil segment. Overall, the 400 positive proteins contain 863 coiled-coil helices (<xref rid="btad495-T1" ref-type="table">Table 1</xref>).</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Protein encoding</title>
      <p>CoCoNat makes use of residue embeddings obtained with large-scale protein language models (pLMs) to represent proteins in training and testing sets. Specifically, we adopted two state-of-the-art pLMs: ProtT5 (<xref rid="btad495-B6" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic> 2021</xref>) and ESM2 (<xref rid="btad495-B15" ref-type="bibr">Lin <italic toggle="yes">et al.</italic> 2023</xref>), generating, for each residue in the protein sequence, 1024 and 1280 features, respectively. The ESM2 model has been released in several versions, based on different transformer architectures with a varying number of cascading layers. In order to limit the resources required to compute the representations and having an embedding dimension comparable to that provided by ProtT5, we adopted the intermediate model, providing representations of 1280 components and comprising 33 transformer layers with 650M of parameters. Residue-level representations are then concatenated together, leading to vectors of 2304 dimensions for each residue in the sequences. The concatenation of embeddings obtained with different pLMs has been shown to improve the performance in previous works (<xref rid="btad495-B23" ref-type="bibr">Manfredi <italic toggle="yes">et al.</italic> 2022</xref>, <xref rid="btad495-B24" ref-type="bibr">2023</xref>).</p>
    </sec>
    <sec>
      <title>2.3 CoCoNat architecture</title>
      <p>CoCoNat is organized as a three-step method combining a deep learning approach, a probabilistic graphical model, and a single-layer neural network (NN) in a cascading way. The three different steps of the model are trained independently from each other. The first two steps are collectively devised for detecting coiled-coil helix boundaries and the residue-level annotation of registers within each predicted helix. The third step predicts the CCD oligomerization state (<xref rid="btad495-F1" ref-type="fig">Fig. 1</xref>). In the following sections, each step is briefly described.</p>
      <fig position="float" id="btad495-F1">
        <label>Figure 1.</label>
        <caption>
          <p>Workflow of the predictive model of CoCoNat, comprising three steps. The <italic toggle="yes">step 1</italic> maps each residue, encoded with a 2304-dimensional vector (the concatenation of ProtT5 and ESM2 embeddings) into an eight-dimensional vector representing the probability distribution over the labels (<italic toggle="yes">a–g</italic> registers for coiled-coil helices and <italic toggle="yes">i</italic> for non-CCD portions). It combines in cascade (i) a convolutional layer that computes a 40-dimensional representation for each position in the sequence, based on a sliding window of 15 contiguous residues, (ii) an LSTM layer that analyzes the whole sequence and provides a 128-dimensional representation for each position, and (iii) a fully connected feed-forward NN that, residue by residue, provides the 8-dimensional mapping. The <italic toggle="yes">step 2</italic> consists of a GRHCRF that casts the grammar of CCDs in the topology of the connections among 20 different states. Each sequence is generated by a path that starts from the BEGIN state and can either enter the self-looping <italic toggle="yes">i</italic>0 state, which models the <italic toggle="yes">N</italic>-terminal non-CCD portion of the protein, or the first eight-state block (<italic toggle="yes">1a–1b–1c–1d–1e–1f–1g–1H</italic>), which models the first CCD domain. Labels <italic toggle="yes">a–g</italic> of the states in the block correspond to registers and state <italic toggle="yes">H</italic> accommodates non-regular transitions. Residues after the first coiled-coil helix are modeled by the <italic toggle="yes">i</italic>1 state (non-CCD) and, in case, by a second CCD block (<italic toggle="yes">2a–2b–2c–2d–2e–2f–2g–2H</italic>), analogous to the first one. All states, but <italic toggle="yes">1H</italic> and <italic toggle="yes">2H</italic>, can make transition to the END state, terminating the path. GRHCRF provides the annotation of coiled-coil helix boundaries and of registers by computing the optimal <italic toggle="yes">a posteriori</italic> Viterbi path, given the probabilities computed in the step 1. The <italic toggle="yes">step 3</italic> provides the prediction of the oligomeric state, based on the annotation computed in step 2 and on the 2304-dimensional embedding. For each predicted coiled-coil helix, embeddings labeled with registers <italic toggle="yes">a</italic> and <italic toggle="yes">d</italic> are separately averaged and fed into a feed-forward NN that computes the probability distribution over the four possible classes (parallel and antiparallel dimer, trimer, and tetramer). The three steps of the architecture are trained separately.</p>
        </caption>
        <graphic xlink:href="btad495f1" position="float"/>
      </fig>
      <sec>
        <title>2.3.1 Deep learning architecture</title>
        <p>The first step (<xref rid="btad495-F1" ref-type="fig">Fig. 1</xref>) is based on a convolutional layer (<xref rid="btad495-B13" ref-type="bibr">LeCun <italic toggle="yes">et al.</italic> 1989</xref>) followed by a long short-term memory (LSTM) layer (<xref rid="btad495-B11" ref-type="bibr">Hochreiter and Schmidhuber 1997</xref>). The convolutional layer captures local dependencies of the input data. This layer, adopting a 15 residue long sliding window, takes as input the protein, where each residue is represented with a 2304-feature vector. By applying 40 different filters, the layer outputs the same protein with residues encoded with 40-feature vectors. This mapping is provided as input to a LSTM layer including 128 output neurons, which captures long-range dependencies. Finally, we apply a standard feed-forward network (with 64 hidden neurons) with 8 output neurons (one for each possible coiled-coil registers, <italic toggle="yes">a</italic>–<italic toggle="yes">b–c–d–e–f–g</italic>, plus one, <italic toggle="yes">i,</italic> for non-CCD residues), endowed with a sigmoid activation function. The output gives the per-residue probability of each register or none.</p>
        <p>In order to reduce overfitting, we introduce dropout layers between convolutional, LSTM, and the feed-forward network with rate fixed to 0.25. The architecture was trained with a gradient descent of the Kullback–Leibler divergence error function with the Adam optimization algorithm (<xref rid="btad495-B12" ref-type="bibr">Kingma and Ba 2017</xref>). The Kullback–Leibler loss was chosen since it well-fits with models providing probability distributions in output, as in our case. The best model was determined using the early stopping technique of 10 epochs in which the validation error did not decrease.</p>
      </sec>
      <sec>
        <title>2.3.2 Refining the prediction with Grammatical-Restrained Hidden Conditional Random Field (second step)</title>
        <p>The second step (<xref rid="btad495-F1" ref-type="fig">Fig. 1</xref>) takes in input the probabilites computed by step 1. Grammatical-Restrained Hidden Conditional Random Field (GRHCRF) is a discriminative probabilistic model (<xref rid="btad495-B7" ref-type="bibr">Fariselli <italic toggle="yes">et al.</italic> 2009</xref>, <xref rid="btad495-B21" ref-type="bibr">Madeo <italic toggle="yes">et al.</italic> 2021</xref>), and it allows to introduce the regular grammar of the CDD registers. In the prediction phase, a posterior-Viterbi dynamic-programming algorithm computes the most probable path along the model, satisfying the grammatical constraints.</p>
        <p>In our model, the grammar has two identical blocks for CCD prediction, two states (<italic toggle="yes">i</italic>0 and <italic toggle="yes">i</italic>1 in <xref rid="btad495-F1" ref-type="fig">Fig. 1</xref>, step 2) with a self-loop modeling the non-CCD regions, one BEGIN and one END states. In each CCD block, seven states model the register sequence, and one further state (H, 1, and 2) accommodates non-regular transitions (i.e. transitions escaping the regular heptad repeat pattern, <italic toggle="yes">abcdefg</italic>). The first GRHCRF block models the first coiled-coil helix and the second one models all the others coiled-coil helices, when present, in the protein sequence.</p>
        <p>The GRHCRF output defines the precise identification of CCD boundaries and annotates the typical heptad repeat pattern along the coiled-coil helices.</p>
      </sec>
      <sec>
        <title>2.3.3 Prediction of the oligomerization state</title>
        <p>The prediction of the CCD oligomerization state adopts a simple feed-forward NN with a single hidden layer, comprising 128 neurons, and four output units corresponding to the four possible oligomerization states: parallel and antiparallel dimers, trimers, and tetramers.</p>
        <p>The input of this network is built based on a well-known biophysical feature: the oligomeric state of canonical CCD is largely determined by the nature of hydrophobic residues in the heptad repeat pattern, namely, residues labeled with registers <italic toggle="yes">a</italic> and <italic toggle="yes">d</italic> (<xref rid="btad495-B33" ref-type="bibr">Woolfson 2023</xref>; <xref rid="btad495-B14" ref-type="bibr">Li <italic toggle="yes">et al.</italic> 2016)</xref>. Based on this observation, for a given coiled-coil helix, the network input is obtained concatenating the average embedding vectors of <italic toggle="yes">a</italic> and <italic toggle="yes">d</italic> predicted positions.</p>
        <p>More formally, given a coiled-coil helix of length <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mi>l</mml:mi></mml:math></inline-formula>, with an embedding matrix <italic toggle="yes">E</italic> of dimension <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mi>l</mml:mi><mml:mo>×</mml:mo><mml:mn>2304</mml:mn></mml:math></inline-formula> (as derived from the concatenation of two pLM embeddings, ProtT5 and ESM2), the following two mean vectors are computed:
where <italic toggle="yes">N<sub>a</sub></italic> and <italic toggle="yes">N<sub>d</sub></italic> are the number of positions labeled with registers <italic toggle="yes">a</italic> and <italic toggle="yes">d</italic>, respectively. The input vector for the network is then obtained concatenating <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>:
where <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mo>·</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> denotes the vector concatenation operator.</p>
        <disp-formula id="E1">
          <label>(1)</label>
          <mml:math id="M1" display="block" overflow="scroll">
            <mml:mrow>
              <mml:msub>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mrow>
                          <mml:mi>e</mml:mi>
                        </mml:mrow>
                        <mml:mo>¯</mml:mo>
                      </mml:mover>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>a</mml:mi>
                </mml:mrow>
              </mml:msub>
            </mml:mrow>
            <mml:mo>=</mml:mo>
            <mml:mrow>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
                <mml:mrow>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>a</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
            <mml:mrow>
              <mml:mrow>
                <mml:munder>
                  <mml:mo stretchy="false">∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>r</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mi>a</mml:mi>
                  </mml:mrow>
                </mml:munder>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi>E</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>r</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <disp-formula id="E2">
          <label>(2)</label>
          <mml:math id="M2" display="block" overflow="scroll">
            <mml:mrow>
              <mml:msub>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mrow>
                          <mml:mi>e</mml:mi>
                        </mml:mrow>
                        <mml:mo>¯</mml:mo>
                      </mml:mover>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>d</mml:mi>
                </mml:mrow>
              </mml:msub>
            </mml:mrow>
            <mml:mo>=</mml:mo>
            <mml:mrow>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
                <mml:mrow>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>d</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
            <mml:mrow>
              <mml:mrow>
                <mml:munder>
                  <mml:mo stretchy="false">∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>r</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mi>d</mml:mi>
                  </mml:mrow>
                </mml:munder>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi>E</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>r</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <disp-formula id="E3">
          <label>(3)</label>
          <mml:math id="M3" display="block" overflow="scroll">
            <mml:mi>x</mml:mi>
            <mml:mo>=</mml:mo>
            <mml:mrow>
              <mml:msub>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mrow>
                          <mml:mi>e</mml:mi>
                        </mml:mrow>
                        <mml:mo>¯</mml:mo>
                      </mml:mover>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>a</mml:mi>
                </mml:mrow>
              </mml:msub>
            </mml:mrow>
            <mml:mo>·</mml:mo>
            <mml:mrow>
              <mml:msub>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mrow>
                          <mml:mi>e</mml:mi>
                        </mml:mrow>
                        <mml:mo>¯</mml:mo>
                      </mml:mover>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>d</mml:mi>
                </mml:mrow>
              </mml:msub>
            </mml:mrow>
          </mml:math>
        </disp-formula>
      </sec>
      <sec>
        <title>2.3.4 Model training and selection procedure</title>
        <p>The whole CoCoNat architecture was trained with three independent training procedures for steps 1, 2, and 3.</p>
        <p>The deep-learning architecture of step 1 was optimized using 10-fold cross-validation and a grid search to select the main model hyperparameters. Specifically, we selected the best number of convolutional filters (testing values in the set 10, 20, 40, 80, 160), the optimal LSTM hidden output size (testing values in the set 32, 64, 128, 256), and the optimal number of hidden neurons in the final feed-forward network (testing values in the set 12, 32, 64, 128, 256). The optimal configuration was chosen as the one maximizing the cross-validation <italic toggle="yes">F</italic>1 score at residue level (see next section), and include 40 convolutional filters, 128 units for the LSTM size and 64 neurons in the hidden layer of the final feed-forward network.</p>
        <p>For step 2, the hyperparameters of the GRHCRF include the σ<sup>2</sup> used for L2 regularization and the number of training iterations (<xref rid="btad495-B7" ref-type="bibr">Fariselli <italic toggle="yes">et al.</italic> 2009</xref>). These were optimized in cross-validation and grid search testing various combinations (σ<sup>2</sup> in the set 0.0001, 0.001, 0.05, 0.1 and iterations in the set 10, 20, 40, 100). The optimal values are σ<sup>2</sup>= 0.05 and 40 iterations.</p>
        <p>Finally, step 3 architecture only required to optimize the number of hidden neurons. Again, we tested different values (16, 32, 64, 128, 256) and selected the optimal one as those maximizing the average MCC across the four oligomeric states. The best value is 128.</p>
        <p>Steps 1 and 3 architectures are implemented in PyTorch (<ext-link xlink:href="https://pytorch.org/" ext-link-type="uri">https://pytorch.org/</ext-link>). The GRHCRF is implemented using the biocrf package (<xref rid="btad495-B7" ref-type="bibr">Fariselli <italic toggle="yes">et al.</italic> 2009</xref>).</p>
      </sec>
    </sec>
    <sec>
      <title>2.4 Scoring performance</title>
      <p>To evaluate the performance of our method in recognizing coiled-coil helices, we adopted residue- and segment-based measures.</p>
      <p>The residue-based scores include precision (PRE<sub>R</sub>), recall (REC<sub>R</sub>), and <italic toggle="yes">F</italic>1-score (<italic toggle="yes">F</italic>1<sub>R</sub>).
where TP<sub>R</sub>, FP<sub>R</sub>, and FN<sub>R</sub> are true positive, false positive, and false negative coiled-coiled residues, respectively.</p>
      <disp-formula id="E4">
        <label>(4)</label>
        <mml:math id="M4" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="normal">PRE</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="normal">R</mml:mi>
              </mml:mrow>
            </mml:msub>
          </mml:mrow>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">FP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula id="E5">
        <label>(5)</label>
        <mml:math id="M5" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="normal">REC</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="normal">R</mml:mi>
              </mml:mrow>
            </mml:msub>
          </mml:mrow>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">FN</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula id="E6">
        <label>(6)</label>
        <mml:math id="M6" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi>F</mml:mi>
                <mml:mn>1</mml:mn>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="normal">R</mml:mi>
              </mml:mrow>
            </mml:msub>
          </mml:mrow>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mn>2</mml:mn>
                <mml:mo>×</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">PRE</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>×</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">REC</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">PRE</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">REC</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>Analogously, the segment-based scores include precision (PRE<sub>S</sub>), recall (REC<sub>S</sub>), and <italic toggle="yes">F</italic>1-score (<italic toggle="yes">F</italic>1<sub>S</sub>):
</p>
      <disp-formula id="E7">
        <label>(7)</label>
        <mml:math id="M7" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="normal">PRE</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="normal">S</mml:mi>
              </mml:mrow>
            </mml:msub>
          </mml:mrow>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">FP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula id="E8">
        <label>(8)</label>
        <mml:math id="M8" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="normal">REC</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="normal">S</mml:mi>
              </mml:mrow>
            </mml:msub>
          </mml:mrow>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">FN</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula id="E9">
        <label>(9)</label>
        <mml:math id="M9" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi>F</mml:mi>
                <mml:mn>1</mml:mn>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>S</mml:mi>
              </mml:mrow>
            </mml:msub>
          </mml:mrow>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mn>2</mml:mn>
                <mml:mo>×</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">PRE</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>×</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">REC</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">PRE</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">REC</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>In this case, TP<sub>S</sub>, FP<sub>S,</sub> and FN<sub>S</sub> are computed for the coiled-coil helices. Prediction is considered correct (TP<sub>S</sub>) only if the overlap between predicted and observed segments is at least equal to the half-length of the longest segment.</p>
      <p>Following <xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> (2022)</xref>, we used two segment overlap (SOV) measures, one taking as reference observed residues (SOVo) and one taking as reference predicted residues (SOVp) (<xref rid="btad495-B34" ref-type="bibr">Zemla <italic toggle="yes">et al.</italic> 1999</xref>).</p>
      <p>We computed the precision-recall (PR) curve and the relative area under the curve (PR-AUC), by plotting the two measures at varying thresholds of coiled-coil probabilities as obtained from the GRHCRF posterior probability values.</p>
      <p>For the register and oligomeric state prediction tasks, we reported class-level MCC values:
</p>
      <disp-formula id="E10">
        <label>(10)</label>
        <mml:math id="M10" display="block" overflow="scroll">
          <mml:mi mathvariant="normal">MCC</mml:mi>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mi mathvariant="normal">TP</mml:mi>
                <mml:mo>×</mml:mo>
                <mml:mi mathvariant="normal">TN</mml:mi>
                <mml:mo>-</mml:mo>
                <mml:mi mathvariant="normal">FP</mml:mi>
                <mml:mo>×</mml:mo>
                <mml:mi mathvariant="normal">FN</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:msqrt>
                  <mml:mo>(</mml:mo>
                  <mml:mi mathvariant="normal">TP</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="normal">FP</mml:mi>
                  <mml:mo>)</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mi mathvariant="normal">TP</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="normal">FN</mml:mi>
                  <mml:mo>)</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mi mathvariant="normal">TN</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="normal">FP</mml:mi>
                  <mml:mo>)</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mi mathvariant="normal">TN</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="normal">FN</mml:mi>
                  <mml:mo>)</mml:mo>
                </mml:msqrt>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Visualizing ProtT5 and ESM2 embeddings with t-SNE</title>
      <p>For evaluating whether the two language models capture coiled-coil-related features in their representations, we adopted <italic toggle="yes">t</italic>-SNE (<xref rid="btad495-B29" ref-type="bibr">van der Maaten and Hinton 2008</xref>) to project raw embedding vectors obtained with ProtT5 and ESM2 in two dimensions.</p>
      <p>First, we wanted to assess if the raw embeddings can distinguish the different register features. To this aim, we projected all representations of coiled-coil residues in the training set, and then we colored projected points by the heptad repeat register they are annotated with, distinguishing two classes: hydrophobic register positions (<italic toggle="yes">a</italic> and <italic toggle="yes">d</italic>) and polar positions (<italic toggle="yes">b</italic>, <italic toggle="yes">c</italic>, <italic toggle="yes">e</italic>, <italic toggle="yes">f</italic>, and <italic toggle="yes">g</italic>). Results are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 2A</xref>. From the projections, even if a clear separation is missing, it is evident that the two models can capture the hydrophobic/polar register difference to a good extent. Among the two models, ProtT5 seems to provide a slightly better separation.</p>
      <p>Second, to investigate if the embedding can capture the relation between hydrophobic registers and oligomeric state, we projected all representations of hydrophobic register positions in the training set (<italic toggle="yes">a</italic> and <italic toggle="yes">d</italic>), and then we colored projected points according to the oligomeric state of the corresponding helix. Resulting <italic toggle="yes">t</italic>-SNE projections are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 2B</xref>. In this case, the separation is less evident, even if some clusters are visible (mostly in ProtT5 projections) for parallel dimers and trimers. Possibly, more <italic toggle="yes">t</italic>-SNE dimensions are needed to achieve a better separation.</p>
      <p>Overall, these experiments suggest that information is already present in the raw embeddings. However, a specific transfer learning architecture, processing the whole sequence, and further exploiting the local and global sequence context is needed to better capture coiled-coil features.</p>
    </sec>
    <sec>
      <title>3.2 Cross-validation results</title>
      <p>We performed 10-fold cross-validation experiments to evaluate the contribution from the two protein language models. We independently trained three different identical models adopting as input: (i) ProtT5, (ii) ESM2, and (iii) both encodings combined in a single vector. Results are reported in <xref rid="btad495-T2" ref-type="table">Table 2</xref>. The overall prediction achieved with each one of the two language models is similar (<italic toggle="yes">F</italic>1<sub>R</sub> and <italic toggle="yes">F</italic>1<sub>S</sub> scores equals 0.44, 0.34, and 0.46, 0.37 with ProtT5 and ESM2, respectively). However, combining the two embeddings into a single vector leads to better performances, raising both precision and recall values, and achieving <italic toggle="yes">F</italic>1<sub>R</sub> and <italic toggle="yes">F</italic>1<sub>S</sub> values of 0.52 and 0.41, respectively. This suggests that the two models are somewhat complementary. We analyzed and compared residue-level true positive predictions obtained with inputs based on the two pLMs. We find that the two models individually trained with ProtT5 and ESM2 share 25 373 correctly predicted residues, and that 4166 and 8341 coiled-coil residues are correctly and uniquely identified, respectively. This finding highlights the complementarity of the two models. These results agree with previous works in which the combination of embeddings from different pLMs has been proven effective also for other prediction tasks (<xref rid="btad495-B23" ref-type="bibr">Manfredi <italic toggle="yes">et al.</italic> 2022</xref>, <xref rid="btad495-B24" ref-type="bibr">2023</xref>). All results presented in this manuscript are obtained using the combination of the two input embeddings.</p>
      <table-wrap position="float" id="btad495-T2">
        <label>Table 2.</label>
        <caption>
          <p>Prediction of coiled-coil helices with CoCoNat adopting different embeddings.<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref></p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Input</th>
              <th rowspan="1" colspan="1">PRE<sub>R</sub></th>
              <th rowspan="1" colspan="1">REC<sub>R</sub></th>
              <th rowspan="1" colspan="1"><italic toggle="yes">F</italic>1<sub>R</sub></th>
              <th rowspan="1" colspan="1">PRAUC</th>
              <th rowspan="1" colspan="1">PRE<sub>S</sub></th>
              <th rowspan="1" colspan="1">REC<sub>S</sub></th>
              <th rowspan="1" colspan="1"><italic toggle="yes">F</italic>1<sub>S</sub></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">ProtT5</td>
              <td rowspan="1" colspan="1">0.42</td>
              <td rowspan="1" colspan="1">0.46</td>
              <td rowspan="1" colspan="1">0.44</td>
              <td rowspan="1" colspan="1">0.38</td>
              <td rowspan="1" colspan="1">0.32</td>
              <td rowspan="1" colspan="1">0.36</td>
              <td rowspan="1" colspan="1">0.34</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ESM2</td>
              <td rowspan="1" colspan="1">0.50</td>
              <td rowspan="1" colspan="1">0.50</td>
              <td rowspan="1" colspan="1">0.46</td>
              <td rowspan="1" colspan="1">0.41</td>
              <td rowspan="1" colspan="1">0.47</td>
              <td rowspan="1" colspan="1">0.32</td>
              <td rowspan="1" colspan="1">0.37</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ProtT5+ESM2</td>
              <td rowspan="1" colspan="1">0.51</td>
              <td rowspan="1" colspan="1">0.47</td>
              <td rowspan="1" colspan="1">0.49</td>
              <td rowspan="1" colspan="1">0.47</td>
              <td rowspan="1" colspan="1">0.38</td>
              <td rowspan="1" colspan="1">0.37</td>
              <td rowspan="1" colspan="1">0.37</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <label>a</label>
            <p>CoCoNat architecture is depicted in <xref rid="btad495-F1" ref-type="fig">Fig. 1</xref>. The training set is described in <xref rid="btad495-T1" ref-type="table">Table 1</xref>. Results are obtained adopting a 10-fold cross-validation. For details, see Section 2. Subscript R: per residue; subscript S: per CC helix segment. Variability across cross-validation sets is lower than 1% for all scores.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.3 Prediction of coiled coils on the blind test set</title>
      <p>CoCoNat is benchmarked on the same blind test set against available methods. In <xref rid="btad495-T3" ref-type="table">Table 3</xref>, we report results for the prediction of coiled-coil helices. Tested methods include: MARCOIL (<xref rid="btad495-B5" ref-type="bibr">Delorenzi and Speed 2002</xref>), CCHMM_prof (<xref rid="btad495-B1" ref-type="bibr">Bartoli <italic toggle="yes">et al.</italic> 2009</xref>), Multicoil2 (<xref rid="btad495-B27" ref-type="bibr">Trigg <italic toggle="yes">et al.</italic> 2011</xref>), DeepCoil2 (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>), and CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>). All the methods were run in house using the respective available standalone versions. Since DeepCoil2 does not provide a classification but rather a probability value, we report results obtained by applying two different probability thresholds set to 0.2 and 0.5, respectively.</p>
      <table-wrap position="float" id="btad495-T3">
        <label>Table 3.</label>
        <caption>
          <p>CoCoNat and the state-of-art methods on the same blind test set.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">
                <bold>Method</bold>
                <xref rid="tblfn2" ref-type="table-fn">
                  <sup>a</sup>
                </xref>
              </th>
              <th rowspan="1" colspan="1">PRE<sub>R</sub></th>
              <th rowspan="1" colspan="1">REC<sub>R</sub></th>
              <th rowspan="1" colspan="1"><italic toggle="yes">F</italic>1<sub>R</sub></th>
              <th rowspan="1" colspan="1">PRAUC</th>
              <th rowspan="1" colspan="1">PRE<sub>S</sub></th>
              <th rowspan="1" colspan="1">REC<sub>S</sub></th>
              <th rowspan="1" colspan="1"><italic toggle="yes">F</italic>1s</th>
              <th rowspan="1" colspan="1">SOV<sub>O</sub></th>
              <th rowspan="1" colspan="1">SOV<sub>P</sub></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">MARCOIL</td>
              <td rowspan="1" colspan="1">0.34</td>
              <td rowspan="1" colspan="1">0.26</td>
              <td rowspan="1" colspan="1">0.29</td>
              <td rowspan="1" colspan="1">0.16</td>
              <td rowspan="1" colspan="1">0.24</td>
              <td rowspan="1" colspan="1">0.06</td>
              <td rowspan="1" colspan="1">0.1</td>
              <td rowspan="1" colspan="1">18.15</td>
              <td rowspan="1" colspan="1">48.03</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CCHMM_prof</td>
              <td rowspan="1" colspan="1">0.16</td>
              <td rowspan="1" colspan="1">
                <bold>0.6</bold>
              </td>
              <td rowspan="1" colspan="1">0.23</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">0.12</td>
              <td rowspan="1" colspan="1">0.25</td>
              <td rowspan="1" colspan="1">0.15</td>
              <td rowspan="1" colspan="1">43.25</td>
              <td rowspan="1" colspan="1">16.32</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Multicoil2</td>
              <td rowspan="1" colspan="1">0.34</td>
              <td rowspan="1" colspan="1">0.13</td>
              <td rowspan="1" colspan="1">0.19</td>
              <td rowspan="1" colspan="1">0.15</td>
              <td rowspan="1" colspan="1">0.19</td>
              <td rowspan="1" colspan="1">0.01</td>
              <td rowspan="1" colspan="1">0.02</td>
              <td rowspan="1" colspan="1">7.40</td>
              <td rowspan="1" colspan="1">48.86</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepCoil2 (th = 0.2)</td>
              <td rowspan="1" colspan="1">0.39</td>
              <td rowspan="1" colspan="1">
                <bold>0.6</bold>
              </td>
              <td rowspan="1" colspan="1">0.48</td>
              <td rowspan="1" colspan="1">0.36</td>
              <td rowspan="1" colspan="1">0.42</td>
              <td rowspan="1" colspan="1">
                <bold>0.49</bold>
              </td>
              <td rowspan="1" colspan="1">0.45</td>
              <td rowspan="1" colspan="1">
                <bold>59.83</bold>
              </td>
              <td rowspan="1" colspan="1">50.93</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepCoil2 (th = 0.5)</td>
              <td rowspan="1" colspan="1">0.51</td>
              <td rowspan="1" colspan="1">0.33</td>
              <td rowspan="1" colspan="1">0.4</td>
              <td rowspan="1" colspan="1">0.36</td>
              <td rowspan="1" colspan="1">0.53</td>
              <td rowspan="1" colspan="1">0.2</td>
              <td rowspan="1" colspan="1">0.29</td>
              <td rowspan="1" colspan="1">31.17</td>
              <td rowspan="1" colspan="1">66.64</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoCoPRED</td>
              <td rowspan="1" colspan="1">0.43</td>
              <td rowspan="1" colspan="1">0.54</td>
              <td rowspan="1" colspan="1">0.48</td>
              <td rowspan="1" colspan="1">0.45</td>
              <td rowspan="1" colspan="1">0.38</td>
              <td rowspan="1" colspan="1">0.46</td>
              <td rowspan="1" colspan="1">0.41</td>
              <td rowspan="1" colspan="1">57.64</td>
              <td rowspan="1" colspan="1">51.17</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoCoNat</td>
              <td rowspan="1" colspan="1">
                <bold>0.55</bold>
              </td>
              <td rowspan="1" colspan="1">0.53</td>
              <td rowspan="1" colspan="1">
                <bold>0.54</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.46</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.57</bold>
              </td>
              <td rowspan="1" colspan="1">0.43</td>
              <td rowspan="1" colspan="1">
                <bold>0.49</bold>
              </td>
              <td rowspan="1" colspan="1">54.35</td>
              <td rowspan="1" colspan="1">
                <bold>66.93</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <label>a</label>
            <p>MARCOIL (<xref rid="btad495-B5" ref-type="bibr">Delorenzi and Speed 2002</xref>), CCHMM_prof (<xref rid="btad495-B1" ref-type="bibr">Bartoli <italic toggle="yes">et al.</italic> 2009</xref>), Multicoil2 (<xref rid="btad495-B27" ref-type="bibr">Trigg <italic toggle="yes">et al.</italic> 2011</xref>), DeepCoil2 (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>), CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>). Subscript R: per residue; subscript S: per CC helix segment. The blind test set contains 400 positive and 318 negative proteins. Bold values highlight the highest scores.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>CoCoNat, which adopts encodings based on ProT5 and ESM2, outperforms the state-of-the-art, showing (with respect to the second top performing method in the benchmark) an improvement in the per-residue precision value (0.55), with a slight loss in recall (0.53), which is reflected in the higher value of the <italic toggle="yes">F</italic>1-score (0.54). The per-segment scores of CoCoNat confirm this trend. Moreover, CoCoNat performs with the highest SOVp and the third highest SOVo (see Section 2.4 for definition).</p>
      <p>For sake of assessing the significance of the differences observed in data reported in <xref rid="btad495-T3" ref-type="table">Table 3</xref>, we performed a boostrapping procedure and a two-sample Welch’s <italic toggle="yes">t</italic>-test. Specifically, from the blind test set results, we randomly selected 100 samples of 300 sequences and evaluated all the methods using residue- and segment-level scoring measures. Then, average performances of CoCoNat were compared for statistical significance with average scores of other tools. All the differences observed in this experiment reflect those reported in <xref rid="btad495-T3" ref-type="table">Table 3</xref> and are all significant at 0.0001 significance threshold. Results are reported in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table 1</xref>.</p>
    </sec>
    <sec>
      <title>3.4 Prediction of coiled-coil registers</title>
      <p>We compared CoCoNat with other tools in the task of annotating heptad repeat registers. To this aim, we used the blind test of 400 proteins endowed with CCDs. Results of all methods were generated using the respective standalone versions (<xref rid="btad495-T4" ref-type="table">Table 4</xref>).</p>
      <table-wrap position="float" id="btad495-T4">
        <label>Table 4.</label>
        <caption>
          <p>CoCoNat and the state-of-art methods on the prediction of heptad repeat registers.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">
                <bold>Method</bold>
                <xref rid="tblfn3" ref-type="table-fn">
                  <sup>a</sup>
                </xref>
              </th>
              <th rowspan="1" colspan="1">MCC (a)</th>
              <th rowspan="1" colspan="1">MCC (b)</th>
              <th rowspan="1" colspan="1">MCC (c)</th>
              <th rowspan="1" colspan="1">MCC (d)</th>
              <th rowspan="1" colspan="1">MCC (e)</th>
              <th rowspan="1" colspan="1">MCC (f)</th>
              <th rowspan="1" colspan="1">MCC (g)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">MARCOIL</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.66</td>
              <td rowspan="1" colspan="1">0.66</td>
              <td rowspan="1" colspan="1">0.66</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Multicoil2</td>
              <td rowspan="1" colspan="1">0.56</td>
              <td rowspan="1" colspan="1">0.56</td>
              <td rowspan="1" colspan="1">0.57</td>
              <td rowspan="1" colspan="1">0.57</td>
              <td rowspan="1" colspan="1">0.58</td>
              <td rowspan="1" colspan="1">0.58</td>
              <td rowspan="1" colspan="1">0.57</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepCoil2 (th = 0.2)</td>
              <td rowspan="1" colspan="1">0.62</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">0.62</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepCoil2 (th = 0.5)</td>
              <td rowspan="1" colspan="1">0.68</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">0.68</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoCoPRED</td>
              <td rowspan="1" colspan="1">0.65</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.66</td>
              <td rowspan="1" colspan="1">0.66</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.65</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoCoNat</td>
              <td rowspan="1" colspan="1">
                <bold>0.84</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.84</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.84</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.84</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.83</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.83</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.83</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <label>a</label>
            <p>MARCOIL (<xref rid="btad495-B5" ref-type="bibr">Delorenzi and Speed 2002</xref>); Multicoil2 (<xref rid="btad495-B27" ref-type="bibr">Trigg <italic toggle="yes">et al.</italic> 2011</xref>); DeepCoil2 (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>); CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>). The blind test set contains 400 positive proteins. Bold values highlight the highest scores.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>For all the register labels <italic toggle="yes">a–g</italic>, CoCoNat MCC values indicate an improvement ranging from 16% to 19% with respect to the second best-performing method, CoCoPRED.</p>
      <p>Remarkably, CoCoNat MCC values are quite similar across all the seven different register labels, suggesting that the register is routinely predicted in the correct regular configuration, from label <italic toggle="yes">a</italic> to <italic toggle="yes">g</italic>. This highlights that the GRHCRF grammar is properly capturing transition constraints among the different registers within the coiled-coil segments.</p>
    </sec>
    <sec>
      <title>3.5 Prediction of the CCD oligomerization state</title>
      <p>We finally compared CoCoNat, LOGICOIL (<xref rid="btad495-B30" ref-type="bibr">Vincent <italic toggle="yes">et al.</italic> 2013</xref>) CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>) on the task of predicting CCD oligomerization state. Again, we used the blind test set of 400 proteins as benchmark. The three methods are compared assuming an oracle predictor for the identification of CCD segments (i.e. we classify real CCD segments into the four oligomerization classes). In <xref rid="btad495-T5" ref-type="table">Table 5</xref>, we report a comparison of the three approaches in terms of per-class MCCs.</p>
      <table-wrap position="float" id="btad495-T5">
        <label>Table 5.</label>
        <caption>
          <p>CoCoNat and the state-of-art methods on the prediction of oligomerization states.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">
                <bold>Method</bold>
                <xref rid="tblfn4" ref-type="table-fn">
                  <sup>a</sup>
                </xref>
              </th>
              <th rowspan="1" colspan="1">MCC (parallel dimer)</th>
              <th rowspan="1" colspan="1">MCC (antiparallel dimer)</th>
              <th rowspan="1" colspan="1">MCC (trimer)</th>
              <th rowspan="1" colspan="1">MCC (tetramer)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">LOGICOIL</td>
              <td rowspan="1" colspan="1">0.12</td>
              <td rowspan="1" colspan="1">0.07</td>
              <td rowspan="1" colspan="1">0.01</td>
              <td rowspan="1" colspan="1">0.01</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoCoPRED</td>
              <td rowspan="1" colspan="1">0.37</td>
              <td rowspan="1" colspan="1">0.21</td>
              <td rowspan="1" colspan="1">0.14</td>
              <td rowspan="1" colspan="1">0.18</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoCoNat</td>
              <td rowspan="1" colspan="1">
                <bold>0.66</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.70</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.50</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.46</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn4">
            <label>a</label>
            <p>LOGICOIL (<xref rid="btad495-B30" ref-type="bibr">Vincent <italic toggle="yes">et al.</italic> 2013</xref>); CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>). The blind test set contains 400 positive proteins. Bold values highlight the highest scores.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Looking at the MCC values, CoCoNat significantly overpasses CoCoPRED and LOGICOIL, providing predictions that are overall higher and more balanced across the four oligomerization state classes. Remarkably, CoCoNat outperforms other tools also on less abundant classes, i.e. trimers and tetramers.</p>
    </sec>
    <sec>
      <title>3.6 CoCoNat availability and analysis of running time</title>
      <p>We release CoCoNat as both web server and standalone version. The web server is available at <ext-link xlink:href="https://coconat.biocomp.unibo.it" ext-link-type="uri">https://coconat.biocomp.unibo.it</ext-link>. The server provides a user-friendly web interface, allowing the user to choose between two modes of use of the tool: (i) analysis and visualization of coiled-coil prediction results for a single input sequence; (ii) submission of a batch job allowing prediction of coiled-coils and download of results (in TSV and JSON formats) for up to 500 sequences per job. Additionally, for single-sequence mode, we also provide the possibility of uploading a pre-determined set of coiled-coil segments, restricting the prediction to the oligomeric state only. The web application is implemented using Django (version 4.0.4), Bootstrap (version 5.3.0), JQuery (version 3.6.0), and neXtProt FeatureViewer (version 1.3.0-beta6) for visualization of predicted coiled-coil segments along the sequence.</p>
      <p>The standalone version of CoCoNat is available on GitHub at <ext-link xlink:href="https://github.com/BolognaBiocomp/coconat" ext-link-type="uri">https://github.com/BolognaBiocomp/coconat</ext-link>. The standalone tool is implemented in Python as a Docker containerized application. This avoids the installation of dependencies and allows users to quickly install the program in any server equipped with Docker. Instructions on how to build the Docker image and run CoCoNat are available on the GitHub repository.</p>
      <p>We performed experiments to evaluate the running time of CoCoNat in different conditions. All the experiments were performed on the virtual machine hosting the web server, equipped with AMD EPYC 7301 12-Core Processor, 48G RAM. No GPU is available on this machine.</p>
      <p>First, we analyzed the impact of the protein sequence length on the running time. To this aim, we randomly selected different sets of 100 sequences with lengths of increasing size. Fifty samples are generated for each length bin. CoCoNat has been then executed on each sample, evaluating its running time. Results are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 3A</xref>. The running time scales linearly with the length of the sequences, ranging from 200 s (for 100 sequences) when protein length is 50–100 residues to 1400 s when length is 600/700 residues.</p>
      <p>Second, we analyzed how the number of sequences in the dataset impacts on the running time. Again, random samples of sequences were generated, varying from 10, 20, 40, 80, 160, 320, and 500. The length of sequences was set between 100 and 200 residues for all samples. Results are reported in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 3B</xref>. The time required for the datasets including 10, 20, and 40 sequences is almost identical. This is due to the overhead required to load the two pLMs for encoding, which dominates the overall running time when the number of sequences is low. For dataset sizes including more than 40 sequences, the running time scales almost linearly from 100 to 1400 s.</p>
      <p>In general, the CoCoNat running time is always low if compared to the time required by other tools based on multiple-sequence alignment inputs, such as CoCoPRED. For instance, to predict coiled-coil helices, including registers and oligomeric state, on 100 sequences of length comprised between 100 and 200 residues, the CoCoNat average running time is 330 s (5.5 min), which is lower than the time required by CoCoPRED, requiring about 2.5 h.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>In this article, we described CoCoNat, a novel method based on protein language model embeddings and deep learning for detection of coiled-coiled helices at residue level, prediction of coiled-coil heptad repeat registers, and oligomerization state.</p>
    <p>Training and testing were performed on datasets derived from literature. When compared with other state-of-the-art tools, CoCoNat reports performance that are significantly better than those obtained by other approaches tested, in particular when considering register and oligomerization state prediction.</p>
    <p>In this work, we also proved the relevance of adopting protein residue representations derived from large-scale protein language models such as ProtT5 (<xref rid="btad495-B6" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic> 2021</xref>) and ESM2 (<xref rid="btad495-B15" ref-type="bibr">Lin <italic toggle="yes">et al.</italic> 2023</xref>) for this specific task. Moreover, we further confirmed that the combination of different language models provides better performance, suggesting that different models obtained with different architectures and data give complementary representations.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btad495_Supplementary_Data</label>
      <media xlink:href="btad495_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>The authors declare no conflict of interest.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>The work was supported by the project 2017483NH8_002 [PRIN2017 to C.S.] from the Italian Ministry of University and Research and by the project “Consolidation of the Italian Infrastructure for Omics Data and Bioinformatics” (ELIXIRxNextGenIT) [IR0000010] from the Italian Ministry of University and Research (EU funding within the NextGeneration EU).</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The data underlying this article are available in the article, in its online <xref rid="sup1" ref-type="supplementary-material">supplementary material</xref> and on the CoCoNat web server at <ext-link xlink:href="https://coconat.biocomp.unibo.it" ext-link-type="uri">https://coconat.biocomp.unibo.it</ext-link>.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btad495-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bartoli</surname><given-names>L</given-names></string-name>, <string-name><surname>Fariselli</surname><given-names>P</given-names></string-name>, <string-name><surname>Krogh</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>CCHMM_PROF: a HMM-based coiled-coil predictor with evolutionary information</article-title>. <source>Bioinformatics</source><year>2009</year>;<volume>25</volume>:<fpage>2757</fpage>–<lpage>63</lpage>.<pub-id pub-id-type="pmid">19744995</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Crick</surname><given-names>FHC.</given-names></string-name></person-group><article-title>Is alpha-keratin a coiled coil?</article-title><source>Nature</source><year>1952</year>;<volume>170</volume>:<fpage>882</fpage>–<lpage>3</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Crick</surname><given-names>FHC.</given-names></string-name></person-group><article-title>The Fourier transform of a coiled-coil</article-title>. <source>Acta Cryst</source><year>1953a</year>;<volume>6</volume>:<fpage>685</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Crick</surname><given-names>FHC.</given-names></string-name></person-group><article-title>The packing of α-helices: simple coiled-coils</article-title>. <source>Acta Cryst</source><year>1953b</year>;<volume>6</volume>:<fpage>689</fpage>–<lpage>97</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Delorenzi</surname><given-names>M</given-names></string-name>, <string-name><surname>Speed</surname><given-names>T.</given-names></string-name></person-group><article-title>An HMM model for coiled-coil domains and a comparison with PSSM-based predictions</article-title>. <source>Bioinformatics</source><year>2002</year>;<volume>18</volume>:<fpage>617</fpage>–<lpage>25</lpage>.<pub-id pub-id-type="pmid">12016059</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Elnaggar</surname><given-names>A</given-names></string-name>, <string-name><surname>Heinzinger</surname><given-names>M</given-names></string-name>, <string-name><surname>Dallago</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>ProtTrans: Toward understanding the language of life through self-supervised learning</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source><year>2022</year>;<volume>44</volume>:<fpage>7112</fpage>–<lpage>27</lpage>.<pub-id pub-id-type="pmid">34232869</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fariselli</surname><given-names>P</given-names></string-name>, <string-name><surname>Savojardo</surname><given-names>C</given-names></string-name>, <string-name><surname>Martelli</surname><given-names>PL</given-names></string-name></person-group><etal>et al</etal><article-title>Grammatical-Restrained Hidden Conditional Random Fields for Bioinformatics applications</article-title>. <source>Algorithms Mol Biol</source><year>2009</year>;<volume>4</volume>:<fpage>13</fpage>.<pub-id pub-id-type="pmid">19849839</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Feng</surname><given-names>S-H</given-names></string-name>, <string-name><surname>Xia</surname><given-names>C-Q</given-names></string-name>, <string-name><surname>Shen</surname><given-names>H-B</given-names></string-name></person-group><etal>et al</etal><article-title>CoCoPRED: coiled-coil protein structural feature prediction from amino acid sequence using deep neural networks</article-title>. <source>Bioinformatics</source><year>2022</year>;<volume>38</volume>:<fpage>720</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">34718416</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fox</surname><given-names>NK</given-names></string-name>, <string-name><surname>Brenner</surname><given-names>SE</given-names></string-name>, <string-name><surname>Chandonia</surname><given-names>J-M</given-names></string-name></person-group><etal>et al</etal><article-title>SCOPe: structural classification of proteins—extended, integrating SCOP and ASTRAL data and classification of new structures</article-title>. <source>Nucleic Acids Res</source><year>2014</year>;<volume>42</volume>:<fpage>D304</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">24304899</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gruber</surname><given-names>M</given-names></string-name>, <string-name><surname>Söding</surname><given-names>J</given-names></string-name>, <string-name><surname>Lupas</surname><given-names>AN</given-names></string-name></person-group><etal>et al</etal><article-title>REPPER–repeats and their periodicities in fibrous proteins</article-title>. <source>Nucleic Acids Res</source><year>2005</year>;<volume>33</volume>:<fpage>W239</fpage>–<lpage>43</lpage>.<pub-id pub-id-type="pmid">15980460</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hochreiter</surname><given-names>S</given-names></string-name>, <string-name><surname>Schmidhuber</surname><given-names>J.</given-names></string-name></person-group><article-title>Long short-term memory</article-title>. <source>Neural Comput</source><year>1997</year>;<volume>9</volume>:<fpage>1735</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>DP</given-names></string-name>, <string-name><surname>Ba</surname><given-names>J.</given-names></string-name></person-group> Adam: a method for stochastic optimization. arXiv:1412.6980 [cs], <year>2017</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btad495-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>LeCun</surname><given-names>Y</given-names></string-name>, <string-name><surname>Boser</surname><given-names>B</given-names></string-name>, <string-name><surname>Denker</surname><given-names>JS</given-names></string-name></person-group><etal>et al</etal><article-title>Backpropagation applied to handwritten zip code recognition</article-title>. <source>Neural Comput</source>. <year>1989</year>;<volume>1</volume>:<fpage>541</fpage>–<lpage>51</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>C</given-names></string-name>, <string-name><surname>Ching Han Chang</surname><given-names>C</given-names></string-name>, <string-name><surname>Nagel</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Critical evaluation of in silico methods for prediction of coiled-coil domains in proteins</article-title>. <source>Brief Bioinform</source><year>2016</year>;<volume>17</volume>:<fpage>270</fpage>–<lpage>82</lpage>.<pub-id pub-id-type="pmid">26177815</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>Z</given-names></string-name>, <string-name><surname>Akin</surname><given-names>H</given-names></string-name>, <string-name><surname>Rao</surname><given-names>R</given-names></string-name></person-group><etal>et al</etal><article-title>Evolutionary-scale prediction of atomic-level protein structure with a language model</article-title>. <source>Science</source><year>2023</year>;<volume>379</volume>:<fpage>1123</fpage>–<lpage>30</lpage>.<pub-id pub-id-type="pmid">36927031</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ludwiczak</surname><given-names>J</given-names></string-name>, <string-name><surname>Winski</surname><given-names>A</given-names></string-name>, <string-name><surname>Szczepaniak</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal><article-title>DeepCoil: a fast and accurate prediction of coiled-coil domains in protein sequences</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>2790</fpage>–<lpage>5</lpage>.<pub-id pub-id-type="pmid">30601942</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lupas</surname><given-names>A</given-names></string-name>, <string-name><surname>Van Dyke</surname><given-names>M</given-names></string-name>, <string-name><surname>Stock</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Predicting coiled coils from protein sequences</article-title>. <source>Science</source><year>1991</year>;<volume>252</volume>:<fpage>1162</fpage>–<lpage>4</lpage>.<pub-id pub-id-type="pmid">2031185</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lupas</surname><given-names>AN</given-names></string-name>, <string-name><surname>Bassler</surname><given-names>J.</given-names></string-name></person-group><article-title>Coiled coils - a model system for the 21st century</article-title>. <source>Trends Biochem Sci</source><year>2017</year>;<volume>42</volume>:<fpage>130</fpage>–<lpage>40</lpage>.<pub-id pub-id-type="pmid">27884598</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B19">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lupas</surname><given-names>AN</given-names></string-name>, <string-name><surname>Gruber</surname><given-names>M.</given-names></string-name></person-group><part-title>The structure of α-helical coiled coils</part-title>. In: <source>Advances in Protein Chemistry: Fibrous Proteins: Coiled-Coils, Collagen and Elastomers</source>. <publisher-name>Academic Press</publisher-name>, <year>2005</year>, <fpage>37</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B20">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lupas</surname><given-names>AN</given-names></string-name>, <string-name><surname>Bassler</surname><given-names>J</given-names></string-name>, <string-name><surname>Dunin-Horkawicz</surname><given-names>S.</given-names></string-name></person-group> The Structure and Topology of α-Helical Coiled Coils. In: Parry, D., Squire, J. (eds) <source>Fibrous Proteins: Structures and Mechanisms. Subcellular Biochemistry</source>, vol 82. Springer, Cham. <pub-id pub-id-type="doi">10.1007/978-3-319-49674-0_4</pub-id>.</mixed-citation>
    </ref>
    <ref id="btad495-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Madeo</surname><given-names>G</given-names></string-name>, <string-name><surname>Savojardo</surname><given-names>C</given-names></string-name>, <string-name><surname>Martelli</surname><given-names>PL</given-names></string-name></person-group><etal>et al</etal><article-title>BetAware-Deep: an accurate web server for discrimination and topology prediction of prokaryotic transmembrane β-barrel proteins</article-title>. <source>J Mol Biol</source><year>2021</year>;<volume>433</volume>:<fpage>166729</fpage>.<pub-id pub-id-type="pmid">33972021</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mahrenholz</surname><given-names>CC</given-names></string-name>, <string-name><surname>Abfalter</surname><given-names>IG</given-names></string-name>, <string-name><surname>Bodenhofer</surname><given-names>U</given-names></string-name></person-group><etal>et al</etal><article-title>Complex networks govern coiled-coil oligomerization–predicting and profiling by means of a machine learning approach</article-title>. <source>Mol Cell Proteomics</source><year>2011</year>;<volume>10</volume>:<fpage>M110.004994</fpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manfredi</surname><given-names>M</given-names></string-name>, <string-name><surname>Savojardo</surname><given-names>C</given-names></string-name>, <string-name><surname>Martelli</surname><given-names>PL</given-names></string-name></person-group><etal>et al</etal><article-title>E-SNPs&amp;GO: embedding of protein sequence and function improves the annotation of human pathogenic variants</article-title>. <source>Bioinformatics</source><year>2022</year>;<volume>38</volume>:<fpage>5168</fpage>–<lpage>74</lpage>.<pub-id pub-id-type="pmid">36227117</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manfredi</surname><given-names>M</given-names></string-name>, <string-name><surname>Savojardo</surname><given-names>C</given-names></string-name>, <string-name><surname>Martelli</surname><given-names>PL</given-names></string-name></person-group><etal>et al</etal><article-title>ISPRED-SEQ: deep neural networks and embeddings for predicting interaction sites in protein sequences</article-title>. <source>J Mol Biol</source><year>2023</year>;<volume>435</volume>:<fpage>167963</fpage>.<pub-id pub-id-type="pmid">37356906</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Szczepaniak</surname><given-names>K</given-names></string-name>, <string-name><surname>Bukala</surname><given-names>A</given-names></string-name>, <string-name><surname>da Silva Neto</surname><given-names>AM</given-names></string-name></person-group><etal>et al</etal><article-title>A library of coiled-coil domains: from regular bundles to peculiar twists</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>5368</fpage>–<lpage>76</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Testa</surname><given-names>OD</given-names></string-name>, <string-name><surname>Moutevelis</surname><given-names>E</given-names></string-name>, <string-name><surname>Woolfson</surname><given-names>DN</given-names></string-name></person-group><etal>et al</etal><article-title>CC+: a relational database of coiled-coil structures</article-title>. <source>Nucleic Acids Res</source><year>2009</year>;<volume>37</volume>:<fpage>D315</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">18842638</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Trigg</surname><given-names>J</given-names></string-name>, <string-name><surname>Gutwin</surname><given-names>K</given-names></string-name>, <string-name><surname>Keating</surname><given-names>AE</given-names></string-name></person-group><etal>et al</etal><article-title>Multicoil2: predicting coiled coils and their oligomerization states from sequence in the twilight zone</article-title>. <source>PLoS One</source><year>2011</year>;<volume>6</volume>:<fpage>e23519</fpage>.<pub-id pub-id-type="pmid">21901122</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Truebestein</surname><given-names>L</given-names></string-name>, <string-name><surname>Leonard</surname><given-names>TA.</given-names></string-name></person-group><article-title>Coiled-coils: the long and short of it</article-title>. <source>Bioessays</source><year>2016</year>;<volume>38</volume>:<fpage>903</fpage>–<lpage>16</lpage>.<pub-id pub-id-type="pmid">27492088</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van der Maaten</surname><given-names>LJP</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>GE.</given-names></string-name></person-group><article-title>Visualizing data using t-SNE</article-title>. <source>J Mach Learn Res</source><year>2008</year>;<volume>9</volume>:<fpage>2579</fpage>–<lpage>605</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vincent</surname><given-names>TL</given-names></string-name>, <string-name><surname>Green</surname><given-names>PJ</given-names></string-name>, <string-name><surname>Woolfson</surname><given-names>DN</given-names></string-name></person-group><etal>et al</etal><article-title>LOGICOIL—multi-state prediction of coiled-coil oligomeric state</article-title>. <source>Bioinformatics</source><year>2013</year>;<volume>29</volume>:<fpage>69</fpage>–<lpage>76</lpage>.<pub-id pub-id-type="pmid">23129295</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walshaw</surname><given-names>J</given-names></string-name>, <string-name><surname>Woolfson</surname><given-names>DN.</given-names></string-name></person-group><article-title>Socket: a program for identifying and analysing coiled-coil motifs within protein structures</article-title>. <source>J Mol Biol</source><year>2001</year>;<volume>307</volume>:<fpage>1427</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">11292353</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname><given-names>IA</given-names></string-name>, <string-name><surname>Skehel</surname><given-names>JJ</given-names></string-name>, <string-name><surname>Wiley</surname><given-names>DC</given-names></string-name></person-group><etal>et al</etal><article-title>Structure of the haemagglutinin membrane glycoprotein of influenza virus at 3 a resolution</article-title>. <source>Nature</source><year>1981</year>;<volume>289</volume>:<fpage>366</fpage>–<lpage>73</lpage>.<pub-id pub-id-type="pmid">7464906</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Woolfson</surname><given-names>DN.</given-names></string-name></person-group><article-title>Understanding a protein fold: the physics, chemistry, and biology of α-helical coiled coils</article-title>. <source>J Biol Chem</source><year>2023</year>;<volume>299</volume>:<fpage>104579</fpage>.<pub-id pub-id-type="pmid">36871758</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zemla</surname><given-names>A</given-names></string-name>, <string-name><surname>Venclovas</surname><given-names>C</given-names></string-name>, <string-name><surname>Fidelis</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal><article-title>A modified definition of SOV, a segment-based measure for protein secondary structure prediction assessment</article-title>. <source>Proteins</source><year>1999</year>;<volume>34</volume>:<fpage>220</fpage>–<lpage>3</lpage>.<pub-id pub-id-type="pmid">10022357</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10425188</article-id>
    <article-id pub-id-type="pmid">37540220</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btad495</article-id>
    <article-id pub-id-type="publisher-id">btad495</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Structural Bioinformatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CoCoNat: a novel method based on deep learning for coiled-coil prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Madeo</surname>
          <given-names>Giovanni</given-names>
        </name>
        <xref rid="btad495-FM1" ref-type="author-notes"/>
        <aff><institution>Biocomputing Group, Department of Pharmacy and Biotechnology, University of Bologna</institution>, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-7359-0633</contrib-id>
        <name>
          <surname>Savojardo</surname>
          <given-names>Castrense</given-names>
        </name>
        <xref rid="btad495-FM1" ref-type="author-notes"/>
        <aff><institution>Biocomputing Group, Department of Pharmacy and Biotechnology, University of Bologna</institution>, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-5479-1723</contrib-id>
        <name>
          <surname>Manfredi</surname>
          <given-names>Matteo</given-names>
        </name>
        <xref rid="btad495-FM1" ref-type="author-notes"/>
        <aff><institution>Biocomputing Group, Department of Pharmacy and Biotechnology, University of Bologna</institution>, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-0274-5669</contrib-id>
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <aff><institution>Biocomputing Group, Department of Pharmacy and Biotechnology, University of Bologna</institution>, <country country="IT">Italy</country></aff>
        <xref rid="btad495-cor1" ref-type="corresp"/>
        <!--pierluigi.martelli@unibo.it-->
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-7462-7039</contrib-id>
        <name>
          <surname>Casadio</surname>
          <given-names>Rita</given-names>
        </name>
        <aff><institution>Biocomputing Group, Department of Pharmacy and Biotechnology, University of Bologna</institution>, <country country="IT">Italy</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Elofsson</surname>
          <given-names>Arne</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btad495-cor1">Corresponding author. Biocomputing Group, Department of Pharmacy and Biotechnology, University of Bologna, via San Giacomo 9/2, 40126 Bologna, Italy. E-mail: <email>pierluigi.martelli@unibo.it</email></corresp>
      <fn id="btad495-FM1">
        <p>Giovanni Madeo and Castrense Savojardo Equal contribution.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="collection">
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-08-04">
      <day>04</day>
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>04</day>
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <volume>39</volume>
    <issue>8</issue>
    <elocation-id>btad495</elocation-id>
    <history>
      <date date-type="received">
        <day>11</day>
        <month>5</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>31</day>
        <month>7</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>01</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>03</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>14</day>
        <month>8</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btad495.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Coiled-coil domains (CCD) are widespread in all organisms and perform several crucial functions. Given their relevance, the computational detection of CCD is very important for protein functional annotation. State-of-the-art prediction methods include the precise identification of CCD boundaries, the annotation of the typical heptad repeat pattern along the coiled-coil helices as well as the prediction of the oligomerization state.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>In this article, we describe CoCoNat, a novel method for predicting coiled-coil helix boundaries, residue-level register annotation, and oligomerization state. Our method encodes sequences with the combination of two state-of-the-art protein language models and implements a three-step deep learning procedure concatenated with a Grammatical-Restrained Hidden Conditional Random Field for CCD identification and refinement. A final neural network predicts the oligomerization state. When tested on a blind test set routinely adopted, CoCoNat obtains a performance superior to the current state-of-the-art both for residue-level and segment-level CCD. CoCoNat significantly outperforms the most recent state-of-the-art methods on register annotation and prediction of oligomerization states.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>CoCoNat web server is available at <ext-link xlink:href="https://coconat.biocomp.unibo.it" ext-link-type="uri">https://coconat.biocomp.unibo.it</ext-link>. Standalone version is available on GitHub at <ext-link xlink:href="https://github.com/BolognaBiocomp/coconat" ext-link-type="uri">https://github.com/BolognaBiocomp/coconat</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Ministry of University and Research</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Coiled-coil domains (CCD) in proteins are structural motifs where α‐helices pack together in an arrangement called knobs into holes (<xref rid="btad495-B2" ref-type="bibr">Crick 1952</xref>, <xref rid="btad495-B3" ref-type="bibr">1953a</xref>, <xref rid="btad495-B4" ref-type="bibr">b</xref>). Since the first crystallographic observation in the structure of influenza virus hemagglutinin (<xref rid="btad495-B32" ref-type="bibr">Wilson <italic toggle="yes">et al.</italic> 1981</xref>), CCDs have been resolved in several proteins through all the kingdoms of life (<xref rid="btad495-B28" ref-type="bibr">Truebestein and Leonard 2016</xref>). CCDs are present, among others, in structural proteins, transcription factors, and enzymes (<xref rid="btad495-B28" ref-type="bibr">Truebestein and Leonard 2016</xref>, <xref rid="btad495-B18" ref-type="bibr">Lupas and Bassler 2017</xref>). CCDs act as molecular spacers, influence the organelle organization, constrain the distance of residues involved in binding and catalytic sites, mediate membrane fusion, and are involved in signal transduction and solute transport.</p>
    <p>Canonical CCDs include the interaction of two or more α‐helices, wound around each other and forming a supercoiled bundle. Each helix is characterized by the repetition of a seven-residue motif (heptad repeat) whose positions are referred to as registers and are labeled as <italic toggle="yes">abcdefg</italic>. Positions <italic toggle="yes">a</italic> and <italic toggle="yes">d</italic> are routinely occupied by hydrophobic residues and mediate the interaction between different helices in the domain. As a result of the formation of the supercoil bundle, the effective periodicity of α‐helices in CCDs changes from 3.6 to 3.5 residues per turn (<xref rid="btad495-B19" ref-type="bibr">Lupas and Gruber 2005</xref>, <xref rid="btad495-B20" ref-type="bibr">Lupas <italic toggle="yes">et al.</italic> 2017</xref>, <xref rid="btad495-B25" ref-type="bibr">Szczepaniak <italic toggle="yes">et al.</italic> 2020</xref>). This implies that residues in the same register lie on the same side of the helix surface. Therefore, the hydrophobic nature of residues in registers <italic toggle="yes">a</italic> and <italic toggle="yes">d</italic> confers a peculiar amphipathic character to the α‐helix. In CCDs, α‐helices interact with each other through their hydrophobic face (<xref rid="btad495-B19" ref-type="bibr">Lupas and Gruber 2005</xref>). CCDs can contain helices characterized by non-canonical repeats, longer than seven residues, i.e. hendecades, pentadecades, and nonadecades (<xref rid="btad495-B19" ref-type="bibr">Lupas and Gruber 2005</xref>, <xref rid="btad495-B25" ref-type="bibr">Szczepaniak <italic toggle="yes">et al.</italic> 2020</xref>). This article does not take into consideration these cases.</p>
    <p>CCDs are classified according to the number and orientation of the involved α‐helices, i.e. by their oligomerization state. CCDs based on the orientation of helices are classified as parallel or antiparallel and based on the number of helices as dimers, trimers, and tetramers.</p>
    <p>CCDs are routinely annotated starting from the protein 3D structure, adopting specialized software such as SOCKET (<xref rid="btad495-B31" ref-type="bibr">Walshaw and Woolfson 2001</xref>) and SamCC-Turbo (<xref rid="btad495-B25" ref-type="bibr">Szczepaniak <italic toggle="yes">et al.</italic> 2020</xref>). Annotations performed with the two methods are collected in the CC+ database (<ext-link xlink:href="http://coiledcoils.chm.bris.ac.uk/ccplus/search/" ext-link-type="uri">http://coiledcoils.chm.bris.ac.uk/ccplus/search/</ext-link>, <xref rid="btad495-B26" ref-type="bibr">Testa <italic toggle="yes">et al.</italic> 2009</xref>) and in the CCdb database (<ext-link xlink:href="https://lbs.cent.uw.edu.pl/ccdb" ext-link-type="uri">https://lbs.cent.uw.edu.pl/ccdb</ext-link>), respectively. Semi-manual annotations are also available in the SCOPe database (<xref rid="btad495-B9" ref-type="bibr">Fox <italic toggle="yes">et al.</italic> 2014</xref>).</p>
    <p>The relevance of CCDs in protein annotation requires the development of computational methods for predicting the presence and localization of CCDs (including registers), and their oligomerization state, starting from the protein sequence. Over the years, several methods have been proposed, addressing the different tasks of CCD prediction. Boundaries of α-helices involved in CCDs can be predicted with COILS (<xref rid="btad495-B17" ref-type="bibr">Lupas <italic toggle="yes">et al.</italic> 1991</xref>), PCOILS (<xref rid="btad495-B10" ref-type="bibr">Gruber <italic toggle="yes">et al.</italic> 2005</xref>), MARCOIL (<xref rid="btad495-B5" ref-type="bibr">Delorenzi and Speed 2002</xref>), Multicoil2 (<xref rid="btad495-B27" ref-type="bibr">Trigg <italic toggle="yes">et al.</italic> 2011</xref>), CCHMM_PROF (<xref rid="btad495-B1" ref-type="bibr">Bartoli <italic toggle="yes">et al.</italic> 2009</xref>), DeepCoil (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>), and CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>).The oligomeric state is predicted with PrOCoil (<xref rid="btad495-B22" ref-type="bibr">Mahrenholz <italic toggle="yes">et al.</italic> 2011</xref>), LOGICOIL (<xref rid="btad495-B30" ref-type="bibr">Vincent <italic toggle="yes">et al.</italic> 2013</xref>), and CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>). To date, methods predicting the registers along the heptad are MARCOIL (<xref rid="btad495-B5" ref-type="bibr">Delorenzi and Speed 2002</xref>), Multicoil2 (<xref rid="btad495-B27" ref-type="bibr">Trigg <italic toggle="yes">et al.</italic> 2011</xref>), DeepCoil2 (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>), and CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>).</p>
    <p>Recently protein language models improved sequence encoding procedures. Here we introduce CoCoNat which, for the first time, adopts a sequence encoding based on the combination of two state-of-the-art protein language models, ProtT5 (<xref rid="btad495-B6" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic> 2021</xref>) and ESM2 (<xref rid="btad495-B15" ref-type="bibr">Lin <italic toggle="yes">et al.</italic> 2023</xref>) and based on deep-learning computes: (i) the coiled-coil helix boundaries; (ii) the residue-level register annotation, and (iii) the CCD oligomerization state.</p>
    <p>We trained CoCoNat on a dataset comprising 2198 proteins containing CCDs and 9062 proteins without CCD (negative examples). When tested on a blind test set including 400 CCD and 318 non-CCD proteins, CoCoNat scores with a performance that is superior to the current state-of-the-art both for residue-level and segment-level CCD detection. Moreover, CoCoNat significantly outperforms other methods, on both register annotation and prediction of CCD oligomerization state.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>CoCoNat is trained and tested on the same datasets adopted in CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>). Numbers are summarized in <xref rid="btad495-T1" ref-type="table">Table 1</xref> and all datasets are available at the CoCoNat website (<ext-link xlink:href="https://coconat.biocomp.unibo.it" ext-link-type="uri">https://coconat.biocomp.unibo.it</ext-link>). Additional statistics on the oligomeric state classification of coiled-coil helices in the training and testing sets are reported in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 1</xref>.</p>
      <table-wrap position="float" id="btad495-T1">
        <label>Table 1.</label>
        <caption>
          <p>Training and testing set of CoCoNat.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Positive proteins</th>
              <th rowspan="1" colspan="1">Helices in CCDs</th>
              <th rowspan="1" colspan="1">Negative proteins</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Training set</td>
              <td rowspan="1" colspan="1">2191</td>
              <td rowspan="1" colspan="1">4342</td>
              <td rowspan="1" colspan="1">9040</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Blind test set</td>
              <td rowspan="1" colspan="1">400</td>
              <td rowspan="1" colspan="1">863</td>
              <td rowspan="1" colspan="1">318</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <sec>
        <title>2.1.1 Training dataset</title>
        <p>The positive training dataset contains 2191 proteins out of the 2337 included in CoCoPRED and deriving from 30,227 CCD-containing proteins annotated with SOCKET (<xref rid="btad495-B31" ref-type="bibr">Walshaw and Woolfson 2001</xref>) in the CC+ database (<xref rid="btad495-B26" ref-type="bibr">Testa <italic toggle="yes">et al.</italic> 2009</xref>).</p>
        <p>Briefly, proteins included in the positive training set of CoCoPRED have been selected with the following criteria: (i) protein structure resolution &lt; 4 Å, (ii) protein length between 25 and 700 residues, (iii) length of CCD helices ≥ 8 residues; (iv) absence of non-canonical (i.e. non-heptad based) CCDs; (v) CCD oligomeric state classified as parallel or antiparallel dimer, trimer, and tetramer; (vi) sequence pairwise identity lower than 30% with respect to proteins in the testing set (see below); and (vii) internal pairwise sequence identity lower than 50%.</p>
        <p>Since CoCoNat relies on full length proteins for the computation of sequence embeddings, we applied further filters to the CoCoPRED positive training dataset, removing: (i) proteins not mapped into UniProt; (ii) synthetic and fusion proteins; and (iii) proteins whose structure coverage with respect to the UniProt sequence is lower than 70%. After this screening, the positive dataset includes 2191 proteins with 4342 coiled-coil helices, whose length ranges from 8 to 145 residues. The number of coiled-coil helices per protein ranges from 1 to 19.</p>
        <p>The negative training set of CoCoNat includes 9040 proteins. This derives from the 9358 proteins of the negative set of CoCoPRED that was obtained from the negative set of DeepCoil (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>) after the exclusion of proteins with a sequence identity &gt; 30% with respect to the blind test set (see Section 2.1.2) and with a sequence identity &gt; 50% with respect to the positive training set. We filtered out proteins not mapped into UniProt.</p>
        <p>Proteins in the training set (both positive and negative examples) were split into 10 subsets for 10-fold cross-validation. To reduce the redundancy among cross-validation sets, proteins sharing more than 25% sequence identity at 50% coverage are clustered in the same set. Cross-validation sets were used to set all the hyperparameters.</p>
      </sec>
      <sec>
        <title>2.1.2 Blind test dataset</title>
        <p>To test and benchmark CoCoNat with other available methods, we adopted the 718 proteins included in the CoCoPRED test set. The CoCoPRED set shares less than 30% sequence identity with proteins in the training sets of CCHMM_PROF (<xref rid="btad495-B1" ref-type="bibr">Bartoli <italic toggle="yes">et al.</italic> 2009</xref>), MARCOIL (<xref rid="btad495-B5" ref-type="bibr">Delorenzi and Speed 2002</xref>), Multicoil2 (<xref rid="btad495-B27" ref-type="bibr">Trigg <italic toggle="yes">et al.</italic> 2011</xref>), CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>), and DeepCoil2 (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>).</p>
        <p>Since coiled-coil annotation for this dataset was not available from the CoCoPRED website, we ran SOCKET in house on the structure of the main biological assembly of each PDB included in the dataset. By this, 400 proteins are annotated as containing CCD while 318 do not contain any coiled-coil segment. Overall, the 400 positive proteins contain 863 coiled-coil helices (<xref rid="btad495-T1" ref-type="table">Table 1</xref>).</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Protein encoding</title>
      <p>CoCoNat makes use of residue embeddings obtained with large-scale protein language models (pLMs) to represent proteins in training and testing sets. Specifically, we adopted two state-of-the-art pLMs: ProtT5 (<xref rid="btad495-B6" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic> 2021</xref>) and ESM2 (<xref rid="btad495-B15" ref-type="bibr">Lin <italic toggle="yes">et al.</italic> 2023</xref>), generating, for each residue in the protein sequence, 1024 and 1280 features, respectively. The ESM2 model has been released in several versions, based on different transformer architectures with a varying number of cascading layers. In order to limit the resources required to compute the representations and having an embedding dimension comparable to that provided by ProtT5, we adopted the intermediate model, providing representations of 1280 components and comprising 33 transformer layers with 650M of parameters. Residue-level representations are then concatenated together, leading to vectors of 2304 dimensions for each residue in the sequences. The concatenation of embeddings obtained with different pLMs has been shown to improve the performance in previous works (<xref rid="btad495-B23" ref-type="bibr">Manfredi <italic toggle="yes">et al.</italic> 2022</xref>, <xref rid="btad495-B24" ref-type="bibr">2023</xref>).</p>
    </sec>
    <sec>
      <title>2.3 CoCoNat architecture</title>
      <p>CoCoNat is organized as a three-step method combining a deep learning approach, a probabilistic graphical model, and a single-layer neural network (NN) in a cascading way. The three different steps of the model are trained independently from each other. The first two steps are collectively devised for detecting coiled-coil helix boundaries and the residue-level annotation of registers within each predicted helix. The third step predicts the CCD oligomerization state (<xref rid="btad495-F1" ref-type="fig">Fig. 1</xref>). In the following sections, each step is briefly described.</p>
      <fig position="float" id="btad495-F1">
        <label>Figure 1.</label>
        <caption>
          <p>Workflow of the predictive model of CoCoNat, comprising three steps. The <italic toggle="yes">step 1</italic> maps each residue, encoded with a 2304-dimensional vector (the concatenation of ProtT5 and ESM2 embeddings) into an eight-dimensional vector representing the probability distribution over the labels (<italic toggle="yes">a–g</italic> registers for coiled-coil helices and <italic toggle="yes">i</italic> for non-CCD portions). It combines in cascade (i) a convolutional layer that computes a 40-dimensional representation for each position in the sequence, based on a sliding window of 15 contiguous residues, (ii) an LSTM layer that analyzes the whole sequence and provides a 128-dimensional representation for each position, and (iii) a fully connected feed-forward NN that, residue by residue, provides the 8-dimensional mapping. The <italic toggle="yes">step 2</italic> consists of a GRHCRF that casts the grammar of CCDs in the topology of the connections among 20 different states. Each sequence is generated by a path that starts from the BEGIN state and can either enter the self-looping <italic toggle="yes">i</italic>0 state, which models the <italic toggle="yes">N</italic>-terminal non-CCD portion of the protein, or the first eight-state block (<italic toggle="yes">1a–1b–1c–1d–1e–1f–1g–1H</italic>), which models the first CCD domain. Labels <italic toggle="yes">a–g</italic> of the states in the block correspond to registers and state <italic toggle="yes">H</italic> accommodates non-regular transitions. Residues after the first coiled-coil helix are modeled by the <italic toggle="yes">i</italic>1 state (non-CCD) and, in case, by a second CCD block (<italic toggle="yes">2a–2b–2c–2d–2e–2f–2g–2H</italic>), analogous to the first one. All states, but <italic toggle="yes">1H</italic> and <italic toggle="yes">2H</italic>, can make transition to the END state, terminating the path. GRHCRF provides the annotation of coiled-coil helix boundaries and of registers by computing the optimal <italic toggle="yes">a posteriori</italic> Viterbi path, given the probabilities computed in the step 1. The <italic toggle="yes">step 3</italic> provides the prediction of the oligomeric state, based on the annotation computed in step 2 and on the 2304-dimensional embedding. For each predicted coiled-coil helix, embeddings labeled with registers <italic toggle="yes">a</italic> and <italic toggle="yes">d</italic> are separately averaged and fed into a feed-forward NN that computes the probability distribution over the four possible classes (parallel and antiparallel dimer, trimer, and tetramer). The three steps of the architecture are trained separately.</p>
        </caption>
        <graphic xlink:href="btad495f1" position="float"/>
      </fig>
      <sec>
        <title>2.3.1 Deep learning architecture</title>
        <p>The first step (<xref rid="btad495-F1" ref-type="fig">Fig. 1</xref>) is based on a convolutional layer (<xref rid="btad495-B13" ref-type="bibr">LeCun <italic toggle="yes">et al.</italic> 1989</xref>) followed by a long short-term memory (LSTM) layer (<xref rid="btad495-B11" ref-type="bibr">Hochreiter and Schmidhuber 1997</xref>). The convolutional layer captures local dependencies of the input data. This layer, adopting a 15 residue long sliding window, takes as input the protein, where each residue is represented with a 2304-feature vector. By applying 40 different filters, the layer outputs the same protein with residues encoded with 40-feature vectors. This mapping is provided as input to a LSTM layer including 128 output neurons, which captures long-range dependencies. Finally, we apply a standard feed-forward network (with 64 hidden neurons) with 8 output neurons (one for each possible coiled-coil registers, <italic toggle="yes">a</italic>–<italic toggle="yes">b–c–d–e–f–g</italic>, plus one, <italic toggle="yes">i,</italic> for non-CCD residues), endowed with a sigmoid activation function. The output gives the per-residue probability of each register or none.</p>
        <p>In order to reduce overfitting, we introduce dropout layers between convolutional, LSTM, and the feed-forward network with rate fixed to 0.25. The architecture was trained with a gradient descent of the Kullback–Leibler divergence error function with the Adam optimization algorithm (<xref rid="btad495-B12" ref-type="bibr">Kingma and Ba 2017</xref>). The Kullback–Leibler loss was chosen since it well-fits with models providing probability distributions in output, as in our case. The best model was determined using the early stopping technique of 10 epochs in which the validation error did not decrease.</p>
      </sec>
      <sec>
        <title>2.3.2 Refining the prediction with Grammatical-Restrained Hidden Conditional Random Field (second step)</title>
        <p>The second step (<xref rid="btad495-F1" ref-type="fig">Fig. 1</xref>) takes in input the probabilites computed by step 1. Grammatical-Restrained Hidden Conditional Random Field (GRHCRF) is a discriminative probabilistic model (<xref rid="btad495-B7" ref-type="bibr">Fariselli <italic toggle="yes">et al.</italic> 2009</xref>, <xref rid="btad495-B21" ref-type="bibr">Madeo <italic toggle="yes">et al.</italic> 2021</xref>), and it allows to introduce the regular grammar of the CDD registers. In the prediction phase, a posterior-Viterbi dynamic-programming algorithm computes the most probable path along the model, satisfying the grammatical constraints.</p>
        <p>In our model, the grammar has two identical blocks for CCD prediction, two states (<italic toggle="yes">i</italic>0 and <italic toggle="yes">i</italic>1 in <xref rid="btad495-F1" ref-type="fig">Fig. 1</xref>, step 2) with a self-loop modeling the non-CCD regions, one BEGIN and one END states. In each CCD block, seven states model the register sequence, and one further state (H, 1, and 2) accommodates non-regular transitions (i.e. transitions escaping the regular heptad repeat pattern, <italic toggle="yes">abcdefg</italic>). The first GRHCRF block models the first coiled-coil helix and the second one models all the others coiled-coil helices, when present, in the protein sequence.</p>
        <p>The GRHCRF output defines the precise identification of CCD boundaries and annotates the typical heptad repeat pattern along the coiled-coil helices.</p>
      </sec>
      <sec>
        <title>2.3.3 Prediction of the oligomerization state</title>
        <p>The prediction of the CCD oligomerization state adopts a simple feed-forward NN with a single hidden layer, comprising 128 neurons, and four output units corresponding to the four possible oligomerization states: parallel and antiparallel dimers, trimers, and tetramers.</p>
        <p>The input of this network is built based on a well-known biophysical feature: the oligomeric state of canonical CCD is largely determined by the nature of hydrophobic residues in the heptad repeat pattern, namely, residues labeled with registers <italic toggle="yes">a</italic> and <italic toggle="yes">d</italic> (<xref rid="btad495-B33" ref-type="bibr">Woolfson 2023</xref>; <xref rid="btad495-B14" ref-type="bibr">Li <italic toggle="yes">et al.</italic> 2016)</xref>. Based on this observation, for a given coiled-coil helix, the network input is obtained concatenating the average embedding vectors of <italic toggle="yes">a</italic> and <italic toggle="yes">d</italic> predicted positions.</p>
        <p>More formally, given a coiled-coil helix of length <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mi>l</mml:mi></mml:math></inline-formula>, with an embedding matrix <italic toggle="yes">E</italic> of dimension <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mi>l</mml:mi><mml:mo>×</mml:mo><mml:mn>2304</mml:mn></mml:math></inline-formula> (as derived from the concatenation of two pLM embeddings, ProtT5 and ESM2), the following two mean vectors are computed:
where <italic toggle="yes">N<sub>a</sub></italic> and <italic toggle="yes">N<sub>d</sub></italic> are the number of positions labeled with registers <italic toggle="yes">a</italic> and <italic toggle="yes">d</italic>, respectively. The input vector for the network is then obtained concatenating <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>:
where <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mo>·</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> denotes the vector concatenation operator.</p>
        <disp-formula id="E1">
          <label>(1)</label>
          <mml:math id="M1" display="block" overflow="scroll">
            <mml:mrow>
              <mml:msub>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mrow>
                          <mml:mi>e</mml:mi>
                        </mml:mrow>
                        <mml:mo>¯</mml:mo>
                      </mml:mover>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>a</mml:mi>
                </mml:mrow>
              </mml:msub>
            </mml:mrow>
            <mml:mo>=</mml:mo>
            <mml:mrow>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
                <mml:mrow>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>a</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
            <mml:mrow>
              <mml:mrow>
                <mml:munder>
                  <mml:mo stretchy="false">∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>r</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mi>a</mml:mi>
                  </mml:mrow>
                </mml:munder>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi>E</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>r</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <disp-formula id="E2">
          <label>(2)</label>
          <mml:math id="M2" display="block" overflow="scroll">
            <mml:mrow>
              <mml:msub>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mrow>
                          <mml:mi>e</mml:mi>
                        </mml:mrow>
                        <mml:mo>¯</mml:mo>
                      </mml:mover>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>d</mml:mi>
                </mml:mrow>
              </mml:msub>
            </mml:mrow>
            <mml:mo>=</mml:mo>
            <mml:mrow>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
                <mml:mrow>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>d</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
            <mml:mrow>
              <mml:mrow>
                <mml:munder>
                  <mml:mo stretchy="false">∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>r</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mi>d</mml:mi>
                  </mml:mrow>
                </mml:munder>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi>E</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>r</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <disp-formula id="E3">
          <label>(3)</label>
          <mml:math id="M3" display="block" overflow="scroll">
            <mml:mi>x</mml:mi>
            <mml:mo>=</mml:mo>
            <mml:mrow>
              <mml:msub>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mrow>
                          <mml:mi>e</mml:mi>
                        </mml:mrow>
                        <mml:mo>¯</mml:mo>
                      </mml:mover>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>a</mml:mi>
                </mml:mrow>
              </mml:msub>
            </mml:mrow>
            <mml:mo>·</mml:mo>
            <mml:mrow>
              <mml:msub>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mrow>
                          <mml:mi>e</mml:mi>
                        </mml:mrow>
                        <mml:mo>¯</mml:mo>
                      </mml:mover>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>d</mml:mi>
                </mml:mrow>
              </mml:msub>
            </mml:mrow>
          </mml:math>
        </disp-formula>
      </sec>
      <sec>
        <title>2.3.4 Model training and selection procedure</title>
        <p>The whole CoCoNat architecture was trained with three independent training procedures for steps 1, 2, and 3.</p>
        <p>The deep-learning architecture of step 1 was optimized using 10-fold cross-validation and a grid search to select the main model hyperparameters. Specifically, we selected the best number of convolutional filters (testing values in the set 10, 20, 40, 80, 160), the optimal LSTM hidden output size (testing values in the set 32, 64, 128, 256), and the optimal number of hidden neurons in the final feed-forward network (testing values in the set 12, 32, 64, 128, 256). The optimal configuration was chosen as the one maximizing the cross-validation <italic toggle="yes">F</italic>1 score at residue level (see next section), and include 40 convolutional filters, 128 units for the LSTM size and 64 neurons in the hidden layer of the final feed-forward network.</p>
        <p>For step 2, the hyperparameters of the GRHCRF include the σ<sup>2</sup> used for L2 regularization and the number of training iterations (<xref rid="btad495-B7" ref-type="bibr">Fariselli <italic toggle="yes">et al.</italic> 2009</xref>). These were optimized in cross-validation and grid search testing various combinations (σ<sup>2</sup> in the set 0.0001, 0.001, 0.05, 0.1 and iterations in the set 10, 20, 40, 100). The optimal values are σ<sup>2</sup>= 0.05 and 40 iterations.</p>
        <p>Finally, step 3 architecture only required to optimize the number of hidden neurons. Again, we tested different values (16, 32, 64, 128, 256) and selected the optimal one as those maximizing the average MCC across the four oligomeric states. The best value is 128.</p>
        <p>Steps 1 and 3 architectures are implemented in PyTorch (<ext-link xlink:href="https://pytorch.org/" ext-link-type="uri">https://pytorch.org/</ext-link>). The GRHCRF is implemented using the biocrf package (<xref rid="btad495-B7" ref-type="bibr">Fariselli <italic toggle="yes">et al.</italic> 2009</xref>).</p>
      </sec>
    </sec>
    <sec>
      <title>2.4 Scoring performance</title>
      <p>To evaluate the performance of our method in recognizing coiled-coil helices, we adopted residue- and segment-based measures.</p>
      <p>The residue-based scores include precision (PRE<sub>R</sub>), recall (REC<sub>R</sub>), and <italic toggle="yes">F</italic>1-score (<italic toggle="yes">F</italic>1<sub>R</sub>).
where TP<sub>R</sub>, FP<sub>R</sub>, and FN<sub>R</sub> are true positive, false positive, and false negative coiled-coiled residues, respectively.</p>
      <disp-formula id="E4">
        <label>(4)</label>
        <mml:math id="M4" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="normal">PRE</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="normal">R</mml:mi>
              </mml:mrow>
            </mml:msub>
          </mml:mrow>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">FP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula id="E5">
        <label>(5)</label>
        <mml:math id="M5" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="normal">REC</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="normal">R</mml:mi>
              </mml:mrow>
            </mml:msub>
          </mml:mrow>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">FN</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula id="E6">
        <label>(6)</label>
        <mml:math id="M6" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi>F</mml:mi>
                <mml:mn>1</mml:mn>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="normal">R</mml:mi>
              </mml:mrow>
            </mml:msub>
          </mml:mrow>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mn>2</mml:mn>
                <mml:mo>×</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">PRE</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>×</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">REC</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">PRE</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">REC</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">R</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>Analogously, the segment-based scores include precision (PRE<sub>S</sub>), recall (REC<sub>S</sub>), and <italic toggle="yes">F</italic>1-score (<italic toggle="yes">F</italic>1<sub>S</sub>):
</p>
      <disp-formula id="E7">
        <label>(7)</label>
        <mml:math id="M7" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="normal">PRE</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="normal">S</mml:mi>
              </mml:mrow>
            </mml:msub>
          </mml:mrow>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">FP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula id="E8">
        <label>(8)</label>
        <mml:math id="M8" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="normal">REC</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="normal">S</mml:mi>
              </mml:mrow>
            </mml:msub>
          </mml:mrow>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">TP</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">FN</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula id="E9">
        <label>(9)</label>
        <mml:math id="M9" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi>F</mml:mi>
                <mml:mn>1</mml:mn>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>S</mml:mi>
              </mml:mrow>
            </mml:msub>
          </mml:mrow>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mn>2</mml:mn>
                <mml:mo>×</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">PRE</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>×</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">REC</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
              <mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">PRE</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">REC</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="normal">S</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>In this case, TP<sub>S</sub>, FP<sub>S,</sub> and FN<sub>S</sub> are computed for the coiled-coil helices. Prediction is considered correct (TP<sub>S</sub>) only if the overlap between predicted and observed segments is at least equal to the half-length of the longest segment.</p>
      <p>Following <xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> (2022)</xref>, we used two segment overlap (SOV) measures, one taking as reference observed residues (SOVo) and one taking as reference predicted residues (SOVp) (<xref rid="btad495-B34" ref-type="bibr">Zemla <italic toggle="yes">et al.</italic> 1999</xref>).</p>
      <p>We computed the precision-recall (PR) curve and the relative area under the curve (PR-AUC), by plotting the two measures at varying thresholds of coiled-coil probabilities as obtained from the GRHCRF posterior probability values.</p>
      <p>For the register and oligomeric state prediction tasks, we reported class-level MCC values:
</p>
      <disp-formula id="E10">
        <label>(10)</label>
        <mml:math id="M10" display="block" overflow="scroll">
          <mml:mi mathvariant="normal">MCC</mml:mi>
          <mml:mo>=</mml:mo>
          <mml:mrow>
            <mml:mfrac>
              <mml:mrow>
                <mml:mi mathvariant="normal">TP</mml:mi>
                <mml:mo>×</mml:mo>
                <mml:mi mathvariant="normal">TN</mml:mi>
                <mml:mo>-</mml:mo>
                <mml:mi mathvariant="normal">FP</mml:mi>
                <mml:mo>×</mml:mo>
                <mml:mi mathvariant="normal">FN</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:msqrt>
                  <mml:mo>(</mml:mo>
                  <mml:mi mathvariant="normal">TP</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="normal">FP</mml:mi>
                  <mml:mo>)</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mi mathvariant="normal">TP</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="normal">FN</mml:mi>
                  <mml:mo>)</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mi mathvariant="normal">TN</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="normal">FP</mml:mi>
                  <mml:mo>)</mml:mo>
                  <mml:mo>(</mml:mo>
                  <mml:mi mathvariant="normal">TN</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="normal">FN</mml:mi>
                  <mml:mo>)</mml:mo>
                </mml:msqrt>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Visualizing ProtT5 and ESM2 embeddings with t-SNE</title>
      <p>For evaluating whether the two language models capture coiled-coil-related features in their representations, we adopted <italic toggle="yes">t</italic>-SNE (<xref rid="btad495-B29" ref-type="bibr">van der Maaten and Hinton 2008</xref>) to project raw embedding vectors obtained with ProtT5 and ESM2 in two dimensions.</p>
      <p>First, we wanted to assess if the raw embeddings can distinguish the different register features. To this aim, we projected all representations of coiled-coil residues in the training set, and then we colored projected points by the heptad repeat register they are annotated with, distinguishing two classes: hydrophobic register positions (<italic toggle="yes">a</italic> and <italic toggle="yes">d</italic>) and polar positions (<italic toggle="yes">b</italic>, <italic toggle="yes">c</italic>, <italic toggle="yes">e</italic>, <italic toggle="yes">f</italic>, and <italic toggle="yes">g</italic>). Results are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 2A</xref>. From the projections, even if a clear separation is missing, it is evident that the two models can capture the hydrophobic/polar register difference to a good extent. Among the two models, ProtT5 seems to provide a slightly better separation.</p>
      <p>Second, to investigate if the embedding can capture the relation between hydrophobic registers and oligomeric state, we projected all representations of hydrophobic register positions in the training set (<italic toggle="yes">a</italic> and <italic toggle="yes">d</italic>), and then we colored projected points according to the oligomeric state of the corresponding helix. Resulting <italic toggle="yes">t</italic>-SNE projections are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 2B</xref>. In this case, the separation is less evident, even if some clusters are visible (mostly in ProtT5 projections) for parallel dimers and trimers. Possibly, more <italic toggle="yes">t</italic>-SNE dimensions are needed to achieve a better separation.</p>
      <p>Overall, these experiments suggest that information is already present in the raw embeddings. However, a specific transfer learning architecture, processing the whole sequence, and further exploiting the local and global sequence context is needed to better capture coiled-coil features.</p>
    </sec>
    <sec>
      <title>3.2 Cross-validation results</title>
      <p>We performed 10-fold cross-validation experiments to evaluate the contribution from the two protein language models. We independently trained three different identical models adopting as input: (i) ProtT5, (ii) ESM2, and (iii) both encodings combined in a single vector. Results are reported in <xref rid="btad495-T2" ref-type="table">Table 2</xref>. The overall prediction achieved with each one of the two language models is similar (<italic toggle="yes">F</italic>1<sub>R</sub> and <italic toggle="yes">F</italic>1<sub>S</sub> scores equals 0.44, 0.34, and 0.46, 0.37 with ProtT5 and ESM2, respectively). However, combining the two embeddings into a single vector leads to better performances, raising both precision and recall values, and achieving <italic toggle="yes">F</italic>1<sub>R</sub> and <italic toggle="yes">F</italic>1<sub>S</sub> values of 0.52 and 0.41, respectively. This suggests that the two models are somewhat complementary. We analyzed and compared residue-level true positive predictions obtained with inputs based on the two pLMs. We find that the two models individually trained with ProtT5 and ESM2 share 25 373 correctly predicted residues, and that 4166 and 8341 coiled-coil residues are correctly and uniquely identified, respectively. This finding highlights the complementarity of the two models. These results agree with previous works in which the combination of embeddings from different pLMs has been proven effective also for other prediction tasks (<xref rid="btad495-B23" ref-type="bibr">Manfredi <italic toggle="yes">et al.</italic> 2022</xref>, <xref rid="btad495-B24" ref-type="bibr">2023</xref>). All results presented in this manuscript are obtained using the combination of the two input embeddings.</p>
      <table-wrap position="float" id="btad495-T2">
        <label>Table 2.</label>
        <caption>
          <p>Prediction of coiled-coil helices with CoCoNat adopting different embeddings.<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref></p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Input</th>
              <th rowspan="1" colspan="1">PRE<sub>R</sub></th>
              <th rowspan="1" colspan="1">REC<sub>R</sub></th>
              <th rowspan="1" colspan="1"><italic toggle="yes">F</italic>1<sub>R</sub></th>
              <th rowspan="1" colspan="1">PRAUC</th>
              <th rowspan="1" colspan="1">PRE<sub>S</sub></th>
              <th rowspan="1" colspan="1">REC<sub>S</sub></th>
              <th rowspan="1" colspan="1"><italic toggle="yes">F</italic>1<sub>S</sub></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">ProtT5</td>
              <td rowspan="1" colspan="1">0.42</td>
              <td rowspan="1" colspan="1">0.46</td>
              <td rowspan="1" colspan="1">0.44</td>
              <td rowspan="1" colspan="1">0.38</td>
              <td rowspan="1" colspan="1">0.32</td>
              <td rowspan="1" colspan="1">0.36</td>
              <td rowspan="1" colspan="1">0.34</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ESM2</td>
              <td rowspan="1" colspan="1">0.50</td>
              <td rowspan="1" colspan="1">0.50</td>
              <td rowspan="1" colspan="1">0.46</td>
              <td rowspan="1" colspan="1">0.41</td>
              <td rowspan="1" colspan="1">0.47</td>
              <td rowspan="1" colspan="1">0.32</td>
              <td rowspan="1" colspan="1">0.37</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ProtT5+ESM2</td>
              <td rowspan="1" colspan="1">0.51</td>
              <td rowspan="1" colspan="1">0.47</td>
              <td rowspan="1" colspan="1">0.49</td>
              <td rowspan="1" colspan="1">0.47</td>
              <td rowspan="1" colspan="1">0.38</td>
              <td rowspan="1" colspan="1">0.37</td>
              <td rowspan="1" colspan="1">0.37</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <label>a</label>
            <p>CoCoNat architecture is depicted in <xref rid="btad495-F1" ref-type="fig">Fig. 1</xref>. The training set is described in <xref rid="btad495-T1" ref-type="table">Table 1</xref>. Results are obtained adopting a 10-fold cross-validation. For details, see Section 2. Subscript R: per residue; subscript S: per CC helix segment. Variability across cross-validation sets is lower than 1% for all scores.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.3 Prediction of coiled coils on the blind test set</title>
      <p>CoCoNat is benchmarked on the same blind test set against available methods. In <xref rid="btad495-T3" ref-type="table">Table 3</xref>, we report results for the prediction of coiled-coil helices. Tested methods include: MARCOIL (<xref rid="btad495-B5" ref-type="bibr">Delorenzi and Speed 2002</xref>), CCHMM_prof (<xref rid="btad495-B1" ref-type="bibr">Bartoli <italic toggle="yes">et al.</italic> 2009</xref>), Multicoil2 (<xref rid="btad495-B27" ref-type="bibr">Trigg <italic toggle="yes">et al.</italic> 2011</xref>), DeepCoil2 (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>), and CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>). All the methods were run in house using the respective available standalone versions. Since DeepCoil2 does not provide a classification but rather a probability value, we report results obtained by applying two different probability thresholds set to 0.2 and 0.5, respectively.</p>
      <table-wrap position="float" id="btad495-T3">
        <label>Table 3.</label>
        <caption>
          <p>CoCoNat and the state-of-art methods on the same blind test set.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">
                <bold>Method</bold>
                <xref rid="tblfn2" ref-type="table-fn">
                  <sup>a</sup>
                </xref>
              </th>
              <th rowspan="1" colspan="1">PRE<sub>R</sub></th>
              <th rowspan="1" colspan="1">REC<sub>R</sub></th>
              <th rowspan="1" colspan="1"><italic toggle="yes">F</italic>1<sub>R</sub></th>
              <th rowspan="1" colspan="1">PRAUC</th>
              <th rowspan="1" colspan="1">PRE<sub>S</sub></th>
              <th rowspan="1" colspan="1">REC<sub>S</sub></th>
              <th rowspan="1" colspan="1"><italic toggle="yes">F</italic>1s</th>
              <th rowspan="1" colspan="1">SOV<sub>O</sub></th>
              <th rowspan="1" colspan="1">SOV<sub>P</sub></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">MARCOIL</td>
              <td rowspan="1" colspan="1">0.34</td>
              <td rowspan="1" colspan="1">0.26</td>
              <td rowspan="1" colspan="1">0.29</td>
              <td rowspan="1" colspan="1">0.16</td>
              <td rowspan="1" colspan="1">0.24</td>
              <td rowspan="1" colspan="1">0.06</td>
              <td rowspan="1" colspan="1">0.1</td>
              <td rowspan="1" colspan="1">18.15</td>
              <td rowspan="1" colspan="1">48.03</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CCHMM_prof</td>
              <td rowspan="1" colspan="1">0.16</td>
              <td rowspan="1" colspan="1">
                <bold>0.6</bold>
              </td>
              <td rowspan="1" colspan="1">0.23</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">0.12</td>
              <td rowspan="1" colspan="1">0.25</td>
              <td rowspan="1" colspan="1">0.15</td>
              <td rowspan="1" colspan="1">43.25</td>
              <td rowspan="1" colspan="1">16.32</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Multicoil2</td>
              <td rowspan="1" colspan="1">0.34</td>
              <td rowspan="1" colspan="1">0.13</td>
              <td rowspan="1" colspan="1">0.19</td>
              <td rowspan="1" colspan="1">0.15</td>
              <td rowspan="1" colspan="1">0.19</td>
              <td rowspan="1" colspan="1">0.01</td>
              <td rowspan="1" colspan="1">0.02</td>
              <td rowspan="1" colspan="1">7.40</td>
              <td rowspan="1" colspan="1">48.86</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepCoil2 (th = 0.2)</td>
              <td rowspan="1" colspan="1">0.39</td>
              <td rowspan="1" colspan="1">
                <bold>0.6</bold>
              </td>
              <td rowspan="1" colspan="1">0.48</td>
              <td rowspan="1" colspan="1">0.36</td>
              <td rowspan="1" colspan="1">0.42</td>
              <td rowspan="1" colspan="1">
                <bold>0.49</bold>
              </td>
              <td rowspan="1" colspan="1">0.45</td>
              <td rowspan="1" colspan="1">
                <bold>59.83</bold>
              </td>
              <td rowspan="1" colspan="1">50.93</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepCoil2 (th = 0.5)</td>
              <td rowspan="1" colspan="1">0.51</td>
              <td rowspan="1" colspan="1">0.33</td>
              <td rowspan="1" colspan="1">0.4</td>
              <td rowspan="1" colspan="1">0.36</td>
              <td rowspan="1" colspan="1">0.53</td>
              <td rowspan="1" colspan="1">0.2</td>
              <td rowspan="1" colspan="1">0.29</td>
              <td rowspan="1" colspan="1">31.17</td>
              <td rowspan="1" colspan="1">66.64</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoCoPRED</td>
              <td rowspan="1" colspan="1">0.43</td>
              <td rowspan="1" colspan="1">0.54</td>
              <td rowspan="1" colspan="1">0.48</td>
              <td rowspan="1" colspan="1">0.45</td>
              <td rowspan="1" colspan="1">0.38</td>
              <td rowspan="1" colspan="1">0.46</td>
              <td rowspan="1" colspan="1">0.41</td>
              <td rowspan="1" colspan="1">57.64</td>
              <td rowspan="1" colspan="1">51.17</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoCoNat</td>
              <td rowspan="1" colspan="1">
                <bold>0.55</bold>
              </td>
              <td rowspan="1" colspan="1">0.53</td>
              <td rowspan="1" colspan="1">
                <bold>0.54</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.46</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.57</bold>
              </td>
              <td rowspan="1" colspan="1">0.43</td>
              <td rowspan="1" colspan="1">
                <bold>0.49</bold>
              </td>
              <td rowspan="1" colspan="1">54.35</td>
              <td rowspan="1" colspan="1">
                <bold>66.93</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <label>a</label>
            <p>MARCOIL (<xref rid="btad495-B5" ref-type="bibr">Delorenzi and Speed 2002</xref>), CCHMM_prof (<xref rid="btad495-B1" ref-type="bibr">Bartoli <italic toggle="yes">et al.</italic> 2009</xref>), Multicoil2 (<xref rid="btad495-B27" ref-type="bibr">Trigg <italic toggle="yes">et al.</italic> 2011</xref>), DeepCoil2 (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>), CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>). Subscript R: per residue; subscript S: per CC helix segment. The blind test set contains 400 positive and 318 negative proteins. Bold values highlight the highest scores.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>CoCoNat, which adopts encodings based on ProT5 and ESM2, outperforms the state-of-the-art, showing (with respect to the second top performing method in the benchmark) an improvement in the per-residue precision value (0.55), with a slight loss in recall (0.53), which is reflected in the higher value of the <italic toggle="yes">F</italic>1-score (0.54). The per-segment scores of CoCoNat confirm this trend. Moreover, CoCoNat performs with the highest SOVp and the third highest SOVo (see Section 2.4 for definition).</p>
      <p>For sake of assessing the significance of the differences observed in data reported in <xref rid="btad495-T3" ref-type="table">Table 3</xref>, we performed a boostrapping procedure and a two-sample Welch’s <italic toggle="yes">t</italic>-test. Specifically, from the blind test set results, we randomly selected 100 samples of 300 sequences and evaluated all the methods using residue- and segment-level scoring measures. Then, average performances of CoCoNat were compared for statistical significance with average scores of other tools. All the differences observed in this experiment reflect those reported in <xref rid="btad495-T3" ref-type="table">Table 3</xref> and are all significant at 0.0001 significance threshold. Results are reported in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table 1</xref>.</p>
    </sec>
    <sec>
      <title>3.4 Prediction of coiled-coil registers</title>
      <p>We compared CoCoNat with other tools in the task of annotating heptad repeat registers. To this aim, we used the blind test of 400 proteins endowed with CCDs. Results of all methods were generated using the respective standalone versions (<xref rid="btad495-T4" ref-type="table">Table 4</xref>).</p>
      <table-wrap position="float" id="btad495-T4">
        <label>Table 4.</label>
        <caption>
          <p>CoCoNat and the state-of-art methods on the prediction of heptad repeat registers.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">
                <bold>Method</bold>
                <xref rid="tblfn3" ref-type="table-fn">
                  <sup>a</sup>
                </xref>
              </th>
              <th rowspan="1" colspan="1">MCC (a)</th>
              <th rowspan="1" colspan="1">MCC (b)</th>
              <th rowspan="1" colspan="1">MCC (c)</th>
              <th rowspan="1" colspan="1">MCC (d)</th>
              <th rowspan="1" colspan="1">MCC (e)</th>
              <th rowspan="1" colspan="1">MCC (f)</th>
              <th rowspan="1" colspan="1">MCC (g)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">MARCOIL</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.66</td>
              <td rowspan="1" colspan="1">0.66</td>
              <td rowspan="1" colspan="1">0.66</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Multicoil2</td>
              <td rowspan="1" colspan="1">0.56</td>
              <td rowspan="1" colspan="1">0.56</td>
              <td rowspan="1" colspan="1">0.57</td>
              <td rowspan="1" colspan="1">0.57</td>
              <td rowspan="1" colspan="1">0.58</td>
              <td rowspan="1" colspan="1">0.58</td>
              <td rowspan="1" colspan="1">0.57</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepCoil2 (th = 0.2)</td>
              <td rowspan="1" colspan="1">0.62</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">0.62</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepCoil2 (th = 0.5)</td>
              <td rowspan="1" colspan="1">0.68</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">0.68</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoCoPRED</td>
              <td rowspan="1" colspan="1">0.65</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.66</td>
              <td rowspan="1" colspan="1">0.66</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.65</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoCoNat</td>
              <td rowspan="1" colspan="1">
                <bold>0.84</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.84</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.84</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.84</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.83</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.83</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.83</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <label>a</label>
            <p>MARCOIL (<xref rid="btad495-B5" ref-type="bibr">Delorenzi and Speed 2002</xref>); Multicoil2 (<xref rid="btad495-B27" ref-type="bibr">Trigg <italic toggle="yes">et al.</italic> 2011</xref>); DeepCoil2 (<xref rid="btad495-B16" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic> 2019</xref>); CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>). The blind test set contains 400 positive proteins. Bold values highlight the highest scores.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>For all the register labels <italic toggle="yes">a–g</italic>, CoCoNat MCC values indicate an improvement ranging from 16% to 19% with respect to the second best-performing method, CoCoPRED.</p>
      <p>Remarkably, CoCoNat MCC values are quite similar across all the seven different register labels, suggesting that the register is routinely predicted in the correct regular configuration, from label <italic toggle="yes">a</italic> to <italic toggle="yes">g</italic>. This highlights that the GRHCRF grammar is properly capturing transition constraints among the different registers within the coiled-coil segments.</p>
    </sec>
    <sec>
      <title>3.5 Prediction of the CCD oligomerization state</title>
      <p>We finally compared CoCoNat, LOGICOIL (<xref rid="btad495-B30" ref-type="bibr">Vincent <italic toggle="yes">et al.</italic> 2013</xref>) CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>) on the task of predicting CCD oligomerization state. Again, we used the blind test set of 400 proteins as benchmark. The three methods are compared assuming an oracle predictor for the identification of CCD segments (i.e. we classify real CCD segments into the four oligomerization classes). In <xref rid="btad495-T5" ref-type="table">Table 5</xref>, we report a comparison of the three approaches in terms of per-class MCCs.</p>
      <table-wrap position="float" id="btad495-T5">
        <label>Table 5.</label>
        <caption>
          <p>CoCoNat and the state-of-art methods on the prediction of oligomerization states.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">
                <bold>Method</bold>
                <xref rid="tblfn4" ref-type="table-fn">
                  <sup>a</sup>
                </xref>
              </th>
              <th rowspan="1" colspan="1">MCC (parallel dimer)</th>
              <th rowspan="1" colspan="1">MCC (antiparallel dimer)</th>
              <th rowspan="1" colspan="1">MCC (trimer)</th>
              <th rowspan="1" colspan="1">MCC (tetramer)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">LOGICOIL</td>
              <td rowspan="1" colspan="1">0.12</td>
              <td rowspan="1" colspan="1">0.07</td>
              <td rowspan="1" colspan="1">0.01</td>
              <td rowspan="1" colspan="1">0.01</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoCoPRED</td>
              <td rowspan="1" colspan="1">0.37</td>
              <td rowspan="1" colspan="1">0.21</td>
              <td rowspan="1" colspan="1">0.14</td>
              <td rowspan="1" colspan="1">0.18</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CoCoNat</td>
              <td rowspan="1" colspan="1">
                <bold>0.66</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.70</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.50</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.46</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn4">
            <label>a</label>
            <p>LOGICOIL (<xref rid="btad495-B30" ref-type="bibr">Vincent <italic toggle="yes">et al.</italic> 2013</xref>); CoCoPRED (<xref rid="btad495-B8" ref-type="bibr">Feng <italic toggle="yes">et al.</italic> 2022</xref>). The blind test set contains 400 positive proteins. Bold values highlight the highest scores.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Looking at the MCC values, CoCoNat significantly overpasses CoCoPRED and LOGICOIL, providing predictions that are overall higher and more balanced across the four oligomerization state classes. Remarkably, CoCoNat outperforms other tools also on less abundant classes, i.e. trimers and tetramers.</p>
    </sec>
    <sec>
      <title>3.6 CoCoNat availability and analysis of running time</title>
      <p>We release CoCoNat as both web server and standalone version. The web server is available at <ext-link xlink:href="https://coconat.biocomp.unibo.it" ext-link-type="uri">https://coconat.biocomp.unibo.it</ext-link>. The server provides a user-friendly web interface, allowing the user to choose between two modes of use of the tool: (i) analysis and visualization of coiled-coil prediction results for a single input sequence; (ii) submission of a batch job allowing prediction of coiled-coils and download of results (in TSV and JSON formats) for up to 500 sequences per job. Additionally, for single-sequence mode, we also provide the possibility of uploading a pre-determined set of coiled-coil segments, restricting the prediction to the oligomeric state only. The web application is implemented using Django (version 4.0.4), Bootstrap (version 5.3.0), JQuery (version 3.6.0), and neXtProt FeatureViewer (version 1.3.0-beta6) for visualization of predicted coiled-coil segments along the sequence.</p>
      <p>The standalone version of CoCoNat is available on GitHub at <ext-link xlink:href="https://github.com/BolognaBiocomp/coconat" ext-link-type="uri">https://github.com/BolognaBiocomp/coconat</ext-link>. The standalone tool is implemented in Python as a Docker containerized application. This avoids the installation of dependencies and allows users to quickly install the program in any server equipped with Docker. Instructions on how to build the Docker image and run CoCoNat are available on the GitHub repository.</p>
      <p>We performed experiments to evaluate the running time of CoCoNat in different conditions. All the experiments were performed on the virtual machine hosting the web server, equipped with AMD EPYC 7301 12-Core Processor, 48G RAM. No GPU is available on this machine.</p>
      <p>First, we analyzed the impact of the protein sequence length on the running time. To this aim, we randomly selected different sets of 100 sequences with lengths of increasing size. Fifty samples are generated for each length bin. CoCoNat has been then executed on each sample, evaluating its running time. Results are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 3A</xref>. The running time scales linearly with the length of the sequences, ranging from 200 s (for 100 sequences) when protein length is 50–100 residues to 1400 s when length is 600/700 residues.</p>
      <p>Second, we analyzed how the number of sequences in the dataset impacts on the running time. Again, random samples of sequences were generated, varying from 10, 20, 40, 80, 160, 320, and 500. The length of sequences was set between 100 and 200 residues for all samples. Results are reported in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 3B</xref>. The time required for the datasets including 10, 20, and 40 sequences is almost identical. This is due to the overhead required to load the two pLMs for encoding, which dominates the overall running time when the number of sequences is low. For dataset sizes including more than 40 sequences, the running time scales almost linearly from 100 to 1400 s.</p>
      <p>In general, the CoCoNat running time is always low if compared to the time required by other tools based on multiple-sequence alignment inputs, such as CoCoPRED. For instance, to predict coiled-coil helices, including registers and oligomeric state, on 100 sequences of length comprised between 100 and 200 residues, the CoCoNat average running time is 330 s (5.5 min), which is lower than the time required by CoCoPRED, requiring about 2.5 h.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>In this article, we described CoCoNat, a novel method based on protein language model embeddings and deep learning for detection of coiled-coiled helices at residue level, prediction of coiled-coil heptad repeat registers, and oligomerization state.</p>
    <p>Training and testing were performed on datasets derived from literature. When compared with other state-of-the-art tools, CoCoNat reports performance that are significantly better than those obtained by other approaches tested, in particular when considering register and oligomerization state prediction.</p>
    <p>In this work, we also proved the relevance of adopting protein residue representations derived from large-scale protein language models such as ProtT5 (<xref rid="btad495-B6" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic> 2021</xref>) and ESM2 (<xref rid="btad495-B15" ref-type="bibr">Lin <italic toggle="yes">et al.</italic> 2023</xref>) for this specific task. Moreover, we further confirmed that the combination of different language models provides better performance, suggesting that different models obtained with different architectures and data give complementary representations.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btad495_Supplementary_Data</label>
      <media xlink:href="btad495_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>The authors declare no conflict of interest.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>The work was supported by the project 2017483NH8_002 [PRIN2017 to C.S.] from the Italian Ministry of University and Research and by the project “Consolidation of the Italian Infrastructure for Omics Data and Bioinformatics” (ELIXIRxNextGenIT) [IR0000010] from the Italian Ministry of University and Research (EU funding within the NextGeneration EU).</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The data underlying this article are available in the article, in its online <xref rid="sup1" ref-type="supplementary-material">supplementary material</xref> and on the CoCoNat web server at <ext-link xlink:href="https://coconat.biocomp.unibo.it" ext-link-type="uri">https://coconat.biocomp.unibo.it</ext-link>.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btad495-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bartoli</surname><given-names>L</given-names></string-name>, <string-name><surname>Fariselli</surname><given-names>P</given-names></string-name>, <string-name><surname>Krogh</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>CCHMM_PROF: a HMM-based coiled-coil predictor with evolutionary information</article-title>. <source>Bioinformatics</source><year>2009</year>;<volume>25</volume>:<fpage>2757</fpage>–<lpage>63</lpage>.<pub-id pub-id-type="pmid">19744995</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Crick</surname><given-names>FHC.</given-names></string-name></person-group><article-title>Is alpha-keratin a coiled coil?</article-title><source>Nature</source><year>1952</year>;<volume>170</volume>:<fpage>882</fpage>–<lpage>3</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Crick</surname><given-names>FHC.</given-names></string-name></person-group><article-title>The Fourier transform of a coiled-coil</article-title>. <source>Acta Cryst</source><year>1953a</year>;<volume>6</volume>:<fpage>685</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Crick</surname><given-names>FHC.</given-names></string-name></person-group><article-title>The packing of α-helices: simple coiled-coils</article-title>. <source>Acta Cryst</source><year>1953b</year>;<volume>6</volume>:<fpage>689</fpage>–<lpage>97</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Delorenzi</surname><given-names>M</given-names></string-name>, <string-name><surname>Speed</surname><given-names>T.</given-names></string-name></person-group><article-title>An HMM model for coiled-coil domains and a comparison with PSSM-based predictions</article-title>. <source>Bioinformatics</source><year>2002</year>;<volume>18</volume>:<fpage>617</fpage>–<lpage>25</lpage>.<pub-id pub-id-type="pmid">12016059</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Elnaggar</surname><given-names>A</given-names></string-name>, <string-name><surname>Heinzinger</surname><given-names>M</given-names></string-name>, <string-name><surname>Dallago</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>ProtTrans: Toward understanding the language of life through self-supervised learning</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source><year>2022</year>;<volume>44</volume>:<fpage>7112</fpage>–<lpage>27</lpage>.<pub-id pub-id-type="pmid">34232869</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fariselli</surname><given-names>P</given-names></string-name>, <string-name><surname>Savojardo</surname><given-names>C</given-names></string-name>, <string-name><surname>Martelli</surname><given-names>PL</given-names></string-name></person-group><etal>et al</etal><article-title>Grammatical-Restrained Hidden Conditional Random Fields for Bioinformatics applications</article-title>. <source>Algorithms Mol Biol</source><year>2009</year>;<volume>4</volume>:<fpage>13</fpage>.<pub-id pub-id-type="pmid">19849839</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Feng</surname><given-names>S-H</given-names></string-name>, <string-name><surname>Xia</surname><given-names>C-Q</given-names></string-name>, <string-name><surname>Shen</surname><given-names>H-B</given-names></string-name></person-group><etal>et al</etal><article-title>CoCoPRED: coiled-coil protein structural feature prediction from amino acid sequence using deep neural networks</article-title>. <source>Bioinformatics</source><year>2022</year>;<volume>38</volume>:<fpage>720</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">34718416</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fox</surname><given-names>NK</given-names></string-name>, <string-name><surname>Brenner</surname><given-names>SE</given-names></string-name>, <string-name><surname>Chandonia</surname><given-names>J-M</given-names></string-name></person-group><etal>et al</etal><article-title>SCOPe: structural classification of proteins—extended, integrating SCOP and ASTRAL data and classification of new structures</article-title>. <source>Nucleic Acids Res</source><year>2014</year>;<volume>42</volume>:<fpage>D304</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">24304899</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gruber</surname><given-names>M</given-names></string-name>, <string-name><surname>Söding</surname><given-names>J</given-names></string-name>, <string-name><surname>Lupas</surname><given-names>AN</given-names></string-name></person-group><etal>et al</etal><article-title>REPPER–repeats and their periodicities in fibrous proteins</article-title>. <source>Nucleic Acids Res</source><year>2005</year>;<volume>33</volume>:<fpage>W239</fpage>–<lpage>43</lpage>.<pub-id pub-id-type="pmid">15980460</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hochreiter</surname><given-names>S</given-names></string-name>, <string-name><surname>Schmidhuber</surname><given-names>J.</given-names></string-name></person-group><article-title>Long short-term memory</article-title>. <source>Neural Comput</source><year>1997</year>;<volume>9</volume>:<fpage>1735</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>DP</given-names></string-name>, <string-name><surname>Ba</surname><given-names>J.</given-names></string-name></person-group> Adam: a method for stochastic optimization. arXiv:1412.6980 [cs], <year>2017</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btad495-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>LeCun</surname><given-names>Y</given-names></string-name>, <string-name><surname>Boser</surname><given-names>B</given-names></string-name>, <string-name><surname>Denker</surname><given-names>JS</given-names></string-name></person-group><etal>et al</etal><article-title>Backpropagation applied to handwritten zip code recognition</article-title>. <source>Neural Comput</source>. <year>1989</year>;<volume>1</volume>:<fpage>541</fpage>–<lpage>51</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>C</given-names></string-name>, <string-name><surname>Ching Han Chang</surname><given-names>C</given-names></string-name>, <string-name><surname>Nagel</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Critical evaluation of in silico methods for prediction of coiled-coil domains in proteins</article-title>. <source>Brief Bioinform</source><year>2016</year>;<volume>17</volume>:<fpage>270</fpage>–<lpage>82</lpage>.<pub-id pub-id-type="pmid">26177815</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>Z</given-names></string-name>, <string-name><surname>Akin</surname><given-names>H</given-names></string-name>, <string-name><surname>Rao</surname><given-names>R</given-names></string-name></person-group><etal>et al</etal><article-title>Evolutionary-scale prediction of atomic-level protein structure with a language model</article-title>. <source>Science</source><year>2023</year>;<volume>379</volume>:<fpage>1123</fpage>–<lpage>30</lpage>.<pub-id pub-id-type="pmid">36927031</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ludwiczak</surname><given-names>J</given-names></string-name>, <string-name><surname>Winski</surname><given-names>A</given-names></string-name>, <string-name><surname>Szczepaniak</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal><article-title>DeepCoil: a fast and accurate prediction of coiled-coil domains in protein sequences</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>2790</fpage>–<lpage>5</lpage>.<pub-id pub-id-type="pmid">30601942</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lupas</surname><given-names>A</given-names></string-name>, <string-name><surname>Van Dyke</surname><given-names>M</given-names></string-name>, <string-name><surname>Stock</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Predicting coiled coils from protein sequences</article-title>. <source>Science</source><year>1991</year>;<volume>252</volume>:<fpage>1162</fpage>–<lpage>4</lpage>.<pub-id pub-id-type="pmid">2031185</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lupas</surname><given-names>AN</given-names></string-name>, <string-name><surname>Bassler</surname><given-names>J.</given-names></string-name></person-group><article-title>Coiled coils - a model system for the 21st century</article-title>. <source>Trends Biochem Sci</source><year>2017</year>;<volume>42</volume>:<fpage>130</fpage>–<lpage>40</lpage>.<pub-id pub-id-type="pmid">27884598</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B19">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lupas</surname><given-names>AN</given-names></string-name>, <string-name><surname>Gruber</surname><given-names>M.</given-names></string-name></person-group><part-title>The structure of α-helical coiled coils</part-title>. In: <source>Advances in Protein Chemistry: Fibrous Proteins: Coiled-Coils, Collagen and Elastomers</source>. <publisher-name>Academic Press</publisher-name>, <year>2005</year>, <fpage>37</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B20">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lupas</surname><given-names>AN</given-names></string-name>, <string-name><surname>Bassler</surname><given-names>J</given-names></string-name>, <string-name><surname>Dunin-Horkawicz</surname><given-names>S.</given-names></string-name></person-group> The Structure and Topology of α-Helical Coiled Coils. In: Parry, D., Squire, J. (eds) <source>Fibrous Proteins: Structures and Mechanisms. Subcellular Biochemistry</source>, vol 82. Springer, Cham. <pub-id pub-id-type="doi">10.1007/978-3-319-49674-0_4</pub-id>.</mixed-citation>
    </ref>
    <ref id="btad495-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Madeo</surname><given-names>G</given-names></string-name>, <string-name><surname>Savojardo</surname><given-names>C</given-names></string-name>, <string-name><surname>Martelli</surname><given-names>PL</given-names></string-name></person-group><etal>et al</etal><article-title>BetAware-Deep: an accurate web server for discrimination and topology prediction of prokaryotic transmembrane β-barrel proteins</article-title>. <source>J Mol Biol</source><year>2021</year>;<volume>433</volume>:<fpage>166729</fpage>.<pub-id pub-id-type="pmid">33972021</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mahrenholz</surname><given-names>CC</given-names></string-name>, <string-name><surname>Abfalter</surname><given-names>IG</given-names></string-name>, <string-name><surname>Bodenhofer</surname><given-names>U</given-names></string-name></person-group><etal>et al</etal><article-title>Complex networks govern coiled-coil oligomerization–predicting and profiling by means of a machine learning approach</article-title>. <source>Mol Cell Proteomics</source><year>2011</year>;<volume>10</volume>:<fpage>M110.004994</fpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manfredi</surname><given-names>M</given-names></string-name>, <string-name><surname>Savojardo</surname><given-names>C</given-names></string-name>, <string-name><surname>Martelli</surname><given-names>PL</given-names></string-name></person-group><etal>et al</etal><article-title>E-SNPs&amp;GO: embedding of protein sequence and function improves the annotation of human pathogenic variants</article-title>. <source>Bioinformatics</source><year>2022</year>;<volume>38</volume>:<fpage>5168</fpage>–<lpage>74</lpage>.<pub-id pub-id-type="pmid">36227117</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manfredi</surname><given-names>M</given-names></string-name>, <string-name><surname>Savojardo</surname><given-names>C</given-names></string-name>, <string-name><surname>Martelli</surname><given-names>PL</given-names></string-name></person-group><etal>et al</etal><article-title>ISPRED-SEQ: deep neural networks and embeddings for predicting interaction sites in protein sequences</article-title>. <source>J Mol Biol</source><year>2023</year>;<volume>435</volume>:<fpage>167963</fpage>.<pub-id pub-id-type="pmid">37356906</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Szczepaniak</surname><given-names>K</given-names></string-name>, <string-name><surname>Bukala</surname><given-names>A</given-names></string-name>, <string-name><surname>da Silva Neto</surname><given-names>AM</given-names></string-name></person-group><etal>et al</etal><article-title>A library of coiled-coil domains: from regular bundles to peculiar twists</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>5368</fpage>–<lpage>76</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Testa</surname><given-names>OD</given-names></string-name>, <string-name><surname>Moutevelis</surname><given-names>E</given-names></string-name>, <string-name><surname>Woolfson</surname><given-names>DN</given-names></string-name></person-group><etal>et al</etal><article-title>CC+: a relational database of coiled-coil structures</article-title>. <source>Nucleic Acids Res</source><year>2009</year>;<volume>37</volume>:<fpage>D315</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">18842638</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Trigg</surname><given-names>J</given-names></string-name>, <string-name><surname>Gutwin</surname><given-names>K</given-names></string-name>, <string-name><surname>Keating</surname><given-names>AE</given-names></string-name></person-group><etal>et al</etal><article-title>Multicoil2: predicting coiled coils and their oligomerization states from sequence in the twilight zone</article-title>. <source>PLoS One</source><year>2011</year>;<volume>6</volume>:<fpage>e23519</fpage>.<pub-id pub-id-type="pmid">21901122</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Truebestein</surname><given-names>L</given-names></string-name>, <string-name><surname>Leonard</surname><given-names>TA.</given-names></string-name></person-group><article-title>Coiled-coils: the long and short of it</article-title>. <source>Bioessays</source><year>2016</year>;<volume>38</volume>:<fpage>903</fpage>–<lpage>16</lpage>.<pub-id pub-id-type="pmid">27492088</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van der Maaten</surname><given-names>LJP</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>GE.</given-names></string-name></person-group><article-title>Visualizing data using t-SNE</article-title>. <source>J Mach Learn Res</source><year>2008</year>;<volume>9</volume>:<fpage>2579</fpage>–<lpage>605</lpage>.</mixed-citation>
    </ref>
    <ref id="btad495-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vincent</surname><given-names>TL</given-names></string-name>, <string-name><surname>Green</surname><given-names>PJ</given-names></string-name>, <string-name><surname>Woolfson</surname><given-names>DN</given-names></string-name></person-group><etal>et al</etal><article-title>LOGICOIL—multi-state prediction of coiled-coil oligomeric state</article-title>. <source>Bioinformatics</source><year>2013</year>;<volume>29</volume>:<fpage>69</fpage>–<lpage>76</lpage>.<pub-id pub-id-type="pmid">23129295</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walshaw</surname><given-names>J</given-names></string-name>, <string-name><surname>Woolfson</surname><given-names>DN.</given-names></string-name></person-group><article-title>Socket: a program for identifying and analysing coiled-coil motifs within protein structures</article-title>. <source>J Mol Biol</source><year>2001</year>;<volume>307</volume>:<fpage>1427</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">11292353</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname><given-names>IA</given-names></string-name>, <string-name><surname>Skehel</surname><given-names>JJ</given-names></string-name>, <string-name><surname>Wiley</surname><given-names>DC</given-names></string-name></person-group><etal>et al</etal><article-title>Structure of the haemagglutinin membrane glycoprotein of influenza virus at 3 a resolution</article-title>. <source>Nature</source><year>1981</year>;<volume>289</volume>:<fpage>366</fpage>–<lpage>73</lpage>.<pub-id pub-id-type="pmid">7464906</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Woolfson</surname><given-names>DN.</given-names></string-name></person-group><article-title>Understanding a protein fold: the physics, chemistry, and biology of α-helical coiled coils</article-title>. <source>J Biol Chem</source><year>2023</year>;<volume>299</volume>:<fpage>104579</fpage>.<pub-id pub-id-type="pmid">36871758</pub-id></mixed-citation>
    </ref>
    <ref id="btad495-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zemla</surname><given-names>A</given-names></string-name>, <string-name><surname>Venclovas</surname><given-names>C</given-names></string-name>, <string-name><surname>Fidelis</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal><article-title>A modified definition of SOV, a segment-based measure for protein secondary structure prediction assessment</article-title>. <source>Proteins</source><year>1999</year>;<volume>34</volume>:<fpage>220</fpage>–<lpage>3</lpage>.<pub-id pub-id-type="pmid">10022357</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
