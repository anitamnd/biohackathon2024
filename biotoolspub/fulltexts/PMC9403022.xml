<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_GPB551 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEgr5 jpg ?>
<?FILEgr6 jpg ?>
<?FILEmmc1 pptx ?>
<?FILEmmc2 docx ?>
<?FILEsi1 svg ?>
<?FILEsi2 svg ?>
<?FILEsi3 svg ?>
<?FILEsi4 svg ?>
<?FILEsi5 svg ?>
<?FILEsi6 svg ?>
<?FILEsi7 svg ?>
<?FILEsi8 svg ?>
<?FILEsi9 svg ?>
<?FILEsi10 svg ?>
<?FILEsi11 svg ?>
<?FILEsi12 svg ?>
<?FILEsi13 svg ?>
<?FILEsi14 svg ?>
<?FILEsi15 svg ?>
<?FILEsi16 svg ?>
<?FILEsi17 svg ?>
<?FILEsi18 svg ?>
<?FILEsi19 svg ?>
<?FILEsi20 svg ?>
<?FILEsi21 svg ?>
<?FILEsi22 svg ?>
<?FILEsi23 svg ?>
<?FILEsi24 svg ?>
<?FILEsi25 svg ?>
<?FILEsi26 svg ?>
<?FILEsi27 svg ?>
<?FILEsi28 svg ?>
<?FILEsi29 svg ?>
<?FILEsi30 svg ?>
<?FILEsi31 svg ?>
<?FILEsi32 svg ?>
<?FILEsi33 svg ?>
<?FILEsi34 svg ?>
<?FILEsi35 svg ?>
<?FILEsi36 svg ?>
<?FILEsi37 svg ?>
<?FILEsi38 svg ?>
<?FILEsi39 svg ?>
<?FILEsi40 svg ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Genomics Proteomics Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Genomics Proteomics Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Genomics, Proteomics &amp; Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1672-0229</issn>
    <issn pub-type="epub">2210-3244</issn>
    <publisher>
      <publisher-name>Elsevier</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9403022</article-id>
    <article-id pub-id-type="pii">S1672-0229(21)00152-2</article-id>
    <article-id pub-id-type="doi">10.1016/j.gpb.2020.06.026</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Application Note</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title><italic>BrcaSeg</italic>: A Deep Learning Approach for Tissue Quantification and Genomic Correlations of Histopathological Images</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au005">
        <name>
          <surname>Lu</surname>
          <given-names>Zixiao</given-names>
        </name>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="fn1" ref-type="fn">#</xref>
      </contrib>
      <contrib contrib-type="author" id="au010">
        <name>
          <surname>Zhan</surname>
          <given-names>Xiaohui</given-names>
        </name>
        <xref rid="af010" ref-type="aff">2</xref>
        <xref rid="af015" ref-type="aff">3</xref>
        <xref rid="fn1" ref-type="fn">#</xref>
      </contrib>
      <contrib contrib-type="author" id="au015">
        <name>
          <surname>Wu</surname>
          <given-names>Yi</given-names>
        </name>
        <xref rid="af015" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au020">
        <name>
          <surname>Cheng</surname>
          <given-names>Jun</given-names>
        </name>
        <xref rid="af010" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author" id="au025">
        <name>
          <surname>Shao</surname>
          <given-names>Wei</given-names>
        </name>
        <xref rid="af015" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au030">
        <name>
          <surname>Ni</surname>
          <given-names>Dong</given-names>
        </name>
        <xref rid="af010" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author" id="au035">
        <name>
          <surname>Han</surname>
          <given-names>Zhi</given-names>
        </name>
        <xref rid="af015" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au040">
        <name>
          <surname>Zhang</surname>
          <given-names>Jie</given-names>
        </name>
        <xref rid="af020" ref-type="aff">4</xref>
      </contrib>
      <contrib contrib-type="author" id="au045">
        <name>
          <surname>Feng</surname>
          <given-names>Qianjin</given-names>
        </name>
        <email>fengqj99@fimmu.com</email>
        <xref rid="af005" ref-type="aff">1</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <contrib contrib-type="author" id="au050">
        <name>
          <surname>Huang</surname>
          <given-names>Kun</given-names>
        </name>
        <email>kunhuang@iu.edu</email>
        <xref rid="af015" ref-type="aff">3</xref>
        <xref rid="af025" ref-type="aff">5</xref>
        <xref rid="af030" ref-type="aff">6</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <aff id="af005"><label>1</label>Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou 510515, China</aff>
      <aff id="af010"><label>2</label>National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen 518060, China</aff>
      <aff id="af015"><label>3</label>Department of Medicine, Indiana University School of Medicine, Indianapolis, IN 46202, USA</aff>
      <aff id="af020"><label>4</label>Department of Medical and Molecular Genetics, Indiana University School of Medicine, Indianapolis, IN 46202, USA</aff>
      <aff id="af025"><label>5</label>Department of Biostatistics and Health Data Science, Indiana University School of Medicine, Indianapolis, IN 46202, USA</aff>
      <aff id="af030"><label>6</label>Regenstrief Institute, Indianapolis, IN 46202, USA</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>⁎</label>Corresponding authors. <email>fengqj99@fimmu.com</email><email>kunhuang@iu.edu</email></corresp>
      <fn id="fn1">
        <label>#</label>
        <p id="np010">Equal contribution.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>17</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="ppub">
      <month>12</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>17</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <volume>19</volume>
    <issue>6</issue>
    <fpage>1032</fpage>
    <lpage>1042</lpage>
    <history>
      <date date-type="received">
        <day>14</day>
        <month>5</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>9</day>
        <month>12</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>9</day>
        <month>8</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2021 The Authors. Published by Elsevier B.V. and Science Press on behalf of Beijing Institute of Genomics, Chinese Academy of Sciences / China National Center for Bioinformation and Genetics Society of China.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder/>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="ab005">
      <p>Epithelial and stromal tissues are components of the tumor microenvironment and play a major role in tumor initiation and progression. Distinguishing stroma from epithelial tissues is critically important for spatial characterization of the tumor microenvironment. Here, we propose <italic>BrcaSeg</italic>, an image analysis pipeline based on a convolutional neural network (CNN) model to classify epithelial and stromal regions in whole-slide hematoxylin and eosin (H&amp;E) stained histopathological images. The CNN model is trained using well-annotated <bold>breast cancer</bold> tissue microarrays and validated with images from The Cancer Genome Atlas (TCGA) Program. <italic>BrcaSeg</italic> achieves a classification accuracy of 91.02%, which outperforms other state-of-the-art methods. Using this model, we generate pixel-level epithelial/stromal tissue maps for 1000 TCGA breast cancer slide images that are paired with gene expression data. We subsequently estimate the epithelial and stromal ratios and perform correlation analysis to model the relationship between gene expression and tissue ratios. Gene Ontology (GO) enrichment analyses of genes that are highly correlated with tissue ratios suggest that the same tissue is associated with similar biological processes in different breast cancer subtypes, whereas each subtype also has its own idiosyncratic biological processes governing the development of these tissues. Taken all together, our approach can lead to new insights in exploring relationships between image-based phenotypes and their underlying genomic events and biological processes for all types of solid tumors. <italic>BrcaSeg</italic> can be accessed at <ext-link ext-link-type="uri" xlink:href="https://github.com/Serian1992/ImgBio" id="ir005">https://github.com/Serian1992/ImgBio</ext-link>.</p>
    </abstract>
    <kwd-group id="kg005">
      <title>Keywords</title>
      <kwd>Whole-slide tissue image</kwd>
      <kwd>Computational pathology</kwd>
      <kwd>Deep learning</kwd>
      <kwd>Integrative genomics</kwd>
      <kwd>Breast cancer</kwd>
    </kwd-group>
  </article-meta>
  <notes>
    <p id="ms005">Handled by Xiangdong Fang</p>
  </notes>
</front>
<body>
  <sec id="s0005">
    <title>Introduction</title>
    <p id="p0005">Most solid tumors are composed of many tissue components such as cancer cells, stroma, and epithelium. The interaction of tissues within such complex neoplasms defines the tumor microenvironment that contributes to cancer initiation, progression, and therapeutic responses. For example, breast cancer epithelial cells of the mammary ducts are commonly the site of tumor initiation, while the stromal tissue dynamics drive invasion and metastasis <xref rid="b0005" ref-type="bibr">[1]</xref>. Tumor-to-stroma ratios of hematoxylin and eosin (H&amp;E) stained images are therefore an important prognostic factor <xref rid="b0010" ref-type="bibr">[2]</xref>, <xref rid="b0015" ref-type="bibr">[3]</xref>, and distinguishing stromal from epithelial tissue in histological images constitutes a basic but crucial task for cancer pathology. Classification methods (<italic>i.e.</italic>, pre-processing, training classifiers with carefully selected features, and patch-level classification) are the most commonly adopted automated computational methods for tissue segmentation <xref rid="b0020" ref-type="bibr">[4]</xref>, <xref rid="b0025" ref-type="bibr">[5]</xref>. For instance, Bunyak et al. <xref rid="b0030" ref-type="bibr">[6]</xref> combined traditional feature selection and classification methods to perform segmentation of epithelial and stromal tissues on a tissue microarray (TMA) database. While this approach is viable, it can be time-consuming and inefficient given the feature selection process. Recently, deep convolutional neural network (CNN) models have greatly boosted the performance of natural image analysis techniques such as image classification <xref rid="b0035" ref-type="bibr">[7]</xref>, object detection <xref rid="b0040" ref-type="bibr">[8]</xref>, and semantic segmentation <xref rid="b0045" ref-type="bibr">[9]</xref>, <xref rid="b0050" ref-type="bibr">[10]</xref>, and biomedical image analysis <xref rid="b0055" ref-type="bibr">[11]</xref>, <xref rid="b0060" ref-type="bibr">[12]</xref>, <xref rid="b0065" ref-type="bibr">[13]</xref>. Additionally, Ronneberger et al<italic>.</italic>
<xref rid="b0070" ref-type="bibr">[14]</xref> proposed implementation of a U-Net architecture to capture context and a symmetric expanding path that enables precise localization in biomedical image segmentation. Therefore, CNN models have the potential to improve the segmentation performance of epithelial and stromal regions <xref rid="b0055" ref-type="bibr">[11]</xref>, <xref rid="b0060" ref-type="bibr">[12]</xref>.</p>
    <p id="p0010">Despite breakthroughs in the application of CNN models to medical image analysis, automated classification of epithelial and stromal tissues in whole-slide tissue images (WSIs) remain challenging due to the large size of WSIs. WSIs often contain billions of pixels, and machine learning methods are limited by the technical hurdles of working with large datasets <xref rid="b0065" ref-type="bibr">[13]</xref>. Several solutions based on deep learning for classification of WSIs have been proposed. For instance, a context-aware stacked CNN was proposed for the classification of breast WSIs into multiple categories, such as normal/benign, ductal carcinoma <italic>in situ</italic>, and invasive ductal carcinoma <xref rid="b0075" ref-type="bibr">[15]</xref>. Saltz et al. <xref rid="b0080" ref-type="bibr">[16]</xref>, <xref rid="b0085" ref-type="bibr">[17]</xref> also presented a patch-based CNN to classify WSIs into glioma and non-small-cell lung carcinoma subtypes.</p>
    <p id="p0015">Additionally, commercial software has been developed to aid in quantitative and objective analyses of tissue WSIs. Among them is GENIE (Leica/Aperio), a tool with proprietary algorithms that incorporate deep learning. While many of its functionalities are designed to handle specific biomarkers using immunohistochemical (IHC) or fluorescent images, for H&amp;E images, tissue segmentation requires user-defined regions of interest (ROIs). Similarly, HALO (Indica Labs) and Visiopharm (Hoersholm) provide a toolbox for histopathological image analysis. The toolbox includes unsupervised algorithms for tissue segmentation that require manual configuration of parameters and usually underperform than supervised methods. The AQUA system (HistoRx) focuses on estimating tissue scores on TMA based on IHC staining by measuring protein expression within defined ROIs. Therefore, reliable systems that enable both fully-automatic tissue segmentation and quantified analysis for WSIs with H&amp;E staining are still in great demand.</p>
    <p id="p0020">In this work, we propose <italic>BrcaSeg,</italic> a WSI processing pipeline that utilizes deep learning to perform automatic segmentation and quantification of epithelial and stromal tissues for breast cancer WSIs from The Cancer Genome Atlas (TCGA). The TCGA data portal provides both clinical information and matched molecular data <xref rid="b0090" ref-type="bibr">[18]</xref>, <xref rid="b0095" ref-type="bibr">[19]</xref>. This offers the opportunity to identify relationships between computational histopathologic image features and the corresponding genomic information, which can greatly inform researcher regarding the molecular basis of tumor cell and tissue morphology <xref rid="b0100" ref-type="bibr">[20]</xref>, <xref rid="b0105" ref-type="bibr">[21]</xref>, <xref rid="b0110" ref-type="bibr">[22]</xref> including important biological processes such as cancer immunology <xref rid="b0085" ref-type="bibr">[17]</xref>.</p>
    <p id="p0025">To achieve our goal, we first trained a deep CNN model on the Stanford Tissue Microarray (sTMA) dataset in a 5-fold cross validation, and then validated the well-trained CNN model on 171 image patches that were randomly cropped from TCGA WSIs. Next, we successfully applied the <italic>BrcaSeg</italic> pipeline to process 1000 TCGA breast cancer WSIs to segment and quantify epithelial and stromal tissues. Spatial quantification and correlations with genomic data of both tissue types for three subtypes of breast cancer (<italic>i.e.</italic>, ER-positive, ER-negative, and triple-negative) were estimated based on the high-resolution global tissue segmentation maps. Gene Ontology (GO) enrichment can reveal whether these tissues are associated with similar biological processes in different breast cancer subtypes, whereas each subtype has its own idiosyncratic biological processes governing the development of tumor tissues. Our results are consistent with underlying biological processes for cancer development, which further affirms the robustness of our image processing method.</p>
    <p id="p0030">Spatial characterization of different tissues in histopathological images plays an important role in diagnosis and prognosis for cancers. However, human assessment of these features is time-consuming and often infeasible for large-scale studies. This study offers an innovative automated deep-learning analysis pipeline that enables rapid and accurate quantification of epithelial and stromal tissues from WSIs of cancer samples. Such approaches are important because they can be adopted to quantify tissue-level epithelial/stromal/cancer phenotypes, which in turn can be integrated with other biomedical data. For this reason, we also demonstrate how model-generated outputs can be correlated with gene expression data and how the results can lead to new insights about genetic mechanisms that contribute to tumor microenvironment heterogeneity in breast cancer. An important contribution of this study is that the approach, data, and demonstrated use of the novel <italic>BrcaSeg</italic> pipeline can be applied to other cancers for tissue quantification. To the best of our knowledge, this is the first study to provide pixel-level tissue segmentation maps of TCGA image data.</p>
  </sec>
  <sec id="s0010">
    <title>Method</title>
    <sec id="s0015">
      <title>Datasets</title>
      <p id="p0035">Two breast cancer image sets were used in this study: (1) TCGA breast cancer (TCGA-BRCA) data collection; and (2) the sTMA database <xref rid="b0010" ref-type="bibr">[2]</xref>. The sTMA database consists of 157 H&amp;E stained rectangular image regions (1128 × 720 pixels) digitized using 20× objective lens, which were acquired from two independent cohorts: 106 samples from Netherlands Cancer Institute (NKI) and 51 samples from Vancouver General Hospital (VGH). In each image in the sTMA dataset, epithelial and stromal tissues were manually annotated by pathologists. The TCGA cohort samples include matched H&amp;E stained WSIs, gene expression data, and clinical information. Patients with missing expression data or images with cryo-artifacts deemed too severe were excluded, leaving a selected set of 1000 samples. Since the TCGA clinical information includes subtyping information, we further categorized the selected samples into three breast cancer subtypes for more specific biological analysis: ER-positive, ER-negative, and triple-negative breast cancers. Sample information for both sTMA and TCGA-BRCA datasets are summarized in <xref rid="t0005" ref-type="table">Table 1</xref>.<table-wrap position="float" id="t0005"><label>Table 1</label><caption><p><bold>Sample information for image datasets used in this study</bold></p></caption><table frame="hsides" rules="groups"><thead><tr><th>Dataset</th><th>Subgroup</th><th>Image type</th><th>No. of images in each subgroup</th><th>No. of images in each cohort</th></tr></thead><tbody><tr><td rowspan="2">sTMA</td><td>NKI</td><td rowspan="2">H&amp;E stained image region (1128 × 720 pixels)</td><td>106</td><td rowspan="2">157</td></tr><tr><td>VGH</td><td>51</td></tr><tr><td colspan="5">  </td></tr><tr><td rowspan="3">TCGA-BRCA</td><td>ER-positive</td><td rowspan="3">WSI</td><td>773</td><td rowspan="3">1000</td></tr><tr><td>ER-negative</td><td>227</td></tr><tr><td>Triple-negative</td><td>112</td></tr></tbody></table><table-wrap-foot><fn><p><italic>Note</italic>: For TCGA cohort, samples in triple-negative subgroup also belong to ER-negative subgroup. sTMA, Stanford Tissue Microarray; TCGA-BRCA, The Cancer Genome Atlas breast cancer data collection; NKI, Netherlands Cancer Institute; VGH, Vancouver General Hospital; WSI, whole-slide tissue image.</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="s0020">
      <title>Overview of the workflow</title>
      <p id="p0040"><xref rid="f0005" ref-type="fig">Figure 1</xref> shows the detailed structure of <italic>BrcaSeg</italic> for tissue segmentation. <xref rid="f0010" ref-type="fig">Figure 2</xref>A shows the WSI processing part of <italic>BrcaSeg</italic>. <xref rid="f0010" ref-type="fig">Figure 2</xref>B shows an overview of the biological analysis of gene expression data and image features. Details of each part are described in the following subsections.<fig id="f0005"><label>Figure 1</label><caption><p><bold>The deep CNN model in <italic>BrcaSeg</italic> workflow for tissue segmentation</bold></p><p>Shown in the scheme is the detailed structure of our deep CNN model in <italic>BrcaSeg</italic> workflow for segmentation of epithelial and stromal tissues in H&amp;E stained breast cancer histopathological images. DC, dilated convolution; DR, dilation rate; MC, multi-channel convolution; CNN, convolutional neural network; H&amp;E, hematoxylin and eosin.</p></caption><graphic xlink:href="gr1"/></fig><fig id="f0010"><label>Figure 2</label><caption><p><bold>The <italic>BrcaSeg</italic> workflow for WSI processing and biological analysis</bold></p><p><bold>A.</bold> The pipeline for processing H&amp;E stained breast cancer WSIs. <bold>B.</bold> Overview of biological analysis of gene expression data and image features. WSI, whole-slide tissue image.</p></caption><graphic xlink:href="gr2"/></fig></p>
    </sec>
    <sec id="s0025">
      <title>CNN model for tissue segmentation</title>
      <p id="p0045">Given an RGB image of height <inline-formula><mml:math id="M1" altimg="si4.svg"><mml:mi>H</mml:mi></mml:math></inline-formula>, width <inline-formula><mml:math id="M2" altimg="si5.svg"><mml:mi>W</mml:mi></mml:math></inline-formula>, with <inline-formula><mml:math id="M3" altimg="si6.svg"><mml:mi>C</mml:mi></mml:math></inline-formula> color channels, the goal of segmentation is to predict a label map with size <inline-formula><mml:math id="M4" altimg="si7.svg"><mml:mrow><mml:mi>H</mml:mi><mml:mo>×</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:math></inline-formula> where each pixel is labeled with a category. CNN-based framework for segmentation essentially consists of an encoding and decoding counterparts.</p>
      <p id="p0050">The encoding block is derived from classification models, which performs downsampling operators to capture global information from input images. Max-pooling is the most commonly adopted operation in encoding, which integrates neighbouring pixels to learn invariance from local image transformation. More recently, dilated convolution was proposed to control spatial resolution, thus enabling dense feature extraction. Given a 1-dimensional input signal <inline-formula><mml:math id="M5" altimg="si8.svg"><mml:mrow><mml:mi>x</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> with a filter <inline-formula><mml:math id="M6" altimg="si9.svg"><mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> of length <inline-formula><mml:math id="M7" altimg="si10.svg"><mml:mi>K</mml:mi></mml:math></inline-formula>, the output of dilated convolution is defined as:<disp-formula id="e0005"><label>(1)</label><mml:math id="M8" altimg="si11.svg"><mml:mrow><mml:mi>y</mml:mi><mml:mfenced open="[" close="]"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced><mml:mo linebreak="goodbreak">=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mi>x</mml:mi><mml:mfenced open="[" close="]"><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>r</mml:mi><mml:mo>∙</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfenced><mml:mi>w</mml:mi><mml:mfenced open="[" close="]"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="M9" altimg="si12.svg"><mml:mi>r</mml:mi></mml:math></inline-formula> is the stride in the sampling input signal, referred to as <inline-formula><mml:math id="M10" altimg="si13.svg"><mml:mrow><mml:mi mathvariant="italic">rate</mml:mi></mml:mrow></mml:math></inline-formula>. By filling zeros between pixels in the filter, dilated convolution can enlarge receptive fields without substantially increasing computational cost.</p>
      <p id="p0055">We carefully constructed our deep hierarchical segmentation model using specific strategies in both encoder and decoder, as shown in <xref rid="f0005" ref-type="fig">Figure 1</xref>. The ResNet-101 structure <xref rid="b0035" ref-type="bibr">[7]</xref>, which contains 101 convolution layers, was adopted as the backbone of our proposed model. Since dilated convolution inserts zeros between pixels in the filter, it can enlarge receptive fields without substantially increasing computational cost. The encoder of <italic>BrcaSeg</italic> inherited the first three blocks of ResNet-101, while the rest was modified into six dilated convolution blocks, each of which further contained four ResUnits with different dilation rates. This configuration was inspired by the success of the atrous spatial pyramid pooling (DeepLab-ASPP) approach from Chen and colleagues <xref rid="b0050" ref-type="bibr">[10]</xref>, which captures objects as well as image context at multiple scales, and thus robustly improves the segmentation performance. In our work, the modification of convolution layers was carried out to ensure that our encoder learned both tissue structures and contextual information for the next phase of processing. In the decoding step, we adopted a multi-channel convolution approach to generate high-resolution segmentation maps. Given a feature map of dimension <inline-formula><mml:math id="M11" altimg="si14.svg"><mml:mrow><mml:mi>h</mml:mi><mml:mo>×</mml:mo><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:math></inline-formula>, multi-channel convolution first generated features of <inline-formula><mml:math id="M12" altimg="si15.svg"><mml:mrow><mml:mi>h</mml:mi><mml:mo>×</mml:mo><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>×</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="M13" altimg="si12.svg"><mml:mi>r</mml:mi></mml:math></inline-formula> is the upsampling rate. Then the features were reshaped to obtain upsampled features of <inline-formula><mml:math id="M14" altimg="si16.svg"><mml:mrow><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>×</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="M15" altimg="si17.svg"><mml:mrow><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>h</mml:mi><mml:mo>×</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.333333em"/><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:math></inline-formula>. To this end, we stretched each individual pixel in the small feature map to the channel of <inline-formula><mml:math id="M16" altimg="si18.svg"><mml:mrow><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>×</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:math></inline-formula>, so that it corresponded to a fixed area (<inline-formula><mml:math id="M17" altimg="si19.svg"><mml:mrow><mml:mi>r</mml:mi><mml:mo>×</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:math></inline-formula>) in the upsampled output map. We applied four parallel dilated multi-channel convolutions with a range of dilation rates and added all of their outputs pixel by pixel in order to further exploit multi-scale contextual information from the encoding feature map.</p>
      <p id="p0060">We next used the sTMA dataset to train our CNN model in a 5-fold cross validation. The proposed model was implemented using the MXNet toolbox. Parameters in the encoder were initialized with pre-trained weights from Deep-Lab V2 <xref rid="b0050" ref-type="bibr">[10]</xref>, while the decoder layers were randomly initialized by Xavier method. Due to GPU memory limitations (8 GB for GeForce GTX 1080), we randomly cropped <inline-formula><mml:math id="M18" altimg="si20.svg"><mml:mrow><mml:mn>600</mml:mn><mml:mo>×</mml:mo><mml:mn>600</mml:mn></mml:mrow></mml:math></inline-formula> patches from the raw images, and performed random mirror and random crop as data augmentation in the training stage.</p>
    </sec>
    <sec id="s0030">
      <title>WSI processing pipeline</title>
      <p id="p0065">During examination of histopathology slide of a tumor sample, pathologists often search for a ROI that contains cancer cells and conduct diagnostic assessment. Inspired by these human analysis steps, we built an automatic pipeline to perform tissue segmentation on WSIs, as shown in <xref rid="f0010" ref-type="fig">Figure 2</xref>A. Our WSI processing pipeline in <italic>BrcaSeg</italic> consists of two parts: (1) automatic identification of ROIs, and (2) epithelial and stromal tissue segmentation on the ROIs. Given a WSI <inline-formula><mml:math id="M19" altimg="si21.svg"><mml:mrow><mml:mi>I</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> we first downsampled <inline-formula><mml:math id="M20" altimg="si22.svg"><mml:mi>I</mml:mi></mml:math></inline-formula> into <inline-formula><mml:math id="M21" altimg="si23.svg"><mml:msup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> at a factor of 16 in both horizontal and vertical directions. Then we converted <inline-formula><mml:math id="M22" altimg="si23.svg"><mml:msup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> from RGB color space to CIELAB color space (<inline-formula><mml:math id="M23" altimg="si24.svg"><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>), denoted as <inline-formula><mml:math id="M24" altimg="si25.svg"><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi mathvariant="italic">lab</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula>. Since the <inline-formula><mml:math id="M25" altimg="si26.svg"><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> channel in <inline-formula><mml:math id="M26" altimg="si24.svg"><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> color space represents the brightness, we extracted the <inline-formula><mml:math id="M27" altimg="si27.svg"><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="M28" altimg="si28.svg"><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> values representing color components in <inline-formula><mml:math id="M29" altimg="si25.svg"><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi mathvariant="italic">lab</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> and obtained a new image <inline-formula><mml:math id="M30" altimg="si29.svg"><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi mathvariant="italic">ab</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula>. Each pixel in <inline-formula><mml:math id="M31" altimg="si29.svg"><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi mathvariant="italic">ab</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> is then represented as a 2-dimentional vector. Next, we applied K-means clustering algorithm (<italic>K</italic> = 2) to divide the pixels of <inline-formula><mml:math id="M32" altimg="si29.svg"><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi mathvariant="italic">ab</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> into two groups. Considering that corners of pathology images are usually unstained, we classified pixels in the same cluster as the upper-left pixel in <inline-formula><mml:math id="M33" altimg="si29.svg"><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi mathvariant="italic">ab</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> as background, while the other pixels were classified as foreground. In this way, we generated a binary mask <inline-formula><mml:math id="M34" altimg="si30.svg"><mml:msup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msup></mml:math></inline-formula>, where 0 and 1 in <inline-formula><mml:math id="M35" altimg="si30.svg"><mml:msup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msup></mml:math></inline-formula> correspond to background and foreground pixels in <inline-formula><mml:math id="M36" altimg="si29.svg"><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi mathvariant="italic">ab</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula>, respectively. Denoting the smallest rectangle region that contains the largest connected component in <inline-formula><mml:math id="M37" altimg="si30.svg"><mml:msup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msup></mml:math></inline-formula> as <inline-formula><mml:math id="M38" altimg="si31.svg"><mml:msub><mml:mi>F</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>, we identified the ROI <inline-formula><mml:math id="M39" altimg="si32.svg"><mml:msub><mml:mi>F</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula> by mapping the coordinates of <inline-formula><mml:math id="M40" altimg="si31.svg"><mml:msub><mml:mi>F</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula> onto <inline-formula><mml:math id="M41" altimg="si22.svg"><mml:mi>I</mml:mi></mml:math></inline-formula>. Finally, <inline-formula><mml:math id="M42" altimg="si32.svg"><mml:msub><mml:mi>F</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula> was cropped from <inline-formula><mml:math id="M43" altimg="si22.svg"><mml:mi>I</mml:mi></mml:math></inline-formula> for downstream processing.</p>
      <p id="p0070">We split <inline-formula><mml:math id="M44" altimg="si32.svg"><mml:msub><mml:mi>F</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula> into patches of 1128 × 720 pixels to fully utilize the proposed CNN model for tissue segmentation. Patches with more than 80% background were discarded. The retained patches were then fed into the CNN model, and all the patch-level predictions were combined to generate a global tissue mask <inline-formula><mml:math id="M45" altimg="si33.svg"><mml:msup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> for <inline-formula><mml:math id="M46" altimg="si32.svg"><mml:msub><mml:mi>F</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula>.</p>
    </sec>
    <sec id="s0035">
      <title>Tissue quantification and biological analysis</title>
      <p id="p0075">We applied the <italic>BrcaSeg</italic> pipeline on 1000 TCGA breast cancer WSIs for further biological analysis, as shown in <xref rid="f0010" ref-type="fig">Figure 2</xref>B. For each WSI <inline-formula><mml:math id="M47" altimg="si22.svg"><mml:mi>I</mml:mi></mml:math></inline-formula>, we performed tissue spatial quantification based on its tissue mask <inline-formula><mml:math id="M48" altimg="si33.svg"><mml:msup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> derived from our method. The two tissue ratios, <inline-formula><mml:math id="M49" altimg="si1.svg"><mml:msub><mml:mrow><mml:mi mathvariant="italic">Ratio</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">epi</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M50" altimg="si34.svg"><mml:msub><mml:mrow><mml:mi mathvariant="italic">Ratio</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">stro</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, which characterize the ratio of epithelial tissue areas and stromal tissue areas to overall tissue areas are respectively estimated as:<disp-formula id="e0010"><label>(2)</label><mml:math id="M51" altimg="si35.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="italic">Ratio</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">epi</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>E</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:msub><mml:mrow><mml:mspace width="0.333333em"/><mml:mi>R</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">stro</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="M52" altimg="si36.svg"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="M53" altimg="si37.svg"><mml:msub><mml:mi>E</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="M54" altimg="si38.svg"><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> represent the number of pixels classified as foreground, epithelial, and stromal in the <inline-formula><mml:math id="M55" altimg="si39.svg"><mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:math></inline-formula> valid patch in <inline-formula><mml:math id="M56" altimg="si32.svg"><mml:msub><mml:mi>F</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula>, respectively, and <inline-formula><mml:math id="M57" altimg="si40.svg"><mml:mi>N</mml:mi></mml:math></inline-formula> represents the total number of valid patches in <inline-formula><mml:math id="M58" altimg="si32.svg"><mml:msub><mml:mi>F</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula>.</p>
      <p id="p0080">To explore the relationships between gene expression data and tissue ratios in different breast cancer subtypes, we divided all the selected TCGA breast cancer samples into three types: ER-positive, ER-negative, and triple-negative, as shown in <xref rid="t0005" ref-type="table">Table 1</xref>. Then, we computed the Spearman correlation coefficients between gene expression data and the two tissue ratios <inline-formula><mml:math id="M59" altimg="si1.svg"><mml:msub><mml:mrow><mml:mi mathvariant="italic">Ratio</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">epi</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M60" altimg="si34.svg"><mml:msub><mml:mrow><mml:mi mathvariant="italic">Ratio</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">stro</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for each breast cancer subtype. Next, we sorted all the Spearman correlation coefficients, and selected the gene symbols that were in the top 1% of Spearman correlation coefficients with <inline-formula><mml:math id="M61" altimg="si1.svg"><mml:msub><mml:mrow><mml:mi mathvariant="italic">Ratio</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">epi</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M62" altimg="si34.svg"><mml:msub><mml:mrow><mml:mi mathvariant="italic">Ratio</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">stro</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for each breast cancer subtype. For the selected genes, we performed GO enrichment analysis using WebGestalt <xref rid="b0115" ref-type="bibr">[23]</xref>. The Overrepresentation Enrichment Analysis (ORA) with Bonferroni adjustment was used to determine statistical significance of the enrichment. Genes presented by the “Genome” platform were used as the reference genes. Finally, the top 10 enriched biological process categories were selected to further examine the biological processes underlying the development of epithelial and stromal tissues for each breast cancer subtype.</p>
    </sec>
  </sec>
  <sec id="s0040">
    <title>Results</title>
    <sec id="s0045">
      <title>Validation of CNN model</title>
      <p id="p0085">We evaluated our proposed deep CNN model on segmentation of epithelial and stromal tissues by comparing <italic>BrcaSeg</italic> with several state-of-the-art methods <xref rid="b0055" ref-type="bibr">[11]</xref>, <xref rid="b0060" ref-type="bibr">[12]</xref>, <xref rid="b0120" ref-type="bibr">[24]</xref>, <xref rid="b0125" ref-type="bibr">[25]</xref>. <italic>BrcaSeg</italic> outperformed all of these methods in terms of classification accuracies and achieved an average accuracy of 91.02% on the entire sTMA dataset (NKI + VGH), as shown in <xref rid="t0010" ref-type="table">Table 2</xref> and <xref rid="t0015" ref-type="table">Table 3</xref>. Visual inspection of the segmentation results also demonstrated that <italic>BrcaSeg</italic> can accurately classify epithelial and stromal tissues (<xref rid="f0015" ref-type="fig">Figure 3</xref>). Note that in the ground truth data, some areas belonging to epithelia have been overlooked and incorrectly annotated as background (an example is shown in the third row of <xref rid="f0015" ref-type="fig">Figure 3</xref>). However, <italic>BrcaSeg</italic> still generated correct predictions for this area (marked by a black circle in <xref rid="f0015" ref-type="fig">Figure 3</xref>). This indicates that <italic>BrcaSeg</italic> is robust enough to make the right judgment, even under partially misleading supervision. We believe this is valuable for future work in biomedical image tasks with only partial or inaccurate annotations.<table-wrap position="float" id="t0010"><label>Table 2</label><caption><p><bold>Performance evaluation of the CNN model in <italic>BrcaSeg</italic> on NKI and VGH cohorts</bold></p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Cohort</th><th rowspan="2">Model</th><th colspan="10">Evaluation metric<hr/></th></tr><tr><th>TPR</th><th>TNR</th><th>PPV</th><th>NPV</th><th>FPR</th><th>FDR</th><th>FNR</th><th>ACC</th><th>F1 score</th><th>MCC</th></tr></thead><tbody><tr><td>NKI</td><td>Xu et al. <xref rid="b0060" ref-type="bibr">[12]</xref></td><td align="char">86.31</td><td align="char">82.15</td><td align="char">84.11</td><td align="char">84.60</td><td align="char">17.85</td><td align="char">15.89</td><td align="char">13.66</td><td align="char">84.34</td><td align="char">85.21</td><td align="char">68.60</td></tr><tr><td/><td>CNN only <xref rid="b0055" ref-type="bibr">[11]</xref></td><td align="char">81.34</td><td align="char">82.89</td><td align="char">84.11</td><td align="char">80.05</td><td align="char">17.11</td><td align="char">15.89</td><td align="char">18.57</td><td align="char">81.69</td><td align="char">82.75</td><td align="char">64.24</td></tr><tr><td/><td>CNN + HFCM <xref rid="b0055" ref-type="bibr">[11]</xref></td><td align="char">89.48</td><td align="char">85.96</td><td align="char">85.94</td><td align="char">89.50</td><td align="char">14.04</td><td align="char">14.06</td><td align="char">10.52</td><td align="char">87.19</td><td align="char">87.68</td><td align="char">75.44</td></tr><tr><td/><td><italic>BrcaSeg</italic></td><td align="char"><bold>90.71</bold></td><td align="char"><bold>89.83</bold></td><td align="char"><bold>90.81</bold></td><td align="char"><bold>89.72</bold></td><td align="char"><bold>10.17</bold></td><td align="char"><bold>9.19</bold></td><td align="char"><bold>9.29</bold></td><td align="char"><bold>90.29</bold></td><td align="char"><bold>90.76</bold></td><td align="char"><bold>80.54</bold></td></tr><tr><td colspan="12">  </td></tr><tr><td>VGH</td><td>Xu et al. <xref rid="b0060" ref-type="bibr">[12]</xref></td><td align="char">88.29</td><td align="char">88.40</td><td align="char">89.93</td><td align="char">86.55</td><td align="char">11.60</td><td align="char">10.07</td><td align="char">11.71</td><td align="char">88.34</td><td align="char">89.10</td><td align="char">76.59</td></tr><tr><td/><td>CNN only <xref rid="b0055" ref-type="bibr">[11]</xref></td><td align="char">90.32</td><td align="char">88.15</td><td align="char">92.98</td><td align="char">83.97</td><td align="char">11.85</td><td align="char">7.02</td><td align="char">9.68</td><td align="char">89.14</td><td align="char">91.63</td><td align="char">77.70</td></tr><tr><td/><td>CNN + HFCM <xref rid="b0055" ref-type="bibr">[11]</xref></td><td align="char"><bold>91.96</bold></td><td align="char"><bold>92.21</bold></td><td align="char"><bold>95.45</bold></td><td align="char">86.59</td><td align="char"><bold>7.79</bold></td><td align="char"><bold>4.55</bold></td><td align="char"><bold>8.04</bold></td><td align="char">91.04</td><td align="char"><bold>93.67</bold></td><td align="char"><bold>83.10</bold></td></tr><tr><td/><td><italic>BrcaSeg</italic></td><td align="char">91.37</td><td align="char">91.49</td><td align="char">92.37</td><td align="char"><bold>90.38</bold></td><td align="char">8.51</td><td align="char">7.63</td><td align="char">8.63</td><td align="char"><bold>91.42</bold></td><td align="char">91.87</td><td align="char">82.80</td></tr></tbody></table><table-wrap-foot><fn><p><italic>Note</italic>: Value in bold represents the best performance result under each metric among different models. TPR = TP/(TP + FN); TNR = TN/(FP + TN); PPV = TP/(TP + FP); NPV = TN/(FN + TN); FPR = FP/(FP + TN); FDR = 1 − TP/(TP + FP); FNR = FN/(FN + TP); ACC = (TP + TN)/(TP + FP + TN + FN); F1 score = 2 × TP/(2 × TP + FP + FN); MCC = (TP  × TN − FP  × FN)/<inline-formula><mml:math id="M63" altimg="si3.svg"><mml:msqrt><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="0.166667em"/></mml:mrow></mml:msqrt></mml:math></inline-formula>. TPR, true positive rate; TNR, true negative rate; PPV, positive predictive value; NPV, negative predictive value; FPR, false positive rate; FDR, false discovery rate; FNR, false negative rate; ACC, accuracy; MCC, Matthews correlation coefficient; TP, true positive; FP, false positive; TN, true negative; FN, false negative.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="t0015"><label>Table 3</label><caption><p><bold>Quantitative performance evaluation of <italic>BrcaSeg</italic> on the whole sTMA dataset</bold></p></caption><table frame="hsides" rules="groups"><thead><tr><th>Dataset</th><th>Model</th><th>ACC</th><th>F1 score</th></tr></thead><tbody><tr><td>NKI + VGH</td><td>Du et al. <xref rid="b0120" ref-type="bibr">[24]</xref></td><td align="char">89.7</td><td align="char">89.7</td></tr><tr><td/><td>Vu et al. <xref rid="b0125" ref-type="bibr">[25]</xref></td><td align="char">90.315</td><td align="char">90.51</td></tr><tr><td/><td><italic>BrcaSeg</italic></td><td align="char">91.02</td><td align="char">91.59</td></tr></tbody></table></table-wrap><fig id="f0015"><label>Figure 3</label><caption><p><bold>Qualitative segmentation results for <italic>BrcaSeg</italic> on sTMA dataset</bold></p><p>Three segmentation examples on the sTMA dataset are provided, including Example 1 (<bold>A</bold>), Example 2 (<bold>B</bold>), and Example 3 (<bold>C</bold>). Raw images are shown on the left; image annotations by pathologists are shown in the middle; and image predictions using <italic>BrcaSeg</italic> are shown on the right. Areas in red, green, and black in annotations and predictions represent epithelial, stromal, and background regions in raw images, respectively. Black circle in Example 3 indicates the overlooked tumor area that is accurately recognized by <italic>BrcaSeg</italic>. sTMA, Stanford Tissue Microarray.</p></caption><graphic xlink:href="gr3"/></fig></p>
    </sec>
    <sec id="s0050">
      <title>Tissue segmentation and quantification on WSIs</title>
      <p id="p0090">To evaluate the effectiveness of our proposed deep CNN model in <italic>BrcaSeg</italic> on TCGA dataset, we randomly selected 171 large image patches with size of 2256 × 2280 pixels, each from the TCGA breast cancer WSIs. We also invited two domain experts to manually annotate the epithelial and stromal tissues on these patches as ground truth. Without any additional training, we applied <italic>BrcaSeg</italic> on these selected large image patches, and compared our segmentation results with the ground truth for evaluation. The validation results suggest that <italic>BrcaSeg</italic> is robust enough to predict credible tissue mask for the TCGA breast cancer dataset based on the quantitative results reported in <xref rid="s0085" ref-type="sec">Table S1</xref> and <xref rid="s0085" ref-type="sec">Figure S1</xref>. We then applied the trained <italic>BrcaSeg</italic> model to the tissue segmentation of 1000 WSIs from three TCGA breast cancer subtypes. Visual results showed that <italic>BrcaSeg</italic> can robustly identify epithelial/stromal tissues in whole-slide images (<xref rid="f0020" ref-type="fig">Figure 4</xref>).<fig id="f0020"><label>Figure 4</label><caption><p><bold>Examples of qualitative segmentation results for <italic>BrcaSeg</italic> on three selected TCGA breast cancer WSIs</bold></p><p>Three segmentation examples of TCGA breast cancer WSIs are provided, including Example 1 (<bold>A</bold>), Example 2 (<bold>B</bold>), and Example 3 (<bold>C</bold>), which have different values of <inline-formula><mml:math id="M64" altimg="si1.svg"><mml:msub><mml:mrow><mml:mi mathvariant="italic">Ratio</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">epi</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. For each TCGA-BRCA WSI, step 1 represents the WSI; step 2 represents the background map of WSI; step 3 represents the ROI in the WSI of raw image; and step 4 represents the tissue segmentation result of ROI. Areas in red, green, and black in step 4 represent the predicted epithelial, stromal, and background regions, respectively. TCGA, The Cancer Genome Atlas; ROI, region of interest.</p></caption><graphic xlink:href="gr4"/></fig></p>
      <p id="p0095">Ratios of epithelial and stromal tissue areas to overall tissue areas were estimated based on the WSI segmentation results. Wide differences in tissue ratios were observed among different breast cancer subtypes (<xref rid="f0025" ref-type="fig">Figure 5</xref>). ER-positive images were predominantly enriched with stromal tissues with a mean stromal ratio of 72.8%, while triple-negative images were abundant in epithelial tissues with a mean epithelial ratio of 63.56%. Epithelial and stromal tissues were nearly equivalent for ER-negative images with mean ratios of 49.35% and 50.65%, respectively.<fig id="f0025"><label>Figure 5</label><caption><p><bold>Distribution of tissues in different breast cancer subtypes</bold></p><p>Epithelial ratio (red) and stromal ratio (blue) represent the ratios of epithelial tissue areas and stromal tissue areas to overall tissue areas, respectively.</p></caption><graphic xlink:href="gr5"/></fig></p>
    </sec>
    <sec id="s0055">
      <title>Tissue-specific functional analysis</title>
      <p id="p0100">We further explored which genes are associated with the development of different tissues in various subtypes of breast cancers by computing pairwise Spearman correlation coefficients between gene expression data and both tissue ratios. Genes in the top 1% of correlation with tissue ratios in each subtype of breast cancer were selected for further analysis. We then performed functional GO analysis for the selected gene-sets. Genes correlated with the epithelial tissues were highly enriched in biological processes related to cell cycle, among which sister chromatid segregation, nuclear division, and mitotic cell cycle are the most commonly enriched GO terms shared by the three breast cancer subtypes. However, we also observed specifically enriched GO terms and genes for each subtype that correspond to different cell cycle stages. The Growth phase-related genes including G1 phase and G2 phase were specifically enriched for the ER-positive subtype, the Mitotic (M) phase-related genes were specifically enriched for the triple-negative subtype, and the Synthesis (S) phase-related genes were specific for the ER-negative subtype.</p>
      <p id="p0105">Similarly, such patterns of shared high-level biological processes with specific functions were also observed for the stromal tissues. For the stromal tissue, the most significantly enriched GO biological process terms were all related to the development of the tumor microenvironment, including vasculature development, cellular component movement, and growth factor stimuli-related GO functions which were shared among the three breast cancer subtypes. For the ER-positive subtype, angiogenesis-related genes were specifically enriched, while for the triple-negative subtype, muscle structure-related genes (especially the ones related to actin fibers and cytoskeleton) were specifically enriched. In addition, for the ER-negative subtype, growth factor genes were enriched. Altogether, our results (<xref rid="f0030" ref-type="fig">Figure 6</xref>) suggest that even though the same tissue was associated with similar biological processes in different subtypes, each subtype still had its idiosyncratic biological processes governing the development of these tissues.<fig id="f0030"><label>Figure 6</label><caption><p><bold>Enrichment of GO biological process terms for genes correlated with epithelial and stromal ratios in different breast cancer subtypes</bold></p><p>Dots represent the most significantly enriched GO biological process terms for each cancer subtype. Sizes of dots represent the ratio of enrichment (GO category). <italic>P</italic> values are adjusted with FDR for multiple comparison correction and coded in color gradient (purple for small values and red for large values).</p></caption><graphic xlink:href="gr6"/></fig></p>
    </sec>
  </sec>
  <sec id="s0060">
    <title>Discussion</title>
    <p id="p0110">Identification and spatial characterizations of epithelial and stromal regions in histopathological images of tumors play crucial roles in cancer diagnosis, prognosis, and treatment. Recently, some studies have focused on developing systems for automatically analyzing H&amp;E stained histological images from tissue microarrays in order to predict prognosis <xref rid="b0130" ref-type="bibr">[26]</xref>, <xref rid="b0135" ref-type="bibr">[27]</xref>. In contrast, our approach is aimed at WSIs rather than manually extracted regions since WSI provides much more comprehensive characterization of tumor tissue heterogeneity. Mackie et al. <xref rid="b0140" ref-type="bibr">[28]</xref> summarized the research progress and challenges facing the application of big data quantitative imaging to cancer treatment, focusing on 3D imaging modalities including CT, PET, and MRI. Our quantitative analysis of histopathological images complements and extends this work in terms of data modality and size, application areas, and computational challenges.</p>
    <p id="p0115">Based on our global tissue quantification, distinct differences were observed in the enriched GO terms for epithelial and stromal tissues <xref rid="b0145" ref-type="bibr">[29]</xref>. At the same time, highly overlapping biological properties were observed in the same tissue across different subtypes, all of which were tied to cancer progression in one way or another. For example, for the epithelial tissue, genes involved in cell cycle-related processes were significantly enriched. Previous studies have addressed that sustaining proliferative signaling is one of the hallmarks of cancer, during which cell cycle is the essential process <xref rid="b0150" ref-type="bibr">[30]</xref>. In addition, <italic>CDK4/6</italic> inhibitors (such as palbociclib and ribociclib) target this biological process <xref rid="b0155" ref-type="bibr">[31]</xref>, <xref rid="b0160" ref-type="bibr">[32]</xref>. For stromal tissue, genes related to the tumor microenvironment were significantly enriched (<italic>e.g.</italic>, vasculature and locomotion). Vasculature is vital for inducing angiogenesis, which is another important hallmark of cancer.</p>
    <p id="p0120">Additionally, we observed differences in biological processes between different subtypes resulting from tumor heterogeneity. Specific biological processes for each subtype were also identified for the same tissue. For the epithelial tissue, genes associated with different stages of the cell cycle were specifically enriched for different subtypes. For ER-positive breast epithelia, we found that G1 and G2 phase-related GO terms were enriched, among which G2/M transition is an important element. Wang et al. <xref rid="b0135" ref-type="bibr">[27]</xref> have highlighted the importance of G2/M transition in ER-positive breast cancer. For the triple-negative subtype of breast cancers, we found that M phase-related GO terms were enriched, during which chromosome segregation plays a key role. Witkiewicet et al. <xref rid="b0165" ref-type="bibr">[33]</xref> have shown the close relationship between chromosome segregation (<italic>PLK1</italic>) with triple-negative breast cancer. Similarly, angiogenesis-related biological processes were significantly associated with the stroma of the ER-positive subtype. Previous studies have indicated that vasculature is one of the important components for tumor stroma <xref rid="b0170" ref-type="bibr">[34]</xref>, as stromal cells can build blood vessels to supply oxygen and nutrients <xref rid="b0175" ref-type="bibr">[35]</xref>.</p>
    <p id="p0125">While the correlation analysis of this study reveals clear pairwise relationships between morphological and genomic features, there are two major limitations to our approach. First, correlation cannot reveal highly nonlinear relationships or multivariate complication relationships. For instance, Wang et al. <xref rid="b0180" ref-type="bibr">[36]</xref> demonstrated that complicated morphological features might need to be modeled using multiple genomic features, implying contributions from multiple genetic factors. Similarly, with our data, more sophisticated analysis such as nonlinear correlation analysis can be applied to reveal deeper relationships. Secondly, correlation is not causation. The genes that are strongly correlated with the stromal or epithelial content may not be the underlying driver genes for the development of the tissues. Identification of such key genes requires further incorporation of biological knowledge, as well as future experimental validation.</p>
    <p id="p0130">In summary, our framework provides not only fully automatic and detailed analysis for large H&amp;E stained images based on a state-of-the-art deep learning model, but also carries out integrative analysis of image features and molecular data. The proposed framework enables us to effectively explore the underlying relationships between gene expression and tissue morphology, free from the extensive labeling and annotation that are laborious even to skilled pathologists.</p>
    <p id="p0135">Our WSI processing pipeline in <italic>BrcaSeg</italic> can be easily applied to histological images of other types of cancers. The global tissue segmentation maps we have presented could also be used for other more specific computational analysis. For example, global morphological features of different tissues could be estimated for better patient survival prediction <xref rid="b0110" ref-type="bibr">[22]</xref>, <xref rid="b0130" ref-type="bibr">[26]</xref>, and lymphocytes in different tissues could be distinguished for observation of more detailed immune response. Currently the imaging data resources have not been exploited to the degree of the other TCGA molecular and clinical outcome data, likely because automatic image annotation is still impeded by the “big data” challenges. In this study, we present global tissue maps for the TCGA breast cancer WSIs, and it is our belief that they will facilitate further exploration and utilization of these imaging data for various cancers.</p>
  </sec>
  <sec id="s0065">
    <title>Code availability</title>
    <p id="p0140">The details about code and data of <italic>BrcaSeg</italic> are provided at <ext-link ext-link-type="uri" xlink:href="https://github.com/Serian1992/ImgBio" id="ir010">https://github.com/Serian1992/ImgBio</ext-link>.</p>
  </sec>
  <sec id="s0070">
    <title>Competing interests</title>
    <p id="p0145">The authors have declared no competing interests.</p>
  </sec>
  <sec id="s0075">
    <title>CRediT authorship contribution statement</title>
    <p id="p0150"><bold>Zixiao Lu:</bold> Methodology, Data curation, Investigation, Validation, Writing – original draft. <bold>Xiaohui Zhan:</bold> Formal analysis, Writing – original draft. <bold>Yi Wu:</bold> Methodology. <bold>Jun Cheng:</bold> Data curation. <bold>Wei Shao:</bold> Methodology. <bold>Dong Ni:</bold> Writing – review &amp; editing. <bold>Zhi Han:</bold> Data curation, Methodology. <bold>Jie Zhang:</bold> Writing – review &amp; editing, Conceptualization. <bold>Qianjin Feng:</bold> Writing – review &amp; editing, Methodology. <bold>Kun Huang:</bold> Conceptualization, Supervision, Funding acquisition, Writing – review &amp; editing, Formal analysis, Investigation.</p>
  </sec>
</body>
<back>
  <ref-list id="bi005">
    <title>References</title>
    <ref id="b0005">
      <label>1</label>
      <element-citation publication-type="journal" id="h0005">
        <person-group person-group-type="author">
          <name>
            <surname>Arendt</surname>
            <given-names>L.M.</given-names>
          </name>
          <name>
            <surname>Rudnick</surname>
            <given-names>J.A.</given-names>
          </name>
          <name>
            <surname>Keller</surname>
            <given-names>P.J.</given-names>
          </name>
          <name>
            <surname>Kuperwasser</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Stroma in breast development and disease</article-title>
        <source>Semin Cell Dev Biol</source>
        <volume>21</volume>
        <year>2010</year>
        <fpage>11</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="pmid">19857593</pub-id>
      </element-citation>
    </ref>
    <ref id="b0010">
      <label>2</label>
      <element-citation publication-type="journal" id="h0010">
        <person-group person-group-type="author">
          <name>
            <surname>de Kruijf</surname>
            <given-names>E.M.</given-names>
          </name>
          <name>
            <surname>van Nes</surname>
            <given-names>J.G.H.</given-names>
          </name>
          <name>
            <surname>van de Velde</surname>
            <given-names>C.J.H.</given-names>
          </name>
          <name>
            <surname>Putter</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Smit</surname>
            <given-names>V.T.H.B.M.</given-names>
          </name>
          <name>
            <surname>Liefers</surname>
            <given-names>G.J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Tumor–stroma ratio in the primary tumor is a prognostic factor in early breast cancer patients, especially in triple-negative carcinoma patients</article-title>
        <source>Breast Cancer Res Treat</source>
        <volume>125</volume>
        <year>2011</year>
        <fpage>687</fpage>
        <lpage>696</lpage>
        <pub-id pub-id-type="pmid">20361254</pub-id>
      </element-citation>
    </ref>
    <ref id="b0015">
      <label>3</label>
      <element-citation publication-type="journal" id="h0015">
        <person-group person-group-type="author">
          <name>
            <surname>Toss</surname>
            <given-names>M.S.</given-names>
          </name>
          <name>
            <surname>Miligy</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Al-Kawaz</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Alsleem</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Khout</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Rida</surname>
            <given-names>P.C.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Prognostic significance of tumor-infiltrating lymphocytes in ductal carcinoma <italic>in situ</italic> of the breast</article-title>
        <source>Mod Pathol</source>
        <volume>31</volume>
        <year>2018</year>
        <fpage>1226</fpage>
        <lpage>1236</lpage>
        <pub-id pub-id-type="pmid">29559742</pub-id>
      </element-citation>
    </ref>
    <ref id="b0020">
      <label>4</label>
      <element-citation publication-type="journal" id="h0020">
        <person-group person-group-type="author">
          <name>
            <surname>Fouad</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Randell</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Galton</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Mehanna</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Landini</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Epithelium and stroma identification in histopathological images using unsupervised and semi-supervised superpixel-based segmentation</article-title>
        <source>J Imaging</source>
        <volume>3</volume>
        <year>2017</year>
        <fpage>61</fpage>
      </element-citation>
    </ref>
    <ref id="b0025">
      <label>5</label>
      <element-citation publication-type="book" id="h0025">
        <person-group person-group-type="author">
          <name>
            <surname>Haridas</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Bunyak</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Palaniappan</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <part-title>Interactive segmentation relabeling for classification of whole-slide histopathology imagery</part-title>
        <source>2015 IEEE 28th Int Symp Comput Med Syst</source>
        <year>2015</year>
        <fpage>84</fpage>
        <lpage>87</lpage>
      </element-citation>
    </ref>
    <ref id="b0030">
      <label>6</label>
      <element-citation publication-type="journal" id="h0030">
        <person-group person-group-type="author">
          <name>
            <surname>Bunyak</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Hafiane</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Al-Milaji</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Ersoy</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Haridas</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Palaniappan</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>A segmentation-based multi-scale framework for the classification of epithelial and stromal tissues in H&amp;E images</article-title>
        <source>IEEE Int Conf Bioinforma Biomed</source>
        <volume>2015</volume>
        <year>2015</year>
        <fpage>450</fpage>
        <lpage>453</lpage>
      </element-citation>
    </ref>
    <ref id="b0035">
      <label>7</label>
      <element-citation publication-type="journal" id="h0035">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Ren</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Deep residual learning for image recognition</article-title>
        <source>Proc IEEE Conf Comput Vis Pattern Recognit</source>
        <volume>39</volume>
        <year>2016</year>
        <fpage>1476</fpage>
        <lpage>1481</lpage>
      </element-citation>
    </ref>
    <ref id="b0040">
      <label>8</label>
      <element-citation publication-type="journal" id="h0040">
        <person-group person-group-type="author">
          <name>
            <surname>Ren</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Girshick</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Faster R-CNN: towards real-time object detection with region proposal networks</article-title>
        <source>IEEE Trans Pattern Anal Mach Intell</source>
        <volume>39</volume>
        <year>2017</year>
        <fpage>1137</fpage>
        <lpage>1149</lpage>
        <pub-id pub-id-type="pmid">27295650</pub-id>
      </element-citation>
    </ref>
    <ref id="b0045">
      <label>9</label>
      <element-citation publication-type="journal" id="h0045">
        <person-group person-group-type="author">
          <name>
            <surname>Shelhamer</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Long</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Darrell</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>Fully convolutional networks for semantic segmentation</article-title>
        <source>IEEE Trans Pattern Anal Mach Intell</source>
        <volume>39</volume>
        <year>2017</year>
        <fpage>640</fpage>
        <lpage>651</lpage>
        <pub-id pub-id-type="pmid">27244717</pub-id>
      </element-citation>
    </ref>
    <ref id="b0050">
      <label>10</label>
      <element-citation publication-type="journal" id="h0050">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>L.C.</given-names>
          </name>
          <name>
            <surname>Papandreou</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Kokkinos</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Murphy</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Yuille</surname>
            <given-names>A.L.</given-names>
          </name>
        </person-group>
        <article-title>Deeplab: semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</article-title>
        <source>IEEE Trans Pattern Anal Mach Intell</source>
        <volume>40</volume>
        <year>2018</year>
        <fpage>834</fpage>
        <lpage>848</lpage>
        <pub-id pub-id-type="pmid">28463186</pub-id>
      </element-citation>
    </ref>
    <ref id="b0055">
      <label>11</label>
      <element-citation publication-type="journal" id="h0055">
        <person-group person-group-type="author">
          <name>
            <surname>Al-Milaji</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Ersoy</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Hafiane</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Palaniappan</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Bunyak</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>Integrating segmentation with deep learning for enhanced classification of epithelial and stromal tissues in H&amp;E images</article-title>
        <source>Pattern Recognit Lett</source>
        <volume>119</volume>
        <year>2019</year>
        <fpage>214</fpage>
        <lpage>221</lpage>
      </element-citation>
    </ref>
    <ref id="b0060">
      <label>12</label>
      <element-citation publication-type="journal" id="h0060">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Gilmore</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Madabhushi</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>A deep convolutional neural network for segmenting and classifying epithelial and stromal regions in histopathological images</article-title>
        <source>Neurocomputing</source>
        <volume>191</volume>
        <year>2016</year>
        <fpage>214</fpage>
        <lpage>223</lpage>
        <pub-id pub-id-type="pmid">28154470</pub-id>
      </element-citation>
    </ref>
    <ref id="b0065">
      <label>13</label>
      <element-citation publication-type="journal" id="h0065">
        <person-group person-group-type="author">
          <name>
            <surname>Farahani</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Parwani</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Pantanowitz</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>Whole slide imaging in pathology: advantages, limitations, and emerging perspectives</article-title>
        <source>Pathol Lab Med Int</source>
        <volume>7</volume>
        <year>2015</year>
        <fpage>23</fpage>
        <lpage>33</lpage>
      </element-citation>
    </ref>
    <ref id="b0070">
      <label>14</label>
      <element-citation publication-type="journal" id="h0070">
        <person-group person-group-type="author">
          <name>
            <surname>Ronneberger</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Fischer</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Brox</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>U-net: convolutional networks for biomedical image segmentation</article-title>
        <source>Lect Notes Comput Sci</source>
        <volume>9351</volume>
        <year>2015</year>
        <fpage>234</fpage>
        <lpage>241</lpage>
      </element-citation>
    </ref>
    <ref id="b0075">
      <label>15</label>
      <element-citation publication-type="journal" id="h0075">
        <person-group person-group-type="author">
          <name>
            <surname>Bejnordi</surname>
            <given-names>B.E.</given-names>
          </name>
          <name>
            <surname>Zuidhof</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Balkenhol</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Hermsen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Bult</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>van Ginneken</surname>
            <given-names>B.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Context-aware stacked convolutional neural networks for classification of breast carcinomas in whole-slide histopathology images</article-title>
        <source>J Med Imaging (Bellingham)</source>
        <volume>4</volume>
        <year>2017</year>
        <fpage>044504</fpage>
        <pub-id pub-id-type="pmid">29285517</pub-id>
      </element-citation>
    </ref>
    <ref id="b0080">
      <label>16</label>
      <element-citation publication-type="journal" id="h0080">
        <person-group person-group-type="author">
          <name>
            <surname>Hou</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Samaras</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Kurc</surname>
            <given-names>T.M.</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Davis</surname>
            <given-names>J.E.</given-names>
          </name>
          <name>
            <surname>Saltz</surname>
            <given-names>J.H.</given-names>
          </name>
        </person-group>
        <article-title>Patch-based convolutional neural network for whole slide tissue image classification</article-title>
        <source>Proc IEEE Conf Comput Vis Pattern Recognit</source>
        <year>2016</year>
        <fpage>2424</fpage>
        <lpage>2433</lpage>
      </element-citation>
    </ref>
    <ref id="b0085">
      <label>17</label>
      <element-citation publication-type="journal" id="h0085">
        <person-group person-group-type="author">
          <name>
            <surname>Saltz</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Gupta</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Kurc</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>V.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Spatial organization and molecular correlation of tumor-infiltrating lymphocytes using deep learning on pathology images</article-title>
        <source>Cell Rep</source>
        <volume>23</volume>
        <year>2018</year>
        <fpage>181</fpage>
        <lpage>193.e7</lpage>
        <pub-id pub-id-type="pmid">29617659</pub-id>
      </element-citation>
    </ref>
    <ref id="b0090">
      <label>18</label>
      <element-citation publication-type="journal" id="h0090">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Akbani</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Ju</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Roebuck</surname>
            <given-names>P.L.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>W.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>TCPA: a resource for cancer functional proteomics data</article-title>
        <source>Nat Methods</source>
        <volume>10</volume>
        <year>2013</year>
        <fpage>1046</fpage>
        <lpage>1047</lpage>
      </element-citation>
    </ref>
    <ref id="b0095">
      <label>19</label>
      <element-citation publication-type="journal" id="h0095">
        <person-group person-group-type="author">
          <name>
            <surname>Akbani</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Ng</surname>
            <given-names>P.K.S.</given-names>
          </name>
          <name>
            <surname>Werner</surname>
            <given-names>H.M.J.</given-names>
          </name>
          <name>
            <surname>Shahmoradgoli</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Ju</surname>
            <given-names>Z.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A pan-cancer proteomic perspective on The Cancer Genome Atlas</article-title>
        <source>Nat Commun</source>
        <volume>5</volume>
        <year>2014</year>
        <fpage>3887</fpage>
        <pub-id pub-id-type="pmid">24871328</pub-id>
      </element-citation>
    </ref>
    <ref id="b0100">
      <label>20</label>
      <element-citation publication-type="journal" id="h0100">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Mo</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Parwani</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Identification of topological features in renal tumor microenvironment associated with patient survival</article-title>
        <source>Bioinformatics</source>
        <volume>34</volume>
        <year>2017</year>
        <fpage>1024</fpage>
        <lpage>1030</lpage>
      </element-citation>
    </ref>
    <ref id="b0105">
      <label>21</label>
      <element-citation publication-type="journal" id="h0105">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>Y.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Integrative analysis of histopathological images and genomic data predicts clear cell renal cell carcinoma prognosis</article-title>
        <source>Cancer Res</source>
        <volume>77</volume>
        <year>2017</year>
        <fpage>e91</fpage>
        <lpage>e100</lpage>
        <pub-id pub-id-type="pmid">29092949</pub-id>
      </element-citation>
    </ref>
    <ref id="b0110">
      <label>22</label>
      <element-citation publication-type="book" id="h0110">
        <person-group person-group-type="author">
          <name>
            <surname>Shao</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>D.</given-names>
          </name>
          <etal/>
        </person-group>
        <part-title>Ordinal multi-modal feature selection for survival analysis of early-stage renal cancer</part-title>
        <source>21st International Conference on Medical Image Computing and Computer - Assisted Intervention</source>
        <year>2018</year>
        <fpage>648</fpage>
        <lpage>656</lpage>
      </element-citation>
    </ref>
    <ref id="b0115">
      <label>23</label>
      <element-citation publication-type="journal" id="h0115">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Vasaikar</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Greer</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>WebGestalt 2017: a more comprehensive, powerful, flexible and interactive gene set enrichment analysis toolkit</article-title>
        <source>Nucleic Acids Res</source>
        <volume>45</volume>
        <year>2017</year>
        <fpage>W130</fpage>
        <lpage>W137</lpage>
        <pub-id pub-id-type="pmid">28472511</pub-id>
      </element-citation>
    </ref>
    <ref id="b0120">
      <label>24</label>
      <mixed-citation publication-type="other" id="h0120">Du Y, Zhang R, Zargari A, Thai TC, Gunderson CC, Moxley KM, et al. A performance comparison of low-and high-level features learned by deep convolutional neural networks in epithelium and stroma classification. Medical Imaging 2018: Digital Pathology 2018;10581:1058116.</mixed-citation>
    </ref>
    <ref id="b0125">
      <label>25</label>
      <element-citation publication-type="journal" id="h0125">
        <person-group person-group-type="author">
          <name>
            <surname>Vu</surname>
            <given-names>Q.D.</given-names>
          </name>
          <name>
            <surname>Kwak</surname>
            <given-names>J.T.</given-names>
          </name>
        </person-group>
        <article-title>A dense multi-path decoder for tissue segmentation in histopathology images</article-title>
        <source>Comput Methods Programs Biomed</source>
        <volume>173</volume>
        <year>2019</year>
        <fpage>119</fpage>
        <lpage>129</lpage>
        <pub-id pub-id-type="pmid">31046986</pub-id>
      </element-citation>
    </ref>
    <ref id="b0130">
      <label>26</label>
      <element-citation publication-type="journal" id="h0130">
        <person-group person-group-type="author">
          <name>
            <surname>Beck</surname>
            <given-names>A.H.</given-names>
          </name>
          <name>
            <surname>Sangoi</surname>
            <given-names>A.R.</given-names>
          </name>
          <name>
            <surname>Leung</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Marinelli</surname>
            <given-names>R.J.</given-names>
          </name>
          <name>
            <surname>Nielsen</surname>
            <given-names>T.O.</given-names>
          </name>
          <name>
            <surname>van de Vijver</surname>
            <given-names>M.J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Systematic analysis of breast cancer morphology uncovers stromal features associated with survival</article-title>
        <source>Sci Transl Med</source>
        <volume>3</volume>
        <year>2011</year>
        <fpage>108ra113</fpage>
      </element-citation>
    </ref>
    <ref id="b0135">
      <label>27</label>
      <element-citation publication-type="journal" id="h0135">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Pécot</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Zynger</surname>
            <given-names>D.L.</given-names>
          </name>
          <name>
            <surname>Machiraju</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Shapiro</surname>
            <given-names>C.L.</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Identifying survival associated morphological features of triple negative breast cancer using multiple datasets</article-title>
        <source>J Am Med Informatics Assoc</source>
        <volume>20</volume>
        <year>2013</year>
        <fpage>680</fpage>
        <lpage>687</lpage>
      </element-citation>
    </ref>
    <ref id="b0140">
      <label>28</label>
      <element-citation publication-type="journal" id="h0140">
        <person-group person-group-type="author">
          <name>
            <surname>Mackie</surname>
            <given-names>T.R.</given-names>
          </name>
          <name>
            <surname>Jackson</surname>
            <given-names>E.F.</given-names>
          </name>
          <name>
            <surname>Giger</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Opportunities and challenges to utilization of quantitative imaging: report of the AAPM practical big data workshop</article-title>
        <source>Med Phys</source>
        <volume>45</volume>
        <year>2018</year>
        <fpage>e820</fpage>
        <lpage>e828</lpage>
        <pub-id pub-id-type="pmid">30248184</pub-id>
      </element-citation>
    </ref>
    <ref id="b0145">
      <label>29</label>
      <element-citation publication-type="journal" id="h0145">
        <person-group person-group-type="author">
          <name>
            <surname>Hoadley</surname>
            <given-names>K.A.</given-names>
          </name>
          <name>
            <surname>Yau</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Hinoue</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Wolf</surname>
            <given-names>D.M.</given-names>
          </name>
          <name>
            <surname>Lazar</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Drill</surname>
            <given-names>E.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Cell-of-origin patterns dominate the molecular classification of 10,000 tumors from 33 types of cancer</article-title>
        <source>Cell</source>
        <volume>173</volume>
        <year>2018</year>
        <fpage>291</fpage>
        <lpage>304.e6</lpage>
        <pub-id pub-id-type="pmid">29625048</pub-id>
      </element-citation>
    </ref>
    <ref id="b0150">
      <label>30</label>
      <element-citation publication-type="journal" id="h0150">
        <person-group person-group-type="author">
          <name>
            <surname>Hanahan</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Weinberg</surname>
            <given-names>R.A.</given-names>
          </name>
        </person-group>
        <article-title>Hallmarks of Cancer: the next generation</article-title>
        <source>Cell</source>
        <volume>144</volume>
        <year>2011</year>
        <fpage>646</fpage>
        <lpage>674</lpage>
        <pub-id pub-id-type="pmid">21376230</pub-id>
      </element-citation>
    </ref>
    <ref id="b0155">
      <label>31</label>
      <element-citation publication-type="journal" id="h0155">
        <person-group person-group-type="author">
          <name>
            <surname>Rocca</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Farolfi</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Bravaccini</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Schirone</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Amadori</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Palbociclib (PD 0332991): targeting the cell cycle machinery in breast cancer</article-title>
        <source>Expert Opin Pharmacother</source>
        <volume>15</volume>
        <year>2014</year>
        <fpage>407</fpage>
        <lpage>420</lpage>
        <pub-id pub-id-type="pmid">24369047</pub-id>
      </element-citation>
    </ref>
    <ref id="b0160">
      <label>32</label>
      <element-citation publication-type="journal" id="h0160">
        <person-group person-group-type="author">
          <name>
            <surname>Murphy</surname>
            <given-names>C.G.</given-names>
          </name>
          <name>
            <surname>Dickler</surname>
            <given-names>M.N.</given-names>
          </name>
        </person-group>
        <article-title>The role of CDK4/6 inhibition in breast cancer</article-title>
        <source>Oncologist</source>
        <volume>20</volume>
        <year>2015</year>
        <fpage>483</fpage>
        <lpage>490</lpage>
        <pub-id pub-id-type="pmid">25876993</pub-id>
      </element-citation>
    </ref>
    <ref id="b0165">
      <label>33</label>
      <element-citation publication-type="journal" id="h0165">
        <person-group person-group-type="author">
          <name>
            <surname>Witkiewicz</surname>
            <given-names>A.K.</given-names>
          </name>
          <name>
            <surname>Chung</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Brough</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Vail</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Franco</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Lord</surname>
            <given-names>C.J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Targeting the vulnerability of RB tumor suppressor loss in triple-negative breast cancer</article-title>
        <source>Cell Rep</source>
        <volume>22</volume>
        <year>2018</year>
        <fpage>1185</fpage>
        <lpage>1199</lpage>
        <pub-id pub-id-type="pmid">29386107</pub-id>
      </element-citation>
    </ref>
    <ref id="b0170">
      <label>34</label>
      <element-citation publication-type="journal" id="h0170">
        <person-group person-group-type="author">
          <name>
            <surname>Bremnes</surname>
            <given-names>R.M.</given-names>
          </name>
          <name>
            <surname>Dønnem</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Al-Saad</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Al-Shibli</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Andersen</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Sirera</surname>
            <given-names>R.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The role of tumor stroma in cancer progression and prognosis: emphasis on carcinoma-associated fibroblasts and non-small cell lung cancer</article-title>
        <source>J Thorac Oncol</source>
        <volume>6</volume>
        <year>2011</year>
        <fpage>209</fpage>
        <lpage>217</lpage>
        <pub-id pub-id-type="pmid">21107292</pub-id>
      </element-citation>
    </ref>
    <ref id="b0175">
      <label>35</label>
      <element-citation publication-type="journal" id="h0175">
        <person-group person-group-type="author">
          <name>
            <surname>Ghesquière</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Wong</surname>
            <given-names>B.W.</given-names>
          </name>
          <name>
            <surname>Kuchnio</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Carmeliet</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>Metabolism of stromal and immune cells in health and disease</article-title>
        <source>Nature</source>
        <volume>511</volume>
        <year>2014</year>
        <fpage>167</fpage>
        <lpage>176</lpage>
        <pub-id pub-id-type="pmid">25008522</pub-id>
      </element-citation>
    </ref>
    <ref id="b0180">
      <label>36</label>
      <element-citation publication-type="journal" id="h0180">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Integrative analysis for lung adenocarcinoma predicts morphological features associated with genetic variations</article-title>
        <source>Pac Symp Biocomput</source>
        <year>2017</year>
        <fpage>82</fpage>
        <lpage>93</lpage>
        <pub-id pub-id-type="pmid">27896964</pub-id>
      </element-citation>
    </ref>
  </ref-list>
  <sec id="s0085" sec-type="supplementary-material">
    <title>Supplementary material</title>
    <p id="p0165">The following are the Supplementary material to this article:<supplementary-material content-type="local-data" id="m0010"><caption><title>Supplementary Figure S1</title><p><bold>Qualitative segmentation results on image patches from TCGA breast cancer dataset using <italic>BrcaSeg</italic></bold> Three segmentation examples on image patches from TCGA dataset are shown, including Example 1 (<bold>A</bold>), Example 2 (<bold>B</bold>), and Example 3 (<bold>C</bold>), which are randomly selected from the 171 image patches cropped from TCGA WSIs. Raw image patches from TCGA are shown on the left; image annotations by pathologists are shown in the middle; and image predictions using <italic>BrcaSeg</italic> are shown on the right. Areas in red, green, and black in annotations and predictions represent epithelial, stromal, and background regions in raw images, respectively.</p></caption><media xlink:href="mmc1.pptx"/></supplementary-material></p>
    <p id="p0170">
      <supplementary-material content-type="local-data" id="m0005">
        <caption>
          <title>Supplementary Table S1</title>
          <p>
            <bold>Quantitative performance evaluation on image patches from TCGA breast cancer dataset using BrcaSeg</bold>
          </p>
        </caption>
        <media xlink:href="mmc2.docx"/>
      </supplementary-material>
    </p>
  </sec>
  <ack id="ak005">
    <title>Acknowledgments</title>
    <p id="p0155">This work was supported by <funding-source id="gp005"><institution-wrap><institution-id institution-id-type="doi">10.13039/100006733</institution-id><institution>Indiana University Precision Health Initiative</institution></institution-wrap></funding-source> to KH and JZ, the <funding-source id="gp010"><institution-wrap><institution-id institution-id-type="doi">10.13039/501100001809</institution-id><institution>NSFC</institution></institution-wrap></funding-source>-Guangdong Joint Fund of China (Grant No. U1501256) to QF, and <funding-source id="gp015"><institution-wrap><institution-id institution-id-type="doi">10.13039/501100012234</institution-id><institution>Shenzhen Peacock Plan</institution></institution-wrap></funding-source> (Grant No. KQTD2016053112051497) to XZ and ND. We thank Dr. Natalie Lambert, Dr. Bryan Helm, and Ms. Megan Metzger for their tremendous help in the discussion and editing of the manuscript.</p>
  </ack>
  <fn-group>
    <fn id="d35e630">
      <p id="np005">Peer review under responsibility of Beijing Institute of Genomics, Chinese Academy of Sciences / China National Center for Bioinformation and Genetics Society of China.</p>
    </fn>
    <fn id="s0080" fn-type="supplementary-material">
      <p id="p0160">Supplementary material to this article can be found online at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.gpb.2020.06.026" id="ir015">https://doi.org/10.1016/j.gpb.2020.06.026</ext-link>.</p>
    </fn>
  </fn-group>
</back>
