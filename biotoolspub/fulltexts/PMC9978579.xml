<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9978579</article-id>
    <article-id pub-id-type="pmid">36825815</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btad096</article-id>
    <article-id pub-id-type="publisher-id">btad096</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Systems Biology</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Regularized adversarial learning for normalization of multi-batch untargeted metabolomics data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Dmitrenko</surname>
          <given-names>Andrei</given-names>
        </name>
        <aff><institution>ETH Zürich, Institute of Molecular Systems Biology</institution>, Zürich 8093, <country country="CH">Switzerland</country></aff>
        <aff><institution>Life Science Zurich PhD Program on Systems Biology</institution>, Zurich, <country country="CH">Switzerland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Reid</surname>
          <given-names>Michelle</given-names>
        </name>
        <aff><institution>ETH Zürich, Institute of Molecular Systems Biology</institution>, Zürich 8093, <country country="CH">Switzerland</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-1271-1021</contrib-id>
        <name>
          <surname>Zamboni</surname>
          <given-names>Nicola</given-names>
        </name>
        <aff><institution>ETH Zürich, Institute of Molecular Systems Biology</institution>, Zürich 8093, <country country="CH">Switzerland</country></aff>
        <aff><institution>PHRT Swiss Multi-OMICS Center</institution>, <country country="CH">Switzerland</country></aff>
        <xref rid="btad096-cor1" ref-type="corresp"/>
        <!--nzamboni@ethz.ch-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Kelso</surname>
          <given-names>Janet</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btad096-cor1">To whom correspondence should be addressed. <email>nzamboni@ethz.ch</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-02-24">
      <day>24</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>24</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <volume>39</volume>
    <issue>3</issue>
    <elocation-id>btad096</elocation-id>
    <history>
      <date date-type="received">
        <day>23</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>13</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>09</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>01</day>
        <month>3</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btad096.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Untargeted metabolomics by mass spectrometry is the method of choice for unbiased analysis of molecules in complex samples of biological, clinical or environmental relevance. The exceptional versatility and sensitivity of modern high-resolution instruments allows profiling of thousands of known and unknown molecules in parallel. Inter-batch differences constitute a common and unresolved problem in untargeted metabolomics, and hinder the analysis of multi-batch studies or the intercomparison of experiments.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We present a new method, Regularized Adversarial Learning Preserving Similarity (RALPS), for the normalization of multi-batch untargeted metabolomics data. RALPS builds on deep adversarial learning with a three-term loss function that mitigates batch effects while preserving biological identity, spectral properties and coefficients of variation. Using two large metabolomics datasets, we showcase the superior performance of RALPS as compared with six state-of-the-art methods for batch correction. Further, we demonstrate that RALPS scales well, is robust, deals with missing values and can handle different experimental designs.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p><ext-link xlink:href="https://github.com/zamboni-lab/RALPS" ext-link-type="uri">https://github.com/zamboni-lab/RALPS</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Strategic Focal Area Personalized Health and Related Technologies</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="6"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Metabolomics is the method of choice for chemical characterization of biological, clinical and environmental samples (<xref rid="btad096-B1" ref-type="bibr">Alseekh <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btad096-B8" ref-type="bibr">Johnson <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btad096-B16" ref-type="bibr">Patti <italic toggle="yes">et al.</italic>, 2012</xref>). When the aim of the analysis is to monitor many and potentially unexpected analytes, the traditional untargeted approach is to scan the full mass and dynamic range with high-resolving instruments. This strategy allows monitoring of virtually all compounds that can be ionized and are sufficiently abundant. Eventually, untargeted metabolomics experiments result in semi-quantitative data for thousands of detectable features and many more unknowns. A largely unsolved problem of such large metabolomics experiments, however, is data normalization. The sheer number of features and the extreme sensitivity of liquid chromatography–mass spectrometry (MS) instruments to multiple factors mean that ion-specific temporal drifts, day-to-day variability or inter-batch effects are common in metabolomics analyses (<xref rid="btad096-B1" ref-type="bibr">Alseekh <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btad096-B7" ref-type="bibr">Dunn <italic toggle="yes">et al.</italic>, 2011</xref>). These problems increase with number of samples.</p>
    <p>The most common way to account for and correct these issues is to employ isotopically labeled internal standards, which are added at a fixed amount to all samples and calibration standards (<xref rid="btad096-B16" ref-type="bibr">Patti <italic toggle="yes">et al.</italic>, 2012</xref>; <xref rid="btad096-B19" ref-type="bibr">Schatschneider <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btad096-B20" ref-type="bibr">Sysi-Aho <italic toggle="yes">et al.</italic>, 2007</xref>; <xref rid="btad096-B22" ref-type="bibr">Wu <italic toggle="yes">et al.</italic>, 2005</xref>). If the standard’s elution times and ionization behavior are identical to those of the compound of interest, the standard can be used to correct for linear matrix effects. This approach is quite effective with a limited number of metabolites, as in targeted metabolomics analyses, but does not scale to untargeted metabolomics. The first problem is the limited availability of heavy standards, and one workaround is to use a few representatives for each class and extrapolate over structurally similar compounds. The second problem is the limit on the number of standards that can be spiked without introducing novel matrix effects, i.e. when using standards available in salt form.</p>
    <p>In the absence of internal standards to assess and correct for experimental variations, drifts, batch effects and so on, normalization needs to operate on the resulting data. Intra-batch ionization drifts are effectively corrected by detrending on the basis of quality control samples (<xref rid="btad096-B3" ref-type="bibr">Broadhurst <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btad096-B7" ref-type="bibr">Dunn <italic toggle="yes">et al.</italic>, 2011</xref>; <xref rid="btad096-B11" ref-type="bibr">Kuligowski <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="btad096-B18" ref-type="bibr">Rusilowicz <italic toggle="yes">et al.</italic>, 2016</xref>). Inter-batch biases, however, are more challenging, and many different approaches to reduce them have been presented in recent years. Notable examples of inter-batch normalization methods are ComBat (<xref rid="btad096-B9" ref-type="bibr">Johnson <italic toggle="yes">et al.</italic>, 2007</xref>), based on empirical Bayes frameworks and EigenMS (<xref rid="btad096-B10" ref-type="bibr">Karpievitch <italic toggle="yes">et al.</italic>, 2014</xref>), using matrix factorization by singular value decomposition. Together with probabilistic quotient normalization (PQN) (<xref rid="btad096-B6" ref-type="bibr">Dieterle <italic toggle="yes">et al.</italic>, 2006</xref>), these approaches have been reported as some of the best options for untargeted metabolomics studies (<xref rid="btad096-B23" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2020</xref>) when applied in combination with metabolite-based scaling (e.g. LEV+EIG for level scaling followed by EigenMS, or PQN+POW for PQN followed by power scaling). In 2019, an algorithm based on the wavelet transform with independent component analysis, WaveICA, was introduced and showed superior performance in large-scale untargeted metabolomics studies (<xref rid="btad096-B5" ref-type="bibr">Deng <italic toggle="yes">et al.</italic>, 2019</xref>).</p>
    <p>A novel avenue for batch correction in metabolomics was opened by NormAE (<xref rid="btad096-B17" ref-type="bibr">Rong <italic toggle="yes">et al.</italic>, 2020</xref>). It employs deep learning and was inspired by the very successful application in single-cell RNA sequencing (<xref rid="btad096-B12" ref-type="bibr">Lakkis <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btad096-B13" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btad096-B21" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019</xref>). NormAE relies on adversarial learning in which two neural networks, an autoencoder and a classifier, are trained simultaneously to reconstruct the data and classify batches based on the latent space of the autoencoder, respectively. The ultimate goal is to reproduce the data but remove differences between user-defined batches. To achieve this, the autoencoder is trained with a loss function that includes two terms. The first term awards correct reconstruction, and the second term applies a penalty if samples from different batches are separated correctly. The latter term pushes the autoencoder to learn the data representations that render any user-defined batches indistinguishable from each other. NormAE set new performance standards in removing batch effects (<xref rid="btad096-B17" ref-type="bibr">Rong <italic toggle="yes">et al.</italic>, 2020</xref>) but still suffers from issues common to all practical applications of deep learning, such as the non-trivial parameter optimization, computational complexity and lack of reproducibility (<xref rid="btad096-B2" ref-type="bibr">Bhojanapalli <italic toggle="yes">et al.</italic>, 2021</xref>). Further, it requires identical reference samples across all batches, which might become a problem in long-term studies. Finally, NormAE and some other aforementioned approaches produce heavily rescaled normalized outputs in arbitrary units, undermining interpretability.</p>
    <p>Here, we present a new normalization method, Regularized Adversarial Learning Preserving Similarity (RALPS), for untargeted metabolomics that efficiently addresses all the aforementioned problems. RALPS builds on adversarial learning but implements a novel three-term loss function that suppresses batch effects while preserving biological information. Using several test sets, we show that RALPS outperforms state-of-the-art methods in terms of performance, scalability, usability and robustness.</p>
  </sec>
  <sec>
    <title>2 Results</title>
    <sec>
      <title>2.1 Method overview</title>
      <p>RALPS was inspired by NormAE: it uses an autoencoder and a classifier to mitigate batch effects, but the loss function was extended with two additional terms beyond the reconstruction loss (<italic toggle="yes">L</italic><sub>g</sub>) and batch discrimination loss (<italic toggle="yes">L</italic><sub>d</sub>) (<xref rid="btad096-F1" ref-type="fig">Fig. 1</xref>). First, we wanted to introduce a mechanism to preserve characteristic differences of any set of supposedly similar samples across the whole sequence as a way to preserve biological information. For this purpose, we added a new regularization term (<italic toggle="yes">r</italic><sub>g</sub>) to the autoencoder loss function to reward tight clustering of reference samples in the embedded space. To evaluate clustering, RALPS flattens the multidimensional space by uniform manifold approximation and projection (UMAP) (<xref rid="btad096-B15" ref-type="bibr">McInnes <italic toggle="yes">et al.</italic>, 2018</xref>) and performs unsupervised hierarchical density-based cluster analysis (HDBSCAN) (<xref rid="btad096-B14" ref-type="bibr">Malzer and Baum, 2020</xref>). Eventually, clustering is evaluated by counting how frequently reference samples of the same type occur in the same cluster. In the case of perfect clustering of biological replicates, the regularization term is zero. We also included a new variation loss term (<italic toggle="yes">L</italic><sub>v</sub>) to encourage a decrease in batch variation coefficients (VCs). This addition was motivated by two observations. First, many normalization methods tend to inflate the VCs of replicate measurements. Second, deep-learning models with encoder–decoder architectures are especially prone to producing outliers.</p>
      <fig position="float" id="btad096-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Graphical overview of RALPS. The autoencoder takes measured data, <italic toggle="yes">X</italic>, as input and produces its reconstruction, <italic toggle="yes">D(E(X))</italic>, as output. The number of neurons in the bottleneck layer is determined by principal component analysis. The aggregated autoencoder loss <bold>L</bold> consists of three terms: the regularized autoencoder loss <italic toggle="yes">L<sub>g</sub></italic>, the classifier loss <italic toggle="yes">L<sub>d</sub></italic> and the variation loss <italic toggle="yes">L<sub>v</sub></italic> with real coefficients <italic toggle="yes">λ<sub>g</sub></italic>, <italic toggle="yes">λ<sub>d</sub></italic> and <italic toggle="yes">λ<sub>v</sub></italic>, respectively</p>
        </caption>
        <graphic xlink:href="btad096f1" position="float"/>
      </fig>
      <p>Furthermore, we included several additional features to improve scalability, usability and robustness. First, RALPS adopts a flexible network architecture, in which the number of neurons in the model layers is automatically adjusted based on a principal component analysis. By default, RALPS sets the number of neurons equal to the number of principal components needed to describe at least 90% of the dataset variance. This modification eliminates many hyperparameters from the model and simplifies parameter optimization. Second, we introduced a randomized hyperparameter grid search and model selection logic, both of which enable finding multiple parameter sets that deliver top normalization results in an automated way. Third, we introduced input validation and a mechanism for early stopping to avoid collapsed normalization solutions that could arise because of inconsistent parametrization or increasing classifier loss. Details are provided in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>. RALPS is implemented in Python programming language with PyTorch deep-learning framework. It requires a single configuration file containing the data and the batch information file paths, as well as a few other parameters to run normalization.</p>
      <p>Information on reference samples is provided by the user to indicate all sample groups that are supposed to be similar. These groups can include biological replicates, technical replicates, pooled study samples, spike-ins and dilution series. There is no formal limit on the number of reference groups, and although sample groups should span multiple batches, the same reference samples do not need to be present in all batches. This flexibility builds considerable freedom into the experimental design, as discussed below.</p>
    </sec>
    <sec>
      <title>2.2 Generation of a multi-batch benchmarking dataset</title>
      <p>We faced the problem of finding suitable multi-batch datasets for testing and comparing normalization methods. Because such datasets are rare and often associated with clinical studies that preclude full disclosure and publication (<xref rid="btad096-B17" ref-type="bibr">Rong <italic toggle="yes">et al.</italic>, 2020</xref>), we opted to generate a novel benchmarking dataset. We assembled a panel of 136 samples with a large variety in sample type, complexity and concentrations (<xref rid="sup1" ref-type="supplementary-material">Supplementary Methods</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>). Roughly half of the samples were prepared in human serum extracts, the rest in water. We included spike-ins with selections of amino acids, fatty acids and nucleobases, and a fully <sup>13</sup>C-labeled <italic toggle="yes">Escherichia coli</italic> extract at different dilutions. The samples were aliquoted, frozen and analyzed seven times over the span of about 2 months with time gaps of up to 3 weeks. Each of the seven batches was acquired and processed independently. To focus on the subset of m/z peaks that possibly relate to metabolites, we selected features with m/z values that were matched to deprotonated compounds listed by the Human Metabolome Database (ver. 4.0, tolerance 0.001 Da). Upon intersecting the putative peak lists obtained from each batch and filtering low-abundance features, we obtained a data table with intensities for 170 putative deprotonated metabolites and 2856 files, divided in seven batches.</p>
      <p>To visualize the extent of batch effects, we plotted the UMAP projections for all samples (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2a</xref>). We observed that samples grouped by batch, and almost no overlap between batches could be found. This result clearly indicates that batch effects dominate and confound chemically identical samples. Another way to quantify batch effects is to calculate the cross-correlation of identical samples within and between batches (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2b</xref>). Although Pearson correlation coefficients were &gt;0.9 within the same batch, the distribution of inter-batch correlations shows a heavy tail, reaching values as low as <italic toggle="yes">r</italic> = 0.4, pointing to strong biases. Below, we use this dataset to benchmark RALPS against state-of-the-art approaches.</p>
    </sec>
    <sec>
      <title>2.3 Normalization of the multi-batch dataset</title>
      <p>As a first demonstration, we evaluated RALPS on a multi-batch benchmarking dataset. Initially, all sample labels were included as reference groups to maximize information available for training. We ran RALPS with default parameters and a randomized grid search of size 50. The best normalization solution selected by the model selection logic was compared to the initial dataset. First, we assessed the normalization effect of our method by highlighting batch labels on the UMAP embeddings plot (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2d</xref>). We observed that replicates from different batches were largely mixed for the normalized data compared with the initial data. The distribution of cross-correlations of all samples’ replicates within and between batches shifted close to the ideal value of one (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2e</xref>). Moreover, VCs calculated for all intensities in every batch were consistently reduced in the normalized data (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2f</xref>) compared with the initial data (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2c</xref>). The total runtime for the 50 independent runs was 291 min, i.e. about 6 min per run for a dataset with almost 3000 samples. Note that only a single CPU core was used for all computations. With an increasing number of CPU cores, it would be possible to evaluate much larger hyperparameter sets overnight, increasing the probability of finding an optimal normalization solution.</p>
    </sec>
    <sec>
      <title>2.4 Normalization of the multi-batch dataset with limited reference groups</title>
      <p>The test described above builds on a rather artificial scenario in which all samples are present in every batch. In practice, however, only a small subset of samples in each batch are repetitions of samples of different batches and can be used to correct for inter-batch effects. The most common scenario is inclusion of one or two reference samples in all batches. If a single sample is available, a frequent option is to spike in standards at a relevant concentration to ensure correct recovery of significant differences, including MS measurement and data processing. To mimic this realistic scenario, we attempted to normalize the benchmarking dataset with RALPS, using only a few reference sample groups each time. Different sets of groups were tested. For instance, <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3</xref> shows the normalization achieved by RALPS using exclusively an undiluted NIST1950 serum extract (P2_S_0001) and the same sample spiked with purines and pyrimidines (P2_S_PP_0001). The labels and relation of all remaining samples were neglected during training. For the normalized data, batches no longer appeared as isolated clouds of points, and instead, samples from different batches were mostly well mixed. Qualitatively, the result was similar to the initial test in which all reference groups were provided during the training phase.</p>
      <p>To demonstrate the flexibility of RALPS, we tested several combinations of up to four reference sample groups. For each combination, we applied RALPS with a randomized grid search of size 100. We used default parameters and set <italic toggle="yes">λ</italic><sub>v</sub> = 0 to loosen the constraints on the joint loss function optimized during training (<xref rid="btad096-F1" ref-type="fig">Fig. 1</xref>).</p>
      <p>We found several combinations of reference samples that produced good normalization effects (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). Comparing some of the evaluation metrics, using only undiluted NIST1950 serum extract (P2_S_0001) or using combinations of two or three samples yielded results similar to those from the examples described above (row #1 in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). As a negative control, we provide results obtained by training with a single reference group consisting of highly diluted fatty acids in water (row #10 in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). Because of matrix differences and the common presence of fatty acids in the background, these samples are unlikely to be sufficient to correct for complex batch effects, e.g. in serum samples.</p>
      <p>All other tested configurations were comparably superior on all evaluation metrics, but not all were reproducible, as assessed by several repetitions of the training with identical reference groups but different random starts. Only half of the cases frequently reproduced comparably good results. For the other half that was not reproducible, including the case with undiluted serum as a unique reference group, multiple independent attempts would be necessary. Nevertheless, all the reference group configurations performed well in mixing batches on the UMAP embedding plot (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4</xref>). These results prove that RALPS is flexible in the choice of reference samples and, in principle, a few reference sample groups in triplicate can suffice.</p>
      <p>Next, we compared RALPS to the state-of-the-art normalization approaches mentioned in the introduction. Of the several training scenarios listed above, RALPS was trained using two reference sample groups with undiluted serum and the derivative with spiked purines and pyrimidines (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>). The performance was evaluated using one qualitative and three quantitative criteria. The quantitative criteria included cross-correlation of all samples’ replicates, batch VCs and percent of features for which the VC across replicate samples increased upon normalization. The qualitative criterion was the spectrum of the normalized data compared with that of the initial data (<xref rid="btad096-F2" ref-type="fig">Fig. 2</xref>).</p>
      <fig position="float" id="btad096-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Comparison of methods for the benchmarking dataset. (<bold>a</bold>) Distributions of cross-correlation of reference samples within batches and between batches. The correlation was calculated for all samples of the same type. (<bold>b</bold>) Percent of samples with increased VCs upon normalization. (<bold>c</bold>) Mean batch VCs. (<bold>d</bold>) Centroided spectra. For comparison, initial and normalized peak intensities (<italic toggle="yes">y</italic>-axis) were scaled by <italic toggle="yes">z</italic>-score</p>
        </caption>
        <graphic xlink:href="btad096f2" position="float"/>
      </fig>
      <p>We found that three of seven methods improved the cross-correlation of replicates among batches: RALPS, NormAE and LEV+EIG (<xref rid="btad096-F2" ref-type="fig">Fig. 2a</xref>). In <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S5</xref>, the effect of normalization on cross-correlation is shown in detail for one of the samples that featured prominent bias effects, i.e. P1_FA_0008. This sample was an 8-fold diluted fatty acid mix that was strongly affected by the common background signal of fatty acids. For this example, RALPS and LEV+EIG achieved the best results, with correlation coefficients &gt;0.9. In the case of RALPS, a small bias between the first batch and all others remained. A different picture was obtained in terms of improving mean batch VCs. All methods except NormAE resulted in reduced mean batch variance (<xref rid="btad096-F2" ref-type="fig">Fig. 2b</xref>). However, LEV+EIG, EigenMS and PQN+POW each resulted in a drastic drop that suggests a degenerated solution. In practice, in the attempt to reduce batch effects, these methods also may attenuate biological differences and obscure the information of interest.</p>
      <p>The third quantitative evaluation criterion highlights a frequently overlooked caveat of normalization procedures: the fraction of sample whose VC increases by 5% or more upon normalization. The expectation is that normalization removes inter-batch biases without compromising intra-batch reproducibility. However, an apparent improvement in inter-batch reproducibility can also be attained by drastically worsening intra-batch precision, generally confounding all data and biological information. The criterion cutoff is arbitrary but provides a simple assessment for the frequency of variance inflation across features. We again found the best results with EigenMS, LEV+EIG and PQN+POW (<xref rid="btad096-F2" ref-type="fig">Fig. 2c</xref>). NormAE, meanwhile, inflated the VC in &gt;95% of the cases. RALPS fell in the middle average of the methods and outperformed ComBat and WaveICA. The striking difference between NormAE and RALPS highlights the relevance of the additional term <italic toggle="yes">L</italic><sub>v</sub> that was introduced in the loss function to control for an increase in variance.</p>
      <p>Lastly, we examined the MS spectra obtained by normalization. From an analytical standpoint, the expectation is that normalization will have a minor effect on the overall spectrum. In reality, this is the case only if the ranking of metabolites based on average intensities is roughly maintained. In contrast, a normalization procedure that has a large effect on the value ranges of features will result in a qualitatively different spectrum. Spectra preservation is particularly important if calibrants are included to estimate concentrations. By visual inspection of the resulting spectra (<xref rid="btad096-F2" ref-type="fig">Fig. 2d</xref>), we indeed observed that using methods with the lowest batch VCs (LEV+EIG and EigenMS) completely altered the data. NormAE preserved high-intensity peaks but suppressed low-intensity features, which is in agreement with the previously reported issue of sensitivity to outliers (<xref rid="btad096-B17" ref-type="bibr">Rong <italic toggle="yes">et al.</italic>, 2020</xref>). PQN+POW yielded the opposite pattern and amplified low-abundance ions. RALPS, WaveICA and ComBat had the most neutral impact on the spectra, preserving both high- and low-intensity features. Of note, WaveICA and ComBat, but not RALPS, can output negative ion intensity values, which can result in complications in downstream data analysis and interpretation. In summary, RALPS was the only method among the seven tested approaches to excel in the suppression of batch biases while controlling for mean batch variance, replicate VCs and drastic spectral transformation.</p>
    </sec>
    <sec>
      <title>2.5 RALPS corrects biases on multi-batch cancer cell metabolomics data</title>
      <p>We further tested the performance of RALPS with data published by <xref rid="btad096-B4" ref-type="bibr">Cherkaoui <italic toggle="yes">et al.</italic> (2021)</xref>. This dataset includes &gt;1400 untargeted metabolomics measurements for a panel of ca. 180 cancer cell lines, resulting in a matrix with relative abundances for 1817 putative metabolite ions. This dataset is interesting for three reasons. First, it represents real-life, mid-sized untargeted metabolomics studies. Second, its batch effects are associated with sample preparation and not with sample acquisition, as in the benchmarking dataset. This association is present because the limiting step in the study was sample generation and not MS analysis. Because of the tedious procedures necessary to cultivate numerous cell lines in parallel, the entire study was divided into seven batches of samples generated over the span of about a year. Upon preparation, cell pellets were stored at −80°C, and when the seven sampling batches were complete, all samples were prepared and subjected to sequential MS analysis. The expected batch effects thus are dominated by shifts in cultivation conditions (e.g. media, incubation conditions and handling). The third aspect of interest is that the study did not use a set of reference samples that were included in all batches. Only two cell lines (MDAMB231 and MCF7) were present in multiple batches (five and four, respectively) and were used as reference samples in the training phase of RALPS.</p>
      <p>As NormAE failed to complete normalization with the full dataset, we focused the comparison on the subset of ca. 170 features that were putatively annotated as deprotonated metabolites. All methods seemingly improved cross-correlation of the MDAMB231 sample, except for PQN+POW (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6a</xref>). Additional odd results included a mean batch variance that dropped to almost zero for LEV+EIG and almost doubled for NormAE (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6d</xref>). In line with the previous results, spectra were altered by LEV+EIG, EigenMS, PQN+POW and NormAE. Overall, RALPS and WaveICA were the best methods for normalizing the data from Cherkaoui <italic toggle="yes">et al.</italic> ComBat was also a good alternative, but the final cross-correlations of MDAMB231 across samples were worse, and more control samples would be needed for more precise conclusions. Among the three best methods, RALPS also appeared to better preserve low-intensity data. ComBat and WaveICA produced negative values that affected ca. 1% of the samples (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>). The normalized negative values exceeded 106 counts, resulting in obvious complications for further analysis and interpretation. In contrast, RALPS produced strictly positive values.</p>
      <p>Finally, we compared the evaluation times of all approaches (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref>). A single run of RALPS took about 3 min. A randomized grid search with 50 samples required about 2–3 h, which was similar to the time required by the slowest algorithms, such as NormAE (even using a GPU), EigenMS or LEV+EIG. However, the total processing time with RALPS can be easily reduced to less than an hour by employing four or more CPUs. We conclude that RALPS, ComBat and WaveICA showed overall competitive performance on the Cherkaoui <italic toggle="yes">et al.</italic> data. However, RALPS is the only method that combines top normalization performance with minimum biological information loss and preservation of spectral properties. A closer look at the UMAP embeddings of the normalized data produced by RALPS reveals that virtually all divisions across batches were successfully removed (<xref rid="btad096-F3" ref-type="fig">Fig. 3</xref>). Similar results were obtained when applying RALPS to the full dataset by Cherkaoui <italic toggle="yes">et al.</italic>, including adducts and features with poor annotation confidence (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S7</xref>).</p>
      <fig position="float" id="btad096-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>UMAP embeddings for the cancer cell lines dataset by Cherkaoui <italic toggle="yes">et al.</italic> Initial (left) versus normalized with RALPS (right) data is presented</p>
        </caption>
        <graphic xlink:href="btad096f3" position="float"/>
      </fig>
      <p>One important issue is the striking difference between NormAE and RALPS, which are both based on adversarial learning but yielded opposing results. In the Cherkaoui <italic toggle="yes">et al.</italic> data, NormAE reproducibly creates a collapsed solution driven by the growing classifier loss (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S8</xref>). This happens when the batches are already fairly mixed in the initial data and the classifier fails to tell them apart. The classifier loss grows and keeps contributing to the joint loss function of the autoencoder, which ultimately leads to a singular output matrix. In RALPS, this degenerate behavior is prevented by the early stopping.</p>
    </sec>
    <sec>
      <title>2.6 Top performance requires three-term loss function</title>
      <p>After demonstrating the performance of RALPS in practice, we set out to investigate in more detail how the regularization terms in the composite objective function (i.e. <italic toggle="yes">L</italic> in <xref rid="btad096-F1" ref-type="fig">Fig. 1</xref>) impact the outcomes. For this investigation, we used the benchmarking dataset and two reference sample groups (as in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>) and tested four scenarios of objective functions with 0–3 regularization terms (<xref rid="btad096-F4" ref-type="fig">Fig. 4a</xref>). For example, the case of <italic toggle="yes">λ</italic><sub>d</sub> = <italic toggle="yes">λ</italic><sub>g</sub> = <italic toggle="yes">λ</italic><sub>v</sub> = 0 corresponds to an autoencoder that is solely trained to reconstruct the data without any penalty. The last scenario with non-zero <italic toggle="yes">λ</italic><sub>d</sub>, <italic toggle="yes">λ</italic><sub>g</sub> and <italic toggle="yes">λ</italic><sub>v</sub> reflects the default architecture with all regularization terms. For each scenario, we applied RALPS with default parameters and performed a randomized grid search of size 100, selected the 10 top-performing normalization solutions and compared their key metrics (<xref rid="btad096-F4" ref-type="fig">Fig. 4a</xref>). As expected, introducing <italic toggle="yes">λ</italic><sub>g</sub> &gt; 0 improved tight clustering of reference samples in the embedded space. Introducing a penalty for the batch classifier with <italic toggle="yes">λ</italic><sub>d</sub> &gt; 0 had only subtle effects on tight clustering and replicate cross-correlation. Clearly, top performance on all three criteria shown is achieved only in combination with <italic toggle="yes">λ</italic><sub>v</sub> &gt; 0. These results indicate that the three terms in the composite objective function <italic toggle="yes">L</italic> of RALPS have a synergetic effect on batch normalization.</p>
      <fig position="float" id="btad096-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Ablation experiments. (<bold>a</bold>) Impact of regularization terms on key evaluation metrics. From left to right, an increasing number of terms were introduced. (<bold>b</bold>) Impact of the number of batches removed on the mean batch VC. (<bold>c</bold>) Impact of missing metabolites on the mean batch VC. (<bold>d</bold>) Impact of missing values on the mean cross-correlation of reference samples. (<bold>e</bold>) Impact of different values of <italic toggle="yes">variance_ratio</italic> parameter on the mean cross-correlation of reference samples</p>
        </caption>
        <graphic xlink:href="btad096f4" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.7 RALPS is robust against data ablations</title>
      <p>Missing values represent a particular challenge for normalization of untargeted metabolomics data. Values are missing when they are undetectable in a subset of samples, as is common for rare compounds, such as derivatives of drugs or special food additives in human serum, or low concentration compounds near the analytical limits of detection. To verify the robustness of RALPS, we performed multiple ablation experiments. All tests were done on the benchmarking dataset using default parameters and the same two reference sample groups as above. First, we ran RALPS on subsets of the initial dataset. We shrank the dataset batch-wise from seven to two (i.e. down to 29% of the samples) keeping the chronological acquisition order. On each iteration, we removed the latest batch and applied RALPS to normalize the remaining data. We observed that the mean batch VC was generally constant and comparable to the full data case (<xref rid="btad096-F4" ref-type="fig">Fig. 4b</xref>). We then shrank the dataset by removing random metabolites down to 10% of the initial number. Only in the last point, corresponding to 17 metabolites, did the mean batch variance tangibly worsen (<xref rid="btad096-F4" ref-type="fig">Fig. 4c</xref>).</p>
      <p>Next, we tested the robustness to randomly distributed missing values. A user-defined parameter (min_relevant_intensity) instructs RALPS on the lowest value to consider. The default is 1000 counts, and missing values are replaced with this minimum value. In our test, we replaced 0%, 5%, 10%, 15%, 20% and 30% randomly picked values in the data matrix with the default minimum value and then trained RALPS. We observed a decreasing trend in cross-correlation of replicates as the fraction of missing values went up (<xref rid="btad096-F4" ref-type="fig">Fig. 4d</xref>). However, the decrease in mean correlation coefficients was marginal (from 0.98 to 0.94 with 30% missing values), indicating that RALPS is generally robust against missing values.</p>
      <p>Finally, we verified how the number of neurons in model architectures affects normalization results. By default, RALPS uses as many neurons as number of principal components necessary to explain at least 90% of variance. We tested multiple values ranging from 99% to 70% variance. We did not observe any clear trends in any of four metrics used to evaluate and compare methods. The mean cross-correlation of replicates stayed above 0.98 in all cases (<xref rid="btad096-F4" ref-type="fig">Fig. 4e</xref>).</p>
    </sec>
  </sec>
  <sec>
    <title>3 Discussion</title>
    <p>We introduce RALPS, a novel batch normalization method based on regularized adversarial learning for untargeted metabolomics data. In this work, we demonstrated its performance on two representative datasets with thousands of samples or spectral features. The benchmarking dataset was generated to test the algorithm on MS data produced over several months. In the case of the cancer cell line data by Cherkaoui <italic toggle="yes">et al.</italic>, batches instead were associated with cultivation and sampling of samples over the span of almost a year, whereas MS analysis was done sequentially with all samples. We demonstrated that RALPS outperformed other state-of-the-art methods on several key metrics. RALPS offers additional features, such as adaptive network architectures, embedded hyperparameter optimization, automated model selection and input validation. Together, these features convey flexibility, scalability, usability and robustness as confirmed by testing with different configurations of reference samples and in ablation experiments.</p>
    <p>Historically, the loss function with three terms embedded in RALPS evolved from multiple tests, we performed with several datasets, some of which are not described here. The classification term is the component that drives the removal of batch effects. However, a deeper analysis of the resulting normalized data revealed novel problems that prompted us to introduce additional terms. The observed increase in VCs for supposedly identical samples (e.g. replicates) upon normalization is common to most methods and is a particularly acute problem for NormAE. To our best knowledge, this issue has not previously been acknowledged or addressed. We offer two hypothetical explanations for this gap. The first is the use of mean absolute error for the reconstruction loss, which is sensitive to outliers. The second is that generally increasing the noise, and thus the VC, makes it more difficult for the classifier to separate batches. Hence, there is an apparent beneficial effect on batch discrimination, but detrimental side effects in downstream analyses. Introducing the variation loss <italic toggle="yes">L</italic><sub>v</sub> mitigated but did not abolish the problem.</p>
    <p>A closer investigation of the RALPS results revealed that the increase in VC arose from a small set of samples (1.2–1.8% of the total for the tested datasets). Filtering these samples by outlier detection (explained below) reversed the increase in VCs for RALPS and EigenMS, but not for NormAE, ComBat, WaveICA and PQN+POW (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S9</xref>), suggesting that the latter methods produced even more outliers. We do not advocate for outlier detection and removal or a particular approach for it, but we recommend that researchers using batch normalization methods carefully evaluate sample-wise VCs and consider correcting them before performing downstream statistical analysis.</p>
    <p>The grouping regularization term <italic toggle="yes">r</italic><sub>g</sub> was the second novel addition to the adversarial training and the key to preserving similarity of supposedly equal samples. Although RALPS relies on clustering of reference samples in the embedded space to assess grouping, alternative approaches could be considered. For example, <italic toggle="yes">r</italic><sub>g</sub> could be calculated from distances in the latent space. Distance-based metrics would carry several hypothetical advantages and pitfalls. Owing to the fast computation, training would be tangibly shorter than with clustering. We expect that distance-based metrics would perform better with data characterized by subtle batch effects in which clustering fails to separate reference samples. Even in the case of all replicates falling into a single cluster (which happens naturally when most batch effects have been already removed), minimizing distances between all pairs of replicates would still have a regularization effect, whereas clustering would not. Among the potential drawbacks, we would expect an increased sensitivity to single outliers. Alternative paradigms for similarity preservation should be tested in the future. One additional aspect that could be optimized is the clustering algorithm. RALPS includes six methods, and HDBSCAN was chosen as the default based on performance, robustness and speed (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S10</xref>). The outcome might differ for different experiments.</p>
    <p>In terms of experimental design, RALPS requires reference samples across batches, but it is not strictly necessary to have the very same reference samples present in all batches. We illustrated this flexibility in our normalization of the Cherkaoui <italic toggle="yes">et al.</italic> data, in which two reference sample groups were present in only four and five of the seven batches, respectively. This feature leaves considerable freedom for the experimental design, in particular for the number of replicate groups to include. Based on our tests with the benchmarking dataset and other studies not shown here, using replicates from a pooled study sample in each batch is generally sufficient to correct for typical batch biases arising from untargeted metabolomics measurements performed over different days. If the total number of samples does not become prohibitively large, including a second group of reference samples is beneficial. In this scenario, the recommendation is to spike in a reduced set of compounds of interest and at low concentrations to present a realistic challenge for calculating the grouping term <italic toggle="yes">r</italic><sub>g</sub>. In contrast, blanks do not constitute a good control group because they can readily be distinguished from all other samples and are ineffective in the training process. The flexibility of RALPS allows it to be tested on existing datasets or applied in experiments that were not specifically designed with its use in mind. In all cases, RALPS is developed to make full use of all available reference samples in correcting inter-batch experiments.</p>
    <p>In the case of multi-batch experiments that are affected both by inter and intra-batch issues, such as excessive sample-to-sample variability or temporal drifts, we recommend a two-step procedure. First, all single batches should be corrected individually to maximize coherence within each individual batch. Second, RALPS should be applied to harmonize data across batches.</p>
    <p>Finally, we see no fundamental problem in using RALPS to normalize any kind of tabular data consisting of samples coming from different batches and with features characterizing the samples. Information about the similarity of samples (for references and beyond) can be encoded via groups in the batch information file. We encourage researchers from other omics fields to challenge RALPS with their own data and drive its further development by reporting experience and issues in the repository.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btad096_Supplementary_Data</label>
      <media xlink:href="btad096_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Funding</title>
    <p>This work was supported by grants from the Strategic Focal Area Personalized Health and Related Technologies (PHRT) of the ETH Domain.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btad096-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alseekh</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Mass spectrometry-based metabolomics: a guide for annotation, quantification and best reporting practices</article-title>. <source>Nat. Methods</source>, <volume>18</volume>, <fpage>747</fpage>–<lpage>756</lpage>.<pub-id pub-id-type="pmid">34239102</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bhojanapalli</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>On the reproducibility of neural network predictions</article-title>. arXiv:2102.03349, <fpage>1</fpage>–<lpage>19</lpage>.</mixed-citation>
    </ref>
    <ref id="btad096-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Broadhurst</surname><given-names>D.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Guidelines and considerations for the use of system suitability and quality control samples in mass spectrometry assays applied in untargeted clinical metabolomic studies</article-title>. <source>Metabolomics</source>, <volume>14</volume>, <fpage>1</fpage>–<lpage>17</lpage>.<pub-id pub-id-type="pmid">29249916</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B4">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Cherkaoui</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) A functional analysis of 180 cancer cell lines reveals conserved intrinsic metabolic programs. <italic toggle="yes">Mol. Syst. Biol.</italic>, <bold>18</bold>(11), e11033.</mixed-citation>
    </ref>
    <ref id="btad096-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deng</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>WaveICA: a novel algorithm to remove batch effects for large-scale untargeted metabolomics data based on wavelet analysis</article-title>. <source>Anal. Chim. Acta</source>, <volume>1061</volume>, <fpage>60</fpage>–<lpage>69</lpage>.<pub-id pub-id-type="pmid">30926040</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dieterle</surname><given-names>F.</given-names></string-name></person-group><etal>et al</etal> (<year>2006</year>) <article-title>Probabilistic quotient normalization as robust method to account for dilution of complex biological mixtures. Application in <sup>1</sup>H NMR metabonomics</article-title>. <source>Anal. Chem</source>., <volume>78</volume>, <fpage>4281</fpage>–<lpage>4290</lpage>.<pub-id pub-id-type="pmid">16808434</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dunn</surname><given-names>W.B.</given-names></string-name></person-group><etal>et al</etal>; <collab>Human Serum Metabolome (HUSERMET) Consortium</collab>. (<year>2011</year>) <article-title>Procedures for large-scale metabolic profiling of serum and plasma using gas chromatography and liquid chromatography coupled to mass spectrometry</article-title>. <source>Nat. Protoc</source>., <volume>6</volume>, <fpage>1060</fpage>–<lpage>1083</lpage>.<pub-id pub-id-type="pmid">21720319</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname><given-names>C.H.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>Metabolomics: beyond biomarkers and towards mechanisms</article-title>. <source>Nat. Rev. Mol. Cell Biol</source>., <volume>17</volume>, <fpage>451</fpage>–<lpage>459</lpage>.<pub-id pub-id-type="pmid">26979502</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname><given-names>W.E.</given-names></string-name></person-group><etal>et al</etal> (<year>2007</year>) <article-title>Adjusting batch effects in microarray expression data using empirical Bayes methods</article-title>. <source>Biostatistics</source>, <volume>8</volume>, <fpage>118</fpage>–<lpage>127</lpage>.<pub-id pub-id-type="pmid">16632515</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Karpievitch</surname><given-names>Y.V.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) <article-title>Metabolomics data normalization with EigenMS</article-title>. <source>PLoS One</source>, <volume>9</volume>, <fpage>e116221</fpage>.<pub-id pub-id-type="pmid">25549083</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kuligowski</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) <article-title>Intra-batch effect correction in liquid chromatography-mass spectrometry using quality control samples and support vector regression (QC-SVRC)</article-title>. <source>Analyst</source>, <volume>140</volume>, <fpage>7810</fpage>–<lpage>7817</lpage>.<pub-id pub-id-type="pmid">26462549</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lakkis</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>A joint deep learning model enables simultaneous batch effect correction, denoising and clustering in single-cell transcriptomics</article-title>. <source>Genome Res</source>., <volume>31</volume>, <fpage>1753</fpage>–<lpage>1766</lpage>.<pub-id pub-id-type="pmid">34035047</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Deep learning enables accurate clustering with batch effect removal in single-cell RNA-seq analysis</article-title>. <source>Nat. Commun</source>., <volume>11</volume>, <fpage>1</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">31911652</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Malzer</surname><given-names>C.</given-names></string-name>, <string-name><surname>Baum</surname><given-names>M.</given-names></string-name></person-group> (<year>2020</year>) A hybrid approach to hierarchical density-based cluster selection. In: <italic toggle="yes">IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems</italic>, Karlsruhe, Germany, pp. <fpage>223</fpage>–<lpage>228</lpage>.</mixed-citation>
    </ref>
    <ref id="btad096-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>McInnes</surname><given-names>L.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>UMAP: uniform manifold approximation and projection for dimension reduction</article-title>. arXiv:1802.03426</mixed-citation>
    </ref>
    <ref id="btad096-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Patti</surname><given-names>G.J.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>Metabolomics: the apogee of the omics trilogy</article-title>. <source>Nat. Rev. Mol. Cell Biol</source>., <volume>13</volume>, <fpage>263</fpage>–<lpage>269</lpage>.<pub-id pub-id-type="pmid">22436749</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rong</surname><given-names>Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>NormAE: deep adversarial learning model to remove batch effects in liquid chromatography mass spectrometry-based metabolomics data</article-title>. <source>Anal. Chem</source>., <volume>92</volume>, <fpage>5082</fpage>–<lpage>5090</lpage>.<pub-id pub-id-type="pmid">32207605</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rusilowicz</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>A batch correction method for liquid chromatography–mass spectrometry data that does not depend on quality control samples</article-title>. <source>Metabolomics</source>, <volume>12</volume>, <fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation>
    </ref>
    <ref id="btad096-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schatschneider</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Quantitative isotope-dilution high-resolution-mass-spectrometry analysis of multiple intracellular metabolites in <italic toggle="yes">Clostridium autoethanogenum</italic> with uniformly <sup>13</sup>C-labeled standards derived from spirulina</article-title>. <source>Anal. Chem</source>., <volume>90</volume>, <fpage>4470</fpage>–<lpage>4477</lpage>.<pub-id pub-id-type="pmid">29533656</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sysi-Aho</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2007</year>) <article-title>Normalization method for metabolomics data using optimal selection of multiple internal standards</article-title>. <source>BMC Bioinformatics</source>, <volume>8</volume>, <fpage>1</fpage>–<lpage>17</lpage>.<pub-id pub-id-type="pmid">17199892</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>BERMUDA: a novel deep transfer learning method for single-cell RNA sequencing batch correction reveals hidden high-resolution cellular subtypes</article-title>. <source>Genome Biol</source>., <volume>20</volume>, <fpage>1</fpage>–<lpage>15</lpage>.<pub-id pub-id-type="pmid">30606230</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>L.</given-names></string-name></person-group><etal>et al</etal> (<year>2005</year>) <article-title>Quantitative analysis of the microbial metabolome by isotope dilution mass spectrometry using uniformly <sup>13</sup>C-labeled cell extracts as internal standards</article-title>. <source>Anal. Biochem</source>., <volume>336</volume>, <fpage>164</fpage>–<lpage>171</lpage>.<pub-id pub-id-type="pmid">15620880</pub-id></mixed-citation>
    </ref>
    <ref id="btad096-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Q.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>NOREVA: enhanced normalization and evaluation of time-course and multi-class metabolomic data</article-title>. <source>Nucleic Acids Res</source>., <volume>48</volume>, <fpage>W436</fpage>–<lpage>W448</lpage>.<pub-id pub-id-type="pmid">32324219</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
