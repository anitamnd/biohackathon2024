<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Nat Commun</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id>
    <journal-title-group>
      <journal-title>Nature Communications</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2041-1723</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9258765</article-id>
    <article-id pub-id-type="publisher-id">31511</article-id>
    <article-id pub-id-type="doi">10.1038/s41467-022-31511-0</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Deep learning from phylogenies to uncover the epidemiological dynamics of outbreaks</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Voznica</surname>
          <given-names>J.</given-names>
        </name>
        <address>
          <email>voznica.jakub@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Zhukova</surname>
          <given-names>A.</given-names>
        </name>
        <address>
          <email>anna.zhukova@pasteur.fr</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Boskova</surname>
          <given-names>V.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff7">7</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Saulnier</surname>
          <given-names>E.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9576-4449</contrib-id>
        <name>
          <surname>Lemoine</surname>
          <given-names>F.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Moslonka-Lefebvre</surname>
          <given-names>M.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9412-9723</contrib-id>
        <name>
          <surname>Gascuel</surname>
          <given-names>O.</given-names>
        </name>
        <address>
          <email>olivier.gascuel@mnhn.fr</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff8">8</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.508487.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 7885 7602</institution-id><institution>Institut Pasteur, </institution><institution>Université Paris Cité, Unité Bioinformatique Evolutive, </institution></institution-wrap>Paris, France </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.508487.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 7885 7602</institution-id><institution>Université de Paris, </institution></institution-wrap>Paris, France </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.508487.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 7885 7602</institution-id><institution>Institut de Biologie de l’École Normale Supérieure, Ecole Normale Supérieure, CNRS, INSERM, </institution><institution>Université Paris Sciences et Lettres, </institution></institution-wrap>Paris, France </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.508487.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 7885 7602</institution-id><institution>Institut Pasteur, </institution><institution>Université Paris Cité, Bioinformatics and Biostatistics Hub, </institution></institution-wrap>Paris, France </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="GRID">grid.508487.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 7885 7602</institution-id><institution>Institut Pasteur, </institution><institution>Université Paris Cité, Epidemiology and Modelling of Antibiotic Evasion, </institution></institution-wrap>Paris, France </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="GRID">grid.463845.8</institution-id><institution-id institution-id-type="ISNI">0000 0004 0638 6872</institution-id><institution>Université Paris-Saclay, UVSQ, Inserm, CESP, </institution></institution-wrap>Villejuif, France </aff>
      <aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="GRID">grid.22937.3d</institution-id><institution-id institution-id-type="ISNI">0000 0000 9259 8492</institution-id><institution>Center for Integrative Bioinformatics Vienna, Max Perutz Labs, </institution><institution>University of Vienna and Medical University of Vienna, </institution></institution-wrap>Vienna, Austria </aff>
      <aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="GRID">grid.463994.5</institution-id><institution-id institution-id-type="ISNI">0000 0004 0370 7618</institution-id><institution>Institut de Systématique, Evolution, Biodiversité (UMR 7205 - CNRS, Muséum National d’Histoire Naturelle, SU, EPHE, UA), </institution></institution-wrap>Paris, France </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>6</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>6</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>13</volume>
    <elocation-id>3896</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>3</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>21</day>
        <month>6</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Widely applicable, accurate and fast inference methods in phylodynamics are needed to fully profit from the richness of genetic data in uncovering the dynamics of epidemics. Standard methods, including maximum-likelihood and Bayesian approaches, generally rely on complex mathematical formulae and approximations, and do not scale with dataset size. We develop a likelihood-free, simulation-based approach, which combines deep learning with (1) a large set of summary statistics measured on phylogenies or (2) a complete and compact representation of trees, which avoids potential limitations of summary statistics and applies to any phylodynamics model. Our method enables both model selection and estimation of epidemiological parameters from very large phylogenies. We demonstrate its speed and accuracy on simulated data, where it performs better than the state-of-the-art methods. To illustrate its applicability, we assess the dynamics induced by superspreading individuals in an HIV dataset of men-having-sex-with-men in Zurich. Our tool PhyloDeep is available on <ext-link ext-link-type="uri" xlink:href="http://github.com/evolbioinfo/phylodeep">github.com/evolbioinfo/phylodeep</ext-link>.</p>
    </abstract>
    <abstract id="Abs2" abstract-type="web-summary">
      <p id="Par2">Widely applicable, accurate and fast inference methods in phylodynamics are needed to fully profit from the richness of genetic data in uncovering the dynamics of epidemics. Here, the authors develop a likelihood-free, simulation-based deep learning approach.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Phylogeny</kwd>
      <kwd>Machine learning</kwd>
      <kwd>Statistical methods</kwd>
      <kwd>Viral infection</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100001665</institution-id>
            <institution>Agence Nationale de la Recherche (French National Research Agency)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>ANR-19-P3IA-0001</award-id>
        <principal-award-recipient>
          <name>
            <surname>Gascuel</surname>
            <given-names>O.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par3">Pathogen phylodynamics is a field combining phylogenetics and epidemiology<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Viral or bacterial samples from patients are sequenced and used to infer a phylogeny, which describes the pathogen’s spread among patients. The tips of such phylogenies represent sampled pathogens, and the internal nodes transmission events. Moreover, transmission events can be dated and thereby provide hints on transmission patterns. Such information is extracted by phylodynamic methods to estimate epidemiological and population dynamic parameters<sup><xref ref-type="bibr" rid="CR2">2</xref>–<xref ref-type="bibr" rid="CR4">4</xref></sup>, assess the impact of population structure<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR5">5</xref></sup>, and reveal the origins of epidemics<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>.</p>
    <p id="Par4">Birth-death models<sup><xref ref-type="bibr" rid="CR7">7</xref></sup> incorporate easily interpretable parameters common to standard infectious-disease epidemiology, such as basic reproduction number R<sub>0</sub>, infectious period, etc. In contrast to the standard epidemiological models, the birth-death models can be applied to estimate parameters from phylogenetic trees<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. In these models, births represent transmission events, while deaths represent removal events for example due to treatment or recovery. Upon a patient’s removal, their pathogens can be sampled, producing tips in the tree.</p>
    <p id="Par5">Here we focus on three specific, well-established birth-death models (Fig. <xref rid="Fig1" ref-type="fig">1</xref>): birth-death model (BD)<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR9">9</xref></sup>, birth-death model with exposed and infectious classes (BDEI)<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR11">11</xref></sup>, and birth-death model with superspreading (BDSS)<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR12">12</xref></sup>. These models were deployed using BEAST2<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup> to study the phylodynamics of such diverse pathogens as Ebola virus<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>, Influenza virus<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, Human Immunodeficiency Virus (HIV)<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>, Zika<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> or SARS-CoV-2<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. Using these models, we will demonstrate the reliability of our deep learning-based approach.<fig id="Fig1"><label>Fig. 1</label><caption><title>Birth-death models.</title><p><bold>a</bold> Birth-death model (BD)<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR9">9</xref></sup>, <bold>b</bold> birth-death model with Exposed-Infectious individuals (BDEI)<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR11">11</xref></sup> and <bold>c</bold> birth-death model with SuperSpreading (BDSS)<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR12">12</xref></sup>. BD is the simplest generative model, used to estimate R<sub>0</sub> and the infectious period (1/γ)<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR9">9</xref></sup>. BDEI and BDSS are extended version of BD. BDEI enables to estimate latency period (1/ε) during which individuals of exposed class E are infected, but not infectious<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR11">11</xref></sup>. BDSS includes two populations with heterogeneous infectiousness: the so-called superspreading individuals (S) and normal spreaders (N). Superspreading individuals are present only at a low fraction in the population (f<sub>ss</sub>) and may transmit the disease at a rate that is multiple times higher than that of normal spreaders (rate ratio = X<sub>ss</sub>)<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR12">12</xref></sup>. Superspreading can have various complex causes, such as the heterogeneity of immune response, disease progression, co-infection with other diseases, social contact patterns or risk behaviour, etc. Infectious individuals I (superspreading infectious individuals I<sub>S</sub> and normal spreaders I<sub>N</sub> for BDSS), transmit the disease at rate β (β<sub>X,Y</sub> for an individual of type X transmitting to an individual of type Y for BDSS), giving rise to a newly infected individual. The newly infected individual is either infectious right away in BD and BDSS or goes through an exposed state before becoming infectious at rate ε in BDEI. Infectious individuals are removed at rate γ. Upon removal, they can be sampled with probability <italic>s</italic>, becoming of removed sampled class R. If not sampled upon removal, they move to non-infectious unsampled class U.</p></caption><graphic xlink:href="41467_2022_31511_Fig1_HTML" id="d32e554"/></fig></p>
    <p id="Par6">While a great effort has been invested in the development of new epidemiological models in phylodynamics, the field has been slowed down by the mathematical complexity inherent to these models. BD, the simplest model, has a closed-form solution for the likelihood formula of a tree for a given set of parameters<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR10">10</xref></sup>, but more complex models (e.g., BDEI and BDSS) rely on a set of ordinary differential equations (ODEs) that cannot be solved analytically. To estimate parameter values through maximum-likelihood and Bayesian approaches, these ODEs must be approximated numerically for each tree node<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR10">10</xref>–<xref ref-type="bibr" rid="CR12">12</xref></sup>. These calculations become difficult as the tree size increases, resulting in numerical instability and inaccuracy<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, as we will see below.</p>
    <p id="Par7">Inference issues with complex models are typically overcome by approximate Bayesian computation (ABC)<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR17">17</xref></sup>. ABC is a simulation-based technique relying on a rejection algorithm<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>, where from a set of simulated phylogenies within a given prior (values assumed for the parameter values), those closest to the analysed phylogeny are retained and give the posterior distribution of the parameters. This scheme relies on the definition of a set of summary statistics aimed at representing a phylogeny and on a distance measure between trees. The ABC approach is thus sensitive to the choice of the summary statistics and distance function (e.g., Euclidean distance). To address this issue Saulnier et al.<sup><xref ref-type="bibr" rid="CR19">19</xref></sup> developed a large set of summary statistics. In addition, they used a regression step to select the most relevant statistics and to correct for the discrepancy between the simulations retained in the rejection step and the analysed phylogeny. They observed that the sensitivity to the rejection parameters were greatly attenuated thanks to regression (see also Blum et al.<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>).</p>
    <p id="Par8">Our work is a continuation of regression-based ABC, and aims at overcoming its main limitations. Using the approximation power of currently available neural network architectures, we propose a likelihood-free method relying on deep learning from millions of trees of varying size simulated within a broad range of parameter values. By doing so, we bypass the rejection step, which is both time-consuming with large simulation sets, and sensitive to the choice of the distance function and summary statistics. To describe simulated trees and use them as input for the deep learner, we develop two tree representations: (1) a large set of summary statistics mostly based on Saulnier et al.<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>, and (2) a complete and compact vectorial representation of phylogenies, including both the tree topology and branch lengths. The summary statistics are derived from our understanding and knowledge of the epidemiological processes. However, they can be incomplete and thus miss some important aspects of the studied phylogenies, which can potentially result in low accuracy during inference. Moreover, it is expected that new phylodynamic models will require design of new summary statistics, as confirmed by our results with BDSS. In contrast, our vectorial representation is a raw data representation that preserves all information contained in the phylogeny and thus should be accurate and deployable on any new model, provided the model parameters are identifiable. Our vectorial representation naturally fits with deep learning methods, especially the convolutional architectures, which have already proven their ability to extract relevant features from raw representations, for example in image analysis<sup><xref ref-type="bibr" rid="CR21">21</xref>,<xref ref-type="bibr" rid="CR22">22</xref></sup> or weather prediction<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>.</p>
    <p id="Par9">In the following, we introduce our vectorial tree representation and the new summary statistics designed for BDSS. We then present the deep learning architectures trained on these representations and evaluate their accuracy on simulated datasets in terms of both parameter estimation and model selection. We show that our approach applies not only to trees of the same size as the training instances, but also to very large trees with thousands of tips through the analysis of their subtrees. The results are compared to those of the gold standard method, BEAST2<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup>. Lastly, we showcase our methods on an HIV dataset<sup><xref ref-type="bibr" rid="CR24">24</xref>,<xref ref-type="bibr" rid="CR25">25</xref></sup> from the men-having-sex-with-men (MSM) community from Zurich. All technical details are provided in ‘Methods’ and <xref rid="MOESM1" ref-type="media">Supplementary Information</xref>. Our methods and tools are implemented in the PhyloDeep software, which is available on GitHub (github.com/evolbioinfo/phylodeep), PyPi (pypi.org/project/phylodeep) and Docker Hub (hub.docker.com/r/evolbioinfo/phylodeep).</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <p id="Par10">Neural networks are trained on numerical vectors from which they can learn regression and classification tasks. We trained such networks on phylogenetic trees to estimate epidemiological parameters (regression) and select phylodynamic models (classification). We undertook two strategies for representing phylogenetic trees as numerical vectors, which we describe first, before showing the results with simulated and real data.</p>
    <sec id="Sec3">
      <title>Summary statistics (SS) representation</title>
      <p id="Par11">We used a set of 83 SS developed by Saulnier et al.<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>: 26 measures of branch lengths, such as median of both internal and tip branch lengths; 8 measures of tree topology, such as tree imbalance; 9 measures on the number of lineages through time, such as time and height of its maximum; and 40 coordinates representing the lineage-through-time (LTT) plot. To capture more information on the phylogenies generated by the BDSS model, we further enriched these SS with 14 new statistics on transmission chains describing the distribution of the duration between consecutive transmissions (internal tree nodes). Our SS are diverse, complementary and somewhat redundant. We used feed-forward neural networks (FFNN) with several hidden layers (Fig. <xref rid="Fig2" ref-type="fig">2b (i)</xref>) that select and combine relevant information from the input features. In addition to SS, we provide both the tree size (i.e., number of tips) and the sampling probability used to generate the tree, as input to our FFNN (Fig. <xref rid="Fig2" ref-type="fig">2a (vi)</xref>). We will refer to this method as FFNN-SS.<fig id="Fig2"><label>Fig. 2</label><caption><title>Pipeline for training neural networks on phylogenies.</title><p>Tree representations: <bold>a</bold> (i), simulated binary trees. Under each model from Fig. <xref rid="Fig1" ref-type="fig">1</xref>, we simulate many trees of variable size (50 to 200 tips for ‘small trees’ and 200 to 500 tips for ‘large trees’). For illustration, we have here a tree with 5 tips. We encode the simulations into two representations, either <bold>a</bold> (ii–v), in a complete and compact tree representation called ‘Compact Bijective Ladderized Vector’ abbreviated as CBLV or <bold>a</bold> (vi) with summary statistics (SS). CBLV is obtained through <bold>a</bold> (ii) ladderization or sorting of internal nodes so that the branch supporting the most recent leaf is always on the left and <bold>a</bold> (iii) an inorder tree traversal, during which we append to a real-valued vector for each visited internal node its distance to the root and for each visited tip its distance to the previously visited internal node. We reshape this representation into <bold>a</bold> (iv), an input matrix in which the information on internal nodes and leaves is separated into two rows. Finally, <bold>a</bold> (v), we complete this matrix with zeros so that the matrices for all simulations have the size of largest simulation matrices. For illustration purpose, we here consider that the maximum tree size covered by simulations is 10, and the representation is thus completed with 0 s accordingly. SS consists of <bold>a</bold> (vi), a set of 98 statistics: 83 published in Saulnier et al.<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>, 14 on transmission chains and 1 on tree size. The information on sampling probability is added to both representations. <bold>b</bold> Neural networks are trained on these representations to estimate parameter values or to select the underlying model. For SS, we use, <bold>b</bold> (i), a deep feed-forward neural network (FFNN) of funnel shape (we show the number of neurons above each layer). For the CBLV representation we train, <bold>b</bold> (ii), convolutional neural networks (CNN). The CNN is added on top of the FFNN. The CNN combines convolutional, maximum pooling and global average pooling layers, as described in detail in ‘Methods’ and <xref rid="MOESM1" ref-type="media">Supplementary Information</xref>.</p></caption><graphic xlink:href="41467_2022_31511_Fig2_HTML" id="d32e710"/></fig></p>
    </sec>
    <sec id="Sec4">
      <title>Compact vectorial tree representation</title>
      <p id="Par12">While converting raw information in the form of a phylogenetic tree into a set of SS, information loss is unavoidable. This means not only that the tree cannot be fully reconstructed from its SS, but also that depending on how much useful and relevant information is contained in the SS, the neural network may fail to solve the problem at hand. As an alternative strategy to SS, and to prevent information loss in the tree representation, we developed a representation called ‘Compact Bijective Ladderized Vector’ (CBLV).</p>
      <p id="Par13">Several vectorial representations of trees based either on polynomial<sup><xref ref-type="bibr" rid="CR26">26</xref>,<xref ref-type="bibr" rid="CR27">27</xref></sup>, Laplacian spectrum<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> or F matrices<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> have been developed previously. However, they represent the tree shape but not the branch lengths<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> or may lose information on trees<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. In addition, some of these representations require vectors or matrices of quadratic size with respect to the number of tips<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>, or are based on complex coordinate systems of exponential size<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>.</p>
      <p id="Par14">Inspired by these approaches, we designed our concise, easily computable, compact, and bijective (i<italic>.</italic>e. 1-to-1) tree representation that applies to trees of variable size and is appropriate as machine learning input. To obtain this representation, we first ladderize the tree, that is, for each internal node, the descending subtree containing the most recently sampled tip is rotated to the left, Fig. <xref rid="Fig2" ref-type="fig">2a (ii)</xref>. This ladderization step does not change the tree but facilitates learning by standardizing the input data. Moreover, it is consistent with trees observed in real epidemiological datasets, for example Influenza, where ladder-like trees reflect selection and are observed for several pathogens<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Then, we perform an inorder traversal<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> of the ladderized tree, during which we collect in a vector for each visited internal node its distance to the root and for each tip its distance to the previously visited internal node. In particular, the first vector entry corresponds to the tree height. This transformation of a tree into a vector is bijective, in the sense that we can unambiguously reconstruct any given tree from its vector representation (Supplementary Fig. <xref rid="MOESM1" ref-type="media">1</xref>). The vector is as compact as possible, and its size grows linearly with the number of tips. We complete this vector with zeros to reach the representation length of the largest tree contained in our simulation set, and we add the sampling probability used to generate the tree (or an estimate of it when analysing real data; Fig. <xref rid="Fig2" ref-type="fig">2a (v), b (i)</xref>).</p>
      <p id="Par15">Bijectivity combined with ladderization facilitates the training of neural networks, which do not need to learn that different representations correspond to the same tree. However, unlike our SS, this full representation does not have any high-level features. In CBLV identical subtrees will have the same representation in the vector whenever the roots of these subtrees have the same height, while the vector representation of the tips in such subtrees will be the same no matter the height of the subtree’s root. Similar subtrees will thus result in repeated patterns along the representation vector. We opted for convolutional neural networks (CNN), which are designed to extract information on patterns in raw data. Our CNN architecture (Fig. <xref rid="Fig2" ref-type="fig">2b (ii)</xref>) includes several convolutional layers that perform feature extraction, as well as maximum and average pooling layers that select relevant features and keep feature maps of reasonable dimensions. The output of the CNN is then fed into a FFNN that combines the patterns found in the input to perform predictions. In the rest of the manuscript, we refer to this method as CNN-CBLV.</p>
    </sec>
    <sec id="Sec5">
      <title>Simulated datasets</title>
      <p id="Par16">For each phylodynamic model (BD, BDEI, BDSS), we simulated 4 million trees, covering a large range of values for each parameter of epidemiological interest (R<sub>0</sub>, infectious period: 1/γ, incubation period: 1/ε, the fraction at equilibrium of superspreading individuals: f<sub>SS</sub>, and the superspreading transmission ratio: X<sub>SS</sub>). Of the 4 million trees, 3.99 million were used as a training set, and 10,000 as a validation set for early stopping in the training phase<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>. In addition, we simulated another 10,000 trees, which we used as a testing set, out of which 100 were also evaluated with the gold standard methods, BEAST2 and TreePar, which are more time-consuming. Another 1 million trees were used to define confidence intervals for estimated parameters. For BD and BDEI we considered two settings: one with small trees (50 to 199 tips, in Supplementary Fig. <xref rid="MOESM1" ref-type="media">2</xref>) and a second with large trees (200 to 500 tips, Fig. <xref rid="Fig3" ref-type="fig">3</xref>). For BDSS, we considered only the setting with large trees, as the superspreading individuals are at a low fraction and cannot be detected in small trees. Lastly, we investigated the applicability of our approach to very large datasets, which are increasingly common with viral pathogens. To this goal, we generated for each model 10,000 ‘huge’ trees, with 5000 to 10,000 tips each and with the same parameter ranges as used with the small and large trees. To estimate the parameter values of a huge tree, we extracted a nearly complete coverage of this tree by disjoint subtrees with 50 to 500 leaves. Then, we predicted the parameter values for every subtree using our NNs, and averaged subtree predictions to obtain parameter estimates for the huge tree.<fig id="Fig3"><label>Fig. 3</label><caption><title>Assessment of deep learning accuracy.</title><p>Comparison of inference accuracy by BEAST2 (in blue), deep neural network trained on SS (in orange) and convolutional neural network trained on the CBLV representation (in green) on 100 test trees. The size of training and testing trees was uniformly sampled between 200 and 500 tips. We show the relative error for each test tree. The error is measured as the normalized distance between the median a posteriori estimate by BEAST2 or point estimates by neural networks and the target value for each parameter. We highlight simulations for which BEAST2 did not converge and whose values were thus set to median of the parameter subspace used for simulations, by depicting them as red squares. We further highlight the analyses with a high relative error (&gt;1.00) for one of the estimates, as black diamonds. We compare the relative errors for <bold>a</bold> BD-simulated, <bold>b</bold> BDEI-simulated and <bold>c</bold> BDSS-simulated trees. Average relative error is displayed for each parameter and method in corresponding colour below each figure. The average error of a FFNN trained on summary statistics but with randomly permuted target is displayed as black dashed line and its value is shown in bold black below the x-axis. The accuracy of each method is compared by two-sided paired z-test; <italic>P</italic> &lt; 0.05 is shown as thick full line; non-significant is not shown.</p></caption><graphic xlink:href="41467_2022_31511_Fig3_HTML" id="d32e825"/></fig></p>
      <p id="Par17">To increase the generality of our approach and avoid the arbitrary choice of the time scale (one unit can be a day, a week, or a year), we rescaled all trees and corresponding epidemiological parameters, such that the average branch length in a tree was equal to 1. After inference, we rescaled the estimated parameter values back to the original time scale.</p>
    </sec>
    <sec id="Sec6">
      <title>Neural networks yield more accurate parameter estimates than gold standard methods</title>
      <p id="Par18">We compared accuracy of parameter estimates yielded by our deep learning methods and those yielded by two state-of-the-art phylodynamics inference tools, BEAST2<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup> and TreePar<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>. The comparison shows that our deep learning methods trained with SS and CBLV are either comparable (BD) or more accurate (BDEI and BDSS) than the state-of-the-art inference methods (Fig. <xref rid="Fig3" ref-type="fig">3</xref>, <xref rid="MOESM1" ref-type="media">Supplementary Table 1</xref>). The simple BD model has a closed-form solution for the likelihood function, and thus BEAST2 results are optimal in theory<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR9">9</xref></sup>. Our results with BD are similar to those obtained with BEAST2, and thus nearly optimal as well. For BDEI and BDSS our results are more accurate than BEAST2, which is likely explained by numerical approximations of likelihood calculations in BEAST2<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR11">11</xref></sup> for these models. These approximations can lead BEAST2 to a lack of convergence (2% cases for BDEI and 15% cases for BDSS) or a convergence to local optima. We suspect BEAST2 of converging to local optima when it converged to values with high relative error (&gt;1.0; 8% cases for BDEI and 11% cases for BDSS, Fig. <xref rid="Fig3" ref-type="fig">3b, c</xref>). Furthermore, our deep learning approaches showed a lower bias in parameter estimation than BEAST2 (<xref rid="MOESM1" ref-type="media">Supplementary Table 2</xref>). As expected, both approaches, FFNN-SS and CNN-CBLV, get more accurate with larger trees (Supplementary Fig. <xref rid="MOESM1" ref-type="media">3</xref>).</p>
      <p id="Par19">We tried to perform maximum-likelihood estimation (MLE) implemented in the TreePar package<sup><xref ref-type="bibr" rid="CR5">5</xref></sup> on the same trees as well. While MLE under BD model on simulations yielded as accurate results as BEAST2, for more complex models it showed overflow and underflow issues (i.e., reaching infinite values of likelihood) and yielded inaccurate results, such as more complex models (BDEI, BDSS) having lower likelihood than a simpler, nested one (BD) for a part of simulations. These issues were more prominent for larger trees. TreePar developers confirmed these limitations and suggested using the latest version of BEAST2 instead.</p>
      <p id="Par20">To further explain the performance of our NNs, we computed the likelihood value of their parameter estimates. This was easy with the BD model since we have a closed-form solution for the likelihood function. The results with this model (<xref rid="MOESM1" ref-type="media">Supplementary Table 3</xref>, using TreePar) showed that the likelihoods of both FFNN-SS and CNN-CBLV estimates are similar to BEAST2’s, which explains the similar accuracy of the three methods (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). We also computed the likelihood of the ‘true’ parameter values used to simulate the trees, in order to have an independent and solid assessment. If a given method tends to produce higher likelihood than that of the true parameter values, then it performs well in terms of likelihood optimization, as optimizing further should not result in higher accuracy. The results (<xref rid="MOESM1" ref-type="media">Supplementary Table 3</xref>) were again quite positive, as BEAST2 and our NNs achieved a higher likelihood than the true parameter values for ~70% of the trees, with a significant mean difference. With BDEI and BDSS, applying the same approach proved difficult due to convergence and numerical issues, with both BEAST2 and TreePar (see above). For the partial results we obtained, the overall pattern seems to be similar to that with BD: the NNs obtain highly likely solutions, with similar likelihood as BEAST2’s (when it converges and produces reasonable estimates), and significantly higher likelihood than that of the true parameter values. All these results are remarkable, as the NNs do not explicitly optimize the likelihood function associated to the models, but use a radically different learning approach, based on simulation.</p>
    </sec>
    <sec id="Sec7">
      <title>Neural networks are fast inference methods</title>
      <p id="Par21">We compared the computing time required by each of our inference methods. All computing times were estimated for a single thread of our cluster, except for the training of neural architectures where we used our GPU farm. Neural networks require heavy computing time in the learning phase; for example, with BDSS (the most complex model), simulating 4 M large trees requires ~800 CPU hours, while training FFNN-SS and CNN-CBLV requires ~5 and ~150 h, respectively. However, with NNs, inference is almost instantaneous and takes ~0.2 CPU seconds per tree on average, including encoding the tree in SS or CBLV, which is the longest part. For comparison, BEAST2 inference under the BD model with 5 million MCMC steps takes on average ~0.2 CPU hours per tree, while inference under BDEI and BDSS with 10 million MCMC steps takes ~55 CPU hours and ~80 CPU hours per tree, respectively. In fact, the convergence time of BEAST2 is usually faster (~6 CPU hours with BDEI and BDSS), but can be very long in some cases, to the point that convergence is not observed after 10 million steps (see above).</p>
    </sec>
    <sec id="Sec8">
      <title>Neural networks have high generalization capabilities and apply to very large datasets</title>
      <p id="Par22">In statistical learning theory<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>, generalization relates to the ability to predict new samples drawn from the same distribution as the training instances. Generalization is opposed to rote learning and overfitting, where the learned classifier or regressor predicts the training instances accurately, but new instances extracted from the same distribution or population poorly. The generalization capabilities of our NNs were demonstrated, as we used independent testing sets in all our experiments (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). However, we expect poor results with trees that depart from the training distribution, for example showing very high R<sub>0</sub>, while our NNs have been trained with R<sub>0</sub> in the range<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR5">5</xref></sup>. If, for a new study, larger or different parameter ranges are required, we must retrain the NNs with ad hoc simulated trees. However, a strength of NNs is that thanks to their flexibility and approximation power, very large parameter ranges can be envisaged, to avoid repeating training sessions too often.</p>
      <p id="Par23">Another sensible issue is that of the size of the trees. Our NNs have been trained with trees of 50-to-199 tips (small) and 200-to-500 tips (large), that is, trees of moderate size (but already highly time-consuming in a Bayesian setting, for the largest ones). Thus, we tested the ability to predict the parameters of small trees using NNs trained on large trees, and vice versa, the ability to predict large trees with NNs trained on small trees. The results (Supplementary Fig. <xref rid="MOESM1" ref-type="media">4</xref>) are surprisingly good, especially with summary statistics (FFNN-SS) which are little impacted by these changes of scale as they largely rely on means (e.g., of branch lengths<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>). This shows unexpected generalization capabilities of the approach regarding tree size. Most importantly, the approach can accurately predict huge trees (Fig. <xref rid="Fig4" ref-type="fig">4</xref>) using their subtrees and the means of the corresponding parameter estimates, in ~1 CPU minute. This extends the applicability of the approach to datasets that cannot be analysed today, unless using similar tree decomposition and very long calculations to analyse all subtrees.<fig id="Fig4"><label>Fig. 4</label><caption><title>Deep learning accuracy with ‘huge’ trees.</title><p>Comparison of inference accuracy by neural networks trained on large trees in predicting large trees (CNN-CBLV, in grey, same as in Fig. <xref rid="Fig3" ref-type="fig">3</xref>) and huge trees (FFNN-SS, in orange, and CBLV-NN, in pink) on 100 large and 100 huge test trees. The training and testing large trees are the same as in Fig. <xref rid="Fig3" ref-type="fig">3</xref> (between 200 and 500 tips each). The huge testing trees were generated for the same parameters as the large training and testing trees, but their size varied between 5000 and 10,000 tips. We show the relative error for each test tree. The error is measured as the normalized distance between the point estimates by neural networks and the target values for each parameter. We compare the relative errors for <bold>a</bold> BD-simulated, <bold>b</bold> BDEI-simulated and <bold>c</bold> BDSS-simulated trees. Average relative error is displayed for each parameter and method in corresponding colour below each plot.</p></caption><graphic xlink:href="41467_2022_31511_Fig4_HTML" id="d32e961"/></fig></p>
    </sec>
    <sec id="Sec9">
      <title>Neural networks are accurate methods for model selection</title>
      <p id="Par24">We trained CNN-CBLV and FFNN-SS on simulated trees to predict the birth-death model under which they were simulated (BD or BDEI for small trees; BD, BDEI or BDSS for large trees). Note that for parameters shared between multiple models, we used identical parameter value ranges across all these models (<xref rid="MOESM1" ref-type="media">Supplementary Table 4</xref>). Then, we assessed the accuracy of both of our approaches on 100 simulations obtained with each model and compared it with the model selection under BEAST2 based on Akaike information criterion through Markov Chain Monte Carlo (AICM)<sup><xref ref-type="bibr" rid="CR32">32</xref>,<xref ref-type="bibr" rid="CR33">33</xref></sup>. The AICM, similar to deviance information criterion (DIC) by Gelman et al.<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>, does not add computational load and is based on the average and variance of posterior log-likelihoods along the Markov Chain Monte Carlo (MCMC).</p>
      <p id="Par25">FFNN-SS and CNN-CBLV have similar accuracy (<xref rid="MOESM1" ref-type="media">Supplementary Table 5</xref>), namely 92% for large trees (BD vs BDEI vs BDSS), and accuracy of 91% and 90%, respectively, for small trees (BD vs BDEI). BEAST2 yielded an accuracy of 91% for large trees and 87% for small trees. The non-converging simulations were not considered for any of these methods (i.e., 5% simulations for small trees and 24% for large trees).</p>
      <p id="Par26">The process of model selection with a neural network is as fast as the parameter inference (~0.2 CPU seconds per tree). This represents a practical, fast and accurate way to perform model selection in phylodynamics.</p>
    </sec>
    <sec id="Sec10">
      <title>Neural networks are well suited to learn complex models</title>
      <p id="Par27">To assess the complexity of learned models, we explored other inference methods, namely: (1) linear regression as a baseline model trained on summary statistics (LR-SS); (2) FFNN trained directly on CBLV (FFNN-CBLV); (3) CNN trained on Compact Random Vector (CNN-CRV), for which the trees were randomly rotated, instead of being ladderized as in Fig. <xref rid="Fig2" ref-type="fig">2 (ii)</xref>; and (4) two “null models”.</p>
      <p id="Par28">LR-SS yielded inaccurate results even for the BD model (<xref rid="MOESM1" ref-type="media">Supplementary Table 1</xref>), which seems to contrast with previous findings<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>, where LR approach combined with ABC performed only slightly worse than BEAST2. This can be explained by the lack of rejection step in LR-SS, which enables to locally reduce the complexity of the relation between the representation and the inferred values to a linear one<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. However, the rejection step requires a metric (e.g., the Euclidean distance), which may or may not be appropriate depending on the model and the summary statistics. Moreover, rejection has a high computational cost with large simulation sets.</p>
      <p id="Par29">Neural networks circumvent these problems with rejection and allow for more complex, non-linear relationships between the tree representation and the inferred values to be captured. This is also reflected in our results with FFNN-CBLV and CNN-CRV, which both proved to be generally more accurate than LR-SS. However, FFNN-CBLV was substantially less accurate than CNN-CBLV (<xref rid="MOESM1" ref-type="media">Supplementary Table 1</xref>, Supplementary Fig. <xref rid="MOESM1" ref-type="media">5</xref>). This indicates the presence of repeated patterns that may appear all along the vectorial representation of trees, such as subtrees of any size, which are better extracted by CNN than by FFNN. In its turn, CNN-CRV required larger training sets to reach an accuracy comparable to CNN-CBLV (<xref rid="MOESM1" ref-type="media">Supplementary Table 1</xref>, Supplementary Fig. <xref rid="MOESM1" ref-type="media">5</xref>), showing that the ladderization and bijectivity of the CBLV helped the training.</p>
      <p id="Par30">To assess how much information is actually learned, we also measured the accuracy of two “null models”: FFNN trained to predict randomly permuted target values; and a random predictor, where parameter values were sampled from prior distributions. Results show that the neural networks extract a considerable amount of information for most of the estimated parameters (<xref rid="MOESM1" ref-type="media">Supplementary Table 1</xref>). The most difficult parameter to estimate was the fraction of superspreading individuals in BDSS model, with accuracy close to random predictions with small trees, but better performance as the tree size increases (Fig. <xref rid="Fig4" ref-type="fig">4</xref>, Supplementary Fig. <xref rid="MOESM1" ref-type="media">3</xref>).</p>
    </sec>
    <sec id="Sec11">
      <title>SS is simpler, but CBLV has high potential for application to new models</title>
      <p id="Par31">FFNN-SS and CNN-CBLV show similar accuracy across all settings (Fig. <xref rid="Fig3" ref-type="fig">3</xref>, <xref rid="MOESM1" ref-type="media">Supplementary Tables 1</xref>, <xref rid="MOESM1" ref-type="media">2</xref>), including when predicting huge trees from their subtrees (Fig. <xref rid="Fig4" ref-type="fig">4</xref>). The only exception is the prediction of large trees using NNs trained with small trees (Supplementary Fig. <xref rid="MOESM1" ref-type="media">4</xref>), where FFNN-SS is superior to CNN-CBLV, but this goes beyond the recommended use of the approach, as only a part of the (large) query tree is given to the (small) CNN-CBLV.</p>
      <p id="Par32">However, the use of the two representations is clearly different, and it is likely that with new models and scenarios their accuracy will differ. SS requires a simpler architecture (FFNN) and is trained faster (e.g., 5 h with large BDSS trees), with less training instances (Supplementary Fig. <xref rid="MOESM1" ref-type="media">6</xref>). However, this simplicity is obtained at the cost of a long preliminary work to design appropriate summary statistics for each new model, as was confirmed in our analyses of BDSS simulations. To estimate the parameters of this model, we added summary statistics on transmission chains on top of the SS taken from Saulnier et al.<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>. This improved the accuracy of superspreading fraction estimates of the FFNN-SS, so that it was comparable to the CNN-CBLV, while the accuracy for the other parameters remained similar (Supplementary Fig. <xref rid="MOESM1" ref-type="media">7</xref>). The advantage of the CBLV is its generality, meaning there is no loss of information between the tree and its representation in CBLV regardless of which model the tree was generated under. However, CBLV requires more complex architectures (CNN), more computing time in the learning phase (150 h with large BDSS trees) and more training instances (Supplementary Fig. <xref rid="MOESM1" ref-type="media">6</xref>). Such an outcome is expected. With raw CBLV representation, the convolutional architecture is used to “discover” relevant summary statistics (or features, in machine learning terminology), which has a computational cost.</p>
      <p id="Par33">In fact, the two representations should not be opposed. An interesting direction for further research would be to combine them (e.g. during the FFNN phase), to possibly obtain even better results. Moreover, SS are still informative and useful (and quickly computed), in particular to perform sanity checks, both a priori and a posteriori (Fig. <xref rid="Fig5" ref-type="fig">5</xref>, Supplementary Fig. <xref rid="MOESM1" ref-type="media">8</xref>), or to quickly evaluate the predictability of new models and scenarios.<fig id="Fig5"><label>Fig. 5</label><caption><title>Parameter inference on HIV data sampled from MSM in Zurich.</title><p>Using BDSS model with BEAST2 (in blue), FFNN-SS (in orange), and CNN-CBLV (in green) we infer: <bold>a</bold> (i) basic reproduction number, <bold>a</bold> (ii) infectious period (in years), <bold>a</bold> (iii) superspreading transmission ratio, and <bold>a</bold> (iv) superspreading fraction. For FFNN-SS and CNN-CBLV, we show the posterior distributions and the 95% CIs obtained with a fast approximation of the parametric bootstrap (‘Methods’, <xref rid="MOESM1" ref-type="media">Supplementary Information</xref>). For BEAST2, the posterior distributions and 95% CI were obtained considering all reported steps (9000 in total) excluding the 10% burn-in. Arrows show the position of the original point estimates obtained with FFNN-SS and CNN-CBLV and the median a posteriori estimate obtained with BEAST2. Circles show lower and upper boundaries of 95% CI. <bold>b</bold> These values are reported in a table, together with point estimates obtained while considering lower and higher sampling probabilities (0.20 and 0.30). <bold>c</bold> 95% CI boundaries obtained with FFNN-SS are used to perform an a posteriori model adequacy check. We simulated 10,000 trees with BDSS while resampling each parameter from a uniform distribution, whose upper and lower bounds were defined by the 95% CI. We then encoded these trees into SS, performed PCA and projected SS obtained from the HIV MSM phylogeny (red stars) on these PCA plots. We show here the projection into <bold>c</bold> (i) first two components of PCA, <bold>c</bold> (ii) the 3rd and 4th components, together with the associated percentage of variance displayed in parentheses. Warm colours correspond to high density of simulations.</p></caption><graphic xlink:href="41467_2022_31511_Fig5_HTML" id="d32e1115"/></fig></p>
    </sec>
    <sec id="Sec12">
      <title>Showcase study of HIV in MSM subpopulation in Zurich</title>
      <p id="Par34">The Swiss HIV Cohort is densely sampled, including more than 16,000 infected individuals<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. Datasets extracted from this cohort have often been studied in phylodynamics<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR25">25</xref></sup>. We analysed a dataset of an MSM subpopulation from Zurich, which corresponds to a cluster of 200 sequences studied previously by Rasmussen et al.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>, who focused on the degree of connectivity and its impact on transmission between infected individuals. Using coalescent approaches, they detected the presence of highly connected individuals at the beginning of the epidemic and estimated R<sub>0</sub> to be between 1.0 and 2.5. We used their tree as input for neural networks and BEAST2.</p>
      <p id="Par35">To perform analyses, one needs an estimate of the sampling probability. We considered that: (1) the cohort is expected to include around 45% of Swiss individuals infected with HIV<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>; and (2) the sequences were collected from around 56% of individuals enroled in this cohort<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>. We used these percentages to obtain an approximation of sampling probability of 0.45*0.56 ~ 0.25 and used this value to analyse the MSM cluster. To check the robustness of our estimates, we also used sampling probabilities of 0.2 and 0.3 in our estimation procedures.</p>
      <p id="Par36">First, we performed a quick sanity check considering the resemblance of HIV phylogeny with simulations obtained with each model. Two approaches were used, both based on SS (Supplementary Fig. <xref rid="MOESM1" ref-type="media">8</xref>). Using principal component analysis (PCA), all three considered birth-death models passed the check. However, when looking at the 98 SS values in detail, namely checking whether the observed tree SS were within the [min, max] range of the corresponding simulated values, the BD and BDEI models were rejected for some of the SS (5 for both models, all related to branch lengths). Then, we performed model selection (BD vs BDEI vs BDSS) and parameter estimation using our two methods and BEAST2 (Fig. <xref rid="Fig5" ref-type="fig">5a, b</xref>). Finally, we checked the model adequacy with a second sanity check, derived from the inferred values and SS (Fig. <xref rid="Fig5" ref-type="fig">5c</xref>, Supplementary Fig. <xref rid="MOESM1" ref-type="media">8</xref>).</p>
      <p id="Par37">Model selection with CNN-CBLV and FFNN-SS resulted in the acceptance of BDSS (probability of 1.00 versus 0.00 for BD and BDEI), and the same result was obtained with BEAST2 and AICM. These results are consistent with our detailed sanity check, and with what is known about HIV epidemiology, namely, the presence of superspreading individuals in the infected subpopulation<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> and the absence of incubation period without infectiousness such as is emulated in BDEI<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>.</p>
      <p id="Par38">We then inferred parameter values under the selected BDSS model (Fig. <xref rid="Fig5" ref-type="fig">5a, b</xref>). The values obtained with FFNN-SS and CNN-CBLV are close to each other, and the 95% CI are nearly identical. We inferred an R<sub>0</sub> of 1.6 and 1.7, and an infectious period of 10.2 and 9.8 years, with FFNN-SS and CNN-CBLV, respectively. Transmission by superspreading individuals was estimated to be around 9 times higher than by normal spreaders and superspreading individuals were estimated to account for around 7–8% of the population. Our R<sub>0</sub> estimates are consistent with the results of a previous study<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> performed on data from the Swiss cohort, and the results of Rasmussen et al.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> with this dataset. The infectious period we inferred is a bit longer than that reported by Stadler et al., who estimated it to be 7.74 [95% CI 4.39–10.99] years<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. The infectious period is a multifactorial parameter depending on treatment efficacy and adherence, the times from infection to detection and to the start of treatment, etc. In contrast to the study by Stadler et al., whose data were sampled in the period between 1998 and 2008, our dataset covers also the period between 2008 and 2014, during which life expectancy of patients with HIV was further extended<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>. This may explain why we found a longer infectious period (with compatible CIs). Lastly, our findings regarding superspreading are in accordance with those of Rassmussen et al.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>, and with a similar study in Latvia<sup><xref ref-type="bibr" rid="CR5">5</xref></sup> based on 40 MSM sequences analysed using a likelihood approach. Although the results of the latter study may not be very accurate due to the small dataset size, they still agree with ours, giving an estimate of a superspreading transmission ratio of 9, and 5.6% of superspreading individuals. Our estimates were quite robust to the choice of sampling probability (e.g., R<sub>0</sub> = 1.54, 1.60 and 1.66, with FFNN-SS and a sampling probability of 0.20, 0.25 and 0.30, respectively, Fig. <xref rid="Fig5" ref-type="fig">5b</xref>).</p>
      <p id="Par39">Compared to BEAST2, the estimates of the infectious period and R<sub>0</sub> were similar for both approaches, but BEAST2 estimates were higher for the transmission ratio (14.5) and the superspreading fraction (10.6%). These values are in accordance with the positive bias of BEAST2 estimates that we observed in our simulation study for these two parameters, while our estimates were nearly unbiased (<xref rid="MOESM1" ref-type="media">Supplementary Table 2</xref>).</p>
      <p id="Par40">Finally, we checked the adequacy of BDSS model by resemblance of HIV phylogeny to simulations. Using inferred 95% CI, we simulated 10,000 trees and performed PCA on SS, to which we projected the SS of our HIV phylogeny. This was close to simulations, specifically close to the densest swarm of simulations, supporting the adequacy of both the inferred values and the selected model (Fig. <xref rid="Fig5" ref-type="fig">5c</xref>). When looking at the 98 SS in detail, some of the observed values where not in the [min, max] range of the 10,000 simulated values. However, these discordant SS were all related to the lineage-through-time plot (LTT; e.g., <italic>x</italic> and <italic>y</italic> coordinates of this plot; Supplementary Fig. <xref rid="MOESM1" ref-type="media">8</xref>), consistent with the fact that the probabilistic, sampling component of the BDSS model is an oversimplification of actual sampling schemes, which depend on contact tracing, sampling campaigns and policies, etc.</p>
    </sec>
  </sec>
  <sec id="Sec13" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par41">In this manuscript, we presented new methods for parameter inference and model selection in phylodynamics based on deep learning from phylogenies. Through extensive simulations, we established that these methods are at least as accurate as state-of-the-art methods and capable of predicting very large trees in minutes, which cannot be achieved today by any other existing method. We also applied our deep learning methods to the Swiss HIV dataset from MSM and obtained results consistent with current knowledge of HIV epidemiology.</p>
    <p id="Par42">Using BEAST2, we obtained inaccurate results for some of the BDEI and BDSS simulations. While BEAST2 has been successfully deployed on many models and tasks, it clearly suffers from approximations in likelihood computation with these two models. However, these will likely improve in near future. In fact, we already witnessed substantial improvements done by BEAST2 developers to the BDSS model, while carrying out this research.</p>
    <p id="Par43">Both of our neural network approaches circumvent likelihood computation and thereby represent a new way of using molecular data in epidemiology, without the need to solve large systems of differential equations. This opens the door to novel phylodynamics models, which would make it possible to answer questions previously too complex to ask. This is especially true for CBLV representation, which does not require the design of new summary statistics, when applied to trees generated by new mathematical models. A direction for further research would be to explore such models, for example based on structured coalescent<sup><xref ref-type="bibr" rid="CR38">38</xref>,<xref ref-type="bibr" rid="CR39">39</xref></sup>, or to extend the approach to macroevolution and species diversification models<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>, which are closely related to epidemiological models. Other fields related to phylodynamics, such as population genetics, have been developing likelihood-free methods<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>, for which our approach might serve as a source of inspiration.</p>
    <p id="Par44">A key issue in both phylodynamics and machine learning applications is scalability. Our results show that very large phylogenies can be analysed very efficiently (~1 min for 10,000 tips), with resulting estimates more accurate than with smaller trees (Fig. <xref rid="Fig4" ref-type="fig">4</xref>), as predicted by learning theory. Again, as expected, more complex models require more training instances, especially BDSS using CBLV (Supplementary Fig. <xref rid="MOESM1" ref-type="media">3</xref>), but the ratio remains reasonable, and it is likely that complex (but identifiable) models will be handled efficiently with manageable training sets. Surprisingly, we did not observe a substantial drop of accuracy with lower sampling probabilities. To analyse very large trees, we used a decomposition into smaller, disjoint subtrees. In fact, all our NNs were trained with trees of moderate size (&lt;500 tips). Another approach would be to learn directly from large trees. This is an interesting direction for further research, but this poses several difficulties. The first is that we need to simulate these very large trees, and a large number of them (millions or more). Then, SS is the easiest representation to learn, but at the risk of losing essential information, which means that new summary statistics will likely be needed for sufficiently complete representation of very large phylogenies. Similarly, with CBLV more complex NN architectures (e.g., with additional and larger kernels in the convolutional layers) will likely be needed, imposing larger training sets. Combining both representations (e.g., during the FFNN phase) is certainly an interesting direction for further research. Note, however, that the predictions of both approaches for the three models we studied are highly correlated (Pearson coefficient nearly equal to 1 for most parameters), which means that there is likely little room for improvement (at least with these models).</p>
    <p id="Par45">A key advantage of the deep learning approaches is that they yield close to immediate estimates and apply to trees of varying size. Collection of pathogen genetic data became standard in many countries, resulting in densely sampled infected populations. Examples of such datasets include HIV in Switzerland and UK<sup><xref ref-type="bibr" rid="CR24">24</xref>,<xref ref-type="bibr" rid="CR42">42</xref></sup>, 2013 Ebola epidemics<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>, several Influenza epidemics and the 2019 SARS-Cov-2 pandemic (<ext-link ext-link-type="uri" xlink:href="http://www.gisaid.org">www.gisaid.org</ext-link>)<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>. For many such pathogens, trees can be efficiently and accurately inferred<sup><xref ref-type="bibr" rid="CR44">44</xref>–<xref ref-type="bibr" rid="CR46">46</xref></sup> and dated<sup><xref ref-type="bibr" rid="CR47">47</xref>–<xref ref-type="bibr" rid="CR49">49</xref></sup> using standard approaches. When applied to such dated trees, our methods can perform model selection and provide accurate phylodynamic parameter estimates within a fraction of a second. Such properties are desirable for phylogeny-based real-time outbreak surveillance methods, which must be able to cope with the daily influx of new samples, and thus increasing size of phylogenies, as the epidemic unfolds, in order to study local outbreaks and clusters, and assess and compare the efficiency of healthcare policies deployed in parallel. Moreover, thanks to the subtree picking and averaging strategy, it is now possible to analyse very large phylogenies, and the approach could be used to track the evolution of parameters (e.g., R<sub>0</sub>) in different regions (sub-trees) of a global tree, as a function of dates (as in Bayesian skyline models<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>), geographical areas, viral variants etc.</p>
  </sec>
  <sec id="Sec14">
    <title>Methods</title>
    <p id="Par46">Here we describe the main methodological steps. For algorithms, technical details, software programs used and their options, and additional comments, an extended version is available in <xref rid="MOESM1" ref-type="media">Supplementary Information</xref>.</p>
    <sec id="Sec15">
      <title>Tree representation using summary statistics (SS)</title>
      <p id="Par47">We use 98 summary statistics (SS), to which we add the sampling probability, summing to a vector of 99 values. We use the 83 SS proposed by Saulnier et al.<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>:<list list-type="bullet"><list-item><p id="Par48">8 SS on tree topology.</p></list-item><list-item><p id="Par49">26 SS on branch lengths.</p></list-item><list-item><p id="Par50">9 SS on lineage-through-time (LTT) plot.</p></list-item><list-item><p id="Par51">40 SS providing the coordinates of the LTT plot.</p></list-item></list></p>
      <p id="Par52">In addition, we designed 14 SS on transmission chains to capture information on the superspreading population. A superspreading individual transmits to more individuals within a given time period than a normal spreader. We thus expect that with superspreading individuals we would have shorter transmission chains. To have a proxy for the transmission chain length, we look at the sum of 4 subsequent shortest times of transmission for each internal node. This gives us a distribution of time-durations of 4-transmission chains. We assume that information on the transmission dynamics of superspreading individuals is retained in the lower (i.e., left) tail of this distribution, which contains relatively many transmissions with short time to next transmission, while the information on normal spreaders should be present in the rest of the distribution. From the observed distribution of 4-transmission-chain lengths, we compute 14 statistics:<list list-type="bullet"><list-item><p id="Par53">Number of 4-transmission chains in the tree.</p></list-item><list-item><p id="Par54">9 deciles of 4-transmission-chain lengths distribution.</p></list-item><list-item><p id="Par55">Minimum and maximum values of 4-transmission-chain lengths.</p></list-item><list-item><p id="Par56">Mean value of 4-transmission-chain lengths.</p></list-item><list-item><p id="Par57">Variance of 4-transmission-chain lengths.</p></list-item></list></p>
      <p id="Par58">Moreover, we provide the number of tips in the input tree, resulting in 83 + 14 + 1 = 98 SS in total.</p>
    </sec>
    <sec id="Sec16">
      <title>Complete and compact tree representation (CBLV)</title>
      <p id="Par59">The representation of a tree with <italic>n</italic> tips is a vector of length 2<italic>n</italic>−1, where one single real-valued scalar corresponds to one internal node or tip. This representation thus scales linearly with the tree size. The encoding is achieved in two steps: tree ladderization and tree traversal.</p>
      <p id="Par60">The tree ladderization consists in ordering the children of each node. Child nodes are sorted based on the sampling time of the most recently sampled tip in their subtrees: for each node, the branch supporting the most recently sampled subtree is rotated to the left, as in Fig. <xref rid="Fig2" ref-type="fig">2a (i–ii)</xref>.</p>
      <p id="Par61">Once the tree is sorted, we perform an inorder tree traversal<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>. When visiting a tip, we add its distance to the previously visited internal node or its distance to the root, for the tip that is visited first (i.e., the tree height due to ladderization). When visiting an internal node, we add its distance to the root. Examples of encoding are shown in Fig. <xref rid="Fig2" ref-type="fig">2a (ii–iii)</xref>. This gives us the Compact Bijective Ladderized Vector (CBLV). We then separate information relative to tips and to internal nodes into two rows (Fig. <xref rid="Fig2" ref-type="fig">2a (iv)</xref>) and complete the representation with zeros until reaching the size of the largest simulated tree for the given simulation set (Fig. <xref rid="Fig2" ref-type="fig">2a (v)</xref>).</p>
      <p id="Par62">CBLV has favourable features for deep learning. Ladderization does not actually change the input tree, but by ordering the subtrees it standardizes the input data and facilitates the learning phase, as observed with random subtree order (Supplementary Fig. <xref rid="MOESM1" ref-type="media">5</xref>, Compact Random Vector (CRV) representation,). The inorder tree traversal procedure is a bijective transformation, as it transforms a tree into a tree-compatible vector, from which the (ordered) tree can be reconstructed unambiguously, using a simple path-agglomeration algorithm shown in Supplementary Fig. <xref rid="MOESM1" ref-type="media">1</xref>. CBLV is “as concise as possible”. A rooted tree has 2<italic>n</italic>−2 branches, and thus 2<italic>n</italic>−2 entries are needed to represent the branch lengths. In our 2<italic>n</italic>−1 vectorial encoding of trees, we not only represent the branch lengths, but also the tree topology using only 1 additional entry.</p>
    </sec>
    <sec id="Sec17">
      <title>Tree rescaling</title>
      <p id="Par63">Before encoding, the trees are rescaled so that the average branch length is 1, that is, each branch length is divided by the average branch length of the given tree, called rescale factor. The values of the corresponding time-dependent parameters (i.e., infectious period and incubation period) are divided by the rescale factor too. The NN is then trained to predict these rescaled values. After parameter prediction, the predicted parameter values are multiplied by the rescale factor and thus rescaled back to the original time scale. Rescaling thus makes a pre-trained NN more generally applicable, for example both to phylogenies of pathogen-associated with an infectious period on the scale of days (e.g., Ebola virus) and years (e.g., HIV).</p>
    </sec>
    <sec id="Sec18">
      <title>Reduction and centering of summary statistics</title>
      <p id="Par64">Before training our NN and after having rescaled the trees to unit average branch length (see above), we reduce and centre every summary statistic by subtracting the mean and scaling to unit variance. To achieve this, we use the standard scaler from the scikit-learn package<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>, which is fitted to the training set. This does not apply to CBLV representation, to avoid losing the ability to reconstruct the tree.</p>
    </sec>
    <sec id="Sec19">
      <title>Parameter and model inference using neural networks</title>
      <p id="Par65">We implemented deep learning methods in Python 3.6 using Tensorflow 1.5.0<sup><xref ref-type="bibr" rid="CR51">51</xref></sup>, Keras 2.2.4<sup><xref ref-type="bibr" rid="CR52">52</xref></sup> and scikit-learn 0.19.1<sup><xref ref-type="bibr" rid="CR50">50</xref></sup> libraries. For each network, several variants in terms of number of layers and neurons, activation functions, regularization, loss functions and optimizer, were tested. In the end, we decided for two specific architectures that best fit our purpose: one deep FFNN trained on SS and one CNN trained on CBLV tree representation.</p>
      <p id="Par66">The FFNN for SS consists of one input layer with 99 input nodes (98 SS + the sampling probability), 4 sequential hidden layers organized in a funnel shape with 64-32-16-8 neurons and 1 output layer of size 2–4 depending on the number of parameters to be estimated. The neurons of the last hidden layer have linear activation, while others have exponential linear activation<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>.</p>
      <p id="Par67">The CNN for CBLV consists of one input layer (of 400 and 1002 input nodes for trees with 50–199 and 200–500 tips, respectively). This input is then reshaped into a matrix of size of 201 × 2 and 501 × 2, for small and large trees, respectively, with entries corresponding to tips and internal nodes separated into two different rows (and one extra column with one entry in each row corresponding to the sampling probability). Then, there are two 1D convolutional layers of 50 kernels each, of size 3 and 10, respectively, followed by max pooling of size 10 and another 1D convolutional layer of 80 kernels of size 10. After the last convolutional layer, there is a GlobalPoolingAverage1D layer and a FFNN of funnel shape (64-32-16-8 neurons) with the same architecture and setting as the NN used with SS.</p>
      <p id="Par68">For both NNs, we use the Adam algorithm<sup><xref ref-type="bibr" rid="CR54">54</xref></sup> as optimizer and the Mean Absolute Percentage Error (MAPE) as loss function. The batch size is set to 8000. To train the network, we split the simulated dataset into 2 groups: (1) proper training set (3,990,000 examples); (2) validation set (10,000). To prevent overfitting during training, we use: (1) the early stopping algorithm evaluating MAPE on the validation set; and (2) dropout that we set to 0.5 in the feedforward part of both NNs<sup><xref ref-type="bibr" rid="CR55">55</xref></sup> (0.4, 0.45, 0.55 and 0.6 values were tried for basic BD model without improving the accuracy).</p>
      <p id="Par69">For model selection, we use the same architecture for FFNN-SS and CNN-CBLV as those for parameter inference described above. The only differences are: (1) the cost function: categorical cross entropy, and (2) the activation function used for the output layer, that is, softmax function (of size 2 for small trees, selecting between BD and BDEI model, and of size 3 for large trees, selecting between BD, BDEI and BDSS). As we use the softmax function, the outputs of prediction are the estimated probabilities of each model, summing to 1.</p>
    </sec>
    <sec id="Sec20">
      <title>Parameter estimation from very large trees using subtree picking and averaging</title>
      <p id="Par70">To estimate parameters from very large trees we designed the ‘Subtree Picker’ algorithm (see <xref rid="MOESM1" ref-type="media">Supplementary Information</xref> for details). The goal of Subtree Picker is to extract subtrees of bounded size representing independent sub-epidemics within the global epidemic represented by the initial huge tree T, while covering most of the initial tree branches and tips in T. The sub-epidemics should follow the same sampling scheme as the global epidemic. This means that we can stop the sampling earlier than the most recent tip in T, but we cannot omit tips sampled before the end the sampling period (this would correspond to lower sampling probability). Each picked subtree corresponds to a sub-epidemic that starts with its root individual and lasts between its root date D<sub>root</sub> and some later date (D<sub>last</sub> &gt; D<sub>root</sub>). The picked subtree corresponds to the top part of the initial tree’s clade with the same root, while the tips sampled after D<sub>last</sub> are pruned. The picked subtrees do not intersect with each other and cover most of the initial tree’s branches: 98.5% (BD), 97.3% (BDEI) and 82.4% (BDSS) of the initial tree branches on the ‘huge’ tree datasets (5000 to 10,000 tips). For the BDSS model, this percentage is lower than for BD and BDEI, because of the narrower subtree size interval (200-to-500 tips versus 50-to-500 tips) corresponding to current PhyloDeep training set settings. Subtree Picker performs a postorder tree traversal (tips-to-root) and requires O(<italic>n</italic><sup>2</sup>) computing time in the worst case, where <italic>n</italic> is the number of tips in T. In practice, Subtree Picker takes on average 0.6 (BD), 0.8 (BDEI) and 0.8 (BDSS) seconds per ‘huge’ tree (5000-to-10,000 tips), meaning that it could easily be applied to much larger trees. Once subtrees (sub-epidemics) have been extracted, they are analysed using CNN-CBLV or FFNN-SS, and the parameter estimates are averaged with weights proportional to subtree sizes.</p>
    </sec>
    <sec id="Sec21">
      <title>Confidence intervals</title>
      <p id="Par71">For all NN-based parameter estimates, we compute 95% CI using a form of parametric bootstrap. To facilitate the deployment and speed-up the computation, we perform an approximation using a separate set of 1,000,000 simulations. For each simulation in the CI set, we store the true parameter values and the parameter values predicted with both of our methods. This large dataset of true/predicted values is used to avoid new simulations, as required with the standard parametric bootstrap. For a given simulated or empirical tree T, we obtain a set of predicted parameter values, {<italic>p</italic>}. The CI computation procedure searches among stored data those that are closest to T in terms of tree size, sampling probability and predicted values. We first subset:<list list-type="bullet"><list-item><p id="Par72">10% of simulations within the CI set, which are closest to T in terms of size (number of tips).</p></list-item><list-item><p id="Par73">Amongst these, 10% of simulations that are closest to T in terms of sampling probability.</p></list-item></list></p>
      <p id="Par74">We thus obtain 10,000 CI sets of real/predicted parameter values, similar in size and sampling probability to T. For each parameter value <italic>p</italic> predicted from T, we identify the 1000 nearest neighbouring values amongst the 10,000 true values of the same parameter available in the CI sets, <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${R}_{{{{{{\rm{CI}}}}}}}=\{{r}_{i=1,1000}\}$$\end{document}</tex-math><mml:math id="M2"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">CI</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1000</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_31511_Article_IEq1.gif"/></alternatives></inline-formula>, and keep the corresponding predicted values, <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${P}_{{{{{{\rm{CI}}}}}}}=\{{p}_{i=1,1000}\}$$\end{document}</tex-math><mml:math id="M4"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">CI</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1000</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_31511_Article_IEq2.gif"/></alternatives></inline-formula>. We then measure the errors for these neighbours as <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${E}_{{{{{{\rm{CI}}}}}}}=\{{e}_{i}={p}_{i}-{r}_{i}\}$$\end{document}</tex-math><mml:math id="M6"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">CI</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_31511_Article_IEq3.gif"/></alternatives></inline-formula>. We centre these errors around <italic>p</italic> using the median of errors, <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m({E}_{{{{{{\rm{CI}}}}}}})$$\end{document}</tex-math><mml:math id="M8"><mml:mi>m</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">CI</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_31511_Article_IEq4.gif"/></alternatives></inline-formula>, which yields the distribution of errors for given prediction <italic>p</italic>: <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D=\{p+{e}_{i}-m({E}_{{{{{{\rm{CI}}}}}}})\}$$\end{document}</tex-math><mml:math id="M10"><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">CI</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_31511_Article_IEq5.gif"/></alternatives></inline-formula><inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$,$$\end{document}</tex-math><mml:math id="M12"><mml:mo>,</mml:mo></mml:math><inline-graphic xlink:href="41467_2022_31511_Article_IEq6.gif"/></alternatives></inline-formula> from which we extract the 95% CI around <italic>p</italic>. Individual points in the obtained distribution that are outside of the parameter ranges covered through simulations are set to the closest boundary value of the parameter range. With very large trees and the subtree picking and averaging procedure, we use a quadratic weighted average of the individual CIs found for every subtree. To assess this fast implementation of the parametric bootstrap, we used the coverage of the true parameter values (expected to be of 95%) and the width (the lower the better) of the CIs. Results and comparisons with BEAST2 are reported in <xref rid="MOESM1" ref-type="media">Supplementary Table 7</xref>.</p>
    </sec>
    <sec id="Sec22">
      <title>Models</title>
      <p id="Par75">The models we used for tree simulations are represented in the form of flow diagrams in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. We simulated dated binary trees for (1) the training of NNs and (2) accuracy assessment of parameter estimation and model selection. We used the following three individual-based phylodynamic models:<list list-type="bullet"><list-item><p id="Par76">Constant rate birth-death model with incomplete sampling: This model (BD<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR9">9</xref></sup>, Fig. <xref rid="Fig1" ref-type="fig">1a</xref>) contains three parameters and three compartments: infectious (I), removed with sampling (R) and removed unsampled (U) individuals. Infection takes place at rate β. Infectious individuals are removed with rate γ. Upon removal, an individual is sampled with probability <italic>s</italic>. For simulations, we re-parameterized the model in terms of: basic reproduction number, R<sub>0</sub>; infectious period, 1/γ; sampling probability, <italic>s</italic>; and tree size, <italic>t</italic>. We then sampled the values for each simulation uniformly at random in the ranges given in <xref rid="MOESM1" ref-type="media">Supplementary Table 4</xref>.</p></list-item><list-item><p id="Par77">Birth-death model with exposed-infectious classes: This model (BDEI<sup><xref ref-type="bibr" rid="CR10">10</xref>–<xref ref-type="bibr" rid="CR12">12</xref></sup>, Fig. <xref rid="Fig1" ref-type="fig">1b</xref>) is a BD model extended through the presence of an exposed class. More specifically, this means that each infected individual starts as non-infectious (E) and becomes infectious (I) at incubation rate ε. BDEI model thus has four parameters (β, γ, ε and <italic>s</italic>) and four compartments (E, I, R and U). For simulations, we re-parameterized the model similarly as described for BD and set the ε value via the incubation ratio (=ε/γ). We sampled all parameters, including ε/γ, from a uniform distribution, just as with BD (<xref rid="MOESM1" ref-type="media">Supplementary Table 4</xref>).</p></list-item><list-item><p id="Par78">Birth-death model with superspreading: This model (BDSS<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR11">11</xref></sup>, Fig. <xref rid="Fig1" ref-type="fig">1c</xref>) accounts for heterogeneous infectious classes. Infected individuals belong to one of two infectious classes (I<sub>S</sub> for superspreading and I<sub>N</sub> for normal spreading) and can transmit the disease by giving birth to individuals of either class, with rates <italic>β</italic><sub>S,S</sub> and <italic>β</italic><sub>S,N</sub> for I<sub>S</sub> transmitting to I<sub>S</sub> and to I<sub>N</sub>, respectively, and <italic>β</italic><sub>N,S</sub> and <italic>β</italic><sub>N,N</sub> for I<sub>N</sub> transmitting to I<sub>S</sub> and I<sub>N</sub>, respectively. However, there is a restriction on parameter values: <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\beta }}}}}_{{{{{{\rm{S}}}}}},{{{{{\rm{S}}}}}}}\times {{{{{\beta }}}}}_{{{{{{\rm{N}}}}}},{{{{{\rm{N}}}}}}}={{{{{\beta }}}}}_{{{{{{\rm{S}}}}}},{{{{{\rm{N}}}}}}}\times {{{{{\beta }}}}}_{{{{{{\rm{N}}}}}},{{{{{\rm{S}}}}}}}$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_31511_Article_IEq7.gif"/></alternatives></inline-formula>. There are thus superspreading transmission rates <italic>β</italic><sub>S.</sub>, and normal transmission rates <italic>β</italic><sub>N.</sub>, that are <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{X}}}}}}_{{{{{{\rm{SS}}}}}}}={{{{{\beta }}}}}_{{{{{{\rm{S}}}}}},{{{{{\rm{S}}}}}}}/{{{{{\beta }}}}}_{{{{{{\rm{N}}}}}},{{{{{\rm{S}}}}}}}={{{{{\beta }}}}}_{{{{{{\rm{S}}}}}},{{{{{\rm{N}}}}}}}/{{{{{\beta }}}}}_{{{{{{\rm{N}}}}}},{{{{{\rm{N}}}}}}}$$\end{document}</tex-math><mml:math id="M16"><mml:msub><mml:mrow><mml:mi mathvariant="normal">X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">SS</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_31511_Article_IEq8.gif"/></alternatives></inline-formula> times higher for superspreading. At transmission, the probability of the recipient to be superspreading is <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\rm{f}}}}}}}_{{{{{{\rm{SS}}}}}}}={{{{{\beta }}}}}_{{{{{{\rm{S}}}}}},{{{{{\rm{S}}}}}}}/({{{{{\beta }}}}}_{{{{{{\rm{S}}}}}},{{{{{\rm{S}}}}}}}+{{{{{\beta }}}}}_{{{{{{\rm{S}}}}}},{{{{{\rm{N}}}}}}})$$\end{document}</tex-math><mml:math id="M18"><mml:msub><mml:mrow><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">SS</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_31511_Article_IEq9.gif"/></alternatives></inline-formula>, the fraction of superspreading individuals at equilibrium. We consider that both I<sub>S</sub> and I<sub>N</sub> populations are otherwise indistinguishable, that is, both populations share the same infectious period (1/γ)<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR11">11</xref></sup>. The model thus has six parameters, but only five need to be estimated to fully define the model<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR10">10</xref></sup>. For simulations, we chose parameters of epidemiological interest for re-parameterization: basic reproduction number R<sub>0</sub>, infectious period 1/γ, f<sub>SS</sub>, X<sub>SS</sub> and sampling probability <italic>s</italic>. In our simulations, we used uniform distributions for these five parameters, just as with BD and BDEI (<xref rid="MOESM1" ref-type="media">Supplementary Table 4</xref>).</p></list-item></list></p>
    </sec>
    <sec id="Sec23">
      <title>Parameter inference with BEAST2</title>
      <p id="Par79">To assess the accuracy of our methods, we compared it with a well-established Bayesian method, as implemented in BEAST2 (version 2.6.2). We used the BDSKY package<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> (version 1.4.5) to estimate the parameter values of BD simulations and the package bdmm<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup> (version 1.0) to infer the parameter values of BDEI and BDSS. Furthermore, for the inference on BDSS simulations, instead of BEAST 2.6.2 we used the BEAST2 code up to the commit nr2311ba7, which includes important fixes to operators critical for our analyses. We set the Markov Chain Monte Carlo (MCMC) length to 5 million steps for the BD model, and to 10 million steps for the BDEI and BDSS models.</p>
      <p id="Par80">The sampling probability was fixed during the estimation. Since the BD, BDEI and BDSS models implemented in BEAST2 do not use the same parametrizations as our methods, we needed to apply parameter conversions for setting the priors for BEAST2 inference (<xref rid="MOESM1" ref-type="media">Supplementary Table 6</xref>), and for translating the BEAST2 results back to parameterizations used in our methods, in order to enable proper comparison of the results (see <xref rid="MOESM1" ref-type="media">Supplementary Information</xref> for details).</p>
      <p id="Par81">After we obtained the parameters of interest from the original parameters estimated by BEAST2, we evaluated the Effective Sample Size (ESS) on all parameters. We reported the absolute percentage error of the median of a posteriori values (more stable and accurate than the maximum a posteriori), corresponding to all reported steps (spaced by 1000 actual MCMC steps) past the 10% burn-in. For simulations for which BEAST2 did not converge, we considered the median of the parameter distribution used for simulations (Fig. <xref rid="Fig3" ref-type="fig">3</xref>, <xref rid="MOESM1" ref-type="media">Supplementary Tables 1</xref>, <xref rid="MOESM1" ref-type="media">2</xref>, Supplementary Fig. <xref rid="MOESM1" ref-type="media">2</xref>) or excluded them from the comparison (<xref rid="MOESM1" ref-type="media">Supplementary Tables 1</xref>, <xref rid="MOESM2" ref-type="media">2</xref>, values reported in brackets, <xref rid="MOESM1" ref-type="media">Supplementary Table 5</xref>).</p>
      <p id="Par82">For the HIV application, the prior of infectious period was set to [0.1, 30] years (uniform). All the other parameters had the same prior distributions as used in simulations and shown in <xref rid="MOESM1" ref-type="media">Supplementary Tables 4</xref>, <xref rid="MOESM1" ref-type="media">6</xref>.</p>
    </sec>
    <sec id="Sec24">
      <title>Accuracy of parameter estimation</title>
      <p id="Par83">To compare the accuracy of the different methods, we used 100 simulated trees per model. For each simulated tree, we computed the relative error and its mean over the 100 trees (Figs. <xref rid="Fig3" ref-type="fig">3</xref>–<xref rid="Fig4" ref-type="fig">4</xref>, <xref rid="MOESM1" ref-type="media">Supplementary Table 1</xref>, Supplementary Figs. <xref rid="MOESM1" ref-type="media">2</xref>–<xref rid="MOESM1" ref-type="media">4</xref>):<disp-formula id="Equa"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\rm{MRE}}}}}}}=\frac{1}{100}\mathop{\sum }\limits_{i=1}^{100}\frac{\left|{{{{{{{\rm{predicted}}}}}}}}_{i}-{{{{{{{\rm{target}}}}}}}}_{i}\right|}{{{{{{{{\rm{target}}}}}}}}_{i}}.$$\end{document}</tex-math><mml:math id="M20"><mml:mi mathvariant="normal">MRE</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>100</mml:mn></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>100</mml:mn></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mfenced close="∣" open="∣"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">predicted</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">target</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">target</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2022_31511_Article_Equa.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par84">The mean relative bias (<xref rid="MOESM1" ref-type="media">Supplementary Table 2</xref>) was measured in a similar manner as:<disp-formula id="Equb"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\rm{MRB}}}}}}}=\frac{1}{100}\mathop{\sum }\limits_{i=1}^{100}\frac{\left({{{{{{{\rm{predicted}}}}}}}}_{i}-{{{{{{{\rm{target}}}}}}}}_{i}\right)}{{{{{{{{\rm{target}}}}}}}}_{i}}.$$\end{document}</tex-math><mml:math id="M22"><mml:mi mathvariant="normal">MRB</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>100</mml:mn></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>100</mml:mn></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">predicted</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">target</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">target</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2022_31511_Article_Equb.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec25">
      <title>Comparison of time efficiency</title>
      <p id="Par85">For FFNN-SS and CNN-CBLV, we reported the average CPU time of encoding a tree (average over 10,000 trees), as reported by NextFlow<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>. The inference time itself was negligible.</p>
      <p id="Par86">For BEAST2, we reported the CPU time averaged over 100 analyses with BEAST2 as reported by NextFlow. For the analyses with BDEI and BDSS models, we reported the CPU time to process 10 million MCMC steps, and for the analyses with BD, we reported the CPU time to process 5 million MCMC steps. To account for convergence, we re-calculated the average CPU time considering only those analyses for which the chain converged and an ESS of 200 was reached for all inferred parameters.</p>
      <p id="Par87">The calculations were performed on a computational cluster with CentOS machines and Slurm workload manager. The machines had the following characteristics: 28 cores, 2.4 GHz, 128 GB of RAM. Each of our jobs (simulation of one tree, tree encoding, BEAST2 run, etc.) was performed requesting one CPU core. The neural network training was performed on a GPU cluster with Nvidia Titan X GPUs.</p>
    </sec>
    <sec id="Sec26">
      <title>HIV dataset</title>
      <p id="Par88">We used the original phylogenetic tree reconstructed by Rasmussen et al.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> from 200 sequences corresponding to the largest cluster of HIV-infected men-having-sex-with-men (MSM) subpopulation in Zurich, collected as a part of the Swiss Cohort Study<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. For details on tree reconstruction, please refer to their article.</p>
    </sec>
    <sec id="Sec27">
      <title>PhyloDeep software</title>
      <p id="Par89">FFNN-SS and CNN-CBLV parameter inference, model selection, 95% CI computation and a priori checks are implemented in the PhyloDeep software, which is available on GitHub (github.com/evolbioinfo/phylodeep), PyPi (pypi.org/project/phylodeep) and Docker Hub (hub.docker.com/r/evolbioinfo/phylodeep). It can be run as a command-line programme, Python3 package and a Docker container. PhyloDeep covers the parameter subspace as described in <xref rid="MOESM1" ref-type="media">Supplementary Table 4</xref>. The input is a dated phylogenetic tree with at least 50 tips and presumed sampling probability. The output is a PCA plot for a priori check, a csv file with all SS, and a csv file with probabilities of each model (for model selection) and point estimates and 95% CI values (for parameter inference with selected model). The installation details and usage examples are available as well on GitHub.</p>
    </sec>
    <sec id="Sec28">
      <title>Reporting summary</title>
      <p id="Par90">Further information on research design is available in the <xref rid="MOESM3" ref-type="media">Nature Research Reporting Summary</xref> linked to this article.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec29">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41467_2022_31511_MOESM1_ESM.pdf">
            <caption>
              <p>Supplementary Information</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="41467_2022_31511_MOESM2_ESM.pdf">
            <caption>
              <p>Peer Review File</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="41467_2022_31511_MOESM3_ESM.pdf">
            <caption>
              <p>Reporting Summary</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p>The online version contains supplementary material available at 10.1038/s41467-022-31511-0.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to thank Dr. Kary Ocaña and Tristan Dot for initiating experiments on machine learning and phylogenetic trees in our laboratory. We would like to thank Quang Tru Huynh for administrating the GPU farm at Institut Pasteur and the INCEPTION programme (Investissement d’Avenir grant ANR-16-CONV-0005) that financed the GPU farm. We would like to thank Dr. Christophe Zimmer from Institut Pasteur, Sophia Lambert and Dr. Hélène Morlon from Institut de Biologie de l’Ecole Normale Supérieure IBENS and Dr. Guy Baele from Katholieke Universiteit KU Leuven for useful discussions, and Dr. Isaac Overcast from IBENS and Luc Blassel from Institut Pasteur for critical reading of the manuscript. We would like to thank Dr. Tanja Stadler and Jérémie Sciré for their help with BEAST2 and MLE approaches. J.V. is supported by Ecole Normale Supérieure Paris-Saclay and by ED Frontières de l’Innovation en Recherche et Education, Programme Bettencourt. V.B. would like to thank Swiss National Science Foundation for funding (Early PostDoc mobility grant P2EZP3_184543). O.G. is supported by PRAIRIE (ANR-19-P3IA-0001).</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>J.V., A.Z. and O.G. conceived and set up the methods; J.V., A.Z. and V.B. performed the experiments; J.V., A.Z. and O.G. analysed the results; J.V. and A.Z. wrote the Python package; J.V. and O.G. wrote the manuscript; J.V., A.Z., V.B. and O.G. edited the manuscript; all authors helped in this research, discussed the results and read the final manuscript; O.G. initiated and supervised the project.</p>
  </notes>
  <notes notes-type="peer-review">
    <title>Peer review</title>
    <sec id="FPar1">
      <title>Peer review information</title>
      <p id="Par91"><italic>Nature Communications</italic> thanks Mohammed El-Kebir and Samuel Soubeyrand for their contribution to the peer review of this work. <xref rid="MOESM2" ref-type="media">Peer reviewer reports</xref> are available.</p>
    </sec>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The data generated in this study (simulated trees, BEAST2 logs, and the results of BEAST2 and PhyloDeep runs), as well as the HIV phylogenetic tree for Zurich epidemic (a showcase application) are provided on GitHub (<ext-link ext-link-type="uri" xlink:href="http://github.com/evolbioinfo/phylodeep">github.com/evolbioinfo/phylodeep</ext-link>, version 0.3) and have been deposited in the Zenodo database under accession code 10.5281/zenodo.6646668. The simulated trees were obtained with our simulator (see Code availability), the HIV tree was previously published by Rasmussen et al.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> and is available on their GitHub: github.com/davidrasm/PairTree (all confidential information has been removed).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Code availability</title>
    <p>The PhyloDeep package (version 0.3) is under the GPL v3.0 license and uses Python (3.6) and Python libraries: ete3 (version 3.1.2 under GNU general licence); pandas (version 1.1.5); numpy (version 1.19.5); scipy (version 1.1.0); scikit-learn (version 0.19.1); tensorflow (version 1.13.1); joblib (version 0.13.2); h5py (version 2.10.0); Keras (version 2.4.3 under Apache 2.0 license); matplotlib (version 3.1.3 under PSF license). We provide (i) the source code of PhyloDeep, (ii) the code of the tree simulators used to train the deep learners and (iii) the log files obtained with BEAST2 on GitHub (<ext-link ext-link-type="uri" xlink:href="http://github.com/evolbioinfo/phylodeep">github.com/evolbioinfo/phylodeep</ext-link>). The code has been deposited in Zenodo<sup><xref ref-type="bibr" rid="CR57">57</xref></sup>. We used the version 2.6.2 of BEAST2 for BD and BDEI inferences and BEAST2 compiled up to the commit nr2311ba7 for BDSS inferences, and version 3.3 of TreePar. For BEAST2 inferences, we used BEAST2 libraries bdmm (version 1.0) and BDSKY (version 1.4.5). We used Snakemake (version 5.10.0) and Nextflow (version 21.04.3.5560) pipeline managers for simulations and analyses of simulated data.</p>
  </notes>
  <notes id="FPar2" notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par92">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grenfell</surname>
            <given-names>BT</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Unifying the epidemiological and evolutionary dynamics of pathogens</article-title>
        <source>Science</source>
        <year>2004</year>
        <volume>303</volume>
        <fpage>327</fpage>
        <lpage>332</lpage>
        <pub-id pub-id-type="doi">10.1126/science.1090727</pub-id>
        <?supplied-pmid 14726583?>
        <pub-id pub-id-type="pmid">14726583</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Volz</surname>
            <given-names>EM</given-names>
          </name>
          <name>
            <surname>Kosakovsky Pond</surname>
            <given-names>SL</given-names>
          </name>
          <name>
            <surname>Ward</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Leigh Brown</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Frost</surname>
            <given-names>SD</given-names>
          </name>
        </person-group>
        <article-title>Phylodynamics of infectious disease epidemics</article-title>
        <source>Genetics</source>
        <year>2009</year>
        <volume>183</volume>
        <fpage>1421</fpage>
        <lpage>1430</lpage>
        <pub-id pub-id-type="doi">10.1534/genetics.109.106021</pub-id>
        <?supplied-pmid 19797047?>
        <pub-id pub-id-type="pmid">19797047</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Drummond</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Rambaut</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Shapiro</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Pybus</surname>
            <given-names>OG</given-names>
          </name>
        </person-group>
        <article-title>Bayesian coalescent inference of past population dynamics from molecular sequences</article-title>
        <source>Mol. Biol. Evolution</source>
        <year>2005</year>
        <volume>22</volume>
        <fpage>1185</fpage>
        <lpage>1192</lpage>
        <pub-id pub-id-type="doi">10.1093/molbev/msi103</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stadler</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Birth–death skyline plot reveals temporal changes of epidemic spread in HIV and hepatitis C virus (HCV)</article-title>
        <source>Proc. Natl Acad. Sci. USA</source>
        <year>2013</year>
        <volume>110</volume>
        <fpage>228</fpage>
        <lpage>233</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1207965110</pub-id>
        <?supplied-pmid 23248286?>
        <pub-id pub-id-type="pmid">23248286</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stadler</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Bonhoeffer</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Uncovering epidemiological dynamics in heterogeneous host populations using phylogenetic methods</article-title>
        <source>Philos. Trans. R. Soc. B: Biol. Sci.</source>
        <year>2013</year>
        <volume>368</volume>
        <fpage>20120198</fpage>
        <pub-id pub-id-type="doi">10.1098/rstb.2012.0198</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gire</surname>
            <given-names>SK</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Genomic surveillance elucidates Ebola virus origin and transmission during the 2014 outbreak</article-title>
        <source>Science</source>
        <year>2014</year>
        <volume>345</volume>
        <fpage>1369</fpage>
        <lpage>1372</lpage>
        <pub-id pub-id-type="doi">10.1126/science.1259657</pub-id>
        <?supplied-pmid 25214632?>
        <pub-id pub-id-type="pmid">25214632</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boskova</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Bonhoeffer</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Stadler</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Inference of epidemiological dynamics based on simulated phylogenies using birth-death and coalescent models</article-title>
        <source>PLOS Comput. Biol.</source>
        <year>2014</year>
        <volume>10</volume>
        <fpage>e1003913</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1003913</pub-id>
        <?supplied-pmid 25375100?>
        <pub-id pub-id-type="pmid">25375100</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stadler</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Estimating the basic reproductive number from viral sequence data</article-title>
        <source>Mol. Biol. Evol.</source>
        <year>2012</year>
        <volume>29</volume>
        <fpage>347</fpage>
        <lpage>357</lpage>
        <pub-id pub-id-type="doi">10.1093/molbev/msr217</pub-id>
        <?supplied-pmid 21890480?>
        <pub-id pub-id-type="pmid">21890480</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Leventhal</surname>
            <given-names>GE</given-names>
          </name>
          <name>
            <surname>Günthard</surname>
            <given-names>HF</given-names>
          </name>
          <name>
            <surname>Bonhoeffer</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Stadler</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Using an epidemiological model for phylogenetic inference reveals density dependence in HIV transmission</article-title>
        <source>Mol. Biol. Evol.</source>
        <year>2014</year>
        <volume>31</volume>
        <fpage>6</fpage>
        <lpage>17</lpage>
        <pub-id pub-id-type="doi">10.1093/molbev/mst172</pub-id>
        <?supplied-pmid 24085839?>
        <pub-id pub-id-type="pmid">24085839</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">Stadler, T., Kuhnert, D., Rasmussen, D. A. &amp; du Plessis, L. Insights into the early epidemic spread of Ebola in sierra leone provided by viral sequence data. <italic>PLoS Curr</italic>. <bold>6</bold>, 10.1371/currents.outbreaks.02bc6d927ecee7bbd33532ec8ba6a25f (2014).</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kühnert</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Stadler</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Vaughan</surname>
            <given-names>TG</given-names>
          </name>
          <name>
            <surname>Drummond</surname>
            <given-names>AJ</given-names>
          </name>
        </person-group>
        <article-title>Phylodynamics with migration: a computational framework to quantify population structure from genomic data</article-title>
        <source>Mol. Biol. Evol.</source>
        <year>2016</year>
        <volume>33</volume>
        <fpage>2102</fpage>
        <lpage>2116</lpage>
        <pub-id pub-id-type="doi">10.1093/molbev/msw064</pub-id>
        <?supplied-pmid 27189573?>
        <pub-id pub-id-type="pmid">27189573</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Sciré, J., Barido-Sottani, J., Kühnert, D., Vaughan, T. G., Stadler, T. Improved multi-type birth-death phylodynamic inference in BEAST 2. Preprint at <italic>bioRxiv</italic>10.1101/2020.01.06.895532 (2020).</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bouckaert</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>BEAST 2: a software platform for Bayesian evolutionary analysis</article-title>
        <source>PLoS Computat. Biol.</source>
        <year>2014</year>
        <volume>10</volume>
        <fpage>e1003537</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1003537</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boskova</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Stadler</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Magnus</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>The influence of phylodynamic model specifications on parameter estimates of the Zika virus epidemic</article-title>
        <source>Virus Evolution</source>
        <year>2018</year>
        <volume>4</volume>
        <fpage>vex044</fpage>
        <pub-id pub-id-type="doi">10.1093/ve/vex044</pub-id>
        <?supplied-pmid 29403651?>
        <pub-id pub-id-type="pmid">29403651</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Vaughan, T. G., Sciré, J., Nadeau, S. A. &amp; Stadler, T. Estimates of outbreak-specific SARS-CoV-2 epidemiological parameters from genomic data. Preprint at 10.1101/2020.09.12.20193284 (2020).</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rubin</surname>
            <given-names>DB</given-names>
          </name>
        </person-group>
        <article-title>Bayesianly justifiable and relevant frequency calculations for the applies statistician</article-title>
        <source>Ann. Stat.</source>
        <year>1984</year>
        <volume>12</volume>
        <fpage>1151</fpage>
        <lpage>1172</lpage>
        <pub-id pub-id-type="doi">10.1214/aos/1176346785</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Beaumont</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Balding</surname>
            <given-names>DJ</given-names>
          </name>
        </person-group>
        <article-title>Approximate Bayesian computation in population genetics</article-title>
        <source>Genetics</source>
        <year>2002</year>
        <volume>164</volume>
        <fpage>2025</fpage>
        <lpage>2035</lpage>
        <pub-id pub-id-type="doi">10.1093/genetics/162.4.2025</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Csilléry</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Blum</surname>
            <given-names>MGB</given-names>
          </name>
          <name>
            <surname>Gaggiotti</surname>
            <given-names>OE</given-names>
          </name>
          <name>
            <surname>François</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>Approximate Bayesian computation (ABC) in practice</article-title>
        <source>Trends Ecol. Evolution</source>
        <year>2010</year>
        <volume>25</volume>
        <fpage>410</fpage>
        <lpage>418</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tree.2010.04.001</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Saulnier</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Gascuel</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Alizon</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Inferring epidemiological parameters from phylogenies using regression-ABC: a comparative study</article-title>
        <source>PLoS Comp. Biol.</source>
        <year>2017</year>
        <volume>13</volume>
        <fpage>e1005416</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005416</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Blum, M. G. B. In <italic>Handbook of Approximate Bayesian Computation</italic> 71–85 (Chapman and Hall/CRC Press, 2018).</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">LeCun, Y., Kavukcuoglu, K. &amp; Farabet, F. Convolutional networks and applications in vision. In <italic>Proc. IEEE Int. Symp. Circuits Syst</italic>. 253–256 (2010).</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Krizhevsky, K., Sutskever, I. &amp; Hinton, G. E. ImageNet classification with deep convolutional neural networks. In <italic>Advances in Neural Information Processing Systems</italic> 1097–1105 (2012).</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chattopadhyay</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hassanzadeh</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Pasha</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Predicting clustered weather patterns: a test case for applications of convolutional neural networks to spatio-temporal climate data</article-title>
        <source>Sci. Rep.</source>
        <year>2020</year>
        <volume>10</volume>
        <fpage>1317</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-020-57897-9</pub-id>
        <?supplied-pmid 31992743?>
        <pub-id pub-id-type="pmid">31992743</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <collab>The Swiss HIV Cohort Study.</collab>
          <etal/>
        </person-group>
        <article-title>Cohort profile: the Swiss HIV Cohort study</article-title>
        <source>Int. J. Epidemiol.</source>
        <year>2010</year>
        <volume>39</volume>
        <fpage>1179</fpage>
        <lpage>1189</lpage>
        <pub-id pub-id-type="doi">10.1093/ije/dyp321</pub-id>
        <pub-id pub-id-type="pmid">19948780</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rasmussen</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Kouyos</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Günthard</surname>
            <given-names>HF</given-names>
          </name>
          <name>
            <surname>Stadler</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Phylodynamics on local sexual contact networks</article-title>
        <source>PLOS Comp. Biol.</source>
        <year>2017</year>
        <volume>13</volume>
        <fpage>e1005448</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005448</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Colijn</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Plazzotta</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>A metric on phylogenetic tree shapes</article-title>
        <source>Syst. Biol.</source>
        <year>2018</year>
        <volume>67</volume>
        <fpage>113</fpage>
        <lpage>126</lpage>
        <pub-id pub-id-type="doi">10.1093/sysbio/syx046</pub-id>
        <?supplied-pmid 28472435?>
        <pub-id pub-id-type="pmid">28472435</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Liu, P., Gould, M. &amp; Colijn, C. Analyzing phylogenetic trees with a tree lattice coordinate system and a graph polynomial. <italic>Syst. Biol.</italic>10.1093/sysbio/syac008 (2022).</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lewitus</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Morlon</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Characterizing and comparing phylogenies from their Laplacian spectrum</article-title>
        <source>Syst. Biol.</source>
        <year>2016</year>
        <volume>65</volume>
        <fpage>495</fpage>
        <lpage>507</lpage>
        <pub-id pub-id-type="doi">10.1093/sysbio/syv116</pub-id>
        <?supplied-pmid 26658901?>
        <pub-id pub-id-type="pmid">26658901</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Rosenberg</surname>
            <given-names>NA</given-names>
          </name>
          <name>
            <surname>Palacios</surname>
            <given-names>JA</given-names>
          </name>
        </person-group>
        <article-title>Distance metrics for ranked evolutionary trees</article-title>
        <source>Proc. Natl Acad. Sci. USA</source>
        <year>2020</year>
        <volume>117</volume>
        <fpage>28876</fpage>
        <lpage>28886</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1922851117</pub-id>
        <?supplied-pmid 33139566?>
        <pub-id pub-id-type="pmid">33139566</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Cormen, T. H., Leiserson, C. E., Rivest, R. L. &amp; Stein, C. <italic>Introduction to Algorithms</italic> 286–307 (The MIT Press, 2009).</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Bengio, Y. In <italic>Neural Networks: Tricks of the Trade</italic> (Springer, 2002).</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">Gelman, A., Carlin, J. B., Stern, H. S. &amp; Rubin, D. B. <italic>Bayesian Data Analysis</italic> 2nd edn (Chapman and Hall/CRC Press, 2004).</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baele</surname>
            <given-names>G</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Improving the accuracy of demographic and molecular clock model comparison while accommodating phylogenetic uncertainty</article-title>
        <source>Mol. Biol. Evol.</source>
        <year>2012</year>
        <volume>29</volume>
        <fpage>2157</fpage>
        <lpage>2167</lpage>
        <pub-id pub-id-type="doi">10.1093/molbev/mss084</pub-id>
        <?supplied-pmid 22403239?>
        <pub-id pub-id-type="pmid">22403239</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kouyos</surname>
            <given-names>RD</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Molecular epidemiology reveals long-term changes in HIV type 1 subtype B transmission in Switzerland</article-title>
        <source>J. Infect. Dis.</source>
        <year>2010</year>
        <volume>201</volume>
        <fpage>1488</fpage>
        <lpage>1497</lpage>
        <pub-id pub-id-type="doi">10.1086/651951</pub-id>
        <?supplied-pmid 20384495?>
        <pub-id pub-id-type="pmid">20384495</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>May</surname>
            <given-names>RM</given-names>
          </name>
          <name>
            <surname>Anderson</surname>
            <given-names>RM</given-names>
          </name>
        </person-group>
        <article-title>Transmission dynamics of HIV infection</article-title>
        <source>Nature</source>
        <year>1987</year>
        <volume>326</volume>
        <fpage>137</fpage>
        <lpage>142</lpage>
        <pub-id pub-id-type="doi">10.1038/326137a0</pub-id>
        <?supplied-pmid 3821890?>
        <pub-id pub-id-type="pmid">3821890</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brenner</surname>
            <given-names>BG</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>High rates of forward transmission events after acute/early HIV-1 infection</article-title>
        <source>J. Infect. Dis.</source>
        <year>2007</year>
        <volume>195</volume>
        <fpage>951</fpage>
        <lpage>959</lpage>
        <pub-id pub-id-type="doi">10.1086/512088</pub-id>
        <?supplied-pmid 17330784?>
        <pub-id pub-id-type="pmid">17330784</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gueler</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Swiss National Cohort Life expectancy in HIV-positive persons in Switzerland</article-title>
        <source>AIDS</source>
        <year>2017</year>
        <volume>31</volume>
        <fpage>427</fpage>
        <lpage>436</lpage>
        <pub-id pub-id-type="doi">10.1097/QAD.0000000000001335</pub-id>
        <?supplied-pmid 27831953?>
        <pub-id pub-id-type="pmid">27831953</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rasmussen</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Volz</surname>
            <given-names>EM</given-names>
          </name>
          <name>
            <surname>Koelle</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Phylodynamic inference for structured epidemiological models</article-title>
        <source>PLoS Comput. Biol.</source>
        <year>2014</year>
        <volume>10</volume>
        <fpage>e1003570</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1003570</pub-id>
        <?supplied-pmid 24743590?>
        <pub-id pub-id-type="pmid">24743590</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Volz</surname>
            <given-names>EM</given-names>
          </name>
          <name>
            <surname>Siveroni</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Bayesian phylodynamic inference with complex models</article-title>
        <source>PLoS Comput. Biol.</source>
        <year>2018</year>
        <volume>14</volume>
        <fpage>e1006546</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006546</pub-id>
        <?supplied-pmid 30422979?>
        <pub-id pub-id-type="pmid">30422979</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>MacPherson</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Louca</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>McLaughlin</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Joy</surname>
            <given-names>JB</given-names>
          </name>
          <name>
            <surname>Pennell</surname>
            <given-names>MW</given-names>
          </name>
        </person-group>
        <article-title>Unifying phylogenetic birth–death models in epidemiology and macroevolution</article-title>
        <source>Syst. Biol.</source>
        <year>2022</year>
        <volume>71</volume>
        <fpage>172</fpage>
        <lpage>189</lpage>
        <pub-id pub-id-type="doi">10.1093/sysbio/syab049</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sanchez</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Cury</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Charpiat</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Jay</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Deep learning for population size history inference: Design, comparison and combination with approximate Bayesian computation</article-title>
        <source>Mol. Ecol. Resour.</source>
        <year>2020</year>
        <volume>00</volume>
        <fpage>1</fpage>
        <lpage>16</lpage>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dunn</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Pillay</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>UK HIV drug resistance database: background and recent outputs</article-title>
        <source>J. HIV Ther.</source>
        <year>2007</year>
        <volume>12</volume>
        <fpage>97</fpage>
        <lpage>98</lpage>
        <?supplied-pmid 18578092?>
        <pub-id pub-id-type="pmid">18578092</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>McCauley</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>GISAID: global initiative on sharing all influenza data—from vision to reality</article-title>
        <source>Eur. Surveill.</source>
        <year>2017</year>
        <volume>22</volume>
        <fpage>30494</fpage>
        <pub-id pub-id-type="doi">10.2807/1560-7917.ES.2017.22.13.30494</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Minh</surname>
            <given-names>BQ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>IQ-TREE 2: new models and efficient methods for phylogenetic inference in the genomic era</article-title>
        <source>Mol. Biol. Evol.</source>
        <year>2020</year>
        <volume>37</volume>
        <fpage>1530</fpage>
        <lpage>1534</lpage>
        <pub-id pub-id-type="doi">10.1093/molbev/msaa015</pub-id>
        <?supplied-pmid 32011700?>
        <pub-id pub-id-type="pmid">32011700</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kozlov</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Darriba</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Flouri</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Morel</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Stamatakis</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>RAxML-NG: a fast, scalable and user-friendly tool for maximum likelihood phylogenetic inference</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <fpage>4453</fpage>
        <lpage>4455</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btz305</pub-id>
        <?supplied-pmid 31070718?>
        <pub-id pub-id-type="pmid">31070718</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guindon</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>New algorithms and methods to estimate maximum-likelihood phylogenies: assessing the performance of PhyML 3.0</article-title>
        <source>Syst. Biol.</source>
        <year>2010</year>
        <volume>59</volume>
        <fpage>307</fpage>
        <lpage>321</lpage>
        <pub-id pub-id-type="doi">10.1093/sysbio/syq010</pub-id>
        <?supplied-pmid 20525638?>
        <pub-id pub-id-type="pmid">20525638</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sagulenko</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Puller</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Neher</surname>
            <given-names>RA</given-names>
          </name>
        </person-group>
        <article-title>TreeTime: maximum-likelihood phylodynamic analysis</article-title>
        <source>Virus Evol.</source>
        <year>2018</year>
        <volume>4</volume>
        <fpage>vex042</fpage>
        <pub-id pub-id-type="doi">10.1093/ve/vex042</pub-id>
        <?supplied-pmid 29340210?>
        <pub-id pub-id-type="pmid">29340210</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>To</surname>
            <given-names>TH</given-names>
          </name>
          <name>
            <surname>Jung</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lycett</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Gascuel</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>Fast dating using least-squares criteria and algorithms</article-title>
        <source>Syst. Biol.</source>
        <year>2016</year>
        <volume>65</volume>
        <fpage>82</fpage>
        <lpage>97</lpage>
        <pub-id pub-id-type="doi">10.1093/sysbio/syv068</pub-id>
        <?supplied-pmid 26424727?>
        <pub-id pub-id-type="pmid">26424727</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Volz</surname>
            <given-names>EM</given-names>
          </name>
          <name>
            <surname>Frost</surname>
            <given-names>SDW</given-names>
          </name>
        </person-group>
        <article-title>Scalable relaxed clock phylogenetic dating</article-title>
        <source>Virus Evol.</source>
        <year>2017</year>
        <volume>3</volume>
        <fpage>vex025</fpage>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pedregosa</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Scikit-learn: machine learning in Python</article-title>
        <source>J. Mach. Learn. Res.</source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>2825</fpage>
        <lpage>2830</lpage>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <mixed-citation publication-type="other">Abadi, M. et al. TensorFlow: large-scale machine learning on heterogeneous systems. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1603.04467">https://arxiv.org/abs/1603.04467</ext-link> (2015).</mixed-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <mixed-citation publication-type="other">Chollet, F. K. <ext-link ext-link-type="uri" xlink:href="https://keras.io">https://keras.io</ext-link> (2015).</mixed-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <mixed-citation publication-type="other">Clevert, D. A., Unterthiner, T. &amp; Hochreiter, S. Fast and accurate deep network learning by exponential linear units (ELUs). in <italic>ICLR</italic> (2016).</mixed-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <mixed-citation publication-type="other">Kingma, D. P. &amp; Ba, J. Adam: a method for stochastic optimization. In <italic>ICLR</italic> (2015).</mixed-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
        <source>J. Mach. Learn. Res.</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Di Tommaso</surname>
            <given-names>P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Nextflow enables reproducible computational workflows</article-title>
        <source>Nat. Biotechnol.</source>
        <year>2017</year>
        <volume>35</volume>
        <fpage>316</fpage>
        <lpage>319</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.3820</pub-id>
        <?supplied-pmid 28398311?>
        <pub-id pub-id-type="pmid">28398311</pub-id>
      </element-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <mixed-citation publication-type="other">Voznica, J. et al. Source code of “Deep learning from phylogenies to uncover the epidemiological dynamics of outbreaks”. <italic>Zenodo</italic>10.5281/zenodo.6646668 (2022).</mixed-citation>
    </ref>
  </ref-list>
</back>
