<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">11025179</article-id>
    <article-id pub-id-type="publisher-id">5775</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-024-05775-w</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>TrieDedup: a fast trie-based deduplication algorithm to handle ambiguous bases in high-throughput sequencing</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Hu</surname>
          <given-names>Jianqiao</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Luo</surname>
          <given-names>Sai</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tian</surname>
          <given-names>Ming</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Ye</surname>
          <given-names>Adam Yongxin</given-names>
        </name>
        <address>
          <email>yeyx2626@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00dvg7y05</institution-id><institution-id institution-id-type="GRID">grid.2515.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 0378 8438</institution-id><institution>Program in Cellular and Molecular Medicine, </institution><institution>Boston Children’s Hospital, </institution></institution-wrap>Boston, MA USA </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00cvxb145</institution-id><institution-id institution-id-type="GRID">grid.34477.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2298 6657</institution-id><institution>Present Address: Department of Biology, </institution><institution>University of Washington, </institution></institution-wrap>Seattle, WA USA </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.38142.3c</institution-id><institution-id institution-id-type="ISNI">000000041936754X</institution-id><institution>Harvard Medical School, </institution></institution-wrap>Boston, MA USA </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.2515.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 0378 8438</institution-id><institution>Howard Hughes Medical Institute, </institution><institution>Boston Children’s Hospital, </institution></institution-wrap>Boston, MA USA </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03cve4549</institution-id><institution-id institution-id-type="GRID">grid.12527.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 0662 3178</institution-id><institution>Present Address: School of Basic Medical Science, </institution><institution>Tsinghua University, </institution></institution-wrap>Beijing, China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>4</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>18</day>
      <month>4</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2024</year>
    </pub-date>
    <volume>25</volume>
    <elocation-id>154</elocation-id>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>1</month>
        <year>2024</year>
      </date>
      <date date-type="accepted">
        <day>10</day>
        <month>4</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">High-throughput sequencing is a powerful tool that is extensively applied in biological studies. However, sequencers may produce low-quality bases, leading to ambiguous bases, ‘N’s. PCR duplicates introduced in library preparation are conventionally removed in genomics studies, and several deduplication tools have been developed for this purpose. Two identical reads may appear different due to ambiguous bases and the existing tools cannot address ‘N’s correctly or efficiently.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Here we proposed and implemented TrieDedup, which uses the trie (prefix tree) data structure to compare and store sequences. TrieDedup can handle ambiguous base ‘N’s, and efficiently deduplicate at the level of raw sequences. We also reduced its memory usage by approximately 20% by implementing restrictedDict in Python. We benchmarked the performance of the algorithm and showed that TrieDedup can deduplicate reads up to 270-fold faster than pairwise comparison at a cost of 32-fold higher memory usage.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">The TrieDedup algorithm may facilitate PCR deduplication, barcode or UMI assignment, and repertoire diversity analysis of large-scale high-throughput sequencing datasets with its ultra-fast algorithm that can account for ambiguous bases due to sequencing errors.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12859-024-05775-w.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Deduplication</kwd>
      <kwd>Ambiguous bases</kwd>
      <kwd>Trie</kwd>
      <kwd>Prefix tree</kwd>
      <kwd>Next-generation sequencing</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
            <institution>National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01AI020047</award-id>
        <award-id>5P01 AI138211-04</award-id>
        <principal-award-recipient>
          <name>
            <surname>Hu</surname>
            <given-names>Jianqiao</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>Ming</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Bill &amp; Melinda Gates Foundation Investment, United States</institution>
        </funding-source>
        <award-id>INV-021989</award-id>
        <award-id>INV-021989</award-id>
        <principal-award-recipient>
          <name>
            <surname>Hu</surname>
            <given-names>Jianqiao</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id>
            <institution>Howard Hughes Medical Institute</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006823</institution-id>
            <institution>Boston Children's Hospital</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© BioMed Central Ltd., part of Springer Nature 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par16">High-throughput sequencing methods have been adapted and applied in many fields of biological studies, including immune repertoire studies [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Polymerase chain reaction (PCR), used during high-throughput sequencing library preparation, may lead to overrepresented templates, when multiple copies of the same DNA templates are amplified. These identical reads are termed as PCR duplicates [<xref ref-type="bibr" rid="CR3">3</xref>]. PCR amplification may be biased based on the sequence and quantity of DNA templates; therefore, PCR duplicates usually need to be marked or removed to keep only one copy of their original template, through deduplication. However, high-throughput sequencing has a relatively higher sequencing error rate in comparison to traditional Sanger sequencing, which poses challenges for data analysis, including deduplication. High-throughput sequencers use base quality score (<italic>Q</italic> score) to represent their confidence in the identity of each base [<xref ref-type="bibr" rid="CR4">4</xref>]. <italic>Q</italic> scores are logarithmically related to the base calling error probabilities <italic>P</italic>, such that <italic>Q</italic> = -10 × log<sub>10</sub><italic>P</italic> [<xref ref-type="bibr" rid="CR5">5</xref>]. For example, a <italic>Q</italic> score of 10 represents an estimated sequencing error rate of 10%, and a <italic>Q</italic> score of 20 represents an error rate of 1%. Due to Illumina sequencing chemistry, the average base quality usually decreases from 5′-end to 3′-end of the reads [<xref ref-type="bibr" rid="CR6">6</xref>]. Low-quality bases, often considered as bases whose <italic>Q</italic> scores are below 10 or 20, can be conventionally converted to the ambiguous base ‘N’s [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>]. Low-quality reads with too many ‘N’s are often discarded as a means of quality control [<xref ref-type="bibr" rid="CR7">7</xref>]. As described below, the presence of ambiguous ‘N’s in the remaining sequencing reads complicates the deduplication process.</p>
    <p id="Par17">Several bioinformatics tools have been developed for deduplication which work at two distinct levels, the level of alignment results and the level of raw reads. Tools that work on sequencing alignment files include samtools-rmdup [<xref ref-type="bibr" rid="CR3">3</xref>], Picard-MarkDuplicates [<xref ref-type="bibr" rid="CR9">9</xref>], EAGER-DeDup [<xref ref-type="bibr" rid="CR10">10</xref>], and gencore [<xref ref-type="bibr" rid="CR11">11</xref>]. A common deduplication strategy of alignment-result-based tools is to drop the reads that have the same coordinates of read alignment, sometimes ignoring the underlying sequences or ambiguous bases, ‘N’s. Our previous bioinformatics pipeline for LAM-HTGTS also performs deduplication according to the alignment coordinates without considering the underlying sequences [<xref ref-type="bibr" rid="CR12">12</xref>]. On the other hand, tools that work at the level of raw sequencing data usually perform sequence comparisons and store the unique, deduplicated sequences in a hash data structure. Such tools include pRESTO [<xref ref-type="bibr" rid="CR13">13</xref>], clumpify [<xref ref-type="bibr" rid="CR14">14</xref>], and dedupe [<xref ref-type="bibr" rid="CR15">15</xref>]. However, most sequence-based deduplication tools cannot handle ambiguous base ‘N’s correctly. In order to use hash for exact sequence matching, which is efficient when handling a large amount of data, they treat ‘N’ as a different base from regular bases ‘A’, ‘C’, ‘G’, ‘T’. Hence, sequence-based tools routinely consider two reads that only differ at positions of low sequencing quality as two distinct reads. The only exception is the tool, pRESTO. pRESTO uses hash to store deduplicated sequences, and its implementation of a pairwise comparison algorithm can handle ambiguous base ‘N’s when comparing a query sequence to the stored deduplicated sequences one-by-one. However, pairwise comparison has a complexity of approximately O(n<sup>2</sup>), and may not be feasible due to the long processing time when dealing with large amounts of input sequences.</p>
    <p id="Par18">A major application of NGS is the repertoire analysis of antibodies in humans and animals. The analysis provides valuable information about antibody diversity and enables the identification of antibodies that have important specific functions. The variable regions of antibodies or the corresponding B cell receptors (BCRs) are encoded by V exons that are assembled by V(D)J recombination during B cell development. The most diverse part of the antibody variable region is the complementarity determining region 3 (CDR3), which includes the junctions of V–D and D–J joints for the immunoglobulin heavy chain (IgH) and V–J join for the immunoglobulin light chain (IgL). To characterize antibody repertoires, we have developed the high-throughput genome-wide translocation sequencing-adapted repertoire and somatic hypermutation sequencing (HTGTS-Rep-SHM-Seq) assay, which can cover nearly full-length of the V(D)J-rearranged sequences after merging paired-end long-length MiSeq reads [<xref ref-type="bibr" rid="CR2">2</xref>]. This assay utilizes the genomic DNA sequence in B cells, with primers designed to target upstream of V segments and downstream of J segments, enabling characterization of the V(D)J recombination and CDR3 sequences of BCR. Each B cell has only one productive V(D)J rearranged allele for heavy chain or light chain; therefore, after deduplication, each read of productive V(D)J rearrangement will represent one B cell. Due to the high error rate of next-generation sequencing technology and the distance from the primers to the CDR3 region, a proportion of the reads capturing CDR3 sequences may contain low-quality ambiguous bases, represented as ‘N’s. Low-quality reads with too many ‘N’s are often discarded as a means of quality control [<xref ref-type="bibr" rid="CR7">7</xref>]. Nonetheless, outright discarding sequences containing any ‘N’s carries the potential risk of overlooking some rare events, which may still be important for biological functional studies. A case in point is a kind of rare IgL that contains a rare 5-amino acid (aa) CDR3. Such IgL with 5-aa CDR3 is a conserved and functionally important feature for a type of broadly neutralizing antibody (VRC01) against HIV-1 [<xref ref-type="bibr" rid="CR16">16</xref>]. To test our method, we analyzed the repertoire data of a mouse model that is engineered to express VRC01 class antibodies; such mouse model is used to test vaccine candidates for eliciting this kind of antibodies. Before the immunization study, it is important to determine the frequency of IgL with 5-aa CDR3, a pre-requisite for VRC01 antibody induction. By analyzing the relevant public dataset GSE214884, we observed that 5–10% of the CDR3 sequences contain ‘N’s, which increased to 12–38% for CDR3 longer than 12 aa (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1). We observed reads that were otherwise identical except for a few low-quality bases or ambiguous ‘N’s (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2), likely representing duplicates of the same template, although it is theoretically possible that these similar reads are indeed from different templates. An exact-matching approach to deduplication, which treats ‘N’s as distinct from other nucleotides, may artificially inflate the count of unique CDR3 sequences (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S3). For efficiency in processing huge amounts of sequencing data, our previous pipeline for HTGTS-Rep-SHM-Seq uses an alignment-result-based approach. It deals with ‘N’s by separating reads with and without ‘N’s, aligning reads with ‘N’s to reads without any ‘N’s using bowtie2, and checking their alignment length for deduplication [<xref ref-type="bibr" rid="CR2">2</xref>]. However, this approach cannot deduplicate among reads with ‘N’s when they do not have common equivalent reads without any ‘N’s. On the other hand, by pairwise comparison, pRESTO can deduplicate among reads with ‘N’s; but it runs slowly with the tremendous amount of input sequences.</p>
    <p id="Par19">Here, we designed and implemented TrieDedup, a faster deduplication algorithm that uses the trie (prefix tree) structure to store deduplicated sequences and efficiently deduplicates at the level of raw sequences, ignoring differences only due to low-quality ambiguous base ‘N’s. We implemented a custom Python class, restrictedDict, to reduce memory usage. We benchmarked the performance of TrieDedup and the pairwise comparison algorithm implemented in pRESTO with simulated data as well as real public data. The source code of TrieDedup is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/lolrenceH/TrieDedup">https://github.com/lolrenceH/TrieDedup</ext-link> under the Apache 2.0 license.</p>
  </sec>
  <sec id="Sec2">
    <title>Implementation</title>
    <sec id="Sec3">
      <title>Deduplication algorithm</title>
      <p id="Par20">Many sequence-based deduplication tools regard the ambiguous ‘N’ as different from the traditional bases, ‘A’, ‘C’, ‘G’, ‘T’, using hash-based exact matching to perform deduplication. The hash algorithm is highly efficient for comparing the literal identity of sequences. However, it offers no room for correctly accounting for sequencing ambiguity. Ambiguous ‘N’s potentially represent any of the four regular DNA bases. They should not be considered as different from other DNA bases by default.</p>
      <p id="Par21">Accounting for ‘N’s in deduplication poses two challenges: (1) when allowing differences at ‘N’s, the equivalence relationship between sequences may become complicated; and (2) we need an efficient algorithm to compare between a large amount of sequences and ignore ‘N’ differences.</p>
      <p id="Par22">For Challenge (1), theoretically, a network graph of equivalence relationship can be constructed, where each node represents an input sequence, and equivalent nodes are connected by an edge. Deduplication can be regarded as the well-known 'maximal independent set (MIS)' problem on the graph. A MIS is a set of nodes that are not adjacent, and its members and their neighbors include all the nodes in the graph. A deduplicated set is equivalent to a MIS on the network graph. The complication is that MIS may be not unique, and the sizes of MISs may vary. As a toy example, a simple equivalence graph ‘TAC’–‘TNC’–‘TGC’ has an MIS {‘TAC’, ‘TGC’} and another MIS {‘TNC’}. More generally, a star-shaped graph can have an MIS consisting of the tip nodes, or another MIS consisting of the center node. Thus, we need a principle for choosing a MIS. For sequence deduplication, we may prefer to choose the nodes with fewer ‘N’s to represent the observed sequences, which correspond to the tip nodes of the star-shaped graph.</p>
      <p id="Par23">Finding a MIS can be achieved by adding a candidate node into a MIS and removing neighbors of the node from the query, iteratively. Instead of performing a pairwise comparison between all input sequences, we can store unique sequences that are previously deduplicated and compare each query sequence to these established deduplicated sequences, reducing the number of comparisons (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). Because we prefer unambiguous sequences, we sort the input sequences by the number of ‘N’s in ascending order, and consider each read, sequentially. This progressive pairwise comparison is implemented in pRESTO.<fig id="Fig1"><label>Fig. 1</label><caption><p>Diagram of progressive pairwise comparison and TrieDedup algorithm</p></caption><graphic xlink:href="12859_2024_5775_Fig1_HTML" id="MO1"/></fig></p>
      <p id="Par24">For Challenge (2), the pairwise comparison algorithm needs to compare each input sequence with the full set of deduplicated sequences to determine if it is unique. We adapted the trie (prefix tree) structure to store the previously deduplicated sequences, whose prefixes are organized into a consensus tree. The trie structure can retain information of sequence similarity from previous comparisons, thereby reducing the number of necessary comparisons. The trie structure can immediately identify an unobserved sequence, as soon as the input sequence diverges from the observed paths, thus reducing the number of comparisons (Fig. <xref rid="Fig1" ref-type="fig">1</xref>).</p>
      <p id="Par25">In summary, we designed and implemented the following algorithms to store and compare sequences, which can ignore mismatches due to ‘N’s.
<fig position="anchor" id="Figa"><label>Algorithm 1</label><caption><p>Deduplication with trie storing a working set of deduplicated sequences</p></caption><graphic position="anchor" xlink:href="12859_2024_5775_Figa_HTML" id="MO2"/></fig><fig position="anchor" id="Figb"><label>Algorithm 2</label><caption><p>Adding a sequence to the trie storing already deduplicated sequences</p></caption><graphic position="anchor" xlink:href="12859_2024_5775_Figb_HTML" id="MO3"/></fig><fig position="anchor" id="Figc"><label>Algorithm 3</label><caption><p>Searching for a query sequence in the trie storing already deduplicated sequences</p></caption><graphic position="anchor" xlink:href="12859_2024_5775_Figc_HTML" id="MO4"/></fig></p>
      <p id="Par26">Note:<list list-type="order"><list-item><p id="Par27">keep ‘N’ the last stored_base (after regular bases) when traversing trie_node</p></list-item><list-item><p id="Par28">searching the whole sequence from trie_root by: trie_root.search(sequence, 0)</p></list-item></list></p>
      <p id="Par29">As an implementation detail, to avoid repeatedly checking the same sequence, we also implemented exact-matching deduplication using a hash dict. This step is executed before performing actual deduplication through the trie algorithm. Subsequently, sequences are sorted in ascending order based on the number of ‘N’s present, ensuring that high-quality sequences are processed first, recognized as unique, and stored in the already deduplicated set. Sequences with more ‘N’s are processed later and progressively matched against those deduplicated sequences with fewer ambiguous ‘N’s.</p>
    </sec>
    <sec id="Sec4">
      <title>Memory usage optimization</title>
      <p id="Par30">The pairwise comparison algorithm directly stores every deduplicated, unique sequence, while our algorithm stores them in the trie structure, which theoretically costs less memory. However, empirically, storing a trie structure may cost more memory on the dict data structure than just storing simple sequences in hash keys, potentially due to Python’s base-level optimizations. To reduce memory consumption, we used __slots__ magic in Python to declare the variables. In Python, by default, a class instance declares a dict attribute named __dict__ to dynamically store its variable names and values. The __slots__ attribute in Python allows for the declaration of a fixed set of attributes for class objects, preventing the creation of the instance dict __dict__, thus significantly reducing the memory footprint of each class instance. We also implemented restrictedDict, a restricted dict with list implementation: it restricts hash keys to predetermined options, stores the values in a list instead of a dict, and keeps a shared dict to map limited keys to the index in the list. The restrictedDict achieves a smaller memory usage by storing values in a list instead of a dict, accommodating for large sequencing datasets. In DNA sequencing data, there are five possible base identities: 'A', 'C', 'G', 'T', and ‘N’. Thus, we only keep one dict as a shared class variable of restrictedDict, which stores the mapping table from the base letter (as the keys of dict) to the index in the list. For simplicity in describing the results, we abbreviate the original trie implementation as trie0, trie with only __slots__ magic as trie1, and trie with __slots__ and restrictedDict as trie2.</p>
    </sec>
    <sec id="Sec5">
      <title>Benchmark and comparison to other tools</title>
      <p id="Par31">We compared progressive pairwise comparison algorithm and trie implementation with or without memory optimization in a Dell PowerEdge T640 server, with 192GB physical memory and limited to one CPU of Intel Xeon Gold 6126 2.6GHz, and in RedHat Linux operation system. In order to ensure a fair comparison with pRESTO, which is implemented in Python and has additional functions that may affect its efficiency, we reimplemented the progressive pairwise comparison algorithm according to pRESTO. We benchmarked the accuracy, running time, and memory usage of the exact-matching, pairwise comparison, and trie algorithms using both simulated reads or real public reads as input.</p>
      <p id="Par32">To simulate input sequences, we first generated a unique set of parental sequences of a specific length, then randomly sampled them with replacement, which usually sampled approximately 55% of unique parental sequences, and lastly converted a fixed number of bases at random locations to ‘N’s in each sampled sequence. We considered sequences originating from the same parental sequence to be PCR duplicates; thereby we knew the ground truth for the size of the deduplicated set. We performed comparisons for 10<sup>3</sup>, 2 × 10<sup>3</sup>, 5 × 10<sup>3</sup>, 10<sup>4</sup>, 2 × 10<sup>4</sup>, 5 × 10<sup>4</sup>, 10<sup>5</sup>, 2 × 10<sup>5</sup>, 5 × 10<sup>5</sup>, and 10<sup>6</sup> input sequences, with lengths of 30, 100, 150, and 200 bp, and converted 1%, 5%, 10% or 20% bases to ‘N’s for each input sequence. Each condition is tested with three repeats.</p>
      <p id="Par33">We also benchmarked the performance in public HTGTS-Rep-SHM-seq data of the BCR repertoire. We downloaded raw fastq files for SRR3744758, SRR3744760 and SRR3744762 from SRA, each containing slightly more than 1 million 300-bp paired-end reads. We then randomly selected 1 million reads and masked bases with a quality score ≤ 10 by ‘N’ to serve as the input sequences.</p>
    </sec>
  </sec>
  <sec id="Sec6">
    <title>Results</title>
    <sec id="Sec7">
      <title>Theoretical complexity analysis</title>
      <p id="Par34">Suppose there are <italic>n</italic> input sequences, and each sequence has <italic>m</italic> bases. For the preprocessing steps, the time complexity of counting ‘N’s is O(<italic>m</italic> × <italic>n</italic>), and sorting <italic>n</italic> sequences can be O(<italic>n</italic> × log(<italic>n</italic>)) for quick sort, or O(<italic>n</italic>) for bucket sort.</p>
      <p id="Par35">Suppose we progressively add sequences to the deduplicated set, and the deduplicated set has already stored <italic>n</italic><sub>d</sub> sequences. The space complexity of plain storing <italic>n</italic><sub>d</sub> sequences is O(<italic>m</italic> × <italic>n</italic><sub>d</sub>). The algorithm of pairwise comparison between a candidate sequence and the deduplicated set has time complexity O(<italic>m</italic> × <italic>n</italic><sub>d</sub>). Then, the overall complexity of the whole deduplication process is O(<italic>m</italic> × <italic>n</italic><sup>2</sup>). This algorithm has been implemented in pRESTO, which runs slowly with a large number <italic>n</italic> of input sequences.</p>
      <p id="Par36">Here, we designed and implemented an algorithm using the trie structure to store the already deduplicated sequences. The upper limit of the space complexity of the trie structure storing <italic>n</italic><sub>d</sub> sequences is O(<italic>m</italic> × <italic>n</italic><sub>d</sub>), and should be lower when the sequences have common prefixes. Without ‘N’s, the time complexity of comparison between a query sequence and the trie structure is only O(<italic>m</italic>); therefore, the lowest overall complexity of the whole deduplication process is O(<italic>m</italic> × <italic>n</italic>). However, when allowing ambiguous base ‘N’s, we may need to explore more branches in the trie to determine the comparison result. Theoretically, the upper limit of complexity for one query sequence is O(<italic>m</italic> × <italic>n</italic><sub>d</sub>); therefore, the upper bound of the overall complexity is still O(<italic>m</italic> × <italic>n</italic><sup>2</sup>). Though, this situation may rarely happen as long as the input sequences do not contain too many ‘N’s. If each sequence has at most <italic>k</italic> ‘N’s, the upper limit of the time complexity between one query sequence and the trie structure is O(<italic>m</italic> × 5<sup><italic>k</italic></sup>), for 5 possible choices of bases ('A', 'C', 'G', 'T', ‘N’) at <italic>k</italic> trie nodes; therefore, the overall time complexity is O(<italic>m</italic> × <italic>n</italic> × 5<sup><italic>k</italic></sup>). Theoretically, the actual time complexity is dependent on the amount and location of ‘N’s in sequences. Sequences with fewer ‘N’s or ‘N’s located closer to the end (near trie tips) will have less complexity than those with more ‘N’s or ‘N’s located closer to the start (near trie root).</p>
    </sec>
    <sec id="Sec8">
      <title>Benchmark on simulated data</title>
      <p id="Par37">We benchmarked the accuracy, speed and memory consumption of the trie algorithm with or without memory optimization, and compared them to the performance of the progressive pairwise comparison algorithm, which we reimplemented from pRESTO, using the simulated 200-bp reads. Both the pairwise comparison and trie algorithms demonstrate high accuracy in recovering the deduplicated sets to the ground truth sizes (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4). In contrast, the exact-matching approach, which treats ‘N’s as distinct from other nucleotides, inflates the sizes a lot (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4), although it runs very fast (&lt; 2.5 s for <italic>n</italic> = 10<sup>6</sup>) and requires minimal memory (&lt; 0.7 GB for <italic>n</italic> = 10<sup>6</sup>).</p>
      <p id="Par38">The pairwise comparison and all the trie algorithms show an approximately linear relationship between log-transformed running time and the log-transformed number of input sequences (Fig. <xref rid="Fig2" ref-type="fig">2</xref>A). The slope of pairwise comparison is close to the theoretical order 2. On the other hand, the slope of the trie algorithm is much lower, which is ≤ 1.3 for <italic>n</italic> ≤ 10<sup>5</sup> and the percentage of ambiguous bases in reads (N%) ≤ 10%, and increases for larger <italic>n</italic> or N%. When the input sequences are less than 5000, the pairwise comparison algorithm is more efficient than the trie algorithm whose performance is less than 3s. When there are more than 5000 input sequences, the trie algorithm runs significantly faster than pairwise comparison.<fig id="Fig2"><label>Fig. 2</label><caption><p>Running time and memory usage increases with larger amount of input sequences (benchmark simulation). <bold>A</bold> Running time; <bold>B</bold> memory usage. Input sequences are 200 bp in length. Error bars shows mean ± standard deviation, each with 3 replicates</p></caption><graphic xlink:href="12859_2024_5775_Fig2_HTML" id="MO5"/></fig></p>
      <p id="Par39">The trie algorithm significantly outperforms pairwise comparison at large input sizes. For example, at N% = 5% and <italic>n</italic> = 10<sup>4</sup>, pairwise comparison needs 8.9s (on average), trie algorithm needs ≤ 5.0s; at <italic>n</italic> = 10<sup>5</sup>, pairwise comparison needs 1100 s (or 18.3 min), trie algorithm needs ≤ 55s; at <italic>n</italic> = 10<sup>6</sup>, pairwise comparison needs 125000s (or 34.7h), trie algorithm needs ≤ 1755s (or 29.3 min).</p>
      <p id="Par40">When comparing the running time among the three different options of memory optimization of the trie implementation, we found that all the three options have very similar running time, without magnitude difference. Trie1 runs relatively faster than trie0 and trie2, with the difference being less than twofold (Fig. <xref rid="Fig2" ref-type="fig">2</xref>A).</p>
      <p id="Par41">In terms of memory usage, the pairwise algorithm is more memory-efficient to implement than the trie because entire sequences can be stored as one item instead of storing each base individually (Fig. <xref rid="Fig2" ref-type="fig">2</xref>B). Among three trie implementations, as expected, trie0 requires the most memory and trie2 requires the least. The slopes for the three options in Python implementation are similar, all close to but a little less than the theoretical 1. For <italic>n</italic> ≥ 10<sup>5</sup>, the implementation of restrictedDict (trie2) improves the memory usage of __slots__ optimization (trie1) by approximately 19%, while trie1 improves 20% compared to trie0; therefore, trie2 only uses 65% memory as much as trie0 uses.</p>
      <p id="Par42">When N% = 5% and <italic>n</italic> = 10<sup>4</sup>, pairwise comparison on average requires 0.07GB memory to run, while trie0 requires 0.62GB, trie1 0.51GB, and trie2 0.42GB; when <italic>n</italic> = 10<sup>5</sup>, pairwise comparison needs 0.19GB, trie0 5.6GB, trie1 4.5GB, and trie2 3.7GB; when <italic>n</italic> = 10<sup>6</sup>, pairwise comparison requires 1.6GB, trie0 55GB, trie1 44GB, and trie2 36GB.</p>
      <p id="Par43">We also evaluated the influence of the length of input sequences and N% on the performance of pairwise comparison and trie2 (Additional file <xref rid="MOESM2" ref-type="media">2</xref>: Fig. S1, Additional file <xref rid="MOESM2" ref-type="media">2</xref>: Fig. S2). As expected, longer length will need more running time and memory usage. The percentage of ambiguous bases in reads (N%) barely impacts the memory usage of both algorithms. This is likely because the memory usage is more closely correlated with the number of unique reads stored in the already deduplicated set, whose ground truth remained constant across different N% in our simulation. On the other hand, a higher N% increases the running time of the trie algorithm, while it does not affect the running time of pairwise comparison. This may be because the pairwise comparison algorithm requires a lot of comparisons between sequence pairs until it finds a match, which is not significantly affected by N; whereas the trie algorithm needs to search through more branches when the query sequence contains more ‘N’s. Additionally, when a sequence with more ‘N’s is considered unique and added to the trie structure, it may slow down subsequent searches by increasing the possible branches at ‘N’.</p>
    </sec>
    <sec id="Sec9">
      <title>Benchmark on real data</title>
      <p id="Par44">We applied the exact-matching, pairwise comparison, and trie algorithms to published sequencing data with a read length of 300 bp and an average N% of 4.9–15.8%. As expected, higher N% and a lower percentage of unique reads were observed in R2 than in R1 reads. With an input size of 10<sup>6</sup> raw reads, both pairwise comparison and trie algorithms reported the same numbers of unique reads (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4). In contrast, although the exact-matching approach runs very fast (&lt; 4 s) and requires minimal memory (&lt; 0.75 GB), it likely inflates the sizes of deduplicated sets, especially for R2 reads, whose N% is higher than R1 reads (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4). Deduplication by trie2 only needed 0.9–2.1 h using 35–55 GB of memory, while deduplication by pairwise comparison required 6–16 days with about 1.5 GB memory usage (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). Therefore, trie2 deduplication can achieve about 270-fold faster speed than pairwise comparison, with 32-fold higher memory usage.<fig id="Fig3"><label>Fig. 3</label><caption><p>Running time and memory usage when applying on 10<sup>6</sup> real 300-bp reads from SRA. X-axis ‘N%’ shows the average percentage of ambiguous base ‘N’s in reads</p></caption><graphic xlink:href="12859_2024_5775_Fig3_HTML" id="MO6"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec10">
    <title>Discussion</title>
    <p id="Par45">To deduplicate high-throughput sequencing libraries while ignoring differences only due to ambiguous base ‘N’s, we adapted the trie structure to store deduplicated sequences, and implemented a corresponding algorithm, named TrieDedup. When the input size is larger than 5000 sequences, the trie algorithm is more efficient than the pairwise comparison algorithm used in pRESTO, at the price of higher memory usage. TrieDedup can deduplicate up to 10<sup>6</sup> input sequences within 2 h using less than 36GB of memory. In addition, TrieDedup may be potentially adapted into pRESTO framework.</p>
    <p id="Par46">The real data we used for benchmarking were public HTGTS-Rep-SHM-seq data of BCR repertoire downloaded from SRA (SRR3744758, SRR3744760, and SRR3744762). For such a typical study targeting B cell receptor repertoire, these samples originally contain 1.22 million, 1.10 million, and 1.49 million 300-bp reads respectively, with the fastq file sizes being approximately 1.6 GB, 1.5 GB, and 2 GB. For our benchmark experiments, we randomly selected 1 million reads from these samples, believing that this number represents a realistic read number for this type of sequencing data. For the other genomic studies, the read number can vary significantly in scale, which depends on the targeted genomic region size, the depth of sequencing, and the lengths of sequenced reads. For instance, a 30X Whole Genome Sequencing (WGS) of a human genome typically requires around 900 million 100-bp reads, while an 80X Whole Exome Sequencing (WES) might need about 24 million 100-bp reads. These quantities are 1–3 orders of magnitude higher than those typical targeted sequencing such as B cell repertoire studies. Our benchmark suggests a dataset of up to 1 million reads, or a fastq file size of approximately 1.5GB, can be efficiently deduplicated by our TrieDedup with approximately 36GB of memory usage which a typical server has the memory capacity to support. Since both the running time and memory usage increase with the number of input sequences, and the complexity order of running time on N exceeds one, the efficiency of deduplication may be further improved if we can divide the input sequences into smaller non-overlapping groups. To handle a larger number of reads, we also recommend grouping reads to reduce each group to below 1 million reads. For example, the reads may be grouped based on sequence prefixes, or the mapped chromosome and coordinate range if the reads have been aligned, or the V and J alignment for V(D)J repertoire. If these subsets of data are processed separately, the algorithm will have to store fewer reads simultaneously, hence reducing memory usage.</p>
    <p id="Par47">Trie structure has also been used in the deduplication of Unique Molecular Identifiers (UMIs) [<xref ref-type="bibr" rid="CR17">17</xref>], but the traditional trie structure cannot handle ambiguous bases, although errors in UMIs are common [<xref ref-type="bibr" rid="CR18">18</xref>]. UMIs containing any ‘N’s or bases with a <italic>Q</italic> score below 10 are by default filtered out during 10x Genomics Cell Ranger processing. Here, we designed and implemented TrieDedup, where the specialized trie structure and algorithm can correctly and efficiently handle the differences due to ambiguous bases. With its ultra-fast algorithm, TrieDedup may also potentially be applied to barcode or UMI assignment when considering reads with a few low-quality bases in the UMIs.</p>
    <p id="Par48">We designed, implemented, and showcased a universal algorithm using a trie for deduplication that allows for ambiguous letter matching, therefore, we did not restrict the allowed keys of restrictedDict to ‘A’, ‘C’, ‘G’, ‘T’ and ‘N’. Our highly versatile TrieDedup algorithm can be applied not only to DNA reads, as evaluated in the manuscript, but also directly to protein amino acid sequences and even text word matching. To further improve runtime and memory usage, we also implemented TrieDedup in Java and C++, but hard-coded the allowed keys to DNA bases. These implementations are also available in our GitHub repository. Compared to Python implementation, TrieDedup C++ implementation achieved 5–11-fold faster and 1/3 memory. However, it imposes limitations by being restricted solely to DNA sequences, underscoring a trade-off between performance optimization and general applicability.</p>
    <p id="Par49">The threshold of <italic>Q</italic> scores for converting low-quality bases to ambiguous ‘N’s, which is often library-specifically set to 10 or 20 arbitrarily, may affect N% in input reads, as well as the amount of deduplicated reads. A potentially more principled approach is to sum up the error rate of mismatches in pairwise comparison, and then set the threshold on the sum error rate to judge the equivalence between reads. However, it may generate a more complicated relationship of equivalence and even higher computational complexity than the current pairwise comparison algorithm in pRESTO.</p>
  </sec>
  <sec id="Sec11">
    <title>Conclusions</title>
    <p id="Par50">We implemented TrieDedup, which uses the trie structure to store deduplicated sequences, and ignores differences only due to ambiguous base ‘N’s. We also implemented a memory-efficient class, restrictedDict, that reduced the memory usage to about 0.8-fold. TrieDedup significantly outperforms the pairwise comparison strategy when the amount of input sequences is larger than a few thousand. TrieDedup can deduplicate reads up to 270-fold faster than pairwise comparison at a cost of 32-fold higher memory usage. Potentially, TrieDedup may be adapted into pRESTO, and may be generalized to other scenarios for deduplication with ambiguous letters.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <sec id="Sec12">
      <title>Supplementary Information</title>
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2024_5775_MOESM1_ESM.xlsx">
            <caption>
              <p><bold>Additional file 1: Table S1.</bold> The percentage of CDR3 sequences containing ambiguous bases (‘N’s) in public dataset GSE214884. <bold>Table S2.</bold> Unique and potential duplicate sequences with ambiguous bases ‘N’s in 5-aa CDR3 sequences from GSM6617404. <bold>Table S3.</bold> The number of CDR3 sequences before and after deduplication in public dataset GSE214884. <bold>Table S4.</bold> The number of sequences after deduplication for benchmark analysis.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="12859_2024_5775_MOESM2_ESM.docx">
            <caption>
              <p><bold>Additional file 2: Figure S1.</bold> Running time for input sequences with different lengths. Error bars shows mean ± standard deviation, each with 3 replicates. <bold>Figure S2.</bold> Memory usage for input sequences with different lengths. Error bars shows mean ± standard deviation, each with 3 replicates.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>PCR</term>
        <def>
          <p id="Par4">Polymerase chain reaction</p>
        </def>
      </def-item>
      <def-item>
        <term><italic>Q</italic> score</term>
        <def>
          <p id="Par5">Base quality score</p>
        </def>
      </def-item>
      <def-item>
        <term>BCR</term>
        <def>
          <p id="Par6">B cell receptor</p>
        </def>
      </def-item>
      <def-item>
        <term>CDR</term>
        <def>
          <p id="Par7">Complementarity-determining region</p>
        </def>
      </def-item>
      <def-item>
        <term>HTGTS-Rep-SHM-Seq</term>
        <def>
          <p id="Par8">High-throughput genome-wide translocation sequencing-adapted repertoire and somatic hypermutation sequencing</p>
        </def>
      </def-item>
      <def-item>
        <term>aa</term>
        <def>
          <p id="Par9">Amino acid</p>
        </def>
      </def-item>
      <def-item>
        <term>MIS</term>
        <def>
          <p id="Par10">Maximal independent set</p>
        </def>
      </def-item>
      <def-item>
        <term>trie0</term>
        <def>
          <p id="Par11">Trie implementation without memory optimization</p>
        </def>
      </def-item>
      <def-item>
        <term>trie1</term>
        <def>
          <p id="Par12">Trie implementation with only __slots__ magic</p>
        </def>
      </def-item>
      <def-item>
        <term>trie2</term>
        <def>
          <p id="Par13">Trie implementation with __slots__ and restrictedDict</p>
        </def>
      </def-item>
      <def-item>
        <term>N%</term>
        <def>
          <p id="Par14">Percentage of ambiguous bases in reads</p>
        </def>
      </def-item>
      <def-item>
        <term>UMIs</term>
        <def>
          <p id="Par15">Unique Molecular Identifiers</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to express our deep gratitude to Prof. Frederick W Alt, for his unwavering support and generously providing the necessary resources and funding throughout this projects.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>SL and MT raised the scientific questions, AYY conceptualized and designed the software. AYY and JH developed the software. JH, SL and MT, and AYY tested and validated the software. JH performed benchmark analysis. JH and AYY conducted data analysis and visualization. JH, SL and MT, and AYY wrote the manuscript. All authors read, critically revised, and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>AYY is a Bioinformatics Specialist of Howard Hughes Medical Institute and Boston Children's Hospital. JH receives salary support from NIH Grants R01AI020047, R01AI077595 and Bill &amp; Melinda Gates Foundation Investment INV-021989. SL receives salary support from Bill &amp; Melinda Gates Foundation Investment INV-021989. MT receives salary support from NIH/NIAID Grants 5P01 AI138211-04 (to M.A), 5UM1 AI144371-03 (to B.H.) and Bill &amp; Melinda Gates Foundation Investment INV-021989 (to F.A. and M.T.).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>TrieDedup code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/lolrenceH/TrieDedup">https://github.com/lolrenceH/TrieDedup</ext-link>. The real data we used for benchmarking are public data downloaded from NCBI-SRA, with accession number: SRR3744758 (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/SRR3744758">https://www.ncbi.nlm.nih.gov/sra/SRR3744758</ext-link>), SRR3744760 (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/SRR3744760">https://www.ncbi.nlm.nih.gov/sra/SRR3744760</ext-link>) and SRR3744762 (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/SRR3744762">https://www.ncbi.nlm.nih.gov/sra/SRR3744762</ext-link>). Project name: TrieDedup: A fast trie-based deduplication algorithm to handle ambiguous bases in high-throughput sequencing. Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/lolrenceH/TrieDedup">https://github.com/lolrenceH/TrieDedup</ext-link>. Operating system(s): Platform independent. Programming language: Python, with C++ and Java implementations available on GitHub. Other requirements: seqtk, pandas. License: Apache 2.0. Any restrictions to use by non-academics: None.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar4">
      <title>Ethics approval and consent to participate</title>
      <p id="Par51">Not applicable.</p>
    </notes>
    <notes id="FPar5">
      <title>Consent for publication</title>
      <p id="Par52">Not applicable.</p>
    </notes>
    <notes id="FPar6" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par53">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>SG</given-names>
          </name>
          <name>
            <surname>Ba</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Alt</surname>
            <given-names>FW</given-names>
          </name>
        </person-group>
        <article-title>Highly sensitive and unbiased approach for elucidating antibody repertoires</article-title>
        <source>Proc Natl Acad Sci</source>
        <year>2016</year>
        <volume>113</volume>
        <fpage>7846</fpage>
        <lpage>7851</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1608649113</pub-id>
        <?supplied-pmid 27354528?>
        <pub-id pub-id-type="pmid">27354528</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>AY</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>C-S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>BCR selection and affinity maturation in Peyer’s patch germinal centres</article-title>
        <source>Nature</source>
        <year>2020</year>
        <volume>582</volume>
        <fpage>421</fpage>
        <lpage>425</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-020-2262-4</pub-id>
        <?supplied-pmid 32499646?>
        <pub-id pub-id-type="pmid">32499646</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Handsaker</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Wysoker</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Fennell</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ruan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Homer</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The sequence alignment/map format and SAMtools</article-title>
        <source>Bioinformatics</source>
        <year>2009</year>
        <volume>25</volume>
        <fpage>2078</fpage>
        <lpage>2079</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btp352</pub-id>
        <?supplied-pmid 19505943?>
        <pub-id pub-id-type="pmid">19505943</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cock</surname>
            <given-names>PJA</given-names>
          </name>
          <name>
            <surname>Fields</surname>
            <given-names>CJ</given-names>
          </name>
          <name>
            <surname>Goto</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Heuer</surname>
            <given-names>ML</given-names>
          </name>
          <name>
            <surname>Rice</surname>
            <given-names>PM</given-names>
          </name>
        </person-group>
        <article-title>The Sanger FASTQ file format for sequences with quality scores, and the Solexa/Illumina FASTQ variants</article-title>
        <source>Nucleic Acids Res</source>
        <year>2010</year>
        <volume>38</volume>
        <fpage>1767</fpage>
        <lpage>1771</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkp1137</pub-id>
        <?supplied-pmid 20015970?>
        <pub-id pub-id-type="pmid">20015970</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ewing</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Green</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Base-calling of automated sequencer traces using <italic>Phred</italic>. II. Error probabilities</article-title>
        <source>Genome Res</source>
        <year>1998</year>
        <volume>8</volume>
        <fpage>186</fpage>
        <lpage>194</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.8.3.186</pub-id>
        <?supplied-pmid 9521922?>
        <pub-id pub-id-type="pmid">9521922</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Manley</surname>
            <given-names>LJ</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Levine</surname>
            <given-names>SS</given-names>
          </name>
        </person-group>
        <article-title>Monitoring error rates in illumina sequencing</article-title>
        <source>J Biomol Tech</source>
        <year>2016</year>
        <volume>27</volume>
        <fpage>125</fpage>
        <lpage>128</lpage>
        <pub-id pub-id-type="doi">10.7171/jbt.16-2704-002</pub-id>
        <?supplied-pmid 27672352?>
        <pub-id pub-id-type="pmid">27672352</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">Hannon GJ. FASTX-Toolkit. GitHub repository. 2010. <ext-link ext-link-type="uri" xlink:href="http://hannonlab.cshl.edu/fastx_toolkit">http://hannonlab.cshl.edu/fastx_toolkit</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">Li H. seqtk. GitHub repository. 2018. <ext-link ext-link-type="uri" xlink:href="https://github.com/lh3/seqtk">https://github.com/lh3/seqtk</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Broad Institute. Picard toolkit. GitHub repository. 2019. <ext-link ext-link-type="uri" xlink:href="https://broadinstitute.github.io/picard/">https://broadinstitute.github.io/picard/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peltzer</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jäger</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Herbig</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Seitz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kniep</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Krause</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>EAGER: efficient ancient genome reconstruction</article-title>
        <source>Genome Biol</source>
        <year>2016</year>
        <volume>17</volume>
        <fpage>60</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-016-0918-z</pub-id>
        <?supplied-pmid 27036623?>
        <pub-id pub-id-type="pmid">27036623</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Liao</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Gencore: an efficient tool to generate consensus reads for error suppressing and duplicate removing of NGS data</article-title>
        <source>BMC Bioinform</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>606</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-019-3280-9</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Meyers</surname>
            <given-names>RM</given-names>
          </name>
          <name>
            <surname>Dong</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Panchakshari</surname>
            <given-names>RA</given-names>
          </name>
          <name>
            <surname>Alt</surname>
            <given-names>FW</given-names>
          </name>
          <name>
            <surname>Frock</surname>
            <given-names>RL</given-names>
          </name>
        </person-group>
        <article-title>Detecting DNA double-stranded breaks in mammalian genomes by linear amplification–mediated high-throughput genome-wide translocation sequencing</article-title>
        <source>Nat Protoc</source>
        <year>2016</year>
        <volume>11</volume>
        <fpage>853</fpage>
        <lpage>871</lpage>
        <pub-id pub-id-type="doi">10.1038/nprot.2016.043</pub-id>
        <?supplied-pmid 27031497?>
        <pub-id pub-id-type="pmid">27031497</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vander Heiden</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Yaari</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Uduman</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Stern</surname>
            <given-names>JNH</given-names>
          </name>
          <name>
            <surname>O’Connor</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Hafler</surname>
            <given-names>DA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>pRESTO: a toolkit for processing high-throughput sequencing raw reads of lymphocyte receptor repertoires</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <fpage>1930</fpage>
        <lpage>1932</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu138</pub-id>
        <?supplied-pmid 24618469?>
        <pub-id pub-id-type="pmid">24618469</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Bushnell B. BBMap—clumpify. GitHub repository. 2021. <ext-link ext-link-type="uri" xlink:href="https://github.com/BioInfoTools/BBMap/blob/master/sh/clumpify.sh">https://github.com/BioInfoTools/BBMap/blob/master/sh/clumpify.sh</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Gregg F, Eder D. Dedupe. GitHub repository. 2022. <ext-link ext-link-type="uri" xlink:href="https://github.com/dedupeio/dedupe">https://github.com/dedupeio/dedupe</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luo</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Jing</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>AY</given-names>
          </name>
          <name>
            <surname>Kratochvil</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Cottrell</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Koo</surname>
            <given-names>J-H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Humanized V(D)J-rearranging and TdT-expressing mouse vaccine models with physiological HIV-1 broadly neutralizing antibody precursors</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2023</year>
        <volume>120</volume>
        <fpage>e2217883120</fpage>
        <pub-id pub-id-type="doi">10.1073/pnas.2217883120</pub-id>
        <?supplied-pmid 36574685?>
        <pub-id pub-id-type="pmid">36574685</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Algorithms for efficiently collapsing reads with Unique Molecular Identifiers</article-title>
        <source>PeerJ</source>
        <year>2019</year>
        <volume>7</volume>
        <fpage>e8275</fpage>
        <pub-id pub-id-type="doi">10.7717/peerj.8275</pub-id>
        <?supplied-pmid 31871845?>
        <pub-id pub-id-type="pmid">31871845</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Smith</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Heger</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sudbery</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>UMI-tools: modeling sequencing errors in Unique Molecular Identifiers to improve quantification accuracy</article-title>
        <source>Genome Res</source>
        <year>2017</year>
        <volume>27</volume>
        <fpage>491</fpage>
        <lpage>499</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.209601.116</pub-id>
        <?supplied-pmid 28100584?>
        <pub-id pub-id-type="pmid">28100584</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">11025179</article-id>
    <article-id pub-id-type="publisher-id">5775</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-024-05775-w</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>TrieDedup: a fast trie-based deduplication algorithm to handle ambiguous bases in high-throughput sequencing</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Hu</surname>
          <given-names>Jianqiao</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Luo</surname>
          <given-names>Sai</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tian</surname>
          <given-names>Ming</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Ye</surname>
          <given-names>Adam Yongxin</given-names>
        </name>
        <address>
          <email>yeyx2626@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00dvg7y05</institution-id><institution-id institution-id-type="GRID">grid.2515.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 0378 8438</institution-id><institution>Program in Cellular and Molecular Medicine, </institution><institution>Boston Children’s Hospital, </institution></institution-wrap>Boston, MA USA </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00cvxb145</institution-id><institution-id institution-id-type="GRID">grid.34477.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2298 6657</institution-id><institution>Present Address: Department of Biology, </institution><institution>University of Washington, </institution></institution-wrap>Seattle, WA USA </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.38142.3c</institution-id><institution-id institution-id-type="ISNI">000000041936754X</institution-id><institution>Harvard Medical School, </institution></institution-wrap>Boston, MA USA </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.2515.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 0378 8438</institution-id><institution>Howard Hughes Medical Institute, </institution><institution>Boston Children’s Hospital, </institution></institution-wrap>Boston, MA USA </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03cve4549</institution-id><institution-id institution-id-type="GRID">grid.12527.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 0662 3178</institution-id><institution>Present Address: School of Basic Medical Science, </institution><institution>Tsinghua University, </institution></institution-wrap>Beijing, China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>4</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>18</day>
      <month>4</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2024</year>
    </pub-date>
    <volume>25</volume>
    <elocation-id>154</elocation-id>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>1</month>
        <year>2024</year>
      </date>
      <date date-type="accepted">
        <day>10</day>
        <month>4</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">High-throughput sequencing is a powerful tool that is extensively applied in biological studies. However, sequencers may produce low-quality bases, leading to ambiguous bases, ‘N’s. PCR duplicates introduced in library preparation are conventionally removed in genomics studies, and several deduplication tools have been developed for this purpose. Two identical reads may appear different due to ambiguous bases and the existing tools cannot address ‘N’s correctly or efficiently.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Here we proposed and implemented TrieDedup, which uses the trie (prefix tree) data structure to compare and store sequences. TrieDedup can handle ambiguous base ‘N’s, and efficiently deduplicate at the level of raw sequences. We also reduced its memory usage by approximately 20% by implementing restrictedDict in Python. We benchmarked the performance of the algorithm and showed that TrieDedup can deduplicate reads up to 270-fold faster than pairwise comparison at a cost of 32-fold higher memory usage.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">The TrieDedup algorithm may facilitate PCR deduplication, barcode or UMI assignment, and repertoire diversity analysis of large-scale high-throughput sequencing datasets with its ultra-fast algorithm that can account for ambiguous bases due to sequencing errors.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12859-024-05775-w.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Deduplication</kwd>
      <kwd>Ambiguous bases</kwd>
      <kwd>Trie</kwd>
      <kwd>Prefix tree</kwd>
      <kwd>Next-generation sequencing</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
            <institution>National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01AI020047</award-id>
        <award-id>5P01 AI138211-04</award-id>
        <principal-award-recipient>
          <name>
            <surname>Hu</surname>
            <given-names>Jianqiao</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>Ming</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Bill &amp; Melinda Gates Foundation Investment, United States</institution>
        </funding-source>
        <award-id>INV-021989</award-id>
        <award-id>INV-021989</award-id>
        <principal-award-recipient>
          <name>
            <surname>Hu</surname>
            <given-names>Jianqiao</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id>
            <institution>Howard Hughes Medical Institute</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006823</institution-id>
            <institution>Boston Children's Hospital</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© BioMed Central Ltd., part of Springer Nature 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par16">High-throughput sequencing methods have been adapted and applied in many fields of biological studies, including immune repertoire studies [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Polymerase chain reaction (PCR), used during high-throughput sequencing library preparation, may lead to overrepresented templates, when multiple copies of the same DNA templates are amplified. These identical reads are termed as PCR duplicates [<xref ref-type="bibr" rid="CR3">3</xref>]. PCR amplification may be biased based on the sequence and quantity of DNA templates; therefore, PCR duplicates usually need to be marked or removed to keep only one copy of their original template, through deduplication. However, high-throughput sequencing has a relatively higher sequencing error rate in comparison to traditional Sanger sequencing, which poses challenges for data analysis, including deduplication. High-throughput sequencers use base quality score (<italic>Q</italic> score) to represent their confidence in the identity of each base [<xref ref-type="bibr" rid="CR4">4</xref>]. <italic>Q</italic> scores are logarithmically related to the base calling error probabilities <italic>P</italic>, such that <italic>Q</italic> = -10 × log<sub>10</sub><italic>P</italic> [<xref ref-type="bibr" rid="CR5">5</xref>]. For example, a <italic>Q</italic> score of 10 represents an estimated sequencing error rate of 10%, and a <italic>Q</italic> score of 20 represents an error rate of 1%. Due to Illumina sequencing chemistry, the average base quality usually decreases from 5′-end to 3′-end of the reads [<xref ref-type="bibr" rid="CR6">6</xref>]. Low-quality bases, often considered as bases whose <italic>Q</italic> scores are below 10 or 20, can be conventionally converted to the ambiguous base ‘N’s [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>]. Low-quality reads with too many ‘N’s are often discarded as a means of quality control [<xref ref-type="bibr" rid="CR7">7</xref>]. As described below, the presence of ambiguous ‘N’s in the remaining sequencing reads complicates the deduplication process.</p>
    <p id="Par17">Several bioinformatics tools have been developed for deduplication which work at two distinct levels, the level of alignment results and the level of raw reads. Tools that work on sequencing alignment files include samtools-rmdup [<xref ref-type="bibr" rid="CR3">3</xref>], Picard-MarkDuplicates [<xref ref-type="bibr" rid="CR9">9</xref>], EAGER-DeDup [<xref ref-type="bibr" rid="CR10">10</xref>], and gencore [<xref ref-type="bibr" rid="CR11">11</xref>]. A common deduplication strategy of alignment-result-based tools is to drop the reads that have the same coordinates of read alignment, sometimes ignoring the underlying sequences or ambiguous bases, ‘N’s. Our previous bioinformatics pipeline for LAM-HTGTS also performs deduplication according to the alignment coordinates without considering the underlying sequences [<xref ref-type="bibr" rid="CR12">12</xref>]. On the other hand, tools that work at the level of raw sequencing data usually perform sequence comparisons and store the unique, deduplicated sequences in a hash data structure. Such tools include pRESTO [<xref ref-type="bibr" rid="CR13">13</xref>], clumpify [<xref ref-type="bibr" rid="CR14">14</xref>], and dedupe [<xref ref-type="bibr" rid="CR15">15</xref>]. However, most sequence-based deduplication tools cannot handle ambiguous base ‘N’s correctly. In order to use hash for exact sequence matching, which is efficient when handling a large amount of data, they treat ‘N’ as a different base from regular bases ‘A’, ‘C’, ‘G’, ‘T’. Hence, sequence-based tools routinely consider two reads that only differ at positions of low sequencing quality as two distinct reads. The only exception is the tool, pRESTO. pRESTO uses hash to store deduplicated sequences, and its implementation of a pairwise comparison algorithm can handle ambiguous base ‘N’s when comparing a query sequence to the stored deduplicated sequences one-by-one. However, pairwise comparison has a complexity of approximately O(n<sup>2</sup>), and may not be feasible due to the long processing time when dealing with large amounts of input sequences.</p>
    <p id="Par18">A major application of NGS is the repertoire analysis of antibodies in humans and animals. The analysis provides valuable information about antibody diversity and enables the identification of antibodies that have important specific functions. The variable regions of antibodies or the corresponding B cell receptors (BCRs) are encoded by V exons that are assembled by V(D)J recombination during B cell development. The most diverse part of the antibody variable region is the complementarity determining region 3 (CDR3), which includes the junctions of V–D and D–J joints for the immunoglobulin heavy chain (IgH) and V–J join for the immunoglobulin light chain (IgL). To characterize antibody repertoires, we have developed the high-throughput genome-wide translocation sequencing-adapted repertoire and somatic hypermutation sequencing (HTGTS-Rep-SHM-Seq) assay, which can cover nearly full-length of the V(D)J-rearranged sequences after merging paired-end long-length MiSeq reads [<xref ref-type="bibr" rid="CR2">2</xref>]. This assay utilizes the genomic DNA sequence in B cells, with primers designed to target upstream of V segments and downstream of J segments, enabling characterization of the V(D)J recombination and CDR3 sequences of BCR. Each B cell has only one productive V(D)J rearranged allele for heavy chain or light chain; therefore, after deduplication, each read of productive V(D)J rearrangement will represent one B cell. Due to the high error rate of next-generation sequencing technology and the distance from the primers to the CDR3 region, a proportion of the reads capturing CDR3 sequences may contain low-quality ambiguous bases, represented as ‘N’s. Low-quality reads with too many ‘N’s are often discarded as a means of quality control [<xref ref-type="bibr" rid="CR7">7</xref>]. Nonetheless, outright discarding sequences containing any ‘N’s carries the potential risk of overlooking some rare events, which may still be important for biological functional studies. A case in point is a kind of rare IgL that contains a rare 5-amino acid (aa) CDR3. Such IgL with 5-aa CDR3 is a conserved and functionally important feature for a type of broadly neutralizing antibody (VRC01) against HIV-1 [<xref ref-type="bibr" rid="CR16">16</xref>]. To test our method, we analyzed the repertoire data of a mouse model that is engineered to express VRC01 class antibodies; such mouse model is used to test vaccine candidates for eliciting this kind of antibodies. Before the immunization study, it is important to determine the frequency of IgL with 5-aa CDR3, a pre-requisite for VRC01 antibody induction. By analyzing the relevant public dataset GSE214884, we observed that 5–10% of the CDR3 sequences contain ‘N’s, which increased to 12–38% for CDR3 longer than 12 aa (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1). We observed reads that were otherwise identical except for a few low-quality bases or ambiguous ‘N’s (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2), likely representing duplicates of the same template, although it is theoretically possible that these similar reads are indeed from different templates. An exact-matching approach to deduplication, which treats ‘N’s as distinct from other nucleotides, may artificially inflate the count of unique CDR3 sequences (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S3). For efficiency in processing huge amounts of sequencing data, our previous pipeline for HTGTS-Rep-SHM-Seq uses an alignment-result-based approach. It deals with ‘N’s by separating reads with and without ‘N’s, aligning reads with ‘N’s to reads without any ‘N’s using bowtie2, and checking their alignment length for deduplication [<xref ref-type="bibr" rid="CR2">2</xref>]. However, this approach cannot deduplicate among reads with ‘N’s when they do not have common equivalent reads without any ‘N’s. On the other hand, by pairwise comparison, pRESTO can deduplicate among reads with ‘N’s; but it runs slowly with the tremendous amount of input sequences.</p>
    <p id="Par19">Here, we designed and implemented TrieDedup, a faster deduplication algorithm that uses the trie (prefix tree) structure to store deduplicated sequences and efficiently deduplicates at the level of raw sequences, ignoring differences only due to low-quality ambiguous base ‘N’s. We implemented a custom Python class, restrictedDict, to reduce memory usage. We benchmarked the performance of TrieDedup and the pairwise comparison algorithm implemented in pRESTO with simulated data as well as real public data. The source code of TrieDedup is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/lolrenceH/TrieDedup">https://github.com/lolrenceH/TrieDedup</ext-link> under the Apache 2.0 license.</p>
  </sec>
  <sec id="Sec2">
    <title>Implementation</title>
    <sec id="Sec3">
      <title>Deduplication algorithm</title>
      <p id="Par20">Many sequence-based deduplication tools regard the ambiguous ‘N’ as different from the traditional bases, ‘A’, ‘C’, ‘G’, ‘T’, using hash-based exact matching to perform deduplication. The hash algorithm is highly efficient for comparing the literal identity of sequences. However, it offers no room for correctly accounting for sequencing ambiguity. Ambiguous ‘N’s potentially represent any of the four regular DNA bases. They should not be considered as different from other DNA bases by default.</p>
      <p id="Par21">Accounting for ‘N’s in deduplication poses two challenges: (1) when allowing differences at ‘N’s, the equivalence relationship between sequences may become complicated; and (2) we need an efficient algorithm to compare between a large amount of sequences and ignore ‘N’ differences.</p>
      <p id="Par22">For Challenge (1), theoretically, a network graph of equivalence relationship can be constructed, where each node represents an input sequence, and equivalent nodes are connected by an edge. Deduplication can be regarded as the well-known 'maximal independent set (MIS)' problem on the graph. A MIS is a set of nodes that are not adjacent, and its members and their neighbors include all the nodes in the graph. A deduplicated set is equivalent to a MIS on the network graph. The complication is that MIS may be not unique, and the sizes of MISs may vary. As a toy example, a simple equivalence graph ‘TAC’–‘TNC’–‘TGC’ has an MIS {‘TAC’, ‘TGC’} and another MIS {‘TNC’}. More generally, a star-shaped graph can have an MIS consisting of the tip nodes, or another MIS consisting of the center node. Thus, we need a principle for choosing a MIS. For sequence deduplication, we may prefer to choose the nodes with fewer ‘N’s to represent the observed sequences, which correspond to the tip nodes of the star-shaped graph.</p>
      <p id="Par23">Finding a MIS can be achieved by adding a candidate node into a MIS and removing neighbors of the node from the query, iteratively. Instead of performing a pairwise comparison between all input sequences, we can store unique sequences that are previously deduplicated and compare each query sequence to these established deduplicated sequences, reducing the number of comparisons (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). Because we prefer unambiguous sequences, we sort the input sequences by the number of ‘N’s in ascending order, and consider each read, sequentially. This progressive pairwise comparison is implemented in pRESTO.<fig id="Fig1"><label>Fig. 1</label><caption><p>Diagram of progressive pairwise comparison and TrieDedup algorithm</p></caption><graphic xlink:href="12859_2024_5775_Fig1_HTML" id="MO1"/></fig></p>
      <p id="Par24">For Challenge (2), the pairwise comparison algorithm needs to compare each input sequence with the full set of deduplicated sequences to determine if it is unique. We adapted the trie (prefix tree) structure to store the previously deduplicated sequences, whose prefixes are organized into a consensus tree. The trie structure can retain information of sequence similarity from previous comparisons, thereby reducing the number of necessary comparisons. The trie structure can immediately identify an unobserved sequence, as soon as the input sequence diverges from the observed paths, thus reducing the number of comparisons (Fig. <xref rid="Fig1" ref-type="fig">1</xref>).</p>
      <p id="Par25">In summary, we designed and implemented the following algorithms to store and compare sequences, which can ignore mismatches due to ‘N’s.
<fig position="anchor" id="Figa"><label>Algorithm 1</label><caption><p>Deduplication with trie storing a working set of deduplicated sequences</p></caption><graphic position="anchor" xlink:href="12859_2024_5775_Figa_HTML" id="MO2"/></fig><fig position="anchor" id="Figb"><label>Algorithm 2</label><caption><p>Adding a sequence to the trie storing already deduplicated sequences</p></caption><graphic position="anchor" xlink:href="12859_2024_5775_Figb_HTML" id="MO3"/></fig><fig position="anchor" id="Figc"><label>Algorithm 3</label><caption><p>Searching for a query sequence in the trie storing already deduplicated sequences</p></caption><graphic position="anchor" xlink:href="12859_2024_5775_Figc_HTML" id="MO4"/></fig></p>
      <p id="Par26">Note:<list list-type="order"><list-item><p id="Par27">keep ‘N’ the last stored_base (after regular bases) when traversing trie_node</p></list-item><list-item><p id="Par28">searching the whole sequence from trie_root by: trie_root.search(sequence, 0)</p></list-item></list></p>
      <p id="Par29">As an implementation detail, to avoid repeatedly checking the same sequence, we also implemented exact-matching deduplication using a hash dict. This step is executed before performing actual deduplication through the trie algorithm. Subsequently, sequences are sorted in ascending order based on the number of ‘N’s present, ensuring that high-quality sequences are processed first, recognized as unique, and stored in the already deduplicated set. Sequences with more ‘N’s are processed later and progressively matched against those deduplicated sequences with fewer ambiguous ‘N’s.</p>
    </sec>
    <sec id="Sec4">
      <title>Memory usage optimization</title>
      <p id="Par30">The pairwise comparison algorithm directly stores every deduplicated, unique sequence, while our algorithm stores them in the trie structure, which theoretically costs less memory. However, empirically, storing a trie structure may cost more memory on the dict data structure than just storing simple sequences in hash keys, potentially due to Python’s base-level optimizations. To reduce memory consumption, we used __slots__ magic in Python to declare the variables. In Python, by default, a class instance declares a dict attribute named __dict__ to dynamically store its variable names and values. The __slots__ attribute in Python allows for the declaration of a fixed set of attributes for class objects, preventing the creation of the instance dict __dict__, thus significantly reducing the memory footprint of each class instance. We also implemented restrictedDict, a restricted dict with list implementation: it restricts hash keys to predetermined options, stores the values in a list instead of a dict, and keeps a shared dict to map limited keys to the index in the list. The restrictedDict achieves a smaller memory usage by storing values in a list instead of a dict, accommodating for large sequencing datasets. In DNA sequencing data, there are five possible base identities: 'A', 'C', 'G', 'T', and ‘N’. Thus, we only keep one dict as a shared class variable of restrictedDict, which stores the mapping table from the base letter (as the keys of dict) to the index in the list. For simplicity in describing the results, we abbreviate the original trie implementation as trie0, trie with only __slots__ magic as trie1, and trie with __slots__ and restrictedDict as trie2.</p>
    </sec>
    <sec id="Sec5">
      <title>Benchmark and comparison to other tools</title>
      <p id="Par31">We compared progressive pairwise comparison algorithm and trie implementation with or without memory optimization in a Dell PowerEdge T640 server, with 192GB physical memory and limited to one CPU of Intel Xeon Gold 6126 2.6GHz, and in RedHat Linux operation system. In order to ensure a fair comparison with pRESTO, which is implemented in Python and has additional functions that may affect its efficiency, we reimplemented the progressive pairwise comparison algorithm according to pRESTO. We benchmarked the accuracy, running time, and memory usage of the exact-matching, pairwise comparison, and trie algorithms using both simulated reads or real public reads as input.</p>
      <p id="Par32">To simulate input sequences, we first generated a unique set of parental sequences of a specific length, then randomly sampled them with replacement, which usually sampled approximately 55% of unique parental sequences, and lastly converted a fixed number of bases at random locations to ‘N’s in each sampled sequence. We considered sequences originating from the same parental sequence to be PCR duplicates; thereby we knew the ground truth for the size of the deduplicated set. We performed comparisons for 10<sup>3</sup>, 2 × 10<sup>3</sup>, 5 × 10<sup>3</sup>, 10<sup>4</sup>, 2 × 10<sup>4</sup>, 5 × 10<sup>4</sup>, 10<sup>5</sup>, 2 × 10<sup>5</sup>, 5 × 10<sup>5</sup>, and 10<sup>6</sup> input sequences, with lengths of 30, 100, 150, and 200 bp, and converted 1%, 5%, 10% or 20% bases to ‘N’s for each input sequence. Each condition is tested with three repeats.</p>
      <p id="Par33">We also benchmarked the performance in public HTGTS-Rep-SHM-seq data of the BCR repertoire. We downloaded raw fastq files for SRR3744758, SRR3744760 and SRR3744762 from SRA, each containing slightly more than 1 million 300-bp paired-end reads. We then randomly selected 1 million reads and masked bases with a quality score ≤ 10 by ‘N’ to serve as the input sequences.</p>
    </sec>
  </sec>
  <sec id="Sec6">
    <title>Results</title>
    <sec id="Sec7">
      <title>Theoretical complexity analysis</title>
      <p id="Par34">Suppose there are <italic>n</italic> input sequences, and each sequence has <italic>m</italic> bases. For the preprocessing steps, the time complexity of counting ‘N’s is O(<italic>m</italic> × <italic>n</italic>), and sorting <italic>n</italic> sequences can be O(<italic>n</italic> × log(<italic>n</italic>)) for quick sort, or O(<italic>n</italic>) for bucket sort.</p>
      <p id="Par35">Suppose we progressively add sequences to the deduplicated set, and the deduplicated set has already stored <italic>n</italic><sub>d</sub> sequences. The space complexity of plain storing <italic>n</italic><sub>d</sub> sequences is O(<italic>m</italic> × <italic>n</italic><sub>d</sub>). The algorithm of pairwise comparison between a candidate sequence and the deduplicated set has time complexity O(<italic>m</italic> × <italic>n</italic><sub>d</sub>). Then, the overall complexity of the whole deduplication process is O(<italic>m</italic> × <italic>n</italic><sup>2</sup>). This algorithm has been implemented in pRESTO, which runs slowly with a large number <italic>n</italic> of input sequences.</p>
      <p id="Par36">Here, we designed and implemented an algorithm using the trie structure to store the already deduplicated sequences. The upper limit of the space complexity of the trie structure storing <italic>n</italic><sub>d</sub> sequences is O(<italic>m</italic> × <italic>n</italic><sub>d</sub>), and should be lower when the sequences have common prefixes. Without ‘N’s, the time complexity of comparison between a query sequence and the trie structure is only O(<italic>m</italic>); therefore, the lowest overall complexity of the whole deduplication process is O(<italic>m</italic> × <italic>n</italic>). However, when allowing ambiguous base ‘N’s, we may need to explore more branches in the trie to determine the comparison result. Theoretically, the upper limit of complexity for one query sequence is O(<italic>m</italic> × <italic>n</italic><sub>d</sub>); therefore, the upper bound of the overall complexity is still O(<italic>m</italic> × <italic>n</italic><sup>2</sup>). Though, this situation may rarely happen as long as the input sequences do not contain too many ‘N’s. If each sequence has at most <italic>k</italic> ‘N’s, the upper limit of the time complexity between one query sequence and the trie structure is O(<italic>m</italic> × 5<sup><italic>k</italic></sup>), for 5 possible choices of bases ('A', 'C', 'G', 'T', ‘N’) at <italic>k</italic> trie nodes; therefore, the overall time complexity is O(<italic>m</italic> × <italic>n</italic> × 5<sup><italic>k</italic></sup>). Theoretically, the actual time complexity is dependent on the amount and location of ‘N’s in sequences. Sequences with fewer ‘N’s or ‘N’s located closer to the end (near trie tips) will have less complexity than those with more ‘N’s or ‘N’s located closer to the start (near trie root).</p>
    </sec>
    <sec id="Sec8">
      <title>Benchmark on simulated data</title>
      <p id="Par37">We benchmarked the accuracy, speed and memory consumption of the trie algorithm with or without memory optimization, and compared them to the performance of the progressive pairwise comparison algorithm, which we reimplemented from pRESTO, using the simulated 200-bp reads. Both the pairwise comparison and trie algorithms demonstrate high accuracy in recovering the deduplicated sets to the ground truth sizes (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4). In contrast, the exact-matching approach, which treats ‘N’s as distinct from other nucleotides, inflates the sizes a lot (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4), although it runs very fast (&lt; 2.5 s for <italic>n</italic> = 10<sup>6</sup>) and requires minimal memory (&lt; 0.7 GB for <italic>n</italic> = 10<sup>6</sup>).</p>
      <p id="Par38">The pairwise comparison and all the trie algorithms show an approximately linear relationship between log-transformed running time and the log-transformed number of input sequences (Fig. <xref rid="Fig2" ref-type="fig">2</xref>A). The slope of pairwise comparison is close to the theoretical order 2. On the other hand, the slope of the trie algorithm is much lower, which is ≤ 1.3 for <italic>n</italic> ≤ 10<sup>5</sup> and the percentage of ambiguous bases in reads (N%) ≤ 10%, and increases for larger <italic>n</italic> or N%. When the input sequences are less than 5000, the pairwise comparison algorithm is more efficient than the trie algorithm whose performance is less than 3s. When there are more than 5000 input sequences, the trie algorithm runs significantly faster than pairwise comparison.<fig id="Fig2"><label>Fig. 2</label><caption><p>Running time and memory usage increases with larger amount of input sequences (benchmark simulation). <bold>A</bold> Running time; <bold>B</bold> memory usage. Input sequences are 200 bp in length. Error bars shows mean ± standard deviation, each with 3 replicates</p></caption><graphic xlink:href="12859_2024_5775_Fig2_HTML" id="MO5"/></fig></p>
      <p id="Par39">The trie algorithm significantly outperforms pairwise comparison at large input sizes. For example, at N% = 5% and <italic>n</italic> = 10<sup>4</sup>, pairwise comparison needs 8.9s (on average), trie algorithm needs ≤ 5.0s; at <italic>n</italic> = 10<sup>5</sup>, pairwise comparison needs 1100 s (or 18.3 min), trie algorithm needs ≤ 55s; at <italic>n</italic> = 10<sup>6</sup>, pairwise comparison needs 125000s (or 34.7h), trie algorithm needs ≤ 1755s (or 29.3 min).</p>
      <p id="Par40">When comparing the running time among the three different options of memory optimization of the trie implementation, we found that all the three options have very similar running time, without magnitude difference. Trie1 runs relatively faster than trie0 and trie2, with the difference being less than twofold (Fig. <xref rid="Fig2" ref-type="fig">2</xref>A).</p>
      <p id="Par41">In terms of memory usage, the pairwise algorithm is more memory-efficient to implement than the trie because entire sequences can be stored as one item instead of storing each base individually (Fig. <xref rid="Fig2" ref-type="fig">2</xref>B). Among three trie implementations, as expected, trie0 requires the most memory and trie2 requires the least. The slopes for the three options in Python implementation are similar, all close to but a little less than the theoretical 1. For <italic>n</italic> ≥ 10<sup>5</sup>, the implementation of restrictedDict (trie2) improves the memory usage of __slots__ optimization (trie1) by approximately 19%, while trie1 improves 20% compared to trie0; therefore, trie2 only uses 65% memory as much as trie0 uses.</p>
      <p id="Par42">When N% = 5% and <italic>n</italic> = 10<sup>4</sup>, pairwise comparison on average requires 0.07GB memory to run, while trie0 requires 0.62GB, trie1 0.51GB, and trie2 0.42GB; when <italic>n</italic> = 10<sup>5</sup>, pairwise comparison needs 0.19GB, trie0 5.6GB, trie1 4.5GB, and trie2 3.7GB; when <italic>n</italic> = 10<sup>6</sup>, pairwise comparison requires 1.6GB, trie0 55GB, trie1 44GB, and trie2 36GB.</p>
      <p id="Par43">We also evaluated the influence of the length of input sequences and N% on the performance of pairwise comparison and trie2 (Additional file <xref rid="MOESM2" ref-type="media">2</xref>: Fig. S1, Additional file <xref rid="MOESM2" ref-type="media">2</xref>: Fig. S2). As expected, longer length will need more running time and memory usage. The percentage of ambiguous bases in reads (N%) barely impacts the memory usage of both algorithms. This is likely because the memory usage is more closely correlated with the number of unique reads stored in the already deduplicated set, whose ground truth remained constant across different N% in our simulation. On the other hand, a higher N% increases the running time of the trie algorithm, while it does not affect the running time of pairwise comparison. This may be because the pairwise comparison algorithm requires a lot of comparisons between sequence pairs until it finds a match, which is not significantly affected by N; whereas the trie algorithm needs to search through more branches when the query sequence contains more ‘N’s. Additionally, when a sequence with more ‘N’s is considered unique and added to the trie structure, it may slow down subsequent searches by increasing the possible branches at ‘N’.</p>
    </sec>
    <sec id="Sec9">
      <title>Benchmark on real data</title>
      <p id="Par44">We applied the exact-matching, pairwise comparison, and trie algorithms to published sequencing data with a read length of 300 bp and an average N% of 4.9–15.8%. As expected, higher N% and a lower percentage of unique reads were observed in R2 than in R1 reads. With an input size of 10<sup>6</sup> raw reads, both pairwise comparison and trie algorithms reported the same numbers of unique reads (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4). In contrast, although the exact-matching approach runs very fast (&lt; 4 s) and requires minimal memory (&lt; 0.75 GB), it likely inflates the sizes of deduplicated sets, especially for R2 reads, whose N% is higher than R1 reads (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4). Deduplication by trie2 only needed 0.9–2.1 h using 35–55 GB of memory, while deduplication by pairwise comparison required 6–16 days with about 1.5 GB memory usage (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). Therefore, trie2 deduplication can achieve about 270-fold faster speed than pairwise comparison, with 32-fold higher memory usage.<fig id="Fig3"><label>Fig. 3</label><caption><p>Running time and memory usage when applying on 10<sup>6</sup> real 300-bp reads from SRA. X-axis ‘N%’ shows the average percentage of ambiguous base ‘N’s in reads</p></caption><graphic xlink:href="12859_2024_5775_Fig3_HTML" id="MO6"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec10">
    <title>Discussion</title>
    <p id="Par45">To deduplicate high-throughput sequencing libraries while ignoring differences only due to ambiguous base ‘N’s, we adapted the trie structure to store deduplicated sequences, and implemented a corresponding algorithm, named TrieDedup. When the input size is larger than 5000 sequences, the trie algorithm is more efficient than the pairwise comparison algorithm used in pRESTO, at the price of higher memory usage. TrieDedup can deduplicate up to 10<sup>6</sup> input sequences within 2 h using less than 36GB of memory. In addition, TrieDedup may be potentially adapted into pRESTO framework.</p>
    <p id="Par46">The real data we used for benchmarking were public HTGTS-Rep-SHM-seq data of BCR repertoire downloaded from SRA (SRR3744758, SRR3744760, and SRR3744762). For such a typical study targeting B cell receptor repertoire, these samples originally contain 1.22 million, 1.10 million, and 1.49 million 300-bp reads respectively, with the fastq file sizes being approximately 1.6 GB, 1.5 GB, and 2 GB. For our benchmark experiments, we randomly selected 1 million reads from these samples, believing that this number represents a realistic read number for this type of sequencing data. For the other genomic studies, the read number can vary significantly in scale, which depends on the targeted genomic region size, the depth of sequencing, and the lengths of sequenced reads. For instance, a 30X Whole Genome Sequencing (WGS) of a human genome typically requires around 900 million 100-bp reads, while an 80X Whole Exome Sequencing (WES) might need about 24 million 100-bp reads. These quantities are 1–3 orders of magnitude higher than those typical targeted sequencing such as B cell repertoire studies. Our benchmark suggests a dataset of up to 1 million reads, or a fastq file size of approximately 1.5GB, can be efficiently deduplicated by our TrieDedup with approximately 36GB of memory usage which a typical server has the memory capacity to support. Since both the running time and memory usage increase with the number of input sequences, and the complexity order of running time on N exceeds one, the efficiency of deduplication may be further improved if we can divide the input sequences into smaller non-overlapping groups. To handle a larger number of reads, we also recommend grouping reads to reduce each group to below 1 million reads. For example, the reads may be grouped based on sequence prefixes, or the mapped chromosome and coordinate range if the reads have been aligned, or the V and J alignment for V(D)J repertoire. If these subsets of data are processed separately, the algorithm will have to store fewer reads simultaneously, hence reducing memory usage.</p>
    <p id="Par47">Trie structure has also been used in the deduplication of Unique Molecular Identifiers (UMIs) [<xref ref-type="bibr" rid="CR17">17</xref>], but the traditional trie structure cannot handle ambiguous bases, although errors in UMIs are common [<xref ref-type="bibr" rid="CR18">18</xref>]. UMIs containing any ‘N’s or bases with a <italic>Q</italic> score below 10 are by default filtered out during 10x Genomics Cell Ranger processing. Here, we designed and implemented TrieDedup, where the specialized trie structure and algorithm can correctly and efficiently handle the differences due to ambiguous bases. With its ultra-fast algorithm, TrieDedup may also potentially be applied to barcode or UMI assignment when considering reads with a few low-quality bases in the UMIs.</p>
    <p id="Par48">We designed, implemented, and showcased a universal algorithm using a trie for deduplication that allows for ambiguous letter matching, therefore, we did not restrict the allowed keys of restrictedDict to ‘A’, ‘C’, ‘G’, ‘T’ and ‘N’. Our highly versatile TrieDedup algorithm can be applied not only to DNA reads, as evaluated in the manuscript, but also directly to protein amino acid sequences and even text word matching. To further improve runtime and memory usage, we also implemented TrieDedup in Java and C++, but hard-coded the allowed keys to DNA bases. These implementations are also available in our GitHub repository. Compared to Python implementation, TrieDedup C++ implementation achieved 5–11-fold faster and 1/3 memory. However, it imposes limitations by being restricted solely to DNA sequences, underscoring a trade-off between performance optimization and general applicability.</p>
    <p id="Par49">The threshold of <italic>Q</italic> scores for converting low-quality bases to ambiguous ‘N’s, which is often library-specifically set to 10 or 20 arbitrarily, may affect N% in input reads, as well as the amount of deduplicated reads. A potentially more principled approach is to sum up the error rate of mismatches in pairwise comparison, and then set the threshold on the sum error rate to judge the equivalence between reads. However, it may generate a more complicated relationship of equivalence and even higher computational complexity than the current pairwise comparison algorithm in pRESTO.</p>
  </sec>
  <sec id="Sec11">
    <title>Conclusions</title>
    <p id="Par50">We implemented TrieDedup, which uses the trie structure to store deduplicated sequences, and ignores differences only due to ambiguous base ‘N’s. We also implemented a memory-efficient class, restrictedDict, that reduced the memory usage to about 0.8-fold. TrieDedup significantly outperforms the pairwise comparison strategy when the amount of input sequences is larger than a few thousand. TrieDedup can deduplicate reads up to 270-fold faster than pairwise comparison at a cost of 32-fold higher memory usage. Potentially, TrieDedup may be adapted into pRESTO, and may be generalized to other scenarios for deduplication with ambiguous letters.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <sec id="Sec12">
      <title>Supplementary Information</title>
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2024_5775_MOESM1_ESM.xlsx">
            <caption>
              <p><bold>Additional file 1: Table S1.</bold> The percentage of CDR3 sequences containing ambiguous bases (‘N’s) in public dataset GSE214884. <bold>Table S2.</bold> Unique and potential duplicate sequences with ambiguous bases ‘N’s in 5-aa CDR3 sequences from GSM6617404. <bold>Table S3.</bold> The number of CDR3 sequences before and after deduplication in public dataset GSE214884. <bold>Table S4.</bold> The number of sequences after deduplication for benchmark analysis.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="12859_2024_5775_MOESM2_ESM.docx">
            <caption>
              <p><bold>Additional file 2: Figure S1.</bold> Running time for input sequences with different lengths. Error bars shows mean ± standard deviation, each with 3 replicates. <bold>Figure S2.</bold> Memory usage for input sequences with different lengths. Error bars shows mean ± standard deviation, each with 3 replicates.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>PCR</term>
        <def>
          <p id="Par4">Polymerase chain reaction</p>
        </def>
      </def-item>
      <def-item>
        <term><italic>Q</italic> score</term>
        <def>
          <p id="Par5">Base quality score</p>
        </def>
      </def-item>
      <def-item>
        <term>BCR</term>
        <def>
          <p id="Par6">B cell receptor</p>
        </def>
      </def-item>
      <def-item>
        <term>CDR</term>
        <def>
          <p id="Par7">Complementarity-determining region</p>
        </def>
      </def-item>
      <def-item>
        <term>HTGTS-Rep-SHM-Seq</term>
        <def>
          <p id="Par8">High-throughput genome-wide translocation sequencing-adapted repertoire and somatic hypermutation sequencing</p>
        </def>
      </def-item>
      <def-item>
        <term>aa</term>
        <def>
          <p id="Par9">Amino acid</p>
        </def>
      </def-item>
      <def-item>
        <term>MIS</term>
        <def>
          <p id="Par10">Maximal independent set</p>
        </def>
      </def-item>
      <def-item>
        <term>trie0</term>
        <def>
          <p id="Par11">Trie implementation without memory optimization</p>
        </def>
      </def-item>
      <def-item>
        <term>trie1</term>
        <def>
          <p id="Par12">Trie implementation with only __slots__ magic</p>
        </def>
      </def-item>
      <def-item>
        <term>trie2</term>
        <def>
          <p id="Par13">Trie implementation with __slots__ and restrictedDict</p>
        </def>
      </def-item>
      <def-item>
        <term>N%</term>
        <def>
          <p id="Par14">Percentage of ambiguous bases in reads</p>
        </def>
      </def-item>
      <def-item>
        <term>UMIs</term>
        <def>
          <p id="Par15">Unique Molecular Identifiers</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to express our deep gratitude to Prof. Frederick W Alt, for his unwavering support and generously providing the necessary resources and funding throughout this projects.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>SL and MT raised the scientific questions, AYY conceptualized and designed the software. AYY and JH developed the software. JH, SL and MT, and AYY tested and validated the software. JH performed benchmark analysis. JH and AYY conducted data analysis and visualization. JH, SL and MT, and AYY wrote the manuscript. All authors read, critically revised, and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>AYY is a Bioinformatics Specialist of Howard Hughes Medical Institute and Boston Children's Hospital. JH receives salary support from NIH Grants R01AI020047, R01AI077595 and Bill &amp; Melinda Gates Foundation Investment INV-021989. SL receives salary support from Bill &amp; Melinda Gates Foundation Investment INV-021989. MT receives salary support from NIH/NIAID Grants 5P01 AI138211-04 (to M.A), 5UM1 AI144371-03 (to B.H.) and Bill &amp; Melinda Gates Foundation Investment INV-021989 (to F.A. and M.T.).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>TrieDedup code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/lolrenceH/TrieDedup">https://github.com/lolrenceH/TrieDedup</ext-link>. The real data we used for benchmarking are public data downloaded from NCBI-SRA, with accession number: SRR3744758 (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/SRR3744758">https://www.ncbi.nlm.nih.gov/sra/SRR3744758</ext-link>), SRR3744760 (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/SRR3744760">https://www.ncbi.nlm.nih.gov/sra/SRR3744760</ext-link>) and SRR3744762 (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/SRR3744762">https://www.ncbi.nlm.nih.gov/sra/SRR3744762</ext-link>). Project name: TrieDedup: A fast trie-based deduplication algorithm to handle ambiguous bases in high-throughput sequencing. Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/lolrenceH/TrieDedup">https://github.com/lolrenceH/TrieDedup</ext-link>. Operating system(s): Platform independent. Programming language: Python, with C++ and Java implementations available on GitHub. Other requirements: seqtk, pandas. License: Apache 2.0. Any restrictions to use by non-academics: None.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar4">
      <title>Ethics approval and consent to participate</title>
      <p id="Par51">Not applicable.</p>
    </notes>
    <notes id="FPar5">
      <title>Consent for publication</title>
      <p id="Par52">Not applicable.</p>
    </notes>
    <notes id="FPar6" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par53">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>SG</given-names>
          </name>
          <name>
            <surname>Ba</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Alt</surname>
            <given-names>FW</given-names>
          </name>
        </person-group>
        <article-title>Highly sensitive and unbiased approach for elucidating antibody repertoires</article-title>
        <source>Proc Natl Acad Sci</source>
        <year>2016</year>
        <volume>113</volume>
        <fpage>7846</fpage>
        <lpage>7851</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1608649113</pub-id>
        <?supplied-pmid 27354528?>
        <pub-id pub-id-type="pmid">27354528</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>AY</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>C-S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>BCR selection and affinity maturation in Peyer’s patch germinal centres</article-title>
        <source>Nature</source>
        <year>2020</year>
        <volume>582</volume>
        <fpage>421</fpage>
        <lpage>425</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-020-2262-4</pub-id>
        <?supplied-pmid 32499646?>
        <pub-id pub-id-type="pmid">32499646</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Handsaker</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Wysoker</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Fennell</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ruan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Homer</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The sequence alignment/map format and SAMtools</article-title>
        <source>Bioinformatics</source>
        <year>2009</year>
        <volume>25</volume>
        <fpage>2078</fpage>
        <lpage>2079</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btp352</pub-id>
        <?supplied-pmid 19505943?>
        <pub-id pub-id-type="pmid">19505943</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cock</surname>
            <given-names>PJA</given-names>
          </name>
          <name>
            <surname>Fields</surname>
            <given-names>CJ</given-names>
          </name>
          <name>
            <surname>Goto</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Heuer</surname>
            <given-names>ML</given-names>
          </name>
          <name>
            <surname>Rice</surname>
            <given-names>PM</given-names>
          </name>
        </person-group>
        <article-title>The Sanger FASTQ file format for sequences with quality scores, and the Solexa/Illumina FASTQ variants</article-title>
        <source>Nucleic Acids Res</source>
        <year>2010</year>
        <volume>38</volume>
        <fpage>1767</fpage>
        <lpage>1771</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkp1137</pub-id>
        <?supplied-pmid 20015970?>
        <pub-id pub-id-type="pmid">20015970</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ewing</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Green</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Base-calling of automated sequencer traces using <italic>Phred</italic>. II. Error probabilities</article-title>
        <source>Genome Res</source>
        <year>1998</year>
        <volume>8</volume>
        <fpage>186</fpage>
        <lpage>194</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.8.3.186</pub-id>
        <?supplied-pmid 9521922?>
        <pub-id pub-id-type="pmid">9521922</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Manley</surname>
            <given-names>LJ</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Levine</surname>
            <given-names>SS</given-names>
          </name>
        </person-group>
        <article-title>Monitoring error rates in illumina sequencing</article-title>
        <source>J Biomol Tech</source>
        <year>2016</year>
        <volume>27</volume>
        <fpage>125</fpage>
        <lpage>128</lpage>
        <pub-id pub-id-type="doi">10.7171/jbt.16-2704-002</pub-id>
        <?supplied-pmid 27672352?>
        <pub-id pub-id-type="pmid">27672352</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">Hannon GJ. FASTX-Toolkit. GitHub repository. 2010. <ext-link ext-link-type="uri" xlink:href="http://hannonlab.cshl.edu/fastx_toolkit">http://hannonlab.cshl.edu/fastx_toolkit</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">Li H. seqtk. GitHub repository. 2018. <ext-link ext-link-type="uri" xlink:href="https://github.com/lh3/seqtk">https://github.com/lh3/seqtk</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Broad Institute. Picard toolkit. GitHub repository. 2019. <ext-link ext-link-type="uri" xlink:href="https://broadinstitute.github.io/picard/">https://broadinstitute.github.io/picard/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peltzer</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jäger</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Herbig</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Seitz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kniep</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Krause</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>EAGER: efficient ancient genome reconstruction</article-title>
        <source>Genome Biol</source>
        <year>2016</year>
        <volume>17</volume>
        <fpage>60</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-016-0918-z</pub-id>
        <?supplied-pmid 27036623?>
        <pub-id pub-id-type="pmid">27036623</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Liao</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Gencore: an efficient tool to generate consensus reads for error suppressing and duplicate removing of NGS data</article-title>
        <source>BMC Bioinform</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>606</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-019-3280-9</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Meyers</surname>
            <given-names>RM</given-names>
          </name>
          <name>
            <surname>Dong</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Panchakshari</surname>
            <given-names>RA</given-names>
          </name>
          <name>
            <surname>Alt</surname>
            <given-names>FW</given-names>
          </name>
          <name>
            <surname>Frock</surname>
            <given-names>RL</given-names>
          </name>
        </person-group>
        <article-title>Detecting DNA double-stranded breaks in mammalian genomes by linear amplification–mediated high-throughput genome-wide translocation sequencing</article-title>
        <source>Nat Protoc</source>
        <year>2016</year>
        <volume>11</volume>
        <fpage>853</fpage>
        <lpage>871</lpage>
        <pub-id pub-id-type="doi">10.1038/nprot.2016.043</pub-id>
        <?supplied-pmid 27031497?>
        <pub-id pub-id-type="pmid">27031497</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vander Heiden</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Yaari</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Uduman</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Stern</surname>
            <given-names>JNH</given-names>
          </name>
          <name>
            <surname>O’Connor</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Hafler</surname>
            <given-names>DA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>pRESTO: a toolkit for processing high-throughput sequencing raw reads of lymphocyte receptor repertoires</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <fpage>1930</fpage>
        <lpage>1932</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu138</pub-id>
        <?supplied-pmid 24618469?>
        <pub-id pub-id-type="pmid">24618469</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Bushnell B. BBMap—clumpify. GitHub repository. 2021. <ext-link ext-link-type="uri" xlink:href="https://github.com/BioInfoTools/BBMap/blob/master/sh/clumpify.sh">https://github.com/BioInfoTools/BBMap/blob/master/sh/clumpify.sh</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Gregg F, Eder D. Dedupe. GitHub repository. 2022. <ext-link ext-link-type="uri" xlink:href="https://github.com/dedupeio/dedupe">https://github.com/dedupeio/dedupe</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luo</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Jing</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>AY</given-names>
          </name>
          <name>
            <surname>Kratochvil</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Cottrell</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Koo</surname>
            <given-names>J-H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Humanized V(D)J-rearranging and TdT-expressing mouse vaccine models with physiological HIV-1 broadly neutralizing antibody precursors</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2023</year>
        <volume>120</volume>
        <fpage>e2217883120</fpage>
        <pub-id pub-id-type="doi">10.1073/pnas.2217883120</pub-id>
        <?supplied-pmid 36574685?>
        <pub-id pub-id-type="pmid">36574685</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Algorithms for efficiently collapsing reads with Unique Molecular Identifiers</article-title>
        <source>PeerJ</source>
        <year>2019</year>
        <volume>7</volume>
        <fpage>e8275</fpage>
        <pub-id pub-id-type="doi">10.7717/peerj.8275</pub-id>
        <?supplied-pmid 31871845?>
        <pub-id pub-id-type="pmid">31871845</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Smith</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Heger</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sudbery</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>UMI-tools: modeling sequencing errors in Unique Molecular Identifiers to improve quantification accuracy</article-title>
        <source>Genome Res</source>
        <year>2017</year>
        <volume>27</volume>
        <fpage>491</fpage>
        <lpage>499</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.209601.116</pub-id>
        <?supplied-pmid 28100584?>
        <pub-id pub-id-type="pmid">28100584</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">11025179</article-id>
    <article-id pub-id-type="publisher-id">5775</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-024-05775-w</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>TrieDedup: a fast trie-based deduplication algorithm to handle ambiguous bases in high-throughput sequencing</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Hu</surname>
          <given-names>Jianqiao</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Luo</surname>
          <given-names>Sai</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tian</surname>
          <given-names>Ming</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Ye</surname>
          <given-names>Adam Yongxin</given-names>
        </name>
        <address>
          <email>yeyx2626@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00dvg7y05</institution-id><institution-id institution-id-type="GRID">grid.2515.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 0378 8438</institution-id><institution>Program in Cellular and Molecular Medicine, </institution><institution>Boston Children’s Hospital, </institution></institution-wrap>Boston, MA USA </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00cvxb145</institution-id><institution-id institution-id-type="GRID">grid.34477.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2298 6657</institution-id><institution>Present Address: Department of Biology, </institution><institution>University of Washington, </institution></institution-wrap>Seattle, WA USA </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.38142.3c</institution-id><institution-id institution-id-type="ISNI">000000041936754X</institution-id><institution>Harvard Medical School, </institution></institution-wrap>Boston, MA USA </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.2515.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 0378 8438</institution-id><institution>Howard Hughes Medical Institute, </institution><institution>Boston Children’s Hospital, </institution></institution-wrap>Boston, MA USA </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03cve4549</institution-id><institution-id institution-id-type="GRID">grid.12527.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 0662 3178</institution-id><institution>Present Address: School of Basic Medical Science, </institution><institution>Tsinghua University, </institution></institution-wrap>Beijing, China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>4</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>18</day>
      <month>4</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2024</year>
    </pub-date>
    <volume>25</volume>
    <elocation-id>154</elocation-id>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>1</month>
        <year>2024</year>
      </date>
      <date date-type="accepted">
        <day>10</day>
        <month>4</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">High-throughput sequencing is a powerful tool that is extensively applied in biological studies. However, sequencers may produce low-quality bases, leading to ambiguous bases, ‘N’s. PCR duplicates introduced in library preparation are conventionally removed in genomics studies, and several deduplication tools have been developed for this purpose. Two identical reads may appear different due to ambiguous bases and the existing tools cannot address ‘N’s correctly or efficiently.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Here we proposed and implemented TrieDedup, which uses the trie (prefix tree) data structure to compare and store sequences. TrieDedup can handle ambiguous base ‘N’s, and efficiently deduplicate at the level of raw sequences. We also reduced its memory usage by approximately 20% by implementing restrictedDict in Python. We benchmarked the performance of the algorithm and showed that TrieDedup can deduplicate reads up to 270-fold faster than pairwise comparison at a cost of 32-fold higher memory usage.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">The TrieDedup algorithm may facilitate PCR deduplication, barcode or UMI assignment, and repertoire diversity analysis of large-scale high-throughput sequencing datasets with its ultra-fast algorithm that can account for ambiguous bases due to sequencing errors.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12859-024-05775-w.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Deduplication</kwd>
      <kwd>Ambiguous bases</kwd>
      <kwd>Trie</kwd>
      <kwd>Prefix tree</kwd>
      <kwd>Next-generation sequencing</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
            <institution>National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01AI020047</award-id>
        <award-id>5P01 AI138211-04</award-id>
        <principal-award-recipient>
          <name>
            <surname>Hu</surname>
            <given-names>Jianqiao</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>Ming</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Bill &amp; Melinda Gates Foundation Investment, United States</institution>
        </funding-source>
        <award-id>INV-021989</award-id>
        <award-id>INV-021989</award-id>
        <principal-award-recipient>
          <name>
            <surname>Hu</surname>
            <given-names>Jianqiao</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id>
            <institution>Howard Hughes Medical Institute</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006823</institution-id>
            <institution>Boston Children's Hospital</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© BioMed Central Ltd., part of Springer Nature 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par16">High-throughput sequencing methods have been adapted and applied in many fields of biological studies, including immune repertoire studies [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Polymerase chain reaction (PCR), used during high-throughput sequencing library preparation, may lead to overrepresented templates, when multiple copies of the same DNA templates are amplified. These identical reads are termed as PCR duplicates [<xref ref-type="bibr" rid="CR3">3</xref>]. PCR amplification may be biased based on the sequence and quantity of DNA templates; therefore, PCR duplicates usually need to be marked or removed to keep only one copy of their original template, through deduplication. However, high-throughput sequencing has a relatively higher sequencing error rate in comparison to traditional Sanger sequencing, which poses challenges for data analysis, including deduplication. High-throughput sequencers use base quality score (<italic>Q</italic> score) to represent their confidence in the identity of each base [<xref ref-type="bibr" rid="CR4">4</xref>]. <italic>Q</italic> scores are logarithmically related to the base calling error probabilities <italic>P</italic>, such that <italic>Q</italic> = -10 × log<sub>10</sub><italic>P</italic> [<xref ref-type="bibr" rid="CR5">5</xref>]. For example, a <italic>Q</italic> score of 10 represents an estimated sequencing error rate of 10%, and a <italic>Q</italic> score of 20 represents an error rate of 1%. Due to Illumina sequencing chemistry, the average base quality usually decreases from 5′-end to 3′-end of the reads [<xref ref-type="bibr" rid="CR6">6</xref>]. Low-quality bases, often considered as bases whose <italic>Q</italic> scores are below 10 or 20, can be conventionally converted to the ambiguous base ‘N’s [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>]. Low-quality reads with too many ‘N’s are often discarded as a means of quality control [<xref ref-type="bibr" rid="CR7">7</xref>]. As described below, the presence of ambiguous ‘N’s in the remaining sequencing reads complicates the deduplication process.</p>
    <p id="Par17">Several bioinformatics tools have been developed for deduplication which work at two distinct levels, the level of alignment results and the level of raw reads. Tools that work on sequencing alignment files include samtools-rmdup [<xref ref-type="bibr" rid="CR3">3</xref>], Picard-MarkDuplicates [<xref ref-type="bibr" rid="CR9">9</xref>], EAGER-DeDup [<xref ref-type="bibr" rid="CR10">10</xref>], and gencore [<xref ref-type="bibr" rid="CR11">11</xref>]. A common deduplication strategy of alignment-result-based tools is to drop the reads that have the same coordinates of read alignment, sometimes ignoring the underlying sequences or ambiguous bases, ‘N’s. Our previous bioinformatics pipeline for LAM-HTGTS also performs deduplication according to the alignment coordinates without considering the underlying sequences [<xref ref-type="bibr" rid="CR12">12</xref>]. On the other hand, tools that work at the level of raw sequencing data usually perform sequence comparisons and store the unique, deduplicated sequences in a hash data structure. Such tools include pRESTO [<xref ref-type="bibr" rid="CR13">13</xref>], clumpify [<xref ref-type="bibr" rid="CR14">14</xref>], and dedupe [<xref ref-type="bibr" rid="CR15">15</xref>]. However, most sequence-based deduplication tools cannot handle ambiguous base ‘N’s correctly. In order to use hash for exact sequence matching, which is efficient when handling a large amount of data, they treat ‘N’ as a different base from regular bases ‘A’, ‘C’, ‘G’, ‘T’. Hence, sequence-based tools routinely consider two reads that only differ at positions of low sequencing quality as two distinct reads. The only exception is the tool, pRESTO. pRESTO uses hash to store deduplicated sequences, and its implementation of a pairwise comparison algorithm can handle ambiguous base ‘N’s when comparing a query sequence to the stored deduplicated sequences one-by-one. However, pairwise comparison has a complexity of approximately O(n<sup>2</sup>), and may not be feasible due to the long processing time when dealing with large amounts of input sequences.</p>
    <p id="Par18">A major application of NGS is the repertoire analysis of antibodies in humans and animals. The analysis provides valuable information about antibody diversity and enables the identification of antibodies that have important specific functions. The variable regions of antibodies or the corresponding B cell receptors (BCRs) are encoded by V exons that are assembled by V(D)J recombination during B cell development. The most diverse part of the antibody variable region is the complementarity determining region 3 (CDR3), which includes the junctions of V–D and D–J joints for the immunoglobulin heavy chain (IgH) and V–J join for the immunoglobulin light chain (IgL). To characterize antibody repertoires, we have developed the high-throughput genome-wide translocation sequencing-adapted repertoire and somatic hypermutation sequencing (HTGTS-Rep-SHM-Seq) assay, which can cover nearly full-length of the V(D)J-rearranged sequences after merging paired-end long-length MiSeq reads [<xref ref-type="bibr" rid="CR2">2</xref>]. This assay utilizes the genomic DNA sequence in B cells, with primers designed to target upstream of V segments and downstream of J segments, enabling characterization of the V(D)J recombination and CDR3 sequences of BCR. Each B cell has only one productive V(D)J rearranged allele for heavy chain or light chain; therefore, after deduplication, each read of productive V(D)J rearrangement will represent one B cell. Due to the high error rate of next-generation sequencing technology and the distance from the primers to the CDR3 region, a proportion of the reads capturing CDR3 sequences may contain low-quality ambiguous bases, represented as ‘N’s. Low-quality reads with too many ‘N’s are often discarded as a means of quality control [<xref ref-type="bibr" rid="CR7">7</xref>]. Nonetheless, outright discarding sequences containing any ‘N’s carries the potential risk of overlooking some rare events, which may still be important for biological functional studies. A case in point is a kind of rare IgL that contains a rare 5-amino acid (aa) CDR3. Such IgL with 5-aa CDR3 is a conserved and functionally important feature for a type of broadly neutralizing antibody (VRC01) against HIV-1 [<xref ref-type="bibr" rid="CR16">16</xref>]. To test our method, we analyzed the repertoire data of a mouse model that is engineered to express VRC01 class antibodies; such mouse model is used to test vaccine candidates for eliciting this kind of antibodies. Before the immunization study, it is important to determine the frequency of IgL with 5-aa CDR3, a pre-requisite for VRC01 antibody induction. By analyzing the relevant public dataset GSE214884, we observed that 5–10% of the CDR3 sequences contain ‘N’s, which increased to 12–38% for CDR3 longer than 12 aa (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1). We observed reads that were otherwise identical except for a few low-quality bases or ambiguous ‘N’s (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2), likely representing duplicates of the same template, although it is theoretically possible that these similar reads are indeed from different templates. An exact-matching approach to deduplication, which treats ‘N’s as distinct from other nucleotides, may artificially inflate the count of unique CDR3 sequences (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S3). For efficiency in processing huge amounts of sequencing data, our previous pipeline for HTGTS-Rep-SHM-Seq uses an alignment-result-based approach. It deals with ‘N’s by separating reads with and without ‘N’s, aligning reads with ‘N’s to reads without any ‘N’s using bowtie2, and checking their alignment length for deduplication [<xref ref-type="bibr" rid="CR2">2</xref>]. However, this approach cannot deduplicate among reads with ‘N’s when they do not have common equivalent reads without any ‘N’s. On the other hand, by pairwise comparison, pRESTO can deduplicate among reads with ‘N’s; but it runs slowly with the tremendous amount of input sequences.</p>
    <p id="Par19">Here, we designed and implemented TrieDedup, a faster deduplication algorithm that uses the trie (prefix tree) structure to store deduplicated sequences and efficiently deduplicates at the level of raw sequences, ignoring differences only due to low-quality ambiguous base ‘N’s. We implemented a custom Python class, restrictedDict, to reduce memory usage. We benchmarked the performance of TrieDedup and the pairwise comparison algorithm implemented in pRESTO with simulated data as well as real public data. The source code of TrieDedup is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/lolrenceH/TrieDedup">https://github.com/lolrenceH/TrieDedup</ext-link> under the Apache 2.0 license.</p>
  </sec>
  <sec id="Sec2">
    <title>Implementation</title>
    <sec id="Sec3">
      <title>Deduplication algorithm</title>
      <p id="Par20">Many sequence-based deduplication tools regard the ambiguous ‘N’ as different from the traditional bases, ‘A’, ‘C’, ‘G’, ‘T’, using hash-based exact matching to perform deduplication. The hash algorithm is highly efficient for comparing the literal identity of sequences. However, it offers no room for correctly accounting for sequencing ambiguity. Ambiguous ‘N’s potentially represent any of the four regular DNA bases. They should not be considered as different from other DNA bases by default.</p>
      <p id="Par21">Accounting for ‘N’s in deduplication poses two challenges: (1) when allowing differences at ‘N’s, the equivalence relationship between sequences may become complicated; and (2) we need an efficient algorithm to compare between a large amount of sequences and ignore ‘N’ differences.</p>
      <p id="Par22">For Challenge (1), theoretically, a network graph of equivalence relationship can be constructed, where each node represents an input sequence, and equivalent nodes are connected by an edge. Deduplication can be regarded as the well-known 'maximal independent set (MIS)' problem on the graph. A MIS is a set of nodes that are not adjacent, and its members and their neighbors include all the nodes in the graph. A deduplicated set is equivalent to a MIS on the network graph. The complication is that MIS may be not unique, and the sizes of MISs may vary. As a toy example, a simple equivalence graph ‘TAC’–‘TNC’–‘TGC’ has an MIS {‘TAC’, ‘TGC’} and another MIS {‘TNC’}. More generally, a star-shaped graph can have an MIS consisting of the tip nodes, or another MIS consisting of the center node. Thus, we need a principle for choosing a MIS. For sequence deduplication, we may prefer to choose the nodes with fewer ‘N’s to represent the observed sequences, which correspond to the tip nodes of the star-shaped graph.</p>
      <p id="Par23">Finding a MIS can be achieved by adding a candidate node into a MIS and removing neighbors of the node from the query, iteratively. Instead of performing a pairwise comparison between all input sequences, we can store unique sequences that are previously deduplicated and compare each query sequence to these established deduplicated sequences, reducing the number of comparisons (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). Because we prefer unambiguous sequences, we sort the input sequences by the number of ‘N’s in ascending order, and consider each read, sequentially. This progressive pairwise comparison is implemented in pRESTO.<fig id="Fig1"><label>Fig. 1</label><caption><p>Diagram of progressive pairwise comparison and TrieDedup algorithm</p></caption><graphic xlink:href="12859_2024_5775_Fig1_HTML" id="MO1"/></fig></p>
      <p id="Par24">For Challenge (2), the pairwise comparison algorithm needs to compare each input sequence with the full set of deduplicated sequences to determine if it is unique. We adapted the trie (prefix tree) structure to store the previously deduplicated sequences, whose prefixes are organized into a consensus tree. The trie structure can retain information of sequence similarity from previous comparisons, thereby reducing the number of necessary comparisons. The trie structure can immediately identify an unobserved sequence, as soon as the input sequence diverges from the observed paths, thus reducing the number of comparisons (Fig. <xref rid="Fig1" ref-type="fig">1</xref>).</p>
      <p id="Par25">In summary, we designed and implemented the following algorithms to store and compare sequences, which can ignore mismatches due to ‘N’s.
<fig position="anchor" id="Figa"><label>Algorithm 1</label><caption><p>Deduplication with trie storing a working set of deduplicated sequences</p></caption><graphic position="anchor" xlink:href="12859_2024_5775_Figa_HTML" id="MO2"/></fig><fig position="anchor" id="Figb"><label>Algorithm 2</label><caption><p>Adding a sequence to the trie storing already deduplicated sequences</p></caption><graphic position="anchor" xlink:href="12859_2024_5775_Figb_HTML" id="MO3"/></fig><fig position="anchor" id="Figc"><label>Algorithm 3</label><caption><p>Searching for a query sequence in the trie storing already deduplicated sequences</p></caption><graphic position="anchor" xlink:href="12859_2024_5775_Figc_HTML" id="MO4"/></fig></p>
      <p id="Par26">Note:<list list-type="order"><list-item><p id="Par27">keep ‘N’ the last stored_base (after regular bases) when traversing trie_node</p></list-item><list-item><p id="Par28">searching the whole sequence from trie_root by: trie_root.search(sequence, 0)</p></list-item></list></p>
      <p id="Par29">As an implementation detail, to avoid repeatedly checking the same sequence, we also implemented exact-matching deduplication using a hash dict. This step is executed before performing actual deduplication through the trie algorithm. Subsequently, sequences are sorted in ascending order based on the number of ‘N’s present, ensuring that high-quality sequences are processed first, recognized as unique, and stored in the already deduplicated set. Sequences with more ‘N’s are processed later and progressively matched against those deduplicated sequences with fewer ambiguous ‘N’s.</p>
    </sec>
    <sec id="Sec4">
      <title>Memory usage optimization</title>
      <p id="Par30">The pairwise comparison algorithm directly stores every deduplicated, unique sequence, while our algorithm stores them in the trie structure, which theoretically costs less memory. However, empirically, storing a trie structure may cost more memory on the dict data structure than just storing simple sequences in hash keys, potentially due to Python’s base-level optimizations. To reduce memory consumption, we used __slots__ magic in Python to declare the variables. In Python, by default, a class instance declares a dict attribute named __dict__ to dynamically store its variable names and values. The __slots__ attribute in Python allows for the declaration of a fixed set of attributes for class objects, preventing the creation of the instance dict __dict__, thus significantly reducing the memory footprint of each class instance. We also implemented restrictedDict, a restricted dict with list implementation: it restricts hash keys to predetermined options, stores the values in a list instead of a dict, and keeps a shared dict to map limited keys to the index in the list. The restrictedDict achieves a smaller memory usage by storing values in a list instead of a dict, accommodating for large sequencing datasets. In DNA sequencing data, there are five possible base identities: 'A', 'C', 'G', 'T', and ‘N’. Thus, we only keep one dict as a shared class variable of restrictedDict, which stores the mapping table from the base letter (as the keys of dict) to the index in the list. For simplicity in describing the results, we abbreviate the original trie implementation as trie0, trie with only __slots__ magic as trie1, and trie with __slots__ and restrictedDict as trie2.</p>
    </sec>
    <sec id="Sec5">
      <title>Benchmark and comparison to other tools</title>
      <p id="Par31">We compared progressive pairwise comparison algorithm and trie implementation with or without memory optimization in a Dell PowerEdge T640 server, with 192GB physical memory and limited to one CPU of Intel Xeon Gold 6126 2.6GHz, and in RedHat Linux operation system. In order to ensure a fair comparison with pRESTO, which is implemented in Python and has additional functions that may affect its efficiency, we reimplemented the progressive pairwise comparison algorithm according to pRESTO. We benchmarked the accuracy, running time, and memory usage of the exact-matching, pairwise comparison, and trie algorithms using both simulated reads or real public reads as input.</p>
      <p id="Par32">To simulate input sequences, we first generated a unique set of parental sequences of a specific length, then randomly sampled them with replacement, which usually sampled approximately 55% of unique parental sequences, and lastly converted a fixed number of bases at random locations to ‘N’s in each sampled sequence. We considered sequences originating from the same parental sequence to be PCR duplicates; thereby we knew the ground truth for the size of the deduplicated set. We performed comparisons for 10<sup>3</sup>, 2 × 10<sup>3</sup>, 5 × 10<sup>3</sup>, 10<sup>4</sup>, 2 × 10<sup>4</sup>, 5 × 10<sup>4</sup>, 10<sup>5</sup>, 2 × 10<sup>5</sup>, 5 × 10<sup>5</sup>, and 10<sup>6</sup> input sequences, with lengths of 30, 100, 150, and 200 bp, and converted 1%, 5%, 10% or 20% bases to ‘N’s for each input sequence. Each condition is tested with three repeats.</p>
      <p id="Par33">We also benchmarked the performance in public HTGTS-Rep-SHM-seq data of the BCR repertoire. We downloaded raw fastq files for SRR3744758, SRR3744760 and SRR3744762 from SRA, each containing slightly more than 1 million 300-bp paired-end reads. We then randomly selected 1 million reads and masked bases with a quality score ≤ 10 by ‘N’ to serve as the input sequences.</p>
    </sec>
  </sec>
  <sec id="Sec6">
    <title>Results</title>
    <sec id="Sec7">
      <title>Theoretical complexity analysis</title>
      <p id="Par34">Suppose there are <italic>n</italic> input sequences, and each sequence has <italic>m</italic> bases. For the preprocessing steps, the time complexity of counting ‘N’s is O(<italic>m</italic> × <italic>n</italic>), and sorting <italic>n</italic> sequences can be O(<italic>n</italic> × log(<italic>n</italic>)) for quick sort, or O(<italic>n</italic>) for bucket sort.</p>
      <p id="Par35">Suppose we progressively add sequences to the deduplicated set, and the deduplicated set has already stored <italic>n</italic><sub>d</sub> sequences. The space complexity of plain storing <italic>n</italic><sub>d</sub> sequences is O(<italic>m</italic> × <italic>n</italic><sub>d</sub>). The algorithm of pairwise comparison between a candidate sequence and the deduplicated set has time complexity O(<italic>m</italic> × <italic>n</italic><sub>d</sub>). Then, the overall complexity of the whole deduplication process is O(<italic>m</italic> × <italic>n</italic><sup>2</sup>). This algorithm has been implemented in pRESTO, which runs slowly with a large number <italic>n</italic> of input sequences.</p>
      <p id="Par36">Here, we designed and implemented an algorithm using the trie structure to store the already deduplicated sequences. The upper limit of the space complexity of the trie structure storing <italic>n</italic><sub>d</sub> sequences is O(<italic>m</italic> × <italic>n</italic><sub>d</sub>), and should be lower when the sequences have common prefixes. Without ‘N’s, the time complexity of comparison between a query sequence and the trie structure is only O(<italic>m</italic>); therefore, the lowest overall complexity of the whole deduplication process is O(<italic>m</italic> × <italic>n</italic>). However, when allowing ambiguous base ‘N’s, we may need to explore more branches in the trie to determine the comparison result. Theoretically, the upper limit of complexity for one query sequence is O(<italic>m</italic> × <italic>n</italic><sub>d</sub>); therefore, the upper bound of the overall complexity is still O(<italic>m</italic> × <italic>n</italic><sup>2</sup>). Though, this situation may rarely happen as long as the input sequences do not contain too many ‘N’s. If each sequence has at most <italic>k</italic> ‘N’s, the upper limit of the time complexity between one query sequence and the trie structure is O(<italic>m</italic> × 5<sup><italic>k</italic></sup>), for 5 possible choices of bases ('A', 'C', 'G', 'T', ‘N’) at <italic>k</italic> trie nodes; therefore, the overall time complexity is O(<italic>m</italic> × <italic>n</italic> × 5<sup><italic>k</italic></sup>). Theoretically, the actual time complexity is dependent on the amount and location of ‘N’s in sequences. Sequences with fewer ‘N’s or ‘N’s located closer to the end (near trie tips) will have less complexity than those with more ‘N’s or ‘N’s located closer to the start (near trie root).</p>
    </sec>
    <sec id="Sec8">
      <title>Benchmark on simulated data</title>
      <p id="Par37">We benchmarked the accuracy, speed and memory consumption of the trie algorithm with or without memory optimization, and compared them to the performance of the progressive pairwise comparison algorithm, which we reimplemented from pRESTO, using the simulated 200-bp reads. Both the pairwise comparison and trie algorithms demonstrate high accuracy in recovering the deduplicated sets to the ground truth sizes (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4). In contrast, the exact-matching approach, which treats ‘N’s as distinct from other nucleotides, inflates the sizes a lot (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4), although it runs very fast (&lt; 2.5 s for <italic>n</italic> = 10<sup>6</sup>) and requires minimal memory (&lt; 0.7 GB for <italic>n</italic> = 10<sup>6</sup>).</p>
      <p id="Par38">The pairwise comparison and all the trie algorithms show an approximately linear relationship between log-transformed running time and the log-transformed number of input sequences (Fig. <xref rid="Fig2" ref-type="fig">2</xref>A). The slope of pairwise comparison is close to the theoretical order 2. On the other hand, the slope of the trie algorithm is much lower, which is ≤ 1.3 for <italic>n</italic> ≤ 10<sup>5</sup> and the percentage of ambiguous bases in reads (N%) ≤ 10%, and increases for larger <italic>n</italic> or N%. When the input sequences are less than 5000, the pairwise comparison algorithm is more efficient than the trie algorithm whose performance is less than 3s. When there are more than 5000 input sequences, the trie algorithm runs significantly faster than pairwise comparison.<fig id="Fig2"><label>Fig. 2</label><caption><p>Running time and memory usage increases with larger amount of input sequences (benchmark simulation). <bold>A</bold> Running time; <bold>B</bold> memory usage. Input sequences are 200 bp in length. Error bars shows mean ± standard deviation, each with 3 replicates</p></caption><graphic xlink:href="12859_2024_5775_Fig2_HTML" id="MO5"/></fig></p>
      <p id="Par39">The trie algorithm significantly outperforms pairwise comparison at large input sizes. For example, at N% = 5% and <italic>n</italic> = 10<sup>4</sup>, pairwise comparison needs 8.9s (on average), trie algorithm needs ≤ 5.0s; at <italic>n</italic> = 10<sup>5</sup>, pairwise comparison needs 1100 s (or 18.3 min), trie algorithm needs ≤ 55s; at <italic>n</italic> = 10<sup>6</sup>, pairwise comparison needs 125000s (or 34.7h), trie algorithm needs ≤ 1755s (or 29.3 min).</p>
      <p id="Par40">When comparing the running time among the three different options of memory optimization of the trie implementation, we found that all the three options have very similar running time, without magnitude difference. Trie1 runs relatively faster than trie0 and trie2, with the difference being less than twofold (Fig. <xref rid="Fig2" ref-type="fig">2</xref>A).</p>
      <p id="Par41">In terms of memory usage, the pairwise algorithm is more memory-efficient to implement than the trie because entire sequences can be stored as one item instead of storing each base individually (Fig. <xref rid="Fig2" ref-type="fig">2</xref>B). Among three trie implementations, as expected, trie0 requires the most memory and trie2 requires the least. The slopes for the three options in Python implementation are similar, all close to but a little less than the theoretical 1. For <italic>n</italic> ≥ 10<sup>5</sup>, the implementation of restrictedDict (trie2) improves the memory usage of __slots__ optimization (trie1) by approximately 19%, while trie1 improves 20% compared to trie0; therefore, trie2 only uses 65% memory as much as trie0 uses.</p>
      <p id="Par42">When N% = 5% and <italic>n</italic> = 10<sup>4</sup>, pairwise comparison on average requires 0.07GB memory to run, while trie0 requires 0.62GB, trie1 0.51GB, and trie2 0.42GB; when <italic>n</italic> = 10<sup>5</sup>, pairwise comparison needs 0.19GB, trie0 5.6GB, trie1 4.5GB, and trie2 3.7GB; when <italic>n</italic> = 10<sup>6</sup>, pairwise comparison requires 1.6GB, trie0 55GB, trie1 44GB, and trie2 36GB.</p>
      <p id="Par43">We also evaluated the influence of the length of input sequences and N% on the performance of pairwise comparison and trie2 (Additional file <xref rid="MOESM2" ref-type="media">2</xref>: Fig. S1, Additional file <xref rid="MOESM2" ref-type="media">2</xref>: Fig. S2). As expected, longer length will need more running time and memory usage. The percentage of ambiguous bases in reads (N%) barely impacts the memory usage of both algorithms. This is likely because the memory usage is more closely correlated with the number of unique reads stored in the already deduplicated set, whose ground truth remained constant across different N% in our simulation. On the other hand, a higher N% increases the running time of the trie algorithm, while it does not affect the running time of pairwise comparison. This may be because the pairwise comparison algorithm requires a lot of comparisons between sequence pairs until it finds a match, which is not significantly affected by N; whereas the trie algorithm needs to search through more branches when the query sequence contains more ‘N’s. Additionally, when a sequence with more ‘N’s is considered unique and added to the trie structure, it may slow down subsequent searches by increasing the possible branches at ‘N’.</p>
    </sec>
    <sec id="Sec9">
      <title>Benchmark on real data</title>
      <p id="Par44">We applied the exact-matching, pairwise comparison, and trie algorithms to published sequencing data with a read length of 300 bp and an average N% of 4.9–15.8%. As expected, higher N% and a lower percentage of unique reads were observed in R2 than in R1 reads. With an input size of 10<sup>6</sup> raw reads, both pairwise comparison and trie algorithms reported the same numbers of unique reads (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4). In contrast, although the exact-matching approach runs very fast (&lt; 4 s) and requires minimal memory (&lt; 0.75 GB), it likely inflates the sizes of deduplicated sets, especially for R2 reads, whose N% is higher than R1 reads (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4). Deduplication by trie2 only needed 0.9–2.1 h using 35–55 GB of memory, while deduplication by pairwise comparison required 6–16 days with about 1.5 GB memory usage (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). Therefore, trie2 deduplication can achieve about 270-fold faster speed than pairwise comparison, with 32-fold higher memory usage.<fig id="Fig3"><label>Fig. 3</label><caption><p>Running time and memory usage when applying on 10<sup>6</sup> real 300-bp reads from SRA. X-axis ‘N%’ shows the average percentage of ambiguous base ‘N’s in reads</p></caption><graphic xlink:href="12859_2024_5775_Fig3_HTML" id="MO6"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec10">
    <title>Discussion</title>
    <p id="Par45">To deduplicate high-throughput sequencing libraries while ignoring differences only due to ambiguous base ‘N’s, we adapted the trie structure to store deduplicated sequences, and implemented a corresponding algorithm, named TrieDedup. When the input size is larger than 5000 sequences, the trie algorithm is more efficient than the pairwise comparison algorithm used in pRESTO, at the price of higher memory usage. TrieDedup can deduplicate up to 10<sup>6</sup> input sequences within 2 h using less than 36GB of memory. In addition, TrieDedup may be potentially adapted into pRESTO framework.</p>
    <p id="Par46">The real data we used for benchmarking were public HTGTS-Rep-SHM-seq data of BCR repertoire downloaded from SRA (SRR3744758, SRR3744760, and SRR3744762). For such a typical study targeting B cell receptor repertoire, these samples originally contain 1.22 million, 1.10 million, and 1.49 million 300-bp reads respectively, with the fastq file sizes being approximately 1.6 GB, 1.5 GB, and 2 GB. For our benchmark experiments, we randomly selected 1 million reads from these samples, believing that this number represents a realistic read number for this type of sequencing data. For the other genomic studies, the read number can vary significantly in scale, which depends on the targeted genomic region size, the depth of sequencing, and the lengths of sequenced reads. For instance, a 30X Whole Genome Sequencing (WGS) of a human genome typically requires around 900 million 100-bp reads, while an 80X Whole Exome Sequencing (WES) might need about 24 million 100-bp reads. These quantities are 1–3 orders of magnitude higher than those typical targeted sequencing such as B cell repertoire studies. Our benchmark suggests a dataset of up to 1 million reads, or a fastq file size of approximately 1.5GB, can be efficiently deduplicated by our TrieDedup with approximately 36GB of memory usage which a typical server has the memory capacity to support. Since both the running time and memory usage increase with the number of input sequences, and the complexity order of running time on N exceeds one, the efficiency of deduplication may be further improved if we can divide the input sequences into smaller non-overlapping groups. To handle a larger number of reads, we also recommend grouping reads to reduce each group to below 1 million reads. For example, the reads may be grouped based on sequence prefixes, or the mapped chromosome and coordinate range if the reads have been aligned, or the V and J alignment for V(D)J repertoire. If these subsets of data are processed separately, the algorithm will have to store fewer reads simultaneously, hence reducing memory usage.</p>
    <p id="Par47">Trie structure has also been used in the deduplication of Unique Molecular Identifiers (UMIs) [<xref ref-type="bibr" rid="CR17">17</xref>], but the traditional trie structure cannot handle ambiguous bases, although errors in UMIs are common [<xref ref-type="bibr" rid="CR18">18</xref>]. UMIs containing any ‘N’s or bases with a <italic>Q</italic> score below 10 are by default filtered out during 10x Genomics Cell Ranger processing. Here, we designed and implemented TrieDedup, where the specialized trie structure and algorithm can correctly and efficiently handle the differences due to ambiguous bases. With its ultra-fast algorithm, TrieDedup may also potentially be applied to barcode or UMI assignment when considering reads with a few low-quality bases in the UMIs.</p>
    <p id="Par48">We designed, implemented, and showcased a universal algorithm using a trie for deduplication that allows for ambiguous letter matching, therefore, we did not restrict the allowed keys of restrictedDict to ‘A’, ‘C’, ‘G’, ‘T’ and ‘N’. Our highly versatile TrieDedup algorithm can be applied not only to DNA reads, as evaluated in the manuscript, but also directly to protein amino acid sequences and even text word matching. To further improve runtime and memory usage, we also implemented TrieDedup in Java and C++, but hard-coded the allowed keys to DNA bases. These implementations are also available in our GitHub repository. Compared to Python implementation, TrieDedup C++ implementation achieved 5–11-fold faster and 1/3 memory. However, it imposes limitations by being restricted solely to DNA sequences, underscoring a trade-off between performance optimization and general applicability.</p>
    <p id="Par49">The threshold of <italic>Q</italic> scores for converting low-quality bases to ambiguous ‘N’s, which is often library-specifically set to 10 or 20 arbitrarily, may affect N% in input reads, as well as the amount of deduplicated reads. A potentially more principled approach is to sum up the error rate of mismatches in pairwise comparison, and then set the threshold on the sum error rate to judge the equivalence between reads. However, it may generate a more complicated relationship of equivalence and even higher computational complexity than the current pairwise comparison algorithm in pRESTO.</p>
  </sec>
  <sec id="Sec11">
    <title>Conclusions</title>
    <p id="Par50">We implemented TrieDedup, which uses the trie structure to store deduplicated sequences, and ignores differences only due to ambiguous base ‘N’s. We also implemented a memory-efficient class, restrictedDict, that reduced the memory usage to about 0.8-fold. TrieDedup significantly outperforms the pairwise comparison strategy when the amount of input sequences is larger than a few thousand. TrieDedup can deduplicate reads up to 270-fold faster than pairwise comparison at a cost of 32-fold higher memory usage. Potentially, TrieDedup may be adapted into pRESTO, and may be generalized to other scenarios for deduplication with ambiguous letters.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <sec id="Sec12">
      <title>Supplementary Information</title>
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2024_5775_MOESM1_ESM.xlsx">
            <caption>
              <p><bold>Additional file 1: Table S1.</bold> The percentage of CDR3 sequences containing ambiguous bases (‘N’s) in public dataset GSE214884. <bold>Table S2.</bold> Unique and potential duplicate sequences with ambiguous bases ‘N’s in 5-aa CDR3 sequences from GSM6617404. <bold>Table S3.</bold> The number of CDR3 sequences before and after deduplication in public dataset GSE214884. <bold>Table S4.</bold> The number of sequences after deduplication for benchmark analysis.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="12859_2024_5775_MOESM2_ESM.docx">
            <caption>
              <p><bold>Additional file 2: Figure S1.</bold> Running time for input sequences with different lengths. Error bars shows mean ± standard deviation, each with 3 replicates. <bold>Figure S2.</bold> Memory usage for input sequences with different lengths. Error bars shows mean ± standard deviation, each with 3 replicates.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>PCR</term>
        <def>
          <p id="Par4">Polymerase chain reaction</p>
        </def>
      </def-item>
      <def-item>
        <term><italic>Q</italic> score</term>
        <def>
          <p id="Par5">Base quality score</p>
        </def>
      </def-item>
      <def-item>
        <term>BCR</term>
        <def>
          <p id="Par6">B cell receptor</p>
        </def>
      </def-item>
      <def-item>
        <term>CDR</term>
        <def>
          <p id="Par7">Complementarity-determining region</p>
        </def>
      </def-item>
      <def-item>
        <term>HTGTS-Rep-SHM-Seq</term>
        <def>
          <p id="Par8">High-throughput genome-wide translocation sequencing-adapted repertoire and somatic hypermutation sequencing</p>
        </def>
      </def-item>
      <def-item>
        <term>aa</term>
        <def>
          <p id="Par9">Amino acid</p>
        </def>
      </def-item>
      <def-item>
        <term>MIS</term>
        <def>
          <p id="Par10">Maximal independent set</p>
        </def>
      </def-item>
      <def-item>
        <term>trie0</term>
        <def>
          <p id="Par11">Trie implementation without memory optimization</p>
        </def>
      </def-item>
      <def-item>
        <term>trie1</term>
        <def>
          <p id="Par12">Trie implementation with only __slots__ magic</p>
        </def>
      </def-item>
      <def-item>
        <term>trie2</term>
        <def>
          <p id="Par13">Trie implementation with __slots__ and restrictedDict</p>
        </def>
      </def-item>
      <def-item>
        <term>N%</term>
        <def>
          <p id="Par14">Percentage of ambiguous bases in reads</p>
        </def>
      </def-item>
      <def-item>
        <term>UMIs</term>
        <def>
          <p id="Par15">Unique Molecular Identifiers</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to express our deep gratitude to Prof. Frederick W Alt, for his unwavering support and generously providing the necessary resources and funding throughout this projects.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>SL and MT raised the scientific questions, AYY conceptualized and designed the software. AYY and JH developed the software. JH, SL and MT, and AYY tested and validated the software. JH performed benchmark analysis. JH and AYY conducted data analysis and visualization. JH, SL and MT, and AYY wrote the manuscript. All authors read, critically revised, and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>AYY is a Bioinformatics Specialist of Howard Hughes Medical Institute and Boston Children's Hospital. JH receives salary support from NIH Grants R01AI020047, R01AI077595 and Bill &amp; Melinda Gates Foundation Investment INV-021989. SL receives salary support from Bill &amp; Melinda Gates Foundation Investment INV-021989. MT receives salary support from NIH/NIAID Grants 5P01 AI138211-04 (to M.A), 5UM1 AI144371-03 (to B.H.) and Bill &amp; Melinda Gates Foundation Investment INV-021989 (to F.A. and M.T.).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>TrieDedup code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/lolrenceH/TrieDedup">https://github.com/lolrenceH/TrieDedup</ext-link>. The real data we used for benchmarking are public data downloaded from NCBI-SRA, with accession number: SRR3744758 (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/SRR3744758">https://www.ncbi.nlm.nih.gov/sra/SRR3744758</ext-link>), SRR3744760 (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/SRR3744760">https://www.ncbi.nlm.nih.gov/sra/SRR3744760</ext-link>) and SRR3744762 (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/SRR3744762">https://www.ncbi.nlm.nih.gov/sra/SRR3744762</ext-link>). Project name: TrieDedup: A fast trie-based deduplication algorithm to handle ambiguous bases in high-throughput sequencing. Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/lolrenceH/TrieDedup">https://github.com/lolrenceH/TrieDedup</ext-link>. Operating system(s): Platform independent. Programming language: Python, with C++ and Java implementations available on GitHub. Other requirements: seqtk, pandas. License: Apache 2.0. Any restrictions to use by non-academics: None.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar4">
      <title>Ethics approval and consent to participate</title>
      <p id="Par51">Not applicable.</p>
    </notes>
    <notes id="FPar5">
      <title>Consent for publication</title>
      <p id="Par52">Not applicable.</p>
    </notes>
    <notes id="FPar6" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par53">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>SG</given-names>
          </name>
          <name>
            <surname>Ba</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Alt</surname>
            <given-names>FW</given-names>
          </name>
        </person-group>
        <article-title>Highly sensitive and unbiased approach for elucidating antibody repertoires</article-title>
        <source>Proc Natl Acad Sci</source>
        <year>2016</year>
        <volume>113</volume>
        <fpage>7846</fpage>
        <lpage>7851</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1608649113</pub-id>
        <?supplied-pmid 27354528?>
        <pub-id pub-id-type="pmid">27354528</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>AY</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>C-S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>BCR selection and affinity maturation in Peyer’s patch germinal centres</article-title>
        <source>Nature</source>
        <year>2020</year>
        <volume>582</volume>
        <fpage>421</fpage>
        <lpage>425</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-020-2262-4</pub-id>
        <?supplied-pmid 32499646?>
        <pub-id pub-id-type="pmid">32499646</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Handsaker</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Wysoker</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Fennell</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ruan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Homer</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The sequence alignment/map format and SAMtools</article-title>
        <source>Bioinformatics</source>
        <year>2009</year>
        <volume>25</volume>
        <fpage>2078</fpage>
        <lpage>2079</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btp352</pub-id>
        <?supplied-pmid 19505943?>
        <pub-id pub-id-type="pmid">19505943</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cock</surname>
            <given-names>PJA</given-names>
          </name>
          <name>
            <surname>Fields</surname>
            <given-names>CJ</given-names>
          </name>
          <name>
            <surname>Goto</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Heuer</surname>
            <given-names>ML</given-names>
          </name>
          <name>
            <surname>Rice</surname>
            <given-names>PM</given-names>
          </name>
        </person-group>
        <article-title>The Sanger FASTQ file format for sequences with quality scores, and the Solexa/Illumina FASTQ variants</article-title>
        <source>Nucleic Acids Res</source>
        <year>2010</year>
        <volume>38</volume>
        <fpage>1767</fpage>
        <lpage>1771</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkp1137</pub-id>
        <?supplied-pmid 20015970?>
        <pub-id pub-id-type="pmid">20015970</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ewing</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Green</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Base-calling of automated sequencer traces using <italic>Phred</italic>. II. Error probabilities</article-title>
        <source>Genome Res</source>
        <year>1998</year>
        <volume>8</volume>
        <fpage>186</fpage>
        <lpage>194</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.8.3.186</pub-id>
        <?supplied-pmid 9521922?>
        <pub-id pub-id-type="pmid">9521922</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Manley</surname>
            <given-names>LJ</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Levine</surname>
            <given-names>SS</given-names>
          </name>
        </person-group>
        <article-title>Monitoring error rates in illumina sequencing</article-title>
        <source>J Biomol Tech</source>
        <year>2016</year>
        <volume>27</volume>
        <fpage>125</fpage>
        <lpage>128</lpage>
        <pub-id pub-id-type="doi">10.7171/jbt.16-2704-002</pub-id>
        <?supplied-pmid 27672352?>
        <pub-id pub-id-type="pmid">27672352</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">Hannon GJ. FASTX-Toolkit. GitHub repository. 2010. <ext-link ext-link-type="uri" xlink:href="http://hannonlab.cshl.edu/fastx_toolkit">http://hannonlab.cshl.edu/fastx_toolkit</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">Li H. seqtk. GitHub repository. 2018. <ext-link ext-link-type="uri" xlink:href="https://github.com/lh3/seqtk">https://github.com/lh3/seqtk</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Broad Institute. Picard toolkit. GitHub repository. 2019. <ext-link ext-link-type="uri" xlink:href="https://broadinstitute.github.io/picard/">https://broadinstitute.github.io/picard/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peltzer</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jäger</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Herbig</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Seitz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kniep</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Krause</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>EAGER: efficient ancient genome reconstruction</article-title>
        <source>Genome Biol</source>
        <year>2016</year>
        <volume>17</volume>
        <fpage>60</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-016-0918-z</pub-id>
        <?supplied-pmid 27036623?>
        <pub-id pub-id-type="pmid">27036623</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Liao</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Gencore: an efficient tool to generate consensus reads for error suppressing and duplicate removing of NGS data</article-title>
        <source>BMC Bioinform</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>606</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-019-3280-9</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Meyers</surname>
            <given-names>RM</given-names>
          </name>
          <name>
            <surname>Dong</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Panchakshari</surname>
            <given-names>RA</given-names>
          </name>
          <name>
            <surname>Alt</surname>
            <given-names>FW</given-names>
          </name>
          <name>
            <surname>Frock</surname>
            <given-names>RL</given-names>
          </name>
        </person-group>
        <article-title>Detecting DNA double-stranded breaks in mammalian genomes by linear amplification–mediated high-throughput genome-wide translocation sequencing</article-title>
        <source>Nat Protoc</source>
        <year>2016</year>
        <volume>11</volume>
        <fpage>853</fpage>
        <lpage>871</lpage>
        <pub-id pub-id-type="doi">10.1038/nprot.2016.043</pub-id>
        <?supplied-pmid 27031497?>
        <pub-id pub-id-type="pmid">27031497</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vander Heiden</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Yaari</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Uduman</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Stern</surname>
            <given-names>JNH</given-names>
          </name>
          <name>
            <surname>O’Connor</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Hafler</surname>
            <given-names>DA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>pRESTO: a toolkit for processing high-throughput sequencing raw reads of lymphocyte receptor repertoires</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <fpage>1930</fpage>
        <lpage>1932</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu138</pub-id>
        <?supplied-pmid 24618469?>
        <pub-id pub-id-type="pmid">24618469</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Bushnell B. BBMap—clumpify. GitHub repository. 2021. <ext-link ext-link-type="uri" xlink:href="https://github.com/BioInfoTools/BBMap/blob/master/sh/clumpify.sh">https://github.com/BioInfoTools/BBMap/blob/master/sh/clumpify.sh</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Gregg F, Eder D. Dedupe. GitHub repository. 2022. <ext-link ext-link-type="uri" xlink:href="https://github.com/dedupeio/dedupe">https://github.com/dedupeio/dedupe</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luo</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Jing</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>AY</given-names>
          </name>
          <name>
            <surname>Kratochvil</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Cottrell</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Koo</surname>
            <given-names>J-H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Humanized V(D)J-rearranging and TdT-expressing mouse vaccine models with physiological HIV-1 broadly neutralizing antibody precursors</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2023</year>
        <volume>120</volume>
        <fpage>e2217883120</fpage>
        <pub-id pub-id-type="doi">10.1073/pnas.2217883120</pub-id>
        <?supplied-pmid 36574685?>
        <pub-id pub-id-type="pmid">36574685</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Algorithms for efficiently collapsing reads with Unique Molecular Identifiers</article-title>
        <source>PeerJ</source>
        <year>2019</year>
        <volume>7</volume>
        <fpage>e8275</fpage>
        <pub-id pub-id-type="doi">10.7717/peerj.8275</pub-id>
        <?supplied-pmid 31871845?>
        <pub-id pub-id-type="pmid">31871845</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Smith</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Heger</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sudbery</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>UMI-tools: modeling sequencing errors in Unique Molecular Identifiers to improve quantification accuracy</article-title>
        <source>Genome Res</source>
        <year>2017</year>
        <volume>27</volume>
        <fpage>491</fpage>
        <lpage>499</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.209601.116</pub-id>
        <?supplied-pmid 28100584?>
        <pub-id pub-id-type="pmid">28100584</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
