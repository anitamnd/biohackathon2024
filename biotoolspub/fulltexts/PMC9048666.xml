<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9048666</article-id>
    <article-id pub-id-type="pmid">35274689</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac154</article-id>
    <article-id pub-id-type="publisher-id">btac154</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Systems Biology</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepREAL: a deep learning powered multi-scale modeling framework for predicting out-of-distribution ligand-induced GPCR activity</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-9516-6489</contrib-id>
        <name>
          <surname>Cai</surname>
          <given-names>Tian</given-names>
        </name>
        <aff><institution>Ph.D. Program in Computer Science, The Graduate Center, The City University of New York</institution>, New York, NY 10016, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Abbu</surname>
          <given-names>Kyra Alyssa</given-names>
        </name>
        <aff><institution>Department of Computer Science, Hunter College, The City University of New York</institution>, New York, NY 10065, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Yang</given-names>
        </name>
        <aff><institution>Department of Computer Science, Hunter College, The City University of New York</institution>, New York, NY 10065, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Xie</surname>
          <given-names>Lei</given-names>
        </name>
        <xref rid="btac154-cor1" ref-type="corresp"/>
        <aff><institution>Ph.D. Program in Computer Science, The Graduate Center, The City University of New York</institution>, New York, NY 10016, <country country="US">USA</country></aff>
        <aff><institution>Department of Computer Science, Hunter College, The City University of New York</institution>, New York, NY 10065, <country country="US">USA</country></aff>
        <aff><institution>Helen and Robert Appel Alzheimer’s Disease Research Institute, Feil Family Brain &amp; Mind Research Institute, Weill Cornell Medicine, Cornell University</institution>, New York, NY 10021, <country country="US">USA</country></aff>
        <!--lei.xie@hunter.cuny.edu-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btac154-cor1">To whom correspondence should be addressed. <email>lei.xie@hunter.cuny.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-03-11">
      <day>11</day>
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>11</day>
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <volume>38</volume>
    <issue>9</issue>
    <fpage>2561</fpage>
    <lpage>2570</lpage>
    <history>
      <date date-type="received">
        <day>25</day>
        <month>11</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>18</day>
        <month>2</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>05</day>
        <month>3</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>10</day>
        <month>3</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>22</day>
        <month>3</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac154.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Drug discovery has witnessed intensive exploration of predictive modeling of drug–target physical interactions over two decades. However, a critical knowledge gap needs to be filled for correlating drug–target interactions with clinical outcomes: predicting genome-wide receptor activities or function selectivity, especially agonist versus antagonist, induced by novel chemicals. Two major obstacles compound the difficulty on this task: known data of receptor activity is far too scarce to train a robust model in light of genome-scale applications, and real-world applications need to deploy a model on data from various shifted distributions.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>To address these challenges, we have developed an end-to-end deep learning framework, DeepREAL, for multi-scale modeling of genome-wide ligand-induced receptor activities. DeepREAL utilizes self-supervised learning on tens of millions of protein sequences and pre-trained binary interaction classification to solve the data distribution shift and data scarcity problems. Extensive benchmark studies on G-protein coupled receptors (GPCRs), which simulate real-world scenarios, demonstrate that DeepREAL achieves state-of-the-art performances in out-of-distribution settings. DeepREAL can be extended to other gene families beyond GPCRs.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>All data used are downloaded from Pfam (<xref rid="btac154-B25" ref-type="bibr">Mistry <italic toggle="yes">et al.</italic>, 2020</xref>), GLASS (<xref rid="btac154-B4" ref-type="bibr">Chan <italic toggle="yes">et al.</italic>, 2015</xref>) and IUPHAR/BPS and the data from reference (<xref rid="btac154-B29" ref-type="bibr">Sakamuru <italic toggle="yes">et al.</italic>, 2021</xref>). Readers are directed to their official website for original data. Code is available on GitHub <ext-link xlink:href="https://github.com/XieResearchGroup/DeepREAL" ext-link-type="uri">https://github.com/XieResearchGroup/DeepREAL</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of General Medical Sciences of National Institute of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01GM122845</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute on Aging of the National Institute of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01AD057555</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Over the past two decades, drug discovery has been dominated by target-based high-throughput compound screening. Unfortunately, this ‘one-drug–one-gene’ approach has been costly and had a low success rate due to our limited understanding of molecular and cellular mechanisms of drug actions (<xref rid="btac154-B5" ref-type="bibr">DiMasi <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btac154-B35" ref-type="bibr">Wong <italic toggle="yes">et al.</italic>, 2019</xref>). Drugs from the target-based screening often interact with unexpected off-targets, leading to serious side effects (<xref rid="btac154-B21" ref-type="bibr">Lin <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac154-B24" ref-type="bibr">Lynch III <italic toggle="yes">et al.</italic>, 2017</xref>). Furthermore, a polypharmacology approach is often needed to achieve desired therapeutic efficacy and overcome drug resistance for complex diseases (<xref rid="btac154-B37" ref-type="bibr">Xie <italic toggle="yes">et al.</italic>, 2012</xref>). To predict drug phenotypic response at the organismal level, it is necessary to not only elucidate genome-scale drug–target interactions (DTIs) but also reveal how DTIs collectively modulate a biological system.</p>
    <p>The drug mode of action is a multi-scale process that starts with drug binding to its targets, principally proteins. Then the drug can act as an antagonist or an agonist to block or enhance downstream biological processes, respectively. Therefore, it is critically important to model the change of receptor activities or functional selectivity upon the drug binding for understanding how the drug modulates pathophysiological functions. The information on the receptor activity following the ligand binding will fill in a critical knowledge gap in correlating DTIs to clinical outcomes. Although a great deal of efforts have been devoted to predict genome-wide DTIs using deep learning (<xref rid="btac154-B3" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac154-B17" ref-type="bibr">Karimi <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac154-B33" ref-type="bibr">Wan and Zeng, 2016</xref>), few large-scale experimental and computational studies have been able to specify the ligand-induced receptor activity, i.e. the functional selectivity of the ligand as an antagonist or an agonist (<xref rid="btac154-B29" ref-type="bibr">Sakamuru <italic toggle="yes">et al.</italic>, 2021</xref>).</p>
    <p>In this research, we aim to predict not only whether any pairs of proteins and chemicals interact with each other or not but also the receptor activity upon the binding, especially, making reliable predictions for understudied ‘dark’ proteins that do not have any ligand annotations (<xref rid="btac154-B26" ref-type="bibr">Oprea, 2019</xref>) and novel chemicals whose structures are different from those in the training data. To our knowledge, only a recent work has used chemical features to train an independent machine learning model for each individual Opioid receptor for predicting their receptor activity (<xref rid="btac154-B29" ref-type="bibr">Sakamuru <italic toggle="yes">et al.</italic>, 2021</xref>). Unfortunately, labeled data for the receptor activity are scarce. Only a limited number of receptors have sufficient function selectivity data to train a robust machine learning model. Thus, the one-protein–one-model approach cannot be extended to majority of proteins that have few or no labeled data (<xref rid="btac154-B29" ref-type="bibr">Sakamuru <italic toggle="yes">et al.</italic>, 2021</xref>). An early work applied a neural network model to predict multiple interaction types for annotated proteins (<xref rid="btac154-B34" ref-type="bibr">Wang and Zeng, 2013</xref>). However, this work neither included antagonist/agonist as prediction tasks nor was tested for dark proteins. It is a challenging task to predict the function for dark proteins in general using machine learning. Conventional machine learning methods assume that the distribution of unseen data and training data is identically and independently distributed (IID). This assumption may not hold for the dark proteins that are dissimilar from those in the training data. In other words, many dark proteins are out-of-distribution (OOD) in terms of the training samples. Similarly, unseen novel chemicals whose structures are different from those in the training set are also OOD cases. To address the data scarcity and OOD challenges, we have developed an artificial intelligence (AI)-powered multi-scale modeling framework, DeepREAL, to simulate the multi-scale drug actions and predict the ligand-induced receptor activity for dark proteins and novel chemicals. We first apply self-supervised learning to train a protein sequence model for a universal protein sequence embedding on a genome scale. This allows us to detect subtle relationships between dark proteins and ligand-annotated proteins as demonstrated in other studies (<xref rid="btac154-B3" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac154-B27" ref-type="bibr">Rao <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac154-B28" ref-type="bibr">Rives <italic toggle="yes">et al.</italic>, 2021</xref>). We then train a binary classification deep learning model to predict whether a chemical binds to a protein and extract a latent presentation of DTIs. Because there is a large amount of binary interaction data, it is possible to train a robust deep learning model. Finally, we integrate chemical embedding model, sequence embedding model and DTI latent representation model to train an end-to-end deep learning model for predicting the ligand-induced receptor activity using limited data. In the rigorous benchmark studies on GPCRs, which simulate real-world applications, DeepREAL significantly improves the generalization ability in the OOD setting compared with the state-of-the-art methods (<xref rid="btac154-B3" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac154-B29" ref-type="bibr">Sakamuru <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac154-B34" ref-type="bibr">Wang and Zeng, 2013</xref>).</p>
    <p>The contributions of DeepREAL can be summarized in twofolds:
</p>
    <list list-type="order">
      <list-item>
        <p>DeepREAL aims to address an unsolved but important challenging problem for drug discovery: robustly predicting genome-wide ligand-induced receptor activities or function selectivity under various data distribution shifts.</p>
      </list-item>
      <list-item>
        <p>DeepREAL is based on a new multi-stage deep transfer learning architecture that combines binary DTI pre-training and embedding with a three-way receptor activity fine-tuning to address OOD challenges using sparse receptor activity data.</p>
      </list-item>
    </list>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Data</title>
      <p>Four datasets were used in this study. Pfam, v33.1 (<xref rid="btac154-B25" ref-type="bibr">Mistry <italic toggle="yes">et al.</italic>, 2020</xref>) was used to pre-train protein descriptors. GPCR–ligand binding binary data were obtained from GLASS, v2019.2 (<xref rid="btac154-B4" ref-type="bibr">Chan <italic toggle="yes">et al.</italic>, 2015</xref>). Agonist/antagonist data were downloaded from the International Union of Basic and Clinical Pharmacology/British Pharmacological Society (IUPHAR/BPS) Guide to Pharmacology, v2020.5. Additional Opioid receptor activity data were from the study by <xref rid="btac154-B29" ref-type="bibr">Sakamuru <italic toggle="yes">et al.</italic> (2021)</xref>. The protein descriptor pre-training exactly followed DISAE (<xref rid="btac154-B3" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2021</xref>). In brief, DISAE built up a distilled triplet sequence dictionary for the whole Pfam proteins based on multiple sequence alignments (MSA). Every input protein was mapped to its distilled triplets representation according to the protein dictionary, as illustrated in <xref rid="btac154-F1" ref-type="fig">Figure 1</xref>. Chemical-protein pairs with the receptor activity annotation was treated as positive in the binary DTI setting and combined with GLASS for the binary classification pre-training. In terms of pre-training, only Stage 1 protein descriptor pre-training was self-supervised as described in the study by <xref rid="btac154-B3" ref-type="bibr">Cai <italic toggle="yes">et al.</italic> (2021)</xref>. Stage 2 uses CLASS data for supervised pre-training. IUPHAR/BPS combined with <xref rid="btac154-B29" ref-type="bibr">Sakamuru <italic toggle="yes">et al.</italic> (2021)</xref> Opioid data were used in the final Stage 3 three-way classification. Detailed data statistics is found in <xref rid="btac154-T1" ref-type="table">Table 1</xref>.</p>
      <fig position="float" id="btac154-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Illustration of DeepREAL. (<bold>A</bold>) Given a chemical and a protein sequence as inputs, DeepREAL will predict not only if the chemical is the ligand of the protein but also the ligand-induced receptor activity. (<bold>B</bold>) DeepREAL is an end-to-end deep learning model trained using three stages of pre-training and fine-tuning. See text for details</p>
        </caption>
        <graphic xlink:href="btac154f1" position="float"/>
      </fig>
      <table-wrap position="float" id="btac154-T1">
        <label>Table 1.</label>
        <caption>
          <p>Training, validation and testing data used in this study</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th align="center" rowspan="1" colspan="1">Unique protein</th>
              <th align="center" rowspan="1" colspan="1">Unique chemical</th>
              <th align="center" rowspan="1" colspan="1">Agonist</th>
              <th align="center" rowspan="1" colspan="1">Antagonist</th>
              <th align="center" rowspan="1" colspan="1">Not-binding</th>
              <th align="center" rowspan="1" colspan="1">Binding</th>
              <th align="center" rowspan="1" colspan="1">(OOD TEST imbalance ratio control) not-binding:agonist:antagonist</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">IUPHAR</td>
              <td rowspan="1" colspan="1">450</td>
              <td rowspan="1" colspan="1">13 126</td>
              <td rowspan="1" colspan="1">14 412</td>
              <td rowspan="1" colspan="1">14 488</td>
              <td rowspan="1" colspan="1">144 500</td>
              <td rowspan="1" colspan="1">28 900</td>
              <td rowspan="1" colspan="1">5:1:1</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Opioid receptors related</td>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">2483</td>
              <td rowspan="1" colspan="1">2920</td>
              <td rowspan="1" colspan="1">2996</td>
              <td rowspan="1" colspan="1">29 580</td>
              <td rowspan="1" colspan="1">5916</td>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GLASS</td>
              <td rowspan="1" colspan="1">689</td>
              <td rowspan="1" colspan="1">181 114</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">70 089</td>
              <td rowspan="1" colspan="1">270 545</td>
              <td rowspan="1" colspan="1">—</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>2.2 State-of-the-art baselines</title>
      <p>We compared DeepREAL with Random Forest (RF) models for three Opiod receptors (<xref rid="btac154-B29" ref-type="bibr">Sakamuru <italic toggle="yes">et al.</italic>, 2021</xref>) that used PubChem fingerprints (ftp://ftp.ncbi.nlm.nih.-gov/pubchem/specifications/pubchem_fingerprints.txt) (<xref rid="btac154-B2" ref-type="bibr">Bolton <italic toggle="yes">et al.</italic>, 2008</xref>) as features. To our knowledge, the RF/protein baseline was the first and only work for the ligand-induced receptor activity prediction. Keeping other hyper-parameters the same as those in the study by <xref rid="btac154-B29" ref-type="bibr">Sakamuru <italic toggle="yes">et al.</italic> (2021)</xref>, the RF depth was tuned to find the best performance model for each Opioid receptor. An example performance curve is shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S6</xref>. For each experiment, one Random Forest is trained for each Opioid receptor. An average RF test performance was calculated by weighting the sample size of each Opioid receptor. When evaluating the variance of model performance, different random seeds were used.</p>
      <p>Another baseline model is similar to restricted Boltzmann machines from an earlier work (<xref rid="btac154-B34" ref-type="bibr">Wang and Zeng, 2013</xref>) which is designed to predict DTI types. We built a multi-task deep learning model that consisted of two layer vanilla MLP (<xref rid="btac154-B14" ref-type="bibr">Goodfellow <italic toggle="yes">et al</italic>., 2016</xref>) for every single target, i.e. one Opioid receptor, with the same number of hidden units and the same definitions of visible units (<xref rid="btac154-B14" ref-type="bibr">Goodfellow <italic toggle="yes">et al.</italic>, 2016</xref>) by optimizing the average cross entropy loss of the model for each target. The constructed multi-task MLP for a multidimensional DTI network was associated with the same parameters. The input feature was also PubChem fingerprints (<xref rid="btac154-B2" ref-type="bibr">Bolton <italic toggle="yes">et al.</italic>, 2008</xref>).</p>
    </sec>
    <sec>
      <title>2.3 DeepREAL framework</title>
      <sec>
        <label>2.3.1</label>
        <title>Architecture</title>
        <p>DeepREAL has a novel three-stage framework. There are four major modules in DeepREAL model: protein sequence embedding, chemical structure descriptor, binary interaction learner and multi-class receptor activity classifier as shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>. Under this framework, the state-of-the-art model DISAE (<xref rid="btac154-B3" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2021</xref>) was employed as the backbone for learning DTI embeddings, which includes ALBERT- (<xref rid="btac154-B19" ref-type="bibr">Lan <italic toggle="yes">et al.</italic>, 2019</xref>) based protein descriptor, and attentive pooling- (<xref rid="btac154-B7" ref-type="bibr">Santos <italic toggle="yes">et al.</italic>, 2016</xref>) based binary interaction learner. Different from DISAE that uses neuro-fingerprint for the chemical representation, the chemical descriptor in DeepREAL is state-of-the-art unpretrained graph neural network GIN (<xref rid="btac154-B38" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2018</xref>).</p>
        <p>The unique component of multi-class receptor activity classifier includes two sub-modules. A three-way interaction learner uses the same architecture as the binary interaction learner. After concatenating all related embeddings, the concatenated tensor goes through a ResNET (<xref rid="btac154-B13" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2015</xref>) layer and MLP (<xref rid="btac154-B12" ref-type="bibr">Hastie <italic toggle="yes">et al.</italic>, 2019</xref>) transformation to generate the final logit vector used in cross entropy loss calculation (<xref rid="btac154-B15" ref-type="bibr">Hu <italic toggle="yes">et al.</italic>, 2019</xref>).</p>
      </sec>
      <sec>
        <label>2.3.2</label>
        <title>Information flow of DeepREAL</title>
        <p>The knowledge transfer across stages is realized by sharing weights on the first three modules in DeepREAL architecture, i.e. protein descriptor, chemical descriptor and binary interaction learner. Protein descriptor first goes through Stage 1 sequence pre-training in a self-supervised fashion. The pre-trained sequence embeddings are then transferred to Stage 2 binary pre-training. Together with initialized chemical descriptor, a binary interaction learner learns to predict whether or not a protein and a chemical would interact in a supervised learning manner. The learned weights of these three modules are all transferred to Stage 3. In Stage 3, the three modules are first duplicated: one copy has frozen weights whereas the other copy updates its weights for <italic toggle="yes">n</italic> epochs with multi-class-learner on DeepREAL receptor activity information in a supervised learning manner, where <italic toggle="yes">n</italic> is a hyper-parameter as shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>. In our experiments, we find that a small <italic toggle="yes">n</italic> such as 50 would help to improve model generalization performance when the training data size was smaller. This phenomenon is due to the fact that a complete model with a large number of trainable parameters is capable of memorizing a small training set, resulting in over-fitting and poor generalization. More frozen weights would limit the over-fitting and put more pressures on the multi-class-learner to learn a robust representation.</p>
        <p>As illustrated in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>, the protein embedding vector, chemical embedding vector and binary interaction embedding vector that is the output of binary pre-trained module are fine-tuned via a three-way receptor activity learner that also learns a three-way receptor activity embedding. Seven embedding vectors, which include the protein embedding, the chemical embedding and the binary interaction embedding, both fine-tuned and frozen after the pre-training, along with the three-way receptor activity embedding, are concatenated and fed into a ResNET (<xref rid="btac154-B13" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2015</xref>) followed by a MLP (<xref rid="btac154-B12" ref-type="bibr">Hastie <italic toggle="yes">et al.</italic>, 2019</xref>) to make the final three-way classification.</p>
        <p>The three-stage model is designed to train sequentially and separately. Only optimized weights are transferred. The Stage 1 optimization procedure has been described in <xref rid="btac154-B3" ref-type="bibr">Cai <italic toggle="yes">et al.</italic> (2021)</xref>. Stages 2 and 3 optimizations are both driven by a cross-entropy loss in a stochastic manner using Adam (<xref rid="btac154-B18" ref-type="bibr">Kingma and Ba, 2014</xref>).</p>
      </sec>
      <sec>
        <label>2.3.3</label>
        <title>Pre-training implementation and module frozen strategy</title>
        <p>A key element of success in multi-stage pre-training is to transfer knowledge. A major challenge in the three-stage pipeline is to prevent the previously learned knowledge from being lost during the weight update in the subsequent stage. DISAE has reported the benefits of a frozen mechanism. This strategy is adopted in DeepREAL Stages 2 and 3 as well. In Stage 2, following the experience of DISAE, part of the transformer (<xref rid="btac154-B32" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic>, 2017</xref>) layers is frozen. In Stage 3, the binary pre-trained modules are duplicated to have one copy always frozen and the other copy fine-tuned for only <italic toggle="yes">n</italic> epochs. Without tuning, <italic toggle="yes">n</italic> is empirically set to 50 in the Opioid receptor focused experiments, while on the complete DeepREAL receptor dataset involving 450 proteins, <italic toggle="yes">n</italic> is set as infinity until the model converges.</p>
      </sec>
      <sec>
        <label>2.3.4</label>
        <title>Data splitting for training and testing</title>
        <p>In terms of data splitting, IID setting splits the data randomly as conventional cross-validations, except for the Opioid-context experiments where all three Opioid proteins are ensured to appear in both training and testing datasets. The OOD data split is carried out using a spectral clustering algorithm (<xref rid="btac154-B23" ref-type="bibr">Luxburg, 2007</xref>) based on pair-wise chemical similarity measured by Tanimoto coefficient and sequence similarity measured by sequence identity. The similarity distributions could be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3</xref>. In our experiments, the Stage 2 binary training is always carried out with the same data. The pairwise scores in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3</xref> are measured for each pair of a chemical from training and a chemical from test as well as a protein from training and a protein from test. For more than 95% chemicals in the test set, less than 2% chemicals in the training set have Tanimoto coefficient larger than 0.6.</p>
        <p>Because we studied several OOD and IID scenarios, in each scenario the number of proteins in the testing set is different.
</p>
        <list list-type="order">
          <list-item>
            <p>IUPHAR OOD-protein-distribution-shift. The split is made upon protein similarity. 49 out of 450 proteins in the test set. Proteins in the training and testing set have no overlaps. As shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3</xref>, majority of proteins in the testing test are not similar to those in the training set with the sequence identity less than 10%.</p>
          </list-item>
          <list-item>
            <p>IUPHAR IID setting. Data are randomly split. 298 out of 450 proteins are in the test set. 246 out of the 298 proteins in the test set are also in the training set, but there are no overlapped protein-chemical pairs between training and testing set.</p>
          </list-item>
          <list-item>
            <p>Opioid OOD-chemical-distribution-shift. The split is made upon pair-wise chemical similarity between chemicals in the training set and chemicals in the test set as shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3</xref>, where only around 0.6% of chemicals in the testing set are similar to those in the training set with Tanimoto coefficient larger than 0.6. All three Opioid proteins are in the test set.</p>
          </list-item>
          <list-item>
            <p>Opioid IID. Data are randomly split. All three Opioid proteins in the test set.</p>
          </list-item>
        </list>
      </sec>
    </sec>
    <sec>
      <title>2.4 Ensemble model for novel receptor activity prediction</title>
      <p>We build an ensemble of three DeepREAL models independently trained with different random seeds. The ensemble model is used to perform predictions on novel relations. Top predictions are selected by filtering out predictions agreed by all the three models in the ensemble.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <sec>
      <title>3.1 Overview of methods</title>
      <p>Given a chemical structure and the sequence of a receptor protein, DeepREAL will predict whether the chemical is an agonist or an antagonist if it binds to the receptor, or not bind to it at all (<xref rid="btac154-F1" ref-type="fig">Fig. 1A</xref>). As an end-to-end learning framework, the DeepReal is a three-way classifier: not-binding/agonist/antagonist. Intuitively, DeepREAL leverages large datasets to hierarchically inform predictions on the receptor activity whose labeled data are scarce along a three-stage pre-training-fine-tuning pipeline as illustrated in <xref rid="btac154-F1" ref-type="fig">Figure 1B</xref>. In Stage 1, protein descriptor was pre-trained using Pfam (<xref rid="btac154-B25" ref-type="bibr">Mistry <italic toggle="yes">et al.</italic>, 2020</xref>) data. In Stage 2, a binary DTI classifier was then pre-trained using GLASS (<xref rid="btac154-B4" ref-type="bibr">Chan <italic toggle="yes">et al.</italic>, 2015</xref>) and IUPHAR binary data (<xref rid="btac154-B1" ref-type="bibr">Armstrong <italic toggle="yes">et al.</italic>, 2019</xref>). Finally, in Stage 3, three-way classification on the receptor activity was fine-tuned using the outputs of Stages 1 and 2 as inputs with IUPHAR antagonist/agonist data (<xref rid="btac154-B1" ref-type="bibr">Armstrong <italic toggle="yes">et al.</italic>, 2019</xref>).</p>
      <p>The Stage 1 self-supervised sequence embedding was based on DISAE (<xref rid="btac154-B3" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2021</xref>). DISAE distilled the protein sequence into an ordered list of triplets by excluding evolutionarily unimportant positions from a multiple sequence alignment. Then long range residue interactions were learned via the self-attention in a transformer module. A self-supervised masked language modeling approach was used to train sequence embeddings. By pre-training protein sequences on whole Pfam in Stage 1, DeepREAL equipped itself with genome-scale protein representations that captured novel relationships between proteins beyond sequence homology as demonstrated by several studies (<xref rid="btac154-B3" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac154-B27" ref-type="bibr">Rao <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac154-B28" ref-type="bibr">Rives <italic toggle="yes">et al.</italic>, 2021</xref>). The second stage was a binary DTI pre-training which predicts binding/not-binding. By pre-training on a large scale of binary DTI data in Stage 2, DeepREAL builds knowledge of chemical–protein interactions which is the initial step in the ligand binding event and generates DTI embeddings. Finally, in Stage 3, information learned from sequence embeddings and DTI embeddings were transferred into predicting receptor activities using a small amount of data. This hierarchy design maintained knowledge learned from heterogeneous resources and enhanced model robustness when facing shifted data distribution during the deployment. The model was trained in an end-to-end fashion without feature engineering. The embedding from the pre-training is not fixed, but can be fine-tuned by the subsequent training stage. More details of DeepREAL design and implementation could be found in Methods section. Detailed model architecture is in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>.</p>
      <p>It notes that DeepREAL is an extension of DISAE (<xref rid="btac154-B3" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2021</xref>) but with several major new contributions. DISAE is a general-purpose protein language model and has been applied to predict chemical-protein interactions (<xref rid="btac154-B3" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2021</xref>), while DeepREAL is a framework designed to tackle a different task that has not been explored: predicting out-of-distribution ligand-induced receptor activity (agonist versus antagonist). This task cannot be solved by the original DISAE architecture (<xref rid="btac154-B3" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2021</xref>). In the DeepREAL framework, DISAE was mainly used as Stage 1 pre-training. In addition, DeepREAL included two more components beyond DISAE: Stage 2 DTI interaction embedding and Stage 3 three-way classification.</p>
      <p>As shown in <xref rid="btac154-T1" ref-type="table">Table 1</xref>, 689 unique human GPCRs was used for the Stage 2 DTI pre-training. These GPCRs consist of six Pfam families: PF00001, PF00002, PF00003, PF052496, PF01534 and PF02101. Among them, 450 GPCRs have known labeled receptor activity data, and was used for the Stage 3 fine-tuning. Among 180 000 ligands of GPCRs, only 3303 ligands have known agonist/antagonist activities. Moreover, majority GPCRs have less than 100 ligands that are labeled with receptor activities, as shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref>. Only 3 Opioid receptors (P35372—Mu Opioid receptor, P41145—Kappa Opioid receptor, P41143—Delta Opioid receptor) have more than 300 chemicals with known receptor activities. Thus, the labeled receptor activity data are not large enough to train a robust machine learning model on the basis of a single protein for most GPCRs.</p>
      <p>To evaluate DeepREAL performance in light of real-world applications for dark proteins and novel chemicals, both data preprocessing and controlled experiment are designed to simulate various scenarios of data distribution shifts and to answer the following questions.
</p>
      <list list-type="simple">
        <list-item>
          <p>Q1: Is the pre-training helpful to improve the performance of receptor activity prediction using a small amount of data?</p>
        </list-item>
        <list-item>
          <p>Q2: When DeepREAL is applied to unseen <italic toggle="yes">dark proteins</italic> that have low sequence similarity to those in the training data, what is the OOD generalization performance of DeepREAL?</p>
        </list-item>
        <list-item>
          <p>Q3: When DeepREAL is used to predict unseen novel <italic toggle="yes">chemicals</italic> that are significantly different from those in the training data, what is the OOD generalization performance of DeepREAL?</p>
        </list-item>
        <list-item>
          <p>Q4: When the test set label (agonist/antagonist/not-binding) distribution is close to reality and imbalanced compared to the training data, what is the generalization performance of DeepREAL?</p>
        </list-item>
        <list-item>
          <p>Q5: How does DeepREAL perform compared to the state-of-the-art baseline models in both OOD and IID settings for predicting Opioid receptor activity?</p>
        </list-item>
      </list>
      <p>We used three metrics, AUC–ROC, MCC and Cohen’s kappa to evaluate the performance of various models under different settings.</p>
    </sec>
    <sec>
      <title>3.2 Pre-training enables DeepREAL to generalize genome-scale receptor activity predictions using a relatively small dataset</title>
      <p>Pre-training has been demonstrated to be effective in several recent works (<xref rid="btac154-B17" ref-type="bibr">Karimi <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac154-B33" ref-type="bibr">Wan and Zeng, 2016</xref>) for predicting protein–ligand interactions. DeepREAL used Stages 1 and 2 as pre-trainings for learning knowledge in the protein sequence space and binary interaction space, respectively. To answer Q1, the same model architecture is trained on the same IID and OOD settings using four procedures: (i) from total scratch without any pre-training, i.e. Stage 3 only, (ii) going through Stage 1 whole Pfam pre-training but not the Stage 2 binary DTI classification pre-training, which is equivalent to the DISAE model (<xref rid="btac154-B3" ref-type="bibr">Cai <italic toggle="yes">et al.</italic>, 2021</xref>), (iii) going through only Stage 2 but not Stage 1 and (iv) complete three-stage pre-training/fine-tuning as DeepREAL. As shown in <xref rid="btac154-F2" ref-type="fig">Figures 2</xref> and <xref rid="btac154-F3" ref-type="fig">3</xref> on the evaluation cross three classes (no-binding, agonist, antagonist), the model without any pre-training (i.e. only Stage 3) has the worst performance. Stages 1 or 2 both boosts performance and the complete three-stage pipeline yields the best performance. From the by-class evaluation for antagonist or agonist as shown in <xref rid="btac154-F4" ref-type="fig">Figures 4</xref> and <xref rid="btac154-F5" ref-type="fig">5</xref>, the precision and recall of DeepREAL is mostly higher than other variants in IID, protein OOD and chemical OOD settings. Furthermore, the training curves of DeepREAL in <xref rid="btac154-F4" ref-type="fig">Figures 4</xref> and <xref rid="btac154-F5" ref-type="fig">5</xref> converges faster than other variants in most cases. The advantage of pre-training is particularly apparent in chemical distribution shift OOD in the cross-class and the by-class evaluation as shown in <xref rid="btac154-F3" ref-type="fig">Figures 3–5</xref>. The chemical OOD is a more challenging OOD setting than other settings, where both chemical structure distribution and label ratio balance shift (more details in the following section). DISAE and the only-Stage 3 model have lower Cohen’s kappa, ROC–AUC, MCC than DeepREAL and the Stage2+Stage3 model. The latter two models have relative close performance, suggesting that DTI pre-training plays a more important role than the sequence pre-training in the current training procedure. It may be because the whole-Pfam information learned at Stage 1 is more difficult to transfer to Stage 3, as supported by the observation shown in <xref rid="btac154-F4" ref-type="fig">Figures 4</xref> and <xref rid="btac154-F5" ref-type="fig">5</xref>. It will be interesting to use other advanced training procedures such as prompting (<xref rid="btac154-B11" ref-type="bibr">Gao <italic toggle="yes">et al.</italic>, 2020</xref>) or design different architectures [e.g. using skip connections (<xref rid="btac154-B6" ref-type="bibr">Dosovitskiy <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac154-B13" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2015</xref>), etc.].</p>
      <fig position="float" id="btac154-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Performance comparison of DeepREAL with its variants in (<bold>A</bold>) protein OOD and (<bold>B</bold>) protein IID settings. The performance is evaluated by multiple gene families in the IUPHAR database</p>
        </caption>
        <graphic xlink:href="btac154f2" position="float"/>
      </fig>
      <fig position="float" id="btac154-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Performance comparison of DeepREAL with its variants in (<bold>A</bold>) chemical OOD and (<bold>B</bold>) chemical IID settings. The performance is evaluated only by Opioid receptors</p>
        </caption>
        <graphic xlink:href="btac154f3" position="float"/>
      </fig>
      <fig position="float" id="btac154-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Training curves of DeepREAL and its variants when measured by the precision for predicting agonists or antagonists. The <italic toggle="yes">x</italic>-axis is number of training epochs. The <italic toggle="yes">y</italic>-axis is precision</p>
        </caption>
        <graphic xlink:href="btac154f4" position="float"/>
      </fig>
      <fig position="float" id="btac154-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>Training curves of DeepREAL and its variants when measured by the recall for predicting agonists or antagonists. The <italic toggle="yes">x</italic>-axis is number of training epochs. The <italic toggle="yes">y</italic>-axis is recall</p>
        </caption>
        <graphic xlink:href="btac154f5" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 DeepREAL is robust in various shifted distribution scenarios</title>
      <p>Q2, Q3, Q4 are three typical shifted distribution scenarios in real-world applications, i.e. the OOD generalization challenge. DeepREAL proves robust in each of the settings. It makes DeepREAL applicable to explore dark chemical genomics space.</p>
      <p>Q2 focuses on the distribution shift coming from proteins. It is a dominant challenge when applying DeepREAL to a genome-scale given majority of proteins are dark without any receptor activity data. In this setting, 450 proteins and their associated interaction data are split into an OOD train/test sets such that the sequence similarities between proteins in the testing set and those in the training set are less than 10% (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>). As shown in <xref rid="btac154-F2" ref-type="fig">Figure 2</xref>, although the performance drops compared with the easier IID setting, the ROC-AUC score is still at 0.766, while existing state-of-the-art RF-based one-protein-one-model (RF/protein) approach (<xref rid="btac154-B29" ref-type="bibr">Sakamuru <italic toggle="yes">et al.</italic>, 2021</xref>) and multi-task neural network model (<xref rid="btac154-B34" ref-type="bibr">Wang and Zeng, 2013</xref>) are totally unable to make reliable predictions in the protein OOD setting.</p>
      <p>In a similar fashion, by splitting the data based on the chemical similarity measured by Tanimoto coefficient, DeepREAL is evaluated in the setting of chemical distribution shift to answer Q3. Only Opioid receptors are used in the evaluation because only Opioid receptors have sufficient large numbers of labeled chemicals to generate OOD training/testing dataset, as shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref>. In addition, we would like to reduce the impact of the OOD from receptors. The advantage of DeepREAL is apparent over other configurations including DISAE, as shown in <xref rid="btac154-F3" ref-type="fig">Figures 3</xref> and <xref rid="btac154-F6" ref-type="fig">6A</xref> in the chemical OOD setting. It notes that only around 0.6% of chemicals in the testing set are similar to those in the training set with Tanimoto coefficient larger than 0.6, as shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3</xref>.</p>
      <fig position="float" id="btac154-F6">
        <label>Fig. 6.</label>
        <caption>
          <p>Performance comparison of DeepREAL with the Random Forest model (RF/protein) and multi-task MLP in (<bold>A</bold>) chemical OOD and, (<bold>B</bold>) chemical IID settings. The performance is evaluated by precision and recall for agonist or antagonist predictions</p>
        </caption>
        <graphic xlink:href="btac154f6" position="float"/>
      </fig>
      <p>Although it is expected that a machine learning model performs the best when positive and negative data are balanced, the unseen binding/not-binding cases are imbalanced in reality, which has an estimated ratio of 1:5 (<xref rid="btac154-B20" ref-type="bibr">Lim <italic toggle="yes">et al.</italic>, 2016</xref>). The ratio of 1:5 is based on the estimated value in the published work (<xref rid="btac154-B20" ref-type="bibr">Lim <italic toggle="yes">et al.</italic>, 2016</xref>) when considering the chemical genomics space (millions of chemicals paired with thousands of proteins) as a whole, which is the same scenario as this manuscript. The ratio is lower than the observations from many compound screenings because a large number of potential off-targets are not taken into account in the existing target-based screening. It should be noted that the purpose here is to compare the use of imbalanced test data with the use of balanced ones, which is a common practice in most existing studies. Hence, to answer Q4 about label distribution shift, for all experiments the number of not-binding samples in the test set is about five times as large as that of the agonist/antagonist data while training data are balanced for each class. For a comparison, a balanced test set is also evaluated. In general, DeepREAL evaluated by the balanced test set in the IID setting, which represents conventional cross-validations, outperforms that evaluated by the imbalanced data. However, in both protein and chemical OOD settings that simulates a real application, DeepREAL evaluated by the imbalanced data performs the best, as shown in <xref rid="btac154-F2" ref-type="fig">Figures 2</xref> and <xref rid="btac154-F3" ref-type="fig">3</xref>. These observations suggest that the cross-validation in an IID setting is often over-optimistic and DeepREAL is more robust in a realistic application. To see if different imbalanced ratio will affect the result, we performed additional experiments with a ratio of 10:1. As shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4</xref>, the change of ratio will not change the results significantly.</p>
    </sec>
    <sec>
      <title>3.4 DeepREAL significantly outperforms state-of-the-art models</title>
      <p>To compare DeepREAL with the leading machine learning model (RF/protein) (<xref rid="btac154-B29" ref-type="bibr">Sakamuru <italic toggle="yes">et al.</italic>, 2021</xref>) that can only predict Opioid receptor activities as well as an earlier multi-task neural network model (<xref rid="btac154-B34" ref-type="bibr">Wang and Zeng, 2013</xref>). Only Opioid receptors are used in the comparison due to two reasons. First, the baseline models can be only trained using chemicals as input. Second, only Opioid receptors have sufficient large numbers of labeled chemicals for training the baseline model (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>). If we include other proteins, the baseline model may have significant disadvantages.</p>
      <p>Opioid receptor dataset is split in two different ways for IID and OOD experiments as described in the previous section. In both IID and OOD settings, DeepREAL significantly outperforms the baselines in terms of precision and recall, as shown in <xref rid="btac154-F6" ref-type="fig">Figure 6</xref>. Furthermore, the performance drop of DeepREAL from the IID setting to the OOD setting is less significant than that of the baseline. To prove the statistical significance of DeepREAL performance against the RF/protein baseline, the same training is repeated for five times under Opioid context with different random seeds. As shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S5</xref>, the <italic toggle="yes">P</italic>-value of the hypothesis that the two models have the same average ROC-AUC is close to 0.0.</p>
    </sec>
    <sec>
      <title>3.5 Application of DeepREAL to cocaine interacting proteins</title>
      <p>We performed a screening for G-protein coupled receptors (GPCRs) that interact with cocaine and its analogs using trained DeepREAL model. Cocaine target, cocaine analogs and top ranked predictions could be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S2–S4</xref>. 14 cocaine interacting GPCRs were collected from <xref rid="btac154-B9" ref-type="bibr">Fant <italic toggle="yes">et al.</italic> (2019)</xref>. We collected 18 cocaine analogs and made predictions on them paired with the 14 targets. Among 14 proteins that we tested, cocaine or cocaine analogue was predicted as an agonist for glutamate metabotropic receptor 2 (GRM2) and 5-hydroxytryptamine receptor subtype 6 (5-HT6). As supporting evidences, <xref rid="btac154-B39" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> (2017)</xref> have showed that GRM2 deletion decreases sensitivity to cocaine reward in rats. 5-HT6 antagonist blocks cocaine-induced DA release and cocaine self-administration, suggesting cocaine probably is a agonist for 5-HT6 (<xref rid="btac154-B30" ref-type="bibr">Valentini <italic toggle="yes">et al.</italic>, 2013</xref>). Our model also predicted cocaine’s antagonist activity against 5-HT2C, delta-Opioid receptor and Cannabinoid Receptor 2 (CNR2). Injection of the 5-HT2C receptor agonist reduces cocaine self-administration in rats, suggesting cocaine is a potential antagonist for 5-HT2C receptor (<xref rid="btac154-B10" ref-type="bibr">Fletcher <italic toggle="yes">et al.</italic>, 2004</xref>). Similarly, dual kappa-delta Opioid receptor agonist blocks cocaine reward behavior intimating cocaine’s antagonist role for delta Opioid receptor (<xref rid="btac154-B31" ref-type="bibr">Váradi <italic toggle="yes">et al.</italic>, 2015</xref>). Research shows CNR2 agonist dose-dependently inhibits cocaine self-administration, thus indicating cocaine negatively regulates CNR2’s activity (<xref rid="btac154-B36" ref-type="bibr">Xi <italic toggle="yes">et al.</italic>, 2011</xref>). Overall, our predictions are largely consistent with existing experimental evidences.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>This article proposed a deep learning framework DeepREAL that expands the traditional DTI task to predicting ligand-induced receptor activities of dark proteins and novel chemicals under various OOD settings. DeepREAL has several unique features. First, unlike the existing method that requires training one model for one protein and applying the trained model on the same protein, DeepREAL needs only to train only one model to make predictions on any proteins with improved accuracy. Second, DeepREAL has improved generalization power when facing all major types of data distribution shifts during deployment, making it robust in real-world applications. Finally, by utilizing large unlabeled sequence data and rich binary bioassay data, DeepREAL models receptor activities on a multi-scale to alleviate data scarcity problem. Together, DeepREAL significantly outperforms existing algorithms for predicting ligand-induced receptor activities. The novelty of DeepREAL lies in the prediction of receptor activities for dark proteins (Stage 3) using pre-trained protein sequence embedding (Stage 1) and binary DTI embedding (Stage 2). The incorporation of Stages 1 and 2 pre-training is motivated to achieve the OOD generalization in Stage 3. Additionally, the excellent performance of Stage 3 is not solely relying on the pre-training of Stages 1 and 2. The end-to-end model architecture as illustrated in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref> is designed to ensure that knowledge transferred over stages will not be lost and get well utilized. Although DeepREAL was only tested using GPCRs, especially, Opioid receptors due to limited labeled data, it can be extended to other gene families when the ligand-induced receptor activity data are available.</p>
    <p>The performance of DeepREAL can be further improved along several directions. For example, unsupervised pre-training of chemical space could improve DeepREAL’s ability to detect novel chemicals (<xref rid="btac154-B15" ref-type="bibr">Hu <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac154-B22" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2021</xref>). The sequence embedding method DISAE used in this study still has room for improvement. Incorporating structure information into the protein sequence embedding could help the downstream prediction tasks for ligand binding and receptor activity. In addition, it may not perform well for small families similar to AlphaFold2 (<xref rid="btac154-B16" ref-type="bibr">Jumper <italic toggle="yes">et al.</italic>, 2021</xref>). It remains an open question to reliably prediction the structure and function of dark proteins from a small family. It will also interesting to test other state-of-the-art sequence embedding methods such as ESM (<xref rid="btac154-B28" ref-type="bibr">Rives <italic toggle="yes">et al.</italic>, 2021</xref>), ProtBERT (<xref rid="btac154-B8" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic>, 2021</xref>) and TAPE (<xref rid="btac154-B27" ref-type="bibr">Rao <italic toggle="yes">et al.</italic>, 2019</xref>). We only predict two classes of receptor activity: agonist versus antagonist. In fact, the receptor activity is more complex than two mutually exclusive classes. There are other subtle activity classes such as partial agonist. A multi-class model could be a more suitable choice and subject to future studies. In practice, detecting if an unseen case is OOD is an important but challenging problem. Few methods have been developed for protein or chemical data for the OOD detection. It is another direction for future works. Furthermore, there are more scenarios of distribution shift worth study such as compounding protein and chemical distribution shifts with various label distribution shifts for stress testing. In addition to the imbalanced ratio of binding/non-binding cases, the ratio of agonist/antagonist could vary a lot for different proteins and there is no generally known trend which one is more prevalent. This question remains unanswered, and will be addressed in the future.</p>
  </sec>
  <sec>
    <title>Author contributions</title>
    <p>L.X. conceived and planned the experiments. T.C. developed and implemented the algorithm. T.C., K.A.A. and Y.L. carried out the experiments. L.X. and T.C. contributed to the interpretation of the results. T.C., K.A.A., Y.L. and L.X. wrote the manuscript. All authors provided critical feedback and helped shape the research, analysis and manuscript.[AQ: Please note that Author contributions section has been set per journal style.]</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This project was funded with federal funds from the National Institute of General Medical Sciences of National Institute of Health [R01GM122845] and the National Institute on Aging of the National Institute of Health [R01AD057555].</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>All data used are downloaded from Pfam (<xref rid="btac154-B25" ref-type="bibr">Mistry <italic toggle="yes">et al.</italic>, 2020</xref>), GLASS (<xref rid="btac154-B4" ref-type="bibr">Chan <italic toggle="yes">et al.</italic>, 2015</xref>) and IUPHAR/BPS and the state-of-the-art paper (<xref rid="btac154-B29" ref-type="bibr">Sakamuru <italic toggle="yes">et al.</italic>, 2021</xref>). Readers are directed to their official website for original data. Code is available on github <ext-link xlink:href="https://github.com/XieResearchGroup/DeepREAL" ext-link-type="uri">https://github.com/XieResearchGroup/DeepREAL</ext-link>.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac154_Supplementary_Data</label>
      <media xlink:href="btac154_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac154-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Armstrong</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal>; NC-IUPHAR. (<year>2019</year>) <article-title>The IUPHAR/BPS Guide to PHARMACOLOGY in 2020: extending immunopharmacology content and introducing the IUPHAR/MMV Guide to MALARIA PHARMACOLOGY</article-title>. <source>Nucleic Acids Res</source>., <volume>48</volume>, <fpage>D1006</fpage>–<lpage>D1021</lpage>.</mixed-citation>
    </ref>
    <ref id="btac154-B2">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bolton</surname><given-names>E.E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2008</year>) <part-title>PubChem: integrated platform of small molecules and biological activities</part-title>. In: <source>Annual Reports in Computational Chemistry</source>, <volume>Vol. 4</volume>. <publisher-name>Elsevier</publisher-name>, pp. <fpage>217</fpage>–<lpage>241</lpage>.</mixed-citation>
    </ref>
    <ref id="btac154-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cai</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>MSA-regularized protein sequence transformer toward predicting genome-wide chemical-protein interactions: application to GPCRome deorphanization</article-title>. <source>J. Chem. Inf. Model</source>., <volume>61</volume>, <fpage>1570</fpage>–<lpage>1582</lpage>.<pub-id pub-id-type="pmid">33757283</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chan</surname><given-names>W.K.B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>GLASS: a comprehensive database for experimentally validated GPCR-ligand associations</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>3035</fpage>–<lpage>3042</lpage>.<pub-id pub-id-type="pmid">25971743</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>DiMasi</surname><given-names>J.A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Innovation in the pharmaceutical industry: new estimates of R&amp;D costs</article-title>. <source>J. Health Econ</source>., <volume>47</volume>, <fpage>20</fpage>–<lpage>33</lpage>.<pub-id pub-id-type="pmid">26928437</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B6">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Dosovitskiy</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) An image is worth 16×16 words: transformers for image recognition at scale. <italic toggle="yes">arXiv preprint </italic>arXiv:2010.11929.</mixed-citation>
    </ref>
    <ref id="btac154-B7">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>dos Santos</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) Attentive pooling networks. <italic toggle="yes">arXiv preprint arXiv:1602.03609.</italic></mixed-citation>
    </ref>
    <ref id="btac154-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Elnaggar</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) ProtTrans: towards cracking the language of life’s code through self-supervised learning. <italic toggle="yes">bioRxiv</italic>, pages <fpage>2020</fpage>–<lpage>07</lpage>.</mixed-citation>
    </ref>
    <ref id="btac154-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fant</surname><given-names>A.D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Toward reducing hERG affinities for DAT inhibitors with a combined machine learning and molecular modeling approach</article-title>. <source>Biophys. J</source>., <volume>116</volume>, <fpage>562a</fpage>.</mixed-citation>
    </ref>
    <ref id="btac154-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fletcher</surname><given-names>P.J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2004</year>) <article-title>Injection of the 5-HT2C receptor agonist Ro60-0175 into the ventral tegmental area reduces cocaine-induced locomotor activity and cocaine self-administration</article-title>. <source>Neuropsychopharmacology</source>, <volume>29</volume>, <fpage>308</fpage>–<lpage>318</lpage>.<pub-id pub-id-type="pmid">14666118</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B11">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gao</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) Making pre-trained language models better few-shot learners. <italic toggle="yes">arXiv preprint arXiv:2012.15723.</italic></mixed-citation>
    </ref>
    <ref id="btac154-B14">
      <mixed-citation publication-type="other">Goodfellow,I. <italic toggle="yes">et al.</italic> (2016) <italic toggle="yes">Deep Learning.</italic> MIT Press, Cambridge, MA, USA, pp. 237–238.</mixed-citation>
    </ref>
    <ref id="btac154-B12">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Hastie</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <source>Statistical Learning with Sparsity: The Lasso and Generalizations</source>. <publisher-name>Chapman and Hall/CRC, Boca Raton, FL, USA</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btac154-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) Deep residual learning for image recognition. In: <italic toggle="yes">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</italic>, Las Vegas, NV, USA. pp. <fpage>770</fpage>–<lpage>778</lpage>.</mixed-citation>
    </ref>
    <ref id="btac154-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Hu</surname><given-names>W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) Strategies for pre-training graph neural networks. <italic toggle="yes">arXiv preprint arXiv:1905.12265.</italic></mixed-citation>
    </ref>
    <ref id="btac154-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jumper</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Highly accurate protein structure prediction with alphafold</article-title>. <source>Nature</source>, <volume>596</volume>, <fpage>583</fpage>–<lpage>511</lpage>.<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Karimi</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>DeepAffinity: interpretable deep learning of compound–protein affinity through unified recurrent and convolutional neural networks</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>3329</fpage>–<lpage>3338</lpage>.<pub-id pub-id-type="pmid">30768156</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B18">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>D.P.</given-names></string-name>, <string-name><surname>Ba</surname><given-names>J.</given-names></string-name></person-group> (<year>2014</year>) Adam: a method for stochastic optimization. <italic toggle="yes">arXiv preprint arXiv:1412.6980.</italic></mixed-citation>
    </ref>
    <ref id="btac154-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lan</surname><given-names>Z.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) ALBERT: A Lite BERT for self-supervised learning of language representations. <italic toggle="yes">arXiv preprint arXiv:1909.11942.</italic></mixed-citation>
    </ref>
    <ref id="btac154-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lim</surname><given-names>H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Large-scale off-target identification using fast and accurate dual regularized one-class collaborative filtering and its application to drug repurposing</article-title>. <source>PLoS Comput. Biol</source>., <volume>12</volume>, <fpage>e1005135</fpage>.<pub-id pub-id-type="pmid">27716836</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Off-target toxicity is a common mechanism of action of cancer drugs undergoing clinical trials</article-title>. <source>Sci. Transl. Med</source>., <volume>11</volume>, <fpage>eaaw8412</fpage>.<pub-id pub-id-type="pmid">31511426</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>COVID-19 multi-targeted drug repurposing using few-shot learning</article-title>. <source>Front. Bioinf</source>., <volume>1</volume>, <fpage>18</fpage>.</mixed-citation>
    </ref>
    <ref id="btac154-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luxburg</surname><given-names>U.V.</given-names></string-name></person-group> (<year>2007</year>) A Tutorial on Spectral Clustering. <italic toggle="yes">Stat. Comput.,</italic><volume>17</volume>, <fpage>395</fpage>–<lpage>416</lpage>.</mixed-citation>
    </ref>
    <ref id="btac154-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lynch</surname><given-names>I.I.I.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Potential functional and pathological side effects related to off-target pharmacological activity</article-title>. <source>J. Pharmacol. Toxicol. Methods</source>, <volume>87</volume>, <fpage>108</fpage>–<lpage>126</lpage>.<pub-id pub-id-type="pmid">28216264</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mistry</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Pfam: the protein families database in 2021</article-title>. <source>Nucleic Acids Res</source>., <volume>49</volume>, <fpage>D412</fpage>–<lpage>D419</lpage>.</mixed-citation>
    </ref>
    <ref id="btac154-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oprea</surname><given-names>T.I.</given-names></string-name></person-group> (<year>2019</year>) <article-title>Exploring the dark genome: implications for precision medicine</article-title>. <source>Mamm. Genome</source>, <volume>30</volume>, <fpage>192</fpage>–<lpage>200</lpage>.<pub-id pub-id-type="pmid">31270560</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rao</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Evaluating protein transfer learning with tape</article-title>. <source>Adv. Neural Inf. Process. Syst</source>., <volume>32</volume>, <fpage>9689</fpage>–<lpage>9701</lpage>.<pub-id pub-id-type="pmid">33390682</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rives</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>118</volume>, <fpage>e2016239118</fpage>.<pub-id pub-id-type="pmid">33876751</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sakamuru</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Predictive models to identify small molecule activators and inhibitors of opioid receptors</article-title>. <source>J. Chem. Inf. Model</source>., <volume>61</volume>, <fpage>2675</fpage>–<lpage>2685</lpage>. [CrossRef<italic toggle="yes">]</italic>[<italic toggle="yes">10.1021/acs.jcim.1c00439]</italic><pub-id pub-id-type="pmid">34047186</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Valentini</surname><given-names>V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>Evidence for a role of a dopamine/5-HT6 receptor interaction in cocaine reinforcement</article-title>. <source>Neuropharmacology</source>, <volume>65</volume>, <fpage>58</fpage>–<lpage>64</lpage>.<pub-id pub-id-type="pmid">22982249</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Váradi</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>Synthesis and characterization of a dual kappa-delta opioid receptor agonist analgesic blocking cocaine reward behavior</article-title>. <source>ACS Chem. Neurosci</source>., <volume>6</volume>, <fpage>1813</fpage>–<lpage>1824</lpage>.<pub-id pub-id-type="pmid">26325040</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B32">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Vaswani</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) Attention is all you need. In: <italic toggle="yes">31th</italic> <italic toggle="yes">Advances in Neural Information Processing Systems</italic>, Long Beach, CA, USA. pp. <fpage>5998</fpage>–<lpage>6008</lpage>.</mixed-citation>
    </ref>
    <ref id="btac154-B33">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wan</surname><given-names>F.</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>J.M.</given-names></string-name></person-group> (<year>2016</year>) Deep learning with feature embedding for compound–protein interaction prediction. <italic toggle="yes">bioRxiv</italic>, 086033.</mixed-citation>
    </ref>
    <ref id="btac154-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>J.</given-names></string-name></person-group> (<year>2013</year>) <article-title>Predicting drug–target interactions using restricted Boltzmann machines</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>i126</fpage>–<lpage>i134</lpage>.<pub-id pub-id-type="pmid">23812976</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wong</surname><given-names>C.H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Estimation of clinical trial success rates and related parameters</article-title>. <source>Biostatistics</source>, <volume>20</volume>, <fpage>273</fpage>–<lpage>286</lpage>.<pub-id pub-id-type="pmid">29394327</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xi</surname><given-names>Z.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) <article-title>Brain cannabinoid CB2 receptors modulate cocaine’s actions in mice</article-title>. <source>Nat. Neurosci</source>., <volume>14</volume>, <fpage>1160</fpage>–<lpage>1166</lpage>.<pub-id pub-id-type="pmid">21785434</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xie</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) <article-title>Novel computational approaches to polypharmacology as a means to define responses to individual drugs</article-title>. <source>Annu. Rev. Pharmacol. Toxicol</source>., <volume>52</volume>, <fpage>361</fpage>–<lpage>379</lpage>.<pub-id pub-id-type="pmid">22017683</pub-id></mixed-citation>
    </ref>
    <ref id="btac154-B38">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) How powerful are graph neural networks? <italic toggle="yes">arXiv preprint arXiv:1810.00826.</italic></mixed-citation>
    </ref>
    <ref id="btac154-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Deletion of type 2 metabotropic glutamate receptor decreases sensitivity to cocaine reward in rats</article-title>. <source>Cell Rep</source>., <volume>20</volume>, <fpage>319</fpage>–<lpage>332</lpage>.<pub-id pub-id-type="pmid">28700935</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
