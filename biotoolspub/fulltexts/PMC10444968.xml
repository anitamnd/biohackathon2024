<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10444968</article-id>
    <article-id pub-id-type="pmid">37535685</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btad468</article-id>
    <article-id pub-id-type="publisher-id">btad468</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>BERTrand—peptide:TCR binding prediction using Bidirectional Encoder Representations from Transformers augmented with random TCR pairing</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6404-270X</contrib-id>
        <name>
          <surname>Myronov</surname>
          <given-names>Alexander</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/conceptualization" degree-contribution="equal">Conceptualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="http://credit.niso.org/contributor-roles/data-curation" degree-contribution="lead">Data curation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="http://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="equal">Formal analysis</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="http://credit.niso.org/contributor-roles/investigation" degree-contribution="equal">Investigation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="http://credit.niso.org/contributor-roles/methodology" degree-contribution="equal">Methodology</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Software" vocab-term-identifier="http://credit.niso.org/contributor-roles/software" degree-contribution="lead">Software</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Validation" vocab-term-identifier="http://credit.niso.org/contributor-roles/validation" degree-contribution="lead">Validation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/visualization" degree-contribution="lead">Visualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="equal">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &amp; editing</role>
        <aff><institution>Faculty of Mathematics and Information Science, Warsaw University of Technology</institution>, Warsaw, <country country="PL">Poland</country></aff>
        <aff><institution>Ardigen</institution>, Krakow, <country country="PL">Poland</country></aff>
        <xref rid="btad468-cor1" ref-type="corresp"/>
        <!--alexander.myronov@gmail.com-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mazzocco</surname>
          <given-names>Giovanni</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/conceptualization" degree-contribution="equal">Conceptualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="http://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="equal">Formal analysis</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Funding acquisition" vocab-term-identifier="http://credit.niso.org/contributor-roles/funding-acquisition" degree-contribution="equal">Funding acquisition</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="http://credit.niso.org/contributor-roles/investigation" degree-contribution="equal">Investigation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="http://credit.niso.org/contributor-roles/methodology" degree-contribution="equal">Methodology</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Project administration" vocab-term-identifier="http://credit.niso.org/contributor-roles/project-administration" degree-contribution="equal">Project administration</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Resources" vocab-term-identifier="http://credit.niso.org/contributor-roles/resources" degree-contribution="equal">Resources</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Supervision" vocab-term-identifier="http://credit.niso.org/contributor-roles/supervision" degree-contribution="equal">Supervision</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="equal">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &amp; editing</role>
        <aff><institution>Ardigen</institution>, Krakow, <country country="PL">Poland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Król</surname>
          <given-names>Paulina</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="http://credit.niso.org/contributor-roles/data-curation" degree-contribution="equal">Data curation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Software" vocab-term-identifier="http://credit.niso.org/contributor-roles/software" degree-contribution="supporting">Software</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Validation" vocab-term-identifier="http://credit.niso.org/contributor-roles/validation" degree-contribution="equal">Validation</role>
        <aff><institution>Ardigen</institution>, Krakow, <country country="PL">Poland</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3840-7610</contrib-id>
        <name>
          <surname>Plewczynski</surname>
          <given-names>Dariusz</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/conceptualization" degree-contribution="equal">Conceptualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="http://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="equal">Formal analysis</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Funding acquisition" vocab-term-identifier="http://credit.niso.org/contributor-roles/funding-acquisition" degree-contribution="equal">Funding acquisition</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="http://credit.niso.org/contributor-roles/investigation" degree-contribution="equal">Investigation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="http://credit.niso.org/contributor-roles/methodology" degree-contribution="equal">Methodology</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Project administration" vocab-term-identifier="http://credit.niso.org/contributor-roles/project-administration" degree-contribution="equal">Project administration</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Resources" vocab-term-identifier="http://credit.niso.org/contributor-roles/resources" degree-contribution="equal">Resources</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Supervision" vocab-term-identifier="http://credit.niso.org/contributor-roles/supervision" degree-contribution="equal">Supervision</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="equal">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &amp; editing</role>
        <aff><institution>Faculty of Mathematics and Information Science, Warsaw University of Technology</institution>, Warsaw, <country country="PL">Poland</country></aff>
        <xref rid="btad468-cor1" ref-type="corresp"/>
        <!--dariusz.plewczynski@pw.edu.pl-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btad468-cor1">Corresponding authors. Faculty of Mathematics and Information Science, Warsaw University of Technology, Koszykowa 75, Warsaw 00-662, Poland. E-mails: <email>alexander.myronov@gmail.com</email> (A.M.) and <email>dariusz.plewczynski@pw.edu.pl</email> (D.P.)</corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-08-03">
      <day>03</day>
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>03</day>
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <volume>39</volume>
    <issue>8</issue>
    <elocation-id>btad468</elocation-id>
    <history>
      <date date-type="received">
        <day>04</day>
        <month>1</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>28</day>
        <month>6</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>27</day>
        <month>7</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>01</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>22</day>
        <month>8</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btad468.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>The advent of T-cell receptor (TCR) sequencing experiments allowed for a significant increase in the amount of peptide:TCR binding data available and a number of machine-learning models appeared in recent years. High-quality prediction models for a fixed epitope sequence are feasible, provided enough known binding TCR sequences are available. However, their performance drops significantly for previously unseen peptides.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We prepare the dataset of known peptide:TCR binders and augment it with negative decoys created using healthy donors’ T-cell repertoires. We employ deep learning methods commonly applied in Natural Language Processing to train part a peptide:TCR binding model with a degree of cross-peptide generalization (0.69 AUROC). We demonstrate that BERTrand outperforms the published methods when evaluated on peptide sequences not used during model training.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The datasets and the code for model training are available at <ext-link xlink:href="https://github.com/SFGLab/bertrand" ext-link-type="uri">https://github.com/SFGLab/bertrand</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Polish Ministry of Education and the research</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Polish Ministry of Science and Higher Education</institution>
          </institution-wrap>
        </funding-source>
        <award-id>7054/IA/SP/2020</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Cytotoxic T-cells play a major role in adaptive immune response in humans. Intracellular proteins are degraded by proteasome into peptides. The antigen processing machinery of the cell allows the presentation of peptides on the cell surface using Major Histocompatibility Complexes (MHC). The focus of this work is MHC class I, which typically presents a peptide of 8–11 amino acids long. These peptide-MHC (pMHC) complexes in turn can be recognized and engaged by CD8+ cytotoxic T-cells. Due to negative selection in the thymus and the high degree diversity of the T-cell receptor (TCR) repertoire, T-cells are capable of recognizing a variety of foreign and mutated epitopes (<xref rid="btad468-B34" ref-type="bibr">Rudolph <italic toggle="yes">et al.</italic> 2006</xref>).</p>
    <p>The binding properties of a TCR to a given pMHC is regulated by hypervariable Complementarity Determining Regions (CDRs). For the <italic toggle="yes">α</italic> and <italic toggle="yes">β</italic> chains of the TCR, three such regions exist. The CDR1 and CDR2 of both <italic toggle="yes">α</italic> and <italic toggle="yes">β</italic> chains mostly interact with the MHC complex, while CDR3 is predominantly interacting with the peptide. The CDR3 region is the most variable region of the TCR and is thought to be the major factor in determining the binding preference of the TCR toward its conjugated pMHC (<xref rid="btad468-B21" ref-type="bibr">La Gruta <italic toggle="yes">et al.</italic> 2018</xref>). While both <italic toggle="yes">α</italic> and <italic toggle="yes">β</italic> chains contribute to the interaction, some studies suggest that the <italic toggle="yes">β</italic> chain plays a more important role in antigen recognition (<xref rid="btad468-B37" ref-type="bibr">Sidhom <italic toggle="yes">et al.</italic> 2021</xref>) and is significantly more prevalent in the data. It should be noted that many researchers—<xref rid="btad468-B6" ref-type="bibr">Dash <italic toggle="yes">et al.</italic> (2017)</xref> and <xref rid="btad468-B28" ref-type="bibr">Montemurro <italic toggle="yes">et al.</italic> (2021)</xref>—have demonstrated the importance of the <italic toggle="yes">α</italic> chain of the TCR in antigen recognition. However, this work implies the use of machine learning (ML) to infer the interaction between TCRs and pMHC complexes, so it can benefit from a high number of observations. In the data we collected, only 18% of the observations have the CDR3<italic toggle="yes">α</italic> annotation. Thus, we will be focusing solely on the sequence of the CDR3<italic toggle="yes">β</italic> part of the TCR, which is readily available in multiple datasets. This is the approach also adopted by <xref rid="btad468-B42" ref-type="bibr">Weber <italic toggle="yes">et al.</italic> (2021)</xref> and <xref rid="btad468-B22" ref-type="bibr">Lu <italic toggle="yes">et al.</italic> (2021)</xref>.</p>
    <p>The MHC is not able to present each and every peptide. Thanks to a high amount of pMHC binding data as well as peptide presentation data from mass spectrometry experiments, researchers were able to produce high accuracy models of pMHC binding and presentation. However, even if the peptide is presented on the surface of the cell, it is still unlikely to be immunogenic. The study by <xref rid="btad468-B30" ref-type="bibr">Parkhurst <italic toggle="yes">et al.</italic> (2019)</xref> of peptide T-cell immunogenicity for 75 cancer patients has been able to find only 57 CD8+ positive mutations along with over 8000 non-immunogenic ones, which account for &lt;1%. One of the frontiers of computational immunology research currently is peptide:TCR binding prediction, which represents a key component for understanding T-cell activation. The amount of data for peptide:TCR binding prediction has been growing in recent years, with the popularization of pMHC dextramer production, single-cell TCR sequencing, and TCR barcoding. In this work, we compile a collection of peptide:TCR sequence data from a number of databases and publications into a single curated dataset of known TCR binders with their cognate epitope sequences. We augment the dataset with negative decoy examples generated from reference T-cell repertoires.</p>
    <p>The growing amount of data on peptide:TCR specificity allowed for the creation of many computational tools that facilitate peptide:TCR binding prediction. These tools can be broadly categorized into three groups. The first group of methods uses the similarity between TCRs to produce clusters and determine their peptide specificity. GLIPH (<xref rid="btad468-B16" ref-type="bibr">Glanville <italic toggle="yes">et al.</italic> 2017</xref>) and TCRdist (<xref rid="btad468-B6" ref-type="bibr">Dash <italic toggle="yes">et al.</italic> 2017</xref>) have demonstrated that for a given epitope sequence, TCR binding can be predicted accurately using distance-based methods. The second group of methods involves the training of peptide-specific TCR binding models—DeepTCR (<xref rid="btad468-B37" ref-type="bibr">Sidhom <italic toggle="yes">et al.</italic> 2021</xref>), TCRex (<xref rid="btad468-B15" ref-type="bibr">Gielis <italic toggle="yes">et al.</italic> 2019</xref>), and TCRGP (<xref rid="btad468-B19" ref-type="bibr">Jokinen <italic toggle="yes">et al.</italic> 2021</xref>). These algorithms often work remarkably well for known peptides but are unable to predict binding for unseen peptides. The third group of methods are the methods that allow prediction for unseen peptides—NetTCR2.0 (<xref rid="btad468-B28" ref-type="bibr">Montemurro <italic toggle="yes">et al.</italic> 2021</xref>), ERGO (<xref rid="btad468-B39" ref-type="bibr">Springer <italic toggle="yes">et al.</italic> 2020</xref>), pMTnet (<xref rid="btad468-B22" ref-type="bibr">Lu <italic toggle="yes">et al.</italic> 2021</xref>), DLpTCR (<xref rid="btad468-B44" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> 2021</xref>), TITAN (<xref rid="btad468-B42" ref-type="bibr">Weber <italic toggle="yes">et al.</italic> 2021</xref>), and PanPEP (<xref rid="btad468-B13" ref-type="bibr">Gao <italic toggle="yes">et al.</italic> 2023</xref>). The goal of this research is to provide immunologists with better tools for <italic toggle="yes">in silico</italic> TCR therapy design. As most of the peptides in the published data originate from viruses, peptide-centric models from the second group have limited applicability for cancer neoantigens or tumor-associated antigens. The focus of this work is thus the peptide:TCR pairing task, specifically the case when the model has not previously seen neither the peptide nor the TCR. We believe that high accuracy for this task would bring the most benefit for potential users.</p>
    <p>Recent breakthroughs in Natural Language Processing (NLP), such as TAPE (<xref rid="btad468-B33" ref-type="bibr">Rao <italic toggle="yes">et al.</italic> 2019</xref>) and DNABERT (<xref rid="btad468-B18" ref-type="bibr">Ji <italic toggle="yes">et al.</italic> 2021</xref>), have prompted many researchers to apply Transformer architectures to solve sequence-based biological problems, such as transcription factors prediction, protein–protein interaction prediction, and binding pockets prediction to name a few. One useful feature of models from the NLP domain is the ability to process variable-length sequences of symbols from a fixed alphabet. Another important aspect is the ability to benefit from unsupervised pre-training, which is often an option in bioinformatics. Researchers usually pre-train the language model on large sequence databases, such as UniPROT. In this work, we construct a pre-training set for the peptide:TCR model, which comprises a hypothetical human peptide:TCR repertoire, based on peptides from MHC-I mass spectrometry peptide presentation experiments and TCRs from healthy donors. After pre-training our model is fine-tuned to predict peptide:TCR binding and was shown to outperform the existing methods in cross-peptide generalization task.</p>
    <p>The overall flow of the analysis is demonstrated in <xref rid="btad468-F1" ref-type="fig">Fig. 1</xref>. In the left part of the figure, we show the process of the NLP model pre-training. Reference TCR sequences from healthy donors are paired randomly with the presented peptides to produce a hypothetical peptide:TCR repertoire, which is then used to perform masked language modeling (MLM) pre-training of the Bidirectional Encoder Representations from Transformers (BERT) neural network. In the right part of the figure, the process of generating negative decoy observations is illustrated. Negative decoys are also based on reference TCRs. A ML model is used to remove outliers, and then the remaining reference TCRs are clustered together with binding TCRs. TCR sequences that are too similar to any binding TCR are removed, and the rest of the reference TCR clusters are randomly paired with peptides from the binding peptide:TCR set. Pre-trained BERT network is then trained to predict peptide:TCR binding.</p>
    <fig position="float" id="btad468-F1">
      <label>Figure 1.</label>
      <caption>
        <p>Flow diagram of the analysis. The left part illustrates the creation of the hypothetical peptide:TCR repertoire and MLM pre-training. The right part shows the process of negative decoys generation and various filtering steps leading to it. These two paths converge on BERT supervised training for peptide:TCR binding prediction</p>
      </caption>
      <graphic xlink:href="btad468f1" position="float"/>
    </fig>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Data</title>
      <sec>
        <title>2.1.1 Data curation</title>
        <p>Our data curation process is shown in <xref rid="btad468-F2" ref-type="fig">Fig. 2</xref>. We collected data containing the amino acid sequences of binding peptide:TCR pairs from a number of databases and publications (<xref rid="btad468-T1" ref-type="table">Table 1</xref>). We narrowed down the dataset to human CD8+ T-cells for peptides of 8–11 amino acids long. We only considered CDR3<italic toggle="yes">β</italic> observations, as CDR3<italic toggle="yes">α</italic> annotations are available for only 18% of the data (&lt;6k observations). Over 99% of the CDR3<italic toggle="yes">β</italic> sequences have a length between 10 and 20 amino acids. Another filtering criterion was the requirement of having specific amino acids in the first and last anchor positions in CDR3<italic toggle="yes">β</italic> chains, cysteine (C) and phenylalanine (F), respectively. This way, we compiled 33k unique CDR3<italic toggle="yes">β</italic> sequences of T-cells binding with a total of 401 epitope sequences. To compensate for the lack of negative examples, we generated negative decoy observations in a 3-to-1 ratio, using a dataset of reference T-cell repertoires from healthy donors (<xref rid="btad468-B29" ref-type="bibr">Oakes <italic toggle="yes">et al.</italic> 2017</xref>) and paired it randomly with peptides from the binders dataset.</p>
        <fig position="float" id="btad468-F2">
          <label>Figure 2.</label>
          <caption>
            <p>Data curation process. (A) Binding peptide:TCR observations. (B) Reference TCRs for decoy generation. (C) Reference TCRs filtering illustrated</p>
          </caption>
          <graphic xlink:href="btad468f2" position="float"/>
        </fig>
        <table-wrap position="float" id="btad468-T1">
          <label>Table 1.</label>
          <caption>
            <p>Summary of the binding peptide:TCR dataset.<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref></p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Dataset</th>
                <th style="text-align: center;" rowspan="1" colspan="1">Number of observations</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">VDJdb (<xref rid="btad468-B36" ref-type="bibr">Shugay <italic toggle="yes">et al.</italic> 2018</xref>)</td>
                <td align="center" rowspan="1" colspan="1">15 751</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">McPAS (<xref rid="btad468-B41" ref-type="bibr">Tickotsky <italic toggle="yes">et al.</italic> 2017</xref>)</td>
                <td align="center" rowspan="1" colspan="1">8482</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B31" ref-type="bibr">Pogorelyy <italic toggle="yes">et al.</italic> (2018)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">5861</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">TBAdb (<xref rid="btad468-B46" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2020</xref>)</td>
                <td align="center" rowspan="1" colspan="1">5852</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">10x Genomics (<xref rid="btad468-B4" ref-type="bibr">Boutet <italic toggle="yes">et al.</italic> 2019</xref>, <xref rid="btad468-B47" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2021</xref>)</td>
                <td align="center" rowspan="1" colspan="1">3813</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B45" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> (2018)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">1093</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B17" ref-type="bibr">Huth <italic toggle="yes">et al.</italic> (2019)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">1039</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B10" ref-type="bibr">Emerson <italic toggle="yes">et al.</italic> (2017)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">803</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B1" ref-type="bibr">Abdel-Hakeem <italic toggle="yes">et al.</italic> (2017)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">324</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B5" ref-type="bibr">Britanova <italic toggle="yes">et al.</italic> (2016)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">260</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B20" ref-type="bibr">Kamga <italic toggle="yes">et al.</italic> (2019)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">217</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B14" ref-type="bibr">Gee <italic toggle="yes">et al.</italic> (2018)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">33</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B40" ref-type="bibr">Takeda <italic toggle="yes">et al.</italic> (2018)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">20</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B38" ref-type="bibr">Soon <italic toggle="yes">et al.</italic> (2019)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">6</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B24" ref-type="bibr">Malekzadeh <italic toggle="yes">et al.</italic> (2019)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">4</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Total</td>
                <td align="center" rowspan="1" colspan="1">43 558</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Unique</td>
                <td align="center" rowspan="1" colspan="1">32 523</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <label>a</label>
              <p>The number of observations is reported after filtering. The curated set of unique peptide:TCR binders is later used to train the model.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <table-wrap position="float" id="btad468-T2">
          <label>Table 2.</label>
          <caption>
            <p>The overview of potential biases that a ML algorithm for peptide:TCR prediction can exploit.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Bias</th>
                <th style="text-align: center;" rowspan="1" colspan="1">Mismatch pairing</th>
                <th style="text-align: center;" rowspan="1" colspan="1">Reference pairing</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">Under-representation of peptides in the dataset</td>
                <td align="center" rowspan="1" colspan="1">Yes</td>
                <td align="center" rowspan="1" colspan="1">Yes, but it is mitigated by pre-training to some extent</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Under-representation of TCRs in the dataset</td>
                <td align="center" rowspan="1" colspan="1">Yes</td>
                <td align="center" rowspan="1" colspan="1">No, because additional TCR sequences are used</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Potential false negatives</td>
                <td align="center" rowspan="1" colspan="1">Yes</td>
                <td align="center" rowspan="1" colspan="1">Yes</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Out-of-distribution easy negative decoys</td>
                <td align="center" rowspan="1" colspan="1">No</td>
                <td align="center" rowspan="1" colspan="1">Yes, but they can be filtered to some extent</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Too homogeneous negative decoys</td>
                <td align="center" rowspan="1" colspan="1">Yes</td>
                <td align="center" rowspan="1" colspan="1">No</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Correlated observations in train and test sets</td>
                <td align="center" rowspan="1" colspan="1">Yes, because mismatch pairing introduces additional dependencies</td>
                <td align="center" rowspan="1" colspan="1">No, peptide and TCR clusters are used for decoy generation and cross-validation</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>Cluster analysis of the peptides was done using hierarchical clustering with Levenshtein distance and single linkage. It revealed that a number of similar epitope sequences are present, differing by three amino acids at most. For example, MART-1 human melanoma-related antigen (ELAGIGILTV) was extensively studied with minor modifications: EAAGIGILTV, LLLGIGILV, ELAGIGLTV, AAGIGILTV, and ALGIGILTV. We argue that using such similar observations in the training and validation set may bias any model trained on peptide sequences and could introduce unwanted overfitting (if the TCR repertoires of two similar peptides are also similar), or unwanted underfitting if the repertoires are too different. Our analysis revealed 261 peptide clusters with a minimum Levenshtein distance of three. Peptide clusters were used as groups during cross-validation.</p>
      </sec>
      <sec>
        <title>2.1.2 Sources of overfitting</title>
        <p>Training a ML model on a limited set of data (i.e. positive peptide:TCR pairs for 400 peptides only) and with a lack of negative examples forces us to create negative decoy observations, which may easily introduce some bias that an ML model could easily exploit. Randomly pairing peptides and TCRs to create negative decoys is certainly a viable approach for this problem. TCRs are highly cross-reactive and are estimated to bind 10<sup>6</sup> multiple epitope sequences (<xref rid="btad468-B25" ref-type="bibr">Mason, 1998</xref>), hence a TCR could potentially bind some other peptide. However, TCRs are also highly specific, as the probability of a specific TCR binding a randomly chosen peptide is estimated to be <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref rid="btad468-B12" ref-type="bibr">Frank, 2020</xref>), which is acceptable for a ML approach. Besides possible false negative observations produced by random pairing and biases that may arise from experimental conditions, we have identified a handful of potential problems for a training setup with negative decoys (see <xref rid="btad468-T2" ref-type="table">Table 2</xref>).</p>
      </sec>
      <sec>
        <title>2.1.3 Mismatch pairing</title>
        <p>Mismatch pairing is an approach used in <xref rid="btad468-B28" ref-type="bibr">Montemurro <italic toggle="yes">et al.</italic> (2021)</xref> and <xref rid="btad468-B39" ref-type="bibr">Springer <italic toggle="yes">et al.</italic> (2020)</xref> to create negative decoy observations by randomly pairing a peptide with a TCRs from a different peptide:TCR pair. Mismatch pairing approach guarantees that the TCR distribution of the negatives will match the positive one. The number of different TCRs in a human body is estimated to be around <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mn>8</mml:mn></mml:msup></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref rid="btad468-B32" ref-type="bibr">Qi <italic toggle="yes">et al.</italic> 2014</xref>, <xref rid="btad468-B23" ref-type="bibr">Lythe <italic toggle="yes">et al.</italic> 2016</xref>), and the number of MHC-I-presented peptides on human cells is around 10<sup>4</sup> (<xref rid="btad468-B26" ref-type="bibr">Mester <italic toggle="yes">et al.</italic> 2011</xref>), thus mismatch pairing is largely under-representing both peptides and TCRs. Moreover, due to publication bias, different potential immunogenicity of viral and cancer peptides in humans, the distribution of T-cell clonotype size in humans (<xref rid="btad468-B3" ref-type="bibr">Bolkhovskaya <italic toggle="yes">et al.</italic> 2014</xref>) and other factors, the number of unique TCR observations per peptide has a power-law decay distribution (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>). In practice, this means that random peptide:TCR pairing will produce negative decoys, where over 61% of TCR sequences come from the five most popular peptides in the dataset. The repertoires of these peptides are too homogeneous and a model might learn to identify those as negatives. Mismatch pairing also produces correlated observations, thus during cross-validation there would be a considerable amount of examples in the training set sharing peptide or TCR sequence with pairs in the test set. These recurring peptides and TCRs may be exploited by the model if not removed. Deep learning models have a tendency to “remember” training data, so correlated observations in the training and test sets should be avoided to ensure test set independence.</p>
      </sec>
      <sec>
        <title>2.1.4 Reference pairing</title>
        <p>Our approach to negative decoys generation was designed to overcome some of the aforementioned biases. We collected around 560k TCR CDR3<italic toggle="yes">β</italic> sequences from repertoires of three healthy donors from <xref rid="btad468-B29" ref-type="bibr">Oakes <italic toggle="yes">et al.</italic> (2017)</xref> and randomly paired them with peptides from the binding dataset CDR3<italic toggle="yes">β</italic> sequences. The study by <xref rid="btad468-B29" ref-type="bibr">Oakes <italic toggle="yes">et al.</italic> (2017)</xref> was used for reference pairing instead of <xref rid="btad468-B7" ref-type="bibr">Dean <italic toggle="yes">et al.</italic> (2015)</xref> due to the improved sequencing protocol that captured the rare clones in the TCR distribution, allowing for a more biologically plausible CDR3<italic toggle="yes">β</italic> sequence space, and the availability of the T-cell type annotation. We used only the CD8+ T-cells from the patients’ repertoires, which matches the MHC class I peptides in the binders’ dataset. Reference TCRs represent a much larger region of the TCR theoretical distribution compared to binding TCRs, although both TCRs and peptides remain still under-represented. Reference TCRs obtained through a different kind of TCR sequencing experiment might introduce CDR3<italic toggle="yes">β</italic> sequences that are out-of-distribution relative to the binding TCRs and thus might be easy targets for a neural network. To address this issue, we filtered the sequences using a ML-based approach, see Outliers filtering section in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> for a detailed description.</p>
        <p>To avoid correlated observations, we performed TCR clustering analysis of the binding TCR sequences together with reference TCRs: hierarchical clustering was used with Levenshtein distance and complete linkage with distance cut-off equal to three. Clustering naturally produced three types of clusters:</p>
        <list list-type="order">
          <list-item>
            <p>clusters with only TCRs from binding peptide:TCR pairs</p>
          </list-item>
          <list-item>
            <p>mixed clusters positive and reference TCRs</p>
          </list-item>
          <list-item>
            <p>clusters with only reference TCRs.</p>
          </list-item>
        </list>
        <p>During decoy generation, we rejected reference TCRs from mixed clusters, as they have a much higher probability of being false negatives, because their sequences are very similar to those of the binding TCRs. TCRs from reference-only clusters were randomly paired with a single peptide from the pool of 401 available peptides in the binding dataset in a 3-to-1 ratio to the number of positive observations for a given peptide. In a cluster of reference TCRs, every TCR is paired with the same peptide, which limits the generation of positive and negative observations with the same peptide sequence and very similar TCR sequences. Such observations would in fact be quite useless, as they should be filtered from the training set if they appear in the test set during cross-validation, otherwise the model would be biased toward predicting the negative class. As the decoy generation is random, the dataset was replicated three times for different seeds. TCR clusters were also used as groups during cross-validation.</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Model</title>
      <p>For this problem, we applied the BERT artificial neural network (<xref rid="btad468-B8" ref-type="bibr">Devlin <italic toggle="yes">et al.</italic> 2019</xref>) from “transformers” python package (<xref rid="btad468-B43" ref-type="bibr">Wolf <italic toggle="yes">et al.</italic> 2019</xref>). The model was initially pre-trained to perform a MLM task on a hypothetical TCR repertoire and then fine-tuned for actual peptide:TCR classification.</p>
      <sec>
        <title>2.2.1 Model architecture</title>
        <p>The architecture of BERT is illustrated in <xref rid="btad468-F3" ref-type="fig">Fig. 3</xref>. Initially, peptides and TCRs need to be represented as a sequence of tokens. The token vocabulary consists of 20 amino acids and 5 additional special tokens: CLS is used to indicate the starting position of the sequence, SEP to indicate the end of the sequence, MASK for MLM, PAD for padding, and UNK for non-standard amino acids. Each peptide and TCR are concatenated into a single sequence of tokens with an additional CLS token at the beginning and two SEP tokens between sequences and at the end of the sequence. The sequence IDs indicating the absolute position of the token and the token type IDs, indicating whether a token belongs to the peptide or to the TCR, are generated as well. Token, position and type IDs are embedded and added creating the sequence of input embeddings for each token. The input is then passed to a BERT network with eight transformer blocks. BERT produces an output embedding for each token, which later on is passed to either a token classification head and to a sequence classification head during pre-training and fine-tuning, respectively. Below is the description of the BERT embedding procedure.
</p>
        <disp-formula id="E1">
          <mml:math id="M1" display="block" overflow="scroll">
            <mml:mtable>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mo>[</mml:mo>
                  <mml:mtext>CLS</mml:mtext>
                  <mml:mo>]</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="italic">tokenize</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mtext>Peptide</mml:mtext>
                  <mml:mo>)</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>[</mml:mo>
                  <mml:mtext>SEP</mml:mtext>
                  <mml:mo>]</mml:mo>
                  <mml:mo>+</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="italic">tokenize</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mtext>CDR</mml:mtext>
                  <mml:mn>3</mml:mn>
                  <mml:mo>β</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>[</mml:mo>
                  <mml:mtext>SEP</mml:mtext>
                  <mml:mo>]</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>position</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mo>[</mml:mo>
                  <mml:mn>1</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mn>2</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mn>3</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mo>…</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mi mathvariant="italic">length</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mtext>Peptide</mml:mtext>
                  <mml:mo>)</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="italic">length</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mtext>CDR</mml:mtext>
                  <mml:mn>3</mml:mn>
                  <mml:mo>β</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mn>3</mml:mn>
                  <mml:mo>]</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>type</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mo>[</mml:mo>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:munder>
                        <mml:mrow>
                          <mml:mrow>
                            <mml:munder>
                              <mml:mrow>
                                <mml:mn>1</mml:mn>
                                <mml:mo>,</mml:mo>
                                <mml:mn>1</mml:mn>
                                <mml:mo>,</mml:mo>
                                <mml:mn>1</mml:mn>
                                <mml:mo>,</mml:mo>
                                <mml:mo>…</mml:mo>
                                <mml:mo>,</mml:mo>
                                <mml:mn>1</mml:mn>
                              </mml:mrow>
                              <mml:mo>︸</mml:mo>
                            </mml:munder>
                          </mml:mrow>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi mathvariant="italic">length</mml:mi>
                          <mml:mo>(</mml:mo>
                          <mml:mtext>Peptide</mml:mtext>
                          <mml:mo>)</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                      </mml:munder>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mo>,</mml:mo>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:munder>
                        <mml:mrow>
                          <mml:mrow>
                            <mml:munder>
                              <mml:mrow>
                                <mml:mn>2</mml:mn>
                                <mml:mo>,</mml:mo>
                                <mml:mn>2</mml:mn>
                                <mml:mo>,</mml:mo>
                                <mml:mn>2</mml:mn>
                                <mml:mo>,</mml:mo>
                                <mml:mo>…</mml:mo>
                                <mml:mo>,</mml:mo>
                                <mml:mn>2</mml:mn>
                              </mml:mrow>
                              <mml:mo>︸</mml:mo>
                            </mml:munder>
                          </mml:mrow>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi mathvariant="italic">length</mml:mi>
                          <mml:mo>(</mml:mo>
                          <mml:mtext>CDR</mml:mtext>
                          <mml:mn>3</mml:mn>
                          <mml:mo>β</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                      </mml:munder>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mo>]</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>embeddings</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">BERT</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>type</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>position</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>)</mml:mo>
                  <mml:mo>.</mml:mo>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:math>
        </disp-formula>
        <fig position="float" id="btad468-F3">
          <label>Figure 3.</label>
          <caption>
            <p>BERT architecture (bottom to top): first, peptide and TCR are tokenized. Then, each token is embedded in a 512-dimensional token space. The absolute position and token type—peptide or TCR—are encoded using separate embeddings. All three embeddings are added to form the input. Eight transformer blocks process the input to produce the output for each token. During MLM pre-training, the token classification head (right) is trained to predict the true token for 15% randomly masked tokens. During sequence classification training (left), the sequence classification head takes output of the CLS token and predicts binding for a peptide:TCR pair</p>
          </caption>
          <graphic xlink:href="btad468f3" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>2.2.2 Pre-training</title>
        <p>The large (over 2.5 M) number of trainable parameters in BERT is compensated by the unsupervised pre-training strategy. For this purpose, we created the hypothetical peptide:TCR repertoire. For CDR3<italic toggle="yes">β</italic> sequences, we used the TCR repertoires of 85 healthy individuals from a large high-throughput immunosequencing study by <xref rid="btad468-B7" ref-type="bibr">Dean <italic toggle="yes">et al.</italic> (2015)</xref>, which resulted in 11 M sequences. Over 150k peptides were acquired from the results of mass spectrometry peptide sequencing experiments (<xref rid="btad468-B2" ref-type="bibr">Abelin <italic toggle="yes">et al.</italic> 2017</xref>, <xref rid="btad468-B9" ref-type="bibr">Di Marco <italic toggle="yes">et al.</italic> 2017</xref>, <xref rid="btad468-B11" ref-type="bibr">Faridi <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btad468-B35" ref-type="bibr">Sarkizova <italic toggle="yes">et al.</italic> 2020</xref>). We randomly paired the MHC-I-presented peptides with reference TCRs and pre-trained a BERT neural network using MLM. Fifteen percentage of randomly chosen amino acids in the input sequence were masked and the network was trained to predict the masked amino acid. The weights from this stage were used as a starting point for the supervised training task. The effect of MLM pre-training can be seen in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>. The network was pre-trained for 100 epochs on a dataset of 9 M peptide:TCR pairs, 2 M of peptide:TCR pairs were used for validation. See Hyperparameters section in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> for more details about model training. Below is the description of the BERT MLM procedure.
</p>
        <disp-formula id="E2">
          <mml:math id="M2" display="block" overflow="scroll">
            <mml:mtable>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mi>p</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">Bernoulli</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mn>0.15</mml:mn>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>masked</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mtext>id</mml:mtext>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mo>=</mml:mo>
                  <mml:mrow>
                    <mml:mo stretchy="false">{</mml:mo>
                    <mml:mrow>
                      <mml:mtable>
                        <mml:mtr columnalign="left">
                          <mml:mtd columnalign="left">
                            <mml:mrow>
                              <mml:mtext>MASK</mml:mtext>
                            </mml:mrow>
                          </mml:mtd>
                          <mml:mtd columnalign="left">
                            <mml:mrow>
                              <mml:mtext>if</mml:mtext>
                              <mml:mo> </mml:mo>
                              <mml:mi>p</mml:mi>
                              <mml:mo>=</mml:mo>
                              <mml:mn>1</mml:mn>
                              <mml:mo>,</mml:mo>
                            </mml:mrow>
                          </mml:mtd>
                        </mml:mtr>
                        <mml:mtr columnalign="left">
                          <mml:mtd columnalign="left">
                            <mml:mrow>
                              <mml:mtext>token</mml:mtext>
                              <mml:mo>_</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mrow>
                                      <mml:mtext>id</mml:mtext>
                                    </mml:mrow>
                                  </mml:mrow>
                                  <mml:mi mathvariant="italic">i</mml:mi>
                                </mml:msub>
                              </mml:mrow>
                            </mml:mrow>
                          </mml:mtd>
                          <mml:mtd columnalign="left">
                            <mml:mrow>
                              <mml:mtext>if</mml:mtext>
                              <mml:mo> </mml:mo>
                              <mml:mi>p</mml:mi>
                              <mml:mo>=</mml:mo>
                              <mml:mn>0.</mml:mn>
                            </mml:mrow>
                          </mml:mtd>
                        </mml:mtr>
                      </mml:mtable>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>embeddings</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">BERT</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mtext>masked</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>type</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>position</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mtext>predicted</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">token</mml:mi>
                  <mml:mo> </mml:mo>
                  <mml:mi mathvariant="italic">classification</mml:mi>
                  <mml:mo> </mml:mo>
                  <mml:mi mathvariant="italic">head</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mtext>embeddings</mml:mtext>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mtext>MLM loss</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">crossentropy</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>predicted</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mo>.</mml:mo>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:math>
        </disp-formula>
      </sec>
      <sec>
        <title>2.2.3 Fine-tuning</title>
        <p>A separate sequence classification head was trained to classify binding peptide:TCR pairs and negative decoys. The hidden representation of the first token in the sequence was passed into a feed-forward layer combined with a softmax layer output. Focal loss with γ = 3 and <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mo>α</mml:mo><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:math></inline-formula> was used. Below is the description of the BERT fine-tuning procedure.
</p>
        <disp-formula id="E3">
          <mml:math id="M3" display="block" overflow="scroll">
            <mml:mtable>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mtext>embeddings</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">BERT</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>type</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>position</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mtext>embedding</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>CLS</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mtext>embeddings</mml:mtext>
                      </mml:mrow>
                      <mml:mn>0</mml:mn>
                    </mml:msub>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mi mathvariant="normal">y</mml:mi>
                        <mml:mo stretchy="false">^</mml:mo>
                      </mml:mover>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">sequence</mml:mi>
                  <mml:mo> </mml:mo>
                  <mml:mi mathvariant="italic">classification</mml:mi>
                  <mml:mo> </mml:mo>
                  <mml:mi mathvariant="italic">head</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mtext>embedding</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>CLS</mml:mtext>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mtext>supervised loss</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">focal</mml:mi>
                  <mml:mo> </mml:mo>
                  <mml:mi mathvariant="italic">loss</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mi mathvariant="normal">y</mml:mi>
                  <mml:mo>,</mml:mo>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mi mathvariant="normal">y</mml:mi>
                        <mml:mo stretchy="false">^</mml:mo>
                      </mml:mover>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mo>,</mml:mo>
                  <mml:mo>γ</mml:mo>
                  <mml:mo>=</mml:mo>
                  <mml:mn>3</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mo>α</mml:mo>
                  <mml:mo>=</mml:mo>
                  <mml:mn>0.25</mml:mn>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mo>.</mml:mo>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:math>
        </disp-formula>
      </sec>
    </sec>
    <sec>
      <title>2.3 Benchmarks and evaluation</title>
      <p>Existing approaches to peptide:TCR binding predictions based on peptide and CDR3<italic toggle="yes">β</italic> sequences were evaluated alongside our model. The selection criteria for the benchmarks were the following—ability for peptide:TCR binding prediction for unseen peptides, code availability with the possibility of re-training the model on our dataset, and the ability to be trained without CDR3<italic toggle="yes">α</italic> chain information. Among the peptide:TCR binding methods mentioned earlier, four algorithms fulfill the above criteria, namely NetTCR2.0, ERGO, TITAN, and DLpTCR. NetTCR2.0 was published by <xref rid="btad468-B28" ref-type="bibr">Montemurro <italic toggle="yes">et al.</italic> (2021)</xref>, which uses a convolutional neural network (CNN) to predict peptide:TCR binding for A02:01-restricted peptides. ERGO is the algorithm published by <xref rid="btad468-B39" ref-type="bibr">Springer <italic toggle="yes">et al.</italic> (2020)</xref>, which uses a pre-trained long short-term memory neural network (LSTM) architecture. TITAN from <xref rid="btad468-B42" ref-type="bibr">Weber <italic toggle="yes">et al.</italic> (2021)</xref> is a bimodal neural network, which is pre-trained on general protein–ligand interactions and uses an atomic-level SMILES input for peptide that is combined with a TCR input using cross-attention. DLpTCR from <xref rid="btad468-B44" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref> uses an ensemble of CNNs, LSTMs and fully connected neural networks. We are grateful to the authors of these approaches for providing the full source code for model training.</p>
      <p>To test the generalization power of our model and the benchmarks, we performed repeated cross-validation grouped by peptide and TCR clusters, to avoid correlated observations in the training and testing set, which can cause inflated results due to neural networks’ ability to remember training examples. For each training episode, the dataset was split into train and test sets. Fourteen peptide clusters and all their associated TCRs were chosen for each test set. Train observations with a TCR belonging to any test set TCR cluster were removed. All models were trained using the same dataset splits to ensure fairness in terms of data availability. The train and test sets were restricted to viral peptides and the final quality of the predictions was measured on an independent set of 76 cancer peptides. This process was repeated 21 times for 3 repetitions of random pairing, resulting in 63 rounds of cross-validation in total.</p>
      <p>The metric used for model validation was AUROC, which is the most popular metric for this problem (<xref rid="btad468-B22" ref-type="bibr">Lu <italic toggle="yes">et al.</italic> 2021</xref>, <xref rid="btad468-B42" ref-type="bibr">Weber <italic toggle="yes">et al.</italic> 2021</xref>, <xref rid="btad468-B44" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> 2021</xref>, <xref rid="btad468-B27" ref-type="bibr">Meysman <italic toggle="yes">et al.</italic> 2023</xref>). It was computed separately for each peptide and then averaged. Using this averaging procedure, we limit the bias, which originates from the high number of observations for some peptides and from the differences between peptide repertoires. We believe that such a measure is preferable to AUROC computed across all the observations, as the latter might likely lead to inflated results.</p>
      <p>Bertrand was trained for 25 epochs. The benchmarks were trained according to the training procedures provided in their corresponding repositories. BERTrand, ERGO, TITAN, and DLpTCR use early stopping on a separate subset of the data, however, NetTCR2.0 used training loss for early stopping. The specifics of the evaluation procedure are explained in detail in the Evaluation section of the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
      <p>Two kinds of baselines were considered during the evaluation: a random baseline (which is equal to 0.5 for AUROC), and baseline based on the prediction using TCR sequence only. The second baseline was estimated by training BERTrand without the peptide sequence. This is a more realistic baseline that represents the biases in the CDR3<italic toggle="yes">β</italic> sequences introduced by the negative decoys generation. For more details about the baselines, see the Baseline estimation section in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <p>We performed 21 rounds of cross-validation, repeated three times with different random pairings, and we evaluated the average per-peptide AUROC for each model. BERTrand converged to the optimal solution at around five epochs, with further training only introducing overfitting (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>). The cross-validation results shown in <xref rid="btad468-F4" ref-type="fig">Fig. 4</xref> indicates that our model can achieve better predictive performance than the state-of-the-art models when tested in multiple scenarios. While the average AUROC indicates a model that is definitely better than the baseline, the high variability in AUROC between peptides is definitely a concern. Out of 76 cancer peptides BERTrand achieved over 0.58 AUROC for 62 of them. While the model may be not optimally suited to perform prediction tasks on single peptide targets, it is applicable to groups of peptide targets in a practical <italic toggle="yes">in silico</italic> TCR prioritization scenario. With a large enough set of previously unseen peptide targets, BERTrand can generate predictions that prioritize binding peptide:TCR pairs, yielding an expected AUROC of 0.69.</p>
    <fig position="float" id="btad468-F4">
      <label>Figure 4.</label>
      <caption>
        <p>Benchmarks. (A) Results for the cross-validation test set. (B) Results for the cross-validation test set without outliers filtering demonstrate the potential metrics inflation due to outliers. (C) Results for the independent cancer set. BERTrand demonstrates better performance that the other models. (D) Results for the independent cancer set without outliers filtering are inflated and again demonstrate the importance of outliers filtering. (E) Results for individual peptides in the independent cancer set. Note that the confidence interval of the mean AUROC is wider as it includes high per-peptide variation</p>
      </caption>
      <graphic xlink:href="btad468f4" position="float"/>
    </fig>
    <p>We performed additional validation by using a different metric—namely average precision (AP). The AP on the cancer dataset for BERTrand is 0.55, which is better than all four benchmarks. See the Average precision section in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> for these results and the discussion on the metric choice.</p>
    <p><xref rid="btad468-T3" ref-type="table">Table 3</xref> summarizes the effect of the two most computationally intensive steps of the pipeline—NLP pre-training (12 days using 4 NVIDIA A100 GPUs) and outliers filtering (7 days using 128 CPUs). More detailed results on the convergence of BERTrand without pre-training can be found in the NLP pre-training section of the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
    <table-wrap position="float" id="btad468-T3">
      <label>Table 3.</label>
      <caption>
        <p>Comparison of the results for the independent cancer set without the most computationally intensive steps.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="left" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="1" colspan="1">Condition</th>
            <th rowspan="1" colspan="1">AUROC</th>
            <th rowspan="1" colspan="1">Explanation</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">Baseline</td>
            <td rowspan="1" colspan="1">0.69</td>
            <td align="center" rowspan="1" colspan="1">All steps in the pipeline</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">No pre-training</td>
            <td rowspan="1" colspan="1">0.62</td>
            <td align="center" rowspan="1" colspan="1">Poor results due to the a large number of weights trained from scratch</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">No outliers filtering</td>
            <td rowspan="1" colspan="1">0.73</td>
            <td align="center" rowspan="1" colspan="1">Inflated results due to out-of-distribution reference TCRs</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>We believe that the biggest challenge in peptide:TCR binding prediction is peptide bias due to low diversity of the peptides available. It is obvious that neither the peptide space (i.e. all possible peptides to be bound by TCRs) nor the TCR space (all possible TCRs) is sufficiently explored in the published data. NetTCR2.0 uses CNNs to predict the binding, which are very susceptible to overfitting when an obvious bias, such as a very popular peptide in the training dataset, is present. ERGO overcomes the TCR diversity problem by applying unsupervised TCR pre-training, but the peptide bias remains unaddressed. TITAN also uses a pre-trained model, but it is pre-trained on general protein–ligand interactions, which may be too different from the peptide:TCR distribution. The strategy of pre-training on a biologically plausible joint peptide:TCR distribution might help to address the peptide bias, as we have shown in this work. Language-based models can be successfully applied to the peptide:TCR binding problem outperforming other state-of-the-art methods, as highlighted in the results of our tests.</p>
  </sec>
  <sec>
    <title>4 Conclusions</title>
    <p>Cross-peptide generalization in peptide:TCR binding prediction remains a hard problem. However, results presented in this work demonstrate that peptide:TCR binding is predictable beyond known peptide targets. We believe the biggest obstacle in this field is data availability. Recent advances in single-cell TCR sequencing allowed for producing more experimental data, so we hope this work will encourage future peptide:TCR binding experiments and in the end, allow predictive models to become very useful for researchers. Potential applications of the peptide:TCR prediction model include the design of off-the-shelf TCR-based therapies for cancer (e.g. TCR-engineered T-cell therapies, TCR-mimicking antibodies, and TCR bispecific antibodies), the development of de-immunization strategies for autoimmune diseases, and the selection of optimal candidates for antiviral vaccine design. Even a model with a limited predictive power can already represent a very useful tool for the optimization of <italic toggle="yes">in vitro</italic> experiments (e.g. reducing the experimental time and costs associated with the typical experimental testing of a large number of putative non-prioritized TCR candidates).</p>
    <p>An important limitation of this work is the lack of CDR3<italic toggle="yes">α</italic> due to low availability of those sequences in databases. Although CDR3<italic toggle="yes">α</italic> sequence has been reported to be important for peptide:TCR binding prediction (<xref rid="btad468-B37" ref-type="bibr">Sidhom <italic toggle="yes">et al.</italic> 2021</xref>), it is only available for &lt;18% of observations. BERTrand architecture can be easily adapted to CDR3<italic toggle="yes">α</italic>-annotated data in the future, when more such data are available. Due to the low MHC diversity in the data, the aspects of the interactions between the MHC and the TCR were also omitted. However, we are confident that the growing collective effort we are witnessing in this field will eventually lead to populating databases with large amounts of fully annotated data. We believe this will open new doors for a holistic solution to the pMHC: TCR binding problem, with profound consequences for the development of immune-related therapies.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btad468_Supplementary_Data</label>
      <media xlink:href="btad468_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We would like to thank our fellows at the Laboratory of Bioinformatics and Computational Genomics at the Warsaw University of Technology for providing valuable suggestions and being a great audience.</p>
  </ack>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>The authors declare no conflict of interest.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the PhD programme “Doktoraty Wdrozeniowe” of the Polish Ministry of Education and the research grant “Stworzenie innowacyjnej, opartej na sztucznej inteligencji technologii TCRact w celu wprowadzenia na rynek nowej usługi polegającej na projektowaniu in silico receptorów limfocytów T (TCR) do wykorzystania w immunoterapiach nowotworów” [grant number POIR.01.01.01-00-0019/20] by the National Centre for Research and Development in Poland. Research was co-funded by Warsaw University of Technology within the Excellence Initiative: Research University (IDUB) programme. This work was co-supported by Polish National Science Centre [2019/35/O/ST6/02484]. Computations were performed thanks to the Laboratory of Bioinformatics and Computational Genomics, Faculty of Mathematics and Information Science, Warsaw University of Technology using Artificial Intelligence HPC platform financed by Polish Ministry of Science and Higher Education [decision no. 7054/IA/SP/2020 of 2020-08-28].</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The data underlying this article are available in GitHub, at <ext-link xlink:href="https://github.com/SFGLab/bertrand" ext-link-type="uri">https://github.com/SFGLab/bertrand</ext-link>. The datasets were derived from sources in the public domain, outlined in <xref rid="btad468-T1" ref-type="table">Table 1</xref>. The complete results of model training and evaluation are available at <ext-link xlink:href="https://drive.google.com/file/d/1U4lA9TsW0IQJXSk-7e478AAUU_59jNdV/view?usp=sharing" ext-link-type="uri">https://drive.google.com/file/d/1U4lA9TsW0IQJXSk-7e478AAUU_59jNdV/view?usp=sharing</ext-link></p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btad468-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abdel-Hakeem</surname><given-names>MS</given-names></string-name>, <string-name><surname>Boisvert</surname><given-names>M</given-names></string-name>, <string-name><surname>Bruneau</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Selective expansion of high functional avidity memory CD8 T cell clonotypes during hepatitis C virus reinfection and clearance</article-title>. <source>PLoS Pathog</source><year>2017</year>;<volume>13</volume>:<fpage>e1006191</fpage>.<pub-id pub-id-type="pmid">28146579</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abelin</surname><given-names>JG</given-names></string-name>, <string-name><surname>Keskin</surname><given-names>DB</given-names></string-name>, <string-name><surname>Sarkizova</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Mass spectrometry profiling of HLA-associated peptidomes in mono-allelic cells enables more accurate epitope prediction</article-title>. <source>Immunity</source><year>2017</year>;<volume>46</volume>:<fpage>315</fpage>–<lpage>26</lpage>.<pub-id pub-id-type="pmid">28228285</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bolkhovskaya</surname><given-names>OV</given-names></string-name>, <string-name><surname>Zorin</surname><given-names>DY</given-names></string-name>, <string-name><surname>Ivanchenko</surname><given-names>MV</given-names></string-name></person-group><etal>et al</etal><article-title>Assessing T cell clonal size distribution: a non-parametric approach</article-title>. <source>PLoS One</source><year>2014</year>;<volume>9</volume>:<fpage>e108658</fpage>.<pub-id pub-id-type="pmid">25275470</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Boutet</surname><given-names>SC</given-names></string-name>, <string-name><surname>Walter</surname><given-names>D</given-names></string-name>, <string-name><surname>Stubbington</surname><given-names>MJT</given-names></string-name></person-group><etal>et al</etal><article-title>Scalable and comprehensive characterization of antigen-specific CD8 T cells using multi-omics single cell analysis</article-title>. <source>J Immunol</source><year>2019</year>;<volume>202</volume>:<fpage>131.4</fpage>.<pub-id pub-id-type="pmid">30518569</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Britanova</surname><given-names>OV</given-names></string-name>, <string-name><surname>Shugay</surname><given-names>M</given-names></string-name>, <string-name><surname>Merzlyak</surname><given-names>EM</given-names></string-name></person-group><etal>et al</etal><article-title>Dynamics of individual T cell repertoires: from cord blood to centenarians</article-title>. <source>J Immunol</source><year>2016</year>;<volume>196</volume>:<fpage>5005</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">27183615</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dash</surname><given-names>P</given-names></string-name>, <string-name><surname>Fiore-Gartland</surname><given-names>AJ</given-names></string-name>, <string-name><surname>Hertz</surname><given-names>T</given-names></string-name></person-group><etal>et al</etal><article-title>Quantifiable predictive features define epitope-specific T cell receptor repertoires</article-title>. <source>Nature</source><year>2017</year>;<volume>547</volume>:<fpage>89</fpage>–<lpage>93</lpage>.<pub-id pub-id-type="pmid">28636592</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dean</surname><given-names>J</given-names></string-name>, <string-name><surname>Emerson</surname><given-names>RO</given-names></string-name>, <string-name><surname>Vignali</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>Annotation of pseudogenic gene segments by massively parallel sequencing of rearranged lymphocyte receptor loci</article-title>. <source>Genome Med</source><year>2015</year>;<volume>7</volume>:<fpage>123</fpage>.<pub-id pub-id-type="pmid">26596423</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B8">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Devlin</surname><given-names>J</given-names></string-name>, <string-name><surname>Chang</surname><given-names>M-W</given-names></string-name>, <string-name><surname>Lee</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal> BERT: pre-training of deep bidirectional transformers for language understanding. In: <italic toggle="yes">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Vol. 1 (Long and Short Papers)</italic>. <publisher-loc>Minneapolis, Minnesota</publisher-loc>: <publisher-name>Association for Computational Linguistics</publisher-name>, <year>2019</year>, <fpage>4171</fpage>–<lpage>86</lpage>.</mixed-citation>
    </ref>
    <ref id="btad468-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Di Marco</surname><given-names>M</given-names></string-name>, <string-name><surname>Schuster</surname><given-names>H</given-names></string-name>, <string-name><surname>Backert</surname><given-names>L</given-names></string-name></person-group><etal>et al</etal><article-title>Unveiling the peptide motifs of HLA-C and HLA-G from naturally presented peptides and generation of binding prediction matrices</article-title>. <source>J Immunol</source><year>2017</year>;<volume>199</volume>:<fpage>2639</fpage>–<lpage>51</lpage>.<pub-id pub-id-type="pmid">28904123</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Emerson</surname><given-names>RO</given-names></string-name>, <string-name><surname>DeWitt</surname><given-names>WS</given-names></string-name>, <string-name><surname>Vignali</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>Immunosequencing identifies signatures of cytomegalovirus exposure history and HLA-mediated effects on the T cell repertoire</article-title>. <source>Nat Genet</source><year>2017</year>;<volume>49</volume>:<fpage>659</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">28369038</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Faridi</surname><given-names>P</given-names></string-name>, <string-name><surname>Li</surname><given-names>C</given-names></string-name>, <string-name><surname>Ramarathinam</surname><given-names>SH</given-names></string-name></person-group><etal>et al</etal><article-title>A subset of HLA-I peptides are not genomically templated: evidence for cis- and trans-spliced peptide ligands</article-title>. <source>Sci Immunol</source><year>2018</year>;<volume>3</volume>:<fpage>eaar3947</fpage>.<pub-id pub-id-type="pmid">30315122</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B12">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Frank</surname><given-names>SA.</given-names></string-name></person-group><source>Immunology and Evolution of Infectious Disease</source>. <publisher-loc>Princeton</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>, <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="btad468-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Gao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Fan</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>Pan-peptide meta learning for T-cell receptor–antigen binding recognition</article-title>. <source>Nat Mach Intell</source><year>2023</year>;<volume>5</volume>:<fpage>236</fpage>–<lpage>49</lpage>.</mixed-citation>
    </ref>
    <ref id="btad468-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gee</surname><given-names>MH</given-names></string-name>, <string-name><surname>Han</surname><given-names>A</given-names></string-name>, <string-name><surname>Lofgren</surname><given-names>SM</given-names></string-name></person-group><etal>et al</etal><article-title>Antigen identification for orphan T cell receptors expressed on tumor-infiltrating lymphocytes</article-title>. <source>Cell</source><year>2018</year>;<volume>172</volume>:<fpage>549</fpage>–<lpage>63.e16</lpage>.<pub-id pub-id-type="pmid">29275860</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gielis</surname><given-names>S</given-names></string-name>, <string-name><surname>Moris</surname><given-names>P</given-names></string-name>, <string-name><surname>Bittremieux</surname><given-names>W</given-names></string-name></person-group><etal>et al</etal><article-title>Detection of enriched T cell epitope specificity in full T cell receptor sequence repertoires</article-title>. <source>Front Immunol</source><year>2019</year>;<volume>10</volume>:<fpage>2820</fpage>.<pub-id pub-id-type="pmid">31849987</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glanville</surname><given-names>J</given-names></string-name>, <string-name><surname>Huang</surname><given-names>H</given-names></string-name>, <string-name><surname>Nau</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Identifying specificity groups in the T cell receptor repertoire</article-title>. <source>Nature</source><year>2017</year>;<volume>547</volume>:<fpage>94</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">28636589</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huth</surname><given-names>A</given-names></string-name>, <string-name><surname>Liang</surname><given-names>X</given-names></string-name>, <string-name><surname>Krebs</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Antigen-specific TCR signatures of cytomegalovirus infection</article-title>. <source>J Immunol</source><year>2019</year>;<volume>202</volume>:<fpage>979</fpage>–<lpage>90</lpage>.<pub-id pub-id-type="pmid">30587531</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ji</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Liu</surname><given-names>H</given-names></string-name></person-group><etal>et al</etal><article-title>DNABERT: pre-trained bidirectional encoder representations from transformers model for DNA-language in genome</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>2112</fpage>–<lpage>20</lpage>.<pub-id pub-id-type="pmid">33538820</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jokinen</surname><given-names>E</given-names></string-name>, <string-name><surname>Huuhtanen</surname><given-names>J</given-names></string-name>, <string-name><surname>Mustjoki</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Predicting recognition between T cell receptors and epitopes with TCRGP</article-title>. <source>PLoS Comput Biol</source><year>2021</year>;<volume>17</volume>:<fpage>e1008814</fpage>.<pub-id pub-id-type="pmid">33764977</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kamga</surname><given-names>L</given-names></string-name>, <string-name><surname>Gil</surname><given-names>A</given-names></string-name>, <string-name><surname>Song</surname><given-names>I</given-names></string-name></person-group><etal>et al</etal><article-title>CDR3<italic toggle="yes">α</italic> drives selection of the immunodominant Epstein Barr virus (EBV) BRLF1-specific CD8 T cell receptor repertoire in primary infection</article-title>. <source>PLoS Pathog</source><year>2019</year>;<volume>15</volume>:<fpage>e1008122</fpage>.<pub-id pub-id-type="pmid">31765434</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>La Gruta</surname><given-names>NL</given-names></string-name>, <string-name><surname>Gras</surname><given-names>S</given-names></string-name>, <string-name><surname>Daley</surname><given-names>SR</given-names></string-name></person-group><etal>et al</etal><article-title>Understanding the drivers of MHC restriction of T cell receptors</article-title>. <source>Nat Rev Immunol</source><year>2018</year>;<volume>18</volume>:<fpage>467</fpage>–<lpage>78</lpage>.<pub-id pub-id-type="pmid">29636542</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lu</surname><given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Deep learning-based prediction of the T cell receptor-antigen binding specificity</article-title>. <source>Nat Mach Intell</source><year>2021</year>;<volume>3</volume>:<fpage>864</fpage>–<lpage>75</lpage>.<pub-id pub-id-type="pmid">36003885</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lythe</surname><given-names>G</given-names></string-name>, <string-name><surname>Callard</surname><given-names>RE</given-names></string-name>, <string-name><surname>Hoare</surname><given-names>RL</given-names></string-name></person-group><etal>et al</etal><article-title>How many TCR clonotypes does a body maintain?</article-title><source>J Theor Biol</source><year>2016</year>;<volume>389</volume>:<fpage>214</fpage>–<lpage>24</lpage>.<pub-id pub-id-type="pmid">26546971</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Malekzadeh</surname><given-names>P</given-names></string-name>, <string-name><surname>Pasetto</surname><given-names>A</given-names></string-name>, <string-name><surname>Robbins</surname><given-names>PF</given-names></string-name></person-group><etal>et al</etal><article-title>Neoantigen screening identifies broad TP53 mutant immunogenicity in patients with epithelial cancers</article-title>. <source>J Clin Invest</source><year>2019</year>;<volume>129</volume>:<fpage>1109</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">30714987</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mason</surname><given-names>D.</given-names></string-name></person-group><article-title>A very high level of crossreactivity is an essential feature of the T-cell receptor</article-title>. <source>Immunol Today</source><year>1998</year>;<volume>19</volume>:<fpage>395</fpage>–<lpage>404</lpage>.<pub-id pub-id-type="pmid">9745202</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mester</surname><given-names>G</given-names></string-name>, <string-name><surname>Hoffmann</surname><given-names>V</given-names></string-name>, <string-name><surname>Stevanović</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Insights into MHC class I antigen processing gained from large-scale analysis of class I ligands</article-title>. <source>Cell Mol Life Sci</source><year>2011</year>;<volume>68</volume>:<fpage>1521</fpage>–<lpage>32</lpage>.<pub-id pub-id-type="pmid">21387142</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meysman</surname><given-names>P</given-names></string-name>, <string-name><surname>Barton</surname><given-names>J</given-names></string-name>, <string-name><surname>Bravi</surname><given-names>B</given-names></string-name></person-group><etal>et al</etal><article-title>Benchmarking solutions to the T-cell receptor epitope prediction problem: IMMREP22 workshop report</article-title>. <source>Immunoinformatics</source><year>2023</year>;<volume>9</volume>:<fpage>100024</fpage>.</mixed-citation>
    </ref>
    <ref id="btad468-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Montemurro</surname><given-names>A</given-names></string-name>, <string-name><surname>Schuster</surname><given-names>V</given-names></string-name>, <string-name><surname>Povlsen</surname><given-names>HR</given-names></string-name></person-group><etal>et al</etal><article-title>NetTCR-2.0 enables accurate prediction of TCR-peptide binding by using paired TCRα and β sequence data</article-title>. <source>Commun Biol</source><year>2021</year>;<volume>4</volume>:<fpage>1060</fpage>.<pub-id pub-id-type="pmid">34508155</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oakes</surname><given-names>T</given-names></string-name>, <string-name><surname>Heather</surname><given-names>JM</given-names></string-name>, <string-name><surname>Best</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal><article-title>Quantitative characterization of the T cell receptor repertoire of naïve and memory subsets using an integrated experimental and computational pipeline which is robust, economical, and versatile</article-title>. <source>Front Immunol</source><year>2017</year>;<volume>8</volume>:<fpage>1267</fpage>.<pub-id pub-id-type="pmid">29075258</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Parkhurst</surname><given-names>MR</given-names></string-name>, <string-name><surname>Robbins</surname><given-names>PF</given-names></string-name>, <string-name><surname>Tran</surname><given-names>E</given-names></string-name></person-group><etal>et al</etal><article-title>Unique neoantigens arise from somatic mutations in patients with gastrointestinal cancers</article-title>. <source>Cancer Discov</source><year>2019</year>;<volume>9</volume>:<fpage>1022</fpage>–<lpage>35</lpage>.<pub-id pub-id-type="pmid">31164343</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pogorelyy</surname><given-names>MV</given-names></string-name>, <string-name><surname>Minervina</surname><given-names>AA</given-names></string-name>, <string-name><surname>Touzel</surname><given-names>MP</given-names></string-name></person-group><etal>et al</etal><article-title>Precise tracking of vaccine-responding T cell clones reveals convergent and personalized response in identical twins</article-title>. <source>Proc Natl Acad Sci USA</source><year>2018</year>;<volume>115</volume>:<fpage>12704</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">30459272</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qi</surname><given-names>Q</given-names></string-name>, <string-name><surname>Liu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Cheng</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>Diversity and clonal selection in the human T-cell repertoire</article-title>. <source>Proc Natl Acad Sci USA</source><year>2014</year>;<volume>111</volume>:<fpage>13139</fpage>–<lpage>44</lpage>.<pub-id pub-id-type="pmid">25157137</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rao</surname><given-names>R</given-names></string-name>, <string-name><surname>Bhattacharya</surname><given-names>N</given-names></string-name>, <string-name><surname>Thomas</surname><given-names>N</given-names></string-name></person-group><etal>et al</etal><article-title>Evaluating protein transfer learning with TAPE</article-title>. <source>Adv Neural Inf Process Syst</source><year>2019</year>;<volume>32</volume>:<fpage>9689</fpage>–<lpage>701</lpage>.<pub-id pub-id-type="pmid">33390682</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rudolph</surname><given-names>MG</given-names></string-name>, <string-name><surname>Stanfield</surname><given-names>RL</given-names></string-name>, <string-name><surname>Wilson</surname><given-names>IA</given-names></string-name></person-group><etal>et al</etal><article-title>How TCRs bind MHCs, peptides, and coreceptors</article-title>. <source>Annu Rev Immunol</source><year>2006</year>;<volume>24</volume>:<fpage>419</fpage>–<lpage>66</lpage>.<pub-id pub-id-type="pmid">16551255</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sarkizova</surname><given-names>S</given-names></string-name>, <string-name><surname>Klaeger</surname><given-names>S</given-names></string-name>, <string-name><surname>Le</surname><given-names>PM</given-names></string-name></person-group><etal>et al</etal><article-title>A large peptidome dataset improves HLA class I epitope prediction across most of the human population</article-title>. <source>Nat Biotechnol</source><year>2020</year>;<volume>38</volume>:<fpage>199</fpage>–<lpage>209</lpage>.<pub-id pub-id-type="pmid">31844290</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shugay</surname><given-names>M</given-names></string-name>, <string-name><surname>Bagaev</surname><given-names>DV</given-names></string-name>, <string-name><surname>Zvyagin</surname><given-names>IV</given-names></string-name></person-group><etal>et al</etal><article-title>VDJdb: a curated database of T-cell receptor sequences with known antigen specificity</article-title>. <source>Nucleic Acids Res</source><year>2018</year>;<volume>46</volume>:<fpage>D419</fpage>–<lpage>27</lpage>.<pub-id pub-id-type="pmid">28977646</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sidhom</surname><given-names>J-W</given-names></string-name>, <string-name><surname>Larman</surname><given-names>HB</given-names></string-name>, <string-name><surname>Pardoll</surname><given-names>DM</given-names></string-name></person-group><etal>et al</etal><article-title>DeepTCR is a deep learning framework for revealing sequence concepts within T-cell repertoires</article-title>. <source>Nat Commun</source><year>2021</year>;<volume>12</volume>:<fpage>1605</fpage>.<pub-id pub-id-type="pmid">33707415</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Soon</surname><given-names>CF</given-names></string-name>, <string-name><surname>Behrendt</surname><given-names>P</given-names></string-name>, <string-name><surname>Todt</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>Defining virus-specific CD8+ TCR repertoires for therapeutic regeneration of T cells against chronic hepatitis E</article-title>. <source>J Hepatol</source><year>2019</year>;<volume>71</volume>:<fpage>673</fpage>–<lpage>84</lpage>.<pub-id pub-id-type="pmid">31203151</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Springer</surname><given-names>I</given-names></string-name>, <string-name><surname>Besser</surname><given-names>H</given-names></string-name>, <string-name><surname>Tickotsky-Moskovitz</surname><given-names>N</given-names></string-name></person-group><etal>et al</etal><article-title>Prediction of specific TCR-peptide binding from large dictionaries of TCR-peptide pairs</article-title>. <source>Front Immunol</source><year>2020</year>;<volume>11</volume>:<fpage>1803</fpage>.<pub-id pub-id-type="pmid">32983088</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Takeda</surname><given-names>K</given-names></string-name>, <string-name><surname>Kitaura</surname><given-names>K</given-names></string-name>, <string-name><surname>Suzuki</surname><given-names>R</given-names></string-name></person-group><etal>et al</etal><article-title>Quantitative T-cell repertoire analysis of peripheral blood mononuclear cells from lung cancer patients following long-term cancer peptide vaccination</article-title>. <source>Cancer Immunol Immunother</source><year>2018</year>;<volume>67</volume>:<fpage>949</fpage>–<lpage>64</lpage>.<pub-id pub-id-type="pmid">29568993</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tickotsky</surname><given-names>N</given-names></string-name>, <string-name><surname>Sagiv</surname><given-names>T</given-names></string-name>, <string-name><surname>Prilusky</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>McPAS-TCR: a manually curated catalogue of pathology-associated T cell receptor sequences</article-title>. <source>Bioinformatics</source><year>2017</year>;<volume>33</volume>:<fpage>2924</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">28481982</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weber</surname><given-names>A</given-names></string-name>, <string-name><surname>Born</surname><given-names>J</given-names></string-name>, <string-name><surname>Rodriguez Martínez</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>TITAN: T-cell receptor specificity prediction with bimodal attention networks</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>i237</fpage>–<lpage>44</lpage>.<pub-id pub-id-type="pmid">34252922</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B43">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wolf</surname><given-names>T</given-names></string-name>, <string-name><surname>Debut</surname><given-names>L</given-names></string-name>, <string-name><surname>Sanh</surname><given-names>V</given-names></string-name></person-group><etal>et al</etal> HuggingFace’s transformers: state-of-the-art natural language processing. <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="btad468-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Luo</surname><given-names>M</given-names></string-name>, <string-name><surname>Lin</surname><given-names>W</given-names></string-name></person-group><etal>et al</etal><article-title>DLpTCR: an ensemble deep learning framework for predicting immunogenic peptide recognized by T cell receptor</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:<fpage>bbab335</fpage>.<pub-id pub-id-type="pmid">34415016</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>S-Q</given-names></string-name>, <string-name><surname>Ma</surname><given-names>K-Y</given-names></string-name>, <string-name><surname>Schonnesen</surname><given-names>AA</given-names></string-name></person-group><etal>et al</etal><article-title>High-throughput determination of the antigen specificities of T cell receptors in single cells</article-title>. <source>Nat Biotechnol</source><year>2018</year>;<volume>36</volume>:<fpage>1156</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="btad468-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>W</given-names></string-name>, <string-name><surname>Wang</surname><given-names>L</given-names></string-name>, <string-name><surname>Liu</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal><article-title>PIRD: pan immune repertoire database</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>897</fpage>–<lpage>903</lpage>.<pub-id pub-id-type="pmid">31373607</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>W</given-names></string-name>, <string-name><surname>Hawkins</surname><given-names>PG</given-names></string-name>, <string-name><surname>He</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>A framework for highly multiplexed dextramer mapping and prediction of T cell receptor sequences to antigen specificity</article-title>. <source>Sci Adv</source><year>2021</year>;<volume>7</volume>:<fpage>eabf5835</fpage>.<pub-id pub-id-type="pmid">33990328</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10444968</article-id>
    <article-id pub-id-type="pmid">37535685</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btad468</article-id>
    <article-id pub-id-type="publisher-id">btad468</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>BERTrand—peptide:TCR binding prediction using Bidirectional Encoder Representations from Transformers augmented with random TCR pairing</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6404-270X</contrib-id>
        <name>
          <surname>Myronov</surname>
          <given-names>Alexander</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/conceptualization" degree-contribution="equal">Conceptualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="http://credit.niso.org/contributor-roles/data-curation" degree-contribution="lead">Data curation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="http://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="equal">Formal analysis</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="http://credit.niso.org/contributor-roles/investigation" degree-contribution="equal">Investigation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="http://credit.niso.org/contributor-roles/methodology" degree-contribution="equal">Methodology</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Software" vocab-term-identifier="http://credit.niso.org/contributor-roles/software" degree-contribution="lead">Software</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Validation" vocab-term-identifier="http://credit.niso.org/contributor-roles/validation" degree-contribution="lead">Validation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/visualization" degree-contribution="lead">Visualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="equal">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &amp; editing</role>
        <aff><institution>Faculty of Mathematics and Information Science, Warsaw University of Technology</institution>, Warsaw, <country country="PL">Poland</country></aff>
        <aff><institution>Ardigen</institution>, Krakow, <country country="PL">Poland</country></aff>
        <xref rid="btad468-cor1" ref-type="corresp"/>
        <!--alexander.myronov@gmail.com-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mazzocco</surname>
          <given-names>Giovanni</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/conceptualization" degree-contribution="equal">Conceptualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="http://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="equal">Formal analysis</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Funding acquisition" vocab-term-identifier="http://credit.niso.org/contributor-roles/funding-acquisition" degree-contribution="equal">Funding acquisition</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="http://credit.niso.org/contributor-roles/investigation" degree-contribution="equal">Investigation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="http://credit.niso.org/contributor-roles/methodology" degree-contribution="equal">Methodology</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Project administration" vocab-term-identifier="http://credit.niso.org/contributor-roles/project-administration" degree-contribution="equal">Project administration</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Resources" vocab-term-identifier="http://credit.niso.org/contributor-roles/resources" degree-contribution="equal">Resources</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Supervision" vocab-term-identifier="http://credit.niso.org/contributor-roles/supervision" degree-contribution="equal">Supervision</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="equal">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &amp; editing</role>
        <aff><institution>Ardigen</institution>, Krakow, <country country="PL">Poland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Król</surname>
          <given-names>Paulina</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="http://credit.niso.org/contributor-roles/data-curation" degree-contribution="equal">Data curation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Software" vocab-term-identifier="http://credit.niso.org/contributor-roles/software" degree-contribution="supporting">Software</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Validation" vocab-term-identifier="http://credit.niso.org/contributor-roles/validation" degree-contribution="equal">Validation</role>
        <aff><institution>Ardigen</institution>, Krakow, <country country="PL">Poland</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3840-7610</contrib-id>
        <name>
          <surname>Plewczynski</surname>
          <given-names>Dariusz</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/conceptualization" degree-contribution="equal">Conceptualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="http://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="equal">Formal analysis</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Funding acquisition" vocab-term-identifier="http://credit.niso.org/contributor-roles/funding-acquisition" degree-contribution="equal">Funding acquisition</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="http://credit.niso.org/contributor-roles/investigation" degree-contribution="equal">Investigation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="http://credit.niso.org/contributor-roles/methodology" degree-contribution="equal">Methodology</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Project administration" vocab-term-identifier="http://credit.niso.org/contributor-roles/project-administration" degree-contribution="equal">Project administration</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Resources" vocab-term-identifier="http://credit.niso.org/contributor-roles/resources" degree-contribution="equal">Resources</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Supervision" vocab-term-identifier="http://credit.niso.org/contributor-roles/supervision" degree-contribution="equal">Supervision</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="equal">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &amp; editing</role>
        <aff><institution>Faculty of Mathematics and Information Science, Warsaw University of Technology</institution>, Warsaw, <country country="PL">Poland</country></aff>
        <xref rid="btad468-cor1" ref-type="corresp"/>
        <!--dariusz.plewczynski@pw.edu.pl-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btad468-cor1">Corresponding authors. Faculty of Mathematics and Information Science, Warsaw University of Technology, Koszykowa 75, Warsaw 00-662, Poland. E-mails: <email>alexander.myronov@gmail.com</email> (A.M.) and <email>dariusz.plewczynski@pw.edu.pl</email> (D.P.)</corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-08-03">
      <day>03</day>
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>03</day>
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <volume>39</volume>
    <issue>8</issue>
    <elocation-id>btad468</elocation-id>
    <history>
      <date date-type="received">
        <day>04</day>
        <month>1</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>28</day>
        <month>6</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>27</day>
        <month>7</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>01</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>22</day>
        <month>8</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btad468.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>The advent of T-cell receptor (TCR) sequencing experiments allowed for a significant increase in the amount of peptide:TCR binding data available and a number of machine-learning models appeared in recent years. High-quality prediction models for a fixed epitope sequence are feasible, provided enough known binding TCR sequences are available. However, their performance drops significantly for previously unseen peptides.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We prepare the dataset of known peptide:TCR binders and augment it with negative decoys created using healthy donors’ T-cell repertoires. We employ deep learning methods commonly applied in Natural Language Processing to train part a peptide:TCR binding model with a degree of cross-peptide generalization (0.69 AUROC). We demonstrate that BERTrand outperforms the published methods when evaluated on peptide sequences not used during model training.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The datasets and the code for model training are available at <ext-link xlink:href="https://github.com/SFGLab/bertrand" ext-link-type="uri">https://github.com/SFGLab/bertrand</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Polish Ministry of Education and the research</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Polish Ministry of Science and Higher Education</institution>
          </institution-wrap>
        </funding-source>
        <award-id>7054/IA/SP/2020</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Cytotoxic T-cells play a major role in adaptive immune response in humans. Intracellular proteins are degraded by proteasome into peptides. The antigen processing machinery of the cell allows the presentation of peptides on the cell surface using Major Histocompatibility Complexes (MHC). The focus of this work is MHC class I, which typically presents a peptide of 8–11 amino acids long. These peptide-MHC (pMHC) complexes in turn can be recognized and engaged by CD8+ cytotoxic T-cells. Due to negative selection in the thymus and the high degree diversity of the T-cell receptor (TCR) repertoire, T-cells are capable of recognizing a variety of foreign and mutated epitopes (<xref rid="btad468-B34" ref-type="bibr">Rudolph <italic toggle="yes">et al.</italic> 2006</xref>).</p>
    <p>The binding properties of a TCR to a given pMHC is regulated by hypervariable Complementarity Determining Regions (CDRs). For the <italic toggle="yes">α</italic> and <italic toggle="yes">β</italic> chains of the TCR, three such regions exist. The CDR1 and CDR2 of both <italic toggle="yes">α</italic> and <italic toggle="yes">β</italic> chains mostly interact with the MHC complex, while CDR3 is predominantly interacting with the peptide. The CDR3 region is the most variable region of the TCR and is thought to be the major factor in determining the binding preference of the TCR toward its conjugated pMHC (<xref rid="btad468-B21" ref-type="bibr">La Gruta <italic toggle="yes">et al.</italic> 2018</xref>). While both <italic toggle="yes">α</italic> and <italic toggle="yes">β</italic> chains contribute to the interaction, some studies suggest that the <italic toggle="yes">β</italic> chain plays a more important role in antigen recognition (<xref rid="btad468-B37" ref-type="bibr">Sidhom <italic toggle="yes">et al.</italic> 2021</xref>) and is significantly more prevalent in the data. It should be noted that many researchers—<xref rid="btad468-B6" ref-type="bibr">Dash <italic toggle="yes">et al.</italic> (2017)</xref> and <xref rid="btad468-B28" ref-type="bibr">Montemurro <italic toggle="yes">et al.</italic> (2021)</xref>—have demonstrated the importance of the <italic toggle="yes">α</italic> chain of the TCR in antigen recognition. However, this work implies the use of machine learning (ML) to infer the interaction between TCRs and pMHC complexes, so it can benefit from a high number of observations. In the data we collected, only 18% of the observations have the CDR3<italic toggle="yes">α</italic> annotation. Thus, we will be focusing solely on the sequence of the CDR3<italic toggle="yes">β</italic> part of the TCR, which is readily available in multiple datasets. This is the approach also adopted by <xref rid="btad468-B42" ref-type="bibr">Weber <italic toggle="yes">et al.</italic> (2021)</xref> and <xref rid="btad468-B22" ref-type="bibr">Lu <italic toggle="yes">et al.</italic> (2021)</xref>.</p>
    <p>The MHC is not able to present each and every peptide. Thanks to a high amount of pMHC binding data as well as peptide presentation data from mass spectrometry experiments, researchers were able to produce high accuracy models of pMHC binding and presentation. However, even if the peptide is presented on the surface of the cell, it is still unlikely to be immunogenic. The study by <xref rid="btad468-B30" ref-type="bibr">Parkhurst <italic toggle="yes">et al.</italic> (2019)</xref> of peptide T-cell immunogenicity for 75 cancer patients has been able to find only 57 CD8+ positive mutations along with over 8000 non-immunogenic ones, which account for &lt;1%. One of the frontiers of computational immunology research currently is peptide:TCR binding prediction, which represents a key component for understanding T-cell activation. The amount of data for peptide:TCR binding prediction has been growing in recent years, with the popularization of pMHC dextramer production, single-cell TCR sequencing, and TCR barcoding. In this work, we compile a collection of peptide:TCR sequence data from a number of databases and publications into a single curated dataset of known TCR binders with their cognate epitope sequences. We augment the dataset with negative decoy examples generated from reference T-cell repertoires.</p>
    <p>The growing amount of data on peptide:TCR specificity allowed for the creation of many computational tools that facilitate peptide:TCR binding prediction. These tools can be broadly categorized into three groups. The first group of methods uses the similarity between TCRs to produce clusters and determine their peptide specificity. GLIPH (<xref rid="btad468-B16" ref-type="bibr">Glanville <italic toggle="yes">et al.</italic> 2017</xref>) and TCRdist (<xref rid="btad468-B6" ref-type="bibr">Dash <italic toggle="yes">et al.</italic> 2017</xref>) have demonstrated that for a given epitope sequence, TCR binding can be predicted accurately using distance-based methods. The second group of methods involves the training of peptide-specific TCR binding models—DeepTCR (<xref rid="btad468-B37" ref-type="bibr">Sidhom <italic toggle="yes">et al.</italic> 2021</xref>), TCRex (<xref rid="btad468-B15" ref-type="bibr">Gielis <italic toggle="yes">et al.</italic> 2019</xref>), and TCRGP (<xref rid="btad468-B19" ref-type="bibr">Jokinen <italic toggle="yes">et al.</italic> 2021</xref>). These algorithms often work remarkably well for known peptides but are unable to predict binding for unseen peptides. The third group of methods are the methods that allow prediction for unseen peptides—NetTCR2.0 (<xref rid="btad468-B28" ref-type="bibr">Montemurro <italic toggle="yes">et al.</italic> 2021</xref>), ERGO (<xref rid="btad468-B39" ref-type="bibr">Springer <italic toggle="yes">et al.</italic> 2020</xref>), pMTnet (<xref rid="btad468-B22" ref-type="bibr">Lu <italic toggle="yes">et al.</italic> 2021</xref>), DLpTCR (<xref rid="btad468-B44" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> 2021</xref>), TITAN (<xref rid="btad468-B42" ref-type="bibr">Weber <italic toggle="yes">et al.</italic> 2021</xref>), and PanPEP (<xref rid="btad468-B13" ref-type="bibr">Gao <italic toggle="yes">et al.</italic> 2023</xref>). The goal of this research is to provide immunologists with better tools for <italic toggle="yes">in silico</italic> TCR therapy design. As most of the peptides in the published data originate from viruses, peptide-centric models from the second group have limited applicability for cancer neoantigens or tumor-associated antigens. The focus of this work is thus the peptide:TCR pairing task, specifically the case when the model has not previously seen neither the peptide nor the TCR. We believe that high accuracy for this task would bring the most benefit for potential users.</p>
    <p>Recent breakthroughs in Natural Language Processing (NLP), such as TAPE (<xref rid="btad468-B33" ref-type="bibr">Rao <italic toggle="yes">et al.</italic> 2019</xref>) and DNABERT (<xref rid="btad468-B18" ref-type="bibr">Ji <italic toggle="yes">et al.</italic> 2021</xref>), have prompted many researchers to apply Transformer architectures to solve sequence-based biological problems, such as transcription factors prediction, protein–protein interaction prediction, and binding pockets prediction to name a few. One useful feature of models from the NLP domain is the ability to process variable-length sequences of symbols from a fixed alphabet. Another important aspect is the ability to benefit from unsupervised pre-training, which is often an option in bioinformatics. Researchers usually pre-train the language model on large sequence databases, such as UniPROT. In this work, we construct a pre-training set for the peptide:TCR model, which comprises a hypothetical human peptide:TCR repertoire, based on peptides from MHC-I mass spectrometry peptide presentation experiments and TCRs from healthy donors. After pre-training our model is fine-tuned to predict peptide:TCR binding and was shown to outperform the existing methods in cross-peptide generalization task.</p>
    <p>The overall flow of the analysis is demonstrated in <xref rid="btad468-F1" ref-type="fig">Fig. 1</xref>. In the left part of the figure, we show the process of the NLP model pre-training. Reference TCR sequences from healthy donors are paired randomly with the presented peptides to produce a hypothetical peptide:TCR repertoire, which is then used to perform masked language modeling (MLM) pre-training of the Bidirectional Encoder Representations from Transformers (BERT) neural network. In the right part of the figure, the process of generating negative decoy observations is illustrated. Negative decoys are also based on reference TCRs. A ML model is used to remove outliers, and then the remaining reference TCRs are clustered together with binding TCRs. TCR sequences that are too similar to any binding TCR are removed, and the rest of the reference TCR clusters are randomly paired with peptides from the binding peptide:TCR set. Pre-trained BERT network is then trained to predict peptide:TCR binding.</p>
    <fig position="float" id="btad468-F1">
      <label>Figure 1.</label>
      <caption>
        <p>Flow diagram of the analysis. The left part illustrates the creation of the hypothetical peptide:TCR repertoire and MLM pre-training. The right part shows the process of negative decoys generation and various filtering steps leading to it. These two paths converge on BERT supervised training for peptide:TCR binding prediction</p>
      </caption>
      <graphic xlink:href="btad468f1" position="float"/>
    </fig>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Data</title>
      <sec>
        <title>2.1.1 Data curation</title>
        <p>Our data curation process is shown in <xref rid="btad468-F2" ref-type="fig">Fig. 2</xref>. We collected data containing the amino acid sequences of binding peptide:TCR pairs from a number of databases and publications (<xref rid="btad468-T1" ref-type="table">Table 1</xref>). We narrowed down the dataset to human CD8+ T-cells for peptides of 8–11 amino acids long. We only considered CDR3<italic toggle="yes">β</italic> observations, as CDR3<italic toggle="yes">α</italic> annotations are available for only 18% of the data (&lt;6k observations). Over 99% of the CDR3<italic toggle="yes">β</italic> sequences have a length between 10 and 20 amino acids. Another filtering criterion was the requirement of having specific amino acids in the first and last anchor positions in CDR3<italic toggle="yes">β</italic> chains, cysteine (C) and phenylalanine (F), respectively. This way, we compiled 33k unique CDR3<italic toggle="yes">β</italic> sequences of T-cells binding with a total of 401 epitope sequences. To compensate for the lack of negative examples, we generated negative decoy observations in a 3-to-1 ratio, using a dataset of reference T-cell repertoires from healthy donors (<xref rid="btad468-B29" ref-type="bibr">Oakes <italic toggle="yes">et al.</italic> 2017</xref>) and paired it randomly with peptides from the binders dataset.</p>
        <fig position="float" id="btad468-F2">
          <label>Figure 2.</label>
          <caption>
            <p>Data curation process. (A) Binding peptide:TCR observations. (B) Reference TCRs for decoy generation. (C) Reference TCRs filtering illustrated</p>
          </caption>
          <graphic xlink:href="btad468f2" position="float"/>
        </fig>
        <table-wrap position="float" id="btad468-T1">
          <label>Table 1.</label>
          <caption>
            <p>Summary of the binding peptide:TCR dataset.<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref></p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Dataset</th>
                <th style="text-align: center;" rowspan="1" colspan="1">Number of observations</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">VDJdb (<xref rid="btad468-B36" ref-type="bibr">Shugay <italic toggle="yes">et al.</italic> 2018</xref>)</td>
                <td align="center" rowspan="1" colspan="1">15 751</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">McPAS (<xref rid="btad468-B41" ref-type="bibr">Tickotsky <italic toggle="yes">et al.</italic> 2017</xref>)</td>
                <td align="center" rowspan="1" colspan="1">8482</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B31" ref-type="bibr">Pogorelyy <italic toggle="yes">et al.</italic> (2018)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">5861</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">TBAdb (<xref rid="btad468-B46" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2020</xref>)</td>
                <td align="center" rowspan="1" colspan="1">5852</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">10x Genomics (<xref rid="btad468-B4" ref-type="bibr">Boutet <italic toggle="yes">et al.</italic> 2019</xref>, <xref rid="btad468-B47" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2021</xref>)</td>
                <td align="center" rowspan="1" colspan="1">3813</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B45" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> (2018)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">1093</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B17" ref-type="bibr">Huth <italic toggle="yes">et al.</italic> (2019)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">1039</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B10" ref-type="bibr">Emerson <italic toggle="yes">et al.</italic> (2017)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">803</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B1" ref-type="bibr">Abdel-Hakeem <italic toggle="yes">et al.</italic> (2017)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">324</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B5" ref-type="bibr">Britanova <italic toggle="yes">et al.</italic> (2016)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">260</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B20" ref-type="bibr">Kamga <italic toggle="yes">et al.</italic> (2019)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">217</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B14" ref-type="bibr">Gee <italic toggle="yes">et al.</italic> (2018)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">33</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B40" ref-type="bibr">Takeda <italic toggle="yes">et al.</italic> (2018)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">20</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B38" ref-type="bibr">Soon <italic toggle="yes">et al.</italic> (2019)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">6</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <xref rid="btad468-B24" ref-type="bibr">Malekzadeh <italic toggle="yes">et al.</italic> (2019)</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">4</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Total</td>
                <td align="center" rowspan="1" colspan="1">43 558</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Unique</td>
                <td align="center" rowspan="1" colspan="1">32 523</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <label>a</label>
              <p>The number of observations is reported after filtering. The curated set of unique peptide:TCR binders is later used to train the model.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <table-wrap position="float" id="btad468-T2">
          <label>Table 2.</label>
          <caption>
            <p>The overview of potential biases that a ML algorithm for peptide:TCR prediction can exploit.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Bias</th>
                <th style="text-align: center;" rowspan="1" colspan="1">Mismatch pairing</th>
                <th style="text-align: center;" rowspan="1" colspan="1">Reference pairing</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">Under-representation of peptides in the dataset</td>
                <td align="center" rowspan="1" colspan="1">Yes</td>
                <td align="center" rowspan="1" colspan="1">Yes, but it is mitigated by pre-training to some extent</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Under-representation of TCRs in the dataset</td>
                <td align="center" rowspan="1" colspan="1">Yes</td>
                <td align="center" rowspan="1" colspan="1">No, because additional TCR sequences are used</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Potential false negatives</td>
                <td align="center" rowspan="1" colspan="1">Yes</td>
                <td align="center" rowspan="1" colspan="1">Yes</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Out-of-distribution easy negative decoys</td>
                <td align="center" rowspan="1" colspan="1">No</td>
                <td align="center" rowspan="1" colspan="1">Yes, but they can be filtered to some extent</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Too homogeneous negative decoys</td>
                <td align="center" rowspan="1" colspan="1">Yes</td>
                <td align="center" rowspan="1" colspan="1">No</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Correlated observations in train and test sets</td>
                <td align="center" rowspan="1" colspan="1">Yes, because mismatch pairing introduces additional dependencies</td>
                <td align="center" rowspan="1" colspan="1">No, peptide and TCR clusters are used for decoy generation and cross-validation</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>Cluster analysis of the peptides was done using hierarchical clustering with Levenshtein distance and single linkage. It revealed that a number of similar epitope sequences are present, differing by three amino acids at most. For example, MART-1 human melanoma-related antigen (ELAGIGILTV) was extensively studied with minor modifications: EAAGIGILTV, LLLGIGILV, ELAGIGLTV, AAGIGILTV, and ALGIGILTV. We argue that using such similar observations in the training and validation set may bias any model trained on peptide sequences and could introduce unwanted overfitting (if the TCR repertoires of two similar peptides are also similar), or unwanted underfitting if the repertoires are too different. Our analysis revealed 261 peptide clusters with a minimum Levenshtein distance of three. Peptide clusters were used as groups during cross-validation.</p>
      </sec>
      <sec>
        <title>2.1.2 Sources of overfitting</title>
        <p>Training a ML model on a limited set of data (i.e. positive peptide:TCR pairs for 400 peptides only) and with a lack of negative examples forces us to create negative decoy observations, which may easily introduce some bias that an ML model could easily exploit. Randomly pairing peptides and TCRs to create negative decoys is certainly a viable approach for this problem. TCRs are highly cross-reactive and are estimated to bind 10<sup>6</sup> multiple epitope sequences (<xref rid="btad468-B25" ref-type="bibr">Mason, 1998</xref>), hence a TCR could potentially bind some other peptide. However, TCRs are also highly specific, as the probability of a specific TCR binding a randomly chosen peptide is estimated to be <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref rid="btad468-B12" ref-type="bibr">Frank, 2020</xref>), which is acceptable for a ML approach. Besides possible false negative observations produced by random pairing and biases that may arise from experimental conditions, we have identified a handful of potential problems for a training setup with negative decoys (see <xref rid="btad468-T2" ref-type="table">Table 2</xref>).</p>
      </sec>
      <sec>
        <title>2.1.3 Mismatch pairing</title>
        <p>Mismatch pairing is an approach used in <xref rid="btad468-B28" ref-type="bibr">Montemurro <italic toggle="yes">et al.</italic> (2021)</xref> and <xref rid="btad468-B39" ref-type="bibr">Springer <italic toggle="yes">et al.</italic> (2020)</xref> to create negative decoy observations by randomly pairing a peptide with a TCRs from a different peptide:TCR pair. Mismatch pairing approach guarantees that the TCR distribution of the negatives will match the positive one. The number of different TCRs in a human body is estimated to be around <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mn>8</mml:mn></mml:msup></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref rid="btad468-B32" ref-type="bibr">Qi <italic toggle="yes">et al.</italic> 2014</xref>, <xref rid="btad468-B23" ref-type="bibr">Lythe <italic toggle="yes">et al.</italic> 2016</xref>), and the number of MHC-I-presented peptides on human cells is around 10<sup>4</sup> (<xref rid="btad468-B26" ref-type="bibr">Mester <italic toggle="yes">et al.</italic> 2011</xref>), thus mismatch pairing is largely under-representing both peptides and TCRs. Moreover, due to publication bias, different potential immunogenicity of viral and cancer peptides in humans, the distribution of T-cell clonotype size in humans (<xref rid="btad468-B3" ref-type="bibr">Bolkhovskaya <italic toggle="yes">et al.</italic> 2014</xref>) and other factors, the number of unique TCR observations per peptide has a power-law decay distribution (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>). In practice, this means that random peptide:TCR pairing will produce negative decoys, where over 61% of TCR sequences come from the five most popular peptides in the dataset. The repertoires of these peptides are too homogeneous and a model might learn to identify those as negatives. Mismatch pairing also produces correlated observations, thus during cross-validation there would be a considerable amount of examples in the training set sharing peptide or TCR sequence with pairs in the test set. These recurring peptides and TCRs may be exploited by the model if not removed. Deep learning models have a tendency to “remember” training data, so correlated observations in the training and test sets should be avoided to ensure test set independence.</p>
      </sec>
      <sec>
        <title>2.1.4 Reference pairing</title>
        <p>Our approach to negative decoys generation was designed to overcome some of the aforementioned biases. We collected around 560k TCR CDR3<italic toggle="yes">β</italic> sequences from repertoires of three healthy donors from <xref rid="btad468-B29" ref-type="bibr">Oakes <italic toggle="yes">et al.</italic> (2017)</xref> and randomly paired them with peptides from the binding dataset CDR3<italic toggle="yes">β</italic> sequences. The study by <xref rid="btad468-B29" ref-type="bibr">Oakes <italic toggle="yes">et al.</italic> (2017)</xref> was used for reference pairing instead of <xref rid="btad468-B7" ref-type="bibr">Dean <italic toggle="yes">et al.</italic> (2015)</xref> due to the improved sequencing protocol that captured the rare clones in the TCR distribution, allowing for a more biologically plausible CDR3<italic toggle="yes">β</italic> sequence space, and the availability of the T-cell type annotation. We used only the CD8+ T-cells from the patients’ repertoires, which matches the MHC class I peptides in the binders’ dataset. Reference TCRs represent a much larger region of the TCR theoretical distribution compared to binding TCRs, although both TCRs and peptides remain still under-represented. Reference TCRs obtained through a different kind of TCR sequencing experiment might introduce CDR3<italic toggle="yes">β</italic> sequences that are out-of-distribution relative to the binding TCRs and thus might be easy targets for a neural network. To address this issue, we filtered the sequences using a ML-based approach, see Outliers filtering section in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> for a detailed description.</p>
        <p>To avoid correlated observations, we performed TCR clustering analysis of the binding TCR sequences together with reference TCRs: hierarchical clustering was used with Levenshtein distance and complete linkage with distance cut-off equal to three. Clustering naturally produced three types of clusters:</p>
        <list list-type="order">
          <list-item>
            <p>clusters with only TCRs from binding peptide:TCR pairs</p>
          </list-item>
          <list-item>
            <p>mixed clusters positive and reference TCRs</p>
          </list-item>
          <list-item>
            <p>clusters with only reference TCRs.</p>
          </list-item>
        </list>
        <p>During decoy generation, we rejected reference TCRs from mixed clusters, as they have a much higher probability of being false negatives, because their sequences are very similar to those of the binding TCRs. TCRs from reference-only clusters were randomly paired with a single peptide from the pool of 401 available peptides in the binding dataset in a 3-to-1 ratio to the number of positive observations for a given peptide. In a cluster of reference TCRs, every TCR is paired with the same peptide, which limits the generation of positive and negative observations with the same peptide sequence and very similar TCR sequences. Such observations would in fact be quite useless, as they should be filtered from the training set if they appear in the test set during cross-validation, otherwise the model would be biased toward predicting the negative class. As the decoy generation is random, the dataset was replicated three times for different seeds. TCR clusters were also used as groups during cross-validation.</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Model</title>
      <p>For this problem, we applied the BERT artificial neural network (<xref rid="btad468-B8" ref-type="bibr">Devlin <italic toggle="yes">et al.</italic> 2019</xref>) from “transformers” python package (<xref rid="btad468-B43" ref-type="bibr">Wolf <italic toggle="yes">et al.</italic> 2019</xref>). The model was initially pre-trained to perform a MLM task on a hypothetical TCR repertoire and then fine-tuned for actual peptide:TCR classification.</p>
      <sec>
        <title>2.2.1 Model architecture</title>
        <p>The architecture of BERT is illustrated in <xref rid="btad468-F3" ref-type="fig">Fig. 3</xref>. Initially, peptides and TCRs need to be represented as a sequence of tokens. The token vocabulary consists of 20 amino acids and 5 additional special tokens: CLS is used to indicate the starting position of the sequence, SEP to indicate the end of the sequence, MASK for MLM, PAD for padding, and UNK for non-standard amino acids. Each peptide and TCR are concatenated into a single sequence of tokens with an additional CLS token at the beginning and two SEP tokens between sequences and at the end of the sequence. The sequence IDs indicating the absolute position of the token and the token type IDs, indicating whether a token belongs to the peptide or to the TCR, are generated as well. Token, position and type IDs are embedded and added creating the sequence of input embeddings for each token. The input is then passed to a BERT network with eight transformer blocks. BERT produces an output embedding for each token, which later on is passed to either a token classification head and to a sequence classification head during pre-training and fine-tuning, respectively. Below is the description of the BERT embedding procedure.
</p>
        <disp-formula id="E1">
          <mml:math id="M1" display="block" overflow="scroll">
            <mml:mtable>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mo>[</mml:mo>
                  <mml:mtext>CLS</mml:mtext>
                  <mml:mo>]</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="italic">tokenize</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mtext>Peptide</mml:mtext>
                  <mml:mo>)</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>[</mml:mo>
                  <mml:mtext>SEP</mml:mtext>
                  <mml:mo>]</mml:mo>
                  <mml:mo>+</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="italic">tokenize</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mtext>CDR</mml:mtext>
                  <mml:mn>3</mml:mn>
                  <mml:mo>β</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mo>[</mml:mo>
                  <mml:mtext>SEP</mml:mtext>
                  <mml:mo>]</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>position</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mo>[</mml:mo>
                  <mml:mn>1</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mn>2</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mn>3</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mo>…</mml:mo>
                  <mml:mo>,</mml:mo>
                  <mml:mi mathvariant="italic">length</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mtext>Peptide</mml:mtext>
                  <mml:mo>)</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mi mathvariant="italic">length</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mtext>CDR</mml:mtext>
                  <mml:mn>3</mml:mn>
                  <mml:mo>β</mml:mo>
                  <mml:mo>)</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mn>3</mml:mn>
                  <mml:mo>]</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>type</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mo>[</mml:mo>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:munder>
                        <mml:mrow>
                          <mml:mrow>
                            <mml:munder>
                              <mml:mrow>
                                <mml:mn>1</mml:mn>
                                <mml:mo>,</mml:mo>
                                <mml:mn>1</mml:mn>
                                <mml:mo>,</mml:mo>
                                <mml:mn>1</mml:mn>
                                <mml:mo>,</mml:mo>
                                <mml:mo>…</mml:mo>
                                <mml:mo>,</mml:mo>
                                <mml:mn>1</mml:mn>
                              </mml:mrow>
                              <mml:mo>︸</mml:mo>
                            </mml:munder>
                          </mml:mrow>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi mathvariant="italic">length</mml:mi>
                          <mml:mo>(</mml:mo>
                          <mml:mtext>Peptide</mml:mtext>
                          <mml:mo>)</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                      </mml:munder>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mo>,</mml:mo>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:munder>
                        <mml:mrow>
                          <mml:mrow>
                            <mml:munder>
                              <mml:mrow>
                                <mml:mn>2</mml:mn>
                                <mml:mo>,</mml:mo>
                                <mml:mn>2</mml:mn>
                                <mml:mo>,</mml:mo>
                                <mml:mn>2</mml:mn>
                                <mml:mo>,</mml:mo>
                                <mml:mo>…</mml:mo>
                                <mml:mo>,</mml:mo>
                                <mml:mn>2</mml:mn>
                              </mml:mrow>
                              <mml:mo>︸</mml:mo>
                            </mml:munder>
                          </mml:mrow>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi mathvariant="italic">length</mml:mi>
                          <mml:mo>(</mml:mo>
                          <mml:mtext>CDR</mml:mtext>
                          <mml:mn>3</mml:mn>
                          <mml:mo>β</mml:mo>
                          <mml:mo>)</mml:mo>
                          <mml:mo>+</mml:mo>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                      </mml:munder>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mo>]</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>embeddings</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">BERT</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>type</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>position</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>)</mml:mo>
                  <mml:mo>.</mml:mo>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:math>
        </disp-formula>
        <fig position="float" id="btad468-F3">
          <label>Figure 3.</label>
          <caption>
            <p>BERT architecture (bottom to top): first, peptide and TCR are tokenized. Then, each token is embedded in a 512-dimensional token space. The absolute position and token type—peptide or TCR—are encoded using separate embeddings. All three embeddings are added to form the input. Eight transformer blocks process the input to produce the output for each token. During MLM pre-training, the token classification head (right) is trained to predict the true token for 15% randomly masked tokens. During sequence classification training (left), the sequence classification head takes output of the CLS token and predicts binding for a peptide:TCR pair</p>
          </caption>
          <graphic xlink:href="btad468f3" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>2.2.2 Pre-training</title>
        <p>The large (over 2.5 M) number of trainable parameters in BERT is compensated by the unsupervised pre-training strategy. For this purpose, we created the hypothetical peptide:TCR repertoire. For CDR3<italic toggle="yes">β</italic> sequences, we used the TCR repertoires of 85 healthy individuals from a large high-throughput immunosequencing study by <xref rid="btad468-B7" ref-type="bibr">Dean <italic toggle="yes">et al.</italic> (2015)</xref>, which resulted in 11 M sequences. Over 150k peptides were acquired from the results of mass spectrometry peptide sequencing experiments (<xref rid="btad468-B2" ref-type="bibr">Abelin <italic toggle="yes">et al.</italic> 2017</xref>, <xref rid="btad468-B9" ref-type="bibr">Di Marco <italic toggle="yes">et al.</italic> 2017</xref>, <xref rid="btad468-B11" ref-type="bibr">Faridi <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btad468-B35" ref-type="bibr">Sarkizova <italic toggle="yes">et al.</italic> 2020</xref>). We randomly paired the MHC-I-presented peptides with reference TCRs and pre-trained a BERT neural network using MLM. Fifteen percentage of randomly chosen amino acids in the input sequence were masked and the network was trained to predict the masked amino acid. The weights from this stage were used as a starting point for the supervised training task. The effect of MLM pre-training can be seen in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>. The network was pre-trained for 100 epochs on a dataset of 9 M peptide:TCR pairs, 2 M of peptide:TCR pairs were used for validation. See Hyperparameters section in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> for more details about model training. Below is the description of the BERT MLM procedure.
</p>
        <disp-formula id="E2">
          <mml:math id="M2" display="block" overflow="scroll">
            <mml:mtable>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mi>p</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">Bernoulli</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mn>0.15</mml:mn>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>masked</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mtext>id</mml:mtext>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mo>=</mml:mo>
                  <mml:mrow>
                    <mml:mo stretchy="false">{</mml:mo>
                    <mml:mrow>
                      <mml:mtable>
                        <mml:mtr columnalign="left">
                          <mml:mtd columnalign="left">
                            <mml:mrow>
                              <mml:mtext>MASK</mml:mtext>
                            </mml:mrow>
                          </mml:mtd>
                          <mml:mtd columnalign="left">
                            <mml:mrow>
                              <mml:mtext>if</mml:mtext>
                              <mml:mo> </mml:mo>
                              <mml:mi>p</mml:mi>
                              <mml:mo>=</mml:mo>
                              <mml:mn>1</mml:mn>
                              <mml:mo>,</mml:mo>
                            </mml:mrow>
                          </mml:mtd>
                        </mml:mtr>
                        <mml:mtr columnalign="left">
                          <mml:mtd columnalign="left">
                            <mml:mrow>
                              <mml:mtext>token</mml:mtext>
                              <mml:mo>_</mml:mo>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mrow>
                                      <mml:mtext>id</mml:mtext>
                                    </mml:mrow>
                                  </mml:mrow>
                                  <mml:mi mathvariant="italic">i</mml:mi>
                                </mml:msub>
                              </mml:mrow>
                            </mml:mrow>
                          </mml:mtd>
                          <mml:mtd columnalign="left">
                            <mml:mrow>
                              <mml:mtext>if</mml:mtext>
                              <mml:mo> </mml:mo>
                              <mml:mi>p</mml:mi>
                              <mml:mo>=</mml:mo>
                              <mml:mn>0.</mml:mn>
                            </mml:mrow>
                          </mml:mtd>
                        </mml:mtr>
                      </mml:mtable>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>embeddings</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">BERT</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mtext>masked</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>type</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>position</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mtext>predicted</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">token</mml:mi>
                  <mml:mo> </mml:mo>
                  <mml:mi mathvariant="italic">classification</mml:mi>
                  <mml:mo> </mml:mo>
                  <mml:mi mathvariant="italic">head</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mtext>embeddings</mml:mtext>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mtext>MLM loss</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">crossentropy</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>predicted</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mo>.</mml:mo>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:math>
        </disp-formula>
      </sec>
      <sec>
        <title>2.2.3 Fine-tuning</title>
        <p>A separate sequence classification head was trained to classify binding peptide:TCR pairs and negative decoys. The hidden representation of the first token in the sequence was passed into a feed-forward layer combined with a softmax layer output. Focal loss with γ = 3 and <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mo>α</mml:mo><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:math></inline-formula> was used. Below is the description of the BERT fine-tuning procedure.
</p>
        <disp-formula id="E3">
          <mml:math id="M3" display="block" overflow="scroll">
            <mml:mtable>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mtext>embeddings</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">BERT</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>token</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>type</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo>,</mml:mo>
                  <mml:mtext>position</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>ids</mml:mtext>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mtext>embedding</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>CLS</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mtext>embeddings</mml:mtext>
                      </mml:mrow>
                      <mml:mn>0</mml:mn>
                    </mml:msub>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mi mathvariant="normal">y</mml:mi>
                        <mml:mo stretchy="false">^</mml:mo>
                      </mml:mover>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">sequence</mml:mi>
                  <mml:mo> </mml:mo>
                  <mml:mi mathvariant="italic">classification</mml:mi>
                  <mml:mo> </mml:mo>
                  <mml:mi mathvariant="italic">head</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mtext>embedding</mml:mtext>
                  <mml:mo>_</mml:mo>
                  <mml:mtext>CLS</mml:mtext>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd columnalign="left">
                  <mml:mtext>supervised loss</mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mi mathvariant="italic">focal</mml:mi>
                  <mml:mo> </mml:mo>
                  <mml:mi mathvariant="italic">loss</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mi mathvariant="normal">y</mml:mi>
                  <mml:mo>,</mml:mo>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mi mathvariant="normal">y</mml:mi>
                        <mml:mo stretchy="false">^</mml:mo>
                      </mml:mover>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mo>,</mml:mo>
                  <mml:mo>γ</mml:mo>
                  <mml:mo>=</mml:mo>
                  <mml:mn>3</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mo>α</mml:mo>
                  <mml:mo>=</mml:mo>
                  <mml:mn>0.25</mml:mn>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mo>.</mml:mo>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:math>
        </disp-formula>
      </sec>
    </sec>
    <sec>
      <title>2.3 Benchmarks and evaluation</title>
      <p>Existing approaches to peptide:TCR binding predictions based on peptide and CDR3<italic toggle="yes">β</italic> sequences were evaluated alongside our model. The selection criteria for the benchmarks were the following—ability for peptide:TCR binding prediction for unseen peptides, code availability with the possibility of re-training the model on our dataset, and the ability to be trained without CDR3<italic toggle="yes">α</italic> chain information. Among the peptide:TCR binding methods mentioned earlier, four algorithms fulfill the above criteria, namely NetTCR2.0, ERGO, TITAN, and DLpTCR. NetTCR2.0 was published by <xref rid="btad468-B28" ref-type="bibr">Montemurro <italic toggle="yes">et al.</italic> (2021)</xref>, which uses a convolutional neural network (CNN) to predict peptide:TCR binding for A02:01-restricted peptides. ERGO is the algorithm published by <xref rid="btad468-B39" ref-type="bibr">Springer <italic toggle="yes">et al.</italic> (2020)</xref>, which uses a pre-trained long short-term memory neural network (LSTM) architecture. TITAN from <xref rid="btad468-B42" ref-type="bibr">Weber <italic toggle="yes">et al.</italic> (2021)</xref> is a bimodal neural network, which is pre-trained on general protein–ligand interactions and uses an atomic-level SMILES input for peptide that is combined with a TCR input using cross-attention. DLpTCR from <xref rid="btad468-B44" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref> uses an ensemble of CNNs, LSTMs and fully connected neural networks. We are grateful to the authors of these approaches for providing the full source code for model training.</p>
      <p>To test the generalization power of our model and the benchmarks, we performed repeated cross-validation grouped by peptide and TCR clusters, to avoid correlated observations in the training and testing set, which can cause inflated results due to neural networks’ ability to remember training examples. For each training episode, the dataset was split into train and test sets. Fourteen peptide clusters and all their associated TCRs were chosen for each test set. Train observations with a TCR belonging to any test set TCR cluster were removed. All models were trained using the same dataset splits to ensure fairness in terms of data availability. The train and test sets were restricted to viral peptides and the final quality of the predictions was measured on an independent set of 76 cancer peptides. This process was repeated 21 times for 3 repetitions of random pairing, resulting in 63 rounds of cross-validation in total.</p>
      <p>The metric used for model validation was AUROC, which is the most popular metric for this problem (<xref rid="btad468-B22" ref-type="bibr">Lu <italic toggle="yes">et al.</italic> 2021</xref>, <xref rid="btad468-B42" ref-type="bibr">Weber <italic toggle="yes">et al.</italic> 2021</xref>, <xref rid="btad468-B44" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> 2021</xref>, <xref rid="btad468-B27" ref-type="bibr">Meysman <italic toggle="yes">et al.</italic> 2023</xref>). It was computed separately for each peptide and then averaged. Using this averaging procedure, we limit the bias, which originates from the high number of observations for some peptides and from the differences between peptide repertoires. We believe that such a measure is preferable to AUROC computed across all the observations, as the latter might likely lead to inflated results.</p>
      <p>Bertrand was trained for 25 epochs. The benchmarks were trained according to the training procedures provided in their corresponding repositories. BERTrand, ERGO, TITAN, and DLpTCR use early stopping on a separate subset of the data, however, NetTCR2.0 used training loss for early stopping. The specifics of the evaluation procedure are explained in detail in the Evaluation section of the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
      <p>Two kinds of baselines were considered during the evaluation: a random baseline (which is equal to 0.5 for AUROC), and baseline based on the prediction using TCR sequence only. The second baseline was estimated by training BERTrand without the peptide sequence. This is a more realistic baseline that represents the biases in the CDR3<italic toggle="yes">β</italic> sequences introduced by the negative decoys generation. For more details about the baselines, see the Baseline estimation section in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <p>We performed 21 rounds of cross-validation, repeated three times with different random pairings, and we evaluated the average per-peptide AUROC for each model. BERTrand converged to the optimal solution at around five epochs, with further training only introducing overfitting (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>). The cross-validation results shown in <xref rid="btad468-F4" ref-type="fig">Fig. 4</xref> indicates that our model can achieve better predictive performance than the state-of-the-art models when tested in multiple scenarios. While the average AUROC indicates a model that is definitely better than the baseline, the high variability in AUROC between peptides is definitely a concern. Out of 76 cancer peptides BERTrand achieved over 0.58 AUROC for 62 of them. While the model may be not optimally suited to perform prediction tasks on single peptide targets, it is applicable to groups of peptide targets in a practical <italic toggle="yes">in silico</italic> TCR prioritization scenario. With a large enough set of previously unseen peptide targets, BERTrand can generate predictions that prioritize binding peptide:TCR pairs, yielding an expected AUROC of 0.69.</p>
    <fig position="float" id="btad468-F4">
      <label>Figure 4.</label>
      <caption>
        <p>Benchmarks. (A) Results for the cross-validation test set. (B) Results for the cross-validation test set without outliers filtering demonstrate the potential metrics inflation due to outliers. (C) Results for the independent cancer set. BERTrand demonstrates better performance that the other models. (D) Results for the independent cancer set without outliers filtering are inflated and again demonstrate the importance of outliers filtering. (E) Results for individual peptides in the independent cancer set. Note that the confidence interval of the mean AUROC is wider as it includes high per-peptide variation</p>
      </caption>
      <graphic xlink:href="btad468f4" position="float"/>
    </fig>
    <p>We performed additional validation by using a different metric—namely average precision (AP). The AP on the cancer dataset for BERTrand is 0.55, which is better than all four benchmarks. See the Average precision section in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> for these results and the discussion on the metric choice.</p>
    <p><xref rid="btad468-T3" ref-type="table">Table 3</xref> summarizes the effect of the two most computationally intensive steps of the pipeline—NLP pre-training (12 days using 4 NVIDIA A100 GPUs) and outliers filtering (7 days using 128 CPUs). More detailed results on the convergence of BERTrand without pre-training can be found in the NLP pre-training section of the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
    <table-wrap position="float" id="btad468-T3">
      <label>Table 3.</label>
      <caption>
        <p>Comparison of the results for the independent cancer set without the most computationally intensive steps.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="left" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="1" colspan="1">Condition</th>
            <th rowspan="1" colspan="1">AUROC</th>
            <th rowspan="1" colspan="1">Explanation</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">Baseline</td>
            <td rowspan="1" colspan="1">0.69</td>
            <td align="center" rowspan="1" colspan="1">All steps in the pipeline</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">No pre-training</td>
            <td rowspan="1" colspan="1">0.62</td>
            <td align="center" rowspan="1" colspan="1">Poor results due to the a large number of weights trained from scratch</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">No outliers filtering</td>
            <td rowspan="1" colspan="1">0.73</td>
            <td align="center" rowspan="1" colspan="1">Inflated results due to out-of-distribution reference TCRs</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>We believe that the biggest challenge in peptide:TCR binding prediction is peptide bias due to low diversity of the peptides available. It is obvious that neither the peptide space (i.e. all possible peptides to be bound by TCRs) nor the TCR space (all possible TCRs) is sufficiently explored in the published data. NetTCR2.0 uses CNNs to predict the binding, which are very susceptible to overfitting when an obvious bias, such as a very popular peptide in the training dataset, is present. ERGO overcomes the TCR diversity problem by applying unsupervised TCR pre-training, but the peptide bias remains unaddressed. TITAN also uses a pre-trained model, but it is pre-trained on general protein–ligand interactions, which may be too different from the peptide:TCR distribution. The strategy of pre-training on a biologically plausible joint peptide:TCR distribution might help to address the peptide bias, as we have shown in this work. Language-based models can be successfully applied to the peptide:TCR binding problem outperforming other state-of-the-art methods, as highlighted in the results of our tests.</p>
  </sec>
  <sec>
    <title>4 Conclusions</title>
    <p>Cross-peptide generalization in peptide:TCR binding prediction remains a hard problem. However, results presented in this work demonstrate that peptide:TCR binding is predictable beyond known peptide targets. We believe the biggest obstacle in this field is data availability. Recent advances in single-cell TCR sequencing allowed for producing more experimental data, so we hope this work will encourage future peptide:TCR binding experiments and in the end, allow predictive models to become very useful for researchers. Potential applications of the peptide:TCR prediction model include the design of off-the-shelf TCR-based therapies for cancer (e.g. TCR-engineered T-cell therapies, TCR-mimicking antibodies, and TCR bispecific antibodies), the development of de-immunization strategies for autoimmune diseases, and the selection of optimal candidates for antiviral vaccine design. Even a model with a limited predictive power can already represent a very useful tool for the optimization of <italic toggle="yes">in vitro</italic> experiments (e.g. reducing the experimental time and costs associated with the typical experimental testing of a large number of putative non-prioritized TCR candidates).</p>
    <p>An important limitation of this work is the lack of CDR3<italic toggle="yes">α</italic> due to low availability of those sequences in databases. Although CDR3<italic toggle="yes">α</italic> sequence has been reported to be important for peptide:TCR binding prediction (<xref rid="btad468-B37" ref-type="bibr">Sidhom <italic toggle="yes">et al.</italic> 2021</xref>), it is only available for &lt;18% of observations. BERTrand architecture can be easily adapted to CDR3<italic toggle="yes">α</italic>-annotated data in the future, when more such data are available. Due to the low MHC diversity in the data, the aspects of the interactions between the MHC and the TCR were also omitted. However, we are confident that the growing collective effort we are witnessing in this field will eventually lead to populating databases with large amounts of fully annotated data. We believe this will open new doors for a holistic solution to the pMHC: TCR binding problem, with profound consequences for the development of immune-related therapies.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btad468_Supplementary_Data</label>
      <media xlink:href="btad468_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We would like to thank our fellows at the Laboratory of Bioinformatics and Computational Genomics at the Warsaw University of Technology for providing valuable suggestions and being a great audience.</p>
  </ack>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>The authors declare no conflict of interest.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the PhD programme “Doktoraty Wdrozeniowe” of the Polish Ministry of Education and the research grant “Stworzenie innowacyjnej, opartej na sztucznej inteligencji technologii TCRact w celu wprowadzenia na rynek nowej usługi polegającej na projektowaniu in silico receptorów limfocytów T (TCR) do wykorzystania w immunoterapiach nowotworów” [grant number POIR.01.01.01-00-0019/20] by the National Centre for Research and Development in Poland. Research was co-funded by Warsaw University of Technology within the Excellence Initiative: Research University (IDUB) programme. This work was co-supported by Polish National Science Centre [2019/35/O/ST6/02484]. Computations were performed thanks to the Laboratory of Bioinformatics and Computational Genomics, Faculty of Mathematics and Information Science, Warsaw University of Technology using Artificial Intelligence HPC platform financed by Polish Ministry of Science and Higher Education [decision no. 7054/IA/SP/2020 of 2020-08-28].</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The data underlying this article are available in GitHub, at <ext-link xlink:href="https://github.com/SFGLab/bertrand" ext-link-type="uri">https://github.com/SFGLab/bertrand</ext-link>. The datasets were derived from sources in the public domain, outlined in <xref rid="btad468-T1" ref-type="table">Table 1</xref>. The complete results of model training and evaluation are available at <ext-link xlink:href="https://drive.google.com/file/d/1U4lA9TsW0IQJXSk-7e478AAUU_59jNdV/view?usp=sharing" ext-link-type="uri">https://drive.google.com/file/d/1U4lA9TsW0IQJXSk-7e478AAUU_59jNdV/view?usp=sharing</ext-link></p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btad468-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abdel-Hakeem</surname><given-names>MS</given-names></string-name>, <string-name><surname>Boisvert</surname><given-names>M</given-names></string-name>, <string-name><surname>Bruneau</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Selective expansion of high functional avidity memory CD8 T cell clonotypes during hepatitis C virus reinfection and clearance</article-title>. <source>PLoS Pathog</source><year>2017</year>;<volume>13</volume>:<fpage>e1006191</fpage>.<pub-id pub-id-type="pmid">28146579</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abelin</surname><given-names>JG</given-names></string-name>, <string-name><surname>Keskin</surname><given-names>DB</given-names></string-name>, <string-name><surname>Sarkizova</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Mass spectrometry profiling of HLA-associated peptidomes in mono-allelic cells enables more accurate epitope prediction</article-title>. <source>Immunity</source><year>2017</year>;<volume>46</volume>:<fpage>315</fpage>–<lpage>26</lpage>.<pub-id pub-id-type="pmid">28228285</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bolkhovskaya</surname><given-names>OV</given-names></string-name>, <string-name><surname>Zorin</surname><given-names>DY</given-names></string-name>, <string-name><surname>Ivanchenko</surname><given-names>MV</given-names></string-name></person-group><etal>et al</etal><article-title>Assessing T cell clonal size distribution: a non-parametric approach</article-title>. <source>PLoS One</source><year>2014</year>;<volume>9</volume>:<fpage>e108658</fpage>.<pub-id pub-id-type="pmid">25275470</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Boutet</surname><given-names>SC</given-names></string-name>, <string-name><surname>Walter</surname><given-names>D</given-names></string-name>, <string-name><surname>Stubbington</surname><given-names>MJT</given-names></string-name></person-group><etal>et al</etal><article-title>Scalable and comprehensive characterization of antigen-specific CD8 T cells using multi-omics single cell analysis</article-title>. <source>J Immunol</source><year>2019</year>;<volume>202</volume>:<fpage>131.4</fpage>.<pub-id pub-id-type="pmid">30518569</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Britanova</surname><given-names>OV</given-names></string-name>, <string-name><surname>Shugay</surname><given-names>M</given-names></string-name>, <string-name><surname>Merzlyak</surname><given-names>EM</given-names></string-name></person-group><etal>et al</etal><article-title>Dynamics of individual T cell repertoires: from cord blood to centenarians</article-title>. <source>J Immunol</source><year>2016</year>;<volume>196</volume>:<fpage>5005</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">27183615</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dash</surname><given-names>P</given-names></string-name>, <string-name><surname>Fiore-Gartland</surname><given-names>AJ</given-names></string-name>, <string-name><surname>Hertz</surname><given-names>T</given-names></string-name></person-group><etal>et al</etal><article-title>Quantifiable predictive features define epitope-specific T cell receptor repertoires</article-title>. <source>Nature</source><year>2017</year>;<volume>547</volume>:<fpage>89</fpage>–<lpage>93</lpage>.<pub-id pub-id-type="pmid">28636592</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dean</surname><given-names>J</given-names></string-name>, <string-name><surname>Emerson</surname><given-names>RO</given-names></string-name>, <string-name><surname>Vignali</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>Annotation of pseudogenic gene segments by massively parallel sequencing of rearranged lymphocyte receptor loci</article-title>. <source>Genome Med</source><year>2015</year>;<volume>7</volume>:<fpage>123</fpage>.<pub-id pub-id-type="pmid">26596423</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B8">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Devlin</surname><given-names>J</given-names></string-name>, <string-name><surname>Chang</surname><given-names>M-W</given-names></string-name>, <string-name><surname>Lee</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal> BERT: pre-training of deep bidirectional transformers for language understanding. In: <italic toggle="yes">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Vol. 1 (Long and Short Papers)</italic>. <publisher-loc>Minneapolis, Minnesota</publisher-loc>: <publisher-name>Association for Computational Linguistics</publisher-name>, <year>2019</year>, <fpage>4171</fpage>–<lpage>86</lpage>.</mixed-citation>
    </ref>
    <ref id="btad468-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Di Marco</surname><given-names>M</given-names></string-name>, <string-name><surname>Schuster</surname><given-names>H</given-names></string-name>, <string-name><surname>Backert</surname><given-names>L</given-names></string-name></person-group><etal>et al</etal><article-title>Unveiling the peptide motifs of HLA-C and HLA-G from naturally presented peptides and generation of binding prediction matrices</article-title>. <source>J Immunol</source><year>2017</year>;<volume>199</volume>:<fpage>2639</fpage>–<lpage>51</lpage>.<pub-id pub-id-type="pmid">28904123</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Emerson</surname><given-names>RO</given-names></string-name>, <string-name><surname>DeWitt</surname><given-names>WS</given-names></string-name>, <string-name><surname>Vignali</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>Immunosequencing identifies signatures of cytomegalovirus exposure history and HLA-mediated effects on the T cell repertoire</article-title>. <source>Nat Genet</source><year>2017</year>;<volume>49</volume>:<fpage>659</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">28369038</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Faridi</surname><given-names>P</given-names></string-name>, <string-name><surname>Li</surname><given-names>C</given-names></string-name>, <string-name><surname>Ramarathinam</surname><given-names>SH</given-names></string-name></person-group><etal>et al</etal><article-title>A subset of HLA-I peptides are not genomically templated: evidence for cis- and trans-spliced peptide ligands</article-title>. <source>Sci Immunol</source><year>2018</year>;<volume>3</volume>:<fpage>eaar3947</fpage>.<pub-id pub-id-type="pmid">30315122</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B12">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Frank</surname><given-names>SA.</given-names></string-name></person-group><source>Immunology and Evolution of Infectious Disease</source>. <publisher-loc>Princeton</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>, <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="btad468-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Gao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Fan</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>Pan-peptide meta learning for T-cell receptor–antigen binding recognition</article-title>. <source>Nat Mach Intell</source><year>2023</year>;<volume>5</volume>:<fpage>236</fpage>–<lpage>49</lpage>.</mixed-citation>
    </ref>
    <ref id="btad468-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gee</surname><given-names>MH</given-names></string-name>, <string-name><surname>Han</surname><given-names>A</given-names></string-name>, <string-name><surname>Lofgren</surname><given-names>SM</given-names></string-name></person-group><etal>et al</etal><article-title>Antigen identification for orphan T cell receptors expressed on tumor-infiltrating lymphocytes</article-title>. <source>Cell</source><year>2018</year>;<volume>172</volume>:<fpage>549</fpage>–<lpage>63.e16</lpage>.<pub-id pub-id-type="pmid">29275860</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gielis</surname><given-names>S</given-names></string-name>, <string-name><surname>Moris</surname><given-names>P</given-names></string-name>, <string-name><surname>Bittremieux</surname><given-names>W</given-names></string-name></person-group><etal>et al</etal><article-title>Detection of enriched T cell epitope specificity in full T cell receptor sequence repertoires</article-title>. <source>Front Immunol</source><year>2019</year>;<volume>10</volume>:<fpage>2820</fpage>.<pub-id pub-id-type="pmid">31849987</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glanville</surname><given-names>J</given-names></string-name>, <string-name><surname>Huang</surname><given-names>H</given-names></string-name>, <string-name><surname>Nau</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Identifying specificity groups in the T cell receptor repertoire</article-title>. <source>Nature</source><year>2017</year>;<volume>547</volume>:<fpage>94</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">28636589</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huth</surname><given-names>A</given-names></string-name>, <string-name><surname>Liang</surname><given-names>X</given-names></string-name>, <string-name><surname>Krebs</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Antigen-specific TCR signatures of cytomegalovirus infection</article-title>. <source>J Immunol</source><year>2019</year>;<volume>202</volume>:<fpage>979</fpage>–<lpage>90</lpage>.<pub-id pub-id-type="pmid">30587531</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ji</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Liu</surname><given-names>H</given-names></string-name></person-group><etal>et al</etal><article-title>DNABERT: pre-trained bidirectional encoder representations from transformers model for DNA-language in genome</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>2112</fpage>–<lpage>20</lpage>.<pub-id pub-id-type="pmid">33538820</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jokinen</surname><given-names>E</given-names></string-name>, <string-name><surname>Huuhtanen</surname><given-names>J</given-names></string-name>, <string-name><surname>Mustjoki</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Predicting recognition between T cell receptors and epitopes with TCRGP</article-title>. <source>PLoS Comput Biol</source><year>2021</year>;<volume>17</volume>:<fpage>e1008814</fpage>.<pub-id pub-id-type="pmid">33764977</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kamga</surname><given-names>L</given-names></string-name>, <string-name><surname>Gil</surname><given-names>A</given-names></string-name>, <string-name><surname>Song</surname><given-names>I</given-names></string-name></person-group><etal>et al</etal><article-title>CDR3<italic toggle="yes">α</italic> drives selection of the immunodominant Epstein Barr virus (EBV) BRLF1-specific CD8 T cell receptor repertoire in primary infection</article-title>. <source>PLoS Pathog</source><year>2019</year>;<volume>15</volume>:<fpage>e1008122</fpage>.<pub-id pub-id-type="pmid">31765434</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>La Gruta</surname><given-names>NL</given-names></string-name>, <string-name><surname>Gras</surname><given-names>S</given-names></string-name>, <string-name><surname>Daley</surname><given-names>SR</given-names></string-name></person-group><etal>et al</etal><article-title>Understanding the drivers of MHC restriction of T cell receptors</article-title>. <source>Nat Rev Immunol</source><year>2018</year>;<volume>18</volume>:<fpage>467</fpage>–<lpage>78</lpage>.<pub-id pub-id-type="pmid">29636542</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lu</surname><given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Deep learning-based prediction of the T cell receptor-antigen binding specificity</article-title>. <source>Nat Mach Intell</source><year>2021</year>;<volume>3</volume>:<fpage>864</fpage>–<lpage>75</lpage>.<pub-id pub-id-type="pmid">36003885</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lythe</surname><given-names>G</given-names></string-name>, <string-name><surname>Callard</surname><given-names>RE</given-names></string-name>, <string-name><surname>Hoare</surname><given-names>RL</given-names></string-name></person-group><etal>et al</etal><article-title>How many TCR clonotypes does a body maintain?</article-title><source>J Theor Biol</source><year>2016</year>;<volume>389</volume>:<fpage>214</fpage>–<lpage>24</lpage>.<pub-id pub-id-type="pmid">26546971</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Malekzadeh</surname><given-names>P</given-names></string-name>, <string-name><surname>Pasetto</surname><given-names>A</given-names></string-name>, <string-name><surname>Robbins</surname><given-names>PF</given-names></string-name></person-group><etal>et al</etal><article-title>Neoantigen screening identifies broad TP53 mutant immunogenicity in patients with epithelial cancers</article-title>. <source>J Clin Invest</source><year>2019</year>;<volume>129</volume>:<fpage>1109</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">30714987</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mason</surname><given-names>D.</given-names></string-name></person-group><article-title>A very high level of crossreactivity is an essential feature of the T-cell receptor</article-title>. <source>Immunol Today</source><year>1998</year>;<volume>19</volume>:<fpage>395</fpage>–<lpage>404</lpage>.<pub-id pub-id-type="pmid">9745202</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mester</surname><given-names>G</given-names></string-name>, <string-name><surname>Hoffmann</surname><given-names>V</given-names></string-name>, <string-name><surname>Stevanović</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Insights into MHC class I antigen processing gained from large-scale analysis of class I ligands</article-title>. <source>Cell Mol Life Sci</source><year>2011</year>;<volume>68</volume>:<fpage>1521</fpage>–<lpage>32</lpage>.<pub-id pub-id-type="pmid">21387142</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meysman</surname><given-names>P</given-names></string-name>, <string-name><surname>Barton</surname><given-names>J</given-names></string-name>, <string-name><surname>Bravi</surname><given-names>B</given-names></string-name></person-group><etal>et al</etal><article-title>Benchmarking solutions to the T-cell receptor epitope prediction problem: IMMREP22 workshop report</article-title>. <source>Immunoinformatics</source><year>2023</year>;<volume>9</volume>:<fpage>100024</fpage>.</mixed-citation>
    </ref>
    <ref id="btad468-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Montemurro</surname><given-names>A</given-names></string-name>, <string-name><surname>Schuster</surname><given-names>V</given-names></string-name>, <string-name><surname>Povlsen</surname><given-names>HR</given-names></string-name></person-group><etal>et al</etal><article-title>NetTCR-2.0 enables accurate prediction of TCR-peptide binding by using paired TCRα and β sequence data</article-title>. <source>Commun Biol</source><year>2021</year>;<volume>4</volume>:<fpage>1060</fpage>.<pub-id pub-id-type="pmid">34508155</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oakes</surname><given-names>T</given-names></string-name>, <string-name><surname>Heather</surname><given-names>JM</given-names></string-name>, <string-name><surname>Best</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal><article-title>Quantitative characterization of the T cell receptor repertoire of naïve and memory subsets using an integrated experimental and computational pipeline which is robust, economical, and versatile</article-title>. <source>Front Immunol</source><year>2017</year>;<volume>8</volume>:<fpage>1267</fpage>.<pub-id pub-id-type="pmid">29075258</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Parkhurst</surname><given-names>MR</given-names></string-name>, <string-name><surname>Robbins</surname><given-names>PF</given-names></string-name>, <string-name><surname>Tran</surname><given-names>E</given-names></string-name></person-group><etal>et al</etal><article-title>Unique neoantigens arise from somatic mutations in patients with gastrointestinal cancers</article-title>. <source>Cancer Discov</source><year>2019</year>;<volume>9</volume>:<fpage>1022</fpage>–<lpage>35</lpage>.<pub-id pub-id-type="pmid">31164343</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pogorelyy</surname><given-names>MV</given-names></string-name>, <string-name><surname>Minervina</surname><given-names>AA</given-names></string-name>, <string-name><surname>Touzel</surname><given-names>MP</given-names></string-name></person-group><etal>et al</etal><article-title>Precise tracking of vaccine-responding T cell clones reveals convergent and personalized response in identical twins</article-title>. <source>Proc Natl Acad Sci USA</source><year>2018</year>;<volume>115</volume>:<fpage>12704</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">30459272</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qi</surname><given-names>Q</given-names></string-name>, <string-name><surname>Liu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Cheng</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>Diversity and clonal selection in the human T-cell repertoire</article-title>. <source>Proc Natl Acad Sci USA</source><year>2014</year>;<volume>111</volume>:<fpage>13139</fpage>–<lpage>44</lpage>.<pub-id pub-id-type="pmid">25157137</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rao</surname><given-names>R</given-names></string-name>, <string-name><surname>Bhattacharya</surname><given-names>N</given-names></string-name>, <string-name><surname>Thomas</surname><given-names>N</given-names></string-name></person-group><etal>et al</etal><article-title>Evaluating protein transfer learning with TAPE</article-title>. <source>Adv Neural Inf Process Syst</source><year>2019</year>;<volume>32</volume>:<fpage>9689</fpage>–<lpage>701</lpage>.<pub-id pub-id-type="pmid">33390682</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rudolph</surname><given-names>MG</given-names></string-name>, <string-name><surname>Stanfield</surname><given-names>RL</given-names></string-name>, <string-name><surname>Wilson</surname><given-names>IA</given-names></string-name></person-group><etal>et al</etal><article-title>How TCRs bind MHCs, peptides, and coreceptors</article-title>. <source>Annu Rev Immunol</source><year>2006</year>;<volume>24</volume>:<fpage>419</fpage>–<lpage>66</lpage>.<pub-id pub-id-type="pmid">16551255</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sarkizova</surname><given-names>S</given-names></string-name>, <string-name><surname>Klaeger</surname><given-names>S</given-names></string-name>, <string-name><surname>Le</surname><given-names>PM</given-names></string-name></person-group><etal>et al</etal><article-title>A large peptidome dataset improves HLA class I epitope prediction across most of the human population</article-title>. <source>Nat Biotechnol</source><year>2020</year>;<volume>38</volume>:<fpage>199</fpage>–<lpage>209</lpage>.<pub-id pub-id-type="pmid">31844290</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shugay</surname><given-names>M</given-names></string-name>, <string-name><surname>Bagaev</surname><given-names>DV</given-names></string-name>, <string-name><surname>Zvyagin</surname><given-names>IV</given-names></string-name></person-group><etal>et al</etal><article-title>VDJdb: a curated database of T-cell receptor sequences with known antigen specificity</article-title>. <source>Nucleic Acids Res</source><year>2018</year>;<volume>46</volume>:<fpage>D419</fpage>–<lpage>27</lpage>.<pub-id pub-id-type="pmid">28977646</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sidhom</surname><given-names>J-W</given-names></string-name>, <string-name><surname>Larman</surname><given-names>HB</given-names></string-name>, <string-name><surname>Pardoll</surname><given-names>DM</given-names></string-name></person-group><etal>et al</etal><article-title>DeepTCR is a deep learning framework for revealing sequence concepts within T-cell repertoires</article-title>. <source>Nat Commun</source><year>2021</year>;<volume>12</volume>:<fpage>1605</fpage>.<pub-id pub-id-type="pmid">33707415</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Soon</surname><given-names>CF</given-names></string-name>, <string-name><surname>Behrendt</surname><given-names>P</given-names></string-name>, <string-name><surname>Todt</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>Defining virus-specific CD8+ TCR repertoires for therapeutic regeneration of T cells against chronic hepatitis E</article-title>. <source>J Hepatol</source><year>2019</year>;<volume>71</volume>:<fpage>673</fpage>–<lpage>84</lpage>.<pub-id pub-id-type="pmid">31203151</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Springer</surname><given-names>I</given-names></string-name>, <string-name><surname>Besser</surname><given-names>H</given-names></string-name>, <string-name><surname>Tickotsky-Moskovitz</surname><given-names>N</given-names></string-name></person-group><etal>et al</etal><article-title>Prediction of specific TCR-peptide binding from large dictionaries of TCR-peptide pairs</article-title>. <source>Front Immunol</source><year>2020</year>;<volume>11</volume>:<fpage>1803</fpage>.<pub-id pub-id-type="pmid">32983088</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Takeda</surname><given-names>K</given-names></string-name>, <string-name><surname>Kitaura</surname><given-names>K</given-names></string-name>, <string-name><surname>Suzuki</surname><given-names>R</given-names></string-name></person-group><etal>et al</etal><article-title>Quantitative T-cell repertoire analysis of peripheral blood mononuclear cells from lung cancer patients following long-term cancer peptide vaccination</article-title>. <source>Cancer Immunol Immunother</source><year>2018</year>;<volume>67</volume>:<fpage>949</fpage>–<lpage>64</lpage>.<pub-id pub-id-type="pmid">29568993</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tickotsky</surname><given-names>N</given-names></string-name>, <string-name><surname>Sagiv</surname><given-names>T</given-names></string-name>, <string-name><surname>Prilusky</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>McPAS-TCR: a manually curated catalogue of pathology-associated T cell receptor sequences</article-title>. <source>Bioinformatics</source><year>2017</year>;<volume>33</volume>:<fpage>2924</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">28481982</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weber</surname><given-names>A</given-names></string-name>, <string-name><surname>Born</surname><given-names>J</given-names></string-name>, <string-name><surname>Rodriguez Martínez</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>TITAN: T-cell receptor specificity prediction with bimodal attention networks</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>i237</fpage>–<lpage>44</lpage>.<pub-id pub-id-type="pmid">34252922</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B43">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wolf</surname><given-names>T</given-names></string-name>, <string-name><surname>Debut</surname><given-names>L</given-names></string-name>, <string-name><surname>Sanh</surname><given-names>V</given-names></string-name></person-group><etal>et al</etal> HuggingFace’s transformers: state-of-the-art natural language processing. <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="btad468-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Luo</surname><given-names>M</given-names></string-name>, <string-name><surname>Lin</surname><given-names>W</given-names></string-name></person-group><etal>et al</etal><article-title>DLpTCR: an ensemble deep learning framework for predicting immunogenic peptide recognized by T cell receptor</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:<fpage>bbab335</fpage>.<pub-id pub-id-type="pmid">34415016</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>S-Q</given-names></string-name>, <string-name><surname>Ma</surname><given-names>K-Y</given-names></string-name>, <string-name><surname>Schonnesen</surname><given-names>AA</given-names></string-name></person-group><etal>et al</etal><article-title>High-throughput determination of the antigen specificities of T cell receptors in single cells</article-title>. <source>Nat Biotechnol</source><year>2018</year>;<volume>36</volume>:<fpage>1156</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="btad468-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>W</given-names></string-name>, <string-name><surname>Wang</surname><given-names>L</given-names></string-name>, <string-name><surname>Liu</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal><article-title>PIRD: pan immune repertoire database</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>897</fpage>–<lpage>903</lpage>.<pub-id pub-id-type="pmid">31373607</pub-id></mixed-citation>
    </ref>
    <ref id="btad468-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>W</given-names></string-name>, <string-name><surname>Hawkins</surname><given-names>PG</given-names></string-name>, <string-name><surname>He</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>A framework for highly multiplexed dextramer mapping and prediction of T cell receptor sequences to antigen specificity</article-title>. <source>Sci Adv</source><year>2021</year>;<volume>7</volume>:<fpage>eabf5835</fpage>.<pub-id pub-id-type="pmid">33990328</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
