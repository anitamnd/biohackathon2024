<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-title>BMC Bioinformatics</journal-title>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">2630331</article-id>
    <article-id pub-id-type="publisher-id">1471-2105-9-461</article-id>
    <article-id pub-id-type="pmid">18959772</article-id>
    <article-id pub-id-type="doi">10.1186/1471-2105-9-461</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title><italic>minet</italic>: A R/Bioconductor Package for Inferring Large Transcriptional Networks Using Mutual Information</article-title>
    </title-group>
    <contrib-group>
      <contrib id="A1" corresp="yes" contrib-type="author">
        <name>
          <surname>Meyer</surname>
          <given-names>Patrick E</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <email>pmeyer@ulb.ac.be</email>
      </contrib>
      <contrib id="A2" contrib-type="author">
        <name>
          <surname>Lafitte</surname>
          <given-names>Frédéric</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <email>flafitte@ulb.ac.be</email>
      </contrib>
      <contrib id="A3" contrib-type="author">
        <name>
          <surname>Bontempi</surname>
          <given-names>Gianluca</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <email>gbonte@ulb.ac.be</email>
      </contrib>
    </contrib-group>
    <aff id="I1"><label>1</label>Machine Learning Group, Computer Science Department, Faculty of Science, Université Libre de Bruxelles, 1050 Brussels, Belgium</aff>
    <pub-date pub-type="collection">
      <year>2008</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>29</day>
      <month>10</month>
      <year>2008</year>
    </pub-date>
    <volume>9</volume>
    <fpage>461</fpage>
    <lpage>461</lpage>
    <ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2105/9/461"/>
    <history>
      <date date-type="received">
        <day>2</day>
        <month>7</month>
        <year>2008</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>10</month>
        <year>2008</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2008 Meyer et al; licensee BioMed Central Ltd.</copyright-statement>
      <copyright-year>2008</copyright-year>
      <copyright-holder>Meyer et al; licensee BioMed Central Ltd.</copyright-holder>
      <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0">
        <p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p>
        <!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>
               Meyer
               E
               Patrick
               
               pmeyer@ulb.ac.be
            </dc:author><dc:title>
            minet: A R/Bioconductor Package for Inferring Large Transcriptional Networks Using Mutual Information
         </dc:title><dc:date>2008</dc:date><dcterms:bibliographicCitation>BMC Bioinformatics 9(1): 461-. (2008)</dcterms:bibliographicCitation><dc:identifier type="sici">1471-2105(2008)9:1&#x0003c;461&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1471-2105</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>-->
      </license>
    </permissions>
    <abstract>
      <sec>
        <title>Results</title>
        <p>This paper presents the R/Bioconductor package <italic>minet </italic>(version 1.1.6) which provides a set of functions to infer mutual information networks from a dataset. Once fed with a microarray dataset, the package returns a network where nodes denote genes, edges model statistical dependencies between genes and the weight of an edge quantifies the statistical evidence of a specific (e.g transcriptional) gene-to-gene interaction. Four different entropy estimators are made available in the package <italic>minet </italic>(empirical, Miller-Madow, Schurmann-Grassberger and shrink) as well as four different inference methods, namely relevance networks, ARACNE, CLR and MRNET. Also, the package integrates accuracy assessment tools, like F-scores, PR-curves and ROC-curves in order to compare the inferred network with a reference one.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p>The package <italic>minet </italic>provides a series of tools for inferring transcriptional networks from microarray data. It is freely available from the Comprehensive R Archive Network (CRAN) as well as from the Bioconductor website.</p>
      </sec>
    </abstract>
  </article-meta>
</front>
<body>
  <sec>
    <title>Background</title>
    <p>Modelling transcriptional interactions by large networks of interacting elements and determining how these interactions can be effectively learned from measured expression data are two important issues in system biology [<xref ref-type="bibr" rid="B1">1</xref>]. It should be noted that by focusing only on transcript data, the inferred network should not be considered as a proper biochemical regulatory network, but rather as a gene-to-gene network where many physical connections between macromolecules might be hidden by short-cuts. In spite of some evident limitations the bioinformatics community made important advances in this domain over the last few years [<xref ref-type="bibr" rid="B2">2</xref>,<xref ref-type="bibr" rid="B3">3</xref>]. In particular, mutual information networks have been succesfully applied to transcriptional network inference [<xref ref-type="bibr" rid="B4">4</xref>-<xref ref-type="bibr" rid="B6">6</xref>]. Such methods, which typically rely on the estimation of mutual information between all pairs of variables, have recently held the attention of the bioinformatics community for the inference of very large networks (up to several thousands nodes) [<xref ref-type="bibr" rid="B4">4</xref>,<xref ref-type="bibr" rid="B7">7</xref>-<xref ref-type="bibr" rid="B9">9</xref>].</p>
    <p>R is a widely used open source language and environment for statistical computing and graphics [<xref ref-type="bibr" rid="B10">10</xref>] which has become a <italic>de-facto </italic>standard in statistical modeling, data analysis, biostatistics and machine learning [<xref ref-type="bibr" rid="B11">11</xref>]. An important feature of the R environment is that it integrates generic data analysis and visualization functionalities with off-the-shelf packages implementing the latest advances in computational statistics. Bioconductor is an open source and open development software project for the analysis and comprehension of genomic data [<xref ref-type="bibr" rid="B12">12</xref>] mainly based on the R programming language. This paper introduces the new R and Bioconductor package <italic>minet</italic>, where the acronym stands for <italic>Mutual Information NETwork inference</italic>. This package is freely available on the R CRAN package resource [<xref ref-type="bibr" rid="B10">10</xref>] as well as on the Bioconductor website [<xref ref-type="bibr" rid="B12">12</xref>].</p>
  </sec>
  <sec>
    <title>1 Mutual information networks</title>
    <p>Mutual information networks are a subcategory of network inference methods. The rationale of this family of methods is to infer a link between a couple of nodes if it has a high score based on mutual information [<xref ref-type="bibr" rid="B9">9</xref>].</p>
    <p>Mutual informaton network inference proceeds in two steps. The first step is the computation of the mutual information matrix (MIM), a square matrix whose <italic>i, j</italic>-th element</p>
    <p>
      <disp-formula id="bmcM1"><label>(1)</label><italic>M I M</italic><sub><italic>ij </italic></sub>= <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>; <italic>X</italic><sub><italic>j</italic></sub>)</disp-formula>
    </p>
    <p>is the mutual information between <italic>X</italic><sub><italic>i </italic></sub>and <italic>X</italic><sub><italic>j</italic></sub>, where <italic>X</italic><sub><italic>i </italic></sub>∈ <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M1" name="1471-2105-9-461-i1" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula>, <italic>i </italic>= 1,...,<italic>n</italic>, is a discrete random variable denoting the expression level of the <italic>i</italic>th gene. The second step is the computation of an edge score for each pair of nodes by an inference algorithm that takes the MIM matrix as input.</p>
    <p>The adoption of mutual information in network inference tasks can be traced back to the Chow and Liu's tree algorithm [<xref ref-type="bibr" rid="B13">13</xref>,<xref ref-type="bibr" rid="B14">14</xref>]. Mutual information provides a natural generalization of the correlation since it is a non-linear measure of dependency. Hence with mutual information generalized correlation networks (relevance networks [<xref ref-type="bibr" rid="B7">7</xref>]) and also conditional independence graphs (e.g. ARACNE [<xref ref-type="bibr" rid="B8">8</xref>]) can be built. An advantage of these methods is their ability to deal with up to several thousands of variables also in the presence of a limited number of samples. This is made possible by the fact that the MIM computation requires only <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M2" name="1471-2105-9-461-i2" overflow="scroll"><mml:semantics><mml:mrow><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:semantics></mml:math></inline-formula> estimations of a bivariate mutual information term. Since each bivariate estimation can be computed fastly and is low variant also for a small number of samples, this family of methods is adapted for dealing with microarray data. Note that since mutual information is a symmetric measure, it is not possible to derive the direction of an edge using a mutual information network inference technique. Notwithstanding the orientation of the edges can be obtained by using algorithms like IC which are well known in the graphical modelling community [<xref ref-type="bibr" rid="B15">15</xref>].</p>
    <sec>
      <title>1.1 Relevance Network</title>
      <p>The relevance network approach [<xref ref-type="bibr" rid="B7">7</xref>] has been introduced in gene clustering and was successfully applied to infer relationships between RNA expressions and chemotherapeutic susceptibility [<xref ref-type="bibr" rid="B6">6</xref>]. The approach consists in inferring a genetic network where a pair of genes {<italic>X</italic><sub><italic>i</italic></sub>, <italic>X</italic><sub><italic>j</italic></sub>} is linked by an edge if the mutual information <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>; <italic>X</italic><sub><italic>j</italic></sub>) is larger than a given threshold <italic>I</italic><sub>0</sub>. The complexity of the method is <italic>O</italic>(<italic>n</italic><sup>2</sup>) since all pairwise interactions are considered.</p>
      <p>Note that this method does not eliminate all the indirect interactions between genes. For example, if gene <italic>X</italic><sub>1 </sub>regulates both gene <italic>X</italic><sub>2 </sub>and gene <italic>X</italic><sub>3</sub>, this would cause a high mutual information between the pairs {<italic>X</italic><sub>1</sub>, <italic>X</italic><sub>2</sub>}, {<italic>X</italic><sub>1</sub>, <italic>X</italic><sub>3</sub>} and {<italic>X</italic><sub>2</sub>, <italic>X</italic><sub>3</sub>}. As a consequence, the algorithm will set an edge between <italic>X</italic><sub>2 </sub>and <italic>X</italic><sub>3 </sub>although these two genes interact only through gene <italic>X</italic><sub>1</sub>.</p>
    </sec>
    <sec>
      <title>1.2 CLR Algorithm</title>
      <p>The CLR algorithm [<xref ref-type="bibr" rid="B4">4</xref>] is an extension of the relevance network approach. This algorithm computes the mutual information for each pair of genes and derives a score related to the empirical distribution of the MI values. In particular, instead of considering the information <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>; <italic>X</italic><sub><italic>j</italic></sub>) between genes <italic>X</italic><sub><italic>i </italic></sub>and <italic>X</italic><sub><italic>j</italic></sub>, it takes into account the score <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M3" name="1471-2105-9-461-i3" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>z</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:semantics></mml:math></inline-formula> where</p>
      <p>
        <disp-formula id="bmcM2">
          <label>(2)</label>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M4" name="1471-2105-9-461-i4" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:msub>
                  <mml:mi>z</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mi>max</mml:mi>
                <mml:mo>⁡</mml:mo>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mrow>
                    <mml:mn>0</mml:mn>
                    <mml:mo>,</mml:mo>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:mi>I</mml:mi>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:msub>
                          <mml:mi>X</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:mo>;</mml:mo>
                        <mml:msub>
                          <mml:mi>X</mml:mi>
                          <mml:mi>j</mml:mi>
                        </mml:msub>
                        <mml:mo stretchy="false">)</mml:mo>
                        <mml:mo>−</mml:mo>
                        <mml:msub>
                          <mml:mi>μ</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>σ</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                    </mml:mfrac>
                  </mml:mrow>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>and <italic>μ</italic><sub><italic>i </italic></sub>and <italic>σ</italic><sub><italic>i </italic></sub>are respectively the sample mean and standard deviation of the empirical distribution of the values <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>, <italic>X</italic><sub><italic>k</italic></sub>), <italic>k </italic>= 1,...,<italic>n</italic>. The CLR algorithm was successfully applied to decipher the <italic>E. Coli </italic>TRN [<xref ref-type="bibr" rid="B4">4</xref>]. CLR has a complexity in <italic>O</italic>(<italic>n</italic><sup>2</sup>) once the MIM is computed.</p>
    </sec>
    <sec>
      <title>1.3 ARACNE</title>
      <p>The Algorithm for the Reconstruction of Accurate Cellular Networks (ARACNE) [<xref ref-type="bibr" rid="B8">8</xref>] is based on the Data Processing Inequality [<xref ref-type="bibr" rid="B16">16</xref>]. This inequality states that, if gene <italic>X</italic><sub>1 </sub>interacts with gene <italic>X</italic><sub>3 </sub>through gene <italic>X</italic><sub>2</sub>, then</p>
      <p>
        <disp-formula><italic>I</italic>(<italic>X</italic><sub>1</sub>; <italic>X</italic><sub>3</sub>) ≤ min (<italic>I</italic>(<italic>X</italic><sub>1</sub>; <italic>X</italic><sub>2</sub>), <italic>I</italic>(<italic>X</italic><sub>2</sub>; <italic>X</italic><sub>3</sub>)).</disp-formula>
      </p>
      <p>ARACNE starts by assigning to each pair of nodes a weight equal to the mutual information. Then, as in relevance networks, all edges for which <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>; <italic>X</italic><sub><italic>j</italic></sub>) &lt;<italic>I</italic><sub>0 </sub>are removed, with <italic>I</italic><sub>0 </sub>a given threshold. Eventually, the weakest edge of each triplet is interpreted as an indirect interaction and is removed if the difference between the two lowest weights is above a threshold <italic>W</italic><sub>0</sub>. Note that by increasing <italic>I</italic><sub>0 </sub>the number of inferred edges is decreased while the opposite effect is obtained by increasing <italic>W</italic><sub>0</sub>.</p>
      <p>If the network is a tree and only pairwise interactions are present, the method guarantees the reconstruction of the original network, once it is provided with the exact MIM. ARACNE's complexity is <italic>O</italic>(<italic>n</italic><sup>3</sup>) since the algorithm considers all triplets of genes. In [<xref ref-type="bibr" rid="B8">8</xref>] the method was able to recover components of the TRN in mammalian cells and outperformed Bayesian networks and relevance networks on several inference tasks [<xref ref-type="bibr" rid="B8">8</xref>].</p>
    </sec>
    <sec>
      <title>1.4 MRNET</title>
      <p>MRNET [<xref ref-type="bibr" rid="B9">9</xref>] infers a network using the maximum relevance/minimum redundancy (MRMR) feature selection method [<xref ref-type="bibr" rid="B17">17</xref>,<xref ref-type="bibr" rid="B18">18</xref>]. The idea consists in performing a series of supervised MRMR gene selection procedures where each gene in turn plays the role of the target output.</p>
      <p>The MRMR method has been introduced in [<xref ref-type="bibr" rid="B17">17</xref>,<xref ref-type="bibr" rid="B18">18</xref>] together with a best-first search strategy for performing filter selection in supervised learning problems. Consider a supervised learning task where the output is denoted by <italic>Y </italic>and <italic>V </italic>is the set of input variables. The method ranks the set <italic>V </italic>of inputs according to a score that is the difference between the mutual information with the output variable <italic>Y </italic>(maximum relevance) and the average mutual information with all the previously ranked variables (minimum redundancy). The rationale is that direct interactions (i.e. the most informative variables to the target <italic>Y</italic>) should be well ranked whereas indirect interactions (i.e. the ones with redundant information with the direct ones) should be badly ranked by the method. The greedy search starts by selecting the variable <italic>X</italic><sub><italic>i </italic></sub>having the highest mutual information to the target <italic>Y</italic>. The second selected variable <italic>X</italic><sub><italic>j </italic></sub>will be the one with a high information <italic>I</italic>(<italic>X</italic><sub><italic>j</italic></sub>; <italic>Y</italic>) to the target and at the same time a low information <italic>I</italic>(<italic>X</italic><sub><italic>j</italic></sub>; <italic>X</italic><sub><italic>i</italic></sub>) to the previously selected variable. In the following steps, given a set <italic>S </italic>of selected variables, the criterion updates <italic>S </italic>by choosing the variable</p>
      <p>
        <disp-formula id="bmcM3">
          <label>(3)</label>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M5" name="1471-2105-9-461-i5" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:msubsup>
                  <mml:mi>X</mml:mi>
                  <mml:mi>j</mml:mi>
                  <mml:mrow>
                    <mml:mi>M</mml:mi>
                    <mml:mi>R</mml:mi>
                    <mml:mi>M</mml:mi>
                    <mml:mi>R</mml:mi>
                  </mml:mrow>
                </mml:msubsup>
                <mml:mo>=</mml:mo>
                <mml:mi>arg</mml:mi>
                <mml:mo>⁡</mml:mo>
                <mml:munder>
                  <mml:mrow>
                    <mml:mi>max</mml:mi>
                    <mml:mo>⁡</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mi>X</mml:mi>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mo>∈</mml:mo>
                    <mml:mi>V</mml:mi>
                    <mml:mo>\</mml:mo>
                    <mml:mi>S</mml:mi>
                  </mml:mrow>
                </mml:munder>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:msub>
                  <mml:mi>u</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:msub>
                <mml:mo>−</mml:mo>
                <mml:msub>
                  <mml:mi>r</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:msub>
                <mml:mo stretchy="false">)</mml:mo>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>that maximizes the score</p>
      <p>
        <disp-formula id="bmcM4"><label>(4)</label><italic>s</italic><sub><italic>j </italic></sub>= <italic>u</italic><sub><italic>j </italic></sub>- <italic>r</italic><sub><italic>j</italic></sub>,</disp-formula>
      </p>
      <p>where <italic>u</italic><sub><italic>j </italic></sub>is a relevance term and <italic>r</italic><sub><italic>j </italic></sub>is a redundancy term. More precisely,</p>
      <p>
        <disp-formula><italic>u</italic><sub><italic>j </italic></sub>= <italic>I</italic>(<italic>X</italic><sub><italic>j</italic></sub>; <italic>Y</italic>)</disp-formula>
      </p>
      <p>is the mutual information of <italic>X</italic><sub><italic>j </italic></sub>with the target variable <italic>Y</italic>, and</p>
      <p>
        <disp-formula>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M6" name="1471-2105-9-461-i6" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:msub>
                  <mml:mi>r</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mn>1</mml:mn>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                    <mml:mi>S</mml:mi>
                    <mml:mo>|</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mstyle displaystyle="true">
                  <mml:munder>
                    <mml:mo>∑</mml:mo>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi>X</mml:mi>
                        <mml:mi>k</mml:mi>
                      </mml:msub>
                      <mml:mo>∈</mml:mo>
                      <mml:mi>S</mml:mi>
                    </mml:mrow>
                  </mml:munder>
                  <mml:mrow>
                    <mml:mi>I</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mi>X</mml:mi>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mo>;</mml:mo>
                    <mml:msub>
                      <mml:mi>X</mml:mi>
                      <mml:mi>k</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                </mml:mstyle>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>measures the average redundancy of <italic>X</italic><sub><italic>j </italic></sub>to each already selected variables <italic>X</italic><sub><italic>k </italic></sub>∈ <italic>S</italic>. At each step of the algorithm, the selected variable is expected to allow an efficient trade-off between relevance and redundancy. It has been shown in [<xref ref-type="bibr" rid="B19">19</xref>] that the MRMR criterion is an optimal "pairwise" approximation of the conditional mutual information between any two genes <italic>X</italic><sub><italic>i </italic></sub>and <italic>X</italic><sub><italic>j </italic></sub>given the set <italic>S </italic>of selected variables <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>; <italic>X</italic><sub><italic>j</italic></sub>|<italic>S</italic>).</p>
      <p>The MRNET approach consists in repeating this selection procedure for each target gene by putting <italic>Y </italic>= <italic>X</italic><sub><italic>i </italic></sub>and <italic>V </italic>= <italic>X </italic>\ {<italic>X</italic><sub><italic>i</italic></sub>}, <italic>i </italic>= 1,...,<italic>n</italic>, where <italic>X </italic>is the set of the expression levels of all genes. For each pair {<italic>X</italic><sub><italic>i</italic></sub>, <italic>X</italic><sub><italic>j</italic></sub>}, MRMR returns two (not necessarily equal) scores <italic>s</italic><sub><italic>i </italic></sub>and <italic>s</italic><sub><italic>j </italic></sub>according to (4). The score of the pair {<italic>X</italic><sub><italic>i</italic></sub>, <italic>X</italic><sub><italic>j</italic></sub>} is then computed by taking the maximum of <italic>s</italic><sub><italic>i </italic></sub>and <italic>s</italic><sub><italic>j</italic></sub>. A specific network can then be inferred by deleting all the edges whose score lies below a given threshold <italic>I</italic><sub>0 </sub>(as in relevance networks, CLR and ARACNE). Thus, the algorithm infers an edge between <italic>X</italic><sub><italic>i </italic></sub>and <italic>X</italic><sub><italic>j </italic></sub>either when <italic>X</italic><sub><italic>i </italic></sub>is a well-ranked predictor of <italic>X</italic><sub><italic>j </italic></sub>(<italic>s</italic><sub><italic>i </italic></sub>&gt; <italic>I</italic><sub>0</sub>) or when <italic>X</italic><sub><italic>j </italic></sub>is a well-ranked predictor of <italic>X</italic><sub><italic>i </italic></sub>(<italic>s</italic><sub><italic>j </italic></sub>&gt; <italic>I</italic><sub>0</sub>).</p>
      <p>An effective implementation of the best-first search for quadratic problems is available in [<xref ref-type="bibr" rid="B20">20</xref>]. This implementation demands an <italic>O</italic>(<italic>f </italic>× <italic>n</italic>) complexity for selecting <italic>f </italic>features using a best first search strategy. It follows that MRNET has an <italic>O</italic>(<italic>f </italic>× <italic>n</italic><sup>2</sup>) complexity since the feature selection step is repeated for each of the <italic>n </italic>genes. In other terms, the complexity ranges between <italic>O</italic>(<italic>n</italic><sup>2</sup>) and <italic>O</italic>(<italic>n</italic><sup>3</sup>) according to the value of <italic>f</italic>. In practice the selection of features stops once a variable obtains a negative score.</p>
      <sec>
        <title>Implementation of the inference algorithms in <italic>minet</italic></title>
        <p>All the algorithms discussed above are available in the <italic>minet </italic>package. The RELNET algorithm is implemented by simply running the command build.mim which returns the MIM matrix which can be considered as a weighted adjacency matrix of the network. CLR, ARACNE and MRNET are implemented by the commands <monospace>aracne(mim), clr(mim), mrnet(mim)</monospace> respectively that return a weighted adjacency matrix of the network.</p>
        <p>It should be noted, that the modularity of the <italic>minet </italic>package makes possible to assess network inference methods on similarity matrices other than MIM [<xref ref-type="bibr" rid="B21">21</xref>].</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>2 Mutual information estimation</title>
    <p>An information-theoretic network inference technique aims at identifying connections between two genes (variables) by estimating the amount of information common to any pair of genes. Mutual information is a measure which calculates dependencies between two discrete random variables. An important property of this measure is that it is not restricted to the identification of linear relations between the random variables [<xref ref-type="bibr" rid="B16">16</xref>].</p>
    <p>If <italic>X </italic>is a continuous random variable taking values between <italic>a </italic>and <italic>b</italic>, the interval [<italic>a, b</italic>] can be discretized by partitioning it into |<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M7" name="1471-2105-9-461-i1" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula>| subintervals, called <italic>bins</italic>, where the symbol <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M8" name="1471-2105-9-461-i1" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula> denotes the bin index vector. We use also <italic>nb</italic>(<italic>x</italic><sub><italic>k</italic></sub>) to denote the number of data points in the <italic>k</italic>th bin and the symbol <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M9" name="1471-2105-9-461-i7" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">X</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi>n</mml:mi><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:semantics></mml:math></inline-formula> to denote the number of samples. If <italic>X </italic>is a random vector each element <italic>X</italic><sub><italic>i </italic></sub>can be discretized separately into |<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M10" name="1471-2105-9-461-i8" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>| bins with index vector <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M11" name="1471-2105-9-461-i8" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>.</p>
    <p>Let <italic>X </italic>be a random vector and <italic>p </italic>a probability measure. The <italic>i, j</italic>-th element of the mutual information matrix (MIM) is defined by</p>
    <p>
      <disp-formula id="bmcM5">
        <label>(5)</label>
        <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M12" name="1471-2105-9-461-i9" overflow="scroll">
          <mml:semantics>
            <mml:mtable>
              <mml:mtr>
                <mml:mtd>
                  <mml:maligngroup/>
                  <mml:mi>M</mml:mi>
                  <mml:mi>I</mml:mi>
                  <mml:msub>
                    <mml:mi>M</mml:mi>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>j</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                  <mml:malignmark/>
                  <mml:mo>=</mml:mo>
                  <mml:mi>H</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:msub>
                    <mml:mi>X</mml:mi>
                    <mml:mi>i</mml:mi>
                  </mml:msub>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mo>+</mml:mo>
                  <mml:mi>H</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:msub>
                    <mml:mi>X</mml:mi>
                    <mml:mi>j</mml:mi>
                  </mml:msub>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mo>−</mml:mo>
                  <mml:mi>H</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:msub>
                    <mml:mi>X</mml:mi>
                    <mml:mi>i</mml:mi>
                  </mml:msub>
                  <mml:mo>,</mml:mo>
                  <mml:msub>
                    <mml:mi>X</mml:mi>
                    <mml:mi>j</mml:mi>
                  </mml:msub>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:maligngroup/>
                  <mml:mo>=</mml:mo>
                  <mml:mi>I</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:msub>
                    <mml:mi>X</mml:mi>
                    <mml:mi>i</mml:mi>
                  </mml:msub>
                  <mml:mo>;</mml:mo>
                  <mml:msub>
                    <mml:mi>X</mml:mi>
                    <mml:mi>j</mml:mi>
                  </mml:msub>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:maligngroup/>
                  <mml:mo>=</mml:mo>
                  <mml:mstyle displaystyle="true">
                    <mml:munder>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>k</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:mo>∈</mml:mo>
                        <mml:msub>
                          <mml:mi mathvariant="script">X</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                    </mml:munder>
                    <mml:mrow>
                      <mml:mstyle displaystyle="true">
                        <mml:munder>
                          <mml:mo>∑</mml:mo>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mi>k</mml:mi>
                              <mml:mi>j</mml:mi>
                            </mml:msub>
                            <mml:mo>∈</mml:mo>
                            <mml:msub>
                              <mml:mi mathvariant="script">X</mml:mi>
                              <mml:mi>j</mml:mi>
                            </mml:msub>
                          </mml:mrow>
                        </mml:munder>
                        <mml:mrow>
                          <mml:mi>p</mml:mi>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mrow>
                              <mml:msub>
                                <mml:mi>k</mml:mi>
                                <mml:mi>i</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>,</mml:mo>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mrow>
                              <mml:msub>
                                <mml:mi>k</mml:mi>
                                <mml:mi>j</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo stretchy="false">)</mml:mo>
                          <mml:mi>log</mml:mi>
                          <mml:mo>⁡</mml:mo>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mrow>
                              <mml:mfrac>
                                <mml:mrow>
                                  <mml:mi>p</mml:mi>
                                  <mml:mo stretchy="false">(</mml:mo>
                                  <mml:msub>
                                    <mml:mi>x</mml:mi>
                                    <mml:mrow>
                                      <mml:msub>
                                        <mml:mi>k</mml:mi>
                                        <mml:mi>i</mml:mi>
                                      </mml:msub>
                                    </mml:mrow>
                                  </mml:msub>
                                  <mml:mo>,</mml:mo>
                                  <mml:msub>
                                    <mml:mi>x</mml:mi>
                                    <mml:mrow>
                                      <mml:msub>
                                        <mml:mi>k</mml:mi>
                                        <mml:mi>j</mml:mi>
                                      </mml:msub>
                                    </mml:mrow>
                                  </mml:msub>
                                  <mml:mo stretchy="false">)</mml:mo>
                                </mml:mrow>
                                <mml:mrow>
                                  <mml:mi>p</mml:mi>
                                  <mml:mo stretchy="false">(</mml:mo>
                                  <mml:msub>
                                    <mml:mi>x</mml:mi>
                                    <mml:mrow>
                                      <mml:msub>
                                        <mml:mi>k</mml:mi>
                                        <mml:mi>i</mml:mi>
                                      </mml:msub>
                                    </mml:mrow>
                                  </mml:msub>
                                  <mml:mo stretchy="false">)</mml:mo>
                                  <mml:mi>p</mml:mi>
                                  <mml:mo stretchy="false">(</mml:mo>
                                  <mml:msub>
                                    <mml:mi>x</mml:mi>
                                    <mml:mrow>
                                      <mml:msub>
                                        <mml:mi>k</mml:mi>
                                        <mml:mi>j</mml:mi>
                                      </mml:msub>
                                    </mml:mrow>
                                  </mml:msub>
                                  <mml:mo stretchy="false">)</mml:mo>
                                </mml:mrow>
                              </mml:mfrac>
                            </mml:mrow>
                            <mml:mo>)</mml:mo>
                          </mml:mrow>
                        </mml:mrow>
                      </mml:mstyle>
                    </mml:mrow>
                  </mml:mstyle>
                  <mml:mo>,</mml:mo>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:semantics>
        </mml:math>
      </disp-formula>
    </p>
    <p>where the entropy of a random variable <italic>X </italic>is defined as</p>
    <p>
      <disp-formula id="bmcM6">
        <label>(6)</label>
        <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M13" name="1471-2105-9-461-i10" overflow="scroll">
          <mml:semantics>
            <mml:mrow>
              <mml:mi>H</mml:mi>
              <mml:mo stretchy="false">(</mml:mo>
              <mml:mi>X</mml:mi>
              <mml:mo stretchy="false">)</mml:mo>
              <mml:mo>=</mml:mo>
              <mml:mo>−</mml:mo>
              <mml:mstyle displaystyle="true">
                <mml:munder>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>k</mml:mi>
                    <mml:mo>∈</mml:mo>
                    <mml:mi mathvariant="script">X</mml:mi>
                  </mml:mrow>
                </mml:munder>
                <mml:mrow>
                  <mml:mi>p</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:msub>
                    <mml:mi>x</mml:mi>
                    <mml:mi>k</mml:mi>
                  </mml:msub>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mrow>
              </mml:mstyle>
              <mml:mi>log</mml:mi>
              <mml:mo>⁡</mml:mo>
              <mml:mi>p</mml:mi>
              <mml:mo stretchy="false">(</mml:mo>
              <mml:msub>
                <mml:mi>x</mml:mi>
                <mml:mi>k</mml:mi>
              </mml:msub>
              <mml:mo stretchy="false">)</mml:mo>
            </mml:mrow>
          </mml:semantics>
        </mml:math>
      </disp-formula>
    </p>
    <p>and <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>; <italic>X</italic><sub><italic>j</italic></sub>) is the mutual information between the random variables <italic>X</italic><sub><italic>i </italic></sub>and <italic>X</italic><sub><italic>j</italic></sub>.</p>
    <p>Hence, each mutual information calculus demands the estimation of three entropy terms (Eq. 5). A fast entropy estimation is therefore essential for an effective network inference based on MI. Entropy estimation has gained much interest in feature selection and network inference over the last decade [<xref ref-type="bibr" rid="B22">22</xref>]. Most approaches focus on reducing the bias inherent to entropy estimation. In this section, some of the fastest and most used entropy estimators are stressed. Other interesting approaches can be found in [<xref ref-type="bibr" rid="B22">22</xref>-<xref ref-type="bibr" rid="B26">26</xref>].</p>
    <sec>
      <title>2.1 Empirical and Miller-Madow corrected estimators</title>
      <p>The empirical estimator (also called "plug-in", "maximum likelihood" or "naïve", see [<xref ref-type="bibr" rid="B23">23</xref>]) is the entropy of the empirical distribution.</p>
      <p>
        <disp-formula id="bmcM7">
          <label>(7)</label>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M14" name="1471-2105-9-461-i11" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:msup>
                  <mml:mover accent="true">
                    <mml:mi>H</mml:mi>
                    <mml:mo>^</mml:mo>
                  </mml:mover>
                  <mml:mrow>
                    <mml:mi>e</mml:mi>
                    <mml:mi>m</mml:mi>
                    <mml:mi>p</mml:mi>
                  </mml:mrow>
                </mml:msup>
                <mml:mo>=</mml:mo>
                <mml:mo>−</mml:mo>
                <mml:mstyle displaystyle="true">
                  <mml:munder>
                    <mml:mo>∑</mml:mo>
                    <mml:mrow>
                      <mml:mi>k</mml:mi>
                      <mml:mo>∈</mml:mo>
                      <mml:mi mathvariant="script">X</mml:mi>
                    </mml:mrow>
                  </mml:munder>
                  <mml:mrow>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:mi>n</mml:mi>
                        <mml:mi>b</mml:mi>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:msub>
                          <mml:mi>x</mml:mi>
                          <mml:mrow>
                            <mml:mi>k</mml:mi>
                            <mml:mo stretchy="false">)</mml:mo>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mi>m</mml:mi>
                    </mml:mfrac>
                  </mml:mrow>
                </mml:mstyle>
                <mml:mi>log</mml:mi>
                <mml:mo>⁡</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>n</mml:mi>
                    <mml:mi>b</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>k</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                  <mml:mi>m</mml:mi>
                </mml:mfrac>
                <mml:mo>.</mml:mo>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>Note that, because of the convexity of the logarithmic function, an underestimate of <italic>p</italic>(<italic>x</italic><sub><italic>k</italic></sub>) causes an error on <italic>H</italic>(<italic>X </italic>= <italic>x</italic><sub><italic>k</italic></sub>) that is larger than the one given by an overestimation of the same quantity. As a result, entropy estimators are biased downwards, that is</p>
      <p>
        <disp-formula id="bmcM8">
          <label>(8)</label>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M15" name="1471-2105-9-461-i12" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:mi>E</mml:mi>
                <mml:mo stretchy="false">[</mml:mo>
                <mml:msup>
                  <mml:mover accent="true">
                    <mml:mi>H</mml:mi>
                    <mml:mo>^</mml:mo>
                  </mml:mover>
                  <mml:mrow>
                    <mml:mi>e</mml:mi>
                    <mml:mi>m</mml:mi>
                    <mml:mi>p</mml:mi>
                  </mml:mrow>
                </mml:msup>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:mi>p</mml:mi>
                <mml:mi>X</mml:mi>
                <mml:mo stretchy="false">)</mml:mo>
                <mml:mo stretchy="false">]</mml:mo>
                <mml:mo>≤</mml:mo>
                <mml:mi>H</mml:mi>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:mi>p</mml:mi>
                <mml:mi>X</mml:mi>
                <mml:mo stretchy="false">)</mml:mo>
                <mml:mo>.</mml:mo>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>It has been shown that the variance of the empirical estimator is upper-bounded by <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M16" name="1471-2105-9-461-i13" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>e</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mi>m</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:semantics></mml:math></inline-formula> which depends only on the number of samples whereas the asymptotic bias of the estimate <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M17" name="1471-2105-9-461-i14" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>e</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">X</mml:mi><mml:mo>|</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>m</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math></inline-formula> depends also on the number of bins |<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M18" name="1471-2105-9-461-i1" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula>| [<xref ref-type="bibr" rid="B23">23</xref>]. As |<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M19" name="1471-2105-9-461-i1" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula>| ≫ <italic>m</italic>, this estimator can still have a low variance but the bias can become very large [<xref ref-type="bibr" rid="B23">23</xref>].</p>
      <p>The Miller-Madow correction is then given by the following formula which is the empirical entropy corrected by the asymptotic bias,</p>
      <p>
        <disp-formula id="bmcM9">
          <label>(9)</label>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M20" name="1471-2105-9-461-i15" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:msup>
                  <mml:mover accent="true">
                    <mml:mi>H</mml:mi>
                    <mml:mo>^</mml:mo>
                  </mml:mover>
                  <mml:mrow>
                    <mml:mi>m</mml:mi>
                    <mml:mi>m</mml:mi>
                  </mml:mrow>
                </mml:msup>
                <mml:mo>=</mml:mo>
                <mml:msup>
                  <mml:mover accent="true">
                    <mml:mi>H</mml:mi>
                    <mml:mo>^</mml:mo>
                  </mml:mover>
                  <mml:mrow>
                    <mml:mi>e</mml:mi>
                    <mml:mi>m</mml:mi>
                    <mml:mi>p</mml:mi>
                  </mml:mrow>
                </mml:msup>
                <mml:mo>+</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                    <mml:mi mathvariant="script">X</mml:mi>
                    <mml:mo>|</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>2</mml:mn>
                    <mml:mi>m</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>.</mml:mo>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>where |<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M21" name="1471-2105-9-461-i1" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula>| is the number of bins with non-zero probability. This correction, while adding no computational cost to the empirical estimator, reduces the bias without changing variance. As a result, the Miller-Madow estimator is often preferred to the naive empirical entropy estimator.</p>
    </sec>
    <sec>
      <title>2.2 Shrink entropy estimator</title>
      <p>The rationale of the shrink estimator, [<xref ref-type="bibr" rid="B27">27</xref>], is to combine two different estimators, one with low variance and one with low bias, by using a weighting factor <italic>λ </italic>∈ [0,1]</p>
      <p>
        <disp-formula id="bmcM10">
          <label>(10)</label>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M22" name="1471-2105-9-461-i16" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:msub>
                  <mml:mover accent="true">
                    <mml:mi>p</mml:mi>
                    <mml:mo>^</mml:mo>
                  </mml:mover>
                  <mml:mi>λ</mml:mi>
                </mml:msub>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:msub>
                  <mml:mi>x</mml:mi>
                  <mml:mi>k</mml:mi>
                </mml:msub>
                <mml:mo stretchy="false">)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mi>λ</mml:mi>
                <mml:mfrac>
                  <mml:mn>1</mml:mn>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                    <mml:mi mathvariant="script">X</mml:mi>
                    <mml:mo>|</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>+</mml:mo>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:mn>1</mml:mn>
                <mml:mo>−</mml:mo>
                <mml:mi>λ</mml:mi>
                <mml:mo stretchy="false">)</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>n</mml:mi>
                    <mml:mi>b</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>k</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                  <mml:mi>m</mml:mi>
                </mml:mfrac>
                <mml:mo>.</mml:mo>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>Shrinkage is a general technique to improve an estimator for a small sample size [<xref ref-type="bibr" rid="B3">3</xref>]. As the value of <italic>λ </italic>tends to one, the estimated entropy is moved toward the maximal entropy (uniform probability) whereas when <italic>λ </italic>is zero the estimated entropy tends to the value of the empirical one.</p>
      <p>Let <italic>λ</italic>* be the value minimizing the mean square function, see [<xref ref-type="bibr" rid="B27">27</xref>],</p>
      <p>
        <disp-formula id="bmcM11">
          <label>(11)</label>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M23" name="1471-2105-9-461-i17" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:mi>λ</mml:mi>
                <mml:mo>*</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mi>arg</mml:mi>
                <mml:mo>⁡</mml:mo>
                <mml:munder>
                  <mml:mrow>
                    <mml:mi>min</mml:mi>
                    <mml:mo>⁡</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>λ</mml:mi>
                    <mml:mo>∈</mml:mo>
                    <mml:mo stretchy="false">[</mml:mo>
                    <mml:mn>0</mml:mn>
                    <mml:mo>,</mml:mo>
                    <mml:mn>1</mml:mn>
                    <mml:mo stretchy="false">]</mml:mo>
                  </mml:mrow>
                </mml:munder>
                <mml:mi>E</mml:mi>
                <mml:mrow>
                  <mml:mo>[</mml:mo>
                  <mml:mrow>
                    <mml:mstyle displaystyle="true">
                      <mml:munder>
                        <mml:mo>∑</mml:mo>
                        <mml:mrow>
                          <mml:mi>k</mml:mi>
                          <mml:mo>∈</mml:mo>
                          <mml:mi mathvariant="script">X</mml:mi>
                        </mml:mrow>
                      </mml:munder>
                      <mml:mrow>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:msub>
                          <mml:mover accent="true">
                            <mml:mi>p</mml:mi>
                            <mml:mo>^</mml:mo>
                          </mml:mover>
                          <mml:mi>λ</mml:mi>
                        </mml:msub>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:msub>
                          <mml:mi>x</mml:mi>
                          <mml:mi>k</mml:mi>
                        </mml:msub>
                        <mml:mo stretchy="false">)</mml:mo>
                      </mml:mrow>
                    </mml:mstyle>
                    <mml:mo>−</mml:mo>
                    <mml:mi>p</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>k</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:msup>
                      <mml:mo stretchy="false">)</mml:mo>
                      <mml:mn>2</mml:mn>
                    </mml:msup>
                  </mml:mrow>
                  <mml:mo>]</mml:mo>
                </mml:mrow>
                <mml:mo>.</mml:mo>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>It has been shown in [<xref ref-type="bibr" rid="B28">28</xref>] that the optimal <italic>λ </italic>is given by</p>
      <p>
        <disp-formula id="bmcM12">
          <label>(12)</label>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M24" name="1471-2105-9-461-i18" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:mi>λ</mml:mi>
                <mml:mo>*</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                    <mml:mi mathvariant="script">X</mml:mi>
                    <mml:mo>|</mml:mo>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msup>
                      <mml:mi>m</mml:mi>
                      <mml:mn>2</mml:mn>
                    </mml:msup>
                    <mml:mo>−</mml:mo>
                    <mml:mstyle displaystyle="true">
                      <mml:msub>
                        <mml:mo>∑</mml:mo>
                        <mml:mrow>
                          <mml:mi>k</mml:mi>
                          <mml:mo>∈</mml:mo>
                          <mml:mi mathvariant="script">X</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mrow>
                        <mml:mi>n</mml:mi>
                        <mml:mi>b</mml:mi>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mo stretchy="false">(</mml:mo>
                            <mml:msub>
                              <mml:mi>x</mml:mi>
                              <mml:mi>k</mml:mi>
                            </mml:msub>
                            <mml:mo stretchy="false">)</mml:mo>
                          </mml:mrow>
                          <mml:mn>2</mml:mn>
                        </mml:msup>
                      </mml:mrow>
                    </mml:mstyle>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>m</mml:mi>
                    <mml:mo>−</mml:mo>
                    <mml:mn>1</mml:mn>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mo>|</mml:mo>
                    <mml:mi mathvariant="script">X</mml:mi>
                    <mml:mtext>|</mml:mtext>
                    <mml:mstyle displaystyle="true">
                      <mml:msub>
                        <mml:mo>∑</mml:mo>
                        <mml:mrow>
                          <mml:mi>k</mml:mi>
                          <mml:mo>∈</mml:mo>
                          <mml:mi mathvariant="script">X</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mrow>
                        <mml:mi>n</mml:mi>
                        <mml:mi>b</mml:mi>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mo stretchy="false">(</mml:mo>
                            <mml:msub>
                              <mml:mi>x</mml:mi>
                              <mml:mi>k</mml:mi>
                            </mml:msub>
                            <mml:mo stretchy="false">)</mml:mo>
                          </mml:mrow>
                          <mml:mn>2</mml:mn>
                        </mml:msup>
                      </mml:mrow>
                    </mml:mstyle>
                    <mml:mo>−</mml:mo>
                    <mml:msup>
                      <mml:mi>m</mml:mi>
                      <mml:mn>2</mml:mn>
                    </mml:msup>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>.</mml:mo>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>
        <disp-formula id="bmcM13">
          <label>(13)</label>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M25" name="1471-2105-9-461-i19" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:msup>
                  <mml:mover accent="true">
                    <mml:mi>H</mml:mi>
                    <mml:mo>^</mml:mo>
                  </mml:mover>
                  <mml:mrow>
                    <mml:mi>s</mml:mi>
                    <mml:mi>h</mml:mi>
                    <mml:mi>r</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>n</mml:mi>
                    <mml:mi>k</mml:mi>
                  </mml:mrow>
                </mml:msup>
                <mml:mo>=</mml:mo>
                <mml:mo>−</mml:mo>
                <mml:mstyle displaystyle="true">
                  <mml:munder>
                    <mml:mo>∑</mml:mo>
                    <mml:mrow>
                      <mml:mi>k</mml:mi>
                      <mml:mo>∈</mml:mo>
                      <mml:mi mathvariant="script">X</mml:mi>
                    </mml:mrow>
                  </mml:munder>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mover accent="true">
                        <mml:mi>p</mml:mi>
                        <mml:mo>^</mml:mo>
                      </mml:mover>
                      <mml:mi>λ</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>k</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mi>log</mml:mi>
                    <mml:mo>⁡</mml:mo>
                    <mml:msub>
                      <mml:mover accent="true">
                        <mml:mi>p</mml:mi>
                        <mml:mo>^</mml:mo>
                      </mml:mover>
                      <mml:mi>λ</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mrow>
                        <mml:mi>k</mml:mi>
                        <mml:mo stretchy="false">)</mml:mo>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:mstyle>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
    </sec>
    <sec>
      <title>2.3 The Schurmann-Grassberger Estimator</title>
      <p>The Dirichlet distribution can be used in order to estimate the entropy of a discrete random variable. The Dirichlet distribution is the multivariate generalization of the beta distribution. It is also the conjugate prior of the multinomial distribution in Bayesian statistics. More precisely, the density of a Dirichlet distribution takes the following form</p>
      <p>
        <disp-formula id="bmcM14">
          <label>(14)</label>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M26" name="1471-2105-9-461-i20" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:mi>f</mml:mi>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:mi>X</mml:mi>
                <mml:mo>;</mml:mo>
                <mml:mi>β</mml:mi>
                <mml:mo stretchy="false">)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mstyle displaystyle="true">
                      <mml:msub>
                        <mml:mo>∏</mml:mo>
                        <mml:mrow>
                          <mml:mi>k</mml:mi>
                          <mml:mo>∈</mml:mo>
                          <mml:mi mathvariant="script">X</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mrow>
                        <mml:mi>Γ</mml:mi>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:msub>
                          <mml:mi>β</mml:mi>
                          <mml:mi>k</mml:mi>
                        </mml:msub>
                        <mml:mo stretchy="false">)</mml:mo>
                      </mml:mrow>
                    </mml:mstyle>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>Γ</mml:mi>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mrow>
                        <mml:mstyle displaystyle="true">
                          <mml:msub>
                            <mml:mo>∑</mml:mo>
                            <mml:mrow>
                              <mml:mi>k</mml:mi>
                              <mml:mo>∈</mml:mo>
                              <mml:mi mathvariant="script">X</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mi>β</mml:mi>
                              <mml:mi>k</mml:mi>
                            </mml:msub>
                          </mml:mrow>
                        </mml:mstyle>
                      </mml:mrow>
                      <mml:mo>)</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mstyle displaystyle="true">
                  <mml:munder>
                    <mml:mo>∏</mml:mo>
                    <mml:mrow>
                      <mml:mi>k</mml:mi>
                      <mml:mo>∈</mml:mo>
                      <mml:mi mathvariant="script">X</mml:mi>
                    </mml:mrow>
                  </mml:munder>
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mi>x</mml:mi>
                      <mml:mi>k</mml:mi>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>β</mml:mi>
                          <mml:mrow>
                            <mml:mi>k</mml:mi>
                            <mml:mo>−</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msubsup>
                  </mml:mrow>
                </mml:mstyle>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>where <italic>β</italic><sub><italic>i </italic></sub>is the prior probability of an event <italic>x</italic><sub><italic>i </italic></sub>and Γ(·) is the gamma function, (see [<xref ref-type="bibr" rid="B25">25</xref>,<xref ref-type="bibr" rid="B27">27</xref>,<xref ref-type="bibr" rid="B29">29</xref>] for more details).</p>
      <p>In case of no a priori knowledge, the <italic>β</italic><sub><italic>k </italic></sub>are assumed to be equal (<italic>β</italic><sub><italic>k </italic></sub>= <italic>N</italic>, <italic>k </italic>∈ <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M27" name="1471-2105-9-461-i1" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula>) so as no event becomes more probable than another. Note that using a Dirichlet prior with parameters <italic>N </italic>is equivalent to adding <italic>N </italic>≥ 0 "pseudo-counts" to each bin <italic>i </italic>∈ <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M28" name="1471-2105-9-461-i1" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula>. The prior actually provides the estimator the information that |<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M29" name="1471-2105-9-461-i1" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula>|<italic>N </italic>counts have been observed in previous experiments. From that viewpoint, |<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M30" name="1471-2105-9-461-i1" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula>|<italic>N </italic>becomes the a priori sample size.</p>
      <p>The entropy of a Dirichlet distribution can be computed directly with the following equation:</p>
      <p>
        <disp-formula id="bmcM15">
          <label>(15)</label>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M31" name="1471-2105-9-461-i21" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:msup>
                  <mml:mover accent="true">
                    <mml:mi>H</mml:mi>
                    <mml:mo>^</mml:mo>
                  </mml:mover>
                  <mml:mrow>
                    <mml:mi>d</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>r</mml:mi>
                  </mml:mrow>
                </mml:msup>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:mi>X</mml:mi>
                <mml:mo stretchy="false">)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mn>1</mml:mn>
                  <mml:mrow>
                    <mml:mi>m</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mo>|</mml:mo>
                    <mml:mi mathvariant="script">X</mml:mi>
                    <mml:mo>|</mml:mo>
                    <mml:mi>N</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mstyle displaystyle="true">
                  <mml:munder>
                    <mml:mo>∑</mml:mo>
                    <mml:mrow>
                      <mml:mi>k</mml:mi>
                      <mml:mo>∈</mml:mo>
                      <mml:mtext>X</mml:mtext>
                    </mml:mrow>
                  </mml:munder>
                  <mml:mrow>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>n</mml:mi>
                    <mml:mi>b</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>k</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>+</mml:mo>
                    <mml:mi>N</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>ψ</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>m</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mo>|</mml:mo>
                    <mml:mi mathvariant="script">X</mml:mi>
                    <mml:mo>|</mml:mo>
                    <mml:mi>N</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mn>1</mml:mn>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:mi>ψ</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>n</mml:mi>
                    <mml:mi>b</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mi>x</mml:mi>
                      <mml:mi>k</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>+</mml:mo>
                    <mml:mi>N</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mn>1</mml:mn>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                </mml:mstyle>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>with <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M32" name="1471-2105-9-461-i22" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>ψ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mi>Γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math></inline-formula> the digamma function.</p>
      <p>Various choices of prior parameters has been proposed in the literature [<xref ref-type="bibr" rid="B29">29</xref>-<xref ref-type="bibr" rid="B31">31</xref>]. Schurmann and Grassberger have proposed the prior <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M33" name="1471-2105-9-461-i23" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">X</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math></inline-formula>[<xref ref-type="bibr" rid="B32">32</xref>] that has been retained in the package.</p>
      <sec>
        <title>Implementation of estimators in <italic>minet</italic></title>
        <p>The mutual information matrix is estimated by using the function build.mim(dataset, estimator). This function returns a matrix of paired mutual informations computed in nats (base <italic>e</italic>) and takes two arguments:</p>
        <p>1. the data frame dataset which stores the gene expression dataset or a generic dataset where columns contain variables/features and rows contain outcomes/samples</p>
        <p>2. the string mi, that denotes the routine used to perform mutual information estimator.</p>
        <p>The package makes available four estimation routines : <monospace>"mi.empirical", "mi.shrink", "mi.sg","mi.mm"</monospace> (default:<monospace>"mi.empirical"</monospace>) each referring to the estimators technique explained above.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Discretization methods</title>
    <p>All the estimators discussed in the previous section have been designed for discrete variables. If the random variable <italic>X </italic>is continuous and takes values comprised between <italic>a </italic>and <italic>b</italic>, it is then required to partition the interval [<italic>a, b</italic>] into |<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M34" name="1471-2105-9-461-i1" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula>| sub-intervals in order to adopt a discrete entropy estimator. The two most used discretizing algorithm are the equal width and the equal frequency quantization. These are explained in the next sections. Other discretization methods can be found in [<xref ref-type="bibr" rid="B33">33</xref>-<xref ref-type="bibr" rid="B35">35</xref>].</p>
    <sec>
      <title>3.1 Equal Width</title>
      <p>The principle of the equal width discretization is to divide the range [<italic>a</italic><sub><italic>i</italic></sub>, <italic>b</italic><sub><italic>i</italic></sub>] of each variable <italic>X</italic><sub><italic>i</italic></sub>, <italic>i </italic>∈ {1, 2,...,<italic>n</italic>} in the dataset into |<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M35" name="1471-2105-9-461-i8" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>| sub-intervals of equal size: <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M36" name="1471-2105-9-461-i24" overflow="scroll"><mml:semantics><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:mo stretchy="false">[</mml:mo><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:mo stretchy="false">[</mml:mo><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>ε</mml:mi><mml:mo stretchy="false">[</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula>. Note that an <italic>ε </italic>is added in the last interval in order to include the maximal value in one of the |<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M37" name="1471-2105-9-461-i8" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>| bins. This discretization scheme has a <italic>O</italic>(<italic>m</italic>) complexity cost (by variable).</p>
    </sec>
    <sec>
      <title>3.2 Global Equal Width</title>
      <p>The principle of the global equal width discretization is the same as the equal width (Sec. 3.1) except that the considered range [<italic>a, b</italic>] is not the range of each random variable such as in Sec. 3.1 but the range of the random vector composed of all the variables in the dataset. In other words, <italic>a </italic>and <italic>b </italic>are respectively the minimal and the maximal value of the dataset.</p>
    </sec>
    <sec>
      <title>3.3 Equal Frequency</title>
      <p>The equal frequency discretization scheme consists in partitioning the range [<italic>a</italic><sub><italic>i</italic></sub>, <italic>b</italic><sub><italic>i</italic></sub>] of each variable <italic>X</italic><sub><italic>i </italic></sub>in the dataset into |<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M38" name="1471-2105-9-461-i8" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>| intervals, each having the same number <italic>m</italic>/|<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M39" name="1471-2105-9-461-i8" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>| of data points points. As a result, the size of each interval can be different. Note that if the |<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M40" name="1471-2105-9-461-i8" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>| intervals have equal frequencies, the computation of entropy is straightforward: it is log <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M41" name="1471-2105-9-461-i25" overflow="scroll"><mml:semantics><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math></inline-formula>. However, there can be more than <italic>m</italic>/|<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M42" name="1471-2105-9-461-i8" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>| identical values in a vector of measurements. In such case, one of the bins will be more dense than the others and the resulting entropy will be different of log <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M43" name="1471-2105-9-461-i25" overflow="scroll"><mml:semantics><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math></inline-formula>. It should be noted that this discretization is reported in some papers as one of the most efficient method (e.g. for naive Bayes classification) [<xref ref-type="bibr" rid="B35">35</xref>].</p>
      <sec>
        <title>Implementation of discretization strategies in <italic>minet</italic></title>
        <p>The discretization is performed in <italic>minet </italic>by the function</p>
        <p>discretize(dataset, disc = "equalfreq", nbins = sqrt(nrow(dataset)))</p>
        <p>where</p>
        <p>• dataset is the dataset to be discretized</p>
        <p>• disc is a string which can take three values: <monospace>"equalfreq" "equalwidth" "globalequalwidth"</monospace>(default is <monospace>" equalfreq"</monospace>).</p>
        <p>• nbins, the number of bins to be used for discretization, which is by default set to <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M44" name="1471-2105-9-461-i26" overflow="scroll"><mml:semantics><mml:mrow><mml:msqrt><mml:mi>m</mml:mi></mml:msqrt></mml:mrow></mml:semantics></mml:math></inline-formula> with <italic>m </italic>is the number of samples [<xref ref-type="bibr" rid="B35">35</xref>]. Note that there are functions used by the built-in R hist() function that can be used here such as <monospace>nclass. FD(dataset), nclass. scott(dataset)</monospace> and <monospace>nclass. Sturges(dataset).</monospace></p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Assessment of the network inference algorithm</title>
    <p>A network inference problem can be seen as a binary decision problem where the inference algorithm plays the role of a classifier: for each pair of nodes, the algorithm either returns an edge or not. Each pair of nodes can thus be assigned a positive label (an edge) or a negative one (no edge).</p>
    <p>A positive label (an edge) predicted by the algorithm is considered as a true positive (TP) or as a false positive (FP) depending on the presence or not of the corresponding edge in the underlying true network, respectively. Analogously, a negative label is considered as a true negative (TN) or a false negative (FN) depending on whether the corresponding edge is present or not in the underlying true network, respectively. Note that all mutual information network inference methods use a threshold value in order to delete the arcs having a too low score. Hence, for each treshold value, a confusion matrix can be computed.</p>
    <sec>
      <title>4.1 ROC curves</title>
      <p>The false positive rate is defined as</p>
      <p>
        <disp-formula>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M45" name="1471-2105-9-461-i27" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:mi>F</mml:mi>
                <mml:mi>P</mml:mi>
                <mml:mi>R</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>F</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>N</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi>F</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>,</mml:mo>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>and the true positive rate as</p>
      <p>
        <disp-formula>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M46" name="1471-2105-9-461-i28" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:mi>T</mml:mi>
                <mml:mi>P</mml:mi>
                <mml:mi>R</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi>F</mml:mi>
                    <mml:mi>N</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>,</mml:mo>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>also known as recall or sensitivity.</p>
      <p>A Receiver Operating Characteristic (ROC) curve, is a graphical plot of the TPR (true positive rate) vs. FPR (false positive rate) for a binary classifier system as the threshold is varied [<xref ref-type="bibr" rid="B36">36</xref>]. A perfect classifier would yield a point in the upper left corner (having coordinates [0,1]) of the ROC space, representing 100% TPR (all true positives are found) and 0% FPR (no false positives are found). A completely random guess gives a point along the diagonal line (the so-called line of no-discrimination) which goes from the left bottom to the top right corners. Points above the diagonal line indicate good classification results, while points below the line indicate wrong results.</p>
    </sec>
    <sec>
      <title>4.2 PR curves</title>
      <p>It is generally recommended [<xref ref-type="bibr" rid="B37">37</xref>] to use receiver operator characteristic (ROC) curves when evaluating binary decision problems in order to avoid effects related to the chosen threshold. However, ROC curves can present an overly optimistic view of an algorithm's performance if there is a large skew in the class distribution, as typically encountered in transcriptional network inference because of sparseness. To tackle this problem, precision-recall (PR) curves have been cited as an alternative to ROC curves [<xref ref-type="bibr" rid="B38">38</xref>].</p>
      <p>Let the precision quantity</p>
      <p>
        <disp-formula>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M47" name="1471-2105-9-461-i29" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:mi>p</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi>F</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>,</mml:mo>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>measure the fraction of real edges among the ones classified as positive and the recall quantity</p>
      <p>
        <disp-formula>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M48" name="1471-2105-9-461-i30" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:mi>r</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mi>P</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi>F</mml:mi>
                    <mml:mi>N</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>,</mml:mo>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>also know as true positive rate (TPR), denote the fraction of real edges that are correctly inferred. These quantities depend on the threshold chosen to return a binary decision. The PR curve is a diagram which plots the precision (<italic>p</italic>) versus recall (<italic>r</italic>) for different values of the threshold on a two-dimensional coordinate system.</p>
    </sec>
    <sec>
      <title>4.3 F-Scores</title>
      <p>Note that a compact representation of the PR diagram is returned by the maximum and/or the average of the F-score quantity [<xref ref-type="bibr" rid="B39">39</xref>]:</p>
      <p>
        <disp-formula>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M49" name="1471-2105-9-461-i31" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:mi>F</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mn>2</mml:mn>
                    <mml:mi>p</mml:mi>
                    <mml:mi>r</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>r</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi>p</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>,</mml:mo>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>which is an harmonic average of precision and recall.</p>
      <p>The general formula for non-negative real <italic>β </italic>is:</p>
      <p>
        <disp-formula>
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M50" name="1471-2105-9-461-i32" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:msub>
                  <mml:mi>F</mml:mi>
                  <mml:mi>β</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mn>1</mml:mn>
                    <mml:mo>−</mml:mo>
                    <mml:mi>β</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>p</mml:mi>
                    <mml:mi>r</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>β</mml:mi>
                    <mml:mi>p</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mi>r</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>where <italic>β </italic>is a parameter denoting the weight of the recall. Two commonly used F-scores are the <italic>F</italic><sub>2</sub>-measure, which weights recall twice as much as precision, and the <italic>F</italic><sub>0.5</sub>-measure, which weights precision twice as much as recall. In transcriptional network inference, precision is often a more desirable feature than recall since it is expensive to investigate if a gene regulates another.</p>
      <sec>
        <title>Assesment functionalities in <italic>minet</italic></title>
        <p>In order to benchmark the inference methods, the package provides a number of assessment tools. The <monospace>validate(net, ref.net, steps = 50)</monospace> function allows to compare an inferred network <monospace>net</monospace> to a reference network <monospace>ref.net</monospace>, described by a Boolean adjacency matrix. The assessment process consists in removing the inferred edges having a score below a given threshold and in computing the related confusion matrix, for steps thresholds ranging from the minimum to the maximum value of edge weigths. A resulting dataframe table containing the list of all the steps confusion matrices is returned and made available for further analysis.</p>
        <p>In particular, the function <monospace>pr(table)</monospace> returns the related precisions and recalls, <monospace>rates(table)</monospace> computes true positive and false positive rates while the function <monospace>fscores(table, beta)</monospace> returns the <italic>F</italic><sub><italic>β </italic></sub>– <italic>scores</italic>. The functions <monospace>show.pr(table)</monospace> and <monospace>show.roc(table)</monospace> allow the user to plot PR-curves and ROC-curves respectively (Figure <xref ref-type="fig" rid="F3">3</xref>) from a list of confusion matrices.</p>
        <fig position="float" id="F3">
          <label>Figure 3</label>
          <caption>
            <p>Precision-Recall curves plotted with show.pr(table).</p>
          </caption>
          <graphic xlink:href="1471-2105-9-461-3"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>5 Example</title>
    <p>Once the R platform is launched, the package, its description and its vignette can be loaded using the following commands:</p>
    <p>library(minet)</p>
    <p>library(help = minet)</p>
    <p>vignette("minet")</p>
    <p>A demo script (<monospace>demo(demo)</monospace>) shows the main functionalities of the package that we describe in the following.</p>
    <p>In order to infer a network with the <italic>minet </italic>package, four steps are required:</p>
    <p>• data discretization,</p>
    <p>• MIM computation,</p>
    <p>• network inference,</p>
    <p>• normalization of the network (optional).</p>
    <p>The main function of the package is <monospace>minet</monospace> which sequentially executes the four steps mentioned above, see Figure <xref ref-type="fig" rid="F1">1</xref>).</p>
    <fig position="float" id="F1">
      <label>Figure 1</label>
      <caption>
        <p>
          <bold>The four steps in the minet function (discretization disc, mutual information matrix build.mim, inference </bold>
          <monospace>mrnet, aracne, clr </monospace>
          <bold>and normalization norm.</bold>
        </p>
      </caption>
      <graphic xlink:href="1471-2105-9-461-1"/>
    </fig>
    <p>The function <monospace>minet(dataset, method, estimator, disc, nbins)</monospace> takes the following arguments: dataset, a matrix or a dataframe containing the microarray data, method, the inference algorithm (such as ARACNE, CLR or MRNET), estimator, the entropy estimator used for the computation of mutual information (empirical, Miller-Madow, shrink, Schurmannn-Grassberger), disc the binning algorithm (i.e. equal frequency or equal size interval) and the parameter nbins which sets the number of bins to use. The final step of the minet function is the normalization using the norm(net) function. This step normalizes all the weights of the inferred adjancy matrix between 0 and 1. Hence, the minet function returns the inferred network as a weighted adjacency matrix with values ranging from 0 to 1 where the higher is a weight, the higher is the evidence that a gene-gene interaction exists.</p>
    <p>For demo purposes the package makes available also the dataset <monospace>syn.data</monospace> representing the expression of 50 genes in 100 experiments. This dataset has been synthetically generated from the network syn.net using the microarray data generator <italic>Syntren </italic>[<xref ref-type="bibr" rid="B40">40</xref>]. This dataset can be loaded with <monospace>data(syn.data)</monospace> and the corresponding original network with <monospace>data(syn.net)</monospace>.</p>
    <p>Note that the command <monospace>res&lt;-minet(syn.data,"mrnet","mi.shrink","equalwidth",10)</monospace> is a compact way to execute the following sequence of instructions:</p>
    <p>discdata&lt;-discretize(syn.data,"equalwidth",10)</p>
    <p>mim&lt;-build.mim(discdata,"mi.shrink")</p>
    <p>net&lt;-mrnet(mim)</p>
    <p>res&lt;-norm(net)</p>
    <p>In order to plot a PR-curve (see Figure <xref ref-type="fig" rid="F3">3</xref>), the functions show.pr and validate can be used.</p>
    <p>table &lt;- validate(res, syn.net)</p>
    <p>show.pr(table)</p>
    <p>In order to display the inferred network, the <italic>Rgraphviz </italic>package [<xref ref-type="bibr" rid="B41">41</xref>] can be used with the following commands (see Fig. <xref ref-type="fig" rid="F2">2</xref>):</p>
    <fig position="float" id="F2">
      <label>Figure 2</label>
      <caption>
        <p>Graph generated with <italic>minet </italic>and plotted with <italic>Rgraphviz</italic>.</p>
      </caption>
      <graphic xlink:href="1471-2105-9-461-2"/>
    </fig>
    <p>library(Rgraphviz)</p>
    <p>graph &lt;- as(res, "graphNEL")</p>
    <p>plot(graph)</p>
    <p>Note that, for the sake of computational efficiency, all the inference functions as well as the entropy estimators are implemented in C++. As a reference, a network of five hundreds variables may be inferred in less than one minute on an Intel Pentium 4 with 2 Ghz and 512 DDR SDRAM.</p>
  </sec>
  <sec>
    <title>6 Conclusion</title>
    <p>Transcriptional network inference is a key issue toward the understanding of the relationships between the genes of an organism. Notwithstanding, few public domain tools are available once a thourough comparison of existing approaches is at stake. A new R/Bioconductor package, freely available, has been introduced in this paper. This package makes available to biologists and bioinformatics practicioneers a set of tools to infer networks from microarray datasets with a large number (several thousands) of genes. Four information-theoretic methods of network inference (i.e. Relevance Networks, CLR, ARACNE and MRNET), four different entropy estimators (i.e. empirical, Miller-Madow, Schurmann-Grassberger and shrink) and three validation tools (i.e. F-scores, PR curves and ROC curves) are implemented in the package. We deem that this tool is an effective answer to the increasing need of comparative tools in the growing domain of transcriptional network inference from expression data.</p>
  </sec>
  <sec>
    <title>Authors' contributions</title>
    <p>PEM and FL carried out the implementation of the R package <italic>minet </italic>(up to version 1.1.6). PEM and GB have written the package documentation as well as the manuscript. All authors read and approved the final version of the manuscripts.</p>
  </sec>
  <sec>
    <title>Availability and requirements</title>
    <p>The R-package <italic>minet </italic>is freely available from the Comprehensive R Archive Network (CRAN) at <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org"/> as well as from the Bioconductor website <ext-link ext-link-type="uri" xlink:href="http://bioconductor.org"/>. The package runs on Linux, Mac OS and MS Windows using an installed version of R.</p>
    <table-wrap position="float" id="T1">
      <label>Table 1</label>
      <caption>
        <p>Available functions of the package <italic>minet </italic>(version 1.1.6)</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <td align="center">Function</td>
            <td align="center">Usage</td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="center">
              <monospace>minet(data, method, estimator, disc, nbins)</monospace>
            </td>
            <td align="center">Network inference from data</td>
          </tr>
          <tr>
            <td colspan="2">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="center">
              <monospace>discretize(data, disc, nbins)</monospace>
            </td>
            <td align="center">Unsupervised discretization</td>
          </tr>
          <tr>
            <td colspan="2">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="center">
              <monospace>build.mim(data, estimator)</monospace>
            </td>
            <td align="center">Mutual information matrix estimation<break/>Estimator can be ""mi.empirical","mi.mm","mi.shrink" and "mi.sg".</td>
          </tr>
          <tr>
            <td colspan="2">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="center">
              <monospace>mrnet(mim)</monospace>
            </td>
            <td align="center">MRNET algorithm</td>
          </tr>
          <tr>
            <td colspan="2">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="center">
              <monospace>aracne(mim)</monospace>
            </td>
            <td align="center">ARACNE algorithm</td>
          </tr>
          <tr>
            <td colspan="2">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="center">
              <monospace>clr(mim)</monospace>
            </td>
            <td align="center">CLR algorithm</td>
          </tr>
          <tr>
            <td colspan="2">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="center">
              <monospace>norm(net)</monospace>
            </td>
            <td align="center">matrix/network normalization</td>
          </tr>
          <tr>
            <td colspan="2">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="center">
              <monospace>validate(net1, net2, steps)</monospace>
            </td>
            <td align="center">Computes confusion matrices</td>
          </tr>
          <tr>
            <td colspan="2">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="center">
              <monospace>pr(table)</monospace>
            </td>
            <td align="center">Computes precisions and recalls from confusion matrices</td>
          </tr>
          <tr>
            <td colspan="2">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="center">
              <monospace>rates(table)</monospace>
            </td>
            <td align="center">Computes true positive rates and false positive rates from confusion matrices</td>
          </tr>
          <tr>
            <td colspan="2">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="center">
              <monospace>show.pr(table)</monospace>
            </td>
            <td align="center">Displays precision-recall curves from confusion matrices</td>
          </tr>
          <tr>
            <td colspan="2">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="center">
              <monospace>show.roc(table)</monospace>
            </td>
            <td align="center">Displays receiver operator caracteristic curves from confusion matrices</td>
          </tr>
          <tr>
            <td colspan="2">
              <hr/>
            </td>
          </tr>
          <tr>
            <td align="center">
              <monospace>fscores(table)</monospace>
            </td>
            <td align="center">Returns a vector of <italic>F</italic><sub><italic>β</italic></sub>-scores from confusion matrices</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </sec>
</body>
<back>
  <ack>
    <sec>
      <title>Acknowledgements</title>
      <p>This work was partially funded by the Communauté Française de Belgique under ARC grant no. 04/09-307. The authors thank their collegue Catharina Olsen for her appreciable comments, suggestions and testing of package functionalities. The authors also thank Korbinian Strimmer as well as the reviewers for their useful comments on the package and the paper.</p>
    </sec>
  </ack>
  <ref-list>
    <ref id="B1">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>van Someren</surname>
            <given-names>EP</given-names>
          </name>
          <name>
            <surname>Wessels</surname>
            <given-names>LFA</given-names>
          </name>
          <name>
            <surname>Backer</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Reinders</surname>
            <given-names>MJT</given-names>
          </name>
        </person-group>
        <article-title>Genetic network modeling</article-title>
        <source>Pharmacogenomics</source>
        <year>2002</year>
        <volume>3</volume>
        <fpage>507</fpage>
        <lpage>525</lpage>
        <pub-id pub-id-type="pmid">12164774</pub-id>
        <pub-id pub-id-type="doi">10.1517/14622416.3.4.507</pub-id>
      </citation>
    </ref>
    <ref id="B2">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Gardner</surname>
            <given-names>TS</given-names>
          </name>
          <name>
            <surname>Faith</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Reverse-engineering transcription control networks</article-title>
        <source>Physics of Life Reviews 2</source>
        <year>2005</year>
      </citation>
    </ref>
    <ref id="B3">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schäfer</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Strimmer</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>An empirical Bayes approach to inferring large-scale gene association networks</article-title>
        <source>Bioinformatics</source>
        <year>2005</year>
        <volume>21</volume>
        <fpage>754</fpage>
        <lpage>764</lpage>
        <pub-id pub-id-type="pmid">15479708</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bti062</pub-id>
      </citation>
    </ref>
    <ref id="B4">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Faith</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hayete</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Thaden</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Mogno</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Wierzbowski</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cottarel</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Kasif</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Collins</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Gardner</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Large-Scale Mapping and Validation of Escherichia coli Transcriptional Regulation from a Compendium of Expression Profiles</article-title>
        <source>PLoS Biology</source>
        <year>2007</year>
        <volume>5</volume>
        <pub-id pub-id-type="pmid">17214507</pub-id>
      </citation>
    </ref>
    <ref id="B5">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Basso</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Margolin</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Stolovitzky</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Klein</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Dalla-Favera</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Califano</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Reverse engineering of regulatory networks in human B cells</article-title>
        <source>Nature Genetics</source>
        <year>2005</year>
        <volume>37</volume>
        <pub-id pub-id-type="pmid">15778709</pub-id>
      </citation>
    </ref>
    <ref id="B6">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Butte</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>PT</surname>
            <given-names/>
          </name>
          <name>
            <surname>Slonim</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Golub</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Kohane</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Discovering functional relationships between RNA expression and chemotherapeutic susceptibility using relevance networks</article-title>
        <source>Proceedings of the National Academy of Sciences</source>
        <year>2000</year>
        <volume>97</volume>
        <fpage>12182</fpage>
        <lpage>12186</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.220392197</pub-id>
      </citation>
    </ref>
    <ref id="B7">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Butte</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Kohane</surname>
            <given-names>IS</given-names>
          </name>
        </person-group>
        <article-title>Mutual Information Relevance Networks: Functional Genomic Clustering Using Pairwise Entropy Measurments</article-title>
        <source>Pac Symp Biocomput</source>
        <year>2000</year>
        <fpage>418</fpage>
        <lpage>429</lpage>
        <pub-id pub-id-type="pmid">10902190</pub-id>
      </citation>
    </ref>
    <ref id="B8">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Margolin</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Nemenman</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Basso</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wiggins</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Stolovitzky</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Favera</surname>
            <given-names>RD</given-names>
          </name>
          <name>
            <surname>Califano</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>ARACNE: an algorithm for the reconstruction of gene regulatory networks in a mammalian cellular context</article-title>
        <source>BMC Bioinformatics</source>
        <year>2006</year>
        <volume>7</volume>
        <pub-id pub-id-type="pmid">16723010</pub-id>
      </citation>
    </ref>
    <ref id="B9">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meyer</surname>
            <given-names>PE</given-names>
          </name>
          <name>
            <surname>Kontos</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Lafitte</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Bontempi</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Information-Theoretic Inference of Large Transcriptional Regulatory Networks</article-title>
        <source>EURASIP J Bioinform Syst Biol</source>
        <year>2007</year>
        <fpage>79879</fpage>
        <pub-id pub-id-type="pmid">18354736</pub-id>
      </citation>
    </ref>
    <ref id="B10">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gentleman</surname>
            <given-names>RIR</given-names>
          </name>
        </person-group>
        <article-title>R: A language for data analysis and graphics</article-title>
        <source>Journal of Computational and Graphical Statistics</source>
        <year>1996</year>
        <volume>5</volume>
        <ext-link ext-link-type="uri" xlink:href="http://www.R-project.org"/>
      </citation>
    </ref>
    <ref id="B11">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Venables</surname>
            <given-names>WN</given-names>
          </name>
          <name>
            <surname>Ripley</surname>
            <given-names>BD</given-names>
          </name>
        </person-group>
        <source>Modern Applied Statistics with S</source>
        <year>2002</year>
        <edition>Fourth</edition>
        <publisher-name>Springer</publisher-name>
      </citation>
    </ref>
    <ref id="B12">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gentleman</surname>
            <given-names>RC</given-names>
          </name>
          <name>
            <surname>Carey</surname>
            <given-names>VJ</given-names>
          </name>
          <name>
            <surname>Bates</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Bolstad</surname>
            <given-names>BM</given-names>
          </name>
          <name>
            <surname>Dettling</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dudoit</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ellis</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Gautier</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Ge</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Gentry</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hornik</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Hothorn</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Huber</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Iacus</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Irizarry</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Leisch</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Maechler</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Rossini</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Sawitzki</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Smyth</surname>
            <given-names>GK</given-names>
          </name>
          <name>
            <surname>Tierney</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>YH</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Bioconductor: Open software development for computational biology and bioinformatics</article-title>
        <source>Genome Biology</source>
        <year>2004</year>
        <volume>5</volume>
        <pub-id pub-id-type="pmid">15461798</pub-id>
      </citation>
    </ref>
    <ref id="B13">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Greiner</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Kelly</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bell</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Learning Bayesian Networks from Data: An Information-Theory Based Approach</article-title>
        <source>Artificial Intelligence</source>
        <year>2002</year>
        <volume>137</volume>
      </citation>
    </ref>
    <ref id="B14">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Chow</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Approximating discrete probability distributions with dependence trees</article-title>
        <source>Information Theory, IEEE Transactions on 1968</source>
        <volume>14</volume>
      </citation>
    </ref>
    <ref id="B15">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Pearl</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <source>Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</source>
        <year>1988</year>
        <publisher-name>Morgan Kaufmann Publishers Inc</publisher-name>
      </citation>
    </ref>
    <ref id="B16">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Cover</surname>
            <given-names>TM</given-names>
          </name>
          <name>
            <surname>Thomas</surname>
            <given-names>JA</given-names>
          </name>
        </person-group>
        <source>Elements of Information Theory</source>
        <year>1990</year>
        <publisher-name>New York: John Wiley</publisher-name>
      </citation>
    </ref>
    <ref id="B17">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tourassi</surname>
            <given-names>GD</given-names>
          </name>
          <name>
            <surname>Frederick</surname>
            <given-names>ED</given-names>
          </name>
          <name>
            <surname>Markey</surname>
            <given-names>MK</given-names>
          </name>
          <name>
            <surname>C</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Floyd</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Application of the mutual information criterion for feature selection in computer-aided diagnosis</article-title>
        <source>Medical Physics</source>
        <year>2001</year>
        <volume>28</volume>
        <fpage>2394</fpage>
        <lpage>2402</lpage>
        <pub-id pub-id-type="pmid">11797941</pub-id>
        <pub-id pub-id-type="doi">10.1118/1.1418724</pub-id>
      </citation>
    </ref>
    <ref id="B18">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peng</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Long</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Feature selection based on mutual information: criteria of max-dependency, max-relevance, and min-redundancy</article-title>
        <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>
        <year>2005</year>
        <volume>27</volume>
        <fpage>1226</fpage>
        <lpage>1238</lpage>
        <pub-id pub-id-type="pmid">16119262</pub-id>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2005.159</pub-id>
      </citation>
    </ref>
    <ref id="B19">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Minimum Redundancy Feature Selection From Microarray Gene Expression Data</article-title>
        <source>Journal of Bioinformatics and Computational Biology</source>
        <year>2005</year>
        <volume>3</volume>
        <fpage>185</fpage>
        <lpage>205</lpage>
        <pub-id pub-id-type="pmid">15852500</pub-id>
        <pub-id pub-id-type="doi">10.1142/S0219720005001004</pub-id>
      </citation>
    </ref>
    <ref id="B20">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Merz</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Freisleben</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Greedy and Local Search Heuristics for Unconstrained Binary Quadratic Programming</article-title>
        <source>Journal of Heuristics</source>
        <year>2002</year>
        <volume>8</volume>
        <fpage>1381</fpage>
        <lpage>1231</lpage>
        <pub-id pub-id-type="doi">10.1023/A:1017912624016</pub-id>
      </citation>
    </ref>
    <ref id="B21">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Olsen</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Meyer</surname>
            <given-names>PE</given-names>
          </name>
          <name>
            <surname>Bontempi</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Ahdesmäki M, Strimmer K, Radde N, Rahnenf hrer J, Klemm K, L hdesm ki H, Yli-Harja O</surname>
          </name>
        </person-group>
        <article-title>On the Impact of Entropy Estimator in Transcriptional Regulatory Network Inference</article-title>
        <source>5th International Workshop on Computational Systems Biology (WSCB 08)</source>
        <year>2008</year>
        <publisher-name>Tampere International Center for Signal Processing</publisher-name>
        <fpage>41</fpage>
      </citation>
    </ref>
    <ref id="B22">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Daub</surname>
            <given-names>CO</given-names>
          </name>
          <name>
            <surname>Steuer</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Selbig</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kloska</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Estimating mutual information using B-spline functions – an improved similarity measure for analysing gene expression data</article-title>
        <source>BMC Bioinformatics</source>
        <year>2004</year>
        <volume>5</volume>
        <pub-id pub-id-type="pmid">15339346</pub-id>
      </citation>
    </ref>
    <ref id="B23">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Paninski</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Estimation of entropy and mutual information</article-title>
        <source>Neural Computation</source>
        <year>2003</year>
        <volume>15</volume>
        <fpage>1191</fpage>
        <lpage>1253</lpage>
        <pub-id pub-id-type="doi">10.1162/089976603321780272</pub-id>
      </citation>
    </ref>
    <ref id="B24">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Beirlant</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Dudewica</surname>
            <given-names>EJ</given-names>
          </name>
          <name>
            <surname>Gyofi</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Meulen</surname>
            <given-names>E van der</given-names>
          </name>
        </person-group>
        <article-title>Nonparametric Entropy Estimation: An Overview</article-title>
        <source>Journal of Statistics</source>
        <fpage>97</fpage>
      </citation>
    </ref>
    <ref id="B25">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nemenman</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Bialek</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>de Ruyter van Steveninck</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Entropy and information in neural spike trains: Progress on the sampling problem</article-title>
        <source>Phys Rev E Stat Nonlin Soft Matter Phys</source>
        <year>2004</year>
        <volume>69</volume>
        <fpage>056111</fpage>
        <pub-id pub-id-type="pmid">15244887</pub-id>
      </citation>
    </ref>
    <ref id="B26">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Darbellay</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Vajda</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Estimation of the information by an adaptive partitioning of the observation space</article-title>
        <source>IEEE Transactions on Information Theory</source>
        <year>1999</year>
      </citation>
    </ref>
    <ref id="B27">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Hausser</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Improving entropy estimation and inferring genetic regulatory networks</article-title>
        <source>Master's thesis</source>
        <year>2006</year>
        <publisher-name>National Institute of Applied Sciences Lyon</publisher-name>
        <ext-link ext-link-type="uri" xlink:href="http://strimmerlab.org/publications/msc-hausser.pdf"/>
      </citation>
    </ref>
    <ref id="B28">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schäfer</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Strimmer</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics</article-title>
        <source> Stat Appl Genet Mol Biol</source>
        <year>2005</year>
        <volume>4</volume>
      </citation>
    </ref>
    <ref id="B29">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Neskovic</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Reyes</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Festa</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Heindel</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Classifying n-back EEG data using entropy and mutual information features</article-title>
        <source>European Symposium on Artificial Neural Networks</source>
        <year>2007</year>
      </citation>
    </ref>
    <ref id="B30">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Beerenwinkel</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Schmidt</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Walter</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Kaiser</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Lengauer</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Hoffmann</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Korn</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Selbig</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Diversity and complexity of HIV-1 drug resistance: A bioinformatics approach to predicting phenotype from genotype</article-title>
        <source>Proc Natl Acad Sci U S A</source>
        <year>2002</year>
        <volume>99</volume>
        <fpage>8271</fpage>
        <lpage>8276</lpage>
        <pub-id pub-id-type="pmid">12060770</pub-id>
        <pub-id pub-id-type="doi">10.1073/pnas.112177799</pub-id>
      </citation>
    </ref>
    <ref id="B31">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Krichevsky</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Trofimov</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>The performance of universal coding</article-title>
        <source>IEEE Transactions in Information Theory</source>
        <year>1981</year>
      </citation>
    </ref>
    <ref id="B32">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Schurmann</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Grassberger</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Entropy estimation of symbol sequences</article-title>
        <source>Chaos</source>
        <year>1996</year>
      </citation>
    </ref>
    <ref id="B33">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Dougherty</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kohavi</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Sahami</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Supervised and Unsupervised Discretization of Continuous Features</article-title>
        <source>International Conference on Machine Learning</source>
        <year>1995</year>
        <fpage>194</fpage>
        <lpage>202</lpage>
      </citation>
    </ref>
    <ref id="B34">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Hussain</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Tan</surname>
            <given-names>CL</given-names>
          </name>
          <name>
            <surname>Dash</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Discretization: An Enabling Technique</article-title>
        <source>Data Mining and Knowledge Discovery</source>
        <year>2002</year>
        <volume>6</volume>
      </citation>
    </ref>
    <ref id="B35">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Webb</surname>
            <given-names>GI</given-names>
          </name>
        </person-group>
        <article-title>On why discretization works for naive-bayes classifiers</article-title>
        <source>Proceedings of the 16th Australian Joint Conference on Artificial Intelligence</source>
        <year>2003</year>
      </citation>
    </ref>
    <ref id="B36">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Davis</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Goadrich</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>The Relationship Between Precision-Recall and ROC Curves</article-title>
        <source>Proceedings of the 23rd international conference on Machine learning</source>
        <year>2006</year>
      </citation>
    </ref>
    <ref id="B37">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Provost</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Fawcett</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Kohavi</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>The case against accuracy estimation for comparing induction algorithms</article-title>
        <source>Proceedings of the Fifteenth International Conference on Machine Learning</source>
        <year>1998</year>
        <publisher-name>Morgan Kaufmann, San Francisco, CA</publisher-name>
        <fpage>445</fpage>
        <lpage>453</lpage>
      </citation>
    </ref>
    <ref id="B38">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Bockhorst</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Craven</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Saul LK, Weiss Y, Bottou L</surname>
          </name>
        </person-group>
        <article-title>Markov Networks for Detecting Overlapping Elements in Sequence Data</article-title>
        <source>Advances in Neural Information Processing Systems 17</source>
        <year>2005</year>
        <publisher-name>Cambridge, MA: MIT Press</publisher-name>
        <fpage>193</fpage>
        <lpage>200</lpage>
      </citation>
    </ref>
    <ref id="B39">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Sokolova</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Japkowicz</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Szpakowicz</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Beyond Accuracy, F-score and ROC: a Family of Discriminant Measures for Performance Evaluation</article-title>
        <source>Proceedings of the AAAI'06 workshop on Evaluation Methods for Machine Learning</source>
        <year>2006</year>
      </citation>
    </ref>
    <ref id="B40">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>den Bulcke</surname>
            <given-names>TV</given-names>
          </name>
          <name>
            <surname>Leemput</surname>
            <given-names>KV</given-names>
          </name>
          <name>
            <surname>Naudts</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>van Remortel</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Verschoren</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Moor</surname>
            <given-names>BD</given-names>
          </name>
          <name>
            <surname>Marchal</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>SynTReN: a generator of synthetic gene expression data for design and analysis of structure learning algorithms</article-title>
        <source>BMC Bioinformatics</source>
        <year>2006</year>
        <volume>7</volume>
        <fpage>43</fpage>
        <pub-id pub-id-type="pmid">16438721</pub-id>
        <pub-id pub-id-type="doi">10.1186/1471-2105-7-43</pub-id>
      </citation>
    </ref>
    <ref id="B41">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Carey</surname>
            <given-names>VJ</given-names>
          </name>
          <name>
            <surname>Gentry</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Whalen</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Gentleman</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Network Structures and Algorithms in Bioconductor</article-title>
        <source>Bioinformatics</source>
        <year>2005</year>
        <volume>21</volume>
        <fpage>135</fpage>
        <lpage>136</lpage>
        <pub-id pub-id-type="pmid">15297301</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bth458</pub-id>
      </citation>
    </ref>
  </ref-list>
</back>
