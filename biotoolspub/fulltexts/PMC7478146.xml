<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Neurosci</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Neurosci</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Neurosci.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Neuroscience</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1662-4548</issn>
    <issn pub-type="epub">1662-453X</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7478146</article-id>
    <article-id pub-id-type="doi">10.3389/fnins.2020.00710</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Neuroscience</subject>
        <subj-group>
          <subject>Methods</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>NUTMEG: Open Source Software for M/EEG Source Reconstruction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Hinkley</surname>
          <given-names>Leighton B. N.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/5409/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dale</surname>
          <given-names>Corby L.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cai</surname>
          <given-names>Chang</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/589585/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zumer</surname>
          <given-names>Johanna</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dalal</surname>
          <given-names>Sarang</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/2525/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Findlay</surname>
          <given-names>Anne</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/937647/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sekihara</surname>
          <given-names>Kensuke</given-names>
        </name>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/54959/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Nagarajan</surname>
          <given-names>Srikantan S.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="c002">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/316/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>Department of Radiology and Biomedical Imaging, University of California, San Francisco</institution>, <addr-line>San Francisco, CA</addr-line>, <country>United States</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Department of Psychology, University of Birmingham</institution>, <addr-line>Birmingham</addr-line>, <country>United Kingdom</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Aarhus University</institution>, <addr-line>Aarhus</addr-line>, <country>Denmark</country></aff>
    <aff id="aff4"><sup>4</sup><institution>Tokyo Medical and Dental University</institution>, <addr-line>Tokyo</addr-line>, <country>Japan</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Satrajit S. Ghosh, Massachusetts Institute of Technology, United States</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Matti Hämäläinen, Massachusetts General Hospital and Harvard Medical School, United States; Eric Larson, University of Washington, United States</p>
      </fn>
      <corresp id="c001">*Correspondence: Leighton B.N. Hinkley, <email>leighton.hinkley@radiology.ucsf.edu</email></corresp>
      <corresp id="c002">Srikantan S. Nagarajan, <email>sri@ucsf.edu</email></corresp>
      <fn fn-type="other" id="fn004">
        <p>This article was submitted to Brain Imaging Methods, a section of the journal Frontiers in Neuroscience</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>25</day>
      <month>8</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>14</volume>
    <elocation-id>710</elocation-id>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>8</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>11</day>
        <month>6</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2020 Hinkley, Dale, Cai, Zumer, Dalal, Findlay, Sekihara and Nagarajan.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Hinkley, Dale, Cai, Zumer, Dalal, Findlay, Sekihara and Nagarajan</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Neurodynamic Utility Toolbox for Magnetoencephalo- and Electroencephalography (NUTMEG) is an open-source MATLAB-based toolbox for the analysis and reconstruction of magnetoencephalography/electroencephalography data in source space. NUTMEG includes a variety of options for the user in data import, preprocessing, source reconstruction, and functional connectivity. A group analysis toolbox allows the user to run a variety of inferential statistics on their data in an easy-to-use GUI-driven format. Importantly, NUTMEG features an interactive five-dimensional data visualization platform. A key feature of NUTMEG is the availability of a large menu of interference cancelation and source reconstruction algorithms. Each NUTMEG operation acts as a stand-alone MATLAB function, allowing the package to be easily adaptable and scripted for the more advanced user for interoperability with other software toolboxes. Therefore, NUTMEG enables a wide range of users access to a complete “sensor-to- source-statistics” analysis pipeline.</p>
    </abstract>
    <kwd-group>
      <kwd>software</kwd>
      <kwd>source space analysis</kwd>
      <kwd>MATLAB</kwd>
      <kwd>electroencephalography</kwd>
      <kwd>magnetoencephalography</kwd>
    </kwd-group>
    <counts>
      <fig-count count="11"/>
      <table-count count="1"/>
      <equation-count count="0"/>
      <ref-count count="39"/>
      <page-count count="17"/>
      <word-count count="0"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="S1">
    <title>Introduction</title>
    <p>Over the past several decades, magnetoencephalography (MEG) has emerged as an efficient technique to study brain function non-invasively with a high temporal resolution. As a result of this utility, a series of software packages have emerged over the same period of time that allow users to analyze this data [most notably FieldTrip (<xref rid="B24" ref-type="bibr">Oostenveld et al., 2011</xref>), minimum-norm estimation (MNE; <xref rid="B15" ref-type="bibr">Gramfort et al., 2013</xref>), and Brainstorm (<xref rid="B34" ref-type="bibr">Tadel et al., 2011</xref>)] and extensions of existing functional neuroimaging toolboxes in order to include MEG analyzes (such as SPM) have been developed. While popular, many of these toolboxes and approaches adapt existing techniques used for the analysis of electroencephalography (EEG) sensor data and apply them to the analysis of MEG data. While this approach is theoretically sound, it can be limiting, often restricting the user to techniques like sensor averaging, dipole fitting, magnetic field topography, and frequency decomposition at the sensor timeseries level.</p>
    <p>More recently, adaptive spatial filtering (e.g., “beamforming”) analytic techniques have been developed in order to capitalize on the exquisite temporal resolution of MEG by providing an ability to localize where changes in MEG sensor data originate along the cortical mantle. These “source space” reconstruction techniques include a variety of spatial scanning estimates (such as minimum-variance adaptive beamforming (MVAB; <xref rid="B30" ref-type="bibr">Sekihara and Nagarajan, 2008</xref>), and synthetic aperture magnetometry (SAM; <xref rid="B37" ref-type="bibr">Vrba and Robinson, 2001</xref>), and tomographic reconstruction techniques including MNE (<xref rid="B19" ref-type="bibr">Hamalainen and Ilmoniemi, 1984</xref>), and standardized low-resolution brain electromagnetic tomography (sLORETA; <xref rid="B27" ref-type="bibr">Pascual-Marqui, 2002</xref>). While each of these inverse solutions are validated, robust techniques for source estimation, many data analysis packages implement only a few of these modeling techniques, and do not embed the ability to compare and contrast between different techniques.</p>
    <p>Our goal is to provide a data analysis “workbench” that allows the user to compare and contrast different source modeling methods that may be the most appropriate for their dataset. In order to meet this demand for a flexible, easy-to-use, inverse-method inclusive MEG data analysis package we developed the Neurodynamic Utility Toolbox for Magnetoencephalo- and Electroencephalography (NUTMEG; <xref rid="B9" ref-type="bibr">Dalal et al., 2004</xref>) at the UC San Francisco Biomagnetic Imaging Lab. Originally released in 2003 and now on its fourth version, NUTMEG is an open-source, freely available MATLAB (Mathworks, Natick, MA, United States) based toolbox designed for M/EEG data analysis distributed for non-commercial use under a BSD-style license (<xref rid="B35" ref-type="bibr">The Open Source Initiative, 2004</xref>). It stands as a start-to-finish (or, “sensor-to-statistics”) pipeline of data analysis, capable of importing raw sensor data to running group-level statistics and functional connectivity (FC) analyzes. Each function in NUTMEG is a stand-alone command line function (akin to other software packages such as FieldTrip) allowing for easy batch scripting and custom pipeline development. In complement to that, these functions are assembled in a series of easy-to-use GUI interfaces that allow a more introductory user (e.g., technicians, clinicians, and students) to analyze full MEG studies with little necessary knowledge of command-line scripting. Visualization based on the SPM engine allows for ready navigation of source-space reconstructions. As the mission of NUTMEG development is to provide a variety of inverse method solutions to users across all levels of experience, it remains unique as a workbench given its vast array of source imaging methods available to the end user. The NUTMEG workbench ranges from gold-standard methods of source reconstruction (e.g., MNE, sLORETA, and beamforming) to more novel inverse methods developed in our lab [e.g., Champage, SAKETINI, and Covariance Optimization Garnering Noise for Active Cancelation (COGNAC)]. This separates NUTMEG from other workbenches given its unique ability to readily switch between different methods for all users to choose which inverse method is appropriate for their own unique studies. Our philosophy is to build a complete, stand-alone data analysis package for M/EEG data that appeals to a wide range of users with little dependency on outside software for running a scientific study.</p>
    <p>Since the original version of NUTMEG and publications promoting its release, there have been substantial changes to the analysis workbench that provide more options to the user along the lines of source reconstruction, statistics, and FC analyzes. Our goal in the following article is two-fold. First, we outline some of the existing and additional, newer features of the workbench. Our focus is to provide new users an overview of how the NUTMEG process operates, from the pipeline itself to the MATLAB machinery “under the hood,” in a framework that allows both new and experienced users of M/EEG data analysis to utilize in a straightforward manner. Second, we present NUTMEG in a “how-to” format explaining how the standard NUTMEG data analysis pipeline is executed, from data import to analysis, using specific examples. We will go over the wide variety of options available in NUTMEG for both the introductory and advanced user, from the types of preprocessing steps available to inverse method solutions to choices of statistical tests.</p>
  </sec>
  <sec id="S2">
    <title>Getting Started</title>
    <p>Neurodynamic Utility Toolbox for Magnetoencephalo- and Electroencephalography is available for download at the NeuroImaging Tools and Resources Collaboratory (NITRC) website<sup><xref ref-type="fn" rid="footnote1">1</xref></sup>. NUTMEG is primarily written in MATLAB and has few dependencies on secondary software packages. NUTMEG has been tested on and currently operates efficiently in the most recent versions of MATLAB (at the time of this article: R2018a) although previous versions of NUTMEG are available for download at the NITRC website for compatibility with previous MATLAB versions. For digital filtering operations, the MATLAB Signal Processing Toolbox is required, and the Image Processing Toolbox is optionally needed for volume-of-interest (VOI) definition (described in Section Step 2. NUTMEG uses the SPM8 engine for visualization purposes<sup><xref ref-type="fn" rid="footnote2">2</xref></sup>. Import of data formats from other software packages (such as FieldTrip) require installation of that software in the user’s MATLAB environment. Optional, third-party toolboxes are also available across the web by other developers that allow for automated artifact detection and rejection, boundary element modeling approaches, and others (<xref rid="B10" ref-type="bibr">Dalal et al., 2011</xref>).</p>
  </sec>
  <sec id="S3">
    <title>Workflow</title>
    <p>A schematic of the typical data analysis pipeline implemented in NUTMEG is shown in <xref ref-type="fig" rid="F1">Figure 1</xref>. Briefly, raw sensor data (or sensor data pre-processed elsewhere) is read into the MATLAB environment and constructed into the NUTMEG variable structure. Following data import, a series of preprocessing steps (including channel selection and bandpass filtering) are available in NUTMEG for the user to prepare the raw data for source analysis. In parallel, a subject-specific head model is imported from the proprietary software associated with the MEG acquisition for lead field/gain matrix generation (spatial filter weights) necessary for source reconstruction, and an anatomical MRI brain template (generally a T1-weighted anatomical MRI specific to the subject) is imported for visualization purposes.</p>
    <fig id="F1" position="float">
      <label>FIGURE 1</label>
      <caption>
        <p>Outline of the standard NUTMEG data analysis pipeline for a single subject. Figure adapted from <xref rid="B10" ref-type="bibr">Dalal et al. (2011)</xref>.</p>
      </caption>
      <graphic xlink:href="fnins-14-00710-g001"/>
    </fig>
    <p>Once the MEG data and associated structural elements are imported, a variety of time-series analysis, time-frequency analysis, and FC source estimation options are available for the user (see <xref rid="T1" ref-type="table">Table 1</xref>). Following source space estimation and reconstruction, their result is saved out as a separate file for visualization on the MRI template. In the case of studies with large (<italic>n</italic> &gt; 5) samples, a statistical workbench within NUTMEG is available for both looking at within-group/session effects as well as comparisons between pre-defined independent variables using voxelwise statistics. Options for visualizing both individual and group results on either canonical MNI templates or brain renderings are available within NUTMEG, as well as options for the user to export the data in different formats (Cartool, ANALYZE) for the purposes of overlay and rendering in the user’s visualization tool of choice (e.g., mri3dX, MRICro, and BrainnetViewer).</p>
    <table-wrap id="T1" position="float">
      <label>TABLE 1</label>
      <caption>
        <p>List of denoising and inverse modeling methods available in NUTMEG.</p>
      </caption>
      <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
        <tbody>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">
              <bold>(A) Denoising options</bold>
            </td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Stimulus evoked factor analysis (SEFA)</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">SEFA ICA</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">DSSP</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Variational bayesian factor analysis (VBFA)</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">
              <bold>(B) Inverse modeling methods — time-series</bold>
            </td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">BF Lf error vector</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Beamspace/Beamspace noES</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Champagne</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Smooth champagne</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">COGNAC</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Correlate columns</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Eigenspace scalar/Vector beamformer</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">LCMV Scalar/Vector beamforner</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">MinNorm/MinNorm scalar</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">NSEFALoc</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Point/Region suppression</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Saketini</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Thresholded lead field</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">AGMN-RUG</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">dSPM</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">sLORETA</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">swLORETA</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">
              <bold>(C) Inverse modeling methods — time-frequency</bold>
            </td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">LCMV Scalar/Vector beamforner</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">MinNorm/MinNorm scalar</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">sLORETA</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">dSPM</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">SAM</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </sec>
  <sec id="S4">
    <title>Gui Environment</title>
    <p>As mentioned earlier, the organization of NUTMEG as a series of stand-alone command-line functions not only make it ideal for the custom user who desires batch scripting and construction of analysis pipelines, but allows it to be easily built into a GUI-based environment where each function can be selected in point-and-click format. An example of this environment is shown in <xref ref-type="fig" rid="F2">Figure 2</xref>. Here, we can see that all of the options laid out in the workflow (<xref ref-type="fig" rid="F1">Figure 1</xref>) are selectable. The main NUTMEG GUI interface consists of three primary windows: the Main Command Window (<xref ref-type="fig" rid="F2">Figure 2A</xref>), the NUTMEG Results Viewer (<xref ref-type="fig" rid="F2">Figure 2B</xref>), and the SPM8 Visualization Engine (<xref ref-type="fig" rid="F2">Figure 2C</xref>). From this point forward, we will present the series of steps necessary for the GUI-based user to execute a standard NUTMEG analysis.</p>
    <fig id="F2" position="float">
      <label>FIGURE 2</label>
      <caption>
        <p>NUTMEG graphical user interface (GUI). <bold>(A)</bold> NUTMEG Main Command Window, <bold>(B)</bold> NUTMEG Results Viewer. <bold>(C)</bold> SPM Visualization Engine.</p>
      </caption>
      <graphic xlink:href="fnins-14-00710-g002"/>
    </fig>
  </sec>
  <sec id="S5">
    <title>Data Import</title>
    <p>Neurodynamic Utility Toolbox for Magnetoencephalo- and Electroencephalography has the capability to import raw data types from a variety of several major MEG manufacturers. This is demonstrated in the menu generated from the first analysis step, selection of the “Load MEG/EEG Data” button in the Main Command Window (<xref ref-type="fig" rid="F2">Figure 2A</xref>). Here, we see options for CTF, 4D/BTi, KIT/Yokogawa/RICOH, and Elekta Neuromag data formats. These options will call one of the specific functions that are in standard use for MEG data import of these types (such as the ctf_read.m function for CTF datasets). Datasets can be either single- or multi-trial, and either raw or pre-processed (such as epoched and artifact-rejected) data in any of these formats can be imported into the toolbox. Datasets which have been cleaned in other software packages prior to data import (e.g., CTF DataEditor, ICA in EEGLab) are importable as well. In addition, several other options are available for import, including reading in data from FieldTrip file structure from EEG/MEG datasets. This converts the FieldTrip <italic>fileio</italic> data structure (<xref rid="B24" ref-type="bibr">Oostenveld et al., 2011</xref>) into the variable structure necessary for MATLAB to perform analyzes.</p>
  </sec>
  <sec id="S6">
    <title>Anatomical MRI and Fiducial Import, VOI Definition</title>
    <p>For purposes of source space imaging, the user is required to import a structural MRI and its associated head model information using the “Coregister MRI…” button on the Main Command Window (<xref ref-type="fig" rid="F2">Figure 2A</xref>). This brings up the Coregistration GUI in a separate window (<xref ref-type="fig" rid="F3">Figure 3</xref>). Through SPM8, NUTMEG is able to load both ANALYZE (<sup>∗</sup>.hdr/<sup>∗</sup>.img) and NIFTI (<sup>∗</sup>.nii) file formats for coregistration. The option of loading an additional, spatially normalized MRI associated with the individual allows for the computation of MNI coordinates for inter-subject comparison later in the analysis pipeline. To align the M/EEG sensor array with the structural MRI image, fiducials can be manually marked on the imported MRI within either the acquisition software (e.g., MRIViewer in CTF, MRILab in Neuromag), or NUTMEG itself, then co-registered with MEG coil positions imported from saved text files or the head model file created using menu options within the proprietary MEG acquisition software (i.e., MRIViewer, MRILab) or command line functions, such as localSpheres in CTF.</p>
    <fig id="F3" position="float">
      <label>FIGURE 3</label>
      <caption>
        <p>Preprocessing Toolbox GUIs. <bold>(A)</bold> Coregistration Toolbox GUI. Options include loading of the single-subject MRI, normalized MRI, fiducial assignment, importation of surface mesh, or headshape points. <bold>(B)</bold> Marker selection tool.</p>
      </caption>
      <graphic xlink:href="fnins-14-00710-g003"/>
    </fig>
    <p>By default, the inverse solutions implemented in NUTMEG localize source activity across the whole brain volume, defined through a back transformation of labeled points in brain space in the spatially normalized structural MRI. However, it is also possible for the user to define an <italic>a priori</italic> VOI restricting source localization to a specific region of the anatomical volume. This is done from the “Manual VOI” drop-down in the main NUTMEG GUI, which allows the user to manually draw a three-dimensional polygon across the three anatomical orientations in the MRI. This VOI could include a specific sub-region of the brain (e.g., perilesional tumor tissue), a single hemisphere or restrict source localization to brain regions exclusively. One practical application of this is through the coherent source suppression approach detailed in <xref rid="B8" ref-type="bibr">Dalal et al. (2006)</xref>, where in the case of highly temporally correlated sources (primary auditory cortex, localized through the M100 auditory evoked field) suppression of a single hemisphere permits more accurate source localization in the hemisphere of interest. VOIs defined through these custom definitions can then be saved out in the GUI for future reference.</p>
  </sec>
  <sec id="S7">
    <title>Pre-Processing and Channel Selection</title>
    <p>With both the MRI and MEG data loaded into the MATLAB environment, the user now has the option to visualize the MEG sensor data by selecting the “View/Select MEG Channels…” button on the Main Command Window, which brings up the Channel Selection interface in a separate window (<xref ref-type="fig" rid="F4">Figure 4</xref>). Several options are available at this pre-processing step for the user to assess data quality prior to source imaging. Options for channel selection (inclusion/exclusion of channels in the analysis) are available in the dataset, and various filtering options (bandpass/notch filtering). Following selection of a time window of interest, the root mean square (RMS) value of the sensors selected will be displayed on a 2D sensor map.</p>
    <fig id="F4" position="float">
      <label>FIGURE 4</label>
      <caption>
        <p>Sensor Preprocessing GUI. On the left, sensor overlay of the averaged dataset is visible. Over the right, RMS distribution over a selected time window is displayed. Options for channel selection, filtering, and denoising are available as well.</p>
      </caption>
      <graphic xlink:href="fnins-14-00710-g004"/>
    </fig>
    <p>Regularization and denoising techniques are available to remove artifacts prior to source localization in time-series/frequency analyzes. These include both approaches based off of ICA (SEFA-based ICA). Bayesian factor analysis (<xref rid="B22" ref-type="bibr">Nagarajan et al., 2007</xref>) algorithms are implemented in NUTMEG, when selected these can identify artifact components present in a control condition so that they can be removed from a condition of interest in the sensor data; this de-noised sensor data may then be input to beamformer or minimum-norm inverse methods. A full list of denoising options are listed in <xref rid="T1" ref-type="table">Table 1</xref>.</p>
    <p><italic>Dual signal subspace projection (DSSP)</italic> One novel advanced denoising method developed in our lab is now available as part of the workbench in the newest releases of NUTMEG. This approach, DSSP (<xref rid="B29" ref-type="bibr">Sekihara et al., 2016</xref>) acts by defining a signals in both the space domain as well as the time domain (<xref rid="B29" ref-type="bibr">Sekihara et al., 2016</xref>). By generating these two data matrices, DSSP projects the data matrix onto the subspace that is orthogonal to the interference subspace, and removes this interference signal with a constant presence in the data matrix. We have validated this algorithm using both simulated and real data (<xref rid="B4" ref-type="bibr">Cai et al., 2019</xref>) and have shown superior artifact rejection in the sensor data through DSSP when benchmarked against other methods, such as signal subspace projection (tSSS). We now provide this option for cleaning the data for both time-series and time-frequency analyzes in the latest release of the workbench.</p>
  </sec>
  <sec id="S8">
    <title>Computation of Forward Model</title>
    <p>Once the sensor data is preprocessed, the user has the option to generate lead fields from sensors loaded in from the dataset, using a forward model and information from the individual brain structure and MEG channel locations (and therefore generating a gain matrix), through selection of the “Obtain Lead Field” button. NUTMEG provides several options to the user for defining the forward model, and built-in support for computation of sensor lead fields and the gain matrix based on single sphere and multisphere head models. The sphere center can either be specified manually, or loaded from a head model file created from CTF’s localSpheres command line function. The current iteration of NUTMEG permits source localization across the whole brain volume, although calculation of lead fields using more computationally intensive boundary element method (BEM) head models is provided via integration between NUTMEG and either the Helsinki BEM (<xref rid="B33" ref-type="bibr">Stenroos et al., 2007</xref>) or the OpenMEEG (<xref rid="B16" ref-type="bibr">Gramfort et al., 2010</xref>) toolboxes. NUTMEG includes functions for importing tissue surface meshes from either BrainSuite or BrainVisa MRI segmenting software, thereby presenting the user with a complete BEM pipeline.</p>
    <p>For EEG datasets, a multisphere model can be generated using a NUTMEG function that adjusts sphere centers to minimize the difference between the forward potentials generated for a few sparsely sampled points using the multisphere method and those derived using the BEM.</p>
  </sec>
  <sec id="S9">
    <title>Inverse Methods: Time-Series (Evoked) Source Analysis</title>
    <p>One option available to the user in NUTMEG for source analysis is the ability to localize evoked magnetic fields (e.g., AEF, SEF, and VEF) generated from averaging of sensor data using a variety of inverse methods. This is selected via the “Source Analysis: Time Series” button in the Main Command window. This brings up the Beamformer Tool GUI (<xref ref-type="fig" rid="F5">Figure 5</xref>) that allows for an interactive and GUI-driven method for users to define their desired baseline period and assign the type of inverse solution to be used.</p>
    <fig id="F5" position="float">
      <label>FIGURE 5</label>
      <caption>
        <p>Time-series source estimation GUI. On the left, sensor overlay of the averaged dataset is visible. On the right, parameters for source space reconstruction (in this case, eigenvalues plotted for the eigenspace vector beamformer). Filtering options, time window selection, method of source inversion, other denoising methods, sensor covariance regularization are also selectable.</p>
      </caption>
      <graphic xlink:href="fnins-14-00710-g005"/>
    </fig>
    <p>Many variants of popular inverse methods for source localization of M/EEG data are included in NUTMEG: beamformer, minimum norm, and Bayesian. Furthermore, NUTMEG is stylized to allow easy drop-in and incorporation of newly-developed inverse methods into the associated menu choices. The use of the time-domain LCMV beamformer (Similar to SAM, <xref rid="B37" ref-type="bibr">Vrba and Robinson, 2001</xref>) for localizing both the oscillatory power changes over many time-frequency windows as well as evoked responses (ERF/ERPs) is well supported in NUTMEG. Minimum-norm methods that are supported include sLORETA (<xref rid="B27" ref-type="bibr">Pascual-Marqui, 2002</xref>) and dSPM (<xref rid="B11" ref-type="bibr">Dale et al., 2000</xref>). Several Bayesian methods have been developed by our group to improve source estimation and allow denoising of data, including Champagne (<xref rid="B25" ref-type="bibr">Owen et al., 2012a</xref>, <xref rid="B26" ref-type="bibr">b</xref>), SAKETINI (<xref rid="B38" ref-type="bibr">Zumer et al., 2007</xref>), and NSEFALoc (<xref rid="B39" ref-type="bibr">Zumer et al., 2008</xref>). Bayesian methods denoise and localize data in one step, resulting in improved spatial specificity and reduced sensitivity to correlated sources. A full list of the inverse methods available for evoked source analysis can be found in <xref rid="T1" ref-type="table">Table 1B</xref> and are explained in detail in our previous publications (<xref rid="B10" ref-type="bibr">Dalal et al., 2011</xref>).</p>
    <p>Covariance Optimization Garnering Noise for Active Cancelation One of the philosophies of NUTMEG is to make a constellation of inverse methods for source solutions available to the user, and in our lab we have developed several such tools (NSEFALoc, SAKETINI, et cetera) that we have readily implemented into the workbench. One major revision to the NUTMEG 4. + release of the software is the inclusion of several novel approaches, including scanning algorithms for source reconstruction. COGNAC (<xref rid="B3" ref-type="bibr">Cai et al., 2018a</xref>) has been readily applied and tested to simulated, MEG, and EEG datasets and is now available in the latest release of the software. Here, probabilistic generative modeling is used to describe the sensor data, which partitions source contributions in the sensor data from a given location from contributions to that point in space from neighboring locations, enabling learning of sensor noise without the need for baseline or pre-stimulus data. We find application of COGNAC to several datasets to be superior to more gold-standard means of source localization (beamforming, sLORETA). Given the high utility of this tool in source imaging, we now include it in our latest releases of the NUTMEG workbench.</p>
    <p><italic>Smooth Champagne</italic> One popular beamformer available in NUTMEG is champagne, which uses an empirical Bayesian framework to yield sparse source solutions to the inverse problem (<xref rid="B26" ref-type="bibr">Owen et al., 2012b</xref>). Recent developments in our lab have acted to improve the fidelity of this technique, and are now available in the NUTMEG workbench. One of these, which introduces kernel smoothing and hyperparameter tilting into the source solution we refer to as Smooth Champagne (<xref rid="B5" ref-type="bibr">Cai et al., 2018b</xref>). We demonstrate that Smooth Champagne is highly robust to noise, interference, and the resolution of highly temporally correlated brain sources for both MEG and EEG. Like COGNAC, this tool is now available in the most up-to-date releases of NUTMEG for users to apply.</p>
    <p>Once the particular inverse solution method parameters are assigned by the user, the source analysis is run and a results file (s_beam<sup>∗</sup>.mat) is generated that can be opened by the user in the Visualization Tool interface (see below).</p>
  </sec>
  <sec id="S10">
    <title>Inverse Methods: Time Frequency (Induced) Source Analysis</title>
    <p>As an alternative (or complementary analysis) to evoked activity, NUTMEG provides the option to reconstruct data in the time-frequency domain to evaluate induced (e.g., non-phase locked) changes in oscillatory dynamics using both GUI and command line functions. Selection of the “Source Analysis: Time Frequency” button in the Main Command Window brings up the Time-Frequency Beamformer GUI (<xref ref-type="fig" rid="F6">Figure 6</xref>), an interactive way to define beamformers for source reconstruction in the NUTMEG toolbox. User options for customized time-window definition (length, duration, and overlap), frequency band (e.g., 8–12Hz, 12–30Hz), filtering techniques [e.g., finite-impulse response (FIR), Butterworth], and beamformer method (e.g., SAM, sLORETA) are available, with options to import custom filters/beamformers if the user chooses to do so. The NUTMEG time-frequency pipeline proceeds in three steps (described in more detail in <xref rid="B10" ref-type="bibr">Dalal et al., 2011</xref>). First, sensor data is passed through a series of filter banks and partitioned into frequency bands (e.g., alpha 8–12Hz, beta 12–30Hz) and overlapping time windows (e.g., 250 ms windows with 50 ms overlap), pre-defined by the user in the associated GUI inputs or via user-created variables in Matlab files that can be selected within the GUI. From these windows a covariance matrix and source weights are used to estimate power changes in oscillatory activity in each window, which are then finally assembled into a single file (s_beam_timef<sup>∗</sup>.mat) for results visualization. Interrogation of the time-frequency reconstruction by the user can be visualized at the single subject level or as group averages. A full list of the inverse methods currently available for time-frequency optimized source analysis can be found in <xref rid="T1" ref-type="table">Table 1C</xref>, and each of these processes is explained in more detail below in the visualization and statistics sections, respectively.</p>
    <fig id="F6" position="float">
      <label>FIGURE 6</label>
      <caption>
        <p>Time-Frequency Beamformer GUI. Specification of time-windows, frequency band, filtering, and source reconstruction algorithms are all available.</p>
      </caption>
      <graphic xlink:href="fnins-14-00710-g006"/>
    </fig>
  </sec>
  <sec id="S11">
    <title>Functional Connectivity Analysis</title>
    <p>Finally, as an alternative to examining evoked or induced changes in oscillatory power, NUTMEG offers a functional connectivity map (FCM) workbench that enables the localization of FC among brain areas from EEG and MEG recordings. NUTMEG computes FC by combining source localization algorithms with measures of FC between those sources. First, the user undertakes an estimate of oscillations across networks at each voxel by calculating the linear combination of the sensor data matrix with a spatial weighting matrix obtained with the solutions and steps outlined in 5B. Next, the user can enable, or select, the “FCM” button on the Main Command Window, which brings up the FCM GUI interface (<xref ref-type="fig" rid="F7">Figure 7</xref>).</p>
    <fig id="F7" position="float">
      <label>FIGURE 7</label>
      <caption>
        <p>Functional Connectivity GUI. Allows for the selection of the type of connectivity metric, frequency band of interest, and regions of interest.</p>
      </caption>
      <graphic xlink:href="fnins-14-00710-g007"/>
    </fig>
    <p>In the FCM GUI, the user can then set the desired configuration parameters for the FC analysis. The current instantiation of NUTMEG’s FCM tool relies on “bivariate” measures of FC, which requires the user to define both a “seed” and the “target” (or “connection”) regions in the configuration tool. These seeds may be defined voxelwise and then averaged across every target in the grid (what is called “Global Connectivity”; see <xref rid="B18" ref-type="bibr">Guggisberg et al., 2008</xref>; <xref rid="B20" ref-type="bibr">Hinkley et al., 2011</xref>), or can be selected as a pre-defined Region of Interest (ROI) by manually drawing the VOI on a template brain or using labels from an anatomical atlas (such as the AAL atlas; <xref rid="B36" ref-type="bibr">Tzourio-Mazoyer et al., 2002</xref>) or, at an even more coarser level, across an entire cerebral hemisphere.</p>
    <p>Functional connectivity estimates can be run on both task-based (e.g., event-locked multi-trial data) and “resting-state” datasets where no significant event occurs (e.g., <xref rid="B12" ref-type="bibr">Dubovik et al., 2012</xref>, continuous single-trial data). NUTMEG includes a variety of FC measures out of the box, including imaginary coherence (<xref rid="B23" ref-type="bibr">Nolte et al., 2004</xref>), magnitude squared coherence, phase lag index (<xref rid="B32" ref-type="bibr">Stam et al., 2007</xref>), amplitude envelope correlations (<xref rid="B2" ref-type="bibr">Brookes et al., 2011</xref>), and general lagged coherence (<xref rid="B28" ref-type="bibr">Pascual-Marqui et al., 2011</xref>). These algorithms are efficient enough to run on a local workstation, but also may be distributed across a parallel computing grid. Output images can then be visualized in the NUTMEG viewer at a single-subject level, or piped into the NUTMEG statistics interface for group analysis.</p>
  </sec>
  <sec id="S12">
    <title>Statistics</title>
    <p>In studies with considerable sample size (<italic>n</italic> &gt; 5), NUTMEG provides the user with the option to run a variety of voxelwise descriptive and inferential statistics using the Statistics Tool, selected through the Main Command Window (<xref ref-type="fig" rid="F8">Figure 8</xref>). Here, the user selects the normalized s_beam reconstructions, or a “pointer” file that specifies path and filenames of a group of normalized reconstructions generated in a prior step within the visualization tool (see next section), to assess statistical significance across subjects. Once the individual subject files are selected, conditions and groups can be specified and the desired statistical test selected. NUTMEG currently uses statistical non-parametric mapping (SnPM; <xref rid="B31" ref-type="bibr">Singh et al., 2003</xref>), which does not depend on an assumption of having normally-distributed data, and is robust for as few as 5 subjects (though having more subjects will allow detection of weaker effects). Current statistical tests available in NUTMEG include grand-mean averaging, one- and two-sample (paired and unpaired) <italic>t</italic>-tests, correlations between power change/FC values with extrinsic (e.g., behavioral) variables, and multi-level ANOVAS. The NUTMEG statistical tool also provides GUI selection options for collapsing across or correcting for significant frequency bands (as in <xref rid="B17" ref-type="bibr">Guggisberg et al., 2010</xref>) and time windows.</p>
    <fig id="F8" position="float">
      <label>FIGURE 8</label>
      <caption>
        <p>Time-Frequency Statistics Tool, showing various options for calculating statistical significance across subjects for source time-frequency maps.</p>
      </caption>
      <graphic xlink:href="fnins-14-00710-g008"/>
    </fig>
    <p>Since variance estimates can be noisy, variance maps are smoothed with a 3D Gaussian kernel (generally 2 cm). A distribution of pseudo-<italic>t</italic> statistics is created from 2^N permutations of the original N subjects by inverting the polarity of the power change values for some subjects (2^N possible negations) and then finding the current maximum pseudo-<italic>t</italic> value among all voxels and time windows for each frequency band. The significance of each pseudo-<italic>t</italic> value is calculated from its position from a distribution of these maximally permuted pseudo-<italic>t</italic> values. Computed statistical probabilities are formulated as tomographic statistical maps that can be displayed in the NUTMEG visualization tool, and can be thresholded in a variety of different ways to allow for statistical exploration of data. Automatic correction for multiple comparisons across voxels and time-windows is saved in the result file and includes family-wise error rate (FWER), false discovery rate (FDR), and a spatial cluster correction. These thresholds can then be applied to the tomographic statistical map, and changed dynamically using drop-down selections, within the visualization tool to reflect both level of correction for multiple comparisons. Additionally, the desired alpha error rate and related statistical value (e.g., <italic>T</italic>-statistic, <italic>r</italic>-score) can be changed dynamically in the visualization tool for both positive and negative tails of the distribution.</p>
  </sec>
  <sec id="S13">
    <title>Visualization of Results</title>
    <p>Both visualization of single-subject (FC, power change) and multi-subject (group statistics) data can be viewed using the NUTMEG Results Viewer (<xref ref-type="fig" rid="F2">Figure 2B</xref>) accessible through the Main Command Window. Loading up an s_beam<sup>∗</sup>.mat file will produce a tomographic map overlaid on either the native-space MRI (in the case of single-subject data) or a canonical anatomical brain (for spatially normalized and group data) using the SPM visualization engine. Using this orthogonal-slice navigator, the researcher can explore the source reconstructed dataset or statistical map in 3D space, while an extra, integrated GUI allows the user to explore the dataset over time by displaying the virtual sensor time course for the voxel selected on the SPM navigator. For time-frequency analysis the virtual sensor data plot is replaced by a time-frequency image of the power for the selected voxel. Additionally, the Results Viewer allows the user to spatially normalize a source-space map by taking the transformation matrix from the subject’s T1-wieghted anatomical MRI and apply it to the source-space volume, using SPM normalization functions (<xref rid="B7" ref-type="bibr">Dalal et al., 2008</xref>). Normalized source-space map activations can then be displayed on a normalized rendered brain surface. This is performed by selecting the “normalize functional data” in the lower right panel of the timeseries viewer (left side). Once normalized, data from multiple subjects can be loaded into the MATLAB workspace (“File Browser” sub-menu) and their file locations, conditions and group designations can be made and saved to a single MATLAB “pointer” file for subsequent analyzes in the statistics tool.</p>
    <p>An example of NUTMEG’s visualization of a group analysis (one-sample <italic>t</italic>-test, thresholded at <italic>p</italic> &lt; 0.0005 uncorrected) is shown in <xref ref-type="fig" rid="F9">Figure 9</xref>. Here, a group of subjects viewed faces projected onto a screen. The activation pattern overlay on top of a MRI in the SPM8 Visualization Engine is on the right, and a time-frequency map is presented on the left. The crosshair over the MRI and statistical/tomographic map indicates the voxel in which the time-frequency decomposition is displayed.</p>
    <fig id="F9" position="float">
      <label>FIGURE 9</label>
      <caption>
        <p>NUTMEG Result Viewer for a time-frequency group analysis (one-sample <italic>t</italic>-test) thresholded at <italic>p</italic> &lt; 0.0005 uncorrected. Time-frequency spectrogram for the voxel highlighted by the crosshairs in the MRI viewer are displayed on the left.</p>
      </caption>
      <graphic xlink:href="fnins-14-00710-g009"/>
    </fig>
    <p>Thresholding of the statistical map can be done in a variety of ways in the results viewer. For a single subject, contrast ratios (raw Power for time-series analysis, or a pseudo-<italic>F</italic> ratio contrasting activation and baseline in a time-frequency reconstruction) are selectable from a drop-down window, with the user manually defining the type of threshold to use in a type-in box. These intensity values can be normalized from a scale of 0–1000, and both abscissa and ordinate scales on the time-frequency plots can be adjusted manually to focus on specific portions of the data period. For group (statistical) maps, the drop-down threshold window expands to options where raw scores (<italic>T</italic>-value, <italic>F</italic>-value, et cetera), uncorrected <italic>p</italic>-values or corrected <italic>p</italic>-values (FWE/FDR) can be selected, with the cut-off alpha level adjusted by the user for both positive and negative test values as desired. This aids in exploring the statistical map not over space and time, but also across levels of significance.</p>
    <p>Neural activity can also be projected on a 3D brain surface imported from BrainSuite from within the results viewer. There are a number of options to for exporting the data in a format that can be viewed in third-party packages. Export into ANALYZE format which can be then further manipulated in CarTool, mri3dX<sup><xref ref-type="fn" rid="footnote3">3</xref></sup>, DataViewer3D (<xref rid="B14" ref-type="bibr">Gouws et al., 2009</xref>), and MRICro (<ext-link ext-link-type="uri" xlink:href="http://www.mricro.com">mricro.com</ext-link>) are available. Extensions of the code from the MATLAB to Python language are in place and support additional viewing tools via Xipy<sup><xref ref-type="fn" rid="footnote4">4</xref></sup>.</p>
    <p>We will now provide demonstrate these steps in practice on three datasets collected on a 275-channel CTF biomagnetometer.</p>
  </sec>
  <sec id="S14">
    <title>NUTMEG in Practice</title>
    <p>In closing, we present two tutorials outlining the step-by-step process for: (1) how to generate source reconstruction maps of evoked fields in NUTMEG, and (2) how to reconstruct induced, non-phase locked sources in the time frequency domain in NUTMEG. Specific examples will use the same dataset (described below) and follow the workflow outlined in the beginning of this article.</p>
    <p>Datasets used in this tutorial are available for public download in both raw and reconstructed (for group analysis purposes) format at the NUTMEG NITRC website<sup><xref ref-type="fn" rid="footnote5">5</xref></sup>. A dataset consisting of MRI (individual subject T1-weighted MRI) and MEG (single run of face/no-face paradigm, see below) were collected from 39 healthy control subjects. MRI data was collected on a Siemens 3.0T scanner using standard anatomical MRI protocols (<xref rid="B21" ref-type="bibr">Hinkley et al., 2019</xref>). MEG data was collected using a 275-channel CTF MEG biomagnetometer. In brief, randomized trials of both face and non-face stimuli were presented foveally on a black background (subtending 12 and 9 degrees of vertical and horizontal visual angle, respectively) requiring the subjects to respond to either “face” or “scrambled face” via button press. 100 neutral face stimuli (<xref rid="B6" ref-type="bibr">Chadick and Gazzaley, 2011</xref>) were equated for gender and transformed to gray scale while 100 non-face stimuli were created by randomly shuffling locations of 25 × 25 pixel regions within each face image in MATLAB (200 trials total). A black oval layer masked both face and non-face stimuli to obscure regions around hairline and ears. Stimulus duration (700 to 1100 ms) and inter-stimulus-onset (1.75 s to 2.15 s) were randomized for each trial.</p>
    <p>Datasets were pre-processed outside of NUTMEG using CTF software in order to meet the following pre-processing criteria: removal of bad channels and trials with excessive movement (&lt;5 mm in run) or noise (signal &gt; 1.5 pT), 3rd order gradiometer correction, bandpass filtered (3–117 Hz), and create a multiple spheres head model prior to source analysis. Correctly-responded trials were then equated for each stimulus type in a movement- and artifact-free epoched dataset. These steps were performed prior to the source analysis outlined below. For both examples, MATLAB paths were set to contain the recent NUTMEG release and SPM8 toolboxes. We begin both examples following opening the main NUTMEG: Neurodynamic Utility Toolbox for MEG and SPM8 visualization windows (<xref ref-type="fig" rid="F2">Figure 2A</xref>). Specific buttons for the GUI are presented in italicized parentheses for each example.</p>
    <sec id="S14.SS1">
      <title>NUTMEG in Practice, Example 1: Source Localization of Visual Evoked Fields in a Single Subject Using Champagne</title>
      <p>In order to localize visual evoked fields from this dataset, we first average the dataset using CTF tools prior to analysis in NUTMEG. Beginning with Step Two (above) we import the subject-specific native space MRI, normalized space MRI and fiducial markers (via headshape) using the Coregistration Tool (<italic>Coregister MRI</italic>) in Nutmeg. Following data import (<italic>Load MEG/EEG Data</italic>) we then check to make sure the averaged sensor data looks reasonable (<italic>View/Select MEG Channels</italic>) and generation of lead fields from the sensor data loaded in (<italic>Obtain Lead Field</italic>) we then import the dataset’s marker file (<italic>Special→Import Markerfile</italic>) to load and select the triggers for this dataset. The timeseries source analysis tool is then selected from the main GUI (<italic>Source Analysis: Time Series</italic>) where several options for beamforming reconstruction become available. We select the default settings for the Champagne beamformer (<xref rid="B25" ref-type="bibr">Owen et al., 2012a</xref>, <xref rid="B26" ref-type="bibr">b</xref>) and apply a 1–100 Hz bandpass filter to data. Selecting the Proceed button allows us to generate the image, which is saved out in a s_beam<sup>∗</sup> file that can be loaded up in the Nutmeg results viewer.</p>
      <p>A single-subject VEF is shown in <xref ref-type="fig" rid="F10">Figure 10</xref>. Here, we are able to localize three visual evoked fields following stimulus presentation. The first, at 92 ms post-stimulus, localizes to the lingual gyrus of primary visual cortex (V1) coincident with the visual evoked response (<xref ref-type="fig" rid="F10">Figure 10A</xref>) around 100 ms. The second responses, localizing to the left (151 ms, <xref ref-type="fig" rid="F10">Figure 10A</xref>), and right (147 ms, <xref ref-type="fig" rid="F10">Figure 10B</xref>) middle occipital gyrus (MOG), correspond to a later, M150 response identifiable in higher order visual and extrastriate fields. These results illustrate that the time-series beamformers implemented in NUTMEG, including Champagne, can reliably localize responses in primary sensory cortices.</p>
      <fig id="F10" position="float">
        <label>FIGURE 10</label>
        <caption>
          <p>Results from a single-subject reconstruction using the Champagne beamformer in NUTMEG for response to visual stimuli (Nutmeg In-Practice, Example 1). Localized fields for both primary visual cortex (∼92 ms, <bold>A</bold>) and higher-order visual fields (142 ms, <bold>B</bold>) are both shown.</p>
        </caption>
        <graphic xlink:href="fnins-14-00710-g010"/>
      </fig>
    </sec>
    <sec id="S14.SS2">
      <title>NUTMEG in Practice, Example 2: Source Localization of Induced Changes in Visual Cortices Using a Time-Frequency Optimized Beamformer and Group Statistics</title>
      <p>Similar steps for data import and preprocessing used in the first example (evoked fields) are used for the reconstruction of induced, non-phase locked sources in the time-frequency domain. Here, instead of using averaged data, single-trial (non-averaged) data is used for the time-frequency optimized beamformer.</p>
      <p>We follow Step 1 (as above) to import individual MRI and normalized images (<xref ref-type="fig" rid="F3">Figure 3</xref>) and load the associated MEG dataset, automatically reading fiducial coordinates from the multiple spheres head model located within the MEG file directory. MRI data was normalized using functions within the SPM8 toolbox prior to import. Fiducial locations were visually inspected after re-selecting “Coregister MRI.” Steps 3 and 4 were followed to inspect the sensor data and, as both structural and functional data are available for an individual, create the forward model based on position of the sensor montage relative to MRI landmarks.</p>
      <p>As the current study requires comparison of two visually-presented conditions, both trial types are included in the epoched CTF MEG dataset. For this example, we compare our experimental (Face), and control (Non-face) conditions over each time window, localizing brain regions that are specific to face identification and not simple visual processing. Trial types are identified using their stimulus markers via the “Import CTF marker file” drop down option in the “Special” menu (<xref ref-type="fig" rid="F3">Figure 3B</xref>). The individual’s structural and functional data, lead field calculation for each sensor, and the specification of “active” or “control” marker type in the beamforming calculation was then saved (via “save session”) to utilize in source localization and for the convenience of returning to an already-associated dataset if other analyzes are desired in the future. Because the contrast of interest is the differential response to two stimuli, our time windows of interest for active and control are identical — spanning stimulus presentation through end of trial. Had our aim been simple sensory response activation (as in Example 1), active and control stimulus markers would be identical, with active time window through post-stimulus trial duration and the control as a static, pre-stimulus time period. Window lengths and frequency band(s) can be custom-defined in the time-frequency dependent on the sampling rate of the dataset acquired, using the Nyquist limit as a guideline. To initiate the induced time-frequency beamforming analysis, we select the lower “Source Analysis: time-frequency.” option which brings up the time-frequency GUI (<xref ref-type="fig" rid="F6">Figure 6</xref>). Here, we specify our Active (i.e., experimental) and Control window length, time window overlap, beamformer algorithm and frequency band(s) of interest (<xref ref-type="fig" rid="F6">Figure 6</xref>).</p>
      <p>In the example study, source localization of 39 participants’ data was batched via NUTMEG command line functions, and run over 5 frequency bands of interest across sliding time windows that covered the trial period, the size of which varied according to bandwidth. Once source localization completed, creating multiple files for each subject, these were consolidated into one result file per individual (“Assemble multiple outputs” selection in the source localization GUI).</p>
      <p>After the consolidated result file was created for a single subject, the “View Results” selection within the main NUTMEG menu visualizes the single subject result across the time and frequency bands analyzed, and also provides a mechanism to read in multiple subjects’ localized data into the NUTMEG workspace by indexing the subsequent subject number and corresponding condition and selecting “Load” in the File Browser portion of the viewer. After reading in each of the 39 participants in this section, a pointer file was created and saved that included all subjects’ filenames, paths, subject numbers, and condition information associated with each individual source localization result file. This pointer file is used in the group analysis run via the “Statistics” button on the main NUTMEG window.</p>
      <p>After reconstruction of all 39 subjects, this pointer file is imported into the NUTMEG Statistical GUI for within-group results of the Face &gt; Non-face contrast. This creates a single file (<sup>∗</sup>ttest1.mat) which can be loaded in the NUTMEG results viewer (<xref ref-type="fig" rid="F11">Figure 11</xref>). The group analysis produces an average activation map for the active (Face) relative to the control (Non-face) condition for the group using a one sample, two-tailed, SnPM <italic>t</italic>-test, with a statistical threshold of <italic>p</italic> &lt; 0.05 under an FDR correction for multiple time windows. This group result reveals significant induced response in high gamma band activity, Faces &gt; Non-faces, in right fusiform gyrus.</p>
      <fig id="F11" position="float">
        <label>FIGURE 11</label>
        <caption>
          <p>Results from the group analysis using the time-frequency optimized beamformer comparing face to non-face conditions (Nutmeg In-Practice, Example 2). An early increase in high-gamma power (63–117 Hz) localized to the right fusiform is greater in the face condition around 187.5 ms following stimulus presentation.</p>
        </caption>
        <graphic xlink:href="fnins-14-00710-g011"/>
      </fig>
    </sec>
  </sec>
  <sec id="S15">
    <title>Discussion</title>
    <p>The M/EEG community is rapidly shifting and expanding, and as NUTMEG now is well into its fourth version, a large focus of our development is centered on being able to incorporate and integrate advanced functionality to meet these needs. A prime example of this is making sure that NUTMEG integrates and interfaces with many of the other software packages available to analyze M/EEG data, allowing the user to seamlessly move datasets and analyzes between the platforms to benefit the most from the strengths of each. With resurgence in both EEG and ECOG research for the purpose of performing source analysis, much work is being done to integrate these types of data into the analysis framework of NUTMEG. While pipelines exist to import more sophisticated head models (like BEM) for source localization in NUTMEG, we are currently working on options for the user to apply these methods directly in the workbench, as well as options for both volume and surface-based source reconstructions. Our own lab and others continually refine and improve inverse methods for the purposes of improving source localization, and our developers are continually at work to include these types of novel techniques available to the NUTMEG user. In the same vein, statistical metrics (including corrections for multiple comparisons at the voxelwise level) and functional connectivity methods continue to evolve and will be added in future versions of the software. Expanded options for multimodal data integration (for example, voxel-based morphometry, and diffusion tensor imaging) will be available in future versions of the software. We also plan to expand the options available for the user at early stages of data preparation, including trial selection for both artifact rejection and trial-by-trial analyzes. Furthermore, the integration of multiple sensor types (e.g., magnetometers and planar gradiometers) in a way that would add value to the robustness of the source solution is another area of robust research in MEG (see <xref rid="B15" ref-type="bibr">Gramfort et al., 2013</xref>; <xref rid="B13" ref-type="bibr">Engemann and Gramfort, 2015</xref>), and could potentially be integrated into next-generation releases versions of NUTMEG.</p>
    <p>Many of the programming environments used for the analysis of neuroimaging data (including NUTMEG) are proprietary extensions of existing computing environments (in our case, MATLAB) optimal for applied mathematics and not imaging analysis <italic>per se</italic>. While MATLAB is the most popular computing platform in neuroscience, it is becoming increasingly clear that newer programming environments may additionally serve data analytics. In order to expand NUTMEG into a true open-source environment, there is a need for future generations of the workbench to be coded in programming languages that are more accessible. Python<sup><xref ref-type="fn" rid="footnote6">6</xref></sup> is a logical choice for next-generation software development in neuroimaging, as it is high-level, object-oriented and interactive. As software development in Python has proven fruitful in other M/EEG analysis software packages (most notably MNE-Python). we plan to produce versions of NUTMEG in this programming language, further providing access to the software.</p>
    <p>On a final note, MEG is entering a modern “renaissance” at the hardware level. Not only are new biomagnetometer manufacturers (such as RICOH of Japan) entering the scene, but exciting developments in so-called “helium-free” or “room-temp” magnetometers (including the HyQUID system offered by York Instruments and the optically-pumped magnetometers outlined in <xref rid="B1" ref-type="bibr">Boto et al., 2017</xref>) provide new potential avenues of data integration for NUTMEG. While this may introduce a unique set of challenges for the regular imaging scientist, as part of our mission, we will ensure that NUTMEG is accessible for every MEG user, regardless of hardware. We welcome and encourage collaborators and developers who wish to contribute to this endeavor.</p>
  </sec>
  <sec sec-type="data-availability" id="S16">
    <title>Data Availability Statement</title>
    <p>The datasets generated for this study are available on the NITRC website (<ext-link ext-link-type="uri" xlink:href="http://nitrc.org/projects/nutmeg/">nitrc.org/projects/nutmeg/</ext-link>) or by request to the corresponding author.</p>
  </sec>
  <sec id="S17">
    <title>Ethics Statement</title>
    <p>The studies involving human participants were reviewed and approved by UCSF Committee on Human Research. The patients/participants provided their written informed consent to participate in this study.</p>
  </sec>
  <sec id="S18">
    <title>Author Contributions</title>
    <p>LH, CD, and SN contributed to writing this manuscript. JZ, SD, CC, KS, and SN designed the analyses used in the manuscript. AF assisted in collection of the data presented in the manuscript. All authors contributed to the article and approved the submitted version.</p>
  </sec>
  <sec id="conf1">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn fn-type="financial-disclosure">
      <p><bold>Funding.</bold> This work was supported by NIH grants R01EB022717, R01DC013979, R01NS100440, R01DC017091, R01AG062196, R01DC0176960, and UCOP-MRP-17-454755.</p>
    </fn>
  </fn-group>
  <fn-group>
    <fn id="footnote1">
      <label>1</label>
      <p>
        <ext-link ext-link-type="uri" xlink:href="https://www.nitrc.org/projects/nutmeg">https://www.nitrc.org/projects/nutmeg</ext-link>
      </p>
    </fn>
    <fn id="footnote2">
      <label>2</label>
      <p>
        <ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk/spm/software/spm8">https://www.fil.ion.ucl.ac.uk/spm/software/spm8</ext-link>
      </p>
    </fn>
    <fn id="footnote3">
      <label>3</label>
      <p>
        <ext-link ext-link-type="uri" xlink:href="http://www.cubric.cf.ac.uk/Documentation/mri3dX">www.cubric.cf.ac.uk/Documentation/mri3dX</ext-link>
      </p>
    </fn>
    <fn id="footnote4">
      <label>4</label>
      <p>
        <ext-link ext-link-type="uri" xlink:href="https://github.com/miketrumpis/xipy">https://github.com/miketrumpis/xipy</ext-link>
      </p>
    </fn>
    <fn id="footnote5">
      <label>5</label>
      <p>
        <ext-link ext-link-type="uri" xlink:href="https://www.nitrc.org/projects/nutmeg">https://www.nitrc.org/projects/nutmeg</ext-link>
      </p>
    </fn>
    <fn id="footnote6">
      <label>6</label>
      <p>
        <ext-link ext-link-type="uri" xlink:href="http://www.python.org">www.python.org</ext-link>
      </p>
    </fn>
  </fn-group>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boto</surname><given-names>E.</given-names></name><name><surname>Meyer</surname><given-names>S. S.</given-names></name><name><surname>Shah</surname><given-names>V.</given-names></name><name><surname>Alem</surname><given-names>O.</given-names></name><name><surname>Knappe</surname><given-names>S.</given-names></name><name><surname>Kruger</surname><given-names>P.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>A new generation of magnetoencephalography: room temperature measurements using optically-pumped magnetometers.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>149</volume>
<fpage>404</fpage>–<lpage>414</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.01.034</pub-id>
<?supplied-pmid 28131890?><pub-id pub-id-type="pmid">28131890</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brookes</surname><given-names>M. J.</given-names></name><name><surname>Hale</surname><given-names>J. R.</given-names></name><name><surname>Zumer</surname><given-names>J. M.</given-names></name><name><surname>Stevenson</surname><given-names>C. M.</given-names></name><name><surname>Francis</surname><given-names>S. T.</given-names></name><name><surname>Barnes</surname><given-names>G. R.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Measuring functional connectivity using MEG: methodology and comparison with fcMRI.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>56</volume>
<fpage>1082</fpage>–<lpage>1104</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.02.054</pub-id>
<?supplied-pmid 21352925?><pub-id pub-id-type="pmid">21352925</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>C.</given-names></name><name><surname>Diwakar</surname><given-names>M.</given-names></name><name><surname>Sekihara</surname><given-names>K.</given-names></name><name><surname>Nagarajan</surname><given-names>S. S.</given-names></name></person-group> (<year>2018a</year>). “<article-title>COGNAC: a novel Bayesian scanning algorithm for electromagnetic brain imaging</article-title>,” in <source><italic>Proceedings of the Society for Biomagnetism 2018 Annual Meeting</italic></source>, Philadelphia, PA.</mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>C.</given-names></name><name><surname>Kang</surname><given-names>H.</given-names></name><name><surname>Kirsch</surname><given-names>H. E.</given-names></name><name><surname>Mizuiri</surname><given-names>D.</given-names></name><name><surname>Chen</surname><given-names>J.</given-names></name><name><surname>Bhutada</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Comparison of DSSP and tSSS algorithms for removing artifacts from vagus nerve stimulators in magnetoencephalography data.</article-title>
<source><italic>J. Neural Eng.</italic></source>
<volume>16</volume>:<issue>066045</issue>. <pub-id pub-id-type="doi">10.1088/1741-2552/ab4065</pub-id>
<?supplied-pmid 31476752?><pub-id pub-id-type="pmid">31476752</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>C.</given-names></name><name><surname>Sekihara</surname><given-names>K.</given-names></name><name><surname>Nagarajan</surname><given-names>S. S.</given-names></name></person-group> (<year>2018b</year>). <article-title>Hierarchical multiscale Bayesian algorithm for robust MEG/EEG source reconstruction.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>183</volume>
<fpage>698</fpage>–<lpage>715</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.07.056</pub-id>
<?supplied-pmid 30059734?><pub-id pub-id-type="pmid">30059734</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chadick</surname><given-names>J. Z.</given-names></name><name><surname>Gazzaley</surname><given-names>A.</given-names></name></person-group> (<year>2011</year>). <article-title>Differential coupling of visual cortex with default network or frontal-parietal network based on goals.</article-title>
<source><italic>Nat. Neurosci.</italic></source>
<volume>14</volume>
<fpage>830</fpage>–<lpage>832</lpage>. <pub-id pub-id-type="doi">10.1038/nn.2823</pub-id>
<?supplied-pmid 21623362?><pub-id pub-id-type="pmid">21623362</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalal</surname><given-names>S. S.</given-names></name><name><surname>Guggisberg</surname><given-names>A. G.</given-names></name><name><surname>Edwards</surname><given-names>E.</given-names></name><name><surname>Sekihara</surname><given-names>K.</given-names></name><name><surname>Findlay</surname><given-names>A. M.</given-names></name><name><surname>Canolty</surname><given-names>R. T.</given-names></name><etal/></person-group> (<year>2008</year>). <article-title>Five-dimensional neuroimaging: localization of the time-frequency dynamics of cortical activity.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>40</volume>
<fpage>1686</fpage>–<lpage>1700</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.01.023</pub-id>
<?supplied-pmid 18356081?><pub-id pub-id-type="pmid">18356081</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalal</surname><given-names>S. S.</given-names></name><name><surname>Sekihara</surname><given-names>K.</given-names></name><name><surname>Nagarajan</surname><given-names>S. S.</given-names></name></person-group> (<year>2006</year>). <article-title>Modified beamformers for coherent source region suppression.</article-title>
<source><italic>IEEE Trans. Biomed. Eng.</italic></source>
<volume>53</volume>
<fpage>1357</fpage>–<lpage>1363</lpage>. <pub-id pub-id-type="doi">10.1109/tbme.2006.873752</pub-id>
<?supplied-pmid 16830939?><pub-id pub-id-type="pmid">16830939</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalal</surname><given-names>S. S.</given-names></name><name><surname>Zumer</surname><given-names>J. M.</given-names></name><name><surname>Agrawal</surname><given-names>V.</given-names></name><name><surname>Hild</surname><given-names>K. E.</given-names></name><name><surname>Sekihara</surname><given-names>K.</given-names></name><name><surname>Nagarajan</surname><given-names>S. S.</given-names></name></person-group> (<year>2004</year>). <article-title>NUTMEG: a neuromagnetic source reconstruction toolbox.</article-title>
<source><italic>Neurol. Clin. Neurophysiol.</italic></source>
<volume>2004</volume>:<issue>52</issue>.</mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalal</surname><given-names>S. S.</given-names></name><name><surname>Zumer</surname><given-names>J. M.</given-names></name><name><surname>Guggisberg</surname><given-names>A. G.</given-names></name><name><surname>Trumpis</surname><given-names>M.</given-names></name><name><surname>Wong</surname><given-names>D. D. E.</given-names></name><name><surname>Sekihara</surname><given-names>K.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>MEG/EEG source reconstruction, statistical evaluation, and visualization with NUTMEG.</article-title>
<source><italic>Comput. Intell. Neurosci.</italic></source>
<volume>758</volume>:<issue>973</issue>.</mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dale</surname><given-names>A. M.</given-names></name><name><surname>Liu</surname><given-names>A. K.</given-names></name><name><surname>Fischl</surname><given-names>B. R.</given-names></name><name><surname>Buckner</surname><given-names>R. L.</given-names></name><name><surname>Belliveau</surname><given-names>J. W.</given-names></name><name><surname>Lewine</surname><given-names>J. D.</given-names></name><etal/></person-group> (<year>2000</year>). <article-title>Dynamic statistical parametric mapping: combining fMRI and MEG for high-resolution imaging of cortical activity.</article-title>
<source><italic>Neuron</italic></source>
<volume>26</volume>
<fpage>55</fpage>–<lpage>67</lpage>.<pub-id pub-id-type="pmid">10798392</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dubovik</surname><given-names>S.</given-names></name><name><surname>Pignat</surname><given-names>J. M.</given-names></name><name><surname>Ptak</surname><given-names>R.</given-names></name><name><surname>Aboulafia</surname><given-names>T.</given-names></name><name><surname>Allet</surname><given-names>L.</given-names></name><name><surname>Gillabert</surname><given-names>N.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>The behavioral significance of coherent resting-state oscillations after stroke.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>61</volume>
<fpage>249</fpage>–<lpage>257</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.03.024</pub-id>
<?supplied-pmid 22440653?><pub-id pub-id-type="pmid">22440653</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engemann</surname><given-names>D. A.</given-names></name><name><surname>Gramfort</surname><given-names>A.</given-names></name></person-group> (<year>2015</year>). <article-title>Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>108</volume>
<fpage>328</fpage>–<lpage>342</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.12.040</pub-id>
<?supplied-pmid 25541187?><pub-id pub-id-type="pmid">25541187</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gouws</surname><given-names>A.</given-names></name><name><surname>Woods</surname><given-names>W.</given-names></name><name><surname>Millman</surname><given-names>R.</given-names></name><name><surname>Morland</surname><given-names>A.</given-names></name><name><surname>Green</surname><given-names>G.</given-names></name></person-group> (<year>2009</year>). <article-title>Dataviewer3D: an open-source, cross-platform multi-modal neuroimaging data visualization tool.</article-title>
<source><italic>Front. Neuroinform.</italic></source>
<volume>3</volume>:<issue>9</issue>. <pub-id pub-id-type="doi">10.3389/neuro.11.009.2009</pub-id>
<?supplied-pmid 19352444?><pub-id pub-id-type="pmid">19352444</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramfort</surname><given-names>A.</given-names></name><name><surname>Luessi</surname><given-names>M.</given-names></name><name><surname>Larson</surname><given-names>E.</given-names></name><name><surname>Engemann</surname><given-names>D. A.</given-names></name><name><surname>Strohmeier</surname><given-names>D.</given-names></name><name><surname>Brodbeck</surname><given-names>C.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>MEG and EEG data analysis with MNE-Python Front.</article-title>
<source><italic>Neuroscience</italic></source>
<volume>7</volume>:<issue>267</issue>.</mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramfort</surname><given-names>A.</given-names></name><name><surname>Papadopoulo</surname><given-names>T.</given-names></name><name><surname>Olivi</surname><given-names>E.</given-names></name><name><surname>Clerc</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>). <article-title>OpenMEEG: opensource software for quasistatic bioelectromagnetics.</article-title>
<source><italic>Biomed. Eng. Online</italic></source>
<volume>9</volume>:<issue>45</issue>. <pub-id pub-id-type="doi">10.1186/1475-925x-9-45</pub-id>
<?supplied-pmid 20819204?><pub-id pub-id-type="pmid">20819204</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guggisberg</surname><given-names>A. G.</given-names></name><name><surname>Dalal</surname><given-names>S. S.</given-names></name><name><surname>Findlay</surname><given-names>A. M.</given-names></name><name><surname>Nagarajan</surname><given-names>S. S.</given-names></name></person-group> (<year>2010</year>). <article-title>High-frequency oscillations in distributed neural networks reveal the dynamics of human decision making.</article-title>
<source><italic>Front. Hum. Neurosci.</italic></source>
<volume>1</volume>:<issue>14</issue>. <pub-id pub-id-type="doi">10.3389/neuro.09.014.2007</pub-id>
<?supplied-pmid 18958227?><pub-id pub-id-type="pmid">18958227</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guggisberg</surname><given-names>A. G.</given-names></name><name><surname>Honma</surname><given-names>S. M.</given-names></name><name><surname>Findlay</surname><given-names>A. M.</given-names></name><name><surname>Dalal</surname><given-names>S. S.</given-names></name><name><surname>Kirsch</surname><given-names>H. E.</given-names></name><name><surname>Berger</surname><given-names>M. S.</given-names></name><etal/></person-group> (<year>2008</year>). <article-title>Mapping functional connectivity in patients with brain lesions.</article-title>
<source><italic>Ann. Neurol.</italic></source>
<volume>63</volume>
<fpage>193</fpage>–<lpage>203</lpage>.<pub-id pub-id-type="pmid">17894381</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hamalainen</surname><given-names>M.</given-names></name><name><surname>Ilmoniemi</surname><given-names>R.</given-names></name></person-group> (<year>1984</year>). <source><italic>Interpreting Magnetic Fields of the Brain: Minimum Norm Estimates</italic>. Technical Report TKK-F-A559</source>. <publisher-loc>Espoo</publisher-loc>: <publisher-name>Helsinki University of Technology</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hinkley</surname><given-names>L. B.</given-names></name><name><surname>Vinogradov</surname><given-names>S.</given-names></name><name><surname>Guggisberg</surname><given-names>A. G.</given-names></name><name><surname>Fisher</surname><given-names>M.</given-names></name><name><surname>Findlay</surname><given-names>A. M.</given-names></name><name><surname>Nagarajan</surname><given-names>S. S.</given-names></name></person-group> (<year>2011</year>). <article-title>Clinical symptoms and alpha band resting-state functional connectivity imaging in patients with schizophrenia: implications for novel approaches to treatment.</article-title>
<source><italic>Biol. Psychiatry</italic></source>
<volume>70</volume>
<fpage>1134</fpage>–<lpage>1142</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsych.2011.06.029</pub-id>
<?supplied-pmid 21861988?><pub-id pub-id-type="pmid">21861988</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hinkley</surname><given-names>L. B. N.</given-names></name><name><surname>Dale</surname><given-names>C. L.</given-names></name><name><surname>Luks</surname><given-names>T. L.</given-names></name><name><surname>Findlay</surname><given-names>A. M.</given-names></name><name><surname>Bukshpun</surname><given-names>P.</given-names></name><name><surname>Pojman</surname><given-names>T.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Sensorimotor cortical oscillations during movement preparation in 16p11.2 deletion carriers.</article-title>
<source><italic>J. Neurosci.</italic></source>
<volume>39</volume>
<fpage>7321</fpage>–<lpage>7331</lpage>. <pub-id pub-id-type="doi">10.1523/jneurosci.3001-17.2019</pub-id>
<?supplied-pmid 31270155?><pub-id pub-id-type="pmid">31270155</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagarajan</surname><given-names>S. S.</given-names></name><name><surname>Attias</surname><given-names>H. T.</given-names></name><name><surname>Hild</surname><given-names>K. E.</given-names></name><name><surname>Sekihara</surname><given-names>K.</given-names></name></person-group> (<year>2007</year>). <article-title>A probabilistic algorithm for robust interference suppression in bioelectromagnetic sensor data.</article-title>
<source><italic>Stat. Med.</italic></source>
<volume>26</volume>
<fpage>3886</fpage>–<lpage>3910</lpage>. <pub-id pub-id-type="doi">10.1002/sim.2941</pub-id>
<?supplied-pmid 17546712?><pub-id pub-id-type="pmid">17546712</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nolte</surname><given-names>G.</given-names></name><name><surname>Bai</surname><given-names>O.</given-names></name><name><surname>Wheaton</surname><given-names>L.</given-names></name><name><surname>Mari</surname><given-names>Z.</given-names></name><name><surname>Vorbach</surname><given-names>S.</given-names></name><name><surname>Hallett</surname><given-names>M.</given-names></name></person-group> (<year>2004</year>). <article-title>Identifying true brain interaction from EEG data using the imaginary part of coherency.</article-title>
<source><italic>Clin. Neurophysiol.</italic></source>
<volume>115</volume>
<fpage>2292</fpage>–<lpage>2307</lpage>. <pub-id pub-id-type="doi">10.1016/j.clinph.2004.04.029</pub-id>
<?supplied-pmid 15351371?><pub-id pub-id-type="pmid">15351371</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R.</given-names></name><name><surname>Fries</surname><given-names>P.</given-names></name><name><surname>Maris</surname><given-names>E.</given-names></name><name><surname>Schoffelen</surname><given-names>J. M.</given-names></name></person-group> (<year>2011</year>). <article-title>Field trip: open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data.</article-title>
<source><italic>Comput. Intell. Neurosci.</italic></source>
<volume>156</volume>:<issue>869</issue>.</mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Owen</surname><given-names>J. P.</given-names></name><name><surname>Sekihara</surname><given-names>K.</given-names></name><name><surname>Nagarajan</surname><given-names>S. S.</given-names></name></person-group> (<year>2012a</year>). <article-title>Non-parametric statistical thresholding for sparse magnetoencephalography source reconstructions.</article-title>
<source><italic>Front. Neurosci.</italic></source>
<volume>6</volume>:<issue>186</issue>. <pub-id pub-id-type="doi">10.3389/fnins.2012.00186</pub-id>
<?supplied-pmid 23271990?><pub-id pub-id-type="pmid">23271990</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Owen</surname><given-names>J. P.</given-names></name><name><surname>Wipf</surname><given-names>D. P.</given-names></name><name><surname>Attias</surname><given-names>H. T.</given-names></name><name><surname>Sekihara</surname><given-names>K.</given-names></name><name><surname>Nagarajan</surname><given-names>S. S.</given-names></name></person-group> (<year>2012b</year>). <article-title>Performance evaluation of the Champagne source reconstruction algorithm on simulated and real M/EEG data.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>60</volume>
<fpage>305</fpage>–<lpage>323</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.12.027</pub-id>
<?supplied-pmid 22209808?><pub-id pub-id-type="pmid">22209808</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pascual-Marqui</surname><given-names>R. D.</given-names></name></person-group> (<year>2002</year>). <article-title>Standardized low-resolution brain electromagnetic tomography (sLORETA): technical details.</article-title>
<source><italic>Methods Find. Exp. Clin. Pharmacol.</italic></source>
<volume>24 Suppl D</volume>
<fpage>5</fpage>–<lpage>12</lpage>.<pub-id pub-id-type="pmid">12575463</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pascual-Marqui</surname><given-names>R. D.</given-names></name><name><surname>Lehmann</surname><given-names>D.</given-names></name><name><surname>Koukkou</surname><given-names>M.</given-names></name><name><surname>Kochi</surname><given-names>K.</given-names></name><name><surname>Anderer</surname><given-names>P.</given-names></name><name><surname>Saletu</surname><given-names>B.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Assessing interactions in the brain with exact low-resolution electromagnetic tomography.</article-title>
<source><italic>Philos. Transact. A Math. Phys. Eng. Sci.</italic></source>
<volume>369</volume>
<fpage>3768</fpage>–<lpage>3784</lpage>. <pub-id pub-id-type="doi">10.1098/rsta.2011.0081</pub-id>
<?supplied-pmid 21893527?><pub-id pub-id-type="pmid">21893527</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sekihara</surname><given-names>K.</given-names></name><name><surname>Kawabata</surname><given-names>Y.</given-names></name><name><surname>Ushio</surname><given-names>S.</given-names></name><name><surname>Sumiya</surname><given-names>S.</given-names></name><name><surname>Kawabata</surname><given-names>S.</given-names></name><name><surname>Adachi</surname><given-names>Y.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Dual signal subspace projection (DSSP): a novel algorithm for removing large interference in Biomagnetic measurements.</article-title>
<source><italic>J. Neural Eng.</italic></source>
<volume>13</volume>:<issue>036007</issue>
<pub-id pub-id-type="doi">10.1088/1741-2560/13/3/036007</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sekihara</surname><given-names>K.</given-names></name><name><surname>Nagarajan</surname><given-names>S. S.</given-names></name></person-group> (<year>2008</year>). <source><italic>Adaptive Spatial Filters for Electromagnetic Brain Imaging.</italic></source>
<publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>K. D.</given-names></name><name><surname>Barnes</surname><given-names>G. R.</given-names></name><name><surname>Hillebrand</surname><given-names>A.</given-names></name></person-group> (<year>2003</year>). <article-title>Group imaging of task-related changes in cortical synchronisation using nonparametric permutation testing.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>19</volume>
<fpage>1589</fpage>–<lpage>1601</lpage>. <pub-id pub-id-type="doi">10.1016/s1053-8119(03)00249-0</pub-id><pub-id pub-id-type="pmid">12948714</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stam</surname><given-names>C. J.</given-names></name><name><surname>Nolte</surname><given-names>G.</given-names></name><name><surname>Daffertshofer</surname><given-names>A.</given-names></name></person-group> (<year>2007</year>). <article-title>Phase lag index: assessment of functional connectivity from multi channel EEG and MEG with diminished bias from common sources.</article-title>
<source><italic>Hum. Brain Mapp.</italic></source>
<volume>28</volume>
<fpage>1178</fpage>–<lpage>1193</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.20346</pub-id>
<?supplied-pmid 17266107?><pub-id pub-id-type="pmid">17266107</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stenroos</surname><given-names>M.</given-names></name><name><surname>Mäntynen</surname><given-names>V.</given-names></name><name><surname>Nenonen</surname><given-names>J.</given-names></name></person-group> (<year>2007</year>). <article-title>A Matlab library for solving quasi-static volume conduction problems using the boundary element method.</article-title>
<source><italic>Comput. Methods Programs Biomed.</italic></source>
<volume>88</volume>
<fpage>256</fpage>–<lpage>263</lpage>. <pub-id pub-id-type="doi">10.1016/j.cmpb.2007.09.004</pub-id>
<?supplied-pmid 18022274?><pub-id pub-id-type="pmid">18022274</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tadel</surname><given-names>F.</given-names></name><name><surname>Baillet</surname><given-names>S.</given-names></name><name><surname>Mosher</surname><given-names>J. C.</given-names></name><name><surname>Pantazis</surname><given-names>D.</given-names></name><name><surname>Leahy</surname><given-names>R. M.</given-names></name></person-group> (<year>2011</year>). <article-title>Brainstorm: a user-friendly application for MEG/EEG analysis.</article-title>
<source><italic>Comput. Intell. Neurosci.</italic></source>
<volume>2011</volume>:<issue>879716</issue>. <pub-id pub-id-type="doi">10.1155/2011/879716</pub-id>
<?supplied-pmid 21584256?><pub-id pub-id-type="pmid">21584256</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><collab>The Open Source Initiative</collab> (<year>2004</year>). <source><italic>The BSD License (2004).</italic></source> Available online at: <ext-link ext-link-type="uri" xlink:href="http://www.opensource.org/licenses/bsd-license.php">http://www.opensource.org/licenses/bsd-license.php</ext-link>
<comment>(accessed March 26, 2020)</comment>.</mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tzourio-Mazoyer</surname><given-names>N.</given-names></name><name><surname>Landeau</surname><given-names>B.</given-names></name><name><surname>Papathanassiou</surname><given-names>D.</given-names></name><name><surname>Crivello</surname><given-names>F.</given-names></name><name><surname>Etard</surname><given-names>O.</given-names></name><name><surname>Delcroix</surname><given-names>N.</given-names></name><etal/></person-group> (<year>2002</year>). <article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>15</volume>
<fpage>273</fpage>–<lpage>289</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.2001.0978</pub-id>
<?supplied-pmid 11771995?><pub-id pub-id-type="pmid">11771995</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vrba</surname><given-names>J.</given-names></name><name><surname>Robinson</surname><given-names>S. E.</given-names></name></person-group> (<year>2001</year>). <article-title>Signal processing in magnetoencephalography.</article-title>
<source><italic>Methods</italic></source>
<volume>25</volume>
<fpage>249</fpage>–<lpage>271</lpage>. <pub-id pub-id-type="doi">10.1006/meth.2001.1238</pub-id>
<?supplied-pmid 11812209?><pub-id pub-id-type="pmid">11812209</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zumer</surname><given-names>J. M.</given-names></name><name><surname>Attias</surname><given-names>H. T.</given-names></name><name><surname>Sekihara</surname><given-names>K.</given-names></name><name><surname>Nagarajan</surname><given-names>S. S.</given-names></name></person-group> (<year>2007</year>). <article-title>A probabilistic algorithm integrating source localization and noise suppression for MEG and EEG data.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>37</volume>
<fpage>102</fpage>–<lpage>115</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.04.054</pub-id>
<?supplied-pmid 17574444?><pub-id pub-id-type="pmid">17574444</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zumer</surname><given-names>J. M.</given-names></name><name><surname>Attias</surname><given-names>H. T.</given-names></name><name><surname>Sekihara</surname><given-names>K.</given-names></name><name><surname>Nagarajan</surname><given-names>S. S.</given-names></name></person-group> (<year>2008</year>). <article-title>Probabilistic algorithms for MEG/EEG source reconstruction using temporal basis functions learned from data.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>41</volume>
<fpage>924</fpage>–<lpage>940</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.02.006</pub-id>
<?supplied-pmid 18455439?><pub-id pub-id-type="pmid">18455439</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
