<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Nat Commun</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id>
    <journal-title-group>
      <journal-title>Nature Communications</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2041-1723</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9968329</article-id>
    <article-id pub-id-type="pmid">36841846</article-id>
    <article-id pub-id-type="publisher-id">36736</article-id>
    <article-id pub-id-type="doi">10.1038/s41467-023-36736-1</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Hierarchical graph learning for protein–protein interaction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7417-3620</contrib-id>
        <name>
          <surname>Gao</surname>
          <given-names>Ziqi</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jiang</surname>
          <given-names>Chenran</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Jiawen</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jiang</surname>
          <given-names>Xiaosen</given-names>
        </name>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1998-4022</contrib-id>
        <name>
          <surname>Li</surname>
          <given-names>Lanqing</given-names>
        </name>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhao</surname>
          <given-names>Peilin</given-names>
        </name>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0858-3410</contrib-id>
        <name>
          <surname>Yang</surname>
          <given-names>Huanming</given-names>
        </name>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8377-8923</contrib-id>
        <name>
          <surname>Huang</surname>
          <given-names>Yong</given-names>
        </name>
        <address>
          <email>yonghuang@ust.hk</email>
        </address>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6362-4385</contrib-id>
        <name>
          <surname>Li</surname>
          <given-names>Jia</given-names>
        </name>
        <address>
          <email>jialee@ust.hk</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.24515.37</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 1450</institution-id><institution>Data Science and Analytics, </institution><institution>The Hong Kong University of Science and Technology, </institution></institution-wrap>Guangzhou, 511400 China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.24515.37</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 1450</institution-id><institution>Division of Emerging Interdisciplinary Areas, </institution><institution>The Hong Kong University of Science and Technology, </institution></institution-wrap>Hong Kong SAR, China </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.510951.9</institution-id><institution-id institution-id-type="ISNI">0000 0004 7775 6738</institution-id><institution>Pingshan Translational Medicine Center, </institution><institution>Shenzhen Bay Laboratory, </institution></institution-wrap>Shenzhen, 518118 China </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.410726.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 1797 8419</institution-id><institution>The Cancer Hospital of the University of Chinese Academy of Sciences (Zhejiang Cancer Hospital), Chinese Academy of Sciences, </institution></institution-wrap>Hangzhou, 310022 China </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="GRID">grid.471330.2</institution-id><institution-id institution-id-type="ISNI">0000 0004 6359 9743</institution-id><institution>AI Lab, Tencent, </institution></institution-wrap>Shenzhen, 518000 China </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="GRID">grid.24515.37</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 1450</institution-id><institution>Department of Chemistry, </institution><institution>The Hong Kong University of Science and Technology, </institution></institution-wrap>Hong Kong SAR, China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>25</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>25</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>14</volume>
    <elocation-id>1093</elocation-id>
    <history>
      <date date-type="received">
        <day>18</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>2</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Protein-Protein Interactions (PPIs) are fundamental means of functions and signalings in biological systems. The massive growth in demand and cost associated with experimental PPI studies calls for computational tools for automated prediction and understanding of PPIs. Despite recent progress, in silico methods remain inadequate in modeling the natural PPI hierarchy. Here we present a double-viewed hierarchical graph learning model, HIGH-PPI, to predict PPIs and extrapolate the molecular details involved. In this model, we create a hierarchical graph, in which a node in the PPI network (top outside-of-protein view) is a protein graph (bottom inside-of-protein view). In the bottom view, a group of chemically relevant descriptors, instead of the protein sequences, are used to better capture the structure-function relationship of the protein. HIGH-PPI examines both outside-of-protein and inside-of-protein of the human interactome to establish a robust machine understanding of PPIs. This model demonstrates high accuracy and robustness in predicting PPIs. Moreover, HIGH-PPI can interpret the modes of action of PPIs by identifying important binding and catalytic sites precisely. Overall, “HIGH-PPI [<ext-link ext-link-type="uri" xlink:href="https://github.com/zqgao22/HIGH-PPI">https://github.com/zqgao22/HIGH-PPI</ext-link>]” is a domain-knowledge-driven and interpretable framework for PPI prediction studies.</p>
    </abstract>
    <abstract id="Abs2" abstract-type="web-summary">
      <p id="Par2">Despite recent progress, machine learning methods remain inadequate in modeling the natural protein-protein interaction (PPI) hierarchy for PPI prediction. Here, the authors present a double-viewed hierarchical graph learning model, HIGH-PPI, to predict PPIs and extrapolate the molecular details involved.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Machine learning</kwd>
      <kwd>Proteome informatics</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China (National Science Foundation of China)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>21825101</award-id>
        <award-id>62206067</award-id>
        <principal-award-recipient>
          <name>
            <surname>Huang</surname>
            <given-names>Yong</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Jia</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Tencent AI Lab Rhino-Bird Focused Research Program RBFR2022008; Guangzhou-HKUST(GZ) Joint Funding Scheme</institution>
        </funding-source>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2023</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par3">Biological functions are accomplished by interactions and chemical reactions among biomolecules. Among them, protein–protein interactions (PPIs) are arguably one of the most important molecular events in the human body and are an important source of therapeutic interventions against diseases. A comprehensive dictionary of PPIs can help connect the dots in complicated biological pathways and expedite the development of therapeutic<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR2">2</xref></sup>. In biology, hierarchy information has been widely exploited to gain in-depth information about phenotypes of interest, for example, in disease biology<sup><xref ref-type="bibr" rid="CR3">3</xref>–<xref ref-type="bibr" rid="CR5">5</xref></sup>, proteomics<sup><xref ref-type="bibr" rid="CR6">6</xref>–<xref ref-type="bibr" rid="CR8">8</xref></sup>, and neurobiology<sup><xref ref-type="bibr" rid="CR9">9</xref>–<xref ref-type="bibr" rid="CR11">11</xref></sup>. Naturally, PPIs encapsulate a two-view hierarchy: on the top view, proteins interact with each other; on the bottom view, key amino acids or residues assemble to form important local domains. Following this logic, biologists often take hierarchical approaches to understand PPIs<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup>. Experimentally, scientists often employ high-throughput mapping<sup><xref ref-type="bibr" rid="CR14">14</xref>–<xref ref-type="bibr" rid="CR16">16</xref></sup> to pre-build the PPI network at scale, and use bioinformatics clustering methods to identify functional modules of the network (top view). On the individual protein level, isolation methods, such as co-immunoprecipitation<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>, pull-down<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>, and crosslinking<sup><xref ref-type="bibr" rid="CR19">19</xref></sup> are used to establish the structures of individual proteins, so that surficial ‘hotspots’ can be located and analyzed. In short, hierarchy knowledge of structure information is important to understand the molecular details of PPIs.</p>
    <p id="Par4">More recently, the massive growth in the demand and the cost of experimentally validating PPIs make it impossible to characterize most unknown PPIs in wet laboratories. To map out the human interactome efficiently and inexpensively, computational methods are increasingly being used to predict PPIs automatically. Over the past decade, as one of the most revolutionary tools in computation, Deep Learning (DL) methods, have been applied to study PPIs. Development in this field has been mostly focused on two aspects, learning appropriate protein representations<sup><xref ref-type="bibr" rid="CR20">20</xref>,<xref ref-type="bibr" rid="CR21">21</xref></sup> and inferring potential PPIs by link predictions<sup><xref ref-type="bibr" rid="CR22">22</xref>,<xref ref-type="bibr" rid="CR23">23</xref></sup>. The former focuses on extracting structural information using protein sequences. In particular, Convolutional Neural Networks (CNNs)<sup><xref ref-type="bibr" rid="CR24">24</xref>,<xref ref-type="bibr" rid="CR25">25</xref></sup> and Recurrent Neural Networks (RNNs)<sup><xref ref-type="bibr" rid="CR26">26</xref>–<xref ref-type="bibr" rid="CR28">28</xref></sup> have demonstrated high generalization and fast inference speed to capture key sequence fragments for PPIs<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. 3D CNNs<sup><xref ref-type="bibr" rid="CR21">21</xref>,<xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR31">31</xref></sup> have shown to be better at extracting 3D structural features of proteins and thus capturing the spatial-biological arrangements of residues<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> that are important to PPI predictions. However, 3D CNN suffers from high computational burdens and limited resolution that is prone to quantization errors<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. The latter aspect of DL in PPI predictions focuses on the PPI network structures, which involves developing link prediction methods to identify missing interactions within the known network topology. Link prediction methods based on common neighbor (CN)<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> assign high probabilities of PPI to protein pairs that are known to share common PPI partners. CN can be generalized to consider neighbors from a greater path length (L3)<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>, which captures the structural and evolutionary forces that govern biological networks such as the interactome. Additionally, distance-based methods measure the possible distances between protein pairs, such as Euclidean commute time (ECT)<sup><xref ref-type="bibr" rid="CR34">34</xref></sup> and random walk with restart (RWR)<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>. Most methods of traditional link prediction focus on known interactions but tend to overlook important network properties such as node degrees and community partitions.</p>
    <p id="Par5">More importantly, these methods perceive only one of the two views of outside-of-protein and inside-of-protein. Few can model the natural PPI hierarchy by connecting both views. To address this issue, we present a hierarchical graph that applies two Graph Neural Networks (GNNs)<sup><xref ref-type="bibr" rid="CR36">36</xref>,<xref ref-type="bibr" rid="CR37">37</xref></sup> to represent protein and network structures, respectively. In this way, the limitations of 3D CNN and link prediction methods mentioned above can be circumvented. First, GNNs can learn the protein 3D structures on more efficient graph representations, even when facing high-resolution requirements for structure processing. Second, due to the propagation mechanism, GNNs are capable of recovering network properties such as node degrees and community partitions. In short, this hierarchical graph approach aims at modeling the natural PPI hierarchy with more effective and efficient structure perceptions.</p>
    <p id="Par6">Here we describe a generic DL platform tailored for predicting PPIs, Hierarchical Graph Neural Networks for Protein–Protein Interactions (HIGH-PPI). HIGH-PPI models the structural protein representations with the bottom inside-of-protein view GNNs (BGNN) and the PPI network with the top outside-of-protein view GNNs (TGNN). In the bottom view, HIGH-PPI constructs protein graphs by treating amino acid residues as nodes and physical adjacencies as edges. Thus, BGNN integrates the information of protein 3D structures and residue-level properties in a synergistic fashion. In the top view, HIGH-PPI constructs the PPI graph by taking protein graphs (the bottom view) as nodes and interactions as edges and learns protein–protein relationships with TGNN. In an end-to-end training paradigm, HIGH-PPI gains mutual benefits from both views. On the one hand, the bottom view feeds protein representations to the top view to learn accurate protein relationships. On the other hand, protein relationships learned by the top view provide insights to further optimize the bottom view to establish better protein representations. HIGH-PPI outputs the probabilities of interactions for given protein pairs and predicts key “contact” sites for such interactions by calculating residue importance. We show the effectiveness of HIGH-PPI on the human interactome from the STRING database<sup><xref ref-type="bibr" rid="CR38">38</xref></sup> and compare it with leading DL methods. We demonstrate the superiority of HIGH-PPI with higher prediction accuracy and better interpretability. We also show examples that HIGH-PPI can identify binding and catalytic sites with high precision automatically.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <sec id="Sec3">
      <title>HIGH-PPI introduces a hierarchical graph for learning structures of proteins and the PPI network</title>
      <p id="Par7">Although deep learning (DL) models for Protein–Protein Interaction (PPI) prediction have been studied extensively, it has not yet been developed for simulating the natural PPI hierarchy. Here, we suggest HIGH-PPI, a hierarchical graph neural network, for accurate and interpretable PPI prediction. HIGH-PPI works like biologists in a hierarchical manner as it contains the bottom inside-of-protein view and top outside-of-protein view (schematic view in Fig. <xref rid="Fig1" ref-type="fig">1c</xref> and detailed architecture in Supplementary Fig. <xref rid="MOESM1" ref-type="media">1a</xref>). On one hand, HIGH-PPI applies the bottom view when dealing with a protein, where a protein is represented by a protein graph with residue as nodes and their physical adjacencies as edges. On the other hand, from the top view, protein graphs and their interactions are considered nodes and edges of the PPI graph, respectively. Correspondingly, two GNNs are respectively employed to learn from protein graphs in the bottom view (BGNN) and learn from a PPI graph in the top view (TGNN). Consequently, a set of graphs are interconnected by edges in a hierarchical graph, to present a potent data representation.<fig id="Fig1"><label>Fig. 1</label><caption><title>Schematic view of the HIGH-PPI architecture.</title><p>Both the protein structure (biology structure) and network structure (interactome structure) are essential for predictions of PPIs. <bold>a</bold> The PPIs with protein structure information. Although protein sequence usually provides details among PPIs, it can also lead to low predictability for PPI prediction. Left: As an example, SERPINA1 and SERPINA3, protein members of a shared superfamily, bind to almost the same binding surface (TM-score is 0.74) of ELANE, whereas they share low sequence consistency (identity is 0.13) locally in the binding surface. Right: From a global perspective, gaps in the sequence and structure of proteins also exist. SERPINA1 and SERPINA3 highly align in structure (TM-Score is 0.89), but share a low sequence consistency (identity is 0.43). <bold>b</bold> The PPIs with network structure information. PPI networks tend to yield community structures that divide proteins into groups with dense connections internally (internal edges) and sparse connections externally (external edges). <bold>c</bold> The HIGH-PPI is a hierarchical model for learning both protein structure information and network structure information. The HIGH-PPI contains two views, the top view and the bottom view. In bottom view, residues serve as nodes, residue-level physicochemical properties as node features and edges connect physically adjacent residues. Two trainable graph convolutional blocks are applied for learning complex protein representations. In top view, proteins serve as nodes, interactions as edges and representations from the bottom view as node features. Three trainable graph isomorphism blocks are applied to update protein representations and after concatenating a pair of query proteins, the resulting embedding is passed through the linear classifier to learn protein correlations.</p></caption><graphic xlink:href="41467_2023_36736_Fig1_HTML" id="d32e510"/></fig></p>
      <p id="Par8">In the proposed end-to-end model, the initial stage is to create protein graphs for learning appropriate protein representation. An adjacency matrix of a protein graph is derived from a contact map connecting physically close residues (See Section 4.1 in “Methods” for details). Node attributes are defined with residue-level features for expressing the physicochemical properties of proteins (See Section 4.1 in “Methods” for details). To produce a protein graph representation, Graph Convolutional Network (GCN)<sup><xref ref-type="bibr" rid="CR36">36</xref></sup> is used in BGNN to optimize the protein graphs. As shown in Fig. <xref rid="Fig1" ref-type="fig">1c</xref>, BGNN contains two GCN blocks, and we construct three components for each GCN block to obtain a fixed-length embedding vector for a protein graph. Both the adjacency matrix and the residue-level features matrix are inputs for a GCN layer. To respectively improve model expressiveness and accelerate training convergence, the nonlinear activation function of ReLU and Batch Normalization (BN) are used. Readout operation including a self-attention graph (SAG) pooling<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> and the average aggregation is used to ensure a fixed-length embedding vector output. Regardless of the number and permutation of residues, a 1D embedding vector is obtained after two GCN blocks. By the end of those operations, the final protein representations are assembled, which are employed as initial features of the PPI graph. In TGNN, features are propagated along interactions in the PPI network for learning network community and degree properties. In the top view, we specifically design a GIN block that contains a Graph Isomorphism Network (GIN)<sup><xref ref-type="bibr" rid="CR37">37</xref></sup> layer, ReLU activation function and a BN layer. Node features of the PPI graph are updated with recursive neighborhood aggregations of three GIN blocks. Two arbitrary protein embeddings are combined by concatenation operations, and a Multi-Layer Perceptron (MLP) is then applied as a classifier for prediction. Moreover, we also consider graph attention (GAT) and arbitrarily deploy two of the three GNN layers (i.e., GCN, GIN and GAT) on BGNN and TGNN. The performance of HIGH-PPI with various GNN layers is shown in Supplementary Fig. <xref rid="MOESM1" ref-type="media">2</xref>.</p>
      <p id="Par9">We train and evaluate HIGH-PPI on multi-type human PPIs from the STRING database<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>, which contains a critical assessment and integration of PPIs. SHS27k<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>, a homo sapiens subset from STRING<sup><xref ref-type="bibr" rid="CR38">38</xref></sup> that comprises 1,690 proteins and 7,624 PPIs, is used to train and evaluate the HIGH-PPI unless otherwise noted. However, a small fraction of proteins (∼ 8%) sometimes need to be removed because of the lack of their native structures in the PDB database. While evaluating the prediction performance for multi-type PPIs, we consider the prediction for each PPI type as a one-vs-all binary classification problem, for which two metrics, F1 score and area under the precision-recall curve (AUPR) are used for predicting the presence or absence of the corresponding PPI class. The overall performance of micro-F1 and AUPR scores for multi-type PPI prediction is averaged across all PPI types.</p>
    </sec>
    <sec id="Sec4">
      <title>HIGH-PPI shows the best performance, robustness and generalization</title>
      <p id="Par10">To validate the predictive power of our model, we compare HIGH-PPI with leading methods from four perspectives, including (1) the overall performance under a random data split, (2) the robustness of HIGH-PPI against random interaction perturbation, (3) model generalization for predicting PPI pairs containing unknown proteins, (4) evaluations in terms of AUPR on five separate PPI types. For each method, all the proposed modules and strategies are involved to get the best performance.</p>
      <p id="Par11">First, we compare the overall performance of HIGH-PPI with leading baselines in Fig. <xref rid="Fig2" ref-type="fig">2a</xref>. To ensure native PDB structures for all proteins, we filter from SHS27k and construct the dataset containing ∼1600 proteins (see Supplementary Data File <xref rid="MOESM4" ref-type="media">1</xref>) and ∼6600 PPIs. We randomly select 20% PPIs for testing and compare PPI to one state-of-the-art DL method (i.e., GNN-PPI<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>), one sequence-based method (i.e., PIPR<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>), one 2D CNN-based method (i.e., DrugVQA<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>) and one machine learning (ML) method based on random forest (i.e., RF-PPI<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>). GNN-PPI applies a GNN module to learn the PPI network topology and 1D CNN to learn protein representations by taking pre-trained residue embeddings as inputs. PIPR, an end-to-end framework based on recurrent neural networks (RNN), represents proteins with only pre-trained residue embeddings. DrugVQA applies a visual question-answering mode to learn from protein contact maps with a 2D CNN model and extract semantic features with a sequential model. Supplementary Data File <xref rid="MOESM5" ref-type="media">2</xref> contains predictions of HIGH-PPI for all test PPIs from SHS27k. We provide the precision-recall curves in Fig. <xref rid="Fig2" ref-type="fig">2a</xref>. In terms of best micro-F1 scores (best-F1), HIGH-PPI obtains the best performance. Pre-trained residue embedding method GNN-PPI takes the second place by effectively generalizing to unknown proteins. Without using any pre-training techniques, HIGH-PPI surpasses GNN-PPI by an average of ∼4%, showing the superiority of the hierarchical modeling approach. DrugVQA gets relatively poor performance (best-F1 ≈ 0.7), which could be attributed to the neglect of residue property information and structures of the PPI network.<fig id="Fig2"><label>Fig. 2</label><caption><title>Performance of HIGH-PPI in predicting PPIs.</title><p><bold>a</bold> Precision-recall curves of PPI prediction on SHS27k (sub-dataset from STRING) containing ∼6600 PPIs and ∼1500 human proteins with native PDB structures showing the performance of HIGH-PPI compared to baselines containing GNN-PPI, PIPR, DrugVQA and RF-PPI. <bold>b</bold> Robustness evaluation showing the best micro-F1 scores (Best-F1) of baseline predictions against link perturbations of various cases where links are randomly added or removed with different ratios. Error bands of <bold>a</bold> and <bold>b</bold> represent the standard deviation of the mean under 9 independent runs. <bold>c</bold> Generalization evaluation showing Best-F1s of baselines tested on a regular and 4 Out-of-Distribution (OOD) cases, in which datasets are constructed with random split (R), Breath-First Search (BFS) and Depth-First Search (DFS) and three ratios represent probabilities of overlap of proteins between the training and test datasets. Distributions of Best-F1s under 9 independent runs of HIGH-PPI and the second-best baseline (GNN-PPI) are represented as boxplots (center line, the median; upper and lower edges, the interquartile range; whiskers, <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.5\times$$\end{document}</tex-math><mml:math id="M2"><mml:mn>0.5</mml:mn><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq1.gif"/></alternatives></inline-formula> interquartile range) and moreover, dotted lines show the mean results of 9 independent runs of PIPR, DrugVQA and RF-PPI under DFS-0.4, the easiest OOD pattern. The significance of HIGH-PPI versus GNN-PPI is shown in each case (Two-sided <italic>t</italic>-test results: ****<inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=1.1\times {10}^{-5}$$\end{document}</tex-math><mml:math id="M4"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>1.1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq2.gif"/></alternatives></inline-formula> for BFS-0.3, ***<inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=4.5\times {10}^{-3}$$\end{document}</tex-math><mml:math id="M6"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>4.5</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq3.gif"/></alternatives></inline-formula> for DFS-0.3, *<inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=1.0\times {10}^{-7}$$\end{document}</tex-math><mml:math id="M8"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq4.gif"/></alternatives></inline-formula> for BFS-0.4, ***<inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=2.0\times {10}^{-2}$$\end{document}</tex-math><mml:math id="M10"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>2.0</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq5.gif"/></alternatives></inline-formula> for DFS-0.4 and **<inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=3.0\times {10}^{-6}$$\end{document}</tex-math><mml:math id="M12"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>3.0</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq6.gif"/></alternatives></inline-formula> for R-0.65). <bold>d</bold> Distributions of AUPR scores of 5 independent runs computed on 5 PPI types and corresponding proportions. Each figure shows the performance significance of HIGH-PPI versus the second-best baseline (GNN-PPI) (Two-sided <italic>t</italic>-test results: ****<inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=2.0\times {10}^{-5}$$\end{document}</tex-math><mml:math id="M14"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>2.0</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq7.gif"/></alternatives></inline-formula> for binding, ***<inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=1.7\times {10}^{-4}$$\end{document}</tex-math><mml:math id="M16"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>1.7</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq8.gif"/></alternatives></inline-formula>for reaction, *<inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=4.4\times {10}^{-2}$$\end{document}</tex-math><mml:math id="M18"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>4.4</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq9.gif"/></alternatives></inline-formula> for ptmod, ***<inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=3.2\times {10}^{-4}$$\end{document}</tex-math><mml:math id="M20"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>3.2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq10.gif"/></alternatives></inline-formula> for catalysis and **<inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=6.0\times {10}^{-3}$$\end{document}</tex-math><mml:math id="M22"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>6.0</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq11.gif"/></alternatives></inline-formula> for inhibition). Error bars represent standard deviation of the mean. Source data are provided as a Source Data file.</p></caption><graphic xlink:href="41467_2023_36736_Fig2_HTML" id="d32e879"/></fig></p>
      <p id="Par12">Second, to evaluate the robustness of HIGH-PPI, we analyze the model tolerance against interaction data perturbation including random addition or removal of known interactions. This simulates scenarios where PPI datasets always omit undiscovered interactions and may introduce mislabeled ones. Based on the perturbated PPI network, we split the training and test sets at an 8:2 ratio. We observe in Fig. <xref rid="Fig2" ref-type="fig">2b</xref> that our method exhibits stable performance in terms of best-F1 with a random perturbation of 40%. When compared to the second-best baseline (i.e., GNN-PPI), HIGH-PPI offers a significant performance gain of up to 19%, which demonstrates the strongest model robustness among all methods. It is crucial to notice that although RF-PPI and DrugVQA perform consistently in the overall evaluation (see Fig. <xref rid="Fig2" ref-type="fig">2a</xref>), DrugVQA performs significantly more robustly than RF-PPI, demonstrating the undisputed superiority of DL methods over ML ones. Furthermore, we perform false discovery on our method, which investigates the effect of the training data unreliability (i.e., false negative (FN) and false positive (FP)) on our model and a solid baseline (GNN-PPI). Specifically, we consider the original dataset to be reliable and artificially add perturbations to represent data unreliability. Supplementary Table <xref rid="MOESM1" ref-type="media">1</xref> shows the created 9 datasets with different FP rates (<inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{FPR}}_{{train}}$$\end{document}</tex-math><mml:math id="M24"><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq12.gif"/></alternatives></inline-formula>) and FN rates (<inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{FNR}}_{{train}}$$\end{document}</tex-math><mml:math id="M26"><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq13.gif"/></alternatives></inline-formula>). We respectively train the model on the reliable training set and created 9 unreliable ones and present the FP rates (<inline-formula id="IEq14"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{FPR}}_{{pre}}$$\end{document}</tex-math><mml:math id="M28"><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq14.gif"/></alternatives></inline-formula>), FN rates (<inline-formula id="IEq15"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{FNR}}_{{pre}}$$\end{document}</tex-math><mml:math id="M30"><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq15.gif"/></alternatives></inline-formula>) and false discovery rates (<inline-formula id="IEq16"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{FDR}}_{{pre}}$$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>D</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq16.gif"/></alternatives></inline-formula>) metrics on the test sets (see Supplementary Table <xref rid="MOESM1" ref-type="media">2</xref> and <xref rid="MOESM1" ref-type="media">3</xref>). Without unreliability, our model achieves best performance with insignificant superiority (*<inline-formula id="IEq17"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=3.8\times {10}^{-2}$$\end{document}</tex-math><mml:math id="M34"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>3.8</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq17.gif"/></alternatives></inline-formula>) in the <inline-formula id="IEq18"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{FPR}}_{{pre}}$$\end{document}</tex-math><mml:math id="M36"><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq18.gif"/></alternatives></inline-formula> metric, and considerable superiority in the <inline-formula id="IEq19"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{FNR}}_{{pre}}$$\end{document}</tex-math><mml:math id="M38"><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq19.gif"/></alternatives></inline-formula> (***<inline-formula id="IEq20"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=1.2\times {10}^{-4}$$\end{document}</tex-math><mml:math id="M40"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq20.gif"/></alternatives></inline-formula>) and <inline-formula id="IEq21"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{FDR}}_{{pre}}$$\end{document}</tex-math><mml:math id="M42"><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>D</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq21.gif"/></alternatives></inline-formula> (***<inline-formula id="IEq22"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=1.5\times {10}^{-4}$$\end{document}</tex-math><mml:math id="M44"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq22.gif"/></alternatives></inline-formula>) metrics. When introducing data unreliability, we are surprised to find that our model substantially improves the superiority significance in the <inline-formula id="IEq23"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{FPR}}_{{pre}}$$\end{document}</tex-math><mml:math id="M46"><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq23.gif"/></alternatives></inline-formula> metric (****<inline-formula id="IEq24"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=4.0\times {10}^{-5}$$\end{document}</tex-math><mml:math id="M48"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>4.0</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq24.gif"/></alternatives></inline-formula>) while retaining the original significance in <inline-formula id="IEq25"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{FNR}}_{{pre}}$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq25.gif"/></alternatives></inline-formula> and <inline-formula id="IEq26"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{FDR}}_{{pre}}$$\end{document}</tex-math><mml:math id="M52"><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>D</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq26.gif"/></alternatives></inline-formula>. In addition to showing the excellent robustness of our model, we also provide more in-depth insights in Section 3.2.</p>
      <p id="Par13">Generalization ability is investigated by testing HIGH-PPI in various out-of-distribution (OOD) scenarios where unknown proteins arrive in the test sets with different probabilities (see Fig. <xref rid="Fig2" ref-type="fig">2c</xref>). For example, BFS-0.3 denotes that the test set involves 30% known proteins via Breath-First Search approach<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. For PIPR, DrugVQA and RF-PPI, we visualize their best performances among all OOD cases using dotted lines, to demonstrate the absolute dominance of HIGH-PPI and GNN-PPI. Furthermore, we observe that HIGH-PPI consistently outperforms GNN-PPI, the second-best method, with large margins in all five scenarios. BFS typically produces worse performance than DFS, because BFS creates a more challenging and realistic mode where unknown proteins exist in cluster forms. ML method (RF-PPI) exhibits poor generalization. Furthermore, we follow Park and Marcotte<sup><xref ref-type="bibr" rid="CR42">42</xref></sup> to explore the differences in model performance on 3 kinds of PPI pairs with different degrees of OOD. Specifically, <inline-formula id="IEq27"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${C}_{1}$$\end{document}</tex-math><mml:math id="M54"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq27.gif"/></alternatives></inline-formula> stands for the percentage of PPIs of which both proteins were present in a training set (Class 1), <inline-formula id="IEq28"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${C}_{2}$$\end{document}</tex-math><mml:math id="M56"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq28.gif"/></alternatives></inline-formula> stands for the percentage of PPIs of which one of (but not both) proteins was present in the training set (Class 2), <inline-formula id="IEq29"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${C}_{3}$$\end{document}</tex-math><mml:math id="M58"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq29.gif"/></alternatives></inline-formula> stands for the percentage of PPIs of which neither protein was present in the training set (Class 3). The detailed experimental protocol has been presented in the Supplementary Method <xref rid="MOESM1" ref-type="media">3</xref>. We come to the same conclusion as Park and Marcotte did<sup><xref ref-type="bibr" rid="CR42">42</xref></sup>. There is a noticeable difference in model test performance across the 3 distinct classes of test pairs. Particularly, on Class 1 test pairs, both models (HIGH-PPI and GNN-PPI) perform the best, on Class 2 test pairs they are the second best, and on Class 3 test pairs they are the poorest. Furthermore, we find that for each model, the class proportion (i.e., <inline-formula id="IEq30"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${C}_{1}/{C}_{2}/{C}_{3}$$\end{document}</tex-math><mml:math id="M60"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq30.gif"/></alternatives></inline-formula>) had an impact on the overall performance of the model despite having little effect on performance on the respective classes. Thus, it seems that the proportion of the three test pair classes (Supplementary Table <xref rid="MOESM1" ref-type="media">6</xref>) as well as the percentage of unknown proteins (Fig. <xref rid="Fig2" ref-type="fig">2c</xref>) in the test sets may both have a significant role in determining the degree of OOD in the dataset.</p>
      <p id="Par14">Finally, for each of the five PPI types, we offer a separate performance analysis in terms of AUPR. In all five types, HIGH-PPI consistently beats other baselines with high significance as shown in Fig. <xref rid="Fig2" ref-type="fig">2d</xref>. As anticipated, PPI types with high proportions (such as binding, reaction, and catalysis) can be predicted more easily since the model could learn enough relevant information. In addition, we find that when predicting binding PPIs, HIGH-PPI outperforms GNN-PPI most significantly (****<inline-formula id="IEq31"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=2.0\times {10}^{-5}$$\end{document}</tex-math><mml:math id="M62"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>2.0</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq31.gif"/></alternatives></inline-formula>). This is reasonable as HIHG-PPI is designed to recognize spatial-biological patterns of proteins, which is highly related to binding type PPIs. Similar trends are also found in the performance of HIGH-PPI and GNN-PPI in various PPI types under OOD cases (Supplementary Fig. <xref rid="MOESM1" ref-type="media">5</xref>).</p>
    </sec>
    <sec id="Sec5">
      <title>Bottom inside-of-protein view improves the performance</title>
      <p id="Par15">We investigate the role of the bottom inside-of-protein view from four perspectives, including (1) the effectiveness of graph representations and backbones with native protein structures, (2) the model tolerance with low-quality protein structures, (3) the capability to predict motifs (i.e., functional sites) in a protein, (4) the overall and type-specific feature importance.</p>
      <p id="Par16">First, we explore the effectiveness of backbones including RF, RNN, CNN and GNN in Fig. <xref rid="Fig3" ref-type="fig">3a</xref>. For fairness, we feed the same features of residue sequence to RF, RNN and CNN, whose results are displayed by bar charts with ‘Seq’. We directly use RF-PPI as the RF backbone. For RNN and CNN backbones, we respectively employ the RNN module of PIPR and the CNN module of GNN-PPI to extract sequence embeddings for representing proteins and apply the same fully connected layer as classifiers. We test the predictive power of each model with 3D information. For RF and RNN, we employ the concatenations of sequence data and Cartesian 3D coordinates of each <inline-formula id="IEq32"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${C}_{\alpha }$$\end{document}</tex-math><mml:math id="M64"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq32.gif"/></alternatives></inline-formula>. For CNN, we apply the 3D CNN module suggested in DeepRank<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>, a deep learning framework for identifying interfaces of PPIs. For GNN, we learn from protein graphs in which the adjacency matrix is determined by <inline-formula id="IEq33"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${C}_{\alpha }-{C}_{\alpha }$$\end{document}</tex-math><mml:math id="M66"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq33.gif"/></alternatives></inline-formula> contact map. With the aid of 3D information, we discover all the model performance can be improved, indicating that 3D information is an important complement to sequence-alone information. Importantly, GNN performs the best when compared to RF ( + 3D), RNN ( + 3D) and CNN ( + 3D), which shows that GNN is the best approach for capturing spatial-biological arrangements of residues within a protein. Moreover, GNN performs significantly better than 3D CNN in memory and time efficiency (Supplementary Fig. <xref rid="MOESM1" ref-type="media">3</xref>).<fig id="Fig3"><label>Fig. 3</label><caption><title>Performance of bottom view GNN of HIGH-PPI to represent a protein for PPI prediction.</title><p><bold>a</bold> Effectiveness in demonstration w or w/o protein 3D information (3D coordinates of <inline-formula id="IEq34"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${C}_{\alpha }$$\end{document}</tex-math><mml:math id="M68"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq34.gif"/></alternatives></inline-formula> atoms in all residues). The protein is represented with backbones including Random Forest (RF from RF-PPI, gray), Recurrent Neural Networks (RNN from PIPR, purple), Convolutional Neural Networks (CNN (Seq) from GNN-PPI, CNN ( + 3D) from DeepRank blue), respectively. Converting 3D information into protein contact maps (CM), a backbone with graph structured data outperforms all other methods with high performance significances (Two-sided <italic>t</italic>-test results: graph versus RF ( + 3D) ****<inline-formula id="IEq35"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=1.1\times {10}^{-8}$$\end{document}</tex-math><mml:math id="M70"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>1.1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq35.gif"/></alternatives></inline-formula>, graph versus RNN ( + 3D) ****<inline-formula id="IEq36"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=6.1\times {10}^{-12}$$\end{document}</tex-math><mml:math id="M72"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>6.1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq36.gif"/></alternatives></inline-formula>, graph versus CNN ( + 3D) ****<inline-formula id="IEq37"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=2.3\times {10}^{-7}$$\end{document}</tex-math><mml:math id="M74"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>2.3</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq37.gif"/></alternatives></inline-formula>). Error bars represent standard deviation of the mean under 9 independent runs. <bold>b</bold> HIGH-PPI can outperform other baselines without absolutely precise structures of query proteins. Blue dotted line (mean value of 9 independent runs) representing the Best-F1 score of second-best baseline (GNN-PPI) without 3D information and boxplot (9 runs with independent seeds) showing the relationship between Best-F1 scores of HIGH-PPI and the Root-Mean-Square Deviation (RMSD) of the tested structures relative to the native structures. For boxplots, the center line represents the median, upper and lower edges represent the interquartile range, and the whiskers represent <inline-formula id="IEq38"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.5\times$$\end{document}</tex-math><mml:math id="M76"><mml:mn>0.5</mml:mn><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq38.gif"/></alternatives></inline-formula> interquartile range. As an example, <bold>c</bold> HIGH-PPI can easily identify the binding site containing four physically adjacent residues via conventional graph motif research method (PDB id: 1BJP). CNN and RNN based backbones may miss (missed) or mis-identify <bold>(</bold>non-essential) residues with Grad-CAM and RNNVis. <bold>d</bold> The feature importance in residue-level for overall (leftmost column) and type-specific (right six columns) PPI prediction calculated as the average <italic>z</italic>-score resulting from dropping each individual feature dimension from our model and calculating changes of AUPR before and after. Source data are provided as a Source Data file.</p></caption><graphic xlink:href="41467_2023_36736_Fig3_HTML" id="d32e1589"/></fig></p>
      <p id="Par17">Second, we examine the model tolerance when testing with low-quality structure data (see Fig. <xref rid="Fig3" ref-type="fig">3b</xref>). This meets the realistic scenarios, where native structure information is not always available for predicting PPIs. We prefer the model whose performance is not seriously limited by the structure quality, which is robust to inputs directly from computational models (e.g., AlphaFold<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>). We evaluate the quality of the input protein structure by calculating the root-mean-square deviation (RMSD) of the native one and the input. Native protein structures (RMSD = 0) are retrieved from the PDB database at the highest resolutions. We compute the best-F1 scores (box plots) of our method on a set of AlphaFold structures with various RMSDs (0.80, 1.59, 2.39, 3.19, 5.36, 7.98), and show the average result of second-best method (GNN-PPI) in a blue dotted line. As can be seen, our model performance is always better than GNN-PPI, even with RMSD up to 8. The comparison with 3D CNN model<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> further proves the denoising ability of the hierarchical graph for protein structure errors (Supplementary Fig. <xref rid="MOESM1" ref-type="media">4a</xref>). In short, our model performance is not significantly affected by structure errors where powerful pre-trained features are not available.</p>
      <p id="Par18">Further, to interpret decisions made by RNN, CNN and GNN, an experiment is conducted to explore the ability to capture protein functional sites. We apply the 3D-grad-CAM approach<sup><xref ref-type="bibr" rid="CR44">44</xref></sup> on the trained 3D CNN model named DeepRank<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>, and apply the RNNVis approach<sup><xref ref-type="bibr" rid="CR45">45</xref></sup> on the trained PIPR<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> model with 3D information. All three methods have identified more than one motif, in which we only show the most crucial site. Figure <xref rid="Fig3" ref-type="fig">3c</xref> displays the binding site for an isomerase protein’s chain A (PDB id: 1BJP). The binding site is made up of four residues with the sequence numbers 6, 42, 43, and 44. As can be seen, whereas neither CNN nor RNN can identify the His-6 residue, our method can precisely identify the binding site by using graph motif search. It seems to be a challenge for the sequence model (i.e., RNN, CNN) to connect His-6 to the other residues, probably because of their weak connections in a sequence mode. Moreover, 3D CNN performs even worse than RNN as it incorrectly classifies the non-essential Ile-41 residue.</p>
      <p id="Par19">For node features in protein graphs, we select seven important features from twelve residue-level feature options (see Supplementary Table <xref rid="MOESM1" ref-type="media">4</xref>) that are easily available. The feature selection process (see Supplementary Method <xref rid="MOESM1" ref-type="media">1</xref> for details) produces the optimal set consisting of seven features to ensure that our model peaks at both AUPR and best-F1 scores. Here, we list the selected seven residue-level physicochemical properties in Fig. <xref rid="Fig3" ref-type="fig">3d</xref> and discuss their importance for different types of PPIs to both better interpret our model and discover enlightening biomarkers for PPI interface. The average z-score, which results from deleting each feature dimension and analyzing changes in AUPR before and after, is calculated to determine the importance of a feature. We choose a representative type (i.e., binding) to explain because it is the most prevalent in the STRING database. As a consequence, HIGH-PPI regards topological polar surface area (TPSA) and octanol-water partition coefficient (KOW) as dominant features. This finding supports the conventional wisdom that TPSA and KOW play a key role in drug transport process<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>, protein interface recognition<sup><xref ref-type="bibr" rid="CR47">47</xref>,<xref ref-type="bibr" rid="CR48">48</xref></sup>, and PPI prediction<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>.</p>
    </sec>
    <sec id="Sec6">
      <title>Top outside-of-protein view improves the performance</title>
      <p id="Par20">We investigate the role of top outside-of-protein view TGNN from three perspectives, including (1) the importance of degree and community recovery for predicting network structures, (2) comparison results of TGNN and other leading link prediction methods, (3) a real-life example to show the shortcomings of the leading link prediction methods.</p>
      <p id="Par21">Recently, various works have demonstrated the usefulness of structure properties (e.g., degree, community) of networks for predicting missing links. HIGH-PPI is inspired to efficiently recover the degree and community partitions of the PPI network by utilizing the network topology. We show an empirical study in Fig. <xref rid="Fig4" ref-type="fig">4a</xref> to illustrate the impact of degree and community recovery for link prediction. We randomly select the test results from the model trained in different epochs and calculate the negative Mean Absolute Error (-MAE) of the predicted degrees and real degrees to represent degree recovery. Similarly, for community recovery, we quantify the community recovery using the normalized mutual information (NMI). As can be seen, we observe a significant correlation (<inline-formula id="IEq39"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R=-0.66$$\end{document}</tex-math><mml:math id="M78"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.66</mml:mn></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq39.gif"/></alternatives></inline-formula>) between degree recovery and model performance (i.e., best-F1) as well as a high correlation (<inline-formula id="IEq40"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R=0.68$$\end{document}</tex-math><mml:math id="M80"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>0.68</mml:mn></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq40.gif"/></alternatives></inline-formula>) between community recovery and model performance, which means better recovery of the degree and community of PPI network implies better PPI prediction performance.<fig id="Fig4"><label>Fig. 4</label><caption><title>Performance of top view GNN of HIGH-PPI to learn relational information in PPI network.</title><p><bold>a</bold> Pearson Correlations (R) between the prediction performance (Best-F1) and degree recovery (left) and community recovery (right). It can be observed that high recovery for the degree and community of PPI network indicates better performance for PPI prediction. Degree recovery is quantified with the Mean Absolute Error (MAE) between the true and predicted degree distributions. Community recovery is quantified with the normalized mutual information (NMI) of true and predicted communities. The shaded area (error band) represents the 95% confidence interval. <bold>b</bold> Boxplots (center line, the median; upper and lower edges, the interquartile range; whiskers, <inline-formula id="IEq41"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.5\times$$\end{document}</tex-math><mml:math id="M82"><mml:mn>0.5</mml:mn><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq41.gif"/></alternatives></inline-formula> interquartile range) showing the Best-F1 distributions (5 runs with independent seeds) using various link prediction methods. Methods (green) predicting PPI networks of which the NMI &lt; 0.7 and MAE &gt; 0.35 significantly underperform the others (orange). <bold>c</bold> Left: An example showing a PPI network with an area of each node representing its degree value and only two external edges connecting the two communities detected. Middle: Real calculating results showing how other link prediction methods generate mislinks as external edges, which may disrupt the community partitions. Right: Real calculating results showing the disability of other link prediction methods to recover degrees. Source data are provided as a Source Data file.</p></caption><graphic xlink:href="41467_2023_36736_Fig4_HTML" id="d32e1724"/></fig></p>
      <p id="Par22">Second, we evaluate the performance of TGNN and leading link prediction methods using PPI network structure as input. Our method (TGNN) takes interactions as edges and node degrees as node features. We compare HIGH-PPI with six heuristic methods and one DL-based method. Heuristic methods, the simple yet effective ones utilizing the heuristic node similarities as the link likelihoods, include common neighbors (CN)<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>, Katz index (Katz)<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>, Adamic-Adar (AA)<sup><xref ref-type="bibr" rid="CR51">51</xref></sup>, preferential attachment (PA)<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>, SimRank (SR)<sup><xref ref-type="bibr" rid="CR53">53</xref></sup> and paths of length three (L3)<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. MLP_IP, a DL approach, learns node representations using a multilayer perceptron (MLP) and identifies the node similarity via inner product (IP) operation. We calculate the MAE and NMI values of recovered networks and highlight those with a high capacity for recovery (NMI ≥ 0.7 and MAE ≤ 0.35) in orange. Results show that link prediction methods that are more adept at recovering network properties typically perform better. This gain validates our findings in Fig. <xref rid="Fig4" ref-type="fig">4a</xref> and highlights the need for TGNN in the top view. In addition, a comparison of MIL_IP and L3 elucidates that pairwise learning is insufficient to well capture the network information. Although L3 can capture the evolutionary principles of PPIs to some extent, our method beats L3 by better recovering the structure of the PPI network.</p>
      <p id="Par23">We provide an example on an SHS27k sub-network. As can be seen, there exist two distinct communities connected by two inter-community edges. We use the original sub-network as inputs and find that non-TGNN link prediction methods (i.e., CN, Katz, SR, AA, PA) tend to give high scores for intercommunity interactions. As an interesting observation, when we apply the Louvain community detection algorithm<sup><xref ref-type="bibr" rid="CR54">54</xref></sup> to the recovered structure, it cannot produce an accurate community partition as the abundant inter-community interactions disrupt the original community structure. To examine degree recovery ability, we randomly select 50% of interactions as inputs and show each method’s degree recovery result for node KIF22 in Fig. <xref rid="Fig4" ref-type="fig">4c</xref>. We find non-TGNN approaches cannot well recover the links connecting the node KIF22 while TGNN approach can. In short, these experiments demonstrate that the structure properties of the PPI network are not always reflected in traditional link prediction methods, and moreover, capturing and learning the network structures in our top view improves the prediction performance.</p>
    </sec>
    <sec id="Sec7">
      <title>HIGH-PPI accurately identifies key residues constituting functional sites</title>
      <p id="Par24">Typically, functional sites are spatially clustered sets of residues. They control protein functions and are thus important for PPI prediction. As our proposed model has the capacity to capture spatial-biological arrangements of residues in the bottom view, this characteristic can be used to explain the model’s decision. It is meaningful to notice that HIGH-PPI can automatically learn the residue importance without any residue-level annotations. In this section, we provide (1) a case study of predicting residue importance for the binding surface, (2) two cases of estimating residue importance for catalytic sites, and (3) an explainable ability comparison of precision in predicting binding sites.</p>
      <p id="Par25">First, a binding example between the query protein (PDB id: 2B6H-A) and its partner (PDB id: 2REY-A) is investigated. The ground truth binding surface is retrieved from the PDBePISA database<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>, which is colored in red in Fig. <xref rid="Fig5" ref-type="fig">5a</xref>. Subsequently, we apply the GNN explanation approach (see Section 4.5 in “Methods” for details) on the HIGH-PPI model. As can be seen from Fig. <xref rid="Fig5" ref-type="fig">5a</xref>, HIGH-PPI can accurately and automatically identify the residues belonging to the binding surface. Another observation is shown in Fig. <xref rid="Fig5" ref-type="fig">5c</xref> which indicates our learned residue importance is quite close to the real profiles. We show another six cases of HIGH-PPI for identifying binding surfaces correctly in Supplementary Fig. <xref rid="MOESM1" ref-type="media">7</xref>.<fig id="Fig5"><label>Fig. 5</label><caption><title>Automatic explanation for residue importance without supervision.</title><p><bold>a</bold> Top: Depiction of a complex protein (left, query protein, PDB id: 2B6H-A; right, interacted protein, PDB id: 2REY-A) modeled in surface representation. Residues on the binding surface of query protein are highlighted in red (important) and others in blue (non-important). Bottom: Residue importance of the query protein learned from HIGH-PPI with coloring ranging from low (blue) to high (red). Important regions are magnified to show the cartoon representation. <bold>b</bold> Depiction of two proteins (left, PDB id: 1S9I-A; right, PDB id: 1I0O-A) modeled in cartoon representations. Residues are colored to match the importance scores, with more important residues highlighted in red and unimportant ones in blue. Residues with catalytic functions that are correctly or incorrectly identified are highlighted in red and black, respectively. <bold>c</bold> Polylines showing the consistency of highest peaks that represent the learned (gray) and real (red) functional regions for the binding interaction case shown in <bold>a</bold>. <bold>d</bold> Boxplots (center line, the median; upper and lower edges, the interquartile range; whiskers, <inline-formula id="IEq42"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.5\times$$\end{document}</tex-math><mml:math id="M84"><mml:mn>0.5</mml:mn><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq42.gif"/></alternatives></inline-formula> interquartile range) showing the explainable ability for binding PPIs by calculating the overlap of real and learned functional regions (IoU, Intersection over Union) with 20 PPI pairs and their real interfaces retrieved from STRING and PDBePISA database, respectively. HIGH-PPI shows greater explainable ability significantly (Two-sided <italic>t</italic>-test results: HIGH-PPI versus CNN ****<inline-formula id="IEq43"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=4.4\times {10}^{-6}$$\end{document}</tex-math><mml:math id="M86"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>4.4</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq43.gif"/></alternatives></inline-formula>, HIGH-PPI versus CNN ( + 3D) ****<inline-formula id="IEq44"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=4.4\times {10}^{-8}$$\end{document}</tex-math><mml:math id="M88"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>4.4</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq44.gif"/></alternatives></inline-formula>). No information about residue importance was used to train our model. Source data are provided as a Source Data file.</p></caption><graphic xlink:href="41467_2023_36736_Fig5_HTML" id="d32e1878"/></fig></p>
      <p id="Par26">Second, in order to evaluate the prediction of catalytic sites for PPIs, we utilize the same GNN explanation approach in our model. The ground truth catalytic site is retrieved from the Catalytic Site Atlas<sup><xref ref-type="bibr" rid="CR56">56</xref></sup> (CSA), a database for catalytic residue annotation for enzymes. We calculate the residue importance of catalytic sites for query proteins (PDB id: 1S9I-A, 1I0O-A). As seen in Fig. <xref rid="Fig5" ref-type="fig">5b</xref>, our proposed HIGH-PPI can correctly predict both residues for 1S9I-A and two out of three for 1I0O-A. We show another nine cases of HIGH-PPI for identifying catalytic sites in Supplementary Fig. <xref rid="MOESM1" ref-type="media">6</xref>, where a total of 25 out of 34 catalytic sites are correctly identified.</p>
      <p id="Par27">Additionally, we compare the model interpretability of the CNN, 3D CNN and HIGI-PPI models. We employ the CNN module in GNN-PPI<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> and 3D CNN module in DeepRank<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>, respectively. We apply grad-CAM<sup><xref ref-type="bibr" rid="CR57">57</xref></sup> and 3Dgrad-CAM<sup><xref ref-type="bibr" rid="CR44">44</xref></sup> approaches to determine residue importance for CNN and 3D CNN models, correspondingly. We use the binding type PPIs from the STRING dataset as the training set, and randomly select 20 binding type PPIs as the test set. We use the ground truth from PDBePISA for each query protein and treat its residues with importance &gt;0 as surface compositions. To gauge the precision of the surface prediction, intersection over union (IoU) is used, and the box plots of the IoU score distributions are shown in Fig. <xref rid="Fig5" ref-type="fig">5d</xref>. The results elucidate that HIGH-PPI significantly outperforms other models in terms of interpretability with a minimum variance. In addition, 3D CNN outperforms CNN with a smaller variance, showing that 3D information supports the learning of reliable and generalized protein representations.</p>
      <p id="Par28">Protein functional site prediction sheds light on the model decisions and how to carry out additional experimental validations for PPI investigation. Excellent model interpretability also shows that our approach can accurately describe biological evidence for proteins.</p>
    </sec>
  </sec>
  <sec id="Sec8" sec-type="discussion">
    <title>Discussion</title>
    <sec id="Sec9">
      <title>Hierarchical graph learning</title>
      <p id="Par29">In this paper, we study the PPI problem from a hierarchical graph perspective and develop a hierarchical graph learning model named HIGH-PPI to predict PPIs. Empirically, HIGH-PPI for PPI prediction outperforms leading methods by a significant margin. The hierarchical graph exhibits high generalization for recognizing unknown proteins and robustness against protein structure errors and PPI network perturbations.</p>
      <p id="Par30">Even without explicit supervision from binding site information, HIGH-PPI demonstrates its ability to capture residue importance for PPI with the aid of a hierarchical graph, which is a good indicator of excellent interpretability. Suppose HIGH-PPI predicts the presence of a catalytic interaction for a protein pair but identifies important sites unrelated to catalysis, we will hardly trust the model’s decision. Moreover, interpretability provides trusted guides for subsequent wet experimental validations. For example, if HIGH-PPI thinks a catalytic site is important, experiments may be designed by targeting the specific site for validation.</p>
      <p id="Par31">In conclusion, interpretable, end-to-end learning with a hierarchical graph revealing the PPI nature can pave the way to map out human interactome and deepen our understanding of PPI mechanisms.</p>
    </sec>
    <sec id="Sec10">
      <title>Limitations and future work</title>
      <p id="Par32">We describe our intuitions in the hierarchical graph learning for PPIs. The world is hierarchical. Humans tend to solve problems or learn knowledge by conceptualizing the world from a hierarchical view<sup><xref ref-type="bibr" rid="CR58">58</xref></sup>. Due to huge semantic gaps between hierarchical views, humans always use a multi-view learning strategy to deepen the understanding of one view from the other one. Given rich hierarchical information, recent machine intelligence methods can effectively learn knowledge in each separate view but are not experts in gaining mutual benefits from both views. This is the challenge that our hierarchical world presents to machine intelligence. Here we connect both views by employing the forward and backward propagation of DL models. The forward propagation benefits the learning for the PPI network in the top view. In turn, the backward propagation optimizes the PPI-appropriate protein representations in the bottom view.</p>
      <p id="Par33">We describe two main limitations of HIGH-PPI and outline potential solutions in future work. (1) We did not explore in depth how to use protein-level annotations. Annotations for protein functions are becoming more available due to the recent growth of protein function databases (e.g., the UniProt Knowledge-base<sup><xref ref-type="bibr" rid="CR59">59</xref></sup>) and computational methods<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> for protein function prediction. Some annotations may speed up learning PPIs. For example, two proteins with low scores of the “protein binding” function term hardly interact with each other. We suggest that future work may consider leveraging function annotations to enhance the expressiveness of protein representations. Inspired by the contrastive learning principle, a potentially feasible solution is to enhance the consistency in protein representations and functions. (2) Protein domain information may be beneficial for hierarchical models. We clarify the core ideas here and provide a detailed description in Supplementary Method <xref rid="MOESM1" ref-type="media">2</xref>. Domains are distinct functional or structural units in proteins and are responsible for PPIs and specific protein functions. Both in terms of structures and functions, the protein domain can represent a crucial middle scale for the PPI hierarchy. However, to our knowledge, true (native) domain annotations are not easily available and predicted ones are usually retrieved from computational tools, which inevitably leads to data unreliability. If we employ the domain scale as a separate view, data unreliability may spread to other views and impair the entire hierarchical model. On this basis, we prefer to recommend domain annotations as supervised information at the residue level. Precisely, a well-designed regularization is required to guarantee that all functional sites, discovered by HIGH-PPI, belong in the prepared domain database. The domain regularization and the PPI prediction loss form a flexible trade-off of learning objectives, which can appropriately tolerate the domain annotation unreliability. (3) Memory requirement grows with the view number of a hierarchical graph. HIGH-PPI employs two views to form the hierarchical graph and treat amino acid residues as microscopic components of proteins. However, we did not further consider one more microscopic view where atoms, the components of residues, provide information for representing residues. It might be beneficial to introduce an atom-level view and develop a memory-efficient way for storing and processing explicit 3D atom-level information. (4) In future work, model robustness can be further improved. Although our model outperforms in the robustness evaluation (see Supplementary Table <xref rid="MOESM1" ref-type="media">3</xref>), we observe that <inline-formula id="IEq45"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{FDR}}_{{pre}}$$\end{document}</tex-math><mml:math id="M90"><mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>D</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq45.gif"/></alternatives></inline-formula> is most impacted by unreliable data, which is mostly because the number of FP significantly increases (up to 6 times) from Data 1 to Data 9. A possible explanation for the significant rise in FP is that the model’s “low demand” for a positive sample permits certain controversial samples to be projected as true. To address this issue, we recommend the future work consider a straightforward method—the voting strategy which uses the voting outcomes of various independent classifiers to identify true PPIs. Independence makes it unlikely for voting classifiers to commit the same errors. A test pair can only be predicted as true if it is approved by most voting classifiers, which makes the model more demanding for the PPI presence.</p>
    </sec>
  </sec>
  <sec id="Sec11">
    <title>Methods</title>
    <sec id="Sec12">
      <title>Construction of a hierarchical graph</title>
      <p id="Par34">We denote a set of amino acid residues in a protein as <inline-formula id="IEq46"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Prot}=\{{r}_{1},{r}_{2},\ldots,{r}_{n}\}$$\end{document}</tex-math><mml:math id="M92"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq46.gif"/></alternatives></inline-formula>. Each residue is described with <inline-formula id="IEq47"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\theta$$\end{document}</tex-math><mml:math id="M94"><mml:mi>θ</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq47.gif"/></alternatives></inline-formula> kinds of physicochemical properties. For the bottom inside-of-protein view, a protein graph <inline-formula id="IEq48"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${g}_{b}=({V}_{b},{A}_{b},{X}_{b})$$\end{document}</tex-math><mml:math id="M96"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq48.gif"/></alternatives></inline-formula> is constructed to model the relationship between residues in <inline-formula id="IEq49"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Prot}$$\end{document}</tex-math><mml:math id="M98"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq49.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq50"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${V}_{b}\subseteq {Prot}$$\end{document}</tex-math><mml:math id="M100"><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>⊆</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq50.gif"/></alternatives></inline-formula> is the set of nodes, <inline-formula id="IEq51"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${A}_{b}$$\end{document}</tex-math><mml:math id="M102"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq51.gif"/></alternatives></inline-formula> is an <inline-formula id="IEq52"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\times n$$\end{document}</tex-math><mml:math id="M104"><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq52.gif"/></alternatives></inline-formula> adjacency matrix representing the connectivity in <inline-formula id="IEq53"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${g}_{b}$$\end{document}</tex-math><mml:math id="M106"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq53.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq54"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{b}\in {{\mathbb{R}}}^{n\times \theta }$$\end{document}</tex-math><mml:math id="M108"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq54.gif"/></alternatives></inline-formula> is a feature matrix containing the properties of all residues.</p>
      <p id="Par35">For the top outside-of-protein view, a set of protein graphs can be interconnected within a PPI graph <inline-formula id="IEq55"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${g}_{t}$$\end{document}</tex-math><mml:math id="M110"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq55.gif"/></alternatives></inline-formula>, which is denoted as <inline-formula id="IEq56"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${g}_{b}\in {V}_{t}$$\end{document}</tex-math><mml:math id="M112"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq56.gif"/></alternatives></inline-formula>. The connectivity (i.e., interactions) between protein graphs can be denoted as an <inline-formula id="IEq57"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m\times m$$\end{document}</tex-math><mml:math id="M114"><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq57.gif"/></alternatives></inline-formula> adjacency matrix <inline-formula id="IEq58"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${A}_{t}$$\end{document}</tex-math><mml:math id="M116"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq58.gif"/></alternatives></inline-formula>. In addition, <inline-formula id="IEq59"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{t}\in {{\mathbb{R}}}^{m\times \varnothing }$$\end{document}</tex-math><mml:math id="M118"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>∅</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq59.gif"/></alternatives></inline-formula> represents a feature matrix containing the representations of all proteins. We model the protein graphs and their connections as a hierarchical graph, in which four key variables (i.e., <inline-formula id="IEq60"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${A}_{b}$$\end{document}</tex-math><mml:math id="M120"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq60.gif"/></alternatives></inline-formula>, <inline-formula id="IEq61"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{b}$$\end{document}</tex-math><mml:math id="M122"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq61.gif"/></alternatives></inline-formula>, <inline-formula id="IEq62"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${A}_{t}$$\end{document}</tex-math><mml:math id="M124"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq62.gif"/></alternatives></inline-formula>, <inline-formula id="IEq63"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{t}$$\end{document}</tex-math><mml:math id="M126"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq63.gif"/></alternatives></inline-formula>) need to be clarified.</p>
      <p id="Par36">(1) The adjacency matrix <inline-formula id="IEq64"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${A}_{b}\in {\{{{{{\mathrm{0,1}}}}}\}}^{n\times n}$$\end{document}</tex-math><mml:math id="M128"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi mathvariant="normal">0, 1</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq64.gif"/></alternatives></inline-formula> in the protein graph and protein contact map are exactly equivalent. Contact maps are obtained with atomic level 3D coordinates of proteins. First, we retrieve the native protein structures from the Protein Data Bank<sup><xref ref-type="bibr" rid="CR60">60</xref></sup> and protein structures of various RMSD scores by AlphaFold<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>. Then we represent the location of each residue by the 3D coordinate of its <inline-formula id="IEq65"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${C}_{\alpha }$$\end{document}</tex-math><mml:math id="M130"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq65.gif"/></alternatives></inline-formula> atom. The presence or the absence of contact between a pair of residues is decided by their <inline-formula id="IEq66"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${C}_{\alpha }-{C}_{\alpha }$$\end{document}</tex-math><mml:math id="M132"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq66.gif"/></alternatives></inline-formula> physical distance. We perform a sensitivity analysis (see Supplementary Fig. <xref rid="MOESM1" ref-type="media">8</xref>) and find that our model produces similar results when trained on contact maps with cutoff distances ranging between 9 Å to 12 Å. Finally, we choose the optimal cutoff distance of 10 Å, which allows our model to peak its performance. (2) For a feature matrix <inline-formula id="IEq67"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{b}$$\end{document}</tex-math><mml:math id="M134"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq67.gif"/></alternatives></inline-formula>, each row represents a set of properties for one amino acid residue. In this work, seven residue-level properties are considered (i.e., <inline-formula id="IEq68"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\theta=7$$\end{document}</tex-math><mml:math id="M136"><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq68.gif"/></alternatives></inline-formula>): isoelectric point, polarity, acidity and alkalinity, hydrogen bond acceptor, hydrogen bond donor, octanol-water partition coefficient, and topological polar surface area. Supplementary Data File <xref rid="MOESM6" ref-type="media">3</xref> contains quantitative values of seven types of properties for each amino acid. All properties can be easily retrieved from the RDKit repository<sup><xref ref-type="bibr" rid="CR61">61</xref></sup>. (3) The PPI network structure determines the adjacency matrix <inline-formula id="IEq69"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${A}_{t}\in {\{{{{{\mathrm{0,1}}}}}\}}^{m\times m}$$\end{document}</tex-math><mml:math id="M138"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi mathvariant="normal">0, 1</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq69.gif"/></alternatives></inline-formula>, in which the <inline-formula id="IEq70"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M140"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq70.gif"/></alternatives></inline-formula>-th row and <inline-formula id="IEq71"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M142"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq71.gif"/></alternatives></inline-formula>-th column element is 1 if the <inline-formula id="IEq72"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M144"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq72.gif"/></alternatives></inline-formula>-th and <inline-formula id="IEq73"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M146"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq73.gif"/></alternatives></inline-formula>-th proteins interact. (4) The <inline-formula id="IEq74"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M148"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq74.gif"/></alternatives></inline-formula>-th row of the feature matrix <inline-formula id="IEq75"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{t}$$\end{document}</tex-math><mml:math id="M150"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq75.gif"/></alternatives></inline-formula> represents the representation vector for the <inline-formula id="IEq76"><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M152"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq76.gif"/></alternatives></inline-formula>-th protein graph <inline-formula id="IEq77"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${g}_{b}$$\end{document}</tex-math><mml:math id="M154"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq77.gif"/></alternatives></inline-formula>.</p>
    </sec>
    <sec id="Sec13">
      <title>BGNN for learning protein representations</title>
      <p id="Par37">We use the bottom view graph neural networks (BGNN) to learn protein representations. Graph convolutional networks (GCNs) have shown great effectiveness for relational data and are suitable for learning graph-structured protein representations. Thus, we propose BGNN based on GCNs.</p>
      <p id="Par38">Given the adjacency matrix <inline-formula id="IEq78"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${A}_{b}\in {\{{{{{\mathrm{0,1}}}}}\}}^{n\times n}$$\end{document}</tex-math><mml:math id="M156"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi mathvariant="normal">0, 1</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq78.gif"/></alternatives></inline-formula> and the feature matrix <inline-formula id="IEq79"><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{b}\in {{\mathbb{R}}}^{n\times \theta }$$\end{document}</tex-math><mml:math id="M158"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq79.gif"/></alternatives></inline-formula> of an arbitrary protein graph <inline-formula id="IEq80"><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${g}_{b}$$\end{document}</tex-math><mml:math id="M160"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq80.gif"/></alternatives></inline-formula>, BGNN outputs the residue-level representations in the first GCN block, <inline-formula id="IEq81"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}^{(1)}\in {{\mathbb{R}}}^{n\times {d}_{1}}$$\end{document}</tex-math><mml:math id="M162"><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq81.gif"/></alternatives></inline-formula>:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}^{(1)}={GCN}\left({A}_{b},{X}_{b}\right)$$\end{document}</tex-math><mml:math id="M164"><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mi>C</mml:mi><mml:mi>N</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="41467_2023_36736_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq82"><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{1}$$\end{document}</tex-math><mml:math id="M166"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq82.gif"/></alternatives></inline-formula> is the embedding dimension for the first GCN layer.</p>
      <p id="Par39">Formally, we update residue representations with the neighbor aggregations based on the work of Kipf and Welling<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}^{(1)}={{{{{\rm{BN}}}}}}\left({{{{{\rm{ReLU}}}}}}\left({\widetilde{D}}^{-1/2}\left({A}_{b}+{I}_{n}\right){\widetilde{D}}^{-1/2}{X}_{b}{W}^{(1)}\right)\right)$$\end{document}</tex-math><mml:math id="M168"><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">BN</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="normal">ReLU</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="41467_2023_36736_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq83"><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${I}_{n}\in {{\mathbb{R}}}^{n\times n}$$\end{document}</tex-math><mml:math id="M170"><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq83.gif"/></alternatives></inline-formula> is the identity matrix, <inline-formula id="IEq84"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{D}\in {{\mathbb{R}}}^{n\times n}$$\end{document}</tex-math><mml:math id="M172"><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq84.gif"/></alternatives></inline-formula> is the diagonal degree matrix with entries <inline-formula id="IEq85"><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{{ii}}={\sum }_{j}{\left({A}_{b}+{I}_{n}\right)}_{{ij}}$$\end{document}</tex-math><mml:math id="M174"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq85.gif"/></alternatives></inline-formula>, <inline-formula id="IEq86"><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}^{(1)}\in {{\mathbb{R}}}^{\theta \times {d}_{1}}$$\end{document}</tex-math><mml:math id="M176"><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq86.gif"/></alternatives></inline-formula> is a learnable weight matrix for the GCN layer, ReLU, BN denotes the ReLU activation function and batch normalization, respectively.</p>
      <p id="Par40">With the learnable weight matrix <inline-formula id="IEq87"><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}^{(2)}\in {{\mathbb{R}}}^{{d}_{1}\times {d}_{2}}$$\end{document}</tex-math><mml:math id="M178"><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq87.gif"/></alternatives></inline-formula>, the second GCN block produces the output <inline-formula id="IEq88"><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}^{(2)}\in {{\mathbb{R}}}^{n\times {d}_{2}}$$\end{document}</tex-math><mml:math id="M180"><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq88.gif"/></alternatives></inline-formula>:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}^{(2)}={{{{{\rm{BN}}}}}}\left({{{{{\rm{ReLU}}}}}}\left({\widetilde{D}}^{-1/2}\left({A}_{b}+{I}_{n}\right){\widetilde{D}}^{-1/2}{H}^{(1)}{W}^{(2)}\right)\right)$$\end{document}</tex-math><mml:math id="M182"><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">BN</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="normal">ReLU</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="41467_2023_36736_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par41">Finally, we perform the readout operation with a self-attention graph pooling layer<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> and average aggregation to obtain the entire graph representation of a fixed size, <inline-formula id="IEq89"><alternatives><tex-math id="M183">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x\in {{\mathbb{R}}}^{1\times {d}_{2}}$$\end{document}</tex-math><mml:math id="M184"><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq89.gif"/></alternatives></inline-formula>.To clarify, we use <inline-formula id="IEq90"><alternatives><tex-math id="M185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{i}\in {{\mathbb{R}}}^{1\times {d}_{2}}$$\end{document}</tex-math><mml:math id="M186"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq90.gif"/></alternatives></inline-formula> to represent the final representation for the <inline-formula id="IEq91"><alternatives><tex-math id="M187">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M188"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq91.gif"/></alternatives></inline-formula>-th protein graph.</p>
    </sec>
    <sec id="Sec14">
      <title>TGNN for learning PPI network information</title>
      <p id="Par42">We use the top view graph neural networks (TGNN) to learn PPI network information. We are inspired by graph isomorphism network (GIN<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>), which has the superb expressive power to capture graph structures. Formally, we are given the PPI graph <inline-formula id="IEq92"><alternatives><tex-math id="M189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${g}_{t}=({V}_{t},{A}_{t},{X}_{t})$$\end{document}</tex-math><mml:math id="M190"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq92.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq93"><alternatives><tex-math id="M191">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{t}\in {{\mathbb{R}}}^{m\times {d}_{2}}$$\end{document}</tex-math><mml:math id="M192"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq93.gif"/></alternatives></inline-formula> is defined as the feature matrix whose row vector is a final protein representation from BGNN (i.e., <inline-formula id="IEq94"><alternatives><tex-math id="M193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{t}^{\left[i,:\right]}={x}_{i},i={{{{\mathrm{1,2}}}}},\ldots,m$$\end{document}</tex-math><mml:math id="M194"><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>:</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">1, 2</mml:mi><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq94.gif"/></alternatives></inline-formula>). TGNN updates the representation of protein <inline-formula id="IEq95"><alternatives><tex-math id="M195">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v$$\end{document}</tex-math><mml:math id="M196"><mml:mi>v</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq95.gif"/></alternatives></inline-formula> in the <inline-formula id="IEq96"><alternatives><tex-math id="M197">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M198"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq96.gif"/></alternatives></inline-formula>-th GIN block:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M199">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{v}^{(k)}={{{{{\rm{BN}}}}}}\left({{{{{\rm{ReLU}}}}}}\left({{{{{{\rm{MLP}}}}}}}^{(k)}\left(\left(1+\epsilon \right) \, \bullet \, {x}_{v}^{\left(k-1\right)}+{\sum }_{u{{\in }}{{{{{\mathscr{N}}}}}}({{{{{\mathcal{v}}}}}})}{x}_{u}^{(k-1)}\right)\right)\right)$$\end{document}</tex-math><mml:math id="M200"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">BN</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="normal">ReLU</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">MLP</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:mfenced><mml:mspace width="0.25em"/><mml:mo>∙</mml:mo><mml:mspace width="0.25em"/><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="41467_2023_36736_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq97"><alternatives><tex-math id="M201">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{v}^{(k)}$$\end{document}</tex-math><mml:math id="M202"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq97.gif"/></alternatives></inline-formula> denotes the representation of protein <inline-formula id="IEq98"><alternatives><tex-math id="M203">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v$$\end{document}</tex-math><mml:math id="M204"><mml:mi>v</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq98.gif"/></alternatives></inline-formula> after the <inline-formula id="IEq99"><alternatives><tex-math id="M205">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M206"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq99.gif"/></alternatives></inline-formula>-th GIN block, <inline-formula id="IEq100"><alternatives><tex-math id="M207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\mathscr{N}}}}}}({{{{{\mathcal{v}}}}}})$$\end{document}</tex-math><mml:math id="M208"><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq100.gif"/></alternatives></inline-formula> is a set of proteins adjacent to <inline-formula id="IEq101"><alternatives><tex-math id="M209">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v$$\end{document}</tex-math><mml:math id="M210"><mml:mi>v</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq101.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq102"><alternatives><tex-math id="M211">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon$$\end{document}</tex-math><mml:math id="M212"><mml:mi>ϵ</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq102.gif"/></alternatives></inline-formula> is a learnable parameter. We denote the inputs of protein representations for the first GIN block as <inline-formula id="IEq103"><alternatives><tex-math id="M213">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{i}^{(0)}={x}_{i},i={{{{\mathrm{1,2}}}}},\ldots,m$$\end{document}</tex-math><mml:math id="M214"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">1, 2</mml:mi><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq103.gif"/></alternatives></inline-formula>.</p>
      <p id="Par43">After three GIN blocks, TGNN produces representations for all proteins. For an arbitrary query pair containing the <inline-formula id="IEq104"><alternatives><tex-math id="M215">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M216"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq104.gif"/></alternatives></inline-formula>-th and <inline-formula id="IEq105"><alternatives><tex-math id="M217">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M218"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq105.gif"/></alternatives></inline-formula>-th proteins, we use the concatenation operation to combine the representations of <inline-formula id="IEq106"><alternatives><tex-math id="M219">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{i}^{(3)}$$\end{document}</tex-math><mml:math id="M220"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq106.gif"/></alternatives></inline-formula> and <inline-formula id="IEq107"><alternatives><tex-math id="M221">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{j}^{(3)}$$\end{document}</tex-math><mml:math id="M222"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq107.gif"/></alternatives></inline-formula>. A fully connected layer (FC) is employed as the classifier. The final vector <inline-formula id="IEq108"><alternatives><tex-math id="M223">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{y}}_{{ij}}\in {{\mathbb{R}}}^{1\times c}$$\end{document}</tex-math><mml:math id="M224"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq108.gif"/></alternatives></inline-formula> for the presence probability of PPI is denoted as <inline-formula id="IEq109"><alternatives><tex-math id="M225">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{y}}_{{ij}}={{{{{\rm{FC}}}}}}\left({h}_{i}^{(3)}{||}{h}_{j}^{(3)}\right)$$\end{document}</tex-math><mml:math id="M226"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">FC</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:mo>∣</mml:mo><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq109.gif"/></alternatives></inline-formula> where <inline-formula id="IEq110"><alternatives><tex-math id="M227">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c$$\end{document}</tex-math><mml:math id="M228"><mml:mi>c</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq110.gif"/></alternatives></inline-formula> denotes the total number of PPI types involved and <inline-formula id="IEq111"><alternatives><tex-math id="M229">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\parallel$$\end{document}</tex-math><mml:math id="M230"><mml:mo>∥</mml:mo></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq111.gif"/></alternatives></inline-formula> denotes the concatenation operation.</p>
    </sec>
    <sec id="Sec15">
      <title>Model training details</title>
      <p id="Par44">Given a training set <inline-formula id="IEq112"><alternatives><tex-math id="M231">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\mathscr{X}}}}}}}_{{train}}$$\end{document}</tex-math><mml:math id="M232"><mml:msub><mml:mrow><mml:mi mathvariant="script">X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq112.gif"/></alternatives></inline-formula> and ground truth labels for multi-type PPIs <inline-formula id="IEq113"><alternatives><tex-math id="M233">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{\mathscr{Y}}}}}}}_{{train}}$$\end{document}</tex-math><mml:math id="M234"><mml:msub><mml:mrow><mml:mi mathvariant="script">Y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq113.gif"/></alternatives></inline-formula>, we train BGNN and TGNN in an end-to-end manner by minimizing the loss function of multi-task binary cross-entropy:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M235">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\mathcal{L}}}}}}\left(\Theta \right)=\mathop{\sum }\limits_{k=0}^{c}\left(\mathop{\sum}\limits_{{x}_{{ij}}\in {{{{{{\mathscr{X}}}}}}}_{{train}}}-{y}_{{ij}}^{k}\log {\hat{y}}_{{ij}}^{k}-\left(1-{y}_{{ij}}^{k}\right)\log \left(1-{\hat{y}}_{{ij}}^{k}\right)\right)$$\end{document}</tex-math><mml:math id="M236"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:munderover><mml:mfenced close=")" open="("><mml:mrow><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mi>log</mml:mi><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mi>log</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="41467_2023_36736_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq114"><alternatives><tex-math id="M237">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Theta$$\end{document}</tex-math><mml:math id="M238"><mml:mi mathvariant="normal">Θ</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq114.gif"/></alternatives></inline-formula> is the set of all learnable parameters, and <inline-formula id="IEq115"><alternatives><tex-math id="M239">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${ij}$$\end{document}</tex-math><mml:math id="M240"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq115.gif"/></alternatives></inline-formula> denotes the ground truth of the <inline-formula id="IEq116"><alternatives><tex-math id="M241">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M242"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq116.gif"/></alternatives></inline-formula>-th type PPI of the <inline-formula id="IEq117"><alternatives><tex-math id="M243">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M244"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq117.gif"/></alternatives></inline-formula>-th and <inline-formula id="IEq118"><alternatives><tex-math id="M245">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M246"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq118.gif"/></alternatives></inline-formula>-th proteins.</p>
      <p id="Par45">We determine all the hyper-parameters through a grid search based on a 5-fold cross-validation. For BGNN, we set the output dimension <inline-formula id="IEq119"><alternatives><tex-math id="M247">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{1}$$\end{document}</tex-math><mml:math id="M248"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq119.gif"/></alternatives></inline-formula>, <inline-formula id="IEq120"><alternatives><tex-math id="M249">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{2}$$\end{document}</tex-math><mml:math id="M250"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq120.gif"/></alternatives></inline-formula> of weight matrix to 128. For each GIN block in TGNN, we use a two-layer MLP and set the output dimension of each layer to 64. As the STRING dataset contains seven types of PPIs, we set the output dimension of the FC layer to <inline-formula id="IEq121"><alternatives><tex-math id="M251">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c=7$$\end{document}</tex-math><mml:math id="M252"><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq121.gif"/></alternatives></inline-formula>. We use the Adam optimizer with a learning rate <inline-formula id="IEq122"><alternatives><tex-math id="M253">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${lr}=0.001$$\end{document}</tex-math><mml:math id="M254"><mml:mi>l</mml:mi><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq122.gif"/></alternatives></inline-formula>, <inline-formula id="IEq123"><alternatives><tex-math id="M255">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}=0.99$$\end{document}</tex-math><mml:math id="M256"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.99</mml:mn></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq123.gif"/></alternatives></inline-formula>, <inline-formula id="IEq124"><alternatives><tex-math id="M257">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{2}=0.99$$\end{document}</tex-math><mml:math id="M258"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.99</mml:mn></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq124.gif"/></alternatives></inline-formula>, a batch size of 128, and the default epoch number of 500. We train all of the model parameters until convergence in each cross-validation.</p>
    </sec>
    <sec id="Sec16">
      <title>Residue importance computation</title>
      <p id="Par46">We employ the method called GNNExplainer<sup><xref ref-type="bibr" rid="CR62">62</xref></sup> to generate explanations for HIGH-PPI. By taking the well-trained GNN model and its predictions as inputs, GNNExplainer returns the most important subgraph by maximizing the mutual information <inline-formula id="IEq125"><alternatives><tex-math id="M259">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${MI}$$\end{document}</tex-math><mml:math id="M260"><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq125.gif"/></alternatives></inline-formula> between the model prediction and possible subgraphs. Motivated by this, we directly formalize the notion of subgraph importance using <inline-formula id="IEq126"><alternatives><tex-math id="M261">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${MI}$$\end{document}</tex-math><mml:math id="M262"><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq126.gif"/></alternatives></inline-formula> and further compute the importance of all nodes (i.e., residues).</p>
      <p id="Par47">Given protein graphs <inline-formula id="IEq127"><alternatives><tex-math id="M263">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${G}_{1}$$\end{document}</tex-math><mml:math id="M264"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq127.gif"/></alternatives></inline-formula> and <inline-formula id="IEq128"><alternatives><tex-math id="M265">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${G}_{2}$$\end{document}</tex-math><mml:math id="M266"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq128.gif"/></alternatives></inline-formula> that connect in the PPI network, our goal is to identify the node importance of <inline-formula id="IEq129"><alternatives><tex-math id="M267">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${G}_{1}$$\end{document}</tex-math><mml:math id="M268"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq129.gif"/></alternatives></inline-formula>. According to GNNExplainer, once sampling a random subgraph <inline-formula id="IEq130"><alternatives><tex-math id="M269">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${G}_{s}\subseteq {G}_{1}$$\end{document}</tex-math><mml:math id="M270"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>⊆</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq130.gif"/></alternatives></inline-formula>, we obtain the entire importance of <inline-formula id="IEq131"><alternatives><tex-math id="M271">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${G}_{s}$$\end{document}</tex-math><mml:math id="M272"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq131.gif"/></alternatives></inline-formula> as follow:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M273">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{MI}}_{s}\left(Y,{G}_{s}\right)=H\left(Y\right)-H\left(Y|G={G}_{s}\right)$$\end{document}</tex-math><mml:math id="M274"><mml:msub><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:mfenced><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>Y</mml:mi><mml:mo>∣</mml:mo><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="41467_2023_36736_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq132"><alternatives><tex-math id="M275">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{MI}}_{s}$$\end{document}</tex-math><mml:math id="M276"><mml:msub><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq132.gif"/></alternatives></inline-formula> represents importance of <inline-formula id="IEq133"><alternatives><tex-math id="M277">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${G}_{s}$$\end{document}</tex-math><mml:math id="M278"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq133.gif"/></alternatives></inline-formula>, <inline-formula id="IEq134"><alternatives><tex-math id="M279">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Y$$\end{document}</tex-math><mml:math id="M280"><mml:mi>Y</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq134.gif"/></alternatives></inline-formula> is a variable indicating the probability of PPI presence of <inline-formula id="IEq135"><alternatives><tex-math id="M281">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${G}_{1}$$\end{document}</tex-math><mml:math id="M282"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq135.gif"/></alternatives></inline-formula> and <inline-formula id="IEq136"><alternatives><tex-math id="M283">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${G}_{2}$$\end{document}</tex-math><mml:math id="M284"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq136.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq137"><alternatives><tex-math id="M285">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H\left(\bullet \right)$$\end{document}</tex-math><mml:math id="M286"><mml:mi>H</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mo>∙</mml:mo></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq137.gif"/></alternatives></inline-formula> is the entropy term.</p>
      <p id="Par48">Assume that all nodes in the subgraph <inline-formula id="IEq138"><alternatives><tex-math id="M287">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${G}_{s}$$\end{document}</tex-math><mml:math id="M288"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq138.gif"/></alternatives></inline-formula> contribute equally to the <inline-formula id="IEq139"><alternatives><tex-math id="M289">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${MI}$$\end{document}</tex-math><mml:math id="M290"><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq139.gif"/></alternatives></inline-formula> value, we obtain the batch importance for each node in <inline-formula id="IEq140"><alternatives><tex-math id="M291">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${G}_{s}$$\end{document}</tex-math><mml:math id="M292"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq140.gif"/></alternatives></inline-formula>. The final importance score for a specific node is the average of all its batch importance scores. For example, if a node <inline-formula id="IEq141"><alternatives><tex-math id="M293">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v$$\end{document}</tex-math><mml:math id="M294"><mml:mi>v</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq141.gif"/></alternatives></inline-formula> contributes 0.4 and 0.6 for two sampled subgraphs respectively, the final importance of node <inline-formula id="IEq142"><alternatives><tex-math id="M295">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v$$\end{document}</tex-math><mml:math id="M296"><mml:mi>v</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq142.gif"/></alternatives></inline-formula> is 0.5. To facilitate comparison, we compute the <italic>z</italic>-scores of final residue importance for standardization:<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M297">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${z}_{s}=\frac{{z}_{f}-\mu }{\sigma }$$\end{document}</tex-math><mml:math id="M298"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41467_2023_36736_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq143"><alternatives><tex-math id="M299">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${z}_{f}\in {{\mathbb{R}}}^{1\times n}$$\end{document}</tex-math><mml:math id="M300"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq143.gif"/></alternatives></inline-formula> is the finally computed importance vector for all residues, <inline-formula id="IEq144"><alternatives><tex-math id="M301">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu$$\end{document}</tex-math><mml:math id="M302"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq144.gif"/></alternatives></inline-formula> is the average of <inline-formula id="IEq145"><alternatives><tex-math id="M303">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${z}_{f}$$\end{document}</tex-math><mml:math id="M304"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq145.gif"/></alternatives></inline-formula>, <inline-formula id="IEq146"><alternatives><tex-math id="M305">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu$$\end{document}</tex-math><mml:math id="M306"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq146.gif"/></alternatives></inline-formula> is the standard deviation of <inline-formula id="IEq147"><alternatives><tex-math id="M307">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${z}_{f}$$\end{document}</tex-math><mml:math id="M308"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq147.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq148"><alternatives><tex-math id="M309">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${z}_{s}\in {{\mathbb{R}}}^{1\times n}$$\end{document}</tex-math><mml:math id="M310"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq148.gif"/></alternatives></inline-formula> is the <italic>z</italic>-score importance after standardization.</p>
    </sec>
    <sec id="Sec17">
      <title>Statistics and reproducibility</title>
      <p id="Par49">As indicated in figure legends, data in bar charts are represented as mean <inline-formula id="IEq149"><alternatives><tex-math id="M311">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pm$$\end{document}</tex-math><mml:math id="M312"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="41467_2023_36736_Article_IEq149.gif"/></alternatives></inline-formula> standard deviation (SD). For all boxplots, the center line represents the median, upper and lower edges represent the interquartile range, and the whiskers represent 0.5× interquartile range. The statistical significance between the two groups was obtained by a two-sided <italic>t</italic>-test with <italic>P</italic>-value &lt; 0.05 considered significant.</p>
    </sec>
    <sec id="Sec18">
      <title>Reporting summary</title>
      <p id="Par50">Further information on research design is available in the <xref rid="MOESM7" ref-type="media">Nature Portfolio Reporting Summary</xref> linked to this article.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec19">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41467_2023_36736_MOESM1_ESM.pdf">
            <caption>
              <p>Supplementary Information</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="41467_2023_36736_MOESM2_ESM.pdf">
            <caption>
              <p>Peer Review File</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="41467_2023_36736_MOESM3_ESM.docx">
            <caption>
              <p>Description of Supplementary Data</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM4">
          <media xlink:href="41467_2023_36736_MOESM4_ESM.xlsx">
            <caption>
              <p>Supplementary Data 1</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM5">
          <media xlink:href="41467_2023_36736_MOESM5_ESM.xlsx">
            <caption>
              <p>Supplementary Data 2</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM6">
          <media xlink:href="41467_2023_36736_MOESM6_ESM.xlsx">
            <caption>
              <p>Supplementary Data 3</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM7">
          <media xlink:href="41467_2023_36736_MOESM7_ESM.pdf">
            <caption>
              <p>Reporting Summary</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <app-group>
    <app id="App1">
      <sec id="Sec20">
        <title>Source data</title>
        <p id="Par54">
          <media position="anchor" xlink:href="41467_2023_36736_MOESM8_ESM.xlsx" id="MOESM8">
            <caption>
              <p>Source Data</p>
            </caption>
          </media>
        </p>
      </sec>
    </app>
  </app-group>
  <fn-group>
    <fn>
      <p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p>The online version contains supplementary material available at 10.1038/s41467-023-36736-1.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>The research of Li was supported by National Natural Science Foundation of China (Grant No. 62206067), Tencent AI Lab Rhino-Bird Focused Research Program RBFR2022008 and Guangzhou-HKUST(GZ) Joint Funding Scheme. The research of Huang was supported by the National Natural Science Foundation of China (Grant No. 21825101).</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>Z.G. and C.J. wrote the first draft of manuscript. J.L., Y.H., and L.L. revised the manuscript to the submitted version. J.L., Z.G., Y.H., and H.Y. conceived the study. Z.G. designed all the experiments and wrote the codebase of HIGH-PPI. Z.G., J.Z., and X.J. conduct the benchmarks, and run all of the analysis. X.J. collected and preprocessed protein contact maps. Z.G., L.L., and P.Z. contributed to data analysis and model discussion. J.Z. conducted the figure design for overall framework. Z.G., C.J., J.Z., and X.J. completed the visualizations. J.L. and Y.H. supervised the research. All of the authors reviewed the manuscript and approved it for submission.</p>
  </notes>
  <notes notes-type="peer-review">
    <title>Peer review</title>
    <sec id="FPar1">
      <title>Peer review information</title>
      <p id="Par51"><italic>Nature Communications</italic> thanks Pufeng Du and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. <xref rid="MOESM2" ref-type="media">Peer reviewer reports</xref> are available.</p>
    </sec>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The PPI and protein data used in this study are available in the Zenodo database under “Accession Code <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.7213401">7213401</ext-link>”. They are obtained from the following publicly available database. Datasets containing protein sequences and their interaction annotations are obtained from <ext-link ext-link-type="uri" xlink:href="https://github.com/muhaochen/seq_ppi">https://github.com/muhaochen/seq_ppi</ext-link>. The native protein structures are obtained from PDB: <ext-link ext-link-type="uri" xlink:href="https://www.rcsb.org/">https://www.rcsb.org/</ext-link>. Protein structures with errors are obtained from AlphaFold: <ext-link ext-link-type="uri" xlink:href="https://alphafold.ebi.ac.uk/">https://alphafold.ebi.ac.uk/</ext-link>. The catalytic site information of proteins can be found at CSA: <ext-link ext-link-type="uri" xlink:href="https://www.ebi.ac.uk/thornton-srv/m-csa/">https://www.ebi.ac.uk/thornton-srv/m-csa/</ext-link>. The ground truth of binding site information is obtained from PDBePISA: <ext-link ext-link-type="uri" xlink:href="https://www.ebi.ac.uk/pdbe/pisa/">https://www.ebi.ac.uk/pdbe/pisa/</ext-link>. All other relevant data supporting the key findings of this study are available within the article and its Supplementary Information files or from the corresponding author upon reasonable request. <xref rid="Sec20" ref-type="sec">Source data</xref> are provided with this paper.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Code availability</title>
    <p>An open-source software implementation of HIGH-PPI is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/zqgao22/HIGH-PPI">https://github.com/zqgao22/HIGH-PPI</ext-link>. The source code can be cited by using 10.5281/zenodo.7600622.</p>
  </notes>
  <notes id="FPar2" notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par52">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Petta</surname>
            <given-names>I</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Modulation of protein–protein interactions for the development of novel therapeutics</article-title>
        <source>Mol. Ther.</source>
        <year>2016</year>
        <volume>24</volume>
        <fpage>707</fpage>
        <lpage>718</lpage>
        <pub-id pub-id-type="doi">10.1038/mt.2015.214</pub-id>
        <?supplied-pmid 26675501?>
        <pub-id pub-id-type="pmid">26675501</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Skrabanek</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Saini</surname>
            <given-names>HK</given-names>
          </name>
          <name>
            <surname>Bader</surname>
            <given-names>GD</given-names>
          </name>
          <name>
            <surname>Enright</surname>
            <given-names>AJ</given-names>
          </name>
        </person-group>
        <article-title>Computational prediction of protein–protein interactions</article-title>
        <source>Mol. Biotechnol.</source>
        <year>2008</year>
        <volume>38</volume>
        <fpage>1</fpage>
        <lpage>17</lpage>
        <pub-id pub-id-type="doi">10.1007/s12033-007-0069-2</pub-id>
        <?supplied-pmid 18095187?>
        <pub-id pub-id-type="pmid">18095187</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hope</surname>
            <given-names>KJ</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Dick</surname>
            <given-names>JE</given-names>
          </name>
        </person-group>
        <article-title>Acute myeloid leukemia originates from a hierarchy of leukemic stem cell classes that differ in self-renewal capacity</article-title>
        <source>Nat. Immunol.</source>
        <year>2004</year>
        <volume>5</volume>
        <fpage>738</fpage>
        <lpage>743</lpage>
        <pub-id pub-id-type="doi">10.1038/ni1080</pub-id>
        <?supplied-pmid 15170211?>
        <pub-id pub-id-type="pmid">15170211</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <mixed-citation publication-type="other">Zeng, A. G. et al. A cellular hierarchy framework for understanding heterogeneity and predicting drug response in acute myeloid leukemia. <italic>Nat. Med.</italic><bold>28</bold>, 1–12 (2022).</mixed-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Couturier</surname>
            <given-names>CP</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Single-cell RNA-seq reveals that glioblastoma recapitulates a normal neurodevelopmental hierarchy</article-title>
        <source>Nat. Commun.</source>
        <year>2020</year>
        <volume>11</volume>
        <fpage>1</fpage>
        <lpage>19</lpage>
        <pub-id pub-id-type="pmid">31911652</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Engelberg</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Bechtel</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Michaud</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Weerapana</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Gubbels</surname>
            <given-names>MJ</given-names>
          </name>
        </person-group>
        <article-title>Proteomic characterization of the Toxoplasma gondii cytokinesis machinery portrays an expanded hierarchy of its assembly and function</article-title>
        <source>Nat. Commun.</source>
        <year>2022</year>
        <volume>13</volume>
        <fpage>1</fpage>
        <lpage>15</lpage>
        <pub-id pub-id-type="doi">10.1038/s41467-022-32151-0</pub-id>
        <pub-id pub-id-type="pmid">34983933</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wigbers</surname>
            <given-names>MC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A hierarchy of protein patterns robustly decodes cell shape information</article-title>
        <source>Nat. Phys.</source>
        <year>2021</year>
        <volume>17</volume>
        <fpage>578</fpage>
        <lpage>584</lpage>
        <pub-id pub-id-type="doi">10.1038/s41567-021-01164-9</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ho</surname>
            <given-names>TSY</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A hierarchy of ankyrin-spectrin complexes clusters sodium channels at nodes of Ranvier</article-title>
        <source>Nat. Neurosci.</source>
        <year>2014</year>
        <volume>17</volume>
        <fpage>1664</fpage>
        <lpage>1672</lpage>
        <pub-id pub-id-type="doi">10.1038/nn.3859</pub-id>
        <?supplied-pmid 25362473?>
        <pub-id pub-id-type="pmid">25362473</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Siegle</surname>
            <given-names>JH</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Survey of spiking in the mouse visual system reveals functional hierarchy</article-title>
        <source>Nature</source>
        <year>2021</year>
        <volume>592</volume>
        <fpage>86</fpage>
        <lpage>92</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-020-03171-x</pub-id>
        <?supplied-pmid 33473216?>
        <pub-id pub-id-type="pmid">33473216</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hendrikx</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Paul</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>van Ackooij</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>van der Stoep</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Harvey</surname>
            <given-names>BM</given-names>
          </name>
        </person-group>
        <article-title>Visual timing-tuned responses in human association cortices and response dynamics in early visual cortex</article-title>
        <source>Nat. Commun.</source>
        <year>2022</year>
        <volume>13</volume>
        <fpage>1</fpage>
        <lpage>19</lpage>
        <pub-id pub-id-type="doi">10.1038/s41467-022-31675-9</pub-id>
        <pub-id pub-id-type="pmid">34983933</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A system hierarchy for brain-inspired computing</article-title>
        <source>Nature</source>
        <year>2020</year>
        <volume>586</volume>
        <fpage>378</fpage>
        <lpage>384</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-020-2782-y</pub-id>
        <?supplied-pmid 33057220?>
        <pub-id pub-id-type="pmid">33057220</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guharoy</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lazar</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Macossay-Castillo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Tompa</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Degron masking outlines degronons, co-degrading functional modules in the proteome</article-title>
        <source>Commun. Biol.</source>
        <year>2022</year>
        <volume>5</volume>
        <fpage>1</fpage>
        <lpage>15</lpage>
        <pub-id pub-id-type="doi">10.1038/s42003-022-03391-z</pub-id>
        <pub-id pub-id-type="pmid">34987157</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>CH</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Identification of lncRNA functions in lung cancer based on associated protein-protein interaction modules</article-title>
        <source>Sci. Rep.</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="pmid">28442746</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rolland</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A proteome-scale map of the human interactome network</article-title>
        <source>Cell</source>
        <year>2014</year>
        <volume>159</volume>
        <fpage>1212</fpage>
        <lpage>1226</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2014.10.050</pub-id>
        <?supplied-pmid 25416956?>
        <pub-id pub-id-type="pmid">25416956</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hein</surname>
            <given-names>MY</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A human interactome in three quantitative dimensions organized by stoichiometries and abundances</article-title>
        <source>Cell</source>
        <year>2015</year>
        <volume>163</volume>
        <fpage>712</fpage>
        <lpage>723</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2015.09.053</pub-id>
        <?supplied-pmid 26496610?>
        <pub-id pub-id-type="pmid">26496610</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huttlin</surname>
            <given-names>EL</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Architecture of the human interactome defines protein communities and disease networks</article-title>
        <source>Nature</source>
        <year>2017</year>
        <volume>545</volume>
        <fpage>505</fpage>
        <lpage>509</lpage>
        <pub-id pub-id-type="doi">10.1038/nature22366</pub-id>
        <?supplied-pmid 28514442?>
        <pub-id pub-id-type="pmid">28514442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Kaboord, B. &amp; Perr, M. Isolation of proteins and protein complexes by immunoprecipitation. <italic>Methods Mol. Biol.</italic><bold>424</bold>, 349–364 (2008).</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Aronheim</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Zandi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Hennemann</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Elledge</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Karin</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Isolation of an AP-1 repressor by a novel method for detecting protein-protein interactions</article-title>
        <source>Mol. Cell. Biol.</source>
        <year>1997</year>
        <volume>17</volume>
        <fpage>3094</fpage>
        <lpage>3102</lpage>
        <pub-id pub-id-type="doi">10.1128/MCB.17.6.3094</pub-id>
        <?supplied-pmid 9154808?>
        <pub-id pub-id-type="pmid">9154808</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Su</surname>
            <given-names>JF</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>XY</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>XY</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Structure and properties of carboxymethyl cellulose/soy protein isolate blend edible films crosslinked by Maillard reactions</article-title>
        <source>Carbohydr. Polym.</source>
        <year>2010</year>
        <volume>79</volume>
        <fpage>145</fpage>
        <lpage>153</lpage>
        <pub-id pub-id-type="doi">10.1016/j.carbpol.2009.07.035</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Conjoint feature representation of GO and protein sequence for PPI prediction based on an inception RNN attention network</article-title>
        <source>Mol. Ther.-Nucleic Acids</source>
        <year>2020</year>
        <volume>22</volume>
        <fpage>198</fpage>
        <lpage>208</lpage>
        <pub-id pub-id-type="doi">10.1016/j.omtn.2020.08.025</pub-id>
        <?supplied-pmid 33230427?>
        <pub-id pub-id-type="pmid">33230427</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Renaud</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DeepRank: a deep learning framework for data mining 3D protein-protein interfaces</article-title>
        <source>Nat. Commun.</source>
        <year>2021</year>
        <volume>12</volume>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1038/s41467-021-27396-0</pub-id>
        <pub-id pub-id-type="pmid">33397941</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kov´acs</surname>
            <given-names>IA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Network-based prediction of protein interactions</article-title>
        <source>Nat. Commun.</source>
        <year>2019</year>
        <volume>10</volume>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1038/s41467-019-09177-y</pub-id>
        <pub-id pub-id-type="pmid">30602773</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nasiri</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Berahmand</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Rostami</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dabiri</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>A novel link prediction algorithm for protein-protein interaction networks by attributed graph embedding</article-title>
        <source>Computers Biol. Med.</source>
        <year>2021</year>
        <volume>137</volume>
        <fpage>104772</fpage>
        <pub-id pub-id-type="doi">10.1016/j.compbiomed.2021.104772</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Lv, G., Hu, Z., Bi, Y. &amp; Zhang, S. Learning unknown from correlations: graph neural network for inter-novel-protein interaction prediction. In <italic>30th International Joint Conference on Artificial Intelligence (IJCAI).</italic>10.48550/arXiv.2105.06709 (2021).</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kulmanov</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Hoehndorf</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>DeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>660</fpage>
        <lpage>668</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx624</pub-id>
        <?supplied-pmid 29028931?>
        <pub-id pub-id-type="pmid">29028931</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Multifaceted protein–protein interaction prediction based on Siamese residual RCNN</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <fpage>i305</fpage>
        <lpage>i314</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btz328</pub-id>
        <?supplied-pmid 31510705?>
        <pub-id pub-id-type="pmid">31510705</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Hsieh, Y. L., Chang, Y. C., Chang, N. W. &amp; Hsu, W. L. In <italic>Proc. 8th International Joint Conference on Natural Language Processing Vol. 2 (Short Papers)</italic> 240–245 (Asian Federation of Natural Language Processing, 2017).</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Saha</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Raghava</surname>
            <given-names>GPS</given-names>
          </name>
        </person-group>
        <article-title>Prediction of continuous B-cell epitopes in an antigen using recurrent neural network</article-title>
        <source>Proteins: Struct., Funct., Bioinforma.</source>
        <year>2006</year>
        <volume>65</volume>
        <fpage>40</fpage>
        <lpage>48</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.21078</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gligorijević</surname>
            <given-names>V</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Structure-based protein function prediction using graph convolutional networks</article-title>
        <source>Nat. Commun.</source>
        <year>2021</year>
        <volume>12</volume>
        <fpage>1</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="doi">10.1038/s41467-021-23303-9</pub-id>
        <pub-id pub-id-type="pmid">33397941</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jiménez</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DeepSite: protein-binding site predictor using 3D-convolutional neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <fpage>3036</fpage>
        <lpage>3042</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx350</pub-id>
        <?supplied-pmid 28575181?>
        <pub-id pub-id-type="pmid">28575181</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Amidi</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>EnzyNet: enzyme classification using 3D convolutional neural networks on spatial representation</article-title>
        <source>PeerJ</source>
        <year>2018</year>
        <volume>6</volume>
        <fpage>e4750</fpage>
        <pub-id pub-id-type="doi">10.7717/peerj.4750</pub-id>
        <?supplied-pmid 29740518?>
        <pub-id pub-id-type="pmid">29740518</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">Tubiana, J., Schneidman-Duhovny, D. &amp; Wolfson, H. J. ScanNet: An interpretable geometric deep learning model for structure-based protein binding site prediction. <italic>Nat. Methods</italic><bold>19</bold>, 1–10 (2022).</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Goldberg</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Roth</surname>
            <given-names>FP</given-names>
          </name>
        </person-group>
        <article-title>Assessing experimentally derived interactions in a small world</article-title>
        <source>Proc. Natl Acad. Sci.</source>
        <year>2003</year>
        <volume>100</volume>
        <fpage>4372</fpage>
        <lpage>4376</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.0735871100</pub-id>
        <?supplied-pmid 12676999?>
        <pub-id pub-id-type="pmid">12676999</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fouss</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Pirotte</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Renders</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Saerens</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Random-walk computation of similarities between nodes of a graph with application to collaborative recommendation</article-title>
        <source>IEEE Trans. Knowl. Data Eng.</source>
        <year>2007</year>
        <volume>19</volume>
        <fpage>355</fpage>
        <lpage>369</lpage>
        <pub-id pub-id-type="doi">10.1109/TKDE.2007.46</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Tong, H., Faloutsos, C. &amp; Pan, J. Y. <italic>6th International Conference on Data Mining (ICDM)</italic> (IEEE, 2006).</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Kipf, T. N. &amp; Welling, M. Semi-supervised classification with graph convolutional networks. In <italic>5th International Conference on Learning Representations (ICLR)</italic><italic>.</italic>10.48550/arXiv.1609.02907 (2017).</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Xu, K., Hu, W., Leskovec, J. &amp; Jegelka, S. How powerful are graph neural networks? In <italic>7th International Conference on Learning Representations (ICLR)</italic><italic>.</italic>10.48550/arXiv.1810.00826 (2019).</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Szklarczyk</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>STRING v11: protein–protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets</article-title>
        <source>Nucleic acids Res.</source>
        <year>2019</year>
        <volume>47</volume>
        <fpage>D607</fpage>
        <lpage>D613</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky1131</pub-id>
        <?supplied-pmid 30476243?>
        <pub-id pub-id-type="pmid">30476243</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Lee, J., Lee, I. &amp; Kang, J. Self-attention graph pooling. In <italic>36th International Conference on Machine Learning (ICML)</italic><italic>.</italic>10.48550/arXiv.1904.08082 (2019).</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Predicting drug–protein interaction using quasi-visual question answering system</article-title>
        <source>Nat. Mach. Intell.</source>
        <year>2020</year>
        <volume>2</volume>
        <fpage>134</fpage>
        <lpage>140</lpage>
        <pub-id pub-id-type="doi">10.1038/s42256-020-0152-y</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">Wong, L., You, Z. H., Li, S., Huang, Y. A. &amp; Liu, G. Detection of protein–protein interactions from amino acid sequences using a rotation forest model with a novel PR-LPQ descriptor. <italic>Adv. Intell. Syst. Comput.</italic>10.1007/978-3-319-22053-6_75 (2015).</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Park</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Marcotte</surname>
            <given-names>EM</given-names>
          </name>
        </person-group>
        <article-title>Flaws in evaluation schemes for pair-input computational predictions</article-title>
        <source>Nat. methods</source>
        <year>2012</year>
        <volume>9</volume>
        <fpage>1134</fpage>
        <lpage>1136</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2259</pub-id>
        <?supplied-pmid 23223166?>
        <pub-id pub-id-type="pmid">23223166</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jumper</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Highly accurate protein structure prediction with AlphaFold</article-title>
        <source>Nature</source>
        <year>2021</year>
        <volume>596</volume>
        <fpage>583</fpage>
        <lpage>589</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-021-03819-2</pub-id>
        <?supplied-pmid 34265844?>
        <pub-id pub-id-type="pmid">34265844</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <mixed-citation publication-type="other">Yang, C., Rangarajan, A. &amp; Ranka, S. Visual explanations from deep 3D convolutional neural networks for Alzheimer’s disease classification. <italic>AMIA Annu. Symp. Proc.</italic><bold>2018</bold>, 1571–1580 (2018).</mixed-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <mixed-citation publication-type="other">Ming, Y. et al. Understanding hidden memories of recurrent neural networks. In <italic>2017 IEEE Conference on Visual Analytics Science and Technology (VAST)</italic><italic>.</italic>10.48550/arXiv.1710.10777 (2017).</mixed-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fernandes</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Gattass</surname>
            <given-names>CR</given-names>
          </name>
        </person-group>
        <article-title>Topological polar surface area defines substrate transport by multidrug resistance associated protein 1 (MRP1/ABCC1)</article-title>
        <source>J. medicinal Chem.</source>
        <year>2009</year>
        <volume>52</volume>
        <fpage>1214</fpage>
        <lpage>1218</lpage>
        <pub-id pub-id-type="doi">10.1021/jm801389m</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Wolfson</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Nussinov</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Conservation of polar residues as hot spots at protein interfaces</article-title>
        <source>Proteins: Struct., Funct., Bioinforma.</source>
        <year>2000</year>
        <volume>39</volume>
        <fpage>331</fpage>
        <lpage>342</lpage>
        <pub-id pub-id-type="doi">10.1002/(SICI)1097-0134(20000601)39:4&lt;331::AID-PROT60&gt;3.0.CO;2-A</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Young</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Jernigan</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Covell</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>A role for surface hydrophobicity in protein-protein recognition</article-title>
        <source>Protein Sci.</source>
        <year>1994</year>
        <volume>3</volume>
        <fpage>717</fpage>
        <lpage>729</lpage>
        <pub-id pub-id-type="doi">10.1002/pro.5560030501</pub-id>
        <?supplied-pmid 8061602?>
        <pub-id pub-id-type="pmid">8061602</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Korn</surname>
            <given-names>AP</given-names>
          </name>
          <name>
            <surname>Burnett</surname>
            <given-names>RM</given-names>
          </name>
        </person-group>
        <article-title>Distribution and complementarity of hydropathy in mutisunit proteins</article-title>
        <source>Proteins: Struct., Funct., Bioinforma.</source>
        <year>1991</year>
        <volume>9</volume>
        <fpage>37</fpage>
        <lpage>55</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.340090106</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Katz</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>A new status index derived from sociometric analysis</article-title>
        <source>Psychometrika</source>
        <year>1953</year>
        <volume>18</volume>
        <fpage>39</fpage>
        <lpage>43</lpage>
        <pub-id pub-id-type="doi">10.1007/BF02289026</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Lv</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>YC</given-names>
          </name>
        </person-group>
        <article-title>Predicting missing links via local information</article-title>
        <source>Eur. Phys. J. B</source>
        <year>2009</year>
        <volume>71</volume>
        <fpage>623</fpage>
        <lpage>630</lpage>
        <pub-id pub-id-type="doi">10.1140/epjb/e2009-00335-8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Barabási</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Albert</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Emergence of scaling in random networks</article-title>
        <source>Science</source>
        <year>1999</year>
        <volume>286</volume>
        <fpage>509</fpage>
        <lpage>512</lpage>
        <pub-id pub-id-type="doi">10.1126/science.286.5439.509</pub-id>
        <?supplied-pmid 10521342?>
        <pub-id pub-id-type="pmid">10521342</pub-id>
      </element-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <mixed-citation publication-type="other">Jeh, G. &amp; Widom, J. <italic>Proc. 8th International Conference on Knowledge Discovery and Data Mining (ACM,</italic> 2002).</mixed-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <mixed-citation publication-type="other">De Meo. P., Ferrara E., Fiumara G. &amp; Provetti A. Generalized louvain method for community detection in large networks. In <italic>11th International Conference on Intelligent Systems Design and Applications (ISDA)</italic><italic>.</italic>10.1109/ISDA.2011.6121636 (2011).</mixed-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Krissinel</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Henrick</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Inference of macromolecular assemblies from crystalline state</article-title>
        <source>J. Mol. Biol.</source>
        <year>2007</year>
        <volume>372</volume>
        <fpage>774</fpage>
        <lpage>797</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmb.2007.05.022</pub-id>
        <?supplied-pmid 17681537?>
        <pub-id pub-id-type="pmid">17681537</pub-id>
      </element-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Porter</surname>
            <given-names>CT</given-names>
          </name>
          <name>
            <surname>Bartlett</surname>
            <given-names>GJ</given-names>
          </name>
          <name>
            <surname>Thornton</surname>
            <given-names>JM</given-names>
          </name>
        </person-group>
        <article-title>The Catalytic Site Atlas: a resource of catalytic sites and residues identified in enzymes using structural data</article-title>
        <source>Nucleic acids Res.</source>
        <year>2004</year>
        <volume>32</volume>
        <fpage>D129</fpage>
        <lpage>D133</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkh028</pub-id>
        <?supplied-pmid 14681376?>
        <pub-id pub-id-type="pmid">14681376</pub-id>
      </element-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <mixed-citation publication-type="other">Selvaraju, R. R. et al. Grad-cam: Visual explanations from deep networks via gradient-based localization. In <italic>Proceedings of the 2017 IEEE International Conference on Computer Vision (ICCV)</italic><italic>.</italic>10.1007/s11263-019-01228-7 (2017).</mixed-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <mixed-citation publication-type="other">Li, J. et al. Semi-supervised graph classification: a hierarchical graph perspective. In <italic>2019 The World Wide Web Conference (WWW).</italic>10.48550/arXiv.1904.05003 (2019).</mixed-citation>
    </ref>
    <ref id="CR59">
      <label>59.</label>
      <mixed-citation publication-type="other">Boutet, E., Lieberherr, D., Tognolli, M., Schneider, M. &amp; Bairoch, A. <italic>UniProtKB/Swiss-Prot</italic> 89–112 (Humana Press, 2007).</mixed-citation>
    </ref>
    <ref id="CR60">
      <label>60.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Berman</surname>
            <given-names>HM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The protein data bank</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2000</year>
        <volume>28</volume>
        <fpage>235</fpage>
        <lpage>242</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/28.1.235</pub-id>
        <?supplied-pmid 10592235?>
        <pub-id pub-id-type="pmid">10592235</pub-id>
      </element-citation>
    </ref>
    <ref id="CR61">
      <label>61.</label>
      <mixed-citation publication-type="other">Landrum, G., Tosco, P. &amp; Kelley, B. <italic>rdkit/rdkit: 2021_09_4 (Q3 2021) 351 Release.</italic><ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/5835217#.Y_JocB9Bzcs">https://zenodo.org/record/5835217#.Y_JocB9Bzcs</ext-link> (2022).</mixed-citation>
    </ref>
    <ref id="CR62">
      <label>62.</label>
      <mixed-citation publication-type="other">Ying, Z., Bourgeois, D., You, J., Zitnik, M. &amp; Leskovec, J. Gnnexplainer: Generating explanations for graph neural networks. In <italic>33rd Advances in Neural Information Processing Systems (NeurIPS)</italic><italic>.</italic>10.48550/arXiv.1903.03894 (2019).</mixed-citation>
    </ref>
  </ref-list>
</back>
