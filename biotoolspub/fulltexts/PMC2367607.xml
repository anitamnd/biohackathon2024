<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Proc</journal-id>
    <journal-title>BMC Proceedings</journal-title>
    <issn pub-type="epub">1753-6561</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">2367607</article-id>
    <article-id pub-id-type="publisher-id">1753-6561-1-S1-S60</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Proceedings</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Detecting disease-causing genes by LASSO-Patternsearch algorithm</article-title>
    </title-group>
    <contrib-group>
      <contrib id="A1" corresp="yes" contrib-type="author">
        <name>
          <surname>Shi</surname>
          <given-names>Weiliang</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <email>shiw@stat.wisc.edu</email>
      </contrib>
      <contrib id="A2" contrib-type="author">
        <name>
          <surname>Lee</surname>
          <given-names>Kristine E</given-names>
        </name>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>klee@epi.ophth.wisc.edu</email>
      </contrib>
      <contrib id="A3" contrib-type="author">
        <name>
          <surname>Wahba</surname>
          <given-names>Grace</given-names>
        </name>
        <xref ref-type="aff" rid="I3">3</xref>
        <email>wahba@stat.wisc.edu</email>
      </contrib>
    </contrib-group>
    <aff id="I1"><label>1</label>Department of Statistics, University of Wisconsin Madison, 1300 University Avenue, Madison, Wisconsin 53706, USA</aff>
    <aff id="I2"><label>2</label>Department of Ophthalmology &amp; Visual Sciences, University of Wisconsin Madison, 610 North Walnut, 4th Floor WARF, Madison, Wisconsin 53726, USA</aff>
    <aff id="I3"><label>3</label>Departments of Statistics, Biostatistics and Medical Informatics and Computer Sciences, University of Wisconsin Madison, 1300 University Avenue, Madison, Wisconsin 53706, USA</aff>
    <pub-date pub-type="collection">
      <year>2007</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>12</month>
      <year>2007</year>
    </pub-date>
    <volume>1</volume>
    <issue>Suppl 1</issue>
    <supplement>
      <named-content content-type="supplement-title">Genetic Analysis Workshop 15: Gene Expression Analysis and Approaches to Detecting Multiple Functional Loci</named-content>
      <named-content content-type="supplement-editor">Heather J Cordell, Mariza de Andrade, Marie-Claude Babron, Christopher W Bartlett, Joseph Beyene, Heike Bickeböller, Robert Culverhouse, Adrienne Cupples, E Warwick Daw, Josée Dupuis, Catherine T Falk, Saurabh Ghosh, Katrina A Goddard, Ellen L Goode, Elizabeth R Hauser, Lisa J Martin, Maria Martinez, Kari E North, Nancy L Saccone, Silke Schmidt, William Tapper, Duncan Thomas, David Tritchler, Veronica J Vieland, Ellen M Wijsman, Marsha A Wilcox, John S Witte, Qiong Yang, Andreas Ziegler, Laura Almasy and Jean W MacCluer</named-content>
    </supplement>
    <fpage>S60</fpage>
    <lpage>S60</lpage>
    <ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1753-6561/1/S1/S60"/>
    <permissions>
      <copyright-statement>Copyright © 2007 Shi et al; licensee BioMed Central Ltd.</copyright-statement>
      <copyright-year>2007</copyright-year>
      <copyright-holder>Shi et al; licensee BioMed Central Ltd.</copyright-holder>
      <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0">
        <p>This is an open access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p>
        <!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>
               Shi
               Weiliang
               
               shiw@stat.wisc.edu
            </dc:author><dc:title>
            Detecting disease-causing genes by LASSO-Patternsearch algorithm
         </dc:title><dc:date>2007</dc:date><dcterms:bibliographicCitation>BMC Proceedings 1(Suppl 1): S60-. (2007)</dcterms:bibliographicCitation><dc:identifier type="sici">1753-6561(2007)1:Suppl 1&#x0003c;S60&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1753-6561</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>-->
      </license>
    </permissions>
    <abstract>
      <p>The Genetic Analysis Workshop 15 Problem 3 simulated rheumatoid arthritis data set provided 100 replicates of simulated single-nucleotide polymorphism (SNP) and covariate data sets for 1500 families with an affected sib pair and 2000 controls, modeled after real rheumatoid arthritis data. The data generation model included nine unobserved trait loci, most of which have one or more of the generated SNPs associated with them. These data sets provide an ideal experimental test bed for evaluating new and old algorithms for selecting SNPs and covariates that can separate cases from controls, because the cases and controls are known as well as the identities of the trait loci. LASSO-Patternsearch is a new multi-step algorithm with a LASSO-type penalized likelihood method at its core specifically designed to detect and model interactions between important predictor variables. In this article the original LASSO-Patternsearch algorithm is modified to handle the large number of SNPs plus covariates. We start with a screen step within the framework of parametric logistic regression. The patterns that survived the screen step were further selected by a penalized logistic regression with the LASSO penalty. And finally, a parametric logistic regression model were built on the patterns that survived the LASSO step. In our analysis of Genetic Analysis Workshop 15 Problem 3 data we have identified most of the associated SNPs and relevant covariates. Upon using the model as a classifier, very competitive error rates were obtained.</p>
    </abstract>
    <conference>
      <conf-date>11–15 November 2006</conf-date>
      <conf-name>Genetic Analysis Workshop 15</conf-name>
      <conf-loc>St. Pete Beach, Florida, USA</conf-loc>
    </conference>
  </article-meta>
</front>
<body>
  <sec>
    <title>Background</title>
    <p>Rheumatoid arthritis (RA) is a complex disease with a moderately strong genetic component. Generally, females are at a higher risk than males and the mean onset of disease is in the fifth decade. Many studies have implicated the HLA region on 6p21 with consistent evidence for several of the DR alleles contributing to risk. There remains much to learn about the genetic susceptibility for rheumatoid arthritis and possible gene and environmental interactions.</p>
    <p>Identification of disease-causing genes requires extensive evaluation of multiple potential genetic sites. The current trends in genetic epidemiology are to evaluate thousands of single-nucleotide polymorphisms (SNPs) along the chromosome to identify regions where the true disease-causing gene may lie. Tree-structured methods such as CART (classification and regression trees) [<xref ref-type="bibr" rid="B1">1</xref>] and Logic regression [<xref ref-type="bibr" rid="B2">2</xref>] usually select variables sequentially, and hence may miss the overall correlation structure of the variables. Random forest [<xref ref-type="bibr" rid="B3">3</xref>], which grows a large number of classification or regression trees with no trimming or pruning, has gained popularity in the analysis of genetic data. More recently a forward-stepwise penalized logistic regression [<xref ref-type="bibr" rid="B4">4</xref>] has been developed for screening gene-gene interactions, which is also a sequential method. We will be using the penalized likelihood method with the LASSO penalty to select SNPs, gene × gene interactions, and gene × environmental interactions. For Gaussian data the LASSO [<xref ref-type="bibr" rid="B5">5</xref>] was proposed as a variant of linear least-squares ridge regression. It was demonstrated that this approach tended to set many of the coefficients to zero, resulting in a sparse model, a property not generally obtained with quadratic penalties. LASSO-Patternsearch algorithm [<xref ref-type="bibr" rid="B6">6</xref>] was proposed to search patterns of multiple risk factors in large demographic studies. The core of the method is global, in that it deals with a very large number of patterns simultaneously, as opposed to sequential methods that constitute much of the literature in this area. In this paper, we applied the modified LASSO-Patternsearch algorithm on the simulated RA data from Genetic Analysis Workshop 15 (GAW15). The method has been modified in three places. First, we introduce a screen step to eliminate most of the noise SNPs and their interactions before applying the LASSO step. Second, we only consider the main effects and second-order interactions for computation and interpretation. And last, we take advantage of the fact that we can extract separate training, tuning, and test data sets, all generated from the same (simulated) population. Therefore, we choose the tuning parameters by prediction accuracy on the tuning set, and, for quantitative comparison with other methods, estimate the prediction accuracy of the resulting model on the test set.</p>
  </sec>
  <sec sec-type="methods">
    <title>Methods</title>
    <sec>
      <title>Data set</title>
      <p>We have chosen to use the simulated data (Problem 3) from GAW15. This data simulation was set up to mimic the familial pattern of RA, including a strong effect of DR type at the HLA 2 locus on chromosome 6. A large population of nuclear families (two parents and two offspring) was generated. This population contains close to 2 million sibling pairs (3.6 million subjects). RA affection status was determined for everyone from a complex genetic and environmental model. There were four loci (A on chromosome 16, B on chromosome 8, and C and D both on chromosome 6) in addition to a strong effect of the DR alleles that directly, or through interactions with smoking and gender, modeled RA status. Additional loci modeled severity and other related RA outcomes. From this population, a random sample of 1500 families was selected from among families with two affected offspring (the affected sib-pair (ASP) group) and another random sample of 2000 families was selected from among families where no member was affected (control group). Within the 2000 families selected for the control group, one offspring was randomly selected to be in the final control group.</p>
      <p>Microsatellites and SNPs were generated on 22 autosomes. These markers were designed to be like real human autosomes in terms of genetic and physical map lengths. The marker and trait loci were generated to have similar properties, such as linkage disequilibrium, to those observed in real data. We chose to analyze the SNPs, for all controls and the first sibling in the ASP group in Replicate 1. In addition, we used similar data from Replicates 2 and 3 as tuning and test data sets.</p>
    </sec>
    <sec>
      <title>LASSO-Patternsearch algorithm</title>
      <p>The LASSO-Patternsearch algorithm [<xref ref-type="bibr" rid="B6">6</xref>] is an approach to identify patterns of risk factors that is built on a global core. We modify the original algorithm for use with genetic (SNP) data (add a screen step, consider only main effects and second-order interactions, and tune the smoothing parameters with a tuning set). Through the use of a series of basis functions described below, we can build a model for the relation between phenotype and variables that embodies main effects and two-factor interactions ("patterns"). The basis functions we use assume dichotomous risk factors. Responses are coded 1 for cases and 0 for controls; females are coded 1 and males 0; smokers as 1 and non-smokers as 0. Age is the only continuous risk factor and we code an elder group (≥ 55) as 1 and a younger group (&lt;55) as 0. Because nearly all SNPs have three levels: normal, one variant allele, and two variant alleles, we retain this information by initially coding them as 0, 1, and 2, respectively. HLA DR also has three levels and we initially code them as DRX = 0, DR1 = 1, and DR4 = 2. For these three level variables, we define basis functions in a generalized way described below, which is equivalent to introducing two dummy variables.</p>
      <p>The modified algorithm has three steps:</p>
      <p>• Step 0: The Screen step</p>
      <p>We first define our coding basis functions to be used: let <italic>x</italic><sub><italic>j </italic></sub>be the <italic>j</italic><sup>th </sup>variable and <italic>x </italic>be (<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>,..., <italic>x</italic><sub><italic>N</italic></sub>) where <italic>N </italic>is the number of variables. Let <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M1" name="1753-6561-1-S1-S60-i1" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mi>j</mml:mi><mml:mn>1</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math></inline-formula> if <italic>x</italic><sub><italic>j </italic></sub>= 1, and 0 otherwise, and let <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M2" name="1753-6561-1-S1-S60-i2" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math></inline-formula> if <italic>x</italic><sub><italic>j </italic></sub>= 2, and 0 otherwise. We call these "main effects" basis functions. Let <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M3" name="1753-6561-1-S1-S60-i3" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math></inline-formula> if <italic>x</italic><sub><italic>j </italic></sub>= <italic>r</italic>, <italic>x</italic><sub><italic>k </italic></sub>= <italic>s</italic>, <italic>r</italic>, <italic>s </italic>= 1, 2, and 0 otherwise (so there are four basis functions for each pair (<italic>j</italic>, <italic>k</italic>)). We call these "two-factor interaction" basis functions. These basis functions will be used to code the variables into logistic or penalized logistic regression models. Let <italic>p</italic>(<italic>x</italic>) be the probability that <italic>y </italic>= 1, given <italic>x</italic>, and let <italic>f</italic>(<italic>x</italic>) = log[<italic>p</italic>(<italic>x</italic>)/(1 - <italic>p</italic>(<italic>x</italic>))]. The negative log likelihood function is given by:</p>
      <p>
        <disp-formula id="bmcM1">
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M4" name="1753-6561-1-S1-S60-i4" overflow="scroll">
            <mml:semantics>
              <mml:mrow>
                <mml:mi>L</mml:mi>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:mi>y</mml:mi>
                <mml:mo>,</mml:mo>
                <mml:mi>f</mml:mi>
                <mml:mo stretchy="false">)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mstyle displaystyle="true">
                  <mml:munderover>
                    <mml:mo>∑</mml:mo>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mo>=</mml:mo>
                      <mml:mn>1</mml:mn>
                    </mml:mrow>
                    <mml:mi>n</mml:mi>
                  </mml:munderover>
                  <mml:mrow>
                    <mml:mo stretchy="false">[</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:msub>
                      <mml:mi>y</mml:mi>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mi>f</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>i</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>+</mml:mo>
                    <mml:mi>log</mml:mi>
                    <mml:mo>⁡</mml:mo>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mn>1</mml:mn>
                    <mml:mo>+</mml:mo>
                    <mml:msup>
                      <mml:mi>e</mml:mi>
                      <mml:mrow>
                        <mml:mi>f</mml:mi>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:mi>x</mml:mi>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:mi>i</mml:mi>
                        <mml:mo stretchy="false">)</mml:mo>
                        <mml:mo stretchy="false">)</mml:mo>
                      </mml:mrow>
                    </mml:msup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">]</mml:mo>
                  </mml:mrow>
                </mml:mstyle>
                <mml:mo>.</mml:mo>
              </mml:mrow>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>We will code the dependence on <italic>x </italic>by <italic>f</italic>(<italic>x</italic>) = <italic>μ </italic>+ ∑<italic>c</italic><sub>ℓ</sub><italic>B</italic><sub>ℓ</sub>(<italic>x</italic>), where the <italic>B</italic><sub>ℓ </sub>will be specified subsets of the basis functions defined above, and <italic>μ </italic>and {<italic>c</italic><sub>ℓ</sub>} are estimated by minimizing <italic>L</italic>(<italic>y</italic>, <italic>f</italic>). The goal is to select those basis functions that encode the variables or pairs of variables that best separate cases from controls.</p>
      <p>Because there are more than 9000 SNPs on all 22 chromosomes, incorporating 9000 main effects and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M5" name="1753-6561-1-S1-S60-i5" overflow="scroll"><mml:semantics><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>9000</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:semantics></mml:math></inline-formula> two-factor interactions, there will be more than 10<sup>8 </sup>basis functions and we cannot deal with them all simultaneously. We first prescreen for main effects with a logistic regression model as follows. For each <italic>j </italic>= 1,..., <italic>N</italic>, we find <italic>μ</italic>, <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M6" name="1753-6561-1-S1-S60-i6" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mi>j</mml:mi><mml:mn>1</mml:mn></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M7" name="1753-6561-1-S1-S60-i7" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> to minimize the negative log likelihood <italic>L</italic>(<italic>y</italic>, <italic>f</italic><sub><italic>j</italic></sub>), where <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M8" name="1753-6561-1-S1-S60-i8" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mi>j</mml:mi><mml:mi>r</mml:mi></mml:msubsup><mml:msubsup><mml:mi>B</mml:mi><mml:mi>j</mml:mi><mml:mi>r</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:semantics></mml:math></inline-formula>. We test the hypothesis at the 0.05 level that <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M9" name="1753-6561-1-S1-S60-i9" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mi>j</mml:mi><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> is different from 0 and if it is, the <italic>j</italic><sup>th </sup>variable will go to the second part of the prescreen step and the basis function <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M10" name="1753-6561-1-S1-S60-i10" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mi>j</mml:mi><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula>(<italic>x</italic>) will go to Step 1. Note that each SNP may contribute two basis functions and they are not necessarily significant simultaneously. In that case, the significant basis function will go to the LASSO step and the SNP is still eligible for the screening of interactions. For each pair of variables (<italic>x</italic><sub><italic>j</italic></sub>, <italic>x</italic><sub><italic>k</italic></sub>), we construct the model <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M11" name="1753-6561-1-S1-S60-i11" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mi>j</mml:mi><mml:mi>r</mml:mi></mml:msubsup><mml:msubsup><mml:mi>B</mml:mi><mml:mi>j</mml:mi><mml:mi>r</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mi>j</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:msubsup><mml:mi>B</mml:mi><mml:mi>k</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:semantics></mml:math></inline-formula> and minimize <italic>L</italic>(<italic>y</italic>, <italic>f</italic><sub><italic>jk</italic></sub>). We test the hypotheses that the coefficients <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M12" name="1753-6561-1-S1-S60-i12" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msubsup><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:semantics></mml:math></inline-formula> are different from 0 at the 0.002 level and the basis functions (patterns) that survive go to Step 1. At this point we would like to select the largest number of candidates that can be comfortably handled by the core global LASSO step. The significance level of 0.002 was chosen in an <italic>ad hoc </italic>manner to select candidates for the next step and resulted in a large set that, very roughly, met this goal.</p>
      <p>• Step 1: The LASSO step</p>
      <p>In this step, we use the LASSO penalty (<italic>l</italic><sub>1</sub>) to do variable selection. We relabel the basis functions that survive Step 0 as <italic>B</italic><sub><italic>l</italic></sub>, <italic>l </italic>= 1, 2..., <italic>N</italic><sub><italic>B</italic></sub>, where <italic>N</italic><sub><italic>B </italic></sub>is the total number of the basis functions. We estimate <italic>f </italic>by minimizing</p>
      <p>
        <disp-formula id="bmcM2"><italic>I</italic><sub><italic>λ </italic></sub>(<italic>y</italic>, <italic>f</italic>) = <italic>L</italic>(<italic>y</italic>, <italic>f</italic>) + <italic>λJ</italic>(<italic>f</italic>),</disp-formula>
      </p>
      <p>where <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M13" name="1753-6561-1-S1-S60-i13" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>μ</mml:mi><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:msub><mml:mi>B</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M14" name="1753-6561-1-S1-S60-i14" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:semantics></mml:math></inline-formula>. The smoothing parameter <italic>λ </italic>balances the trade-off between data fitting and the sparsity of the model. We will choose the smoothing parameter by the prediction accuracy on a separate tuning set. This is done as follows: for each trial value of <italic>λ</italic>, the minimizer of Eq. (2) produces <italic>f</italic><sub><italic>λ </italic></sub>(<italic>x</italic>) and hence <italic>p</italic><sub><italic>λ </italic></sub>(<italic>x</italic>). We make the important observation that the ratio of cases and controls in the training set is <italic>the same </italic>as the ratio of cases and controls in the tuning set. Thus, if one had a perfect estimate of <italic>p</italic>(<italic>x</italic>) <italic>for the population that generated both the test and tuning set</italic>, and costs of misclassification were the same for both types of misclassification, then the Bayes rule (to minimize expected cost) for classifying members of the tuning set would be to classify a member as case if <italic>p</italic>(<italic>x</italic>) &gt; 0.5 and as a control if <italic>p</italic>(<italic>x</italic>) &lt; 0.5 [<xref ref-type="bibr" rid="B7">7</xref>]. Therefore we are motivated to examine the actual error rates on the tuning set, for each choice of <italic>λ</italic>, by using <italic>p</italic><sub><italic>λ</italic></sub>(<italic>x</italic>) = 0.5 as the classifier.</p>
      <p>• Step 2: The logistic regression step</p>
      <p>Step 1 produces a relatively sparse model, but we have seen a general tendency for the LASSO-Patternsearch to err on the conservative side in selecting basis functions, that is, there is a very high probability of including all relevant basis functions, at the expense of including some noise terms [<xref ref-type="bibr" rid="B6">6</xref>,<xref ref-type="bibr" rid="B8">8</xref>]. Thus, we took a closer look at the terms that passed Step 1 by putting them into a parametric logistic regression and testing the significance of each term at level <italic>α</italic>. Rather than choose <italic>α </italic>on an ad hoc basis, it is selected based on prediction accuracy on the tuning set. The significant term goes into the logistic regression model again and that gives the final model.</p>
      <p>It is believed that this multi-step process is an effective procedure to meet two goals simultaneously, sparsity and generalizability, and the results below tend to bear this out.</p>
    </sec>
  </sec>
  <sec>
    <title>Results</title>
    <p>We selected the first replicate as the training set, the second replicate as the tuning set, and the third replicate as the test set. In our first pass, we examined age, smoking, and sex as environmental factors, and all chromosome 6 SNPs. The screen step identified 145 main effects and 1439 interactions, while the final model included only 6 main effects and no interactions (Table <xref ref-type="table" rid="T1">1</xref>). We found SNP6_153–SNP6_154, which we later (after obtaining the answers) found out were close to locus C, and SNP6_162, which was close to locus D. We also found sex and smoking as expected. Applying this model to predict the RA cases in Replicate 3 as any with an estimated probability &gt;0.5 resulted in a 13.8% error rate, with sensitivity of 85.3% and specificity of 87.0%. In fact, a plot of the prediction error rate as a function of the threshold (not shown) is essentially a convex curve with a minimum of 13.8% for any <italic>p </italic>between 0.41 and 0.56, verifying the appropriateness of the use of <italic>p </italic>= 0.5 as the threshold.</p>
    <table-wrap position="float" id="T1">
      <label>Table 1</label>
      <caption>
        <p>Model on chromosome 6</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <td align="left">Variable</td>
            <td align="center">No. variant alleles at locus</td>
            <td align="center">Coefficient<sup>a</sup></td>
            <td align="center">SD</td>
            <td align="center"><italic>p</italic>-Value</td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">Smoking</td>
            <td align="center">-</td>
            <td align="center">0.8653</td>
            <td align="center">0.1088</td>
            <td align="center">10<sup>-15</sup></td>
          </tr>
          <tr>
            <td align="left">Sex</td>
            <td align="center">-</td>
            <td align="center">1.0478</td>
            <td align="center">0.1131</td>
            <td align="center">10<sup>-20</sup></td>
          </tr>
          <tr>
            <td align="left">SNP6_153</td>
            <td align="center">1</td>
            <td align="center">-2.0411</td>
            <td align="center">0.1365</td>
            <td align="center">10<sup>-50</sup></td>
          </tr>
          <tr>
            <td align="left">SNP6_154</td>
            <td align="center">1</td>
            <td align="center">-1.4509</td>
            <td align="center">0.1448</td>
            <td align="center">10<sup>-23</sup></td>
          </tr>
          <tr>
            <td align="left">SNP6_162</td>
            <td align="center">1</td>
            <td align="center">2.2297</td>
            <td align="center">0.2767</td>
            <td align="center">10<sup>-16</sup></td>
          </tr>
          <tr>
            <td align="left">SNP6_153</td>
            <td align="center">2</td>
            <td align="center">-5.5977</td>
            <td align="center">0.2707</td>
            <td align="center">10<sup>-95</sup></td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <p><sup>a</sup>Coefficients are estimated in the final parametric logistic regression model.</p>
      </table-wrap-foot>
    </table-wrap>
    <p>We then expanded our analysis to SNPs on all chromosomes and included the DR allele from each parent. That gave us 9192 variables, including 9187 SNPs, two DR alleles from parents, age, smoking, and sex. The main effect screen in Step 0 identified 880 basis functions, corresponding to 795 variables. We then screened for the interaction of these 795 variables and got 1679 interactions. Step 1 included 2559 (880 + 1679) basis functions. The final model identified eight main effects and three interactions (listed in Table <xref ref-type="table" rid="T2">2</xref> and <xref ref-type="table" rid="T3">3</xref>). The main effects include DR allele from the parents, gender, and smoking, as well as the SNPs from chromosome 6 and an additional SNP on chromosomes 11. All of these were modeled in the simulation: SNP6_154 is close to locus C, SNP6_162 is close to locus D, and SNP11_389 is close to locus F (which modeled severity of IgM). We have also identified three interaction terms, including one within-chromosome interaction on chromosome 2 and two between-chromosome interactions. These interactions were not directly modeled in the simulation. The prediction error of this model on Replicate 3 is 12.6%, with sensitivity of 85.5% and specificity of 88.8%. A plot of the prediction error as a function of the threshold is a convex curve with the minimum error rate of 12.6% for any <italic>p </italic>between 0.49 and 0.51.</p>
    <table-wrap position="float" id="T2">
      <label>Table 2</label>
      <caption>
        <p>Main effects model on all chromosomes</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <td align="left">Variable</td>
            <td align="center">Level</td>
            <td align="center">Coefficient</td>
            <td align="center">SD</td>
            <td align="center"><italic>p</italic>-Value</td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">Smoking</td>
            <td align="center">-</td>
            <td align="center">1.0434</td>
            <td align="center">0.1214</td>
            <td align="center">10<sup>-18</sup></td>
          </tr>
          <tr>
            <td align="left">Sex</td>
            <td align="center">-</td>
            <td align="center">1.0819</td>
            <td align="center">0.1251</td>
            <td align="center">10<sup>-18</sup></td>
          </tr>
          <tr>
            <td align="left">SNP6_154</td>
            <td align="center">1</td>
            <td align="center">-1.6228</td>
            <td align="center">0.1395</td>
            <td align="center">10<sup>-31</sup></td>
          </tr>
          <tr>
            <td align="left">SNP6_162</td>
            <td align="center">1</td>
            <td align="center">2.2717</td>
            <td align="center">0.2885</td>
            <td align="center">10<sup>-15</sup></td>
          </tr>
          <tr>
            <td align="left">HLA DR type, father</td>
            <td align="center">2</td>
            <td align="center">2.3848</td>
            <td align="center">0.1405</td>
            <td align="center">10<sup>-64</sup></td>
          </tr>
          <tr>
            <td align="left">HLA DR type, mother</td>
            <td align="center">2</td>
            <td align="center">2.3443</td>
            <td align="center">0.1388</td>
            <td align="center">10<sup>-64</sup></td>
          </tr>
          <tr>
            <td align="left">SNP6_154</td>
            <td align="center">2</td>
            <td align="center">-3.0081</td>
            <td align="center">0.5492</td>
            <td align="center">10<sup>-8</sup></td>
          </tr>
          <tr>
            <td align="left">SNP11_389</td>
            <td align="center">2</td>
            <td align="center">0.9521</td>
            <td align="center">0.1264</td>
            <td align="center">10<sup>-14</sup></td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <p><sup>a</sup>For SNPs, level is the number of variant alleles.  For DR type, level = 1 means DR1 and level = 2 means DR4.</p>
      </table-wrap-foot>
    </table-wrap>
    <table-wrap position="float" id="T3">
      <label>Table 3</label>
      <caption>
        <p>Interactions on all chromosomes</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <td align="left">Variable 1</td>
            <td align="center">No. variant alleles of Variable 1</td>
            <td align="center">Variable 2</td>
            <td align="center">No. variant alleles of Variable 2</td>
            <td align="center">Coefficient</td>
            <td align="center">SD</td>
            <td align="center"><italic>p</italic>-Value</td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">SNP2_542</td>
            <td align="center">1</td>
            <td align="center">SNP2_768</td>
            <td align="center">1</td>
            <td align="center">-0.5061</td>
            <td align="center">0.1389</td>
            <td align="center">0.0003</td>
          </tr>
          <tr>
            <td align="left">SNP1_673</td>
            <td align="center">1</td>
            <td align="center">SNP15_77</td>
            <td align="center">1</td>
            <td align="center">-0.8369</td>
            <td align="center">0.1693</td>
            <td align="center">10<sup>-7</sup></td>
          </tr>
          <tr>
            <td align="left">SNP8_233</td>
            <td align="center">1</td>
            <td align="center">SNP16_131</td>
            <td align="center">2</td>
            <td align="center">-0.8044</td>
            <td align="center">0.1633</td>
            <td align="center">10<sup>-7</sup></td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>Our method successfully selected many trait loci, but it also missed some. Locus B is on chromosome 8 and it increases the RA risk for smokers. We did not find this because locus B is at the end of the chromosome and none of the SNPs are close by. We also missed locus A, which affects the impact of HLA DR types. Another interaction we missed is sex and locus C. We tabulate the raw data in Table <xref ref-type="table" rid="T4">4</xref>. According to the solution and the relationship between locus C and SNP6_154, we should see no difference between males and females when SNP6_154 = 2. Females will be at higher risk than males when SNP6_154 = 1 and the difference is even bigger when SNP6_154 = 0. However, there are very few cases when SNP6_154 = 2. We cannot really tell whether there is a difference at this level. Plus, locus C has a strong correlation with the DR allele. Therefore, we ended up with the main effects of sex and SNP6_154 rather than their interaction.</p>
    <table-wrap position="float" id="T4">
      <label>Table 4</label>
      <caption>
        <p>The raw data of sex and SNP6 15. The denominator is the total number of people and the numerator is the total number of RA patients.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <td align="left">SNP6154</td>
            <td align="center">Male</td>
            <td align="center">Female</td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">0</td>
            <td align="center">341/551 = 0.619</td>
            <td align="center">1015/1241 = 0.818</td>
          </tr>
          <tr>
            <td align="left">1</td>
            <td align="center">43/520 = 0.083</td>
            <td align="center">97/628 = 0.154</td>
          </tr>
          <tr>
            <td align="left">2</td>
            <td align="center">1/270 = 0.004</td>
            <td align="center">3/290 = 0.010</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </sec>
  <sec>
    <title>Discussion</title>
    <p>The LASSO-Patternsearch algorithm [<xref ref-type="bibr" rid="B6">6</xref>] was originally designed for demographic studies in which the data sets are smaller with fewer variables. It is a two-stage method whose core is global, as opposed to sequential methods, like trees and forward-stepwise penalized logistic regression [<xref ref-type="bibr" rid="B4">4</xref>]. We added a screen step to the front end here to handle the extremely large number of potential SNP patterns. We roughly maximized the number of patterns surviving this step within the limits of the core LASSO step, which can handle 4000 basis functions. We believe that this conservative screen step is unlikely to delete important patterns here. Proof would await our ability to handle larger numbers of basis functions but the results in selecting relevant SNP patterns here certainly support that belief. The LASSO step took in the resulting large number of basis functions and returned a small fraction of them, retaining the flavor of a completely global algorithm, with the final tuning step removing less significant patterns, chosen as to maximize classification accuracy on the tuning set. The LASSO-Patternsearch method is complementary to random forest approaches. The random forest method is global, but operates quite differently. Thus, LASSO-Patternsearch provides a complimentary tool for the data analyst dealing with very large attribute vectors. LASSO-Patternsearch is also very efficient. Run time for the LASSO step with 2559 basis functions was 30 minutes on our system (3.4 GHz CPU, 3.7 GB memory). Speed and capacity of the algorithm compare well with other methods discussed. Our method was able to identify important SNPs and covariates, and separate cases from controls similar to the best results presented at the meeting. We believe that it provides a useful new tool for the analysis of genetic data.</p>
  </sec>
  <sec>
    <title>Competing interests</title>
    <p>The author(s) declare that they have no competing interests.</p>
  </sec>
</body>
<back>
  <ack>
    <sec>
      <title>Acknowledgements</title>
      <p>Research supported in part by grants DMS-0505636, DMS-0604572, N00014-06-1-0095, EY09964, EY06594, and EY13438.</p>
      <p>This article has been published as part of <italic>BMC Proceedings </italic>Volume 1 Supplement 1, 2007: Genetic Analysis Workshop 15: Gene Expression Analysis and Approaches to Detecting Multiple Functional Loci. The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1753-6561/1?issue=S1"/>.</p>
    </sec>
  </ack>
  <ref-list>
    <ref id="B1">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Breiman</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Friedman</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Olshen</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Stone</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <source>Classification and Regression Trees</source>
        <year>1984</year>
        <publisher-name>New York: Chapman &amp; Hall</publisher-name>
      </citation>
    </ref>
    <ref id="B2">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ruczinski</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Kooperberg</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Leblanc</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Logic regression</article-title>
        <source>J Comput Graph Stat</source>
        <year>2003</year>
        <volume>12</volume>
        <fpage>475</fpage>
        <lpage>511</lpage>
        <pub-id pub-id-type="doi">10.1198/1061860032238</pub-id>
      </citation>
    </ref>
    <ref id="B3">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Breiman</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Random forests</article-title>
        <source>Mach Learn</source>
        <year>2001</year>
        <volume>45</volume>
        <fpage>5</fpage>
        <lpage>32</lpage>
        <pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id>
      </citation>
    </ref>
    <ref id="B4">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Park</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hastie</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <source>Penalized Logistic Regression for Detecting Gene Interactions Tech Rep 00-25</source>
        <year>2006</year>
        <publisher-name>Palo Alto: Department of Statistics, Stanford University</publisher-name>
      </citation>
    </ref>
    <ref id="B5">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Regression shrinkage and selection via the lasso</article-title>
        <source>J Roy Stat Soc B</source>
        <year>1996</year>
        <volume>58</volume>
        <fpage>267</fpage>
        <lpage>288</lpage>
      </citation>
    </ref>
    <ref id="B6">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Shi</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Wahba</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Wright</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Klein</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Klein</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <source>LASSO-Patternsearch Algorithm with Application to Ophthalmology Data Tech Rep 1131</source>
        <year>2006</year>
        <publisher-name>Madison: Department of Statistics, University of Wisconsin, Madison</publisher-name>
      </citation>
    </ref>
    <ref id="B7">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Wahba</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Denison D, Hansen M, Holmes C, Mallick B, Yu B</surname>
          </name>
        </person-group>
        <article-title>Optimal properties and adaptive tuning of standard and nonstandard support vector machines</article-title>
        <source>Nonlinear Estimation and Classification</source>
        <year>2002</year>
        <publisher-name>New York: Springer</publisher-name>
        <fpage>125</fpage>
        <lpage>143</lpage>
      </citation>
    </ref>
    <ref id="B8">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Leng</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wahba</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>A note on the LASSO and related procedures in model selection</article-title>
        <source>Stat Sinica</source>
        <year>2006</year>
        <volume>16</volume>
        <fpage>1273</fpage>
        <lpage>1284</lpage>
      </citation>
    </ref>
  </ref-list>
</back>
