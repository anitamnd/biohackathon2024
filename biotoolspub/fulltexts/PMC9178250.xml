<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Oncol</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Oncol</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Oncol.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Oncology</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2234-943X</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9178250</article-id>
    <article-id pub-id-type="doi">10.3389/fonc.2022.899825</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Oncology</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Inferring Gene Regulatory Networks From Single-Cell Transcriptomic Data Using Bidirectional RNN</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Gan</surname>
          <given-names>Yanglan</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/788599"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hu</surname>
          <given-names>Xin</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1725099"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zou</surname>
          <given-names>Guobing</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1109829"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yan</surname>
          <given-names>Cairong</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Xu</surname>
          <given-names>Guangwei</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="fn001" ref-type="author-notes">
          <sup>*</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>School of Computer Science and Technology, Donghua University</institution>, <addr-line>Shanghai</addr-line>, <country>China</country></aff>
    <aff id="aff2"><sup>2</sup><institution>School of Computer Engineering and Science, Shanghai University</institution>, <addr-line>Shanghai</addr-line>, <country>China</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Liang Cheng, Harbin Medical University, China</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Jianxing Zheng, Shanxi University, China; Yuzhong Peng, Nanning Normal University, China</p>
      </fn>
      <corresp id="fn001">*Correspondence: Guangwei Xu, <email xlink:href="mailto:gwxu@dhu.edu.cn">gwxu@dhu.edu.cn</email>
</corresp>
      <fn fn-type="other" id="fn002">
        <p>This article was submitted to Cancer Genetics, a section of the journal Frontiers in Oncology</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>26</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>12</volume>
    <elocation-id>899825</elocation-id>
    <history>
      <date date-type="received">
        <day>19</day>
        <month>3</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>22</day>
        <month>4</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2022 Gan, Hu, Zou, Yan and Xu</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Gan, Hu, Zou, Yan and Xu</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Accurate inference of gene regulatory rules is critical to understanding cellular processes. Existing computational methods usually decompose the inference of gene regulatory networks (GRNs) into multiple subproblems, rather than detecting potential causal relationships simultaneously, which limits the application to data with a small number of genes. Here, we propose BiRGRN, a novel computational algorithm for inferring GRNs from time-series single-cell RNA-seq (scRNA-seq) data. BiRGRN utilizes a bidirectional recurrent neural network to infer GRNs. The recurrent neural network is a complex deep neural network that can capture complex, non-linear, and dynamic relationships among variables. It maps neurons to genes, and maps the connections between neural network layers to the regulatory relationship between genes, providing an intuitive solution to model GRNs with biological closeness and mathematical flexibility. Based on the deep network, we transform the inference of GRNs into a regression problem, using the gene expression data at previous time points to predict the gene expression data at the later time point. Furthermore, we adopt two strategies to improve the accuracy and stability of the algorithm. Specifically, we utilize a bidirectional structure to integrate the forward and reverse inference results and exploit an incomplete set of prior knowledge to filter out some candidate inferences of low confidence. BiRGRN is applied to four simulated datasets and three real scRNA-seq datasets to verify the proposed method. We perform comprehensive comparisons between our proposed method with other state-of-the-art techniques. These experimental results indicate that BiRGRN is capable of inferring GRN simultaneously from time-series scRNA-seq data. Our method BiRGRN is implemented in Python using the TensorFlow machine-learning library, and it is freely available at <uri xlink:href="https://gitee.com/DHUDBLab/bi-rgrn">https://gitee.com/DHUDBLab/bi-rgrn</uri>.</p>
    </abstract>
    <kwd-group>
      <kwd>gene regulatory network</kwd>
      <kwd>recurrent neural network</kwd>
      <kwd>gene expression</kwd>
      <kwd>single-cell transcriptomic data</kwd>
      <kwd>bidirectional structure</kwd>
    </kwd-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="4"/>
      <equation-count count="12"/>
      <ref-count count="36"/>
      <page-count count="10"/>
      <word-count count="5041"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>1 Introduction</title>
    <p>Gene regulatory mechanisms are crucial to understanding diverse dynamic processes such as development, stress response and disease (<xref rid="B1" ref-type="bibr">1</xref>). Cell states and the dynamics of cell behavior are governed by complex gene interactions (<xref rid="B2" ref-type="bibr">2</xref>), which in turn define cellular morphology and functions. Such regulatory interactions can be modeled as a gene regulatory network (GRN), where nodes are regulators and their target genes, and edges represent the regulatory relationships between genes (<xref rid="B3" ref-type="bibr">3</xref>). Unraveling GRNs is one of the major challenges in the field of computational biology, which allows us to pinpoint key factors that determine phenotype in health systems as well as in diseases (<xref rid="B4" ref-type="bibr">4</xref>, <xref rid="B5" ref-type="bibr">5</xref>).</p>
    <p>A plethora of computational or statistical approaches have been developed for inferring networks from observational gene expression data (<xref rid="B6" ref-type="bibr">6</xref>–<xref rid="B8" ref-type="bibr">8</xref>). The widely used algorithm GENIE3 decomposes the inference of gene regulatory networks into different regression subproblems. Using tree-based ensemble methods, the expression pattern of each target gene is predicted by the expression of all the other genes (<xref rid="B9" ref-type="bibr">9</xref>). ENNET also considers the inference problem as a regression task, which is solved by a decision tree optimizing the least-squares loss function (<xref rid="B10" ref-type="bibr">10</xref>). It builds the model additively using a boosting procedure. PPCOR reconstructs gene regulatory network by calculating partial correlation coefficient and semi-partial correlation coefficient between genes (<xref rid="B11" ref-type="bibr">11</xref>). PIDC exploits information theory to infer the regulatory relationship between genes (<xref rid="B12" ref-type="bibr">12</xref>). Biologically, it is assumed that changes in regulators should precede changes in their targets in time. However, such time information is not available in steady-state gene expression data, and thus GRNs constructed from these data have limited ability to capture dynamic regulatory relationships between genes. Several methods have been proposed to infer GRNs based on time-series gene expression data to address this issue. The algorithm LEAP reconstructs gene regulatory networks by calculating the Pearson correlation coefficient. With pseudo-time data information, the algorithm defines a fixed-size time window and assumes that the earlier expressed gene in this window can affect other genes (<xref rid="B13" ref-type="bibr">13</xref>). SCODE infers regulatory networks based on ordinary differential equations and linear regression (<xref rid="B14" ref-type="bibr">14</xref>). The method SINCERITIES adopts the Kolmogorov–Smirnov distance to quantify the distance between two cumulative distribution functions of gene expressions from subsequent time points, and recovers directed regulatory relationships among genes by employing regularized linear regression (<xref rid="B15" ref-type="bibr">15</xref>). BiXGBoost infers the regulatory network through both forward and reverse directions, separately considering the regulatory genes and target genes of specific genes, and uses the gradient boosting decision tree to integrate the final regulatory relationship (<xref rid="B16" ref-type="bibr">16</xref>). The algorithm GRGNN proposes an end-to-end gene regulation graph neural network approach to reconstruct GRNs from scratch utilizing gene expression data in both a supervised and a semi-supervised framework (<xref rid="B17" ref-type="bibr">17</xref>). DeepSEM is a neural network version of the structural equation model (SEM) to explicitly model the regulatory relationships among genes (<xref rid="B18" ref-type="bibr">18</xref>). These efforts mainly focus on intracellular interactions, inferring gene regulatory relationships within a specific cell. Recently developed methods for spatial transcriptomics are now providing high-throughput information about both the expression patterns of genes within a single cell and the spatial relationships between cells (<xref rid="B19" ref-type="bibr">19</xref>–<xref rid="B21" ref-type="bibr">21</xref>). The algorithm CNNC is a supervised framework for gene relationship inference, using convolutional neural networks to analyze summarized co-occurrence histograms from pairs of genes in scRNA-seq data (<xref rid="B22" ref-type="bibr">22</xref>). GCNG transforms the problem of gene regulation network reconstruction into a classification problem. It uses a graph convolutional neural network to fit cell location information and gene expression data and infer the final result (<xref rid="B23" ref-type="bibr">23</xref>).</p>
    <p>Although much progress has been made, inferring a network of regulatory interactions between genes is still challenging. On one hand, for time-series scRNA-seq data, methods for reconstructing GRNs on bulk data are not directly applicable. As the biological meaning of a sample changes from the average for several cells in bulk data to the value for a single cell, the form of the gene expression data is also changed. Meanwhile, as the approaches devised for single-cell transcriptomics typically require a large number of time points to infer GRNs, they are usually suitable for a small number of genes. Adding a few genes to a network inference analysis may require the inference algorithm to consider many additional regulatory interactions between them. As the number of genes grows, the number of edges and the demand for input data might explode.</p>
    <p>Here, we present BiRGRN, a novel method of inferring GRNs from time-series scRNA-seq data. BiRGRN adopts a bidirectional recurrent neural network to infer GRNs. The recurrent neural network is a deep neural network that can capture complex, non-linear, and dynamic relationships among variables. It maps a neuron to a gene, and maps the connections between neural network layers to the regulatory relationship between genes, giving a good solution to model GRN with biological closeness and mathematical flexibility. Then we transform the reconstruction of GRNs into a regression problem, using the gene expression data of the previous time points to predict the gene expression data of the later time point. Meanwhile, we adopt a bidirectional structure and incorporate an incomplete set of prior knowledge to improve the accuracy and stability of the algorithm. To evaluate the performance of BiRGRN, we apply it to four simulated datasets and three real single-cell transcriptomic datasets. We performed a comparison of our results with other state-of-the-art techniques, which shows the better performance of our proposed model.</p>
  </sec>
  <sec id="s2">
    <title>2 Materials</title>
    <sec id="s2_1">
      <title>2.1 The BiRGRN Method</title>
      <p>In this work, we propose a new computational method BiRGRN to reconstruct gene regulatory networks based on bidirectional recurrent neural network and multiple prior networks. The overview of the BiRGRN is shown in <xref rid="f1" ref-type="fig"><bold>Figure 1</bold></xref>. The proposed algorithm consists of the following three main steps. Firstly, we train a deep neural network to infer preliminary gene regulatory networks, where neurons are mapped to genes, and the links between adjacent layers of the neural network are related to gene regulation relationships. Secondly, we incorporate incomplete prior knowledge to filter the candidate regulatory edges obtained in the first step. Finally, we adopt a voting strategy to integrate multiple candidate regulatory networks and utilize a bidirectional strategy to optimize the inferred GRN.</p>
      <fig position="float" id="f1">
        <label>Figure 1</label>
        <caption>
          <p>BiRGRN reconstructs GRNs from time-series single cell transcriptome data using bidirection RNN. <bold>(A)</bold> Inferring initial gene regulatory network with RNN. <bold>(B)</bold> Incorporating incomplete prior knowledge to adjust candidate regulatory edges. <bold>(C)</bold> Adopting a voting strategy to integrate multiple candidate regulatory networks, and further utilizing bidirectional model to optimize the inferred GRN.</p>
        </caption>
        <graphic xlink:href="fonc-12-899825-g001" position="float"/>
      </fig>
      <sec id="s2_1_1">
        <title>2.1.1 Step 1: Training RNN to Infer the Initial Gene Regulatory Networks</title>
        <p>Inferring gene regulatory network from single-cell transcriptomic data is actually to construct a directed graph, where the nodes represent the genes, and the edges represent the regulatory relationships among genes. If we assume that the expression pattern of gene <italic>i</italic> at time point <italic>p+1</italic> is the total regulatory effect of the expression values of all genes at the previous <italic>p</italic> time points, the regulation process can be described as the following function (<xref rid="B16" ref-type="bibr">16</xref>):</p>
        <disp-formula>
          <label>(1)</label>
          <mml:math id="M1" display="block" overflow="scroll">
            <mml:mrow>
              <mml:msubsup>
                <mml:mi>e</mml:mi>
                <mml:mrow>
                  <mml:mi>p</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
                <mml:mi>i</mml:mi>
              </mml:msubsup>
              <mml:mo>=</mml:mo>
              <mml:msup>
                <mml:mi>f</mml:mi>
                <mml:mi>i</mml:mi>
              </mml:msup>
              <mml:mrow>
                <mml:mo>(</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mi>E</mml:mi>
                    <mml:mi>p</mml:mi>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>)</mml:mo>
              </mml:mrow>
              <mml:mo>+</mml:mo>
              <mml:msub>
                <mml:mo>∈</mml:mo>
                <mml:mi>i</mml:mi>
              </mml:msub>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>where <inline-formula><mml:math id="im1" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> represents the expression value of gene <italic>i</italic> at the time point <italic>p+1</italic>, <italic>E<sub>p</sub>
</italic> represents the expression value of all genes at the previous <italic>p</italic> time points, and ∈<italic><sub>i</sub></italic> represents the influence of external noise. Specifically, <italic>p</italic> is the time lag, which represents the maximum time delay of the interaction between genes.</p>
        <p>Here, to model the regulation process of different genes in a parallel manner, we adopt RNN to formalize gene regulatory networks (<xref rid="B24" ref-type="bibr">24</xref>). A recurrent neural network is a type of artificial neural network that can capture complex, non-linear, and dynamic relationships among variables. It is mainly used for processing sequential data like time series and solving ordinal or temporal problems. As shown in the example RNN (<xref rid="f2" ref-type="fig"><bold>Figure 2</bold></xref>), each node represents a particular gene and the edges between the nodes represent the regulatory interactions among the genes. Each layer of the neural network defines the gene expression level of the genes at a specific time point. The expression level of all genes at the time point <italic>p+1</italic> depends upon the expression level of all the genes at the preceding <italic>p</italic> time points and the weights of the corresponding connecting edges with that particular gene (<xref rid="B25" ref-type="bibr">25</xref>, <xref rid="B26" ref-type="bibr">26</xref>). Then the regulation process can be formulated as:</p>
        <disp-formula>
          <label>(2)</label>
          <mml:math id="M2" display="block" overflow="scroll">
            <mml:mrow>
              <mml:msub>
                <mml:mi>E</mml:mi>
                <mml:mrow>
                  <mml:mi>p</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
              </mml:msub>
              <mml:mo>=</mml:mo>
              <mml:mi>F</mml:mi>
              <mml:mrow>
                <mml:mo>(</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mi>E</mml:mi>
                    <mml:mi>p</mml:mi>
                  </mml:msub>
                </mml:mrow>
                <mml:mo>)</mml:mo>
              </mml:mrow>
              <mml:mo>+</mml:mo>
              <mml:mo>∈</mml:mo>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <fig position="float" id="f2">
          <label>Figure 2</label>
          <caption>
            <p>The schematic structure of a RNN unfolded in time. Each node corresponds to a gene and a connection between two nodes defines their interaction.</p>
          </caption>
          <graphic xlink:href="fonc-12-899825-g002" position="float"/>
        </fig>
        <p>where <italic>E<sub>p</sub>
</italic><sub>+1</sub> represents the expression value of all genes at the time point <italic>p+1</italic>.</p>
        <p>To improve the stability of the algorithm, BiRGRN integrates multiple fully connected layers with the RNN to train gene expression data. Therefore, the proposed network structure consists of an RNN, multiple fully connected layers with ResNet residual connections (<xref rid="B27" ref-type="bibr">27</xref>), and an output layer. In detail, the proposed RNN contains <italic>p</italic> layers corresponding to <italic>p</italic> time points, with multiple inputs and one output. Subsequently, the output of the RNN is used as the input of these fully connected layers. To avoid the over-fitting problem usually caused by the deep neural network, BiRGRN adds a ResNet residual connection for every five fully connected layers. In the experiment, we set the number of the connected layers ranging from 10 to 100. We find that too few fully connected layers will lead to a significant decrease in the stability of the algorithm, whereas too many fully connected layers can not improve the accuracy but increase the running time of the algorithm. Therefore, we use 50 fully connected layers and add a ResNet structure. To train the deep neural network, we take the gene expression data of the genes at the previous <italic>p</italic> time points as input, and the gene expression data at the <italic>p+1</italic> time point as output. Then, the problem is transformed into a supervised regression problem, which overcomes the difficulty of obtaining training labels.</p>
        <p>Here, we utilize mean square loss (MSE) as the regression loss function for deep neural network training. The RNN is a fully connected structure, whereas the regulatory network is usually sparsely connected. Thus, we add L1 regularization in the objective function, aiming to control the sparsity of the resulted weight matrix <italic>w</italic>. The loss function is defined as follows:</p>
        <disp-formula>
          <label>(3)</label>
          <mml:math id="M3" display="block" overflow="scroll">
            <mml:mrow>
              <mml:mi>l</mml:mi>
              <mml:mi>o</mml:mi>
              <mml:mi>s</mml:mi>
              <mml:mi>s</mml:mi>
              <mml:mo>=</mml:mo>
              <mml:mfrac>
                <mml:mn>1</mml:mn>
                <mml:mi>T</mml:mi>
              </mml:mfrac>
              <mml:munderover>
                <mml:mo>∑</mml:mo>
                <mml:mrow>
                  <mml:mi>t</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
                <mml:mi>T</mml:mi>
              </mml:munderover>
              <mml:msup>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi>E</mml:mi>
                        <mml:mrow>
                          <mml:mi>t</mml:mi>
                          <mml:mo>,</mml:mo>
                          <mml:mi>p</mml:mi>
                          <mml:mo>+</mml:mo>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mo>−</mml:mo>
                      <mml:msubsup>
                        <mml:mi>E</mml:mi>
                        <mml:mrow>
                          <mml:mi>t</mml:mi>
                          <mml:mo>,</mml:mo>
                          <mml:mi>p</mml:mi>
                          <mml:mo>+</mml:mo>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                        <mml:mo>*</mml:mo>
                      </mml:msubsup>
                    </mml:mrow>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:mrow>
                <mml:mn>2</mml:mn>
              </mml:msup>
              <mml:mo>+</mml:mo>
              <mml:mi>α</mml:mi>
              <mml:msub>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mo>∥</mml:mo>
                    <mml:mi>ω</mml:mi>
                    <mml:mo>∥</mml:mo>
                  </mml:mrow>
                </mml:mrow>
                <mml:mn>1</mml:mn>
              </mml:msub>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>where <inline-formula><mml:math id="im2" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> and <italic>E<sub>t</sub>
</italic>,<italic><sub>p</sub></italic><sub>+1</sub> respectively represent the predicted and the real expression value of all genes at the time point <italic>t+p+1</italic>. <italic>α</italic>∥ <italic>ω</italic> ∥<sub>1</sub> is the regularized term.</p>
        <p>For the training process, when the objective function converges to the minimum, the algorithm extracts the multiple weight matrixes between the RNN layer and each fully connected layer. Then we normalize each basic weight matrix separately. According to the proposed network structure, the weight matrix corresponds to the regulatory relationships among genes, which can be used to reconstruct a candidate gene regulatory network. For each matrix, we take the top <italic>m</italic> (Usually 1.2 times the number of inferred regulation edge) connections as the candidate regulatory edges. As multiple weight matrixes are obtained after the training process, we can infer multiple candidate gene regulatory networks, which are used as the basic voters to determine the final regulatory edges in the following steps.</p>
      </sec>
      <sec id="s2_1_2">
        <title>2.1.2 Step 2: Incorporating Prior Knowledge to Adjust Candidate Regulatory Edges</title>
        <p>During the above training process, the final loss function of the model usually cannot be completely reduced to zero due to the influence of external noise. Meanwhile, in convex optimization problems, there are a large number of approximate solutions near the global optimal. In order to improve the accuracy of the GRN inference, some prior knowledge can be utilized to filter the candidate regulatory edges. The previous method, such as NetREX and MiPGRN, assumes that the prior network and the target GRN have some similarity, and then bias the optimization procedure toward networks that overlap with the prior (<xref rid="B28" ref-type="bibr">28</xref>, <xref rid="B29" ref-type="bibr">29</xref>). Here, if the initial candidate GRN defined by the basic weight matrix has more overlap with the prior network, it is considered to be closer to the final inferred GRN. Correspondingly, this candidate GRN is assigned a higher voting weight in the following ensemble process. Specifically, the weight of the candidate GRN is calculated according to the following strategy:</p>
        <disp-formula>
          <label>(4)</label>
          <mml:math id="M4" display="block" overflow="scroll">
            <mml:mrow>
              <mml:msub>
                <mml:mi>ω</mml:mi>
                <mml:mi>k</mml:mi>
              </mml:msub>
              <mml:mo>=</mml:mo>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mi>C</mml:mi>
                  <mml:mi>o</mml:mi>
                  <mml:mi>n</mml:mi>
                  <mml:mi>t</mml:mi>
                  <mml:mi>a</mml:mi>
                  <mml:mi>i</mml:mi>
                  <mml:mi>n</mml:mi>
                  <mml:mi>P</mml:mi>
                  <mml:mi>r</mml:mi>
                  <mml:msub>
                    <mml:mi>e</mml:mi>
                    <mml:mi>k</mml:mi>
                  </mml:msub>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>p</mml:mi>
                  <mml:mi>r</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:mi>N</mml:mi>
                  <mml:mi>u</mml:mi>
                  <mml:mi>m</mml:mi>
                  <mml:mi>b</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:mi>r</mml:mi>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>where <italic>ω<sub>k</sub>
</italic> represents the weight of the <italic>k<sub>th</sub>
</italic> initial GRN, <italic>ContainPre<sub>k</sub>
</italic> denotes the number of candidate edges in the <italic>k<sub>th</sub>
</italic> inferred GRN overlapping with the prior network, and <italic>preNumber</italic> represents the number of the prior edges.</p>
        <p>As the usable prior knowledge usually does not exist for given datasets, here we adopt a general strategy to obtain an incomplete prior edge set. We utilize different computational algorithms to predict the putative GRNs, apply the method NETRex to optimize the predictions, and then integrate the top 10% of the resulted edges to obtain an incomplete prior edge set (<xref rid="B29" ref-type="bibr">29</xref>). Through evaluating different methods, here we select three methods, including GRNBOOST2, PPCOR, and PIDC. These three methods respectively adopt a different strategy to predict GRNs. NetRex is an algorithm based on Network Component Analysis (NCA) to optimize the predicted GRN (<xref rid="B28" ref-type="bibr">28</xref>).</p>
      </sec>
      <sec id="s2_1_3">
        <title>2.1.3 Step 3: Utilizing a Bidirectional Model to Optimize the Inferred GRN</title>
        <p>Based on the deep neural network, we obtain <italic>K</italic> candidate GRNs, and each candidate GRN possesses an adjusted weight matrix. Next, we integrate these <italic>K</italic> different initial gene regulatory networks. The voting strategy is the addition of weights, and finally a global regulatory edge ranking is obtained according to the weights. For the regulatory edge of gene <italic>i</italic> to gene <italic>j</italic>, the weight <italic>e<sub>ij</sub>
</italic> is calculated as:</p>
        <disp-formula>
          <label>(5)</label>
          <mml:math id="M5" display="block" overflow="scroll">
            <mml:mrow>
              <mml:msub>
                <mml:mi>e</mml:mi>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mo>=</mml:mo>
              <mml:mstyle displaystyle="true">
                <mml:munderover>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>k</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mi>K</mml:mi>
                </mml:munderover>
                <mml:mrow>
                  <mml:msub>
                    <mml:mi>ω</mml:mi>
                    <mml:mi>k</mml:mi>
                  </mml:msub>
                  <mml:mo>∗</mml:mo>
                  <mml:msubsup>
                    <mml:mi>e</mml:mi>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>j</mml:mi>
                    </mml:mrow>
                    <mml:mi>k</mml:mi>
                  </mml:msubsup>
                </mml:mrow>
              </mml:mstyle>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>where <italic>ω<sub>k</sub>
</italic> represents the weight of the <italic>k<sub>th</sub>
</italic> candidate GRN, and <inline-formula><mml:math id="im3" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> represents the regulatory edge of gene <italic>i</italic> to gene <italic>j</italic> in the <italic>k<sub>th</sub>
</italic> candidate GRN.</p>
        <p>Inspired by the bidirectional model of the algorithm BiXGBoost (<xref rid="B16" ref-type="bibr">16</xref>), we further utilize the bidirectional model to fully mine the regulatory genes and target genes. Different from BiXGBoost which proposes local_in and local_out models to deal with forward and reverse inference, we use forward time-series expression data and reverse time-series expression data to respectively infer two regulatory networks. For the reverse time series data, the weight matrix obtained by the model represents the regulatory strength between gene. Next, considering the directionality of the regulatory relationship, we assume that genes expressed at earlier time points regulate genes expressed at later time points. Therefore, for the reverse inference, the input of the algorithm is the gene expression data at <italic>p</italic> time points of <italic>p+1</italic>, <italic>p</italic>, <italic>p-1</italic>,…, <italic>2</italic>, and the output is the gene expression data of the first time point. After getting the trained model, the algorithm extracts the weight matrix <italic>ω<sup>r</sup>
</italic>, and the subsequent operations are consistent with the forward model. Then the algorithm will eventually get two regulatory networks, and also use voting strategies to integrate forward and reverse results to get the final inferred regulatory network:</p>
        <disp-formula>
          <label>(6)</label>
          <mml:math id="M6" display="block" overflow="scroll">
            <mml:mrow>
              <mml:msubsup>
                <mml:mi>e</mml:mi>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:mrow>
                <mml:mo>*</mml:mo>
              </mml:msubsup>
              <mml:mo>=</mml:mo>
              <mml:msubsup>
                <mml:mi>e</mml:mi>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:mrow>
                <mml:mi>f</mml:mi>
              </mml:msubsup>
              <mml:mo>+</mml:mo>
              <mml:msubsup>
                <mml:mi>e</mml:mi>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:mrow>
                <mml:mi>r</mml:mi>
              </mml:msubsup>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>where <inline-formula><mml:math id="im4" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> represents the weight <italic>e<sub>ij</sub>
</italic> obtained from forward inferring, and <inline-formula><mml:math id="im5" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> represents the weight <italic>e<sub>ij</sub>
</italic> obtain the reverse inferred GRN. Based on the calculated new weights of these edges, we rank the regulatory edges and select the top <italic>m</italic> regulatory edges to form the inferred GRN.</p>
      </sec>
    </sec>
    <sec id="s2_2">
      <title>2.2 Datasets</title>
      <p>Real scRNA-seq data sets. In order to evaluate the performance of the proposed algorithm on real scRNA-seq datasets, we select three widely used scRNA-seq data sets as the previous method SCODE did (<xref rid="B14" ref-type="bibr">14</xref>). The first dataset is derived from primitive endoderm (PrE) cells differentiated from mouse ES cells (measured at 0, 12, 24, 48, and 72 hours, respectively) and contains 456 cells (<xref rid="B30" ref-type="bibr">30</xref>). The second dataset is derived from examining direct reprogramming from mouse embryonic fibroblast (MEF) cells to myocytes (measured on 0, 2, 5, and 22 days), and this data set contains 405 cells (<xref rid="B31" ref-type="bibr">31</xref>). The third dataset is the scRNA-seq data of definitive endoderm cells derived from human ES cell differentiation (measured at 0, 12, 24, 36, 72, and 96 hours, respectively), and this dataset contains 758 cells (<xref rid="B32" ref-type="bibr">32</xref>). In order to verify the inferred GRN on these scRNA-seq datasets, SCODE used the transcription factor regulation network database (<uri xlink:href="http://www.regulatorynetworks.org">http://www.regulatorynetworks.org</uri>), which was constructed from DNaseI footprints and TF-binding motifs (<xref rid="B33" ref-type="bibr">33</xref>, <xref rid="B34" ref-type="bibr">34</xref>). They integrated the TF regulatory networks of human and mouse, and extracted 100*100 TF regulatory networks for each dataset. We use this regulatory network as the correct network for each data set, and calculate the AUC value of the inferred network.</p>
      <p>Simulated data sets. For real single-cell gene expression datasets, it is usually difficult to obtain the real labels for the edges in the gene regulatory network. In order to verify the effectiveness of the proposed method and compare it with existing methods, four simulated datasets are also used to evaluate the inferred results (<xref rid="B6" ref-type="bibr">6</xref>). These four data sets are all generated by the Boolean model simulating real cell expression data (<xref rid="B35" ref-type="bibr">35</xref>). The advantage of using the Boolean model is that it can be used as a real biological regulatory network to evaluate the performance of the reconstructed regulatory network. We utilize the four gene expression data sets of gonadal sex determination (GSD), hematopoietic stem cell differentiation (HSC), ventral spinal cord development (VSC), and mammalian cortical development (mCAD) to evaluate the performance of the algorithm. These four datasets all contain 10 simulation subsets composed of 2000 cells. The detailed information of the data sets is shown in <xref rid="T1" ref-type="table"><bold>Table 1</bold></xref>.</p>
      <table-wrap position="float" id="T1">
        <label>Table 1</label>
        <caption>
          <p>Details of time-seris gene expression datasets used in the experiment.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">Dataset </th>
              <th valign="top" align="center" rowspan="1" colspan="1">Genes </th>
              <th valign="top" align="center" rowspan="1" colspan="1">Time points </th>
              <th valign="top" align="center" rowspan="1" colspan="1">Cells </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">GSD</td>
              <td valign="top" align="center" rowspan="1" colspan="1">19</td>
              <td valign="top" align="center" rowspan="1" colspan="1">734</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2000</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">HSC</td>
              <td valign="top" align="center" rowspan="1" colspan="1">11</td>
              <td valign="top" align="center" rowspan="1" colspan="1">731</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2000</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">VSC</td>
              <td valign="top" align="center" rowspan="1" colspan="1">8</td>
              <td valign="top" align="center" rowspan="1" colspan="1">492</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2000</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mCAD</td>
              <td valign="top" align="center" rowspan="1" colspan="1">5</td>
              <td valign="top" align="center" rowspan="1" colspan="1">492</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2000</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Real Dataset1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">100</td>
              <td valign="top" align="center" rowspan="1" colspan="1">456</td>
              <td valign="top" align="center" rowspan="1" colspan="1">456</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Real Dataset2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">100</td>
              <td valign="top" align="center" rowspan="1" colspan="1">405</td>
              <td valign="top" align="center" rowspan="1" colspan="1">405</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Real Dataset3</td>
              <td valign="top" align="center" rowspan="1" colspan="1">100</td>
              <td valign="top" align="center" rowspan="1" colspan="1">758</td>
              <td valign="top" align="center" rowspan="1" colspan="1">758</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="s2_3">
      <title>2.3 Evaluation Metrics</title>
      <p>To evaluate the performance of different methods in inferring GRNs, we utilize two widely-used metrics AUROC and AUPRC. Specifically, AUROC is the area under the ROC based on TPR and FPR. AUPRC is the area under the PRC based on the precision rate and the recall rate.</p>
      <disp-formula>
        <label>(7)</label>
        <mml:math id="M7" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mi>T</mml:mi>
            <mml:mi>P</mml:mi>
            <mml:mi>R</mml:mi>
            <mml:mo>=</mml:mo>
            <mml:mfrac>
              <mml:mrow>
                <mml:mi>T</mml:mi>
                <mml:mi>P</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>T</mml:mi>
                <mml:mi>P</mml:mi>
                <mml:mo>+</mml:mo>
                <mml:mi>F</mml:mi>
                <mml:mi>N</mml:mi>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula>
        <label>(8)</label>
        <mml:math id="M8" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mi>F</mml:mi>
            <mml:mi>P</mml:mi>
            <mml:mi>R</mml:mi>
            <mml:mo>=</mml:mo>
            <mml:mfrac>
              <mml:mrow>
                <mml:mi>F</mml:mi>
                <mml:mi>P</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>F</mml:mi>
                <mml:mi>P</mml:mi>
                <mml:mo>+</mml:mo>
                <mml:mi>T</mml:mi>
                <mml:mi>N</mml:mi>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula>
        <label>(9)</label>
        <mml:math id="M9" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mi>P</mml:mi>
            <mml:mi>r</mml:mi>
            <mml:mi>e</mml:mi>
            <mml:mi>c</mml:mi>
            <mml:mi>i</mml:mi>
            <mml:mi>s</mml:mi>
            <mml:mi>i</mml:mi>
            <mml:mi>o</mml:mi>
            <mml:mi>n</mml:mi>
            <mml:mo>=</mml:mo>
            <mml:mfrac>
              <mml:mrow>
                <mml:mi>T</mml:mi>
                <mml:mi>P</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>T</mml:mi>
                <mml:mi>P</mml:mi>
                <mml:mo>+</mml:mo>
                <mml:mi>F</mml:mi>
                <mml:mi>P</mml:mi>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula>
        <label>(10)</label>
        <mml:math id="M10" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mi>R</mml:mi>
            <mml:mi>e</mml:mi>
            <mml:mi>c</mml:mi>
            <mml:mi>a</mml:mi>
            <mml:mi>l</mml:mi>
            <mml:mi>l</mml:mi>
            <mml:mo>=</mml:mo>
            <mml:mi>T</mml:mi>
            <mml:mi>P</mml:mi>
            <mml:mi>R</mml:mi>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>where TP and FP indicate the numbers of true and false positives, and TN and FN are true and false negatives. For the simulated datasets, we calculated the average of the AUROC and AUPRC to evaluate the accuracy of the inferred network on different subsets. Further, we calculated the overall score of <italic>AUROC<sub>score</sub>
</italic> and <italic>AUPRC<sub>score</sub>
</italic>. The definition is as follows:</p>
      <disp-formula>
        <label>(11)</label>
        <mml:math id="M11" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mi>A</mml:mi>
            <mml:mi>U</mml:mi>
            <mml:mi>R</mml:mi>
            <mml:mi>O</mml:mi>
            <mml:msub>
              <mml:mi>C</mml:mi>
              <mml:mrow>
                <mml:mi>s</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>o</mml:mi>
                <mml:mi>r</mml:mi>
                <mml:mi>e</mml:mi>
              </mml:mrow>
            </mml:msub>
            <mml:mo>=</mml:mo>
            <mml:mfrac>
              <mml:mn>1</mml:mn>
              <mml:mi>n</mml:mi>
            </mml:mfrac>
            <mml:mstyle displaystyle="true">
              <mml:munderover>
                <mml:mo>∑</mml:mo>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
                <mml:mi>n</mml:mi>
              </mml:munderover>
              <mml:mrow>
                <mml:mi>A</mml:mi>
                <mml:mi>U</mml:mi>
                <mml:mi>R</mml:mi>
                <mml:mi>O</mml:mi>
                <mml:msub>
                  <mml:mi>C</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
              </mml:mrow>
            </mml:mstyle>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula>
        <label>(12)</label>
        <mml:math id="M12" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mi>A</mml:mi>
            <mml:mi>U</mml:mi>
            <mml:mi>P</mml:mi>
            <mml:mi>R</mml:mi>
            <mml:msub>
              <mml:mi>C</mml:mi>
              <mml:mrow>
                <mml:mi>s</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>o</mml:mi>
                <mml:mi>r</mml:mi>
                <mml:mi>e</mml:mi>
              </mml:mrow>
            </mml:msub>
            <mml:mo>=</mml:mo>
            <mml:mfrac>
              <mml:mn>1</mml:mn>
              <mml:mi>n</mml:mi>
            </mml:mfrac>
            <mml:mstyle displaystyle="true">
              <mml:munderover>
                <mml:mo>∑</mml:mo>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
                <mml:mi>n</mml:mi>
              </mml:munderover>
              <mml:mrow>
                <mml:mi>A</mml:mi>
                <mml:mi>U</mml:mi>
                <mml:mi>P</mml:mi>
                <mml:mi>R</mml:mi>
                <mml:msub>
                  <mml:mi>C</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
              </mml:mrow>
            </mml:mstyle>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>where <italic>n</italic> represents the number of subsets in each dataset (taking the dataset GSD as an example, <italic>n</italic> is 10). <italic>AUROC<sub>i</sub>
</italic> and <italic>AUPRC<sub>i</sub>
</italic> respectively denote the average AUROC and AUPRC of the algorithm on the <italic>i<sub>th</sub>
</italic> data set.</p>
    </sec>
  </sec>
  <sec id="s3">
    <title>3 Results</title>
    <sec id="s3_1">
      <title>3.1 Performance on Simulated Data Sets</title>
      <p>To evaluate the effectiveness of BiRGRN, We apply the proposed GRN inference method to four simulated datasets, including datasets related to hematopoietic stem cell differentiation (HSC), gonadal sex determination (GSD), ventral spinal cord development (VSC), and mammalian cortical development (mCAD). In detail, each dataset is generated by the Boolean model in previous study (<xref rid="B6" ref-type="bibr">6</xref>), including 10 data subsets composed of 2000 cells and multiple time points. <xref rid="T1" ref-type="table"><bold>Table 1</bold></xref> lists the detailed information of these datasets. We take each synthetic network as the ground truth and adopt two metrics to evaluate the inferred GRNs. We utilize both the area under the receiver operating characteristic curve and the area under the precision-recall curve (AUROC/AUPRC) as our evaluation metrics across the 10 different datasets. Further, we compare BiRGRN with four widely used methods, including three prior algorithms GRNBOOST2 (<xref rid="B36" ref-type="bibr">36</xref>), PPCOR, PIDC, and the classic algorithm GEINE3.</p>
      <p><xref rid="f3" ref-type="fig"><bold>Figures 3</bold></xref>, <xref rid="f4" ref-type="fig"><bold>4</bold></xref> respectively show the AUROC and AUPRC of these compared methods on the four datasets. As can be seen, BiRGRN outperforms the compared methods on all four simulated datasets. We observe significant improvement over the three methods (GRNBOOST2, PPCOR, and PIDC) using the provided prior edge sets. Also, BiRGRN performs better than the widely used method GENIE3. Compared with the second-ranked algorithm on GSD, BiRGRN has a 6.2% increase in AUROC and a 33.3% increase in AUPRC. On the dataset HSC, BiRGRN achieves an improvement of 11.3% in AUROC and 10.2% in AUPRC over the other methods. For the dataset VSC, BiRGRN has a 3.8% higher AUROC and a 13.2% higher AUPRC than the second-ranked algorithm, whereas the performance of PPCOR is not as good as other methods. And as shown in the figures, the compared algorithms perform poorly on mCAD, and the AUROC values of the four algorithms are only around 0.5. In contrast, our proposed BiRGRN reaches a mean AUROC of 0.8. Compared with the second-ranked algorithm, the AUROC of BiRGRN increases by 55%, AUPRC increases by 56.1%. Furthermore, <xref rid="f5" ref-type="fig"><bold>Figure 5</bold></xref> presents the overall score of these algorithms on the four datasets, the histogram of the overall score also intuitively shows that the algorithm in this paper has a better performance.</p>
      <fig position="float" id="f3">
        <label>Figure 3</label>
        <caption>
          <p>AUROC scores of the compared GRN inference algorithms on four simulated datasets.</p>
        </caption>
        <graphic xlink:href="fonc-12-899825-g003" position="float"/>
      </fig>
      <fig position="float" id="f4">
        <label>Figure 4</label>
        <caption>
          <p>AUPRC scores of of the compared GRN inference algorithms on four simulated datasets.</p>
        </caption>
        <graphic xlink:href="fonc-12-899825-g004" position="float"/>
      </fig>
      <fig position="float" id="f5">
        <label>Figure 5</label>
        <caption>
          <p>The overall score of the algorithm on the four simulated datasets.</p>
        </caption>
        <graphic xlink:href="fonc-12-899825-g005" position="float"/>
      </fig>
    </sec>
    <sec id="s3_2">
      <title>3.2 Performance on the Real scRNA-Seq Data Sets</title>
      <p>We next measure the performance of BiRGRN for inferring GRNs on real datasets. Here, BiRGRN is applied to three real time-series scRNA-seq datasets. As previous studies did (<xref rid="B14" ref-type="bibr">14</xref>), the inferred GRN is validated by the TF regulatory network based on DNaseI footprints and TF-binding motifs. We calculate the AUROC values of BiRGRN given 15% of the prior knowledge and compared them with four widely used methods, including GENIE3, LEAP, BiXGBoost, and SCODE. Specifically, GENIE3 is a classic random forest-based method for inferring GRNs. The algorithm BiXGBoost adopts local-in and local-out models to utilize time information in two directions and integrates XGBoost to evaluate the feature importance. LEAP and SCODE are two advanced GRN inference methods for scRNA-seq data.</p>
      <p><xref rid="T2" ref-type="table"><bold>Table 2</bold></xref> presents the performance of these compared methods on the real scRNA-seq datasets. Compared to other network inference algorithms, our proposed algorithm BiRGRN can infer TF regulatory networks with high performance. On Dataset 1 and Dataset 3, the AUROC values of BiRGRN are obviously higher than those of the four previous algorithms. Compared with the second-ranked algorithm SCODE, the AUROC of BiRGRN is increased by 6.5% on dataset1, and the AUROC of BiRGRN is increased by 7.4% on dateset3. On Dataset 2, the performance of BiRGRN is close to the best performance. These results indicate that the RNN structure utilized in BiRGRN has a high capability of incorporating time point information, which is effective in network inference.</p>
      <table-wrap position="float" id="T2">
        <label>Table 2</label>
        <caption>
          <p>The AUROC value of the algorithm on three real scRNA-seq datasets.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">Algorithm</th>
              <th valign="top" align="center" rowspan="1" colspan="1">Dataset 1</th>
              <th valign="top" align="center" rowspan="1" colspan="1">Dataset 2</th>
              <th valign="top" align="center" rowspan="1" colspan="1">Dataset 3</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">BiRGRN</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.571</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.573</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.562</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">GENIE3</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.503</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.498</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.507</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">LEAP</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.487</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.5</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.494</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">SCODE</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.536</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.581</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.523</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">BiXGBoost</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.509</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.479</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.510</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>The value in bold represents the highest value in the column.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>We also record the runtime of each method on three real data sets. As shown in <xref rid="T3" ref-type="table"><bold>Table 3</bold></xref>, LEAP and GENIE3 have the highest efficiency. The runtime of BiRGRN is at the median level among several methods. On Dataset 1 and Dataset 2, BiRGRN runs for 1min and 58s, which is much faster than SCODE and BiXGBoost. These results show that BiRGRN can efficiently use temporal information to rapidly reconstruct gene regulatory networks.</p>
      <table-wrap position="float" id="T3">
        <label>Table 3</label>
        <caption>
          <p>The runtime of each method for three real datasets.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">Runtime<sup>1</sup>
</th>
              <th valign="top" align="center" rowspan="1" colspan="1">BiRGRN</th>
              <th valign="top" align="center" rowspan="1" colspan="1">SCODE</th>
              <th valign="top" align="center" rowspan="1" colspan="1">GENIE3</th>
              <th valign="top" align="center" rowspan="1" colspan="1">LEAP</th>
              <th valign="top" align="center" rowspan="1" colspan="1">BiXGBoost</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Dataset 1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1min58s</td>
              <td valign="top" align="center" rowspan="1" colspan="1">7min3s</td>
              <td valign="top" align="center" rowspan="1" colspan="1">58s</td>
              <td valign="top" align="center" rowspan="1" colspan="1">6s</td>
              <td valign="top" align="center" rowspan="1" colspan="1">min49s</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Dataset 2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1min58s</td>
              <td valign="top" align="center" rowspan="1" colspan="1">6min39s</td>
              <td valign="top" align="center" rowspan="1" colspan="1">52s</td>
              <td valign="top" align="center" rowspan="1" colspan="1">4s</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3min21s</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Dataset 3</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2min22s</td>
              <td valign="top" align="center" rowspan="1" colspan="1">8min49s</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1min6s</td>
              <td valign="top" align="center" rowspan="1" colspan="1">11s</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3min58s</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p><sup>1</sup>All algorithms except BiXGBoost are tested on Beeline(a benchmarking software for GRN inference algorithms). The computations were performed on a Lenovo Legion R7000 2020 equipped with a 3.0GHz AMD Ryzen 5 4600H processor a 4GB NVIDIA GeForce GTX 1650Ti and 16GB of 3200MHz DDR4 RAM.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="s3_3">
      <title>3.3 Ablation Study</title>
      <p>As BiRGRN is mainly composed of the bidirectional RNN integrating the forward and reverse training, and the voting model incorporating prior knowledge, we further investigate the impact of the different components on the overall performance. Accordingly, we obtain three variants of BiRGRN, including BiRGRN-Prior(the model removing incorporated prior knowledge), BiRGRN-Forward (the model removing forward training), and BiRGRN-Reverse (the model removing reverse training). We respectively carry out the ablation study on the four simulated datasets. <xref rid="T4" ref-type="table"><bold>Table 4</bold></xref> summarizes the performance comparison between BiRGRN and these three variants.</p>
      <table-wrap position="float" id="T4">
        <label>Table 4</label>
        <caption>
          <p>The AUROC value of the algorithm and three variants on the simulated datasets.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">Dataset</th>
              <th valign="top" align="center" rowspan="1" colspan="1">BiRGRN</th>
              <th valign="top" align="center" rowspan="1" colspan="1">Prior network</th>
              <th valign="top" align="center" rowspan="1" colspan="1">Forward</th>
              <th valign="top" align="center" rowspan="1" colspan="1">Reverse</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">GSD</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.597</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.544</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.583</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.587</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">HSC</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.684</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.586</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.656</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.660</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">VSC</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.795</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.624</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.761</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.763</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">mCAD</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.796</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.678</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.796</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.792</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>The value in bold represents the highest value in the row.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>We first evaluate the contribution of prior information for guiding the voting process in the model. The results show that the removal of the prior information results in a slight drop in performance. Without incorporating prior information, the network is able to reconstruct a relatively coarse segmentation. Without further guidance of prior information, it might be not able to refine it properly. To further inspect the effectiveness of the bidirectional model, we respectively compare the performance of the BiRGRN without forwarding training and reverse training. From the table, we observe that the performance of two single directional training models is similar, and they are slightly lower than those of the bidirectional training model. This result of ablation Study indicates the forward training and the reverse training might be complementary to each other, and thus the bidirectional RNN structure is capable of capturing more regulation relationships among genes. On the whole, these results demonstrate that both the components are contributive to the performance of BiRGRN.</p>
    </sec>
  </sec>
  <sec id="s4">
    <title>4 Conclusion</title>
    <p>Many cellular processes, either in development or disease progression are governed by complex gene regulatory mechanisms. GRN reverse engineering methods attempt to infer GRNs from large-scale transcriptomic data using computational or statistical models. A plethora of GRN inference methods has been proposed. However, with the development of single-cell sequencing technology, traditional GRN inference methods designed for bulk transcriptomic data might be unsuitable to process large quantities of scRNA-seq data. In this paper, we proposed a novel computational method BiRGRN to infer GRNs from time-series scRNA-seq data. BiRGRN utilizes a bidirectional recurrent neural network to infer GRNs. The recurrent neural network is a complex neural network, which can capture complex, non-linear, and dynamic relationships among variables. It maps a neuron to a gene, and maps the connections between neural network layers to the regulatory relationship between genes, giving a good solution to model GRN with biological closeness and mathematical flexibility. Then we transform the reconstruction of GRNs problem into a regression problem that uses the gene expression data of the previous time points to predict the gene expression data of the later time node. In order to improve the accuracy of the algorithm, the method can use an incomplete set of prior knowledge. The developed model has been tested on four simulated data and three real datasets. We performed a comparison of our results with other state-of-the-art techniques which shows the superiority of our proposed model. The experiments conducted on simulated datasets and real scRNA-seq datasets demonstrate that BiRGRN can infer gene regulatory networks with high performance, which that the proposed bidirectional RNN structure is effective in GRN inference.</p>
  </sec>
  <sec sec-type="data-availability" id="s5">
    <title>Data Availability Statement</title>
    <p>Publicly available datasets were analyzed in this study. The real dataset can be found in <uri xlink:href="https://github.com/hmatsu1226/SCODE">https://github.com/hmatsu1226/SCODE</uri>, the simulated datasets are all from Beeline and can be found in <uri xlink:href="https://github.com/Murali-group/Beeline">https://github.com/Murali-group/Beeline</uri>.</p>
  </sec>
  <sec sec-type="author-contributions" id="s6">
    <title>Author Contributions</title>
    <p>YG and XH are responsible for the main idea, as well as the completion of the manuscript. XH has developed the algorithm and performed data analysis. GZ, CY, and GX have coordinated data preprocessing and supervised the effort. All authors have read and approved the final manuscript.</p>
  </sec>
  <sec sec-type="funding-information" id="s7">
    <title>Funding</title>
    <p>This work was sponsored in part by the National Natural Science Foundation of China (62172088), National Key Research and Development Program of China (2016YFC0901704), and Shanghai Natural Science Foundation (21ZR1400400, 19ZR1402000).</p>
  </sec>
  <sec sec-type="COI-statement" id="s8">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s9">
    <title>Publisher’s Note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <label>1</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lambert</surname><given-names>SA</given-names></name><name><surname>Jolma</surname><given-names>A</given-names></name><name><surname>Campitelli</surname><given-names>LF</given-names></name><name><surname>Das</surname><given-names>PK</given-names></name><name><surname>Yin</surname><given-names>Y</given-names></name><name><surname>Albu</surname><given-names>M</given-names></name><etal/></person-group>. <article-title>The Human Transcription Factors</article-title>. <source>Cell</source> (<year>2018</year>) <volume>172</volume>:<page-range>650–65</page-range>. doi: <pub-id pub-id-type="doi">10.1016/j.cell.2018.01.029</pub-id>
</mixed-citation>
    </ref>
    <ref id="B2">
      <label>2</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiers</surname><given-names>MW</given-names></name><name><surname>Minnoye</surname><given-names>L</given-names></name><name><surname>Aibar</surname><given-names>S</given-names></name><name><surname>Bravo González-Blas</surname><given-names>C</given-names></name><name><surname>Kalender Atak</surname><given-names>Z</given-names></name><name><surname>Aerts</surname><given-names>S</given-names></name></person-group>. <article-title>Mapping Gene Regulatory Networks From Single-Cell Omics Data</article-title>. <source>Briefings Funct Genomics</source> (<year>2018</year>) <volume>17</volume>:<page-range>246–54</page-range>. doi: <pub-id pub-id-type="doi">10.1093/bfgp/elx046</pub-id>
</mixed-citation>
    </ref>
    <ref id="B3">
      <label>3</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marbach</surname><given-names>D</given-names></name><name><surname>Lamparter</surname><given-names>D</given-names></name><name><surname>Quon</surname><given-names>G</given-names></name><name><surname>Kellis</surname><given-names>M</given-names></name><name><surname>Kutalik</surname><given-names>Z</given-names></name><name><surname>Bergmann</surname><given-names>S</given-names></name></person-group>. <article-title>Tissue-Specific Regulatory Circuits Reveal Variable Modular Perturbations Across Complex Diseases</article-title>. <source>Nat Methods</source> (<year>2016</year>) <volume>13</volume>:<page-range>366–70</page-range>. doi: <pub-id pub-id-type="doi">10.1038/nmeth.3799</pub-id>
</mixed-citation>
    </ref>
    <ref id="B4">
      <label>4</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iacono</surname><given-names>G</given-names></name><name><surname>Massoni-Badosa</surname><given-names>R</given-names></name><name><surname>Heyn</surname><given-names>H</given-names></name></person-group>. <article-title>Single-Cell Transcriptomics Unveils Gene Regulatory Network Plasticity</article-title>. <source>Genome Biol</source> (<year>2019</year>) <volume>20</volume>:<fpage>1</fpage>–<lpage>20</lpage>. doi: <pub-id pub-id-type="doi">10.1186/s13059-019-1713-4</pub-id>
<pub-id pub-id-type="pmid">30606230</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <label>5</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fazilaty</surname><given-names>H</given-names></name><name><surname>Rago</surname><given-names>L</given-names></name><name><surname>Youssef</surname><given-names>KK</given-names></name><name><surname>Ocaña</surname><given-names>OH</given-names></name><name><surname>Garcia-Asencio</surname><given-names>F</given-names></name><name><surname>Arcas</surname><given-names>A</given-names></name><etal/></person-group>. <article-title>A Gene Regulatory Network to Control Emt Programs in Development and Disease</article-title>. <source>Nat Commun</source> (<year>2019</year>) <volume>10</volume>:<fpage>1</fpage>–<lpage>16</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41467-019-13091-8</pub-id>
<pub-id pub-id-type="pmid">30602773</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <label>6</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pratapa</surname><given-names>A</given-names></name><name><surname>Jalihal</surname><given-names>AP</given-names></name><name><surname>Law</surname><given-names>JN</given-names></name><name><surname>Bharadwaj</surname><given-names>A</given-names></name><name><surname>Murali</surname><given-names>T</given-names></name></person-group>. <article-title>Benchmarking Algorithms for Gene Regulatory Network Inference From Single-Cell Transcriptomic Data</article-title>. <source>Nat Methods</source> (<year>2020</year>) <volume>17</volume>:<page-range>147–54</page-range>. doi: <pub-id pub-id-type="doi">10.1038/s41592-019-0690-6</pub-id>
</mixed-citation>
    </ref>
    <ref id="B7">
      <label>7</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delgado</surname><given-names>FM</given-names></name><name><surname>Gómez-Vela</surname><given-names>F</given-names></name></person-group>. <article-title>Computational Methods for Gene Regulatory Networks Reconstruction and Analysis: A Review</article-title>. <source>Artif Intell Med</source> (<year>2019</year>) <volume>95</volume>:<page-range>133–45</page-range>. doi: <pub-id pub-id-type="doi">10.1016/j.artmed.2018.10.006</pub-id>
</mixed-citation>
    </ref>
    <ref id="B8">
      <label>8</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Castro</surname><given-names>DM</given-names></name><name><surname>De Veaux</surname><given-names>NR</given-names></name><name><surname>Miraldi</surname><given-names>ER</given-names></name><name><surname>Bonneau</surname><given-names>R</given-names></name></person-group>. <article-title>Multi-Study Inference of Regulatory Networks for More Accurate Models of Gene Regulation</article-title>. <source>PloS Comput Biol</source> (<year>2019</year>) <volume>15</volume>:<elocation-id>e1006591</elocation-id>. doi: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006591</pub-id>
<pub-id pub-id-type="pmid">30677040</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <label>9</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huynh-Thu</surname><given-names>VA</given-names></name><name><surname>Irrthum</surname><given-names>A</given-names></name><name><surname>Wehenkel</surname><given-names>L</given-names></name><name><surname>Geurts</surname><given-names>P</given-names></name></person-group>. <article-title>Inferring Regulatory Networks From Expression Data Using Tree-Based Methods</article-title>. <source>PloS One</source> (<year>2010</year>) <volume>5</volume>:<elocation-id>e12776</elocation-id>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0012776</pub-id>
<pub-id pub-id-type="pmid">20927193</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <label>10</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sławek</surname><given-names>J</given-names></name><name><surname>Arodź</surname><given-names>T</given-names></name></person-group>. <article-title>Ennet: Inferring Large Gene Regulatory Networks From Expression Data Using Gradient Boosting</article-title>. <source>BMC Syst Biol</source> (<year>2013</year>) <volume>7</volume>:<fpage>1</fpage>–<lpage>13</lpage>. doi: <pub-id pub-id-type="doi">10.1186/1752-0509-7-106</pub-id>
<pub-id pub-id-type="pmid">23280066</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <label>11</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>S</given-names></name></person-group>. <article-title>Ppcor: An R Package for a Fast Calculation to Semi-Partial Correlation Coefficients</article-title>. <source>Commun Stat Appl Methods</source> (<year>2015</year>) <volume>22</volume>:<fpage>665</fpage>. doi: <pub-id pub-id-type="doi">10.5351/CSAM.2015.22.6.665</pub-id>
<pub-id pub-id-type="pmid">26688802</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <label>12</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>TE</given-names></name><name><surname>Stumpf</surname><given-names>MP</given-names></name><name><surname>Babtie</surname><given-names>AC</given-names></name></person-group>. <article-title>Gene Regulatory Network Inference From Single-Cell Data Using Multivariate Information Measures</article-title>. <source>Cell Syst</source> (<year>2017</year>) <volume>5</volume>:<page-range>251–67</page-range>. doi: <pub-id pub-id-type="doi">10.1016/j.cels.2017.08.014</pub-id>
</mixed-citation>
    </ref>
    <ref id="B13">
      <label>13</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Specht</surname><given-names>AT</given-names></name><name><surname>Li</surname><given-names>J</given-names></name></person-group>. <article-title>Leap: Constructing Gene Co-Expression Networks for Single-Cell Rna-Sequencing Data Using Pseudotime Ordering</article-title>. <source>Bioinformatics</source> (<year>2017</year>) <volume>33</volume>:<page-range>764–6</page-range>. doi: <pub-id pub-id-type="doi">10.1093/bioinformatics/btw729</pub-id>
</mixed-citation>
    </ref>
    <ref id="B14">
      <label>14</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matsumoto</surname><given-names>H</given-names></name><name><surname>Kiryu</surname><given-names>H</given-names></name><name><surname>Furusawa</surname><given-names>C</given-names></name><name><surname>Ko</surname><given-names>MS</given-names></name><name><surname>Ko</surname><given-names>SB</given-names></name><name><surname>Gouda</surname><given-names>N</given-names></name><etal/></person-group>. <article-title>Scode: An Efficient Regulatory Network Inference Algorithm From Single-Cell Rna-Seq During Differentiation</article-title>. <source>Bioinformatics</source> (<year>2017</year>) <volume>33</volume>:<page-range>2314–21</page-range>. doi: <pub-id pub-id-type="doi">10.1093/bioinformatics/btx194</pub-id>
</mixed-citation>
    </ref>
    <ref id="B15">
      <label>15</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Papili</surname></name><name><surname>Gao</surname><given-names>N</given-names></name><name><surname>Ud-Dean</surname><given-names>SM</given-names></name><name><surname>Gandrillon</surname><given-names>O</given-names></name><name><surname>Gunawan</surname><given-names>R</given-names></name></person-group>. <article-title>Sincerities: Inferring Gene Regulatory Networks From Time-Stamped Single Cell Transcriptional Expression Profiles</article-title>. <source>Bioinformatics</source> (<year>2018</year>) <volume>34</volume>:<page-range>258–66</page-range>. doi: <pub-id pub-id-type="doi">10.1093/bioinformatics/btx575</pub-id>
</mixed-citation>
    </ref>
    <ref id="B16">
      <label>16</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>R</given-names></name><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Wu</surname><given-names>FX</given-names></name><name><surname>Pan</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name></person-group>. <article-title>Bixgboost: A Scalable, Flexible Boosting-Based Method for Reconstructing Gene Regulatory Networks</article-title>. <source>Bioinformatics</source> (<year>2019</year>) <volume>35</volume>:<page-range>1893–900</page-range>. doi: <pub-id pub-id-type="doi">10.1093/bioinformatics/bty908</pub-id>
</mixed-citation>
    </ref>
    <ref id="B17">
      <label>17</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Ma</surname><given-names>A</given-names></name><name><surname>Ma</surname><given-names>Q</given-names></name><name><surname>Xu</surname><given-names>D</given-names></name><name><surname>Joshi</surname><given-names>T</given-names></name></person-group>. <article-title>Inductive Inference of Gene Regulatory Network Using Supervised and Semi-Supervised Graph Neural Networks</article-title>. <source>Comput Struct Biotechnol J</source> (<year>2020</year>) <volume>18</volume>:<page-range>3335–43</page-range>. doi: <pub-id pub-id-type="doi">10.1016/j.csbj.2020.10.022</pub-id>
</mixed-citation>
    </ref>
    <ref id="B18">
      <label>18</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shu</surname><given-names>H</given-names></name><name><surname>Zhou</surname><given-names>J</given-names></name><name><surname>Lian</surname><given-names>Q</given-names></name><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Zhao</surname><given-names>D</given-names></name><name><surname>Zeng</surname><given-names>J</given-names></name><etal/></person-group>. <article-title>Modeling Gene Regulatory Networks Using Neural Network Architectures</article-title>. <source>Nat Comput Sci</source> (<year>2021</year>) <volume>1</volume>:<fpage>491</fpage>–<lpage>501</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s43588-021-00099-8</pub-id>
</mixed-citation>
    </ref>
    <ref id="B19">
      <label>19</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>Q</given-names></name><name><surname>Su</surname><given-names>J</given-names></name></person-group>. <article-title>Dstg: Deconvoluting Spatial Transcriptomics Data Through Graph-Based Artificial Intelligence</article-title>. <source>Briefings Bioinf</source> (<year>2021</year>) <volume>22</volume>:<fpage>1</fpage>–<lpage>13</lpage>. doi: <pub-id pub-id-type="doi">10.1093/bib/bbaa414</pub-id>
</mixed-citation>
    </ref>
    <ref id="B20">
      <label>20</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jin</surname><given-names>S</given-names></name><name><surname>Guerrero-Juarez</surname><given-names>CF</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Chang</surname><given-names>I</given-names></name><name><surname>Ramos</surname><given-names>R</given-names></name><name><surname>Kuan</surname><given-names>CH</given-names></name><etal/></person-group>. <article-title>Inference and Analysis of Cell-Cell Communication Using Cellchat</article-title>. <source>Nat Commun</source> (<year>2021</year>) <volume>12</volume>:<fpage>1</fpage>–<lpage>20</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41467-021-21246-9</pub-id>
<pub-id pub-id-type="pmid">33397941</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <label>21</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Jakobsen S</surname><given-names>T</given-names></name><name><surname>Natarajan</surname><given-names>KN</given-names></name><name><surname>Won</surname><given-names>KJ</given-names></name></person-group>. <article-title>Tenet: Gene Network Reconstruction Using Transfer Entropy Reveals Key Regulatory Factors From Single Cell Transcriptomic Data</article-title>. <source>Nucleic Acids Res</source> (<year>2021</year>) <volume>49</volume>:<page-range>e1–1</page-range>. doi: <pub-id pub-id-type="doi">10.1093/nar/gkaa1014</pub-id>
</mixed-citation>
    </ref>
    <ref id="B22">
      <label>22</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>Y</given-names></name><name><surname>Bar-Joseph</surname><given-names>Z</given-names></name></person-group>. <article-title>Deep Learning for Inferring Gene Relationships From Single-Cell Expression Data</article-title>. <source>Proc Natl Acad Sci</source> (<year>2019</year>) <volume>116</volume>:<page-range>27151–8</page-range>. doi: <pub-id pub-id-type="doi">10.1073/pnas.1911536116</pub-id>
</mixed-citation>
    </ref>
    <ref id="B23">
      <label>23</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>Y</given-names></name><name><surname>Bar-Joseph</surname><given-names>Z</given-names></name></person-group>. <article-title>Gcng: Graph Convolutional Networks for Inferring Gene Interaction From Spatial Transcriptomics Data</article-title>. <source>Genome Biol</source> (<year>2020</year>) <volume>21</volume>:<fpage>1</fpage>–<lpage>16</lpage>. doi: <pub-id pub-id-type="doi">10.1186/s13059-020-02214-w</pub-id>
</mixed-citation>
    </ref>
    <ref id="B24">
      <label>24</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zaremba</surname><given-names>W</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Vinyals</surname><given-names>O</given-names></name></person-group>. <article-title>Recurrent Neural Network Regularization</article-title>. <source>ArXiv Prepr ArXiv</source> (<year>2014</year>) <volume>1409</volume>:<fpage>2329</fpage>. doi: <pub-id pub-id-type="doi">10.48550/arXiv.1409.2329</pub-id>
</mixed-citation>
    </ref>
    <ref id="B25">
      <label>25</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>L</given-names></name><name><surname>Hou</surname><given-names>ZG</given-names></name><name><surname>Lin</surname><given-names>Y</given-names></name><name><surname>Tan</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>WC</given-names></name><name><surname>Wu</surname><given-names>FX</given-names></name></person-group>. <article-title>Recurrent Neural Network for Non-Smooth Convex Optimization Problems With Application to the Identification of Genetic Regulatory Networks</article-title>. <source>IEEE Trans Neural Networks</source> (<year>2011</year>) <volume>22</volume>:<page-range>714–26</page-range>. doi: <pub-id pub-id-type="doi">10.1109/TNN.2011.2109735</pub-id>
</mixed-citation>
    </ref>
    <ref id="B26">
      <label>26</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Biswas</surname><given-names>S</given-names></name><name><surname>Acharyya</surname><given-names>S</given-names></name></person-group>. <article-title>A Bi-Objective Rnn Model to Reconstruct Gene Regulatory Network: A Modified Multi-Objective Simulated Annealing Approach</article-title>. <source>IEEE/ACM Trans Comput Biol Bioinf</source> (<year>2018</year>) <volume>15</volume>:<page-range>2053–9</page-range>. doi: <pub-id pub-id-type="doi">10.1109/TCBB.2017.2771360</pub-id>
</mixed-citation>
    </ref>
    <ref id="B27">
      <label>27</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>He</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Ren</surname><given-names>S</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name></person-group>. <source>Deep Residual Learning for Image Recognition, in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source>. <publisher-loc>Las Vegas, NV</publisher-loc>: <publisher-name>IEEE</publisher-name> (<year>2016</year>). <page-range>770–8</page-range>. p.</mixed-citation>
    </ref>
    <ref id="B28">
      <label>28</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liao</surname><given-names>JC</given-names></name><name><surname>Boscolo</surname><given-names>R</given-names></name><name><surname>Yang</surname><given-names>YL</given-names></name><name><surname>Tran</surname><given-names>LM</given-names></name><name><surname>Sabatti</surname><given-names>C</given-names></name><name><surname>Roychowdhury</surname><given-names>VP</given-names></name></person-group>. <article-title>Network Component Analysis: Reconstruction of Regulatory Signals in Biological Systems</article-title>. <source>Proc Natl Acad Sci</source> (<year>2003</year>) <volume>100</volume>:<page-range>15522–7</page-range>. doi: <pub-id pub-id-type="doi">10.1073/pnas.2136632100</pub-id>
</mixed-citation>
    </ref>
    <ref id="B29">
      <label>29</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gan</surname><given-names>Y</given-names></name><name><surname>Xin</surname><given-names>Y</given-names></name><name><surname>Hu</surname><given-names>X</given-names></name><name><surname>Zou</surname><given-names>G</given-names></name></person-group>. <article-title>Inferring Gene Regulatory Network From Single-Cell Transcriptomic Data by Integrating Multiple Prior Networks</article-title>. <source>Comput Biol Chem</source> (<year>2021</year>) <volume>93</volume>:<fpage>107512</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.compbiolchem.2021.107512</pub-id>
<pub-id pub-id-type="pmid">34044202</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <label>30</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shimosato</surname><given-names>D</given-names></name><name><surname>Shiki</surname><given-names>M</given-names></name><name><surname>Niwa</surname><given-names>H</given-names></name></person-group>. <article-title>Extra-Embryonic Endoderm Cells Derived From Es Cells Induced by Gata Factors Acquire the Character of Xen Cells</article-title>. <source>BMC Dev Biol</source> (<year>2007</year>) <volume>7</volume>:<fpage>1</fpage>–<lpage>12</lpage>. doi: <pub-id pub-id-type="doi">10.1186/1471-213X-7-80</pub-id>
<pub-id pub-id-type="pmid">17199897</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <label>31</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treutlein</surname><given-names>B</given-names></name><name><surname>Lee</surname><given-names>QY</given-names></name><name><surname>Camp</surname><given-names>JG</given-names></name><name><surname>Mall</surname><given-names>M</given-names></name><name><surname>Koh</surname><given-names>W</given-names></name><name><surname>Shariati</surname><given-names>SAM</given-names></name><etal/></person-group>. <article-title>Dissecting Direct Reprogramming From Fibroblast to Neuron Using Single-Cell Rna-Seq</article-title>. <source>Nature</source> (<year>2016</year>) <volume>534</volume>:<page-range>391–5</page-range>. doi: <pub-id pub-id-type="doi">10.1038/nature18323</pub-id>
</mixed-citation>
    </ref>
    <ref id="B32">
      <label>32</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chu</surname><given-names>LF</given-names></name><name><surname>Leng</surname><given-names>N</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Hou</surname><given-names>Z</given-names></name><name><surname>Mamott</surname><given-names>D</given-names></name><name><surname>Vereide</surname><given-names>DT</given-names></name><etal/></person-group>. <article-title>Single-Cell Rna-Seq Reveals Novel Regulators of Human Embryonic Stem Cell Differentiation to Definitive Endoderm</article-title>. <source>Genome Biol</source> (<year>2016</year>) <volume>17</volume>:<fpage>1</fpage>–<lpage>20</lpage>. doi: <pub-id pub-id-type="doi">10.1186/s13059-016-1033-x</pub-id>
<pub-id pub-id-type="pmid">26753840</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <label>33</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neph</surname><given-names>S</given-names></name><name><surname>Stergachis</surname><given-names>AB</given-names></name><name><surname>Reynolds</surname><given-names>A</given-names></name><name><surname>Sandstrom</surname><given-names>R</given-names></name><name><surname>Borenstein</surname><given-names>E</given-names></name><name><surname>Stamatoyannopoulos</surname><given-names>JA</given-names></name></person-group>. <article-title>Circuitry and Dynamics of Human Transcription Factor Regulatory Networks</article-title>. <source>Cell</source> (<year>2012</year>) <volume>150</volume>:<page-range>1274–86</page-range>. doi: <pub-id pub-id-type="doi">10.1016/j.cell.2012.04.040</pub-id>
</mixed-citation>
    </ref>
    <ref id="B34">
      <label>34</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stergachis</surname><given-names>AB</given-names></name><name><surname>Neph</surname><given-names>S</given-names></name><name><surname>Sandstrom</surname><given-names>R</given-names></name><name><surname>Haugen</surname><given-names>E</given-names></name><name><surname>Reynolds</surname><given-names>AP</given-names></name><name><surname>Zhang</surname><given-names>M</given-names></name><etal/></person-group>. <article-title>Conservation of Trans-Acting Circuitry During Mammalian Regulatory Evolution</article-title>. <source>Nature</source> (<year>2014</year>) <volume>515</volume>:<page-range>365–70</page-range>. doi: <pub-id pub-id-type="doi">10.1038/nature13972</pub-id>
</mixed-citation>
    </ref>
    <ref id="B35">
      <label>35</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giacomantonio</surname><given-names>CE</given-names></name><name><surname>Goodhill</surname><given-names>GJ</given-names></name></person-group>. <article-title>A Boolean Model of the Gene Regulatory Network Underlying Mammalian Cortical Area Development</article-title>. <source>PloS Comput Biol</source> (<year>2010</year>) <volume>6</volume>:<elocation-id>e1000936</elocation-id>. doi: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1000936</pub-id>
<pub-id pub-id-type="pmid">20862356</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <label>36</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moerman</surname><given-names>T</given-names></name><name><surname>Aibar Santos</surname><given-names>S</given-names></name><name><surname>Bravo González-Blas</surname><given-names>C</given-names></name><name><surname>Simm</surname><given-names>J</given-names></name><name><surname>Moreau</surname><given-names>Y</given-names></name><name><surname>Aerts</surname><given-names>J</given-names></name><etal/></person-group>. <article-title>Grnboost2 and Arboreto: Efficient and Scalable Inference of Gene Regulatory Networks</article-title>. <source>Bioinformatics</source> (<year>2019</year>) <volume>35</volume>:<page-range>2159–61</page-range>. doi: <pub-id pub-id-type="doi">10.1093/bioinformatics/bty916</pub-id>
</mixed-citation>
    </ref>
  </ref-list>
</back>
