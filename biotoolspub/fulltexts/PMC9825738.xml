<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9825738</article-id>
    <article-id pub-id-type="pmid">36445000</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac765</article-id>
    <article-id pub-id-type="publisher-id">btac765</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Note</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Genetics and Population Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title><monospace>dnadna</monospace>: a deep learning framework for population genetics inference</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Sanchez</surname>
          <given-names>Théophile</given-names>
        </name>
        <aff><institution>Université Paris-Saclay, CNRS UMR 9015, INRIA, Laboratoire Interdisciplinaire des Sciences du Numérique</institution>, 91400 Orsay, <country country="FR">France</country></aff>
        <xref rid="btac765-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bray</surname>
          <given-names>Erik Madison</given-names>
        </name>
        <aff><institution>Université Paris-Saclay, CNRS UMR 9015, INRIA, Laboratoire Interdisciplinaire des Sciences du Numérique</institution>, 91400 Orsay, <country country="FR">France</country></aff>
        <xref rid="btac765-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jobic</surname>
          <given-names>Pierre</given-names>
        </name>
        <aff><institution>Université Paris-Saclay, CNRS UMR 9015, INRIA, Laboratoire Interdisciplinaire des Sciences du Numérique</institution>, 91400 Orsay, <country country="FR">France</country></aff>
        <aff><institution>ENS Paris-Saclay, 91190 Gif-sur-Yvette</institution>, <country country="FR">France</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Guez</surname>
          <given-names>Jérémy</given-names>
        </name>
        <aff><institution>Université Paris-Saclay, CNRS UMR 9015, INRIA, Laboratoire Interdisciplinaire des Sciences du Numérique</institution>, 91400 Orsay, <country country="FR">France</country></aff>
        <aff><institution>UMR7206 Eco-Anthropologie, Muséum National d’Histoire Naturelle, CNRS, Université de Paris</institution>, 75016 Paris, <country country="FR">France</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Letournel</surname>
          <given-names>Anne-Catherine</given-names>
        </name>
        <aff><institution>Université Paris-Saclay, CNRS UMR 9015, INRIA, Laboratoire Interdisciplinaire des Sciences du Numérique</institution>, 91400 Orsay, <country country="FR">France</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Charpiat</surname>
          <given-names>Guillaume</given-names>
        </name>
        <aff><institution>Université Paris-Saclay, CNRS UMR 9015, INRIA, Laboratoire Interdisciplinaire des Sciences du Numérique</institution>, 91400 Orsay, <country country="FR">France</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-6462-8783</contrib-id>
        <name>
          <surname>Cury</surname>
          <given-names>Jean</given-names>
        </name>
        <aff><institution>Université Paris-Saclay, CNRS UMR 9015, INRIA, Laboratoire Interdisciplinaire des Sciences du Numérique</institution>, 91400 Orsay, <country country="FR">France</country></aff>
        <aff><institution>SEED, U1284, INSERM, Université de Paris</institution>, 75004 Paris, <country country="FR">France</country></aff>
        <xref rid="btac765-cor1" ref-type="corresp"/>
        <!--jean.cury@normalesup.org-->
        <xref rid="btac765-FM2" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-5884-4730</contrib-id>
        <name>
          <surname>Jay</surname>
          <given-names>Flora</given-names>
        </name>
        <aff><institution>Université Paris-Saclay, CNRS UMR 9015, INRIA, Laboratoire Interdisciplinaire des Sciences du Numérique</institution>, 91400 Orsay, <country country="FR">France</country></aff>
        <xref rid="btac765-cor1" ref-type="corresp"/>
        <xref rid="btac765-FM2" ref-type="author-notes"/>
        <!--flora.jay@lri.fr-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Kelso</surname>
          <given-names>Janet</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <fn id="btac765-FM1">
        <p>The authors wish it to be known that, in their opinion, Théophile Sanchez and Pierre Jobic authors should be regarded as Joint First Authors.</p>
      </fn>
      <fn id="btac765-FM2">
        <p>The authors wish it to be known that, in their opinion, Jean Cury and Flora Jay authors should be regarded as Joint Last Authors.</p>
      </fn>
      <corresp id="btac765-cor1">To whom correspondence should be addressed. <email>flora.jay@lri.fr</email> or <email>jean.cury@normalesup.org</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-11-29">
      <day>29</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>29</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <volume>39</volume>
    <issue>1</issue>
    <elocation-id>btac765</elocation-id>
    <history>
      <date date-type="received">
        <day>17</day>
        <month>11</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>30</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>22</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>28</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>26</day>
        <month>12</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac765.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>We present <monospace>dnadna</monospace>, a flexible python-based software for deep learning inference in population genetics. It is task-agnostic and aims at facilitating the development, reproducibility, dissemination and re-usability of neural networks designed for population genetic data.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p><monospace>dnadna</monospace> defines multiple user-friendly workflows. First, users can implement new architectures and tasks, while benefiting from <monospace>dnadna</monospace> utility functions, training procedure and test environment, which saves time and decreases the likelihood of bugs. Second, the implemented networks can be re-optimized based on user-specified training sets and/or tasks. Newly implemented architectures and pre-trained networks are easily shareable with the community for further benchmarking or other applications. Finally, users can apply pre-trained networks in order to predict evolutionary history from alternative real or simulated genetic datasets, without requiring extensive knowledge in deep learning or coding in general. <monospace>dnadna</monospace> comes with a peer-reviewed, exchangeable neural network, allowing demographic inference from SNP data, that can be used directly or retrained to solve other tasks. Toy networks are also available to ease the exploration of the software, and we expect that the range of available architectures will keep expanding thanks to community contributions.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p><monospace>dnadna</monospace> is a Python (≥3.7) package, its repository is available at <monospace><ext-link xlink:href="http://gitlab.com/mlgenetics/dnadna" ext-link-type="uri">gitlab.com/mlgenetics/dnadna</ext-link></monospace> and its associated documentation at <monospace><ext-link xlink:href="http://mlgenetics.gitlab.io/dnadna/" ext-link-type="uri">mlgenetics.gitlab.io/dnadna/</ext-link></monospace>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Human Frontier Science Project</institution>
          </institution-wrap>
        </funding-source>
        <award-id>RGY0075/2019</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="3"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>In recent years, deep learning has been applied to biology with the hope of facilitating complex data analyses and information discovery, and methods are now flourishing in population genetics (<xref rid="btac765-B5" ref-type="bibr">Borowiec <italic toggle="yes">et al.</italic>, 2022</xref>). As reviewed by <xref rid="btac765-B19" ref-type="bibr">Sanchez <italic toggle="yes">et al.</italic> (2021)</xref>, we distinguish two families: those processing many summary statistics, with fully connected or convolutional networks and those based on ’raw’ genetic data leveraging deep architectures to automatically construct informative features (e.g. <xref rid="btac765-B2" ref-type="bibr">Adrion <italic toggle="yes">et al.</italic>, 2020b</xref>; <xref rid="btac765-B3" ref-type="bibr">Battey <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac765-B4" ref-type="bibr">2021</xref>; <xref rid="btac765-B6" ref-type="bibr">Burger <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac765-B7" ref-type="bibr">Chan <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac765-B8" ref-type="bibr">Deelder <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac765-B9" ref-type="bibr">Flagel <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac765-B10" ref-type="bibr">Fonseca <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac765-B11" ref-type="bibr">Gower <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac765-B12" ref-type="bibr">Isildak <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac765-B14" ref-type="bibr">Meisner and Albrechtsen, 2022</xref>; <xref rid="btac765-B15" ref-type="bibr">Montserrat <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac765-B16" ref-type="bibr">Perez <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac765-B17" ref-type="bibr">Qin <italic toggle="yes">et al.</italic>, 2022</xref>; Sanchez <italic toggle="yes">et al.</italic>, 2020; <xref rid="btac765-B20" ref-type="bibr">Torada <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac765-B21" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac765-B23" ref-type="bibr">Yelmen <italic toggle="yes">et al.</italic>, 2021</xref>). Previous studies have made their implementations available at least for reproducibility and sometimes with a specific effort for re-usability. Even so, each of them focuses on a specific network for a specific task. Adapting them requires a careful understanding of the code and its direct modification since many options are hard-coded. This is not only error-prone but also leads to a rapid code divergence between parallel projects, accompanied by complex maintenance. The community demands flexible and rigorous tools as demonstrated by <monospace>stdpopsim</monospace>, a library for population genetic simulations which allows contributions from many researchers (<xref rid="btac765-B1" ref-type="bibr">Adrion <italic toggle="yes">et al.</italic>, 2020a</xref>). In genomics, a suite of tools has been developed to facilitate deep learning applications (e.g. <xref rid="btac765-B13" ref-type="bibr">Kopp <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac765-B18" ref-type="bibr">Routhier <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac765-B24" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2021</xref>). However, none is able to handle population genetic datasets and tasks. For these reasons, we developed <monospace>dnadna</monospace>, Deep Neural Architectures for DNA, a task-agnostic software (in the context of population genetics) that aims at facilitating applications, development, distribution and exchanges around neural networks in the field.</p>
  </sec>
  <sec>
    <title>2 Software</title>
    <p><monospace>dnadna</monospace> is a python-based software for population genetics inference that enables researchers to (i) develop new networks or re-use existing architectures, (ii) train them for a given task (regression, classification or a mix of those) and (iii) share them in such a way that users can easily apply these trained networks to their own dataset. In particular, it already implements several neural networks that have been tested for inferring demographic and adaptive histories from genetic data. Pre-trained networks can be used directly on real and simulated genetic data for the prediction step. Networks can also be re-trained on new simulations (e.g. corresponding to another species or evolutionary model) and/or to solve other tasks (e.g. classifying introgressed versus non-introgressed segments or inferring recombination). Finally, any user can implement new architectures and tasks, while benefiting from training procedure, test environment, routines that may be otherwise overlooked (such as proper preprocessing or efficient data loading), and the possibility to easily share a network to facilitate re-use and benchmarking.</p>
    <p><xref rid="btac765-F1" ref-type="fig">Figure 1</xref> provides an overview of <monospace>dnadna</monospace> steps. It is accessible without coding knowledge thanks to its YAML configuration files which provide the user with a variety of options at each step of the process. Because each use case has its own specificity, we developed a system which allows users to implement plugins (e.g. data transformations, simulators or networks) without modifying the core of the code.</p>
    <p><monospace>dnadna</monospace> is a Python (≥3.7) package with multiple dependencies, the main one being the open-source machine learning library PyTorch. It has a command line interface and an application programming interface (API) (<monospace><ext-link xlink:href="http://mlgenetics.gitlab.io/dnadna/api.html" ext-link-type="uri">mlgenetics.gitlab.io/dnadna/api.html</ext-link></monospace>). It is highly flexible thanks to a structured configuration file system based on YAML and JSON Schema. <monospace>dnadna</monospace> is dual-licensed under the GNU Lesser General Public License (LGPLv3+) and the compatible CeCILL-C Free Software License Agreement. Release 1.0 is available from PyPI at <monospace><ext-link xlink:href="http://pypi.org/project/dnadna/" ext-link-type="uri">pypi.org/project/dnadna/</ext-link></monospace> and Anaconda at <monospace><ext-link xlink:href="http://anaconda.org/mlgenetics/dnadna" ext-link-type="uri">anaconda.org/mlgenetics/dnadna</ext-link></monospace>. Docker images are available at <monospace><ext-link xlink:href="http://hub.docker.com/u/mlgenetics" ext-link-type="uri">hub.docker.com/u/mlgenetics</ext-link></monospace>.</p>
    <fig position="float" id="btac765-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>(<bold>A</bold>) <monospace>dnadna</monospace> workflow and its corresponding commands. Each step could be done as a standalone: (1) simulation of a large genetic dataset according to evolutionary scenarios and priors; genetic data type is not enforced and can be Boolean (classical single-nucleotide polymorphism (SNP) data), integer (e.g. genotype data 0/1/2) or float [e.g. local density of SNPs as in <xref rid="btac765-B11" ref-type="bibr">Gower <italic toggle="yes">et al.</italic> (2021)</xref> or summary statistics along the genome as in <xref rid="btac765-B22" ref-type="bibr">Xue <italic toggle="yes">et al.</italic> (2021)</xref>]; (2) preprocessing, mainly to filter out examples that do not fit minimal requirements and split the rest into train/validation/test sets; (3) training neural networks; (4) predicting on test or real datasets using optimized neural networks. Note that simulations can be skipped if the user already possesses a labeled dataset. Similarly, training can be skipped if the user reuses a pre-trained network. Here is a subset of options at each step: (1a) generating simulations: name of predefined scenario to be simulated and its related parameters, such as number of individuals, number of replicates, mutation rate and demographic parameters; (1b) handling simulations: location on disk and filesystem layout; (2) preprocessing: initial data transformations, filtering values such as minimal number of sampled individuals or SNPs; (3a) architecture design: network name and related arguments (number of filters, layers,…); (3b) training: loss functions, optimization and training hyperparameters (number of epochs, learning rate, batch size, optimizer name,…); (3c) on-the-fly data transformations (subsampling, cropping,…). (<bold>B</bold>, <bold>C</bold>) Illustration of two standard use cases of <monospace>dnadna</monospace>. (<bold>D</bold>) Extract of a training configuration file in YAML format. (<bold>E</bold>) View of a plugin python file that will be passed to <monospace>dnadna</monospace><monospace>train</monospace>, where users can implement novel networks based on PyTorch. <bold>F</bold>: Illustration of a regression task with a pre-trained network. Here we only need to use ‘dnadna predict’ since the network is already trained. Dotted lines denote true known histories, while boxplots indicate the population sizes predicted for 100 independent genomic regions at each time step. The estimates for a ‘complete’ genome are given by the averaged predicted values. The error corresponds to the relative squared errors averaged over the whole time period. (<bold>G</bold>) Illustration of a classification task, following Quickstart tutorial 2. The network was trained on a toy dataset (2000 independent population samples split into training and validation) and tested on 2000 additional samples to discriminate whether the population underwent a decline or an expansion of its size. The contingency table shows that for this classification task, the accuracy is 85.3% on a test set. See <monospace><ext-link xlink:href="http://mlgenetics.gitlab.io/dnadna/tutorials.html" ext-link-type="uri">mlgenetics.gitlab.io/dnadna/tutorials.html</ext-link></monospace> for details on both experiments</p>
      </caption>
      <graphic xlink:href="btac765f1" position="float"/>
    </fig>
  </sec>
  <sec>
    <title>3 Tutorial examples</title>
    <p>We showcase various <monospace>dnadna</monospace> use cases via tutorials that will continue to expand. It is not required to have coding knowledge to perform similar tasks. A first tutorial walks the user through the complete process from configuring and generating simulated genetic data, to running data pre-processing and training a convolutional network to solve a regression task (here predicting the parameters of a two-step population size history). A second tutorial solves a classification task instead (<xref rid="btac765-F1" ref-type="fig">Fig. 1G</xref>). A third tutorial helps users who already have simulated data, to familiarize themselves with <monospace>dnadna</monospace> and train a SPIDNA network on a provided dataset. Finally, we provide tutorials in the form of jupyter notebooks (<monospace><ext-link xlink:href="http://mlgenetics.gitlab.io/dnadna/tutorials.html" ext-link-type="uri">mlgenetics.gitlab.io/dnadna/tutorials.html</ext-link></monospace> and <xref rid="btac765-F1" ref-type="fig">Fig. 1F</xref>).</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>TAU and Kepler GPU platforms and their managers. M Fumagalli and the participants of the School ‘Inference using full genome data’ (DFG SPP1819) for beta-testing. S Ribeiro for her comments.</p>
  </ack>
  <sec>
    <title>Funding</title>
    <p>DIM One Health 2017 RPH17094JJP, Human Frontier Science Project RGY0075/2019, Paris-Saclay CDS 2.0 (IRS), French National Center for Scientific Research (CNRS) 80Prime fellowship TransIA, Agence Nationale de la Recherche ANR-20-CE45-0010-01 RoDAPoG.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The data underlying this article are available in its associated online software repository.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac765-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Adrion</surname><given-names>J.R.</given-names></string-name></person-group><etal>et al</etal> (<year>2020a</year>) <article-title>A community-maintained standard library of population genetic models</article-title>. <source>eLife</source>, <volume>9</volume>, <fpage>e54967</fpage>.<pub-id pub-id-type="pmid">32573438</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Adrion</surname><given-names>J.R.</given-names></string-name></person-group><etal>et al</etal> (<year>2020b</year>) <article-title>Predicting the landscape of recombination using deep learning</article-title>. <source>Mol. Biol. Evol</source>., <volume>37</volume>, <fpage>1790</fpage>–<lpage>1808</lpage>.<pub-id pub-id-type="pmid">32077950</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Battey</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Predicting geographic location from genetic variation with deep neural networks</article-title>. <source>eLife</source>, <volume>9</volume>, <fpage>e54507</fpage>.<pub-id pub-id-type="pmid">32511092</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Battey</surname><given-names>C.J.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Visualizing population structure with variational autoencoders</article-title>. <source>G3</source>, <volume>11</volume>, <fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation>
    </ref>
    <ref id="btac765-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Borowiec</surname><given-names>M.L.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Deep learning as a tool for ecology and evolution</article-title>. <source>Methods Ecol. Evol</source>., <volume>13</volume>, <fpage>1640</fpage>–<lpage>1660</lpage>.</mixed-citation>
    </ref>
    <ref id="btac765-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Burger</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Neural networks for self-adjusting mutation rate estimation when the recombination rate is unknown</article-title>. <source>PLoS Comput. Biol</source>., <volume>18</volume>, <fpage>e1010407</fpage>.<pub-id pub-id-type="pmid">35921376</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chan</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) A likelihood-free inference framework for population genetic data using exchangeable neural networks. In: <italic toggle="yes">Advances in Neural Information Processing Systems, Montréal, Canada</italic>, Vol. <volume>31</volume>, pp. 8603–8614. <ext-link xlink:href="https://dblp.org/rec/conf/nips/ChanPSJMS18.html?view=bibtex" ext-link-type="uri">https://dblp.org/rec/conf/nips/ChanPSJMS18.html?view=bibtex</ext-link>.</mixed-citation>
    </ref>
    <ref id="btac765-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deelder</surname><given-names>W.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Using deep learning to identify recent positive selection in malaria parasite sequence data</article-title>. <source>Malaria J</source>., <volume>20</volume>, <fpage>270</fpage>.</mixed-citation>
    </ref>
    <ref id="btac765-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Flagel</surname><given-names>L.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>The unreasonable effectiveness of convolutional neural networks in population genetic inference</article-title>. <source>Mol. Biol. Evol</source>., <volume>36</volume>, <fpage>220</fpage>–<lpage>238</lpage>.<pub-id pub-id-type="pmid">30517664</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fonseca</surname><given-names>E.M.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Phylogeographic model selection using convolutional neural networks</article-title>. <source>Mol. Ecol. Resour</source>., <volume>21</volume>, <fpage>2661</fpage>–<lpage>2675</lpage>.<pub-id pub-id-type="pmid">33973350</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gower</surname><given-names>G.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Detecting adaptive introgression in human evolution using convolutional neural networks</article-title>. <source>eLife</source>, <volume>10</volume>, <fpage>e64669</fpage>.<pub-id pub-id-type="pmid">34032215</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Isildak</surname><given-names>U.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Distinguishing between recent balancing selection and incomplete sweep using deep neural networks</article-title>. <source>Mol. Ecol. Resour</source>., <volume>21</volume>, <fpage>2706</fpage>–<lpage>2718</lpage>.<pub-id pub-id-type="pmid">33749134</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kopp</surname><given-names>W.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Deep learning for genomics using janggu</article-title>. <source>Nat. Commun</source>., <volume>11</volume>, <fpage>3488</fpage>.<pub-id pub-id-type="pmid">32661261</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meisner</surname><given-names>J.</given-names></string-name>, <string-name><surname>Albrechtsen</surname><given-names>A.</given-names></string-name></person-group> (<year>2022</year>) <article-title>Haplotype and population structure inference using neural networks in whole-genome sequencing data</article-title>. <source>Genome Res</source>., <volume>32</volume>, <fpage>1542</fpage>–<lpage>1552</lpage>.<pub-id pub-id-type="pmid">35794006</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Montserrat</surname><given-names>D.M.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) Class-conditional VAE-GAN for local-ancestry simulation. In: <italic toggle="yes">The 14th Machine Learning in Computational Biology (MLCB) meeting.</italic><ext-link xlink:href="https://dblp.org/rec/journals/corr/abs-1911-13220.html" ext-link-type="uri">https://dblp.org/rec/journals/corr/abs-1911-13220.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="btac765-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Perez</surname><given-names>M.F.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Coalescent-based species delimitation meets deep learning: insights from a highly fragmented cactus system</article-title>. <source>Mol. Ecol. Resour</source>., <volume>22</volume>, <fpage>1016</fpage>–<lpage>1028</lpage>.<pub-id pub-id-type="pmid">34669256</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qin</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Deciphering signatures of natural selection via deep learning</article-title>. <source>Brief. Bioinformatics</source>, <volume>23</volume>. <pub-id pub-id-type="doi">10.1093/bib/bbac354</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac765-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Routhier</surname><given-names>E.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>keras_dna: a wrapper for fast implementation of deep learning models in genomics</article-title>. <source>Bioinformatics</source>, <volume>37</volume>, <fpage>1593</fpage>–<lpage>1594</lpage>.<pub-id pub-id-type="pmid">33135730</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sanchez</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Deep learning for population size history inference: design, comparison and combination with approximate Bayesian computation</article-title>. <source>Mol. Ecol. Resour</source>., <volume>21</volume>, <fpage>2645</fpage>–<lpage>2660</lpage>.<pub-id pub-id-type="pmid">32644216</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Torada</surname><given-names>L.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>ImaGene: a convolutional neural network to quantify natural selection from genomic data</article-title>. <source>BMC Bioinformatics</source>, <volume>20</volume>, <fpage>337</fpage>.<pub-id pub-id-type="pmid">31757205</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Automatic inference of demographic parameters using generative adversarial networks</article-title>. <source>Mol. Ecol. Resour</source>., <volume>21</volume>, <fpage>2689</fpage>–<lpage>2705</lpage>.<pub-id pub-id-type="pmid">33745225</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xue</surname><given-names>A.T.</given-names></string-name></person-group><etal>et al</etal>; <collab>Ag1000g Consortium</collab>. (<year>2021</year>) <article-title>Discovery of ongoing selective sweeps within anopheles mosquito populations using deep learning</article-title>. <source>Mol. Biol. Evol</source>., <volume>38</volume>, <fpage>1168</fpage>–<lpage>1183</lpage>.<pub-id pub-id-type="pmid">33022051</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yelmen</surname><given-names>B.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Creating artificial human genomes using generative neural networks</article-title>. <source>PLoS Genet</source>., <volume>17</volume>, <fpage>e1009303</fpage>.<pub-id pub-id-type="pmid">33539374</pub-id></mixed-citation>
    </ref>
    <ref id="btac765-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>An automated framework for efficiently designing deep convolutional neural networks in genomics</article-title>. <source>Nat. Mach. Intell</source>., <volume>3</volume>, <fpage>392</fpage>–<lpage>400</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
