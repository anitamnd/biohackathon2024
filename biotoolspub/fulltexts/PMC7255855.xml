<?properties open_access?>
<?subarticle report63640?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">F1000Res</journal-id>
    <journal-id journal-id-type="iso-abbrev">F1000Res</journal-id>
    <journal-id journal-id-type="pmc">F1000Research</journal-id>
    <journal-title-group>
      <journal-title>F1000Research</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2046-1402</issn>
    <publisher>
      <publisher-name>F1000 Research Limited</publisher-name>
      <publisher-loc>London, UK</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7255855</article-id>
    <article-id pub-id-type="doi">10.12688/f1000research.21642.2</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software Tool Article</subject>
      </subj-group>
      <subj-group>
        <subject>Articles</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Generalized EmbedSOM on quadtree-structured self-organizing maps</article-title>
      <fn-group content-type="pub-status">
        <fn>
          <p>[version 2; peer review: 2 approved]</p>
        </fn>
      </fn-group>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Kratochvíl</surname>
          <given-names>Miroslav</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Visualization</role>
        <role content-type="http://credit.casrai.org/">Writing – Original Draft Preparation</role>
        <role content-type="http://credit.casrai.org/">Writing – Review &amp; Editing</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7356-4075</contrib-id>
        <xref ref-type="corresp" rid="c1">a</xref>
        <xref ref-type="aff" rid="a1">1</xref>
        <xref ref-type="aff" rid="a2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Koladiya</surname>
          <given-names>Abhishek</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Investigation</role>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Resources</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Visualization</role>
        <role content-type="http://credit.casrai.org/">Writing – Review &amp; Editing</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7348-4048</contrib-id>
        <xref ref-type="aff" rid="a3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Vondrášek</surname>
          <given-names>Jiří</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Funding Acquisition</role>
        <role content-type="http://credit.casrai.org/">Project Administration</role>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <role content-type="http://credit.casrai.org/">Writing – Review &amp; Editing</role>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <aff id="a1"><label>1</label>Institute of Organic Chemistry and Biochemistry of the CAS, Prague, Czech Republic</aff>
      <aff id="a2"><label>2</label>Department of Software Engineering, Faculty of Mathematics and Physics, Charles University, Prague, Czech Republic</aff>
      <aff id="a3"><label>3</label>Institute of Hematology and Blood Transfusion, Prague, Czech Republic</aff>
    </contrib-group>
    <author-notes>
      <corresp id="c1">
        <label>a</label>
        <email xlink:href="mailto:miroslav.kratochvil@uochb.cas.cz">miroslav.kratochvil@uochb.cas.cz</email>
      </corresp>
      <fn fn-type="con">
        <p>M.K. designed and implemented the algorithms and wrote the manuscript. A.K. designed and documented the use-cases for the manuscript, and provided development feedback. J.V. supervised the project. All authors participated in preparing and approving the final version of the manuscript.</p>
      </fn>
      <fn fn-type="COI-statement">
        <p>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>19</day>
      <month>5</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>8</volume>
    <elocation-id>2120</elocation-id>
    <history>
      <date date-type="accepted">
        <day>12</day>
        <month>5</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright: © 2020 Kratochvíl M et al.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="f1000research-8-26529.pdf"/>
    <abstract>
      <p>EmbedSOM is a simple and fast dimensionality reduction algorithm, originally developed for its applications in single-cell cytometry data analysis. We present an updated version of EmbedSOM, viewed as an algorithm for landmark-directed embedding enrichment, and demonstrate that it works well even with manifold-learning techniques other than the self-organizing maps. Using this generalization, we introduce an inwards-growing variant of self-organizing maps that is designed to mitigate some earlier identified deficiencies of EmbedSOM output. Finally, we measure the performance of the generalized EmbedSOM, compare several variants of the algorithm that utilize different landmark-generating functions, and showcase the functionality on single-cell cytometry datasets from recent studies.</p>
    </abstract>
    <kwd-group kwd-group-type="author">
      <kwd>dimensionality reduction</kwd>
      <kwd>self-organizing maps</kwd>
      <kwd>single-cell cytometry</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="fund-1">
        <funding-source>Ministerstvo Školství, Mládeže a Tělovýchovy</funding-source>
        <award-id>ElixirCZLM2015047</award-id>
      </award-group>
      <award-group id="fund-2">
        <funding-source>Institute of Organic Chemistry and Biochemistry of the CAS</funding-source>
        <award-id>61388963</award-id>
        <award-id>e-INFRALM2018140</award-id>
      </award-group>
      <award-group id="fund-3">
        <funding-source>European Regional Development Fund</funding-source>
        <award-id>AIIHHP:CZ.02.1.01/0.0/0.0/16_025/0007428</award-id>
        <award-id>OPRDE</award-id>
        <award-id>MEYS</award-id>
      </award-group>
      <funding-statement>M.K. and J.V. were supported by ELIXIR CZ LM2015047 (MEYS).
A.K. was supported by European Regional Development Fund and the state budget of the Czech Republic (project AIIHHP: CZ.02.1.01/0.0/0.0/16_025/0007428, OP RDE, MEYS).
Funding for open access publication was provided by the Institute of Organic Chemistry and Biochemistry of the CAS (RVO), project number 61388963.
Computational resources were supplied by the project ``e-Infrastruktura CZ'' (e-INFRA LM2018140) provided within the program </funding-statement>
    </funding-group>
  </article-meta>
  <notes notes-type="version-changes">
    <sec sec-type="version-changes">
      <label>Revised</label>
      <title>Amendments from Version 1</title>
      <p>This version improves upon the main issues raised by the reviewers: We have added an useful comparison with other dimensionality reduction methods (results on a toy dataset can be compared in Figure 1, performance of the EmbedSOM implementation is compared with UMAP, tSNE and TriMap in Figure 2), and a slightly technical overview of the differences in a separate section. We have fixed several wording problems and corrected minor mistakes and difficulties throughout the text, mainly in the description of Wong dataset (mainly providing a cleaner explanation of the phenomenon with γδTCR T cells, noticed by the reviewers).</p>
    </sec>
  </notes>
</front>
<body>
  <sec sec-type="intro">
    <title>Introduction</title>
    <p>EmbedSOM is a dimensionality reduction (DR) algorithm for single-cell cytometry data, designed for high scalability, computational efficiency and performance
<sup><xref rid="ref-1" ref-type="bibr">1</xref></sup>. The design is based off FlowSOM
<sup><xref rid="ref-2" ref-type="bibr">2</xref></sup>, which utilizes unsupervised manifold learning by self-organizing maps (SOMs) to find structure in the high-dimensional data, and process the result into a meaningful and easily interpretable clustering of the dataset. So far, FlowSOM and SOMs in general seem to be the manifold learning and clustering method of choice for all kinds of cytometry based on protein-targeting antibodies, surpassing other clustering methods in precision, speed and scalability
<sup><xref rid="ref-3" ref-type="bibr">3</xref></sup>. EmbedSOM utilizes the same manifold learning method to extract information about the topology of an approximate manifold that describes the high-dimensional cell expression space, and uses it to quickly compute low-dimensional image of the cells that is suitable for visualization.</p>
    <p>In this work, we focus on fixing inconsistencies and problems of the first version of EmbedSOM: First, we describe an updated version of EmbedSOM that improves the approximation to achieve mathematical smoothness of the projection. The brief description of EmbedSOM provided in the original paper is supplemented here by fully commented pseudocode, in order to aid scrutinization and interpretation of the method. Second, we review EmbedSOM as a generalized function for enriching a projection of selected landmarks to a projection of entire spaces. We demonstrate this by replacing the original SOMs with less-demanding t-SNE on random landmarks. Additionally, we describe GQTSOM, a novel variant of growing self-organizing maps (GSOMs, described e.g. by Rauber
<italic>et al.</italic>
<sup><xref rid="ref-4" ref-type="bibr">4</xref></sup>) that was designed to alleviate precision and overcrowding problems of the original EmbedSOM. GQTSOMs utilize quad-tree space-partitioning structure to grow inwards, thus allowing the training algorithm to increase the resolution of manifold approximation on demand, and to benefit from the performance gain in early stages of training that is common to all GSOMs.</p>
    <p>The functionality of the new algorithm is showcased on datasets that were recently used for studying other DR techniques. We show the differences between individual variants of landmark-generating functions, and provide visualizations comparable to those produced by current state-of-art algorithms. Finally, we demonstrate how the dynamic resolution of GQTSOMs aids detection of various small cell populations and rare cell types.</p>
  </sec>
  <sec sec-type="methods">
    <title>Methods</title>
    <sec>
      <title>Landmark-directed embedding</title>
      <p>EmbedSOM projection can be viewed as an embedding enrichment method: From a set of landmarks in the high-dimensional space and a set of corresponding landmarks in the low-dimensional space, it produces a smooth function that maps all points from the higher-dimensional space to the low-dimensional space and preserves the relative neighborhoods of the landmarks. EmbedSOM was originally designed to work with simple SOM-originating landmarks, as shown in
<xref ref-type="fig" rid="f1">Figure 1</xref>.</p>
      <fig fig-type="figure" id="f1" orientation="portrait" position="anchor">
        <label>Figure 1. </label>
        <caption>
          <title>Overview of EmbedSOM interaction with landmarks on a toy dataset.</title>
          <p>Embedding process starts by reducing the input dataset (data flow is visualized as orange arrows) to landmarks (black arrows and dots) in high-dimensional (top row) and low-dimensional space (middle row). EmbedSOM quickly places the relatively large amount of individual input points into matching neighborhoods of the low-dimensional landmarks. The landmark-generating methods from left: A simple grid from SOM algorithm, a random selection of input points with 2-D topology reconstructed by t-SNE, and a GQTSOM-based grid. GQTSOM landmarks are labeled by their level in the quadtree. Visualizations from other methods
<sup><xref rid="ref-5" ref-type="bibr">5</xref>–
<xref rid="ref-8" ref-type="bibr">8</xref></sup> (bottom row) are presented with computation time (
<italic>t</italic>) for comparison. R code that produces the plots is available in Supplementary material.</p>
        </caption>
        <graphic xlink:href="f1000research-8-26529-g0000"/>
      </fig>
      <p>We will refer to the high- and low-dimensional landmarks as
<italic>L</italic> ϵ ℝ
<sup><italic>n</italic>×
<italic>D</italic></sup> and
<italic>l</italic> ϵ ℝ
<sup><italic>n</italic>×2</sup>. EmbedSOM embedding of a single high-dimensional point is achieved by reducing it to a collection of coordinates of its projections into subspaces that are generated by affine combinations of landmark pairs from
<italic>L</italic>, and reconstructing it in low-dimensional space by reversing the process with corresponding landmark pairs from
<italic>l</italic>.</p>
      <p>The procedure is detailed as
<xref ref-type="other" rid="A1">Algorithm 1</xref>. First, the algorithm chooses
<italic>k</italic> landmarks closest to
<italic>X</italic>, which are expected to give sufficient approximation. In lines 2–6 it computes scores for the
<italic>k</italic> landmarks. The affine projection of
<italic>X</italic> to a space defined by a pair of landmarks from
<italic>L</italic> is computed at line 12 as
<italic>d</italic>, its value is used to create a linear equation which has solutions at positions that would project to the same position
<italic>d</italic> in the affine space generated from corresponding landmarks in
<italic>l</italic>. After adding all parts of the approximation together, the linear system stored in
<italic>M</italic> is very unlikely to remain singular. The position of embedded point is then obtained by simply solving the linear equation of 2 variables. Alternatively, one can view the algorithm as a minimization of the total squared error in all projected
<italic>d</italic>:</p>
      <p>
        <disp-formula id="e1">
          <mml:math id="M1">
            <mml:mrow>
              <mml:munder>
                <mml:mrow>
                  <mml:mi>arg</mml:mi>
                  <mml:mo>⁡</mml:mo>
                  <mml:mi>min</mml:mi>
                  <mml:mo>⁡</mml:mo>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>x</mml:mi>
                  <mml:mo>ϵ</mml:mo>
                  <mml:msup>
                    <mml:mi>ℝ</mml:mi>
                    <mml:mn>2</mml:mn>
                  </mml:msup>
                </mml:mrow>
              </mml:munder>
              <mml:mstyle displaystyle="true">
                <mml:munder>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>,</mml:mo>
                    <mml:mi>j</mml:mi>
                  </mml:mrow>
                </mml:munder>
                <mml:mrow>
                  <mml:msub>
                    <mml:mi>s</mml:mi>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mo>,</mml:mo>
                      <mml:mi>j</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mstyle>
              <mml:msup>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi>d</mml:mi>
                        <mml:mrow>
                          <mml:mi>i</mml:mi>
                          <mml:mo>,</mml:mo>
                          <mml:mi>j</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mo>–</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mrow>
                            <mml:mo>〈</mml:mo>
                            <mml:mrow>
                              <mml:mi>x</mml:mi>
                              <mml:mo>–</mml:mo>
                              <mml:msub>
                                <mml:mi>l</mml:mi>
                                <mml:mi>i</mml:mi>
                              </mml:msub>
                              <mml:mo>,</mml:mo>
                              <mml:msub>
                                <mml:mi>l</mml:mi>
                                <mml:mi>j</mml:mi>
                              </mml:msub>
                              <mml:mo>–</mml:mo>
                              <mml:msub>
                                <mml:mi>l</mml:mi>
                                <mml:mi>i</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                            <mml:mo>〉</mml:mo>
                          </mml:mrow>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mrow>
                            <mml:mo>〈〈</mml:mo>
                            <mml:mrow>
                              <mml:msub>
                                <mml:mi>l</mml:mi>
                                <mml:mi>j</mml:mi>
                              </mml:msub>
                              <mml:mo>–</mml:mo>
                              <mml:msub>
                                <mml:mi>l</mml:mi>
                                <mml:mi>i</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                            <mml:mo>〉〉</mml:mo>
                          </mml:mrow>
                        </mml:mrow>
                      </mml:mfrac>
                    </mml:mrow>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:mrow>
                <mml:mn>2</mml:mn>
              </mml:msup>
            </mml:mrow>
          </mml:math>
        </disp-formula>
      </p>
      <boxed-text id="A1" position="float" orientation="portrait">
        <label>Algorithm 1. </label>
        <caption>
          <title>EmbedSOM projection from
<italic>D</italic>-dimensional Euclidean space to 2-D using
<italic>n</italic> landmarks.</title>
        </caption>
        <p>  1:  
<bold>procedure</bold> E
<sc>mbed</sc>SOM(
<italic>X</italic> ϵ ℝ
<sup><italic>n</italic></sup>,
<italic>L</italic> ϵ ℝ
<sup><italic>n</italic>×
<italic>D</italic></sup>,
<italic>l</italic> ϵ ℝ
<sup><italic>n</italic>×2</sup>,
<italic>k</italic> ϵ {4 . . .
<italic>n</italic>},
<italic>m</italic> &gt; 0,
<italic>a</italic> &gt; 0) </p>
        <p>  2:        
<italic>c</italic> ← a sequence of
<italic>c
<sub>i</sub></italic> = 〈〈
<italic>X</italic> −
<italic>L
<sub>i</sub></italic>〉〉 for
<italic>i</italic> ϵ {1 . . .
<italic>n</italic>}</p>
        <p>  3:        
<italic>o</italic> ← indexes of
<italic>k</italic> smallest elements of
<italic>c</italic> in order</p>
        <p>  4:        
<italic>μ</italic> ←
<inline-formula><mml:math id="M2"><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>⋅</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>                                                               ▷ estimate the distribution of landmark distances</p>
        <p>  5:        
<italic>σ</italic> ←
<inline-formula><mml:math id="M3"><mml:mrow><mml:msqrt><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>–</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>
</p>
        <p>  6:        
<italic>S</italic> ← a sequence of
<inline-formula><mml:math id="M4"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:mrow><mml:mi>b</mml:mi><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>μ</mml:mi><mml:mo>–</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>–</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>–</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>⋅</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for
<italic>i</italic> ϵ {1 . . .
<italic>k</italic>}        ▷ compute scores</p>
        <p>  7:        
<inline-formula><mml:math id="M5"><mml:mrow><mml:mi>M</mml:mi><mml:mo>←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mrow><mml:mspace width="0.3em"/><mml:mo>|</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mspace width="0.3em"/><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="0.3em"/><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>                                                                  ▷ accumulator for the linear equation system</p>
        <p>  8:       
<bold>for</bold>
<italic>i′</italic> ϵ {1 . . .
<italic>k</italic> − 2}
<bold>do</bold>                                                  ▷ iterate through pairs of
<italic>k</italic> − 1 closest landmarks</p>
        <p>  9:            
<bold>for</bold> 
<italic>j′</italic> ϵ {
<italic>i</italic> + 1 . . .
<italic>k</italic> − 1}
<bold>do</bold>
</p>
        <p>10:                 
<italic>i</italic> ←
<italic>o</italic>(
<italic>i</italic>′)                                                                            ▷ obtain non-permuted landmark indexes</p>
        <p>11:                 
<italic>j</italic> ←
<italic>o</italic>(
<italic>j</italic>′)</p>
        <p>12:                 
<inline-formula><mml:math id="M6"><mml:mrow><mml:mi>d</mml:mi><mml:mo>←</mml:mo><mml:mfrac><mml:mrow><mml:mo>〈</mml:mo><mml:mi>X</mml:mi><mml:mo>–</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mtext>,</mml:mtext><mml:msub><mml:mi>L</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>–</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>〉</mml:mo></mml:mrow><mml:mrow><mml:mo>〈〈</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>–</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>〉〉</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>                                                                 ▷ projection position in the affine space</p>
        <p>13:                 
<italic>h</italic> ←
<italic>l
<sub>j</sub></italic> −
<italic>l
<sub>i</sub></italic>                                                                                                                ▷ helper values</p>
        <p>14:                 
<inline-formula><mml:math id="M7"><mml:mrow><mml:mi>y</mml:mi><mml:mo>←</mml:mo><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mo>〈</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>〉</mml:mo></mml:mrow><mml:mrow><mml:mo>〈〈</mml:mo><mml:mi>h</mml:mi><mml:mo>〉〉</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>
</p>
        <p>15:                 
<inline-formula><mml:math id="M8"><mml:mrow><mml:mi>s</mml:mi><mml:mo>←</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mtext>(</mml:mtext><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mo>〈〈</mml:mo><mml:mi>h</mml:mi><mml:mtext>〉〉</mml:mtext></mml:mrow><mml:mtext>)</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mo>–</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msup><mml:mo>⋅</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>–</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msup><mml:mo>⋅</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:msup><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mtext>,</mml:mtext></mml:mrow></mml:math></inline-formula>                                    ▷ score for this pair of landmarks</p>
        <p>16:                 
<inline-formula><mml:math id="M9"><mml:mrow><mml:mi>M</mml:mi><mml:mo>←</mml:mo><mml:mi>M</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:mspace width="0.1em"/><mml:mo>⋅</mml:mo><mml:mspace width="0.1em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>h</mml:mi><mml:mo>⋅</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:mo>〈〈</mml:mo><mml:mi>h</mml:mi><mml:mo>〉〉</mml:mo></mml:mrow></mml:mfrac><mml:mrow><mml:mspace width="0.3em"/><mml:mo>|</mml:mo><mml:mspace width="0.3em"/><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>y</mml:mi><mml:mo>⋅</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>y</mml:mi><mml:mo>⋅</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>                                   ▷ add this approximation to the linear system</p>
        <p>17:            
<bold>end for</bold>
</p>
        <p>18:       
<bold>end for</bold>
</p>
        <p>19:       
<bold>return</bold> solution (
<italic>x</italic>
<sub>1</sub>,
<italic>x</italic>
<sub>2</sub> ) of the linear system in
<italic>M</italic>
</p>
        <p>20:
<bold>end procedure</bold>
</p>
      </boxed-text>
      <p>Since the squared term is linear in
<italic>x</italic>, the inner function is a quadratic form that can be minimized algebraically by finding zero of its derivation. This procedure gives the formulas used in the algorithm.</p>
      <p>The algorithm can be easily expanded to embedding into general
<italic>P</italic>-dimensional spaces by taking the low-dimensional landmarks
<italic>l</italic> from ℝ
<sup><italic>n</italic>×
<italic>P</italic></sup>, increasing the size of the matrix
<italic>M</italic> for a linear equation of
<italic>P</italic> variables, and solving a larger linear system at the end.</p>
      <p>Notably, the initial reduction of the input data to one-dimensional projections to affine spaces (
<italic>d</italic> in the algorithm) prevents various complications from fitting the high-dimensional
<italic>distances</italic> into low-dimensional space, avoiding many problems that arise from dimensionality overhead in other DR algorithms. Similar approach has been taken e.g. by TriMap
<sup><xref rid="ref-5" ref-type="bibr">5</xref></sup>, where the transferred information is reduced to mere binary relations between point distances.</p>
      <p><bold>Embedding parameters</bold> The embedding procedure admits several tunable parameters:
<italic>k</italic> is the number of nearest landmarks used for the approximation,
<italic>m</italic> &gt; 0 is an arbitrary parameter that selects the steepness of score decay for distance order approaching
<italic>k</italic>,
<italic>b</italic> &gt; 0 chooses the steepness of score decay for landmarks far from
<italic>X</italic>, and
<italic>a</italic> lowers the score of approximations to pairs of relatively far low-dimensional landmarks.</p>
      <p>Parameter
<italic>m</italic> is specifically designed to lower the score of landmarks with distances that approach
<italic>k</italic>-closest landmark. As a result, small changes in the input point
<italic>X</italic> can not cause sharp changes in the scores assigned to individual parts of the approximation. Consequently, EmbedSOM function is smooth in
<italic>X</italic>.</p>
      <p>Values of parameters
<italic>k</italic>,
<italic>m</italic>, and
<italic>a</italic> must be chosen to avoid singularities and near-singularities when computing the final approximation, which may happen if the set of
<italic>s</italic>
<sub><italic>i</italic>,
<italic>j</italic></sub> contains insufficient number of higher-than-negligible scores. That may be caused mainly by setting too low values of
<italic>k</italic> or
<italic>m</italic>, or too high value of
<italic>b</italic>. Argument setting of
<inline-formula><mml:math id="M10"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≃</mml:mo><mml:msqrt><mml:mrow><mml:mo>|</mml:mo><mml:mi>L</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>,
<italic>m</italic> = 10,
<italic>b</italic> =
<italic>e</italic>
<sup>−1</sup> and
<italic>a</italic> = 1 worked well in a majority of tested use cases and can be considered a good default.</p>
      <p><bold>Embedding complexity</bold> To compute a
<italic>P</italic>-dimensional projection of a single point from a
<italic>D</italic>-dimensional space, EmbedSOM projection conducts the following operations: |
<italic>L</italic>| measurements of distances in high-dimensional space, sorting the
<italic>k</italic> smallest elements of the distance vector of size |
<italic>L</italic>|, and conversion of
<italic>k</italic> distances to scores. On the landmark pairs, it conducts at most
<italic>k</italic>
<sup>2</sup> computations of scores
<italic>s</italic>, the same number of computations of
<italic>d</italic>
<sub><italic>i</italic>,
<italic>j</italic></sub> from 2 dot-products in high-dimensional space, and computation of a partial
<italic>P</italic>-by-(
<italic>P</italic> + 1) matrix for solving the linear system in ℝ
<sup><italic>P</italic></sup>. Finally, the linear system is solved using Cramer’s rule. The total of computation times is thus, in respective order,</p>
      <p>
        <disp-formula>
          <mml:math id="M11">
            <mml:mrow>
              <mml:mi/>
              <mml:mrow>
                <mml:mo>(</mml:mo>
                <mml:mrow>
                  <mml:mi>D</mml:mi>
                  <mml:mo>⋅</mml:mo>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                    <mml:mi>L</mml:mi>
                    <mml:mo>|</mml:mo>
                  </mml:mrow>
                </mml:mrow>
                <mml:mo>)</mml:mo>
              </mml:mrow>
              <mml:mtext> </mml:mtext>
              <mml:mo>+</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:mi/>
              <mml:mrow>
                <mml:mo>(</mml:mo>
                <mml:mrow>
                  <mml:mi>log</mml:mi>
                  <mml:mo>⁡</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mi>k</mml:mi>
                  <mml:mo>⋅</mml:mo>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                    <mml:mi>L</mml:mi>
                    <mml:mo>|</mml:mo>
                  </mml:mrow>
                </mml:mrow>
                <mml:mo>)</mml:mo>
              </mml:mrow>
              <mml:mtext> </mml:mtext>
              <mml:mo>+</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:msup>
                <mml:mi>k</mml:mi>
                <mml:mn>2</mml:mn>
              </mml:msup>
              <mml:mtext> </mml:mtext>
              <mml:mrow>
                <mml:mo>(</mml:mo>
                <mml:mrow>
                  <mml:mi/>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mn>1</mml:mn>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>+</mml:mo>
                  <mml:mi/>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mi>D</mml:mi>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                  <mml:mo>+</mml:mo>
                  <mml:mi/>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mrow>
                      <mml:msup>
                        <mml:mi>P</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msup>
                    </mml:mrow>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:mrow>
                <mml:mo>)</mml:mo>
              </mml:mrow>
              <mml:mtext> </mml:mtext>
              <mml:mo>+</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:mi/>
              <mml:mrow>
                <mml:mo>(</mml:mo>
                <mml:mrow>
                  <mml:mi>P</mml:mi>
                  <mml:mo>!</mml:mo>
                </mml:mrow>
                <mml:mo>)</mml:mo>
              </mml:mrow>
              <mml:mo>.</mml:mo>
            </mml:mrow>
          </mml:math>
        </disp-formula>
      </p>
      <p>Assuming the default parameter setting and
<italic>P</italic> ϵ {2, 3}, this complexity sums to (
<italic>D</italic> · |
<italic>L</italic>|). The procedure can be trivially repeated for any number of input points.</p>
      <p><bold>Different distance measures</bold> We have assumed that the metric used in both high-dimensional and low-dimensional spaces is Euclidean. Generally, EmbedSOM behaves well even if the distance measure used for the scoring function is swapped for any function that acts as a metric on vector spaces, including the popular
<italic>L</italic>
<sup>1</sup> and
<italic>L</italic>
<sup>∞</sup> metrics.</p>
      <p>Nevertheless, the computation of ‘projections’ using dot-products may then be viewed as a rather questionable reinterpretation of the point coordinates in an inner product space. Fortunately, the minimal-distance projection to a fixed subspace is a linear operator under both
<italic>L</italic>
<sup>1</sup> and
<italic>L</italic>
<sup>∞
<xref rid="ref-9" ref-type="bibr">9</xref></sup>, which is sufficient for EmbedSOM computation even without requiring the inner product property.</p>
      <p><bold>Relation to other dimensionality-reduction algorithms</bold> The currently used non-linear dimensionality reduction methods are most often constructed from optimization tasks that optimize the embedding of the data points into the low-dimensional space, attempting to preserve selected properties from the high-dimensional space. The methods include t-SNE (optimizes Kullback-Leibler divergence between transformed distances in high-dimensional
<italic>k</italic>-neighborhoods
<sup><xref rid="ref-5" ref-type="bibr">5</xref></sup>), UMAP (optimizes the cross-entropy between topological representations of the data
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup>), TriMap (optimizes the preservation of distance ordering in triplets of data points
<sup><xref rid="ref-7" ref-type="bibr">7</xref></sup>, MDS (optimizes the mean squared error between dissimilarity and distance matrices), isomap (optimizes walk-like distances on k-neighborhood graph used as dissimilarities in MDS), PHATE (uses a dissimilarity based on heat transfer potential in MDS
<sup><xref rid="ref-8" ref-type="bibr">8</xref></sup>), Kamada-Kawaii algorithm (uses simulation to optimize a spring model of a graph) and many others. Performance of such methods is most impacted by the necessity to examine a large subset of the
<inline-formula><mml:math id="M12"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mi>n</mml:mi></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> relations between the
<italic>n</italic> input data points.</p>
      <p>This computationally expensive optimization can be traded off by first creating a smaller model of the data, and using it to find approximate embedding of the data points. This is used e.g. by scvis, which trains an autoencoder to represent the data by 2 variables; using the variables as the embedding
<sup><xref rid="ref-10" ref-type="bibr">10</xref></sup>. The simplification in the model and resulting approximation may produce suboptimal results especially in ‘local’ microstructure of the data, but the strict separation brings more beneficial properties: The necessary generalization prevents overfitting and thus improves the applicability of the model to newly incoming data. Performance of the algorithm is usually improved, because fitting of the data to the constant trained model can be trivially accelerated by parallelization.</p>
      <p>In EmbedSOM, the model consists of the pairs of the corresponding high- and low-dimensional landmarks (
<italic>L</italic> and
<italic>l</italic>) created by any suitable algorithm (including SOMs, autoencoders, and any of the optimization-based dimensionality reduction described above); fitting of the data into the model is then performed by minimizing the total projection error for each data point separately.</p>
      <p>The geometrical interpretation of EmbedSOM bears similarity to linear dimensionality reduction methods — the projection is locally linear, and the non-linearity is caused only by the non-linear weighting of landmark influences (scores
<italic>S</italic> in
<xref ref-type="other" rid="A1">Algorithm 1</xref>). With SOMs, the result can thus be viewed as many local PCA projections smoothly stitched together. For extreme parameter settings (4 landmarks generated by a 2×2 SOM,
<italic>k</italic> = |
<italic>L</italic>| = 4,
<italic>a</italic> =
<italic>b</italic> = 0 and
<italic>m</italic> = ∞), EmbedSOM produces results almost identical to PCA.</p>
    </sec>
    <sec>
      <title>Generalized landmarks and GQTSOMs</title>
      <p>While the SOMs are a great method to generate landmarks
<italic>L</italic> and
<italic>l</italic> that carry various beneficial properties that simplify human interpretation of the result (notably the regularity of
<italic>l</italic>), other methods are admissible as well, as long as they can cover the input space sufficiently by
<italic>L</italic> and generate the corresponding landmarks
<italic>l</italic> in the low-dimensional output space so that the topology is similar to
<italic>L</italic>.</p>
      <p>For example, the embedding process can be simplified to a great extent by completely removing SOMs: Instead of constructing
<italic>L</italic> in a complicated way so that it reflects the input space topology, we can take only a small random sample of input points as the landmarks, and use a general DR method to find its topology and arrange landmarks
<italic>l</italic> in a matching way, as shown in
<xref ref-type="fig" rid="f1">Figure 1</xref> on an example with t-SNE. While this is often sufficient, for the purposes of embedding it is more beneficial to find a smaller set of landmarks that provide better description of the various features in the input space than the random sampling.</p>
      <p>Many variants of the SOM algorithm have been created to optimize this metric: For example, the Growing SOMs (GSOMs) by Dittenbach
<italic>et al.</italic>
<sup><xref rid="ref-11" ref-type="bibr">11</xref></sup>, start with a simple 2×2 SOM grid, and dynamically add new SOM grid vertices at the SOM perimeter only if it is necessary to keep the total quantization error low. A hierarchical variant of GSOM called GHSOM introduced by Rauber
<italic>et al.</italic>
<sup><xref rid="ref-4" ref-type="bibr">4</xref></sup> aims to improve the description of small details in the input data space that were not described sufficiently by GSOMs. Depending on the heuristic, the vertices of GHSOM grid are converted to small independent versions of GHSOMs, which map the corresponding local parts of the input space; this continues recursively to create a layered structure of SOMs that describe increasingly fine and subtle details in the data.</p>
      <p><bold>GQTSOMs</bold> Although the GHSOMs improve the classification of small-scale features in the datasets, the hypertree structure complicates their use as landmarks for planar visualization with EmbedSOM. We propose the Growing QuadTree-structured SOMs (GQTSOMs) to alleviate this problem: The GQTSOMs grow by recursively splitting the nodes to form a hypertree, but unlike GHSOMs the hypertree shape is restricted to a quadtree, which possesses straightforward interpretation as a 2-dimensional structure
<sup><xref rid="ref-12" ref-type="bibr">12</xref></sup>.</p>
      <p>The nodes in GQTSOMs are identified by their position and depth in the quadtree, represented as an integer triple (
<italic>L</italic>,
<italic>x</italic>,
<italic>y</italic>). The corresponding 2-dimensional coordinates are obtained as (2
<italic>x</italic> + 1, 2
<italic>y</italic> + 1) ⋅ 2
<sup>−
<italic>L</italic></sup>. Initial nodes in training occupy positions on a regular grid with
<italic>L</italic> = 0. Upon growing, a node (
<italic>L</italic>,
<italic>x</italic>,
<italic>y</italic>) is split into 4 nodes identified as (
<italic>L</italic> +1, 2
<italic>x</italic>, 2
<italic>y</italic>), (
<italic>L</italic> +1, 2
<italic>x</italic> +1, 2
<italic>y</italic>), (
<italic>L</italic> +1, 2
<italic>x</italic> +1, 2
<italic>y</italic> +1), and (
<italic>L</italic> +1, 2
<italic>x</italic>, 2
<italic>y</italic> +1).
<xref ref-type="fig" rid="f1">Figure 1</xref> shows an example of 3-level GQTSOM in a 2-dimensional space, where the initial 3×3 SOM grew 7 times to produce 30 landmarks.</p>
      <p>GQTSOM training proceeds by batches as in the usual batch SOM training. After each epoch, several nodes with greatest position change in the input data space are split, so that the total number of nodes grows linearly during the whole training. Initial positions for the new nodes are interpolated from the topological SOM neighborhood, using the same neighborhood function as for training the SOM (e.g. a Gaussian). To avoid overcrowding of the map by small nodes and promote their specialization to fine details, the nodes are penalized by a factor of
<italic>L</italic>
<sup>−1</sup> in the growing heuristic, and by a factor of 4
<sup><italic>L</italic></sup> applied to their neighborhood volume in both input space and SOM space.</p>
    </sec>
    <sec>
      <title>Implementation</title>
      <p>The current version of EmbedSOM is available as R package
<monospace>EmbedSOM</monospace> from
<ext-link ext-link-type="uri" xlink:href="http://github.com/exaexa/EmbedSOM">http://github.com/exaexa/EmbedSOM</ext-link>, together with the customized versions of SOM and GQTSOM algorithms. The implementations are conducted in C++ independent of the R wrapping, and can be reused in other environments. The integration into R serves mostly as a bridge to the large number of cytometry-oriented packages in the ecosystem.</p>
      <p>Low-level implementation has provided several ways to improve the performance of the algorithms when compared to the original implementation: For example, cache-efficient version of the SOM training has improved the performance by up to 15× on SOMs larger than 40×40; SIMD-based acceleration of the vector operations by up to 4×, and parallelization of the batch SOM training and embedding by a factor roughly equivalent to the number of used CPUs.</p>
      <p>Overall, the computation time required for typical datasets was reduced by a factor greater than 10× on commonly available hardware, and often more than 30× in case of processing complicated datasets using very large SOMs on highly parallel hardware.</p>
    </sec>
    <sec>
      <title>Operation</title>
      <p>For single-cell analysis, EmbedSOM is best used from R environment; the package can be downloaded from GitHub using R command
<monospace>devtools::install_github('exaexa/EmbedSOM')</monospace>. The package installation will automatically compile the code that uses the SIMD capabilities if they are enabled on the target platform.</p>
      <p>Generally, the SOM and embedding process can be executed on any real matrix with individual data points in rows, and parameters in columns. This expectation is consistent with many other DR or clustering packages, including
<monospace>FlowSOM</monospace>,
<monospace>Rtsne</monospace> and
<monospace>umap</monospace>. For example, a user may obtain an embedding of the Iris dataset as such:</p>
      <p>
        <preformat>
          <styled-content style="font-size:15px;color:#000000;">library(EmbedSOM)                                                
d &lt;- iris[,1:4]                                                    
map &lt;- SOM(d)                                                     
e &lt;- EmbedSOM(map=map, data=d)                                     </styled-content>
        </preformat>
      </p>
      <p>In the code, the landmarks are first created using a SOM and saved in the
<monospace>map</monospace>, which is then passed to the
<monospace>EmbedSOM</monospace> function that produces the final 2-column matrix
<monospace>e</monospace> with embedded coordinates. These can be plotted e.g. using the standard
<monospace>plot</monospace> function.</p>
      <p>On data larger than Iris dataset, GQTSOMs may be used to generate the landmarks and a
<monospace>map</monospace> usable with
<monospace>EmbedSOM</monospace> function in a similar way:</p>
      <p>
        <preformat>
          <styled-content style="font-size:15px;color:#000000;">map &lt;- GQTSOM(d, target_codes=500, parallel=T)                   </styled-content>
        </preformat>
      </p>
      <p>Here,
<monospace>target_codes</monospace> chooses the desired final number of the landmarks in the fully grown SOM, and parameter
<monospace>parallel=T</monospace> allows the computation to use multiple available CPUs. Functions
<monospace>SOM</monospace> and
<monospace>EmbedSOM</monospace> support parallelization as well, using the same parameter.</p>
      <p>Other DR methods may create the landmarks. For example, the following code generates a map object with 500 landmarks projected with t-SNE, suitable for t-SNE-directed embedding:</p>
      <p>
        <preformat>
          <styled-content style="font-size:15px;color:#000000;">library(Rtsne)       
landmark_idx &lt;- sample(nrow(d) , 500)         
map &lt;- list(codes=d[landmark_idx,], grid=Rtsne(d[landmark_idx,])$Y)</styled-content>
        </preformat>
      </p>
      <p>The parameters of the SOM, GQTSOM and EmbedSOM functions are extensively documented in the supplied R manual pages.</p>
    </sec>
  </sec>
  <sec>
    <title>Use cases</title>
    <p>The primary purpose of EmbedSOM is to produce quickly available and highly comprehensible data visualization in situations where processing speed and efficiency is critical. The embedding time of the demonstration datasets was measured on an AMD Ryzen 7 2700U CPU with 16GB of RAM running Debian Linux (Bullseye), R version 3.6.2 compiled with gcc version 9.3; the timing is reported in the corresponding figures as
<italic>t</italic>, together with number of cells (
<italic>n</italic>) and landmarks (|
<italic>L</italic>|). Comparison of embedding speed with other popular dimensionality-reduction methods can be seen in
<xref ref-type="fig" rid="f2">Figure 2</xref>. As the main result, the measurements show that a high-quality visualization of a data file from a common experiment (around 300 thousand cells) can be obtained in less than 10 seconds using common office hardware.</p>
    <p>Here, we demonstrate EmbedSOM functionality on two use-cases: First, using the described variants of landmark-generating functions, we reproduced the visualizations by Becht
<italic>et al</italic>.
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup> of a dataset that maps specific trafficking and cytokine signatures of human T cells across tissues, created by Wong
<italic>et al</italic>.
<sup><xref rid="ref-13" ref-type="bibr">13</xref></sup>. Second, we visualized a human gastrointestinal disorders dataset by van Unen
<italic>et al</italic>.
<sup><xref rid="ref-14" ref-type="bibr">14</xref></sup> using GQTSOMs, showing that EmbedSOM provides a viable alternative to the semi-interactive analysis of rare cell types using the HSNE algorithm
<sup><xref rid="ref-15" ref-type="bibr">15</xref></sup>.</p>
    <sec>
      <title>Alternative landmark-generating methods improve visualization</title>
      <p>To visualize the Wong dataset, we have run EmbedSOM algorithm with the SOM landmarks, t-SNE generated landmarks, and GQTSOM-generated landmarks. As seen in
<xref ref-type="fig" rid="f2">Figure 2</xref>, the original EmbedSOM implementation has managed to separate and visualize both the different cell types and their layout according to source organ. However, the result may seem unsatisfactory due to overcrowding and loss of both detail and global layout, especially when compared to UMAP visualizations of the same dataset [
<xref rid="ref-6" ref-type="bibr">6</xref>, Figure 1a,b]. Despite the overcrowding, it is still possible to identify clusters of CD69
<sup>+</sup>CD103
<sup>+</sup> Trms (resident-memory T cells) in all organs except cord blood, and naive (CD69
<sup>+</sup>CD45RA
<sup>+</sup>), central memory (CCR7
<sup>+</sup>CD62L
<sup>+</sup>) and effector memory T cells (CD45RA
<sup>–</sup> CD45RO
<sup>+</sup>CCR7
<sup>–</sup>CD62L
<sup>–</sup>) within both CD4 and CD8 T cell types; this is in agreement with findings of van Unen
<italic>et al.</italic> [
<xref rid="ref-14" ref-type="bibr">14</xref>, Figure 3a,b]. Plots of all marker expressions are available as
<italic>Extended data</italic>.</p>
      <fig fig-type="figure" id="f2" orientation="portrait" position="anchor">
        <label>Figure 2. </label>
        <caption>
          <title>Performance of EmbedSOM variants compared with other dimensionality reduction methods.</title>
          <p>The speed is represented in cells per second. EmbedSOM-based algorithms show almost perfect linear scaling with growing dataset size, and even minor speed improvements when sufficient data is available for saturating the parallel computation. As expected from their asymptotic complexities, performance of UMAP, TriMap and t-SNE decreased with additional data. t-SNE was not executed on datasets larger than 50 thousand cells because of time constrains.</p>
        </caption>
        <graphic xlink:href="f1000research-8-26529-g0001"/>
      </fig>
      <p>Improved methods of landmark positioning have successfully alleviated both overcrowding and layout problems. In particular, the layout of MAIT (mucosal-associated invariant T) and
<italic>γδ</italic> T cells in the embedding with t-SNE-generated landmarks reflects the expected properties of cell populations, and the individual population clusters are clearly separated by low-density areas with intermediate cell states and noise. The usefulness of the smoothness property can be observed on the cluster of
<italic>γδ</italic> T cells, where EmbedSOM shows a similarity of the gut-originating part of
<italic>γδ</italic> T cells to both gut-originating CD8
<sup>+</sup> T cells and other types of
<italic>γδ</italic> T cells, even though this is neglected by the underlying t-SNE. In comparison, this connection is preserved by all tested types of SOMs, but neglected by both plain t-SNE and UMAP, which show the population separated to 3 resp. 2 separate clusters [
<xref rid="ref-6" ref-type="bibr">6</xref>, Figure 1a]. The embedding based on GQTSOM landmarks has provided similar global layout of the output as the one with t-SNE landmarks, additionally capturing the continuity of
<italic>γδ</italic> T cell cluster and its similarity to MAIT and NK cells, and providing separation of individual clusters differentiated by tissue of origin comparable to that of UMAP. Compared to the SOM used with the original EmbedSOM approach, GQTSOM generates a smaller amount of more precise landmarks, which resulted in significant computation speed increase (around 50%) and better description of the small and rare cell populations by landmarks. In particular, the small subpopulations of
<italic>γδ</italic> T cells were assigned roughly twice the number of landmarks by GQTSOM than by the standard SOM, which resulted in spatially correct separation of the cell subtypes in the embedding.</p>
    </sec>
    <sec>
      <title>GQTSOM landmarks improve display of rare cell types</title>
      <p>We showcase the ability of GQTSOM landmark generation method to capture and display various rare cell types using a dataset by van Unen
<italic>et al.</italic>
<sup><xref rid="ref-14" ref-type="bibr">14</xref></sup> The dataset was created as such: A total of 5.2 million single cells were collected from duodenum biopsies, rectum biopsies, perianal fistulas, and PBMC from patients undergoing various gastrointestinal disorders and healthy individuals (as controls). The gastrointestinal disorders included celiac disease (CeD), refractory celiac disease type-II (RCDII), enteropathy associated T-cell lymphoma type II (EATLII), and Crohn’s disease. Cells were stained using 32 metal conjugated monoclonal antibodies to identify cells within the innate and adaptive immune system. This dataset was later reanalyzed by van Unen
<italic>et al.</italic>
<sup><xref rid="ref-15" ref-type="bibr">15</xref></sup> using a hierarchical version of t-SNE algorithm called HSNE, showing that the hierarchical dissection of the data was able to identify several rare cell types within the innate lymphoid cell (ILC) compartment.</p>
      <p>For the purpose of demonstration, we preprocessed the same dataset by removing debris, doublets and dead cells based on simple thresholds on the DNA, Event length and Viability parameters. The 32 antibody markers of the 4.14 million cleaned cells were then transformed by hyperbolic arcsine and used to train the GQTSOM and produce an embedding. The result in
<xref ref-type="fig" rid="f4">Figure 4</xref> allows easy observation of both the ILC compartment and the CD4
<sup>+</sup> T cell subset, corresponding to the observations produced by second-level HSNE [
<xref rid="ref-15" ref-type="bibr">15</xref>, Figures 3 and 5]. Additionally, the embedding shows presence of many clusters from lower levels of the hierarchical dissection: In the figure, it is possible to identify clusters of CD4
<sup>+</sup>CD28
<sup>–</sup>CCR7
<sup>–</sup>CD56
<sup>–</sup> and CD4
<sup>+</sup>CD28
<sup>–</sup>CCR7
<sup>–</sup>CD56
<sup>+</sup> rare cell types within the CD4
<sup>+</sup> compartment, and of the CD127
<sup>–</sup>CD45RA
<sup>–</sup>CD56
<sup>partial</sup> cluster within the ILC (CD7
<sup>+</sup>CD3
<sup>–</sup>) compartment. These clusters were identified by HSNE at 4
<sup>th</sup> resp. 3
<sup>rd</sup> levels of dissection [
<xref rid="ref-15" ref-type="bibr">15</xref>, Figures 5b and 3c]. Recently, Belkina
<italic>et al.</italic>
<sup><xref rid="ref-16" ref-type="bibr">16</xref></sup> showed that the opt-SNE algorithm can additionally identify CD4
<sup>+</sup>CD28
<sup>–</sup>CCR7
<sup>+</sup>CD56
<sup>–</sup> rare cell type, which is also clearly separated by the GQTSOM-based embedding, using much less computational resources than optSNE.</p>
      <fig fig-type="figure" id="f3" orientation="portrait" position="anchor">
        <label>Figure 3. </label>
        <caption>
          <title>Comparison of EmbedSOM visualizations of the Wong dataset using different landmarks.</title>
          <p>Top row: cells embedded using 3 different landmark-generating methods, colored by the tissue of sample origin. Middle row: The same embedding colored by major cell types. The colors used for annotation are purposefully reproduced from the article of Becht
<italic>et al.</italic>
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup> to simplify comparison. Bottom row: visualizations of the low-dimensional landmark images, colored by their corresponding marker expressions.</p>
        </caption>
        <graphic xlink:href="f1000research-8-26529-g0002"/>
      </fig>
      <fig fig-type="figure" id="f4" orientation="portrait" position="anchor">
        <label>Figure 4. </label>
        <caption>
          <title>Display of clusters of rare cell types in GQTSOM-based embedding.</title>
          <p>Top left: Overview of the cleaned and embedded Unen dataset, colored by expression of main cell lineage markers. The contour based on Gaussian difference is added for easier identification of changes in cell density. Labels mark the rare cell types identified by van Unen
<italic>et al</italic>.
<sup><xref rid="ref-15" ref-type="bibr">15</xref></sup>, Belkina
<italic>et al</italic>.
<sup><xref rid="ref-16" ref-type="bibr">16</xref></sup>: (a) CD4
<sup>+</sup>CD28
<sup>–</sup>CCR7
<sup>+</sup>, (b) CD4
<sup>+</sup>CD28
<sup>–</sup>CCR7
<sup>–</sup>CD56
<sup>–</sup>, (c) CD4
<sup>+</sup>CD28
<sup>–</sup>CCR7
<sup>–</sup>CD56
<sup>+</sup>, and (d) CD7
<sup>+</sup>CD3
<sup>–</sup>CD127
<sup>–</sup>CD45RA
<sup>–</sup>CD56
<sup>partial</sup>. Top right: Expressions of separate markers used for the identification. Bottom: Cells color-coded by sample origin (left) and separated by disease status of the patient (right).</p>
        </caption>
        <graphic xlink:href="f1000research-8-26529-g0003"/>
      </fig>
      <p>The plot of cells separated by disease status in
<xref ref-type="fig" rid="f4">Figure 4</xref> confirms the observation that the rare CD4
<sup>+</sup>CD28
<sup>–</sup>CD56
<sup>+</sup> phenotype is enriched in the samples from patients with Crohn’s disease. Moreover, the plot gives a useful overview for identifying cell types specific for the other diseases, showing two specific and one enriched cluster for RCDII, a single specific cluster of CD8
<sup>+</sup>CD56
<sup>+</sup>CD127
<sup>+</sup>c-KIT
<sup>+</sup> cells for EATLII, and one specific and some enriched cell types in patients with CeD.</p>
    </sec>
  </sec>
  <sec>
    <title>Summary</title>
    <p>We have presented an improved and generalized version of EmbedSOM, supported by the new model of quadtree-structured growing self-organizing maps. The functionality of the new algorithm was demonstrated on data and analyses from recent studies, showing that the new combination provides superior embedding speed and good rendering of various cell types, including tissue-specific and rare phenotypes.</p>
  </sec>
  <sec>
    <title>Software availability</title>
    <list list-type="bullet">
      <list-item>
        <p>Source code available from:
<ext-link ext-link-type="uri" xlink:href="https://github.com/exaexa/EmbedSOM">https://github.com/exaexa/EmbedSOM</ext-link>
</p>
      </list-item>
      <list-item>
        <p>Archived source code available from:
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.3568980">https://doi.org/10.5281/zenodo.3568980</ext-link>
</p>
      </list-item>
      <list-item>
        <p>Software license: GNU GPLv3</p>
      </list-item>
    </list>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The used datasets are freely available from FlowRepository.org under accession IDs:</p>
    <list list-type="bullet">
      <list-item>
        <p><monospace>FR-FCM-ZZTM</monospace> (Wong dataset; the data was preprocessed exactly as described by Becht
<italic>et al.</italic>
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup>)</p>
      </list-item>
      <list-item>
        <p><monospace>FR-FCM-ZYRM</monospace> (Unen dataset)</p>
      </list-item>
    </list>
    <p>Supplementary code and visualizations of the embedded datasets are available on FigShare, under DOI
<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.6084/m9.figshare.11328035">10.6084/m9.figshare.11328035</ext-link>
</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>We would like to thank all authors of the original EmbedSOM article for supplying the interesting problems and use-cases that motivated the development of the current version of EmbedSOM.</p>
  </ack>
  <ref-list>
    <ref id="ref-1">
      <label>1</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kratochvíl</surname><given-names>M</given-names></name><name><surname>Koladiya</surname><given-names>A</given-names></name><name><surname>Balounova</surname><given-names>J</given-names></name><etal/></person-group>:
<article-title>SOM-based embedding improves efficiency of high-dimensional cytometry data analysis.</article-title><source><italic toggle="yes">bioRxiv.</italic></source><year>2019</year><pub-id pub-id-type="doi">10.1101/496869</pub-id></mixed-citation>
    </ref>
    <ref id="ref-2">
      <label>2</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Gassen</surname><given-names>S</given-names></name><name><surname>Callebaut</surname><given-names>B</given-names></name><name><surname>Van Helden</surname><given-names>MJ</given-names></name><etal/></person-group>:
<article-title>FlowSOM: Using self-organizing maps for visualization and interpretation of cytometry data.</article-title><source><italic toggle="yes">Cytometry A.</italic></source><year>2015</year>;<volume>87</volume>(<issue>7</issue>):<fpage>636</fpage>–<lpage>645</lpage>.
<pub-id pub-id-type="doi">10.1002/cyto.a.22625</pub-id><?supplied-pmid 25573116?><pub-id pub-id-type="pmid">25573116</pub-id></mixed-citation>
    </ref>
    <ref id="ref-3">
      <label>3</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weber</surname><given-names>LM</given-names></name><name><surname>Robinson</surname><given-names>MD</given-names></name></person-group>:
<article-title>Comparison of clustering methods for high-dimensional single-cell flow and mass cytometry data.</article-title><source><italic toggle="yes">Cytometry Part A.</italic></source><year>2016</year>;<volume>89</volume>(<issue>12</issue>):<fpage>1084</fpage>–<lpage>1096</lpage>.
<pub-id pub-id-type="doi">10.1002/cyto.a.23030</pub-id><?supplied-pmid 27992111?><pub-id pub-id-type="pmid">27992111</pub-id></mixed-citation>
    </ref>
    <ref id="ref-4">
      <label>4</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rauber</surname><given-names>A</given-names></name><name><surname>Merkl</surname><given-names>D</given-names></name><name><surname>Dittenbach</surname><given-names>M</given-names></name></person-group>:
<article-title>The growing hierarchical self-organizing map: exploratory analysis of high-dimensional data.</article-title><source><italic toggle="yes">IEEE Trans Neural Netw.</italic></source><year>2002</year>;<volume>13</volume>(<issue>6</issue>):<fpage>1331</fpage>–<lpage>1341</lpage>.
<pub-id pub-id-type="doi">10.1109/TNN.2002.804221</pub-id><?supplied-pmid 18244531?><pub-id pub-id-type="pmid">18244531</pub-id></mixed-citation>
    </ref>
    <ref id="ref-5">
      <label>5</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Der Maaten</surname><given-names>L</given-names></name></person-group>:
<article-title>Accelerating t-SNE using tree-based algorithms.</article-title><source><italic toggle="yes">J Mach Learn Res.</italic></source><year>2014</year>;<volume>15</volume>(<issue>1</issue>):<fpage>3221</fpage>–<lpage>3245</lpage>.
<ext-link ext-link-type="uri" xlink:href="http://jmlr.org/papers/volume15/vandermaaten14a/vandermaaten14a.pdf">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-6">
      <label>6</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Becht</surname><given-names>E</given-names></name><name><surname>McInnes</surname><given-names>L</given-names></name><name><surname>Healy</surname><given-names>J</given-names></name><etal/></person-group>:
<article-title>Dimensionality reduction for visualizing single-cell data using UMAP.</article-title><source><italic toggle="yes">Nat Biotechnol.</italic></source><year>2019</year>;<volume>37</volume>(<issue>1</issue>):<fpage>38</fpage>.
<pub-id pub-id-type="doi">10.1038/nbt.4314</pub-id><?supplied-pmid 30531897?><pub-id pub-id-type="pmid">30531897</pub-id></mixed-citation>
    </ref>
    <ref id="ref-7">
      <label>7</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amid</surname><given-names>E</given-names></name><name><surname>Warmuth</surname><given-names>MK</given-names></name></person-group>:
<article-title>TriMap: Large-scale dimensionality reduction using triplets</article-title>.<year>2019</year><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/pdf/1910.00204.pdf">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-8">
      <label>8</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moon</surname><given-names>KR</given-names></name><name><surname>van Dijk</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><etal/></person-group>:
<article-title>Visualizing structure and transitions in high-dimensional biological data.</article-title><source><italic toggle="yes">Nat Biotechnol.</italic></source><year>2019</year>;<volume>37</volume>(<issue>2</issue>):<fpage>1482</fpage>–<lpage>1492</lpage>.
<pub-id pub-id-type="doi">10.1038/s41587-019-0336-3</pub-id><!--<pub-id pub-id-type="pmcid">7073148</pub-id>--><?supplied-pmid 31796933?><pub-id pub-id-type="pmid">31796933</pub-id></mixed-citation>
    </ref>
    <ref id="ref-9">
      <label>9</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borodin</surname><given-names>PA</given-names></name></person-group>:
<article-title>Linearity of metric projections on Chebyshev subspaces in
<italic>L
<sub>1</sub></italic> and
<italic>C</italic>.</article-title><source><italic toggle="yes">Mathematical Notes.</italic></source><year>1998</year>;<volume>63</volume>(<issue>6</issue>):<fpage>717</fpage>–<lpage>723</lpage>.
<pub-id pub-id-type="doi">10.1007/BF02312764</pub-id></mixed-citation>
    </ref>
    <ref id="ref-10">
      <label>10</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>J</given-names></name><name><surname>Condon</surname><given-names>A</given-names></name><name><surname>Shah</surname><given-names>SP</given-names></name></person-group>:
<article-title>Interpretable dimensionality reduction of single cell transcriptome data with deep generative models.</article-title><source><italic toggle="yes">Nat Commun.</italic></source><year>2018</year>;<volume>9</volume>(<issue>1</issue>):<fpage>2002</fpage>.
<pub-id pub-id-type="doi">10.1038/s41467-018-04368-5</pub-id><!--<pub-id pub-id-type="pmcid">5962608</pub-id>--><?supplied-pmid 29784946?><pub-id pub-id-type="pmid">29784946</pub-id></mixed-citation>
    </ref>
    <ref id="ref-11">
      <label>11</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dittenbach</surname><given-names>M</given-names></name><name><surname>Merkl</surname><given-names>D</given-names></name><name><surname>Rauber</surname><given-names>A</given-names></name></person-group>:
<article-title>The growing hierarchical self-organizing map</article-title>. In:
<italic>Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: NewChallenges and Perspectives for the New Millennium</italic>, IEEE,<year>2000</year>;<volume>6</volume>:<fpage>15</fpage>–<lpage>19</lpage>.
<pub-id pub-id-type="doi">10.1109/IJCNN.2000.859366</pub-id></mixed-citation>
    </ref>
    <ref id="ref-12">
      <label>12</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samet</surname><given-names>H</given-names></name></person-group>:
<article-title>The quadtree and related hierarchical data structures.</article-title><source><italic toggle="yes">ACM Computing Surveys (CSUR).</italic></source><year>1984</year>;<volume>16</volume>(<issue>2</issue>):<fpage>187</fpage>–<lpage>260</lpage>.
<pub-id pub-id-type="doi">10.1145/356924.356930</pub-id></mixed-citation>
    </ref>
    <ref id="ref-13">
      <label>13</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>MT</given-names></name><name><surname>Ong</surname><given-names>DE</given-names></name><name><surname>Lim</surname><given-names>FS</given-names></name><etal/></person-group>:
<article-title>A High-Dimensional Atlas of Human T Cell Diversity Reveals Tissue-Specific Trafficking and Cytokine Signatures.</article-title><source><italic toggle="yes">Immunity.</italic></source><year>2016</year>;<volume>45</volume>(<issue>2</issue>):<fpage>442</fpage>–<lpage>456</lpage>.
<pub-id pub-id-type="doi">10.1016/j.immuni.2016.07.007</pub-id><?supplied-pmid 27521270?><pub-id pub-id-type="pmid">27521270</pub-id></mixed-citation>
    </ref>
    <ref id="ref-14">
      <label>14</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Unen</surname><given-names>V</given-names></name><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Molendijk</surname><given-names>I</given-names></name><etal/></person-group>:
<article-title>Mass Cytometry of the Human Mucosal Immune System Identifies Tissue- and Disease-Associated Immune Subsets.</article-title><source><italic toggle="yes">Immunity.</italic></source><year>2016</year>;<volume>44</volume>(<issue>5</issue>):<fpage>1227</fpage>–<lpage>1239</lpage>.
<pub-id pub-id-type="doi">10.1016/j.immuni.2016.04.014</pub-id><?supplied-pmid 27178470?><pub-id pub-id-type="pmid">27178470</pub-id></mixed-citation>
    </ref>
    <ref id="ref-15">
      <label>15</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Unen</surname><given-names>V</given-names></name><name><surname>Höllt</surname><given-names>T</given-names></name><name><surname>Pezzotti</surname><given-names>N</given-names></name><etal/></person-group>:
<article-title>Visual analysis of mass cytometry data by hierarchical stochastic neighbour embedding reveals rare cell types.</article-title><source><italic toggle="yes">Nat Commun.</italic></source><year>2017</year>;<volume>8</volume>(<issue>1</issue>):<fpage>1740</fpage>.
<pub-id pub-id-type="doi">10.1038/s41467-017-01689-9</pub-id><!--<pub-id pub-id-type="pmcid">5700955</pub-id>--><?supplied-pmid 29170529?><pub-id pub-id-type="pmid">29170529</pub-id></mixed-citation>
    </ref>
    <ref id="ref-16">
      <label>16</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belkina</surname><given-names>AC </given-names></name><name><surname>Ciccolella</surname><given-names>CO</given-names></name><name><surname>Anno</surname><given-names>R</given-names></name><etal/></person-group>:
<article-title>Automated optimized parameters for T-distributed stochastic neighbor embedding improve visualization and analysis of large datasets.</article-title><source><italic toggle="yes">Nat Commun.</italic></source><year>2019</year>;<volume>10</volume>(<issue>1</issue>):<fpage>5415</fpage>.
<pub-id pub-id-type="doi">10.1038/s41467-019-13055-y</pub-id><!--<pub-id pub-id-type="pmcid">6882880</pub-id>--><?supplied-pmid 31780669?><pub-id pub-id-type="pmid">31780669</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article id="report63640" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.26529.r63640</article-id>
    <title-group>
      <article-title>Reviewer response for version 2</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Oskolkov</surname>
          <given-names>Nikolay</given-names>
        </name>
        <xref ref-type="aff" rid="r63640a1">1</xref>
        <role>Referee</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5326-8893</contrib-id>
      </contrib>
      <aff id="r63640a1"><label>1</label>Department of Biology, National Bioinformatics Infrastructure Sweden, Science for Life Laboratory, Lund University, Lund, Sweden</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>26</day>
      <month>5</month>
      <year>2020</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2020 Oskolkov N</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d36e3039" ext-link-type="doi" xlink:href="10.12688/f1000research.21642.2">Version 2</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>The concerns previously raised by me have been properly addressed and I believe the manuscript is ready for publication</p>
    <p>Are the conclusions about the tool and its performance adequately supported by the findings presented in the article?</p>
    <p>Yes</p>
    <p>Is the rationale for developing the new software tool clearly explained?</p>
    <p>Partly</p>
    <p>Is the description of the software tool technically sound?</p>
    <p>Yes</p>
    <p>Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others?</p>
    <p>Partly</p>
    <p>Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool?</p>
    <p>Yes</p>
    <p>Reviewer Expertise:</p>
    <p>Computational Biology, Bioinformatics, Mathematical Statistics and Machine Learning</p>
    <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
  </body>
</sub-article>
<sub-article id="report59220" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.23857.r59220</article-id>
    <title-group>
      <article-title>Reviewer response for version 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Oskolkov</surname>
          <given-names>Nikolay</given-names>
        </name>
        <xref ref-type="aff" rid="r59220a1">1</xref>
        <role>Referee</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5326-8893</contrib-id>
      </contrib>
      <aff id="r59220a1"><label>1</label>Department of Biology, National Bioinformatics Infrastructure Sweden, Science for Life Laboratory, Lund University, Lund, Sweden</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>25</day>
      <month>2</month>
      <year>2020</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2020 Oskolkov N</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d36e3123" ext-link-type="doi" xlink:href="10.12688/f1000research.21642.1">Version 1</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve-with-reservations</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>The authors present an improved version of EmbedSOM that was optimized for speed to address extra large single cell data sets. In addition, a novel way of growing SOM based on quad-tree was proposed.</p>
    <p> Dimension reduction of large single cell RNAseq and flow cytometry data sets is very challenging due to the crowding problem and algorithm scalability issues. Therefore, developing methods alternative to the current golden standards such as PCA, tSNE and UMAP is of high importance. More specifically, tSNE and UMAP are capable of preserving only local structure while PCA keeps the global structure information. However, no method is currently available that can preserve both local and global structure.</p>
    <p> Self-Organizing Maps (SOMs) and the modified EmbedSOM that are discussed in the manuscript represent an interesting and promising algorithm in this respect. However, I would like to raise a few questions and concerns to be addressed by the authors.</p>
    <p> First, based on the cost function mentioned on the page 3, the algorithm seems to resemble MDS / PCA type of dimension reduction. Therefore, I would like to see a comparison of EmbedSOM with MDS / PCA. If a connection between the gamma-delta T cells and CD8 T cells was not captured by tSNE and UMAP as it is mentioned on the page 8, probably due to the lack of global structure preservation by tSNE and UMAP, was this connection captured by MDS / PCA?</p>
    <p> Second, what would be the benefit of using EmbedSOM compared to PCA / MDS, tSNE and UMAP? Do we discover any new biology using EmbedSOM that is not captured by PCA / tSNE / UMAP? Do we benefit from the computational speed of EmbedSOM compared to PCA / tSNE / UMAP? If so, is it really faster (and how much faster) than PCA? I would like to see a clear formulation of the role of the EmbedSOM among other dimension reduction methods.</p>
    <p> Third, I was really impressed by the Figure 1 and how well GQTSOM-based embedding was able to reconstruct the original 3D S-shaped non-linear manifold. To my experience, tSNE / UMAP and especially PCA / MDS would have difficulty reconstructing the 3D S-shaped manifold as 2D embeddings. I have not found any links to the codes for reproducing this embedding and would be very curious to see whether GQTMSOM / EmbedSOM is really capable of capturing the internal 2D structure of the 3D S-shaped non-linear manifold.</p>
    <p>Are the conclusions about the tool and its performance adequately supported by the findings presented in the article?</p>
    <p>Yes</p>
    <p>Is the rationale for developing the new software tool clearly explained?</p>
    <p>Partly</p>
    <p>Is the description of the software tool technically sound?</p>
    <p>Yes</p>
    <p>Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others?</p>
    <p>Partly</p>
    <p>Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool?</p>
    <p>Yes</p>
    <p>Reviewer Expertise:</p>
    <p>Computational Biology, Bioinformatics, Mathematical Statistics and Machine Learning</p>
    <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard, however I have significant reservations, as outlined above.</p>
  </body>
  <sub-article id="comment5430-59220" article-type="response">
    <front-stub>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Kratochvíl</surname>
            <given-names>Miroslav</given-names>
          </name>
          <aff>Department of software engineering, Faculty of Mathematics and Physics, Charles University, Prague, Czech Republic</aff>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-statement">
          <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>16</day>
        <month>4</month>
        <year>2020</year>
      </pub-date>
    </front-stub>
    <body>
      <p>Thank you for the review and for pointing out the deficiencies. We believe that the raised points should be addressed -- especially regarding the comparison of EmbedSOM with other dimensionality reduction methods (adding some helpful hints for the readers to decide whether they should use EmbedSOM) and the code that produces the Figure 1 and processes the other dataset (thus improving availability and reproducibility). We plan to submit the extended version of the article in several days.</p>
    </body>
  </sub-article>
</sub-article>
<sub-article id="report57989" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.23857.r57989</article-id>
    <title-group>
      <article-title>Reviewer response for version 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Newell</surname>
          <given-names>Evan</given-names>
        </name>
        <xref ref-type="aff" rid="r57989a1">1</xref>
        <role>Referee</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2889-243X</contrib-id>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>MacMilan</surname>
          <given-names>Hugh</given-names>
        </name>
        <xref ref-type="aff" rid="r57989a1">1</xref>
        <role>Co-referee</role>
      </contrib>
      <aff id="r57989a1"><label>1</label>Fred Hutchinson Cancer Research Center, Seattle, WA, USA</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>11</day>
      <month>2</month>
      <year>2020</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2020 Newell E and MacMilan H</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d36e3266" ext-link-type="doi" xlink:href="10.12688/f1000research.21642.1">Version 1</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>The authors generalize their EmbedSOM approach to examine two additional ways of selecting the respective sets of landmarks in the high- and low-dimensional spaces, beyond the standard SOM, to address. Example data analyses are appreciated.</p>
    <p> That selection is the first stage in the embedSOM approach. The second stage is the actual embedding enrichment process. </p>
    <p> The authors explain: "EmbedSOM projection can be viewed as an embedding enrichment method: From a set of landmarks in the high-dimensional space and a set of corresponding landmarks in the low-dimensional space, it produces a smooth function that maps all points from the higher-dimensional space to the low-dimensional space and preserves the relative neighborhoods of the landmarks."</p>
    <p>
      <underline>Testing:</underline>
      <list list-type="bullet">
        <list-item>
          <p>We followed the paper’s guidance on some in-house fcs files and had success with embedSOM and the  GQTSOM function.</p>
        </list-item>
      </list>
      <underline>Some naming confusion:</underline>
      <list list-type="bullet">
        <list-item>
          <p>By "generalized EmbedSOM” the authors refer to using different ways of generating landmarks, other than the original (self-organizing map) SOM approach. </p>
        </list-item>
        <list-item>
          <p>It seems preferable to drop the “SOM” rather than refer to these variants as "generalized EmbedSOM” methods.  The authors might use the more general notion of landmarks, rather than SOM. As they note, the random-sampling, followed by tSNE, version of “generalized EmbedSOM” doesn’t use SOMs at all. </p>
        </list-item>
      </list>
    </p>
    <p>
      <underline>Re “compacting noise"</underline>
      <list list-type="bullet">
        <list-item>
          <p>The first reference of the manuscript includes some background on differences between the “generalized EmbedSOM” approach and what the authors call “plain tSNE and UMAP,” and attributes these differences to the respective designs of the algorithms. </p>
        </list-item>
        <list-item>
          <p>In that background paper, the authors explain: “neither UMAP nor tSNE aim to preserve local linearity of the transformation, which allows them to take apart the clusters with noisy data and attach the residual noise to nearest clusters.”  </p>
        </list-item>
        <list-item>
          <p>They concluded in that paper: “Compacting the residual or unexplained noise is desirable for providing a clean display of the data for publication. On the contrary, almost-immediate availability of all information about very large datasets, including the (often informative) noise, is more important for producing comprehensive graphics for high-throughput analysis." </p>
        </list-item>
        <list-item>
          <p>This paper marks an attempt to explore those differences, and the apparent trade-offs, in more detail, so it would benefit from discussing these tradeoffs in the context of the algorithm designs.</p>
        </list-item>
        <list-item>
          <p>The authors noted in the first reference, "While the observed cluster separation may be desirable if the embedding is expected to approximate the population boundaries, it may be inappropriate if the population environment is relevant for analysis."</p>
        </list-item>
      </list>
    </p>
    <p>
      <underline>GQTSOMs:</underline>
      <list list-type="bullet">
        <list-item>
          <p>The manuscript introduces a new landmark-generating algorithm that simplifies a hierarchical variant of an adaptive SOM approach, namely, growing quad tree SOMS (GQTSOMs) as a simplified growing hierarchical SOM (GHSOM), which is in turn a variant of growing SOMs (GSOMs). </p>
        </list-item>
        <list-item>
          <p>The aim is to identify and incorporate features in the input space more efficiently than random sampling, by using a "layered structure of SOMs". This is a natural thing to do to improve on SOM.</p>
        </list-item>
        <list-item>
          <p>On page 8 the authors report that GQTSOM leads to using a “smaller amount of more precise landmarks” and thus faster computation, and appears to be a nice contribution.</p>
        </list-item>
      </list>
    </p>
    <p>Are the conclusions about the tool and its performance adequately supported by the findings presented in the article?</p>
    <p>Yes</p>
    <p>Is the rationale for developing the new software tool clearly explained?</p>
    <p>Yes</p>
    <p>Is the description of the software tool technically sound?</p>
    <p>Yes</p>
    <p>Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others?</p>
    <p>Yes</p>
    <p>Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool?</p>
    <p>Yes</p>
    <p>Reviewer Expertise:</p>
    <p>Cellular immunology</p>
    <p>We confirm that we have read this submission and believe that we have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
  </body>
  <sub-article id="comment5252-57989" article-type="response">
    <front-stub>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Kratochvíl</surname>
            <given-names>Miroslav</given-names>
          </name>
          <aff>Department of software engineering, Faculty of Mathematics and Physics, Charles University, Prague, Czech Republic</aff>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-statement">
          <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>22</day>
        <month>2</month>
        <year>2020</year>
      </pub-date>
    </front-stub>
    <body>
      <p>Thank you for the review and comments. We will wait for the additional reviews and address some of your suggestions in the second version of the manuscript.</p>
      <p>Regarding the name of EmbedSOM, we are aware of the issue with textual "specialization" to SOMs which ignores the modifiable parts of the workflow, but since the package is already published over a year and we had not been able to invent a strictly better name so far, we expect that the name will stay. We will gratefully accept suggestions (also from readers) for a reasonably short name that sufficiently characterizes the projection procedure.</p>
    </body>
  </sub-article>
</sub-article>
