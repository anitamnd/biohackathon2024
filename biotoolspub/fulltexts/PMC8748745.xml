<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Sci Rep</journal-id>
    <journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id>
    <journal-title-group>
      <journal-title>Scientific Reports</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2045-2322</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8748745</article-id>
    <article-id pub-id-type="publisher-id">4048</article-id>
    <article-id pub-id-type="doi">10.1038/s41598-021-04048-3</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A novel deep learning-based 3D cell segmentation framework for future image-based disease detection</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Wang</surname>
          <given-names>Andong</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Zhang</surname>
          <given-names>Qi</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Han</surname>
          <given-names>Yang</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Megason</surname>
          <given-names>Sean</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hormoz</surname>
          <given-names>Sahand</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mosaliganti</surname>
          <given-names>Kishore R.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Lam</surname>
          <given-names>Jacqueline C. K.</given-names>
        </name>
        <address>
          <email>jcklam@eee.hklu.hk</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Li</surname>
          <given-names>Victor O. K.</given-names>
        </name>
        <address>
          <email>vli@eee.hku.hk</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.194645.b</institution-id><institution-id institution-id-type="ISNI">0000000121742757</institution-id><institution>Department of Electrical and Electronic Engineering, </institution><institution>The University of Hong Kong, </institution></institution-wrap>Hong Kong, China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.38142.3c</institution-id><institution-id institution-id-type="ISNI">000000041936754X</institution-id><institution>Department of Systems Biology, </institution><institution>Harvard Medical School, </institution></institution-wrap>Boston, MA USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>10</day>
      <month>1</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>10</day>
      <month>1</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>12</volume>
    <elocation-id>342</elocation-id>
    <history>
      <date date-type="received">
        <day>24</day>
        <month>7</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>9</day>
        <month>12</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Cell segmentation plays a crucial role in understanding, diagnosing, and treating diseases. Despite the recent success of deep learning-based cell segmentation methods, it remains challenging to accurately segment densely packed cells in 3D cell membrane images. Existing approaches also require fine-tuning multiple manually selected hyperparameters on the new datasets. We develop a deep learning-based 3D cell segmentation pipeline, 3DCellSeg, to address these challenges. Compared to the existing methods, our approach carries the following novelties: (1) a robust two-stage pipeline, requiring only one hyperparameter; (2) a light-weight deep convolutional neural network (3DCellSegNet) to efficiently output voxel-wise masks; (3) a custom loss function (3DCellSeg Loss) to tackle the clumped cell problem; and (4) an efficient touching area-based clustering algorithm (TASCAN) to separate 3D cells from the foreground masks. Cell segmentation experiments conducted on four different cell datasets show that 3DCellSeg outperforms the baseline models on the ATAS (plant), HMS (animal), and LRP (plant) datasets with an overall accuracy of 95.6%, 76.4%, and 74.7%, respectively, while achieving an accuracy comparable to the baselines on the Ovules (plant) dataset with an overall accuracy of 82.2%. Ablation studies show that the individual improvements in accuracy is attributable to 3DCellSegNet, 3DCellSeg Loss, and TASCAN, with the 3DCellSeg demonstrating robustness across different datasets and cell shapes. Our results suggest that 3DCellSeg can serve a powerful biomedical and clinical tool, such as histo-pathological image analysis, for cancer diagnosis and grading.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Computational biology and bioinformatics</kwd>
      <kwd>Image processing</kwd>
      <kwd>Machine learning</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002920</institution-id>
            <institution>Research Grants Council, University Grants Committee</institution>
          </institution-wrap>
        </funding-source>
        <award-id>T41-709/17-N</award-id>
        <award-id>T41-709/17-N</award-id>
        <award-id>T41-709/17-N</award-id>
        <award-id>T41-709/17-N</award-id>
        <award-id>T41-709/17-N</award-id>
        <principal-award-recipient>
          <name>
            <surname>Wang</surname>
            <given-names>Andong</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Qi</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>Yang</given-names>
          </name>
          <name>
            <surname>Lam</surname>
            <given-names>Jacqueline C. K.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Victor O. K.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par2">Computer-aided digital pathology plays an increasingly important role in understanding, diagnosing, and treating various kinds of diseases<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Digital image processing has become increasingly widespread in biological research as high-throughput/high-content microscopy and screening generate significant quantities of complex fine-grained cellular images<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. With the development of modern biomedical techniques—such as cellular staining, whole-slide imaging, telemedicine, and cloud storage—millions of tissue biopsies are analysed annually<sup><xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR4">4</xref></sup>. To increase the efficiency of screening big cell image data, and to standardize image analysis and reduce variation in interpretability, there is a need to develop improved computer vision techniques for big cell image data analysis.</p>
    <p id="Par3">Cell segmentation plays a key role in biological image processing. Computer-aided diagnostics requires the identification of single cells. With regards to histo-pathological image analysis for cancer diagnosis and grading, the regularity of cell borders, shapes, and distributions provides an important insight into whether tissue regions are cancerous<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>. Other recent research studies have shown that the distribution and quality of blood cells are connected with the pathogenesis of Alzheimer’s Disease and may contribute to disease progression<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. Cell segmentation has also been applied in studying the dynamics of gene regulation, cell growth and proliferation. Time-lapse microscopy technologies—including confocal, two photon, and light sheet microscopy—enable detailed data analytics based on dynamic cellular processes at the single-cell level<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR8">8</xref></sup>. However, recognizing cells as the objects of an image, and tracking these objects from one image to the next, still presents a central challenge<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. The development of computational cell segmentation methods dramatically decreases time and labour in related biomedical applications.</p>
    <p id="Par4">Cell segmentation algorithms can be categorized into semantic segmentation and instance segmentation. Semantic segmentation refers to the partitioning of images into different semantic parts and assigning each pixel to a class (e.g. cell foreground or background). Instance segmentation seeks to identify each instance of the same class, by separately detecting and delineating every single cell shown in the image. Table <xref rid="Tab1" ref-type="table">1</xref> overviews the current deep learning-based methods for cell segmentation and lists their major drawbacks. For a more detailed description of traditional methods and deep learning-based approaches for cell instance segmentation, please refer to <xref rid="MOESM1" ref-type="media">Supplementary Information</xref>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>An overview of the existing deep learning models for 2D/3D cell segmentation.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="2">Segmentation type</th><th align="left">Deep learning model for 2D cell segmentation</th><th align="left">Deep learning model for 3D cell segmentation</th><th align="left">Major drawback</th></tr></thead><tbody><tr><td align="left" colspan="2">Semantic segmentation</td><td align="left">U-Net<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>; DeepCell<sup><xref ref-type="bibr" rid="CR10">10</xref></sup></td><td align="left">3D U-net<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>; V-Net<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>; VoxRexNet<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>; 3D-DSN<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>; 2D-3D<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>; C2FNAS<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>; Automatic Data Augmentation<sup><xref ref-type="bibr" rid="CR17">17</xref></sup></td><td align="left">Fails to distinguish different cell instances</td></tr><tr><td align="left" rowspan="3">Instance segmentation</td><td align="left">Contour-aware approach</td><td align="left">DCAN<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>; Deep Watershed<sup><xref ref-type="bibr" rid="CR19">19</xref></sup></td><td align="left">U-Net + CRF<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>; U-Net + SWS<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>; PlantSeg<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>; DISCo<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>; U-Net + Graph based<sup><xref ref-type="bibr" rid="CR24">24</xref></sup></td><td align="left"><p>Performance is highly dependent on the manually selected parameters during the post-processing procedures</p><p>Prone to fuse cells that are tightly adhered</p></td></tr><tr><td align="left">Object-detection-based</td><td align="left">Retinanet<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>; R-CNN, and a series of revised structures<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>–<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>; Keypoint bounding box<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>; PointINS<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>; FCOS<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>; CenterMask<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>; YOLACT<sup><xref ref-type="bibr" rid="CR33">33</xref></sup></td><td align="left">Retina-Unet<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>; Weak Annotation<sup><xref ref-type="bibr" rid="CR35">35</xref></sup></td><td align="left"><p>Suffers from a severe imbalance between the number of positive and negative anchor boxes</p><p>May fail to discern objects that are poorly approximated with bounding boxes</p></td></tr><tr><td align="left">Other strategies</td><td align="left">GAN<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>; Embedding<sup><xref ref-type="bibr" rid="CR37">37</xref>,<xref ref-type="bibr" rid="CR38">38</xref></sup>; StarDist<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>; TensorMask<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>; AdaptIS<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>; CondInst<sup><xref ref-type="bibr" rid="CR42">42</xref></sup></td><td align="left">StarDist 3D<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>; ShapeMetrics<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>; Spherical Harmonics<sup><xref ref-type="bibr" rid="CR45">45</xref></sup></td><td align="left"><p>Less accurate than the previous two mainstream strategies</p><p>Many of these models are based on specific assumptions</p><p>The training process of GAN networks is highly complex, especially on 3D datasets</p></td></tr></tbody></table></table-wrap></p>
    <p id="Par5">Most existing 3D segmentation deep learning models focus on semantic segmentation. 3D U-Net<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> extends 2D U-Net into 3D, incorporating a path for extracting high-level features and a path for generating segmented cells in full-resolution. V-Net is another 3D version of U-Net, with residual connections added between the convolutional layers<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. VoxResNet extends a 2D deep residual network to a 3D residual network<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>. 3D-DSN is a 3D fully convolutional network equipped with a deep supervision mechanism<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. These methods have been applied in various biomedical segmentation tasks, including image segmentation for brain, liver, prostate, and heart tissues. C2FNAS (coarse-to-fine neural architecture search)<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> automatically identifies a 3D segmentation network, and<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> employs automatic data augmentation for medical image segmentation tasks. Both of these two models<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR16">16</xref></sup> have achieved state-of-the-art performance.</p>
    <p id="Par6">Some recent methods have applied instance segmentation on 3D cellular images<sup><xref ref-type="bibr" rid="CR21">21</xref>–<xref ref-type="bibr" rid="CR23">23</xref>,<xref ref-type="bibr" rid="CR25">25</xref>,<xref ref-type="bibr" rid="CR40">40</xref>,<xref ref-type="bibr" rid="CR41">41</xref></sup>. These methods use deep learning based 3D semantic segmentation models in their first step to generate a pixel-based classification of the cell interiors, edges, and backgrounds. Traditional techniques, including thresholding and watershed, are then used to separate single cells from each other. Their major drawback is in processing clumped cells, which leads to the adhesion of cell instances after semantic segmentation, thereby degrading the segmentation accuracy. Furthermore, the performance of existing methods is highly dependent on the manually selected hyperparameters during the separation procedure. Many methods have deployed a large number of hyperparameters that are fine-tuned on pre-existing datasets, which require retuning on new datasets. Meanwhile, some models<sup><xref ref-type="bibr" rid="CR58">58</xref>,<xref ref-type="bibr" rid="CR59">59</xref></sup> use shape priors to constrain model predictions to a set of natural variations, but these also require the cells to fall into a particular shape, thus making model generalization difficult. Instead of following the recent trends in developing more accurate and complex semantic segmentation models, we aim to build a simplified model of high robustness and efficiency, and yet achieving comparable performance in 3D cell segmentation.</p>
    <p id="Par7">We propose 3DCellSeg, a novel domain-specific 3D cell instance segmentation model, with four distinctive novelties. A two-stage pipeline is followed. In the first stage, a light-weight CNN is developed to perform semantic segmentation. In the second stage, cell instance segmentation is conducted using a super voxel-based clustering algorithm (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>).<fig id="Fig1"><label>Figure 1</label><caption><p>3DCellSeg: A two-stage light-weight, fast, and robust pipeline for 3D cell segmentation. [Note: There are two stages in the pipeline. The first stage is a semantic segmentation, where the input is a 3D cell membrane image and the output consists of three masks, which indicate whether a voxel is the cell foreground, membrane, or background. The second stage is an instance segmentation performed on the basis of these three masks. The cellular images and segmentation results were generated by Python Matplotlib (<ext-link ext-link-type="uri" xlink:href="https://matplotlib.org">https://matplotlib.org</ext-link>) using the HMS dataset].</p></caption><graphic xlink:href="41598_2021_4048_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par8">The main novelties of 3DCellSeg are summarized in Table <xref rid="Tab2" ref-type="table">2</xref>.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Key novelties of 3DCellSeg.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Aspect</th><th align="left">Novelty</th></tr></thead><tbody><tr><td align="left">Network</td><td align="left">Based on the characteristics of cell membrane images, a light-weight network, 3DCellSeg, is designed to yield a fast inference speed while achieving an accuracy comparable or superior to the existing cutting-edge approaches</td></tr><tr><td align="left">Loss function</td><td align="left">A new loss function, 3DCellSeg Loss, is proposed to tackle the clumped cell problem</td></tr><tr><td align="left">Post-processing</td><td align="left">Inspired by DBSCAN (Density-based Spatial Clustering of Applications with Noise)<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>, a new clustering method, TASCAN (Touching Area-based Spatial Clustering of Applications with Noise) is proposed for 3D cell instance segmentation; TASCAN operates faster, achieves better performance, and requires only one single manually selected hyperparameter</td></tr><tr><td align="left">Model usability</td><td align="left">3DCellSeg pipeline is robust, easy to fine-tune, and outperforms existing cutting-edge methods across different experimental datasets</td></tr></tbody></table></table-wrap></p>
  </sec>
  <sec id="Sec2">
    <title>Results</title>
    <sec id="Sec3">
      <title>3DCellSeg pipeline</title>
      <sec id="Sec4">
        <title>Semantic segmentation</title>
        <p id="Par9">Most existing biomedical image processing models, such as V-Net and VoxResNet, are designed for images containing multiple tissues and structures, such as CT or MRI images. However, the content of the cell membrane images is much simpler. We used this domain-specific knowledge to design our light-weight CNN model, 3DCellSegNet, which has a faster inference speed while achieving performance comparable to other state-of-the-art cell segmentation models.</p>
      </sec>
      <sec id="Sec5">
        <title>Instance segmentation</title>
        <p id="Par10">Our TASCAN algorithm works on super voxels (small clusters of voxels). Only one hyperparameter in TASCAN (and for the whole pipeline) needs to be set: namely, the minimum touching area between two cell foreground super voxels. TASCAN helps reduce mis-clustering because the super voxels within the same cell usually have much larger touching areas than the super voxels across two neighboring cells. The super voxels across two neighboring cells are caused by membrane voxels being misclassified as the cell foreground, and this misclassified area is usually small in practice.</p>
      </sec>
      <sec id="Sec6">
        <title>Loss function</title>
        <p id="Par11">Cells are densely packed across membrane images. Under existing methods, this results in the adhesion of cell masks after semantic segmentation, which greatly degrades the accuracy of instance segmentation. We therefore designed a new loss function, 3DCellSeg Loss, to address the problem. As the top right box in Fig. <xref rid="Fig1" ref-type="fig">1</xref> shows, based on the Dice Loss function, 3DCellSeg adds weight matrices to penalize the voxels that are closer to the cell membranes and replaces <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{k}$$\end{document}</tex-math><mml:math id="M2"><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq1.gif"/></alternatives></inline-formula> (model confidence of a voxel being the cell foreground) with <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{p_{k} }}{{p_{k} + \alpha }}$$\end{document}</tex-math><mml:math id="M4"><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq2.gif"/></alternatives></inline-formula> (see Method for further details). This suppresses the segmentation of the cell foreground when the model confidence is low (which often happens near the cell membranes) and thus reduces adhesions of cell masks.</p>
        <p id="Par12">Four cell membrane image datasets consisting of both animal and plant tissues were used for training and testing: HMS (zebrafish cells); ATAS (Arabidopsis thaliana apical stem cells)<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>; LRP (Arabidopsis thaliana lateral root cells)<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>; and Ovules (Arabidopsis thaliana Ovules cells)<sup><xref ref-type="bibr" rid="CR51">51</xref></sup>. Four types of metrics were used for evaluation: Jaccard Index (JI), Dice Similarity Coefficient (DSC), Adapted Rand Error (ARE)<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>, and Variation of Information (VOI)<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>. A detailed description of the experimental datasets and performance evaluation metrics can be found under Method.</p>
      </sec>
      <sec id="Sec7">
        <title>Performance comparison</title>
        <p id="Par13">We compared our 3DCellSeg with both traditional and deep learning methods. To benchmark 3D image performance, we compared 3DCellSeg with 3D U-Net based methods<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. To test the model performance on the animal cell membrane images, we retrained U-Net + SWS<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>, U-Net + GASP<sup><xref ref-type="bibr" rid="CR23">23</xref>,<xref ref-type="bibr" rid="CR40">40</xref></sup>, U-Net + MultiCut<sup><xref ref-type="bibr" rid="CR23">23</xref>,<xref ref-type="bibr" rid="CR48">48</xref></sup>, and U-Net + MutexWS<sup><xref ref-type="bibr" rid="CR23">23</xref>,<xref ref-type="bibr" rid="CR41">41</xref></sup> on the HMS dataset, and compared their performance with our method and ACME (traditional method, developed using the HMS dataset) (see Table <xref rid="Tab2" ref-type="table">2</xref> and Fig. <xref rid="Fig2" ref-type="fig">2</xref>). To ensure that our model comparison using the same set of plant cell membrane images is being fairly conducted, we compared our model with U-Net + SWS (built using ATAS) on the ATAS dataset, while U-Net + MutexWS, U-Net + MultiCut, and U-Net + GASP (built using LRP and Ovules) were compared with our method on the LRP and Ovules datasets (see Table <xref rid="Tab2" ref-type="table">2</xref> and Fig. <xref rid="Fig3" ref-type="fig">3</xref>). We used the default hyperparameters of other models (most of the hyperparameters relate to instance segmentation), and used the same hyperparameter (the minimum touching area between two cell foreground super voxels) for our model across the four datasets. We evaluated 3DCellSeg and other baseline models with nine metrics: ARE, VOI<sub>split</sub>, VOI<sub>merge</sub>, Avg JI, Avg DSC, JI &gt; 70%, DSC &gt; 70%, JI &gt; 50%, and DSC &gt; 50% (for their definitions, see Datasets and metrics in Method). The results are shown in Table <xref rid="Tab3" ref-type="table">3</xref>. For ARE, VOIsplit, and VOImerge, the lower the value, the higher the accuracy. For Avg JI, Avg DSC, JI &gt; 70%, DSC &gt; 70%, JI &gt; 50%, and DSC &gt; 50%, a higher value indicates a higher accuracy.<fig id="Fig2"><label>Figure 2</label><caption><p>Model comparison and representative slices. [<italic>Note</italic> (<bold>a</bold>) shows the accuracies of different cell segmentation models for the HMS dataset. 3DCellSeg achieves the second best accuracy in ARE, VOI<sub>split</sub>, and VOI<sub>merge</sub>, and achieves the best accuracy in Avg JI, JI &gt; 70%, and JI &gt; 50% (the plots for DSC-related metrics are of high similarity to JI-related metrics). (<bold>b</bold>) and (<bold>c</bold>) show representative slices of different model segments. ACME tends to under-segment (see the dark green region which mis-classifies different cells as one cell) while U-Net + SWS tends to over-segment (see the over-segmented small cells in the central region). PanopticFCN, Mask R-CNN FPN, and Mask R-CNN C4 are accurate on the HMS dataset but they are severely under-segment on the ATAS dataset. The cellular images in (<bold>b</bold>) and (<bold>c</bold>) were generated by Python Matplotlib (<ext-link ext-link-type="uri" xlink:href="https://matplotlib.org">https://matplotlib.org</ext-link>) using the HMS and ATAS<sup><xref ref-type="bibr" rid="CR49">49</xref></sup> datasets].</p></caption><graphic xlink:href="41598_2021_4048_Fig2_HTML" id="MO2"/></fig><fig id="Fig3"><label>Figure 3</label><caption><p>3DCellSeg performance on the ATAS, LRP, and Ovules datasets. [Note: Different cell instances were randomly assigned different colors. The LRP dataset images are annotated: the yellow circle shows where 3DCellSeg has made a mistake and the green circle shows that 3DCellSeg can segment cells that were not labelled in the ground truth. The cellular images were generated by Python Matplotlib (<ext-link ext-link-type="uri" xlink:href="https://matplotlib.org">https://matplotlib.org</ext-link>) using the ATAS<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>, LRP<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>, and Ovules<sup><xref ref-type="bibr" rid="CR51">51</xref></sup> datasets].</p></caption><graphic xlink:href="41598_2021_4048_Fig3_HTML" id="MO3"/></fig><table-wrap id="Tab3"><label>Table 3</label><caption><p>Comparison of model performance on the HMS, ATAS, LRP, and Ovules datasets.</p></caption><graphic position="anchor" xlink:href="41598_2021_4048_Tab3_HTML" id="MO4"/><table-wrap-foot><p>[Note: For the HMS dataset, U-Net + SWS, U-Net + GASP, U-Net + MultiCut, and U-Net + MutexWS were retrained on default hyperparameters, and compared with our 3DCellSeg. For the ATAS dataset, U-Net + SWS, which was originally developed, trained and fine-tuned on the ATAS dataset, was compared with 3DCellSeg. For the LRP and Ovules datasets, U-Net + GASP, U-Net + MultiCut, and U-Net + MutexWS , which were originally built, trained and fine-tuned on LRP and Ovules, were compared with 3DCellSeg. Object-detection based instance segmentation methods (PanopticFCN, Mask R-CNN FPN, and Mask R-CNN C4) trained on 2D slices of the HMS, ATAS, LRP, and Ovules datasets were also taken as baselines for model comparison. ARE, VOI<sub>split</sub>, VOI<sub>merge</sub>, JI-related, and DSC-related metrics were calculated on 3D space for 3DCellSeg, ACME, U-Net + SWS, U-Net + GASP, U-Net + MultiCut, and U-Net + MutexWS and were calculated on 2D slices for PanopticFCN, Mask R-CNN FPN, and Mask R-CNN C4].</p></table-wrap-foot></table-wrap></p>
        <p id="Par14">To assess 2D image performance, we ran three object-detection-based instance segmentation models developed for 2D images: two Mask R-CNN<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> models with different backbones (ResNet-50-C4 and ResNet-50-FPN<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>, denoted as Mask R-CNN C4 and Mask R-CNN FPN respectively) and a currently-published panoptic segmentation method named PanopticFPN<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>. These models were fed 2D slices of cell membrane images from HMS, ATAS, LRP, and Ovules for model training and testing. ARE, VOI<sub>split</sub>, VOI<sub>merge</sub>, JI -related, and DSC-related metrics were calculated for each 2D segmentation method. The results are shown in Table <xref rid="Tab3" ref-type="table">3</xref>. For all the results shown in this article (except for the ablation study for transfer learning in Table <xref rid="Tab4" ref-type="table">4</xref>), the models were re-trained on the same dataset they were tested on. We observe that since segmenting 2D images is intrinsically easier than segmenting 3D images, if the accuracy values of the three object-detection-based models for 2D images are lower than those of 3DCellSeg and other baseline models for 3D images, then the performance deficit of the three object-detection-based models when adapted to segment 3D images will be even larger.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Ablation studies showing 3DCellSeg Loss, 3DCellSegNet, TASCAN, and Transfer Learning.</p></caption><graphic position="anchor" xlink:href="41598_2021_4048_Tab4_HTML" id="MO5"/></table-wrap></p>
        <p id="Par15">As shown in Table <xref rid="Tab3" ref-type="table">3</xref>, 3DCellSeg achieves the best performance over three datasets, the HMS, ATAS, and LRP, while attaining a comparable performance on the Ovules dataset. U-Net + SWS, U-Net + GASP, U-Net + MultiCut, and U-Net + MutexWS were built and fine-tuned on Arabidopsis thaliana cell membrane images (the ATAS, LRP, and Ovules datasets). However, their performance drops significantly when applied to the zebra fish cell membrane images (the HMS dataset). It has been noted that U-Net + GASP and U-Net + MutexWS perform less satisfactorily as compared to the traditional ACME method on the HMS dataset. This might be related to their reliance on a significant number of manually selected hyperparameters, which are fine-tuned on the membrane images of a certain type of cells, and may not be transferrable to a new type of cells. 3DCellSeg is more robust, as it requires only one hyperparameter.</p>
        <p id="Par16">Moreover, though PanopticFCN, Mask R-CNN FPN, and Mask R-CNN C4 can achieve a high accuracy on the LRP dataset when only a few cell instances are shown on one 2D slice, they perform poorly on the HMS, ATAS, and Ovules datasets when many more cell instances (100–300) are shown on each slice. The results show that 3DCellSeg is more robust while object detection-based instance segmentation method may work much less satisfactorily when the number of target instances to be segmented is large.</p>
        <p id="Par17">Additionally, the size of the 3DCellSegNet (~ 5 MB) adopted in our pipeline is much smaller than the U-Net (~ 15 MB) in U-Net + SWS, and the U-Net (~ 50 MB) in U-Net + GASP, U-Net + MultiCut, and U-Net + MutexWS, with significant reductions in inference time (the inference time of 3DCellSeg is around 50% to 70% of that of other baseline models on the ATAS, LRP, and Ovules datasets).</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec8">
    <title>Ablation studies</title>
    <p id="Par18">Ablation studies show that instance segmentation accuracy is improved by our CNN model 3DCellSegNet, our loss function 3DCellSeg Loss, and our clustering algorithm TASCAN.</p>
    <sec id="Sec9">
      <title>Effects of 3DCellSeg loss</title>
      <p id="Par19">First, we evaluate the effect of the loss function. We compare our 3DCellSeg Loss with the original Dice Loss function (denoted as Dice Loss), Dice Loss with weight matrices (denoted as Dice Loss w/ weights), and 3DCellSeg Loss with the replacement <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{p_{k} }}{{p_{k} + \alpha }}$$\end{document}</tex-math><mml:math id="M6"><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq3.gif"/></alternatives></inline-formula> but without weight matrices (denoted as 3DCellSeg Loss w/o weights) on the four datasets (shown in the green-colored rows in Table <xref rid="Tab4" ref-type="table">4</xref>). We find that weight matrices and replacement both greatly improve segmentation accuracy on all metrics. When both are incorporated into the model, the accuracy is further improved.</p>
    </sec>
    <sec id="Sec10">
      <title>Effects of 3DCellSegNet</title>
      <p id="Par20">Second, we compare the performance of 3DCellSegNet with that of the two commonly used models for medical image processing, VoxResNet and 3D U-Net, as the backbone CNN in our pipeline (shown in the blue-colored rows in Table <xref rid="Tab4" ref-type="table">4</xref>). We find that all three models have a similar accuracy on the four datasets. However, 3DCellSegNet performs slightly better than the other two models on most metrics. With regards to model size and inference time, 3DCellSegNet (~ 5 MB) is much smaller than VoxResNet (~ 30 MB) and 3D U-Net (~ 50 MB). 3DCellSegNet takes less than 20 s to segment one membrane image from the HMS dataset while the other two require more than one minute.</p>
    </sec>
    <sec id="Sec11">
      <title>Effects of TASCAN</title>
      <p id="Par21">Third, we compare the accuracy of adopting TASCAN versus DBSCAN in instance segmentation in our pipeline on the four datasets. This is shown in the orange-colored rows in Table <xref rid="Tab4" ref-type="table">4</xref>. TASCAN performs slightly better than DBSCAN. However, the execution time of TASCAN is less than 20 s while that of DBSCAN is about 180 s. The efficiency advantage of TASCAN becomes more apparent when tackling larger images because the execution time increases cubically with image size. Segmenting larger images like LRP and Ovules takes just a few minutes on TASCAN but more than one hour for a single image on DBSCAN.</p>
    </sec>
    <sec id="Sec12">
      <title>Transfer learning</title>
      <p id="Par22">The model’s transfer learning capability was tested. Based on 3DCellSegNet trained on ATAS dataset, we re-trained the models over only 2 images randomly-picked from the HMS training set. The last row in Table <xref rid="Tab4" ref-type="table">4</xref> showed that with transfer learning our pipeline still performed well over the HMS dataset, implying that our pipeline was robust and easily applicable to the new cell membrane datasets.</p>
    </sec>
  </sec>
  <sec id="Sec13">
    <title>Discussion</title>
    <p id="Par23">Most existing deep learning approaches to 3D cell segmentation follow a two-stage pipeline and focus on either CNN model architecture design in the semantic segmentation stage or post-processing design in the instance segmentation stage. However, the clumped cell problem in cell segmentation has not been adequately addressed, with challenges in accuracy and robustness as existing segmentation pipelines rely on extensive manually selected hyperparameters. To tackle these critical but overlooked problems, we propose a deep learning-based two-stage pipeline, 3DCellSeg. The whole pipeline requires only one manually selected hyperparameter (the minimum touching area between two super voxels of the cell foreground). In the first stage, a light-weight CNN-based U-Net-like model, 3DCellSegNet, performs semantic segmentation while addressing the clumped cell problem by incorporating a novel loss function, 3DCellSeg Loss, into the network training process. In the second stage, a novel touching area-based clustering algorithm, TASCAN, distinguishes cell instances from the other types of semantic voxels according to the minimum touching area.</p>
    <p id="Par24">The experimental results based on four animal and plant cell membrane image datasets show the performance of the 3DCellSeg pipeline to be better than or at least comparable to other approaches. For the HMS (animal), ATAS (plant), and LRP (plant) datasets, 3DCellSeg pipeline achieved better performance than the traditional baseline (ACME) and the U-Net-based deep learning baselines in terms of both overall accuracy and cell count accuracy. For the Ovules (plant) dataset, 3DCellSeg pipeline achieved performance comparable to the U-Net-based deep learning baselines that were initially built and fine-tuned based on the datasets of Arabidopsis thaliana cells, including the Ovules dataset. However, some of these U-Net-based deep learning baselines performed even worse than the ACME method on the HMS dataset (zebrafish cells), likely due to the use of extensive hyperparameters that are not transferrable across different cell types. In contrast, even without fine-tuning, 3DCellSeg still performed satisfactorily across the four different datasets because it has a simple structure and only utilizes one hyperparameter.</p>
    <p id="Par25">Moreover, 3DCellSeg is more robust than the object-detection-based deep learning baselines when the number of cell instances to be segmented is large. As compared to 3DCellSeg, when the number of cell instances was small on each slice (tens of cells), the object-detection-based deep learning baselines (including Mask R-CNN FPN and Mask R-CNN C4) achieved a higher accuracy on the LRP dataset. However, when the number of cell instances became large on each slice (around 100–300 cells), these object-detection-based baselines failed to accurately segment cells from the HMS and ATAS datasets.</p>
    <p id="Par26">Our ablation study reveals how the four components of the 3DCellSeg pipeline perform relative to their counterparts across four different datasets. Firstly, the use of 3DCellSeg Loss improved the segmentation accuracy of the original Dice Loss function for the four datasets, especially for the LRP and Ovules datasets with a higher cell shape irregularity. This is because 3DcellSeg Loss was designed specifically for cell segmentation and can suppress the cell foreground segmentation near the cell membranes where model confidence is not sufficiently high, thus reducing misclassification of voxels and enabling more accurate cell instance clustering.</p>
    <p id="Par27">Secondly, 3DCellSegNet slightly outperformed two CNN backbones commonly used in CT or MRI image segmentation (VoxResNet and 3D U-Net) for most performance metrics across the four datasets. This result suggests that a simple CNN structure with fewer parameters can fully capture the characteristics of cell membrane images that have a more recurrent structure than CT and MRI images. The simplified CNN structure can reduce the risk of model overfitting when limited training samples are available, thus providing a more robust backbone for cell segmentation across different datasets. In addition to improved accuracy, the light-weight design of 3DCellSegNet enables it to deliver much faster training and segmentation than the CNN models implemented in other pipelines. With 3DCellSegNet, a HMS image of 5 MB takes &lt; 20 s to process, as compared to one of 30 MB or larger, which takes ~ 60 s to process, using VoxResNet or 3D U-Net.</p>
    <p id="Par28">Thirdly, the touching area-based clustering method, TASCAN, is slightly more accurate than the original clustering method DBSCAN. The marginal improvement in accuracy is probably due to the fact that most misclassified foreground masks have already been addressed by the 3DCellSeg Loss function in the first stage. However, TASCAN has a higher robustness and is easier to implement as it requires only one hyperparameter. In addition, the computational complexity of TASCAN is much lower because it processes super voxels rather than voxels. When dealing with larger images such as those in the LRP and Ovules datasets, TASCAN can significantly reduce the clustering time from one hour to a few minutes in the second stage.</p>
    <p id="Par29">Fourthly, the transfer learning experiment demonstrates the robustness of the whole 3DCellSeg pipeline across different datasets. When re-purposing a trained 3DCellSegNet model to segment cells in different cell membrane images, our 3DCellSeg pipeline still performs well, despite the fact that only a few new images are available for re-training.</p>
    <p id="Par30">Overall, as compared to other existing approaches to 3D cell segmentation, our approach is superior in three aspects: Firstly, our approach champions the use of domain-specific modelling to better capture the characteristics of the 3D cell images. We have utilized a light-weight CNN model with fewer parameters to perform semantic segmentation based on the knowledge that cell membrane images contain more recurrent patterns than CT or MRI images. Meanwhile, we have designed a custom loss function to address the misclassification challenge due to clumped cells. Secondly, our approach is robust and easy to fine-tune, requiring only one hyperparameter. Minimizing the number of hyperparameters is especially beneficial when adapting the pipeline to a new dataset, as the setting of hyperparameters is often not transferable across different datasets. Thirdly, the experimental results have demonstrated that our proposed method achieves performance better than or similar to state-of-the-art models but is more computationally efficient. They also suggest that our novel 3DCellSeg pipeline can accurately process high-throughput imaging data, allowing the automatic detection of 3D cells in a large scale in real-time, thus paving the way for cellular disease mechanism discovery.</p>
    <p id="Par31">Our work can be improved in two aspects. First, given that the CNN model is only used in semantic segmentation, we are yet to fully exploit deep learning models in learning representations of high-dimensional 3D images. In the future, we will build an end-to-end deep learning model to output the 3D cell instance segmentation directly. Second, despite the fact that we have accounted for the clumped cell issue, more domain-specific knowledge of the cell characteristics, such as the size and distribution of cells, can be integrated into our pipeline to improve cell identification/classification accuracy.</p>
  </sec>
  <sec id="Sec14">
    <title>Method</title>
    <p id="Par32">3DCellSeg performs semantic segmentation to identify the cell foreground masks, followed by instance segmentation. Two challenges of cell segmentation are addressed. The first is the clumped cell problem. Adhesions of the cell foreground masks need to be addressed during semantic segmentation, as they reduce the accuracy of instance segmentation. The second is the selection of hyperparameters, which is currently performed manually on a trial-and-error basis across a particular dataset, and may not be transferable across other datasets.</p>
    <sec id="Sec15">
      <title>Experimental setup</title>
      <p id="Par33">Consider a training set <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}$$\end{document}</tex-math><mml:math id="M8"><mml:mi mathvariant="script">D</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq4.gif"/></alternatives></inline-formula> of pairs <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{ {\left( {{\varvec{x}}_{i} ,{ }{\varvec{s}}_{i} } \right)} \right\}_{i = 1}^{N}$$\end{document}</tex-math><mml:math id="M10"><mml:msubsup><mml:mfenced close="}" open="{"><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow/><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mfenced><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq5.gif"/></alternatives></inline-formula> where <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{x}}_{i}$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq6.gif"/></alternatives></inline-formula> is a 3D cell membrane image and <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{s}}_{i}$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq7.gif"/></alternatives></inline-formula> is the corresponding segmentation, where different integers represent different cell instances. Furthermore, consider a segmentation pipeline <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h\left( f \right)_{\theta ,\lambda }$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:mi>h</mml:mi><mml:msub><mml:mfenced close=")" open="("><mml:mi>f</mml:mi></mml:mfenced><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq8.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f$$\end{document}</tex-math><mml:math id="M18"><mml:mi>f</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq9.gif"/></alternatives></inline-formula> denotes semantic segmentation, <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h$$\end{document}</tex-math><mml:math id="M20"><mml:mi>h</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq10.gif"/></alternatives></inline-formula> denotes instance segmentation, <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\theta$$\end{document}</tex-math><mml:math id="M22"><mml:mi>θ</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq11.gif"/></alternatives></inline-formula> denotes the CNN parameters to be trained, and <inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M24"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq12.gif"/></alternatives></inline-formula> denotes the manually set hyperparameter(s).</p>
    </sec>
    <sec id="Sec16">
      <title>Dataset and metric</title>
      <p id="Par34">Four datasets containing 3D cell membrane images and corresponding voxel-wise cell labels were used for model training and testing. The first dataset, labelled as HMS, contains images of zebrafish cells. It is a new open-source dataset compiled by the Department of Systems Biology of Harvard Medical School. There are 36 images with a size of 181 × 331 × 160. A detailed description of HMS dataset is shown in the last subsection of Method. The second dataset, labelled as ATAS<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>, is an open-source dataset containing membrane images of Arabidopsis thaliana apical stem cells. It contains 126 cell membrane images with a size of 224 × 512 × 512. The third dataset, labelled as LRP<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>, is generated from three time-lapse videos documenting how Arabidopsis thaliana lateral root primordia developed. 27 images of the size of 2000 × 1000 × 500 are labelled voxel by voxel. The fourth dataset, labelled as Ovules<sup><xref ref-type="bibr" rid="CR51">51</xref></sup>, contains 48 images of size 500 × 1000 × 1000 documenting all development stages of Arabidopsis thaliana ovules.</p>
      <p id="Par35">Our CNN model was trained for semantic segmentation, to generate the cell foreground, membrane, and background masks <inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{g}}_{i}^{c}$$\end{document}</tex-math><mml:math id="M26"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq13.gif"/></alternatives></inline-formula> (every voxel in <inline-formula id="IEq14"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{g}}_{i}^{c}$$\end{document}</tex-math><mml:math id="M28"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq14.gif"/></alternatives></inline-formula> is 0 or 1; <inline-formula id="IEq15"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c$$\end{document}</tex-math><mml:math id="M30"><mml:mi>c</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq15.gif"/></alternatives></inline-formula> represents a category) for each image <inline-formula id="IEq16"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{x}}_{i}$$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq16.gif"/></alternatives></inline-formula>. Additionally, to address the clumped cell problem, in the loss function we use a weight matrix <inline-formula id="IEq17"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{w}}_{i}^{c}$$\end{document}</tex-math><mml:math id="M34"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq17.gif"/></alternatives></inline-formula> that assigns a larger weight to voxels closer to the cell membranes. <inline-formula id="IEq18"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{w}}_{i}^{c}$$\end{document}</tex-math><mml:math id="M36"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq18.gif"/></alternatives></inline-formula> is calculated by applying a reverse distance transform<sup><xref ref-type="bibr" rid="CR57">57</xref></sup> to <inline-formula id="IEq19"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{g}}_{i}^{c}$$\end{document}</tex-math><mml:math id="M38"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq19.gif"/></alternatives></inline-formula>. To reduce memory usage, we cropped <inline-formula id="IEq20"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{x}}_{i}$$\end{document}</tex-math><mml:math id="M40"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq20.gif"/></alternatives></inline-formula>, <inline-formula id="IEq21"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{g}}_{i}^{c}$$\end{document}</tex-math><mml:math id="M42"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq21.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq22"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{w}}_{i}^{c}$$\end{document}</tex-math><mml:math id="M44"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq22.gif"/></alternatives></inline-formula> to small cuboids <inline-formula id="IEq23"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{ {{\varvec{x}}_{i}^{j} } \right\}$$\end{document}</tex-math><mml:math id="M46"><mml:mfenced close="}" open="{"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msubsup></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq23.gif"/></alternatives></inline-formula>, <inline-formula id="IEq24"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{ {{\varvec{g}}_{i}^{c,j} } \right\}$$\end{document}</tex-math><mml:math id="M48"><mml:mfenced close="}" open="{"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq24.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq25"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{ {{\varvec{w}}_{i}^{c,j} } \right\}$$\end{document}</tex-math><mml:math id="M50"><mml:mfenced close="}" open="{"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq25.gif"/></alternatives></inline-formula>, and trained the CNN model on cuboids <inline-formula id="IEq26"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{ {\left\{ {\left( {{\varvec{x}}_{i}^{j} ,{ }{\varvec{g}}_{i}^{c,j} ,{\varvec{w}}_{i}^{c,j} } \right)} \right\}_{j = 1}^{M} } \right\}_{i = 1}^{N}$$\end{document}</tex-math><mml:math id="M52"><mml:msubsup><mml:mfenced close="}" open="{"><mml:msubsup><mml:mfenced close="}" open="{"><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mrow/><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mfenced><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup></mml:mfenced><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq26.gif"/></alternatives></inline-formula>.</p>
      <p id="Par36">We evaluated the performance of the segmentation based on four types of metrics: Jaccard Index (JI), Dice Similarity Coefficient (DSC), Adapted Rand Error (ARE), and Variation of Information (VOI). JI and DSC values were calculated for each cell, measuring the ratio of the correctly predicted voxels. We evaluated performance based on overall accuracy and cell count accuracy. Overall accuracy refers to the average values of JI and DSC of all cells (denoted as Avg JI and Avg DSC, respectively). Cell count accuracy is the fraction of cells whose JI (or DSC) is more than 0.7 (or 0.5). ARE measures how much the algorithm outperforms a random model<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>, and VOI is an entropy-based measure of clustering quality<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>. VOI<sub>split</sub> measures split errors and VOI<sub>merge</sub> measures merge errors.<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$JI\left( {seg,gt} \right) = \frac{{\left| {seg \cap gt} \right|}}{{\left| {seg \cup gt} \right|}}$$\end{document}</tex-math><mml:math id="M54" display="block"><mml:mrow><mml:mi>J</mml:mi><mml:mi>I</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mfenced close="|" open="|"><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>∩</mml:mo><mml:mi>g</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mfenced close="|" open="|"><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>∪</mml:mo><mml:mi>g</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2021_4048_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$DSC\left( {seg,gt} \right) = \frac{{2\left| {seg \cap gt} \right|}}{{\left| {seg} \right| + \left| {gt} \right|}}$$\end{document}</tex-math><mml:math id="M56" display="block"><mml:mrow><mml:mi>D</mml:mi><mml:mi>S</mml:mi><mml:mi>C</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mfenced close="|" open="|"><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>∩</mml:mo><mml:mi>g</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfenced close="|" open="|"><mml:mrow><mml:mi mathvariant="italic">seg</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mfenced close="|" open="|"><mml:mrow><mml:mi mathvariant="italic">gt</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2021_4048_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ARE = 1 - maxFscore\left( {Rand\, Index} \right)$$\end{document}</tex-math><mml:math id="M58" display="block"><mml:mrow><mml:mi>A</mml:mi><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mi>F</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>R</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mspace width="0.166667em"/><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="41598_2021_4048_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$VOI\left( {seg,gt} \right) = 2H\left( {seg \cap gt} \right) - H\left( {seg} \right) - H\left( {gt} \right)$$\end{document}</tex-math><mml:math id="M60" display="block"><mml:mrow><mml:mi>V</mml:mi><mml:mi>O</mml:mi><mml:mi>I</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>H</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>∩</mml:mo><mml:mi>g</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mi>H</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">seg</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mi>H</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">gt</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="41598_2021_4048_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq27"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$seg$$\end{document}</tex-math><mml:math id="M62"><mml:mrow><mml:mi mathvariant="italic">seg</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq27.gif"/></alternatives></inline-formula> is the model prediction, <inline-formula id="IEq28"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$gt$$\end{document}</tex-math><mml:math id="M64"><mml:mrow><mml:mi mathvariant="italic">gt</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq28.gif"/></alternatives></inline-formula> is the ground truth mask, and <inline-formula id="IEq29"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H$$\end{document}</tex-math><mml:math id="M66"><mml:mi>H</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq29.gif"/></alternatives></inline-formula> is the conditional entropy function. <inline-formula id="IEq30"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${ }JI$$\end{document}</tex-math><mml:math id="M68"><mml:mrow><mml:mrow/><mml:mi>J</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq30.gif"/></alternatives></inline-formula> is the ratio of the intersection of <inline-formula id="IEq31"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$seg$$\end{document}</tex-math><mml:math id="M70"><mml:mrow><mml:mi mathvariant="italic">seg</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq31.gif"/></alternatives></inline-formula> and <inline-formula id="IEq32"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$gt$$\end{document}</tex-math><mml:math id="M72"><mml:mrow><mml:mi mathvariant="italic">gt</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq32.gif"/></alternatives></inline-formula> over the union of them while <inline-formula id="IEq33"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$DSC$$\end{document}</tex-math><mml:math id="M74"><mml:mrow><mml:mi mathvariant="italic">DSC</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq33.gif"/></alternatives></inline-formula> is the ratio of two times of the intersection over the sum of the size of <inline-formula id="IEq34"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$seg$$\end{document}</tex-math><mml:math id="M76"><mml:mrow><mml:mi mathvariant="italic">seg</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq34.gif"/></alternatives></inline-formula> and <inline-formula id="IEq35"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$gt$$\end{document}</tex-math><mml:math id="M78"><mml:mrow><mml:mi mathvariant="italic">gt</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq35.gif"/></alternatives></inline-formula>. <inline-formula id="IEq36"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ARE$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:mi mathvariant="italic">ARE</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq36.gif"/></alternatives></inline-formula> is derived from the Rand Index and <inline-formula id="IEq37"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$VOI$$\end{document}</tex-math><mml:math id="M82"><mml:mrow><mml:mi mathvariant="italic">VOI</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq37.gif"/></alternatives></inline-formula> is an entropy-based measure. Please see the complete definitions of <inline-formula id="IEq38"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ARE$$\end{document}</tex-math><mml:math id="M84"><mml:mrow><mml:mi mathvariant="italic">ARE</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq38.gif"/></alternatives></inline-formula> and <inline-formula id="IEq39"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$VOI$$\end{document}</tex-math><mml:math id="M86"><mml:mrow><mml:mi mathvariant="italic">VOI</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq39.gif"/></alternatives></inline-formula> in<sup><xref ref-type="bibr" rid="CR52">52</xref></sup> and<sup><xref ref-type="bibr" rid="CR53">53</xref></sup> respectively.</p>
    </sec>
    <sec id="Sec17">
      <title>3DCellSegNet for semantic segmentation</title>
      <p id="Par37">Figure <xref rid="Fig4" ref-type="fig">4</xref> shows the structure of 3DCellSegNet. Based on the knowledge that cell membrane images contain more recurrent patterns than CT or MRI images, we built a lighter weight network for medical image processing which achieves faster inference speed with similar performance. For example, the average inference time of 3DCellSegNet on HMS and LRP is 20 and 50 s respectively, while the inference time of 3D U-Net and VoxResNet is around 2 times and 1.5 times longer. 3DCellSegNet has a shallow U-Net like shape with residual connection at the down sampling stage. Intuitively, for cell membrane images, only local features are required to determine the voxel category. In addition, by removing extra voxels on the edge of the feature maps during up-sampling, 3DCellSegNet can process cuboid-shape images of any size. We trained the model by feeding cuboids of slightly different sizes, thus improving the segmentation of cuboid interface and the model’s robustness.<fig id="Fig4"><label>Figure 4</label><caption><p>The structure of 3DCellSegNet. [Note: The extra voxels on the edge of the feature maps are removed after each deconvolution operation, in order to ensure the size of the up-sampled feature map is identical with that of the corresponding down-sampled feature map].</p></caption><graphic xlink:href="41598_2021_4048_Fig4_HTML" id="MO6"/></fig></p>
      <p id="Par38">We implemented 3DCellSegNet with PyTorch<sup><xref ref-type="bibr" rid="CR58">58</xref></sup>. The model was trained on one Nvidia GeForce RTX 2080 Ti with a cuboid size ranging from 56 × 56 × 56 to 64 × 64 × 64. For the four datasets, the longest training time is 48 h, using Adam optimizer and a batch size of 7.</p>
    </sec>
    <sec id="Sec18">
      <title>3DCellSeg Loss to tackle the clumped cell problem</title>
      <p id="Par39">Since cells are densely packed in the HMS dataset, there is an adhesion of the cell foreground masks in the semantic segmentation, thereby decreasing the accuracy of the instance segmentation. We proposed our 3DCellSeg Loss <inline-formula id="IEq40"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L$$\end{document}</tex-math><mml:math id="M88"><mml:mi>L</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq40.gif"/></alternatives></inline-formula> to tackle the problem.<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{Others} = 1 - \frac{{2\mathop \sum \nolimits_{k = 1}^{K} p_{k} g_{k} w_{k} }}{{\mathop \sum \nolimits_{k = 1}^{K} p_{k}^{2} + \mathop \sum \nolimits_{k = 1}^{K} g_{k}^{2} }}$$\end{document}</tex-math><mml:math id="M90" display="block"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">Others</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2021_4048_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{Cell Foreground} = 1 - \frac{{2\mathop \sum \nolimits_{k = 1}^{K} \left( {\frac{{p_{k} }}{{p_{k} + \alpha }}} \right)g_{k} w_{k} }}{{\mathop \sum \nolimits_{k = 1}^{K} \left( {\frac{{p_{k} }}{{p_{k} + \alpha }}} \right)^{2} + \mathop \sum \nolimits_{k = 1}^{K} g_{k}^{2} }}$$\end{document}</tex-math><mml:math id="M92" display="block"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">CellForeground</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:mfenced><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2021_4048_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L = L_{Cell Foreground} + L_{Others}$$\end{document}</tex-math><mml:math id="M94" display="block"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">CellForeground</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">Others</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><graphic xlink:href="41598_2021_4048_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq41"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{k} \in \left[ {0,1} \right]$$\end{document}</tex-math><mml:math id="M96"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq41.gif"/></alternatives></inline-formula> is the model confidence of a voxel being the cell foreground; <inline-formula id="IEq42"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$g_{k} \in \left\{ {0,1} \right\}$$\end{document}</tex-math><mml:math id="M98"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq42.gif"/></alternatives></inline-formula> is the voxel value of the category mask; <inline-formula id="IEq43"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_{k}$$\end{document}</tex-math><mml:math id="M100"><mml:msub><mml:mi>w</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq43.gif"/></alternatives></inline-formula> is the weight of a voxel <inline-formula id="IEq44"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M102"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq44.gif"/></alternatives></inline-formula> (<inline-formula id="IEq45"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_{k}$$\end{document}</tex-math><mml:math id="M104"><mml:msub><mml:mi>w</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq45.gif"/></alternatives></inline-formula> is larger if <inline-formula id="IEq46"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M106"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq46.gif"/></alternatives></inline-formula> is closer to cell membrane); <inline-formula id="IEq47"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K$$\end{document}</tex-math><mml:math id="M108"><mml:mi>K</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq47.gif"/></alternatives></inline-formula> is the number of voxels; <inline-formula id="IEq48"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math><mml:math id="M110"><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq48.gif"/></alternatives></inline-formula> is a constant; <inline-formula id="IEq49"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{Cell Foreground}$$\end{document}</tex-math><mml:math id="M112"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">CellForeground</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq49.gif"/></alternatives></inline-formula> is the loss function for the cell foreground and <inline-formula id="IEq50"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{Others}$$\end{document}</tex-math><mml:math id="M114"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">Others</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq50.gif"/></alternatives></inline-formula> is the loss function for other categories.</p>
      <p id="Par40">We used weight matrix <inline-formula id="IEq51"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{w}}$$\end{document}</tex-math><mml:math id="M116"><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq51.gif"/></alternatives></inline-formula> and replacement <inline-formula id="IEq52"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{p_{k} }}{{p_{k} + \alpha }}$$\end{document}</tex-math><mml:math id="M118"><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq52.gif"/></alternatives></inline-formula> to suppress the segmentation of the cell foreground close to the cell membrane if the confidence is not high, as the false positives of foreground voxels will result in clumped cell instances. 3DCellSeg Loss works like a regularizer, penalizing low confidence. Figure <xref rid="Fig5" ref-type="fig">5</xref>a shows the values of <inline-formula id="IEq53"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{p_{k} }}{{p_{k} + \alpha }}$$\end{document}</tex-math><mml:math id="M120"><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq53.gif"/></alternatives></inline-formula> at different <inline-formula id="IEq54"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math><mml:math id="M122"><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq54.gif"/></alternatives></inline-formula> values. We chose 0.1 to achieve our desired regularization effect: when <inline-formula id="IEq55"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{k}$$\end{document}</tex-math><mml:math id="M124"><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq55.gif"/></alternatives></inline-formula> is small, the increasing rate of <inline-formula id="IEq56"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{p_{k} }}{{p_{k} + \alpha }}$$\end{document}</tex-math><mml:math id="M126"><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq56.gif"/></alternatives></inline-formula> should be high; when <inline-formula id="IEq57"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{k}$$\end{document}</tex-math><mml:math id="M128"><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq57.gif"/></alternatives></inline-formula> is near 0.5, <inline-formula id="IEq58"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{p_{k} }}{{p_{k} + \alpha }}$$\end{document}</tex-math><mml:math id="M130"><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq58.gif"/></alternatives></inline-formula> grows slowly as <inline-formula id="IEq59"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{k}$$\end{document}</tex-math><mml:math id="M132"><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq59.gif"/></alternatives></inline-formula> increases; however, even when <inline-formula id="IEq60"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{k}$$\end{document}</tex-math><mml:math id="M134"><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq60.gif"/></alternatives></inline-formula> is near 1, <inline-formula id="IEq61"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{p_{k} }}{{p_{k} + \alpha }}$$\end{document}</tex-math><mml:math id="M136"><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq61.gif"/></alternatives></inline-formula> should be slightly less than 1, thus maintaining the penalty.<fig id="Fig5"><label>Figure 5</label><caption><p>Addressing the clumped cell problem using 3DCellSeg Loss. [<italic>Note</italic> (<bold>a</bold>) <inline-formula id="IEq94"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{p_{k} }}{{p_{k} + \alpha }}$$\end{document}</tex-math><mml:math id="M138"><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq94.gif"/></alternatives></inline-formula> vs <inline-formula id="IEq95"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{k}$$\end{document}</tex-math><mml:math id="M140"><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq95.gif"/></alternatives></inline-formula> at different <inline-formula id="IEq96"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math><mml:math id="M142"><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq96.gif"/></alternatives></inline-formula> values shows how different <inline-formula id="IEq97"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math><mml:math id="M144"><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq97.gif"/></alternatives></inline-formula> affects the replacement <inline-formula id="IEq98"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{p_{k} }}{{p_{k} + \alpha }}$$\end{document}</tex-math><mml:math id="M146"><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq98.gif"/></alternatives></inline-formula>. (<bold>b</bold>) A 2D slice of a simulation illustrating the difference between Dice Loss <inline-formula id="IEq99"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial L{ }}}{{\partial {\varvec{p}}}}$$\end{document}</tex-math><mml:math id="M148"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq99.gif"/></alternatives></inline-formula> and 3DCellSeg Loss <inline-formula id="IEq100"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial Dice Loss{ }}}{{\partial {\varvec{p}}}}$$\end{document}</tex-math><mml:math id="M150"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq100.gif"/></alternatives></inline-formula>. The simulation results in (<bold>b</bold>) were generated by Python Matplotlib (<ext-link ext-link-type="uri" xlink:href="https://matplotlib.org">https://matplotlib.org</ext-link>)].</p></caption><graphic xlink:href="41598_2021_4048_Fig5_HTML" id="MO7"/></fig></p>
      <p id="Par41"><inline-formula id="IEq62"><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial L{ }}}{{\partial {\varvec{p}}}}$$\end{document}</tex-math><mml:math id="M152"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq62.gif"/></alternatives></inline-formula> indicates that 3DCellSeg Loss penalizes heavily the positive voxels of low confidence (&lt; 0.2), but penalizes slightly other positive voxels. <inline-formula id="IEq63"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial Dice Loss{ }}}{{\partial {\varvec{p}}}}$$\end{document}</tex-math><mml:math id="M154"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq63.gif"/></alternatives></inline-formula> penalizes the voxels on an equal basis. Hence, 3DCellSeg Loss will not push positive voxels of medium confidence (0.2—0.5) to a more positive end. The derivative of 3DCellSeg Loss <inline-formula id="IEq64"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial L{ }}}{{\partial p_{k} }}$$\end{document}</tex-math><mml:math id="M156"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq64.gif"/></alternatives></inline-formula> (<inline-formula id="IEq65"><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial L{ }}}{{\partial p_{k} }} = \frac{{\partial L_{Cell Foreground} { }}}{{\partial p_{k} }} + \frac{{\partial L_{Others} { }}}{{\partial p_{k} }}$$\end{document}</tex-math><mml:math id="M158"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">CellForeground</mml:mi></mml:mrow></mml:msub><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">Others</mml:mi></mml:mrow></mml:msub><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq65.gif"/></alternatives></inline-formula>) provides a numerical explanation on how 3DCellSeg Loss works by comparing how <inline-formula id="IEq66"><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial L{ }}}{{\partial p_{k} }}$$\end{document}</tex-math><mml:math id="M160"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq66.gif"/></alternatives></inline-formula> and <inline-formula id="IEq67"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial Dice Loss{ }}}{{\partial p_{k} }}$$\end{document}</tex-math><mml:math id="M162"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq67.gif"/></alternatives></inline-formula> change with <inline-formula id="IEq68"><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{k}$$\end{document}</tex-math><mml:math id="M164"><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq68.gif"/></alternatives></inline-formula> in the top right box in Fig. <xref rid="Fig1" ref-type="fig">1</xref>.<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial L_{Others} { }}}{{\partial p_{k} }} = 2\frac{{ - g_{k} w_{k} \left( {\mathop \sum \nolimits_{l = 1}^{K} p_{l}^{2} + \mathop \sum \nolimits_{l = 1}^{K} g_{l}^{2} } \right) + 2p_{k} \mathop \sum \nolimits_{l = 1}^{K} p_{l} g_{l} w_{l} }}{{\left( {\mathop \sum \nolimits_{l = 1}^{K} p_{l}^{2} + \mathop \sum \nolimits_{l = 1}^{K} g_{l}^{2} } \right)^{2} }}$$\end{document}</tex-math><mml:math id="M166" display="block"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">Others</mml:mi></mml:mrow></mml:msub><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msub><mml:mi>p</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>g</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2021_4048_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial L_{Cell Foreground} }}{{\partial p_{k} }} = 2\frac{{ - g_{k} w_{k} \left( {\mathop \sum \nolimits_{l = 1}^{K} \left( {\frac{{p_{l} }}{{p_{l} + \alpha }}} \right)^{2} + \mathop \sum \nolimits_{l = 1}^{K} g_{l}^{2} } \right) + 2\left( {\frac{{p_{k} }}{{p_{k} + \alpha }}} \right)\mathop \sum \nolimits_{l = 1}^{K} \left( {\frac{{p_{l} }}{{p_{l} + \alpha }}} \right)g_{l} w_{l} }}{{\left( {\mathop \sum \nolimits_{l = 1}^{K} \left( {\frac{{p_{l} }}{{p_{l} + \alpha }}} \right)^{2} + \mathop \sum \nolimits_{l = 1}^{K} g_{l}^{2} } \right)^{2} }} \cdot \frac{\alpha }{{\left( {p_{k} + \alpha } \right)^{2} }}$$\end{document}</tex-math><mml:math id="M168" display="block"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">CellForeground</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mfenced close=")" open="("><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:mfenced><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:mfenced><mml:msub><mml:mi>g</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mfrac><mml:mo>·</mml:mo><mml:mfrac><mml:mi>α</mml:mi><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2021_4048_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par42">In Fig. <xref rid="Fig1" ref-type="fig">1</xref>, the orange line indicates <inline-formula id="IEq69"><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial L{ }}}{{\partial p_{k} }}$$\end{document}</tex-math><mml:math id="M170"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq69.gif"/></alternatives></inline-formula> while the blue line indicates <inline-formula id="IEq70"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial Dice{ }Loss{ }}}{{\partial p_{k} }}$$\end{document}</tex-math><mml:math id="M172"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mrow/><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq70.gif"/></alternatives></inline-formula>. The two lines represent a simulation case where the model confidence of a cell foreground voxel <inline-formula id="IEq71"><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{k}$$\end{document}</tex-math><mml:math id="M174"><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq71.gif"/></alternatives></inline-formula> varies from 0 to 1. As the figure shows, <inline-formula id="IEq72"><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial Dice{ }Loss{ }}}{{\partial p_{k} }}$$\end{document}</tex-math><mml:math id="M176"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mrow/><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq72.gif"/></alternatives></inline-formula> follows a linear trend as <inline-formula id="IEq73"><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{k}$$\end{document}</tex-math><mml:math id="M178"><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq73.gif"/></alternatives></inline-formula> changes. However, <inline-formula id="IEq74"><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial L{ }}}{{\partial p_{k} }}$$\end{document}</tex-math><mml:math id="M180"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq74.gif"/></alternatives></inline-formula> imposes a heavy penalty for low confidence cases (<inline-formula id="IEq75"><alternatives><tex-math id="M181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{k}$$\end{document}</tex-math><mml:math id="M182"><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq75.gif"/></alternatives></inline-formula> &lt; 0.2) but only a light penalty for high confidence cases (where the penalty is lower than <inline-formula id="IEq76"><alternatives><tex-math id="M183">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial Dice{ }Loss{ }}}{{\partial p_{k} }}$$\end{document}</tex-math><mml:math id="M184"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mrow/><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq76.gif"/></alternatives></inline-formula>). This shows that 3DCellSeg Loss works like a regularizer that penalizes model predictions of low confidence. The regularization effect of 3DCellSeg Loss is also illustrated in Fig. <xref rid="Fig5" ref-type="fig">5</xref>b which shows a 2D simulation. With the ground truth, where the yellow round shapes represent the cell foreground and the purple region represents the cell background, a simulated model output is generated. The lightness of the color indicates the confidence of a pixel being identified as a cell. Based on the ground truth and model output, the derivatives of Dice Loss and 3DCellSeg Loss over the 2D slice are shown in the images labelled <inline-formula id="IEq77"><alternatives><tex-math id="M185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{\partial L }{{\partial {\varvec{p}}}}$$\end{document}</tex-math><mml:math id="M186"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq77.gif"/></alternatives></inline-formula> and <inline-formula id="IEq78"><alternatives><tex-math id="M187">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{\partial Dice{ }Loss{ }}}{{\partial {\varvec{p}}}}$$\end{document}</tex-math><mml:math id="M188"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mrow/><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mrow/></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq78.gif"/></alternatives></inline-formula> respectively. Significantly, the mis-classified voxels around the edge are penalized more heavily than those in the center. Since mis-classification of the cell foreground often occurs near cell membranes, 3DCellSeg Loss helps address the adhesions of the cell foreground masks.</p>
    </sec>
    <sec id="Sec19">
      <title>TASCAN for instance segmentation</title>
      <p id="Par43">After the voxels were assigned different semantic labels, we applied Algorithm <inline-formula id="IEq79"><alternatives><tex-math id="M189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h$$\end{document}</tex-math><mml:math id="M190"><mml:mi>h</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq79.gif"/></alternatives></inline-formula> to the foreground voxels to divide them into different cell instances. The proposed TASCAN is inspired by DBSCAN<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>. However, our clustering algorithm is much more efficient. First, we applied watershed algorithm to pre-cluster the foreground voxels into super voxels, i.e., small clusters of voxels. Second, TASCAN was used to merge those super voxels that share a large touching area. The details of the algorithm are shown below.</p>
      <p id="Par44">Let <inline-formula id="IEq80"><alternatives><tex-math id="M191">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$u$$\end{document}</tex-math><mml:math id="M192"><mml:mi>u</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq80.gif"/></alternatives></inline-formula> be a super voxel. <inline-formula id="IEq81"><alternatives><tex-math id="M193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_{u}$$\end{document}</tex-math><mml:math id="M194"><mml:msub><mml:mi>S</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq81.gif"/></alternatives></inline-formula> denotes the area of its surface. <inline-formula id="IEq82"><alternatives><tex-math id="M195">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V_{u}$$\end{document}</tex-math><mml:math id="M196"><mml:msub><mml:mi>V</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq82.gif"/></alternatives></inline-formula> denotes the set of all super voxels that touches <inline-formula id="IEq83"><alternatives><tex-math id="M197">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$u.$$\end{document}</tex-math><mml:math id="M198"><mml:mrow><mml:mi>u</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq83.gif"/></alternatives></inline-formula> For a super voxel <inline-formula id="IEq84"><alternatives><tex-math id="M199">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v \in V_{u}$$\end{document}</tex-math><mml:math id="M200"><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq84.gif"/></alternatives></inline-formula>, the touching area of <inline-formula id="IEq85"><alternatives><tex-math id="M201">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$u$$\end{document}</tex-math><mml:math id="M202"><mml:mi>u</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq85.gif"/></alternatives></inline-formula> and <inline-formula id="IEq86"><alternatives><tex-math id="M203">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v$$\end{document}</tex-math><mml:math id="M204"><mml:mi>v</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq86.gif"/></alternatives></inline-formula> is denoted as <inline-formula id="IEq87"><alternatives><tex-math id="M205">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_{uv}$$\end{document}</tex-math><mml:math id="M206"><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">uv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq87.gif"/></alternatives></inline-formula>. We also define a threshold value <inline-formula id="IEq88"><alternatives><tex-math id="M207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$minArea$$\end{document}</tex-math><mml:math id="M208"><mml:mrow><mml:mi mathvariant="italic">minArea</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq88.gif"/></alternatives></inline-formula>. If the touching area of two super voxels is smaller than <inline-formula id="IEq89"><alternatives><tex-math id="M209">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$minArea$$\end{document}</tex-math><mml:math id="M210"><mml:mrow><mml:mi mathvariant="italic">minArea</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq89.gif"/></alternatives></inline-formula>, they are taken as two separate cells. We set the value of minArea at 30 for the four different datasets. This value is relatively robust and intuitively decided by the size of holes on the membrane (the area of the cell membrane that is mis-classified as the cell interior) in relation to the inference error generated by the backbone neural network. Basically, for an image with a much larger cell size, the value should be increased.</p>
      <p id="Par45">Algorithm 1 (see Fig. <xref rid="Fig6" ref-type="fig">6</xref>) shows the operation of TASCAN. The watershed algorithm is used to generate small clusters within the normal cells. Small super voxels are merged with the surrounding super voxels if the touching area is greater than half of its surface area. The physical interpretation of setting the threshold to 0.5 is that if at least half of the surface of one voxel is surrounded by another voxel, these voxels will be merged. After TASCAN clustering has been performed, the unassigned foreground voxels are assigned to their nearest cells. In addition, the membrane voxels are also assigned to their nearest cells. Since the metric for judging whether cell <inline-formula id="IEq90"><alternatives><tex-math id="M211">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$u$$\end{document}</tex-math><mml:math id="M212"><mml:mi>u</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq90.gif"/></alternatives></inline-formula> and <inline-formula id="IEq91"><alternatives><tex-math id="M213">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v$$\end{document}</tex-math><mml:math id="M214"><mml:mi>v</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq91.gif"/></alternatives></inline-formula> should be merged is symmetrical in terms of <inline-formula id="IEq92"><alternatives><tex-math id="M215">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$u$$\end{document}</tex-math><mml:math id="M216"><mml:mi>u</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq92.gif"/></alternatives></inline-formula> and <inline-formula id="IEq93"><alternatives><tex-math id="M217">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v$$\end{document}</tex-math><mml:math id="M218"><mml:mi>v</mml:mi></mml:math><inline-graphic xlink:href="41598_2021_4048_Article_IEq93.gif"/></alternatives></inline-formula>, TASCAN does not rely on the order of super voxels; the voxels in each experiment are processed in a random order.<fig id="Fig6"><label>Figure 6</label><caption><p>TASCAN algorithm for cell clustering.</p></caption><graphic xlink:href="41598_2021_4048_Fig6_HTML" id="MO8"/></fig></p>
      <p id="Par46">TASCAN operates at a higher speed than DBSCAN. It is capable of processing a large number of voxels all at once, instead of processing each voxel individually. Additionally, TASCAN is good at separating clumped cells. Although our revised loss function can improve the accuracy of recognizing the cell membranes, membrane voxels can still be mis-classified as foreground pixels, since the foreground voxel clusters may be connected with each other. Whereas DBSCAN finds it difficult to separate these clusters if the search radius utilized is either too small or too large (exceeding the thickness of a membrane), TASCAN is able to resolve this problem. The clusters can mostly be separated firstly by the watershed algorithm, followed by separation performed by TASCAN as the connection tunnels are usually very thin.</p>
    </sec>
    <sec id="Sec20">
      <title>HMS dataset</title>
      <p id="Par47">Zebrafish transgenic embryos expressing nuclear-localized tomato and membrane-localized citrine (Tg(actb2:Hsa.H2B-tdTomato); Tg(actb2:mem-citrine)hm32,33), Tg(actb2:mem-citrine-citrine)hm30 were used to capture a time-lapse confocal dataset from 12–45 h postfertilization of development. High-resolution imaging was performed with Zeiss 710 confocal microscope with a Plan-Apochromat 40X 1.2 NA objective and a 514 nm laser (20mW, 3% laser power), pixel dwell time: 1.58 μs; pinhole size: 89 μm; line averaging: 1; image spacing: 0.2 × 0.2 μm, and 1024 × 1024 pixels per image, with an interval of 1.0 μm through Z for 80 μm, and temporal resolution of 2 min. A total of 225 timepoints were collected and 32 z-stacks were selected at regular intervals of 10 min for generating ground truth. The otic vesicle and inner lumenal surfaces were manually contoured in 2D using Gofigure2 and ITK-Snap. The surfaces were reconstructed in 3D using Powercrust reconstruction algorithm<sup><xref ref-type="bibr" rid="CR59">59</xref></sup>. Since the otic vesicle is ellipsoidal, the images were rotated in 2D so that principal axes were aligned with coordinate axes. The 3D volumetric datasets were then cropped into a smaller size and resampled to have near isotropic sampling ratios (0.4 × 0.4 × 0.5 μm). To establish the ground truth dataset, cells were segmented using ACME. Semantic segmentation images were evaluated in 3D by overlaying on raw image data in GoFigure2 and stepping through z-stacks. Three types of segmentation errors were corrected. Missing cells, over- and under-segmented cells were identified, re-seeded, and the segmentations were re-generated. The generated segmentations were then evaluated manually a second time to guarantee highly accurate ground truth data. For example, the otic vesicle consists of epithelial cells that form a closed ellipsoid containing a fluid-filled lumen inside. This lumen is not a cell, so we manually relabelled the area as the background.</p>
    </sec>
  </sec>
  <sec id="Sec21">
    <title>Conclusion</title>
    <p id="Par48">Existing 3D cell segmentation methods face two challenges: (1) low accuracy in the presence of densely packed cells and (2) low robustness due to the need to fine-tune multiple manually selected hyperparameters on new datasets. This study aims to tackle these challenges by developing a deep learning-based two-stage pipeline, 3DCellSeg, for accurate and robust 3D cell segmentation with high computational efficiency. Specifically, the first stage utilizes a light-weight CNN model, 3DCellSegNet, to output the voxel-wise foreground, background, and membrane masks. A novel loss function, 3DCellSeg Loss, is incorporated into the model training process to address the clumped cell challenge. The second stage, which does not require any parameters from the first stage, pre-clusters the labeled voxels into super voxels using a standard watershed algorithm. A novel touching area-based clustering algorithm, TASCAN, is adopted to assemble the super voxels into cell instances while fine-tuning only one hyperparameter, i.e., the minimum touching area between two super voxels of the cell foreground, to better separate the clumped cells among the foreground voxel clusters.</p>
    <p id="Par49">Our experiments on four animal and plant datasets, namely, HMS (animal), ATAS (plant), LRP (plant), and Ovules (plant), show that 3DCellSeg has outperformed the state-of-the-art models on HMS, ATAS, and LRP, achieving an overall accuracy of 76.4%, 95.6%, and 74.7%, respectively. 3DCellSeg has also reached comparable performance to the state-of-the-art results from Ovules, achieving an overall accuracy of 82.2%. Our ablation studies further reveal that 3DCellSeg’s improvement in performance is attributable to 3DCellSeg Loss, 3DCellSegNet, and TASCAN, while showing why the whole 3DCellSeg pipeline is more robust across the four datasets. First, the use of 3DCellSeg Loss, a tailored loss function for cell segmentation, has improved the accuracy of voxel classification, especially for more irregular cells presented in the LRP and Ovules datasets. Second, 3DCellSegNet, a light-weight CNN structure using few parameters for cell segmentation, is more accurate and efficient than more complex CNN models when using different datasets with limited training samples. Third, TASCAN is slightly more accurate than its counterpart, is more robust and computationally efficient, requiring only one hyperparameter. Finally, after re-training 3DCellSegNet using a few samples from a different dataset, 3DCellSeg still performs well, demonstrating that our model is robust and transferable to new datasets. The experimental results and the ablation studies suggest that our novel 3DCellSeg can advance research on 3D instance segmentation; it can serve a powerful cell-based disease identification tool, such as cancer diagnostics, when our cell segmentation model is further trained on labelled human cancer/normal cell images. In the future, we will develop an end-to-end deep learning pipeline to segment cell instances in 3D images directly. We will also incorporate more domain-specific knowledge related to the cell characteristics into the pipeline to improve performance.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec22">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41598_2021_4048_MOESM1_ESM.docx">
            <caption>
              <p>Supplementary Information.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>These authors contributed equally: Andong Wang and Qi Zhang</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary Information</title>
    <p>The online version contains supplementary material available at 10.1038/s41598-021-04048-3.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank Mr. Kelvin Chan, Senior Research Assistant, the Department of Electrical and Electronic Engineering, the University of Hong Kong, for carefully editing this manuscript.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>J.C.L. and V.O.L. were responsible for conceptualization and initial framework development. K.R.M. collected the data. Q.Z. conducted a literature review. Q.Z. and A.W. developed the methodology. A.W. wrote and ran the code for the algorithm. Q.Z., A.W., and Y.H. interpreted the results and wrote the main manuscript. J.C.L. and V.O.L. substantially revised the manuscript. J.C.L., V.O.L., S.M., and S.H. provided crucial guidance on the presentation structure, methodology and analysis. J.C.L. and V.O.L. applied for funding. A.W. and Q.Z. contributed equally.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The code is available on <ext-link ext-link-type="uri" xlink:href="https://github.com/AntonotnaWang/3DCellSeg">https://github.com/AntonotnaWang/3DCellSeg</ext-link>. The HMS dataset used during this study is available upon email request to the author Kishore R. Mosaliganti. The ATAS, LRP, and Ovules datasets used during this study are available from the previous studies cited in this article (Willis et al., 2016; Barro et al. 2019; Tofanelli et al., 2019).</p>
  </notes>
  <notes id="FPar1" notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par50">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shostak</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Histology’s nomenclature: past, present and future</article-title>
        <source>Bio. Syst.</source>
        <year>2013</year>
        <volume>2</volume>
        <fpage>122</fpage>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Usaj</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>Styles</surname>
            <given-names>EB</given-names>
          </name>
          <name>
            <surname>Verster</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Friesen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Boone</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>High-content screening for quantitative cell biology</article-title>
        <source>Trends Cell Biol.</source>
        <year>2016</year>
        <volume>26</volume>
        <issue>8</issue>
        <fpage>598</fpage>
        <lpage>611</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tcb.2016.03.008</pub-id>
        <pub-id pub-id-type="pmid">27118708</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Williams</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Henricks</surname>
            <given-names>WH</given-names>
          </name>
          <name>
            <surname>Becich</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Toscano</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Carter</surname>
            <given-names>AB</given-names>
          </name>
        </person-group>
        <article-title>Telepathology for patient care: what am I getting myself into?</article-title>
        <source>Adv. Anat. Pathol.</source>
        <year>2010</year>
        <volume>17</volume>
        <issue>2</issue>
        <fpage>130</fpage>
        <lpage>149</lpage>
        <pub-id pub-id-type="doi">10.1097/PAP.0b013e3181cfb788</pub-id>
        <?supplied-pmid 20179435?>
        <pub-id pub-id-type="pmid">20179435</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dey</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Cancer nucleus: morphology and beyond</article-title>
        <source>Diagn. Cytopathol.</source>
        <year>2010</year>
        <volume>38</volume>
        <issue>5</issue>
        <fpage>382</fpage>
        <lpage>390</lpage>
        <?supplied-pmid 19894267?>
        <pub-id pub-id-type="pmid">19894267</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Veta</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Pluim</surname>
            <given-names>JPW</given-names>
          </name>
          <name>
            <surname>Van Diest</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Viergever</surname>
            <given-names>MA</given-names>
          </name>
        </person-group>
        <article-title>Breast cancer histopathology image analysis: a review</article-title>
        <source>IEEE Trans. Biomed. Eng.</source>
        <year>2014</year>
        <volume>61</volume>
        <issue>5</issue>
        <fpage>1400</fpage>
        <lpage>1411</lpage>
        <pub-id pub-id-type="doi">10.1109/TBME.2014.2303852</pub-id>
        <?supplied-pmid 24759275?>
        <pub-id pub-id-type="pmid">24759275</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">S.-H. Chen <italic>et al.</italic>, Altered peripheral profile of blood cells in Alzheimer disease: a hospital-based case-control study. <italic>Med. (Baltim.)</italic><bold>96(</bold>21) 2017.</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Longo</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hasty</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Dynamics of single-cell gene expression</article-title>
        <source>Mol. Syst. Biol.</source>
        <year>2006</year>
        <volume>2</volume>
        <issue>1</issue>
        <fpage>64</fpage>
        <pub-id pub-id-type="doi">10.1038/msb4100110</pub-id>
        <?supplied-pmid 17130866?>
        <pub-id pub-id-type="pmid">17130866</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Megason</surname>
            <given-names>SG</given-names>
          </name>
          <name>
            <surname>Fraser</surname>
            <given-names>SE</given-names>
          </name>
        </person-group>
        <article-title>Imaging in systems biology</article-title>
        <source>Cell</source>
        <year>2007</year>
        <volume>130</volume>
        <issue>5</issue>
        <fpage>784</fpage>
        <lpage>795</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2007.08.031</pub-id>
        <?supplied-pmid 17803903?>
        <pub-id pub-id-type="pmid">17803903</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Falk</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>U-Net: deep learning for cell counting, detection, and morphometry</article-title>
        <source>Nat. Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <issue>1</issue>
        <fpage>67</fpage>
        <lpage>70</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-018-0261-2</pub-id>
        <?supplied-pmid 30559429?>
        <pub-id pub-id-type="pmid">30559429</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Van Valen</surname>
            <given-names>DA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep learning automates the quantitative analysis of individual cells in live-cell imaging experiments</article-title>
        <source>PLoS Comput. Biol.</source>
        <year>2016</year>
        <volume>12</volume>
        <issue>11</issue>
        <fpage>e1005177</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005177</pub-id>
        <?supplied-pmid 27814364?>
        <pub-id pub-id-type="pmid">27814364</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Çiçek, Ö., Abdulkadir, A., Lienkamp, S. S., Brox, T., &amp; Ronneberger, O. 3D U-Net: learning dense volumetric segmentation from sparse annotation. In <italic>International conference on medical image computing and computer-assisted intervention</italic>, 424–432 (2016).</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Milletari, F., Navab, N., &amp; Ahmadi, S. A. V-Net: Fully convolutional neural networks for volumetric medical image segmentation. In <italic>Proc. - 2016 4th International. Conference 3D Vision, 3DV 2016</italic>, 565–571 (2016).</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Dou</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Qin</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Heng</surname>
            <given-names>P-A</given-names>
          </name>
        </person-group>
        <article-title>VoxResNet: Deep voxelwise residual networks for brain segmentation from 3D MR images</article-title>
        <source>Neuroimage</source>
        <year>2018</year>
        <volume>170</volume>
        <fpage>446</fpage>
        <lpage>455</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.04.041</pub-id>
        <?supplied-pmid 28445774?>
        <pub-id pub-id-type="pmid">28445774</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dou</surname>
            <given-names>Q</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>3D deeply supervised network for automated segmentation of volumetric medical images</article-title>
        <source>Med. Image Anal.</source>
        <year>2017</year>
        <volume>41</volume>
        <fpage>40</fpage>
        <lpage>54</lpage>
        <pub-id pub-id-type="doi">10.1016/j.media.2017.05.001</pub-id>
        <?supplied-pmid 28526212?>
        <pub-id pub-id-type="pmid">28526212</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Guay, M. D., Emam, Z. A. S., Anderson, A. B., Aronova, M. A., &amp; Leapman, R. D. Dense cellular segmentation for EM using 2D-3D neural network ensembles, <italic>BioRxiv</italic>, (2020).</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Q. Yu <italic>et al.</italic>, C2fnas: Coarse-to-fine neural architecture search for 3d medical image segmentation. In <italic>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</italic>, 4126–4135 (2020).</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Xu, J., Li, M., &amp; Zhu, Z. Automatic data augmentation for 3D medical image segmentation. In <italic>International Conference on Medical Image Computing and Computer-Assisted Intervention</italic>, 378–387 (2020).</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Chen, H., Qi, X., Yu, L., &amp; Heng, P.-A. DCAN: deep contour-aware networks for accurate gland segmentation. In <italic>Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</italic>, 2487–2496 (2016).</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Bai, M., &amp; Urtasun, R. Deep watershed transform for instance segmentation. In <italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>, 5221–5229 (2017).</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Jiang, J., Kao, P.-Y., Belteton, S. A., Szymanski, D. B., &amp; Manjunath, B. S. Accurate 3D cell segmentation using deep features and CRF refinement. In <italic>2019 IEEE International Conference on Image Processing (ICIP)</italic>, 1555–1559 (2019).</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Eschweiler, D., Spina, T. V., Choudhury, R. C., Meyerowitz, E., Cunha, A., &amp; Stegmaier, J. CNN-based preprocessing to optimize watershed-based cell segmentation in 3D confocal microscopy images. In <italic>2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)</italic>, 223–227 (2019).</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wolny</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Accurate and versatile 3D segmentation of plant tissues at cellular resolution</article-title>
        <source>Elife</source>
        <year>2020</year>
        <volume>9</volume>
        <fpage>1</fpage>
        <lpage>34</lpage>
        <pub-id pub-id-type="doi">10.7554/eLife.57613</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Kirschbaum, E., Bailoni, A., &amp; Hamprecht, F. A. DISCo: deep learning, instance segmentation, and correlations for cell segmentation in calcium imaging. In <italic>International Conference on Medical Image Computing and Computer-Assisted Intervention</italic>, 151–162 (2020).</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scherr</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Löffler</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Böhland</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Mikut</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Cell segmentation and tracking using CNN-based distance predictions and a graph-based matching strategy</article-title>
        <source>PLoS ONE</source>
        <year>2020</year>
        <volume>15</volume>
        <issue>12</issue>
        <fpage>e0243219</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0243219</pub-id>
        <?supplied-pmid 33290432?>
        <pub-id pub-id-type="pmid">33290432</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Lin, T.-Y., Goyal, P., Girshick, R., He, K., &amp; Dollár, P. Focal loss for dense object detection. In <italic>Proceedings of the IEEE international conference on computer vision</italic>, 2980–2988 (2017).</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Girshick, R., Donahue, J., Darrell, T., &amp; Malik, J. Rich feature hierarchies for accurate object detection and semantic segmentation. In <italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>, 580–587 (2014). </mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Ren, S., He, K., Girshick, R. &amp; Sun, J. Faster r-cnn: Towards real-time object detection with region proposal networks. In <italic>Advances in neural information processing systems</italic>, 91–99 (2015).</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">He, K., Gkioxari, G., Dollár, P. &amp; Girshick, R. Mask r-cnn, In <italic>Proceedings of the IEEE international conference on computer vision</italic>, 2961–2969 (2017). </mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">J. Yi <italic>et al.</italic>, Multi-scale cell instance segmentation with keypoint graph based bounding boxes. In <italic>International Conference on Medical Image Computing and Computer-Assisted Intervention</italic>, 369–377 (2019).</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Qi, L. <italic>et al.</italic>, Pointins: Point-based instance segmentation. <italic>IEEE Trans. Pattern Anal. Mach. Intell.</italic> (2021).</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Tian, Z., Shen, C., Chen, H., &amp; He, T. Fcos: Fully convolutional one-stage object detection. In <italic>Proceedings of the IEEE/CVF international conference on computer vision</italic>, 9627–9636 (2019).</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">Lee, Y. &amp; Park, J. Centermask: Real-time anchor-free instance segmentation. In <italic>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</italic>, 13906–13915 (2020).</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Bolya, D., Zhou, C., Xiao, F., &amp; Lee, Y. J. Yolact: Real-time instance segmentation. In <italic>Proceedings of the IEEE/CVF International Conference on Computer Vision</italic>, 9157–9166 (2019). </mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <mixed-citation publication-type="other">Jaeger, P. F. <italic>et al.</italic>, Retina U-Net: Embarrassingly simple exploitation of segmentation supervision for medical object detection. In <italic>Machine Learning for Health Workshop</italic>, 171–183 (2020). </mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Zhao, Z., Yang, L., Zheng, H., Guldner, I. H., Zhang, S. &amp; Chen, D. Z. Deep learning based instance segmentation in 3D biomedical images using weak annotation. In <italic>International Conference on Medical Image Computing and Computer-Assisted Intervention</italic>, 352–360 (2018). </mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Mahmood, F. <italic>et al.</italic>, Deep adversarial training for multi-organ nuclei segmentation in histopathology images. <italic>IEEE Trans. Med. Imaging</italic>, 1–1, (2019).</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Payer, C., Štern, D., Neff, T., Bischof, H. &amp; Urschler, M. Instance segmentation and tracking with cosine embeddings and recurrent hourglass networks. In <italic>International Conference on Medical Image Computing and Computer-Assisted Intervention</italic>, 3–11 (2018). </mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Y. Xiang, C. Xie, A. Mousavian, and D. Fox, “Learning RGB-D feature embeddings for unseen object instance segmentation,” <italic>arXiv Prepr. arXiv2007.15157</italic>, 2020.</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Schmidt, U., Weigert, M., Broaddus, C., Myers, G. Cell detection with star-convex polygons. In <italic>International Conference on Medical Image Computing and Computer-Assisted Intervention</italic>, 265–273 (2018). </mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">Chen, X., Girshick, R., He, K. &amp; Dollár, P. Tensormask: A foundation for dense object segmentation. In <italic>Proc.</italic><italic>of the IEEE/CVF International Conference on Computer Vision</italic>, 2061–2069 (2019). </mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">Sofiiuk, K., Barinova, O., &amp; Konushin, A. Adaptis: Adaptive instance selection network. In <italic>Proc. of the IEEE/CVF International Conference on Computer Vision</italic>, 7355–7363 (2019). </mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <mixed-citation publication-type="other">Tian, Z., Shen, C. &amp; Chen, H. Conditional convolutions for instance segmentation. In <italic>Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part I 16</italic>, 282–298 (2020). </mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Weigert, M., Schmidt, U., Haase, R., Sugawara, K., &amp; Myers, G. Star-convex polyhedra for 3d object detection and segmentation in microscopy. In <italic>Proc. of the IEEE/CVF Winter Conference on Applications of Computer Vision</italic>, 3666–3673 (2020). </mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Takko</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Pajanoja</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Kurtzeborn</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Hsin</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kuure</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kerosuo</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>ShapeMetrics: A userfriendly pipeline for 3D cell segmentation and spatial tissue analysis</article-title>
        <source>Dev. Biol.</source>
        <year>2020</year>
        <volume>462</volume>
        <issue>1</issue>
        <fpage>7</fpage>
        <lpage>19</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ydbio.2020.02.003</pub-id>
        <?supplied-pmid 32061886?>
        <pub-id pub-id-type="pmid">32061886</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <mixed-citation publication-type="other">Eschweiler, D., Rethwisch, M., Koppers, S., &amp; Stegmaier, J. Spherical harmonics for shape-constrained 3D cell segmentation. In <italic>2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)</italic>, 792–796 (2021). </mixed-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <mixed-citation publication-type="other">Bailoni, A., Pape, C., Wolf, S., Beier, T., Kreshuk, A. &amp; Hamprecht, F. A. A generalized framework for agglomerative clustering of signed graphs applied to instance segmentation. <italic>arXiv</italic>, 1–19 (2019).</mixed-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <mixed-citation publication-type="other">Wolf, S. <italic>et al.</italic>, The mutex watershed: efficient, parameter-free image partitioning. In <italic>Proc. of the European Conference on Computer Vision (ECCV)</italic>, 546–562 (2018). </mixed-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ester</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kriegel</surname>
            <given-names>H-P</given-names>
          </name>
          <name>
            <surname>Sander</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>A density-based algorithm for discovering clusters in large spatial databases with noise</article-title>
        <source>Kdd</source>
        <year>1996</year>
        <volume>96</volume>
        <issue>34</issue>
        <fpage>226</fpage>
        <lpage>231</lpage>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Willis</surname>
            <given-names>L</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Cell size and growth regulation in the Arabidopsis thaliana apical stem cell niche</article-title>
        <source>Proc. Natl. Acad. Sci.</source>
        <year>2016</year>
        <volume>113</volume>
        <issue>51</issue>
        <fpage>E8238</fpage>
        <lpage>E8246</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1616768113</pub-id>
        <?supplied-pmid 27930326?>
        <pub-id pub-id-type="pmid">27930326</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Barro</surname>
            <given-names>AV</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Cytoskeleton dynamics are necessary for early events of lateral root initiation in Arabidopsis</article-title>
        <source>Curr. Biol.</source>
        <year>2019</year>
        <volume>29</volume>
        <issue>15</issue>
        <fpage>2443</fpage>
        <lpage>2454</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cub.2019.06.039</pub-id>
        <pub-id pub-id-type="pmid">31327713</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tofanelli</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Vijayan</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Scholz</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schneitz</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Protocol for rapid clearing and staining of fixed Arabidopsis ovules for improved imaging by confocal laser scanning microscopy</article-title>
        <source>Plant Methods</source>
        <year>2019</year>
        <volume>15</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>13</lpage>
        <pub-id pub-id-type="doi">10.1186/s13007-019-0505-x</pub-id>
        <pub-id pub-id-type="pmid">30622623</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Arganda-Carreras</surname>
            <given-names>I</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Crowdsourcing the creation of image segmentation algorithms for connectomics</article-title>
        <source>Front. Neuroanat.</source>
        <year>2015</year>
        <volume>9</volume>
        <fpage>142</fpage>
        <pub-id pub-id-type="doi">10.3389/fnana.2015.00142</pub-id>
        <?supplied-pmid 26594156?>
        <pub-id pub-id-type="pmid">26594156</pub-id>
      </element-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <mixed-citation publication-type="other">Meilǎ, M. Comparing clusterings: an axiomatic view. In <italic>Proc. of the 22nd International Conference on Machine learning</italic>, 577–584 (2005).</mixed-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <mixed-citation publication-type="other">Kappes, J. H., Speth, M., Andres, B., Reinelt, G., &amp; Schn, C. Globally optimal image partitioning by multicuts. In <italic>International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition</italic>, 31–44 (2011). </mixed-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <mixed-citation publication-type="other">He, K., Zhang, X., Ren, S. &amp; Sun, J. Deep residual learning for image recognition. In <italic>Proceedings of the IEEE conference on computer vision and pattern recognition</italic>, 770–778 (2016). </mixed-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <mixed-citation publication-type="other">Li, Y. <italic>et al.</italic>, Fully convolutional networks for panoptic segmentation. In <italic>Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</italic>, 214–223 (2021). </mixed-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kimmel</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Kiryati</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Bruckstein</surname>
            <given-names>AM</given-names>
          </name>
        </person-group>
        <article-title>Sub-pixel distance maps and weighted distance transforms</article-title>
        <source>J. Math. Imaging Vis.</source>
        <year>1996</year>
        <volume>6</volume>
        <issue>2</issue>
        <fpage>223</fpage>
        <lpage>233</lpage>
        <pub-id pub-id-type="doi">10.1007/BF00119840</pub-id>
      </element-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <mixed-citation publication-type="other">Paszke, A. <italic>et al.</italic>, Pytorch: An imperative style, high-performance deep learning library. In <italic>Advances in Neural Information Processing Systems</italic>, 8026–8037 (2019). </mixed-citation>
    </ref>
    <ref id="CR59">
      <label>59.</label>
      <mixed-citation publication-type="other">Amenta, N., Choi, S. &amp; Kolluri, R. K. The power crust. In <italic>Proc. of the sixth ACM symposium on Solid modeling and applications</italic>, 249–266 (2001) </mixed-citation>
    </ref>
  </ref-list>
</back>
