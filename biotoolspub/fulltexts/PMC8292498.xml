<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Brain Inform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Brain Inform</journal-id>
    <journal-title-group>
      <journal-title>Brain Informatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">2198-4018</issn>
    <issn pub-type="epub">2198-4026</issn>
    <publisher>
      <publisher-name>Springer Berlin Heidelberg</publisher-name>
      <publisher-loc>Berlin/Heidelberg</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8292498</article-id>
    <article-id pub-id-type="pmid">34283328</article-id>
    <article-id pub-id-type="publisher-id">135</article-id>
    <article-id pub-id-type="doi">10.1186/s40708-021-00135-3</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SANTIA: a Matlab-based open-source toolbox for artifact detection and removal from extracellular neuronal signals</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Fabietti</surname>
          <given-names>Marcos</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2037-8348</contrib-id>
        <name>
          <surname>Mahmud</surname>
          <given-names>Mufti</given-names>
        </name>
        <address>
          <email>muftimahmud@gmail.com</email>
          <email>mufti.mahmud@ntu.ac.uk</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lotfi</surname>
          <given-names>Ahmad</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kaiser </surname>
          <given-names>M. Shamim</given-names>
        </name>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Averna</surname>
          <given-names>Alberto</given-names>
        </name>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Guggenmos</surname>
          <given-names>David J.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Nudo</surname>
          <given-names>Randolph J.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chiappalone</surname>
          <given-names>Michela</given-names>
        </name>
        <xref ref-type="aff" rid="Aff7">7</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Jianhui</given-names>
        </name>
        <xref ref-type="aff" rid="Aff8">8</xref>
        <xref ref-type="aff" rid="Aff9">9</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.12361.37</institution-id><institution-id institution-id-type="ISNI">0000 0001 0727 0669</institution-id><institution>Department of Computer Science, </institution><institution>Nottingham Trent University, </institution></institution-wrap>Clifton Lane, Nottingham, NG11 8NS UK </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.12361.37</institution-id><institution-id institution-id-type="ISNI">0000 0001 0727 0669</institution-id><institution>Medical Technologies Innovation Facility, </institution><institution>Nottingham Trent University, </institution></institution-wrap>Clifton Lane, Nottingham, NG11 8NS UK </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.12361.37</institution-id><institution-id institution-id-type="ISNI">0000 0001 0727 0669</institution-id><institution>Computing and Informatics Research Centre, </institution><institution>Nottingham Trent University, </institution></institution-wrap>Clifton Lane, Nottingham, NG11 8NS UK </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.411808.4</institution-id><institution-id institution-id-type="ISNI">0000 0001 0664 5967</institution-id><institution>Institute of Information Technology, Jahangirnagar University, </institution></institution-wrap>Savar, Dhaka, 1342 Bangladesh </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="GRID">grid.4708.b</institution-id><institution-id institution-id-type="ISNI">0000 0004 1757 2822</institution-id><institution>Department of Health Sciences, </institution><institution>University of Milan, </institution></institution-wrap>Via di Rudinì, 8, 20142 Milan, Italy </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="GRID">grid.412016.0</institution-id><institution-id institution-id-type="ISNI">0000 0001 2177 6375</institution-id><institution>Department of Physical Medicine and Rehabilitation, </institution><institution>University of Kansas Medical Center, </institution></institution-wrap>3901 Rainbow Blvd, Kansas City, 66160 USA </aff>
      <aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="GRID">grid.5606.5</institution-id><institution-id institution-id-type="ISNI">0000 0001 2151 3065</institution-id><institution>Department of informatics, Bioengineering, Robotics and System Engineering-DIBRIS, </institution><institution>University of Genova, </institution></institution-wrap>Via All’Opera Pia, 13, 16145 Genoa, Italy </aff>
      <aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="GRID">grid.28703.3e</institution-id><institution-id institution-id-type="ISNI">0000 0000 9040 3743</institution-id><institution>Faculty of Information Technology, International WIC Institute, </institution><institution>Beijing University of Technology, </institution></institution-wrap>Beijing, 100124 China </aff>
      <aff id="Aff9"><label>9</label>Beijing International Collaboration Base on Brain Informatics and Wisdom Services, Beijing, 100124 China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>20</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>20</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>12</month>
      <year>2021</year>
    </pub-date>
    <volume>8</volume>
    <issue>1</issue>
    <elocation-id>14</elocation-id>
    <history>
      <date date-type="received">
        <day>2</day>
        <month>5</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>6</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Neuronal signals generally represent activation of the neuronal networks and give insights into brain functionalities. They are considered as fingerprints of actions and their processing across different structures of the brain. These recordings generate a large volume of data that are susceptible to noise and artifacts. Therefore, the review of these data to ensure high quality by automatically detecting and removing the artifacts is imperative. Toward this aim, this work proposes a custom-developed automatic artifact removal toolbox named, SANTIA (SigMate Advanced: a Novel Tool for Identification of Artifacts in Neuronal Signals). Developed in Matlab, SANTIA is an open-source toolbox that applies neural network-based machine learning techniques to label and train models to detect artifacts from the invasive neuronal signals known as local field potentials.</p>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Local field potential</kwd>
      <kwd>Artifacts</kwd>
      <kwd>Neural networks</kwd>
      <kwd>Machine learning</kwd>
      <kwd>Neuronal signals</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010016</institution-id>
            <institution>Nottingham Trent University</institution>
          </institution-wrap>
        </funding-source>
        <award-id>PhD studentship 2019</award-id>
        <principal-award-recipient>
          <name>
            <surname>Fabietti</surname>
            <given-names>Marcos</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002888</institution-id>
            <institution>Beijing Municipal Commission of Education</institution>
          </institution-wrap>
        </funding-source>
        <award-id>KM201710005026</award-id>
        <principal-award-recipient>
          <name>
            <surname>Chen</surname>
            <given-names>Jianhui</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100012166</institution-id>
            <institution>National Basic Research Program of China (973 Program)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2014CB744600</award-id>
        <principal-award-recipient>
          <name>
            <surname>Chen</surname>
            <given-names>Jianhui</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004826</institution-id>
            <institution>Natural Science Foundation of Beijing Municipality</institution>
          </institution-wrap>
        </funding-source>
        <award-id>4182005</award-id>
        <principal-award-recipient>
          <name>
            <surname>Chen</surname>
            <given-names>Jianhui</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2021</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par2">Neural recordings give insight into the brain’s structures and functions. The recording systems aim to capture the electrical activity of the biological structures; however, these are not isolated systems and activities from other sources are also recorded. Besides, faulty equipment handling, electrical stimulation, or movements of electrodes can cause distortions in the recordings. As part of the recording process, the recordings must be reviewed to identify corrupted segments and address them, as they are detrimental for any posterior analysis. This includes artifact removal (e.g., filtering, template subtraction, or advanced computational techniques) or discarding the segment.</p>
    <p id="Par3">Each neural recording session produces a huge volume of data, especially if it is obtained over a long period of time and the experiment requires repetition. The amount of data gets multiplied by the number of recording sites. The post-experimental reviewing process consisting of annotating long recordings for evoked responses or unusual activities, which may happen in a much smaller time scale (e.g., 0.1 s in an hour), is a tedious and tiresome task. By automating this task, the researcher can focus on the interpretation task for diagnosis or an application. Employing machine learning (ML) algorithms, which have the ability to learn from patterns to predict unseen data, has been successful in the literature. However, a computational background is required to apply them successfully as there are intricacies such as defining hyper-parameters.</p>
    <p id="Par4">Research groups in the neuroscience community have developed and shared toolboxes for analyzing neural recordings [<xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR3">3</xref>]. Given the wide arrange of neuronal signals, data formats, analysis techniques, and purposes, each one has advocated their efforts into specific elements. Table <xref rid="Tab1" ref-type="table">1</xref> lists the available open toolboxes and their functions in regard to aiding noise detection and removal in local field potential signals (LFP). An in-depth analysis of these toolboxes is reported in [<xref ref-type="bibr" rid="CR4">4</xref>]. Hence, the description below will be dedicated to elaborate on the reported toolboxes.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Open-source toolboxes and noise detection and removal functionalities</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Artifact detection</th><th align="left">Digital filtering</th><th align="left">Data visual.</th><th align="left">Spectral analysis</th><th align="left">Stim. art. removal</th><th align="left">File oper.</th><th align="left">Multiple formats</th></tr></thead><tbody><tr><td align="left">Brainstorm [<xref ref-type="bibr" rid="CR5">5</xref>]</td><td align="left"><inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M2"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq1.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M4"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq2.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M6"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq3.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M8"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq4.gif"/></alternatives></inline-formula></td><td align="left">X</td><td align="left">X</td><td align="left"><inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M10"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq5.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">BSMART [<xref ref-type="bibr" rid="CR6">6</xref>]</td><td align="left">X</td><td align="left">X</td><td align="left"><inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M12"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq6.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M14"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq7.gif"/></alternatives></inline-formula></td><td align="left">X</td><td align="left">X</td><td align="left"><inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M16"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq8.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">Chronux [<xref ref-type="bibr" rid="CR7">7</xref>]</td><td align="left">X</td><td align="left">X</td><td align="left"><inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M18"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq9.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M20"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq10.gif"/></alternatives></inline-formula></td><td align="left">X</td><td align="left">X</td><td align="left">X</td></tr><tr><td align="left">Elephant [<xref ref-type="bibr" rid="CR8">8</xref>]</td><td align="left">X</td><td align="left">X</td><td align="left"><inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M22"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq11.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M24"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq12.gif"/></alternatives></inline-formula></td><td align="left">X</td><td align="left">X</td><td align="left"><inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M26"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq13.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">Fieldtrip [<xref ref-type="bibr" rid="CR9">9</xref>]</td><td align="left">X</td><td align="left"><inline-formula id="IEq14"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M28"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq14.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq15"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M30"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq15.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq16"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M32"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq16.gif"/></alternatives></inline-formula></td><td align="left">X</td><td align="left">X</td><td align="left"><inline-formula id="IEq17"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M34"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq17.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">Klusters, NeuroScope, NDManager [<xref ref-type="bibr" rid="CR10">10</xref>]</td><td align="left">X</td><td align="left"><inline-formula id="IEq18"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M36"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq18.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq19"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M38"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq19.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq20"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M40"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq20.gif"/></alternatives></inline-formula></td><td align="left">X</td><td align="left"><inline-formula id="IEq21"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M42"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq21.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq22"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M44"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq22.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">Neo [<xref ref-type="bibr" rid="CR11">11</xref>]</td><td align="left">X</td><td align="left">X</td><td align="left"><inline-formula id="IEq23"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M46"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq23.gif"/></alternatives></inline-formula></td><td align="left">X</td><td align="left">X</td><td align="left"><inline-formula id="IEq24"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M48"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq24.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq25"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M50"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq25.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">NeuroChaT [<xref ref-type="bibr" rid="CR12">12</xref>]</td><td align="left">X</td><td align="left">X</td><td align="left"><inline-formula id="IEq26"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M52"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq26.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq27"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M54"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq27.gif"/></alternatives></inline-formula></td><td align="left">X</td><td align="left">X</td><td align="left"><inline-formula id="IEq28"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M56"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq28.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">Spycode [<xref ref-type="bibr" rid="CR13">13</xref>]</td><td align="left">X</td><td align="left"><inline-formula id="IEq29"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M58"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq29.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq30"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M60"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq30.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq31"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M62"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq31.gif"/></alternatives></inline-formula></td><td align="left">X</td><td align="left">X</td><td align="left"><inline-formula id="IEq32"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M64"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq32.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">SANTIA</td><td align="left"><inline-formula id="IEq33"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M66"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq33.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq34"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M68"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq34.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq35"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M70"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq35.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq36"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M72"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq36.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq37"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M74"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq37.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq38"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M76"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq38.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq39"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M78"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq39.gif"/></alternatives></inline-formula></td></tr></tbody></table><table-wrap-foot><p>Data visualization, stimulation artifact removal and file operations (i.e., file splitting, concatenation, column rearranging)</p></table-wrap-foot></table-wrap></p>
    <p id="Par5">Brainstorm [<xref ref-type="bibr" rid="CR5">5</xref>] is an open-source application dedicated to neuronal data visualization and processing, with an emphasis on cortical source estimation techniques and their integration with anatomical magnetic resonance imaging data. It offers an intuitive interface, powerful visualization tools, and the structure of its database allows the user to work at a higher level. BSMART [<xref ref-type="bibr" rid="CR6">6</xref>] is a toolbox intended for spectral analysis of continuous neural time series data recorded simultaneously from multiple sensors. It is composed mainly of tools for auto-regressive model estimation, spectral quantity analysis, and network analysis. All functionality has been integrated into a graphical user interface (GUI) environment designed for easy accessibility.</p>
    <p id="Par6">Chronux [<xref ref-type="bibr" rid="CR7">7</xref>] is an open-source Matlab software project for the analysis of neural signals via signal specialized modules for spectral analysis, spike sorting, local regression, audio segmentation, and other tasks. Similarly, Elephant [<xref ref-type="bibr" rid="CR8">8</xref>] is a Python library for the analysis of electrophysiological data, such as LFP or intracellular voltages. It offers a broad range of functions for analyzing multi-scale data of brain dynamics from experiments and brain simulations, such as signal-based analysis, spike-based analysis, and methods combining both signal types.</p>
    <p id="Par7">FieldTrip [<xref ref-type="bibr" rid="CR9">9</xref>] is an open-source software package developed for the analysis of electrophysiological data. It supports reading data from a large number of different file formats and includes algorithms for data preprocessing, event-related field/response analysis, parametric and non-parametric spectral analysis, forward and inverse source modeling, connectivity analysis, classification, real-time data processing, and statistical inference. Klusters, NeuroScope, and NDManager [<xref ref-type="bibr" rid="CR10">10</xref>] are a free software suite for neurophysiological data processing and visualization. NeuroScope is an advanced viewer for electrophysiological and behavioral data with limited editing capabilities, Klusters a graphical cluster cutting application for manual and semi-automatic spike sorting, and NDManager an experimental parameter and data processing manager.</p>
    <p id="Par8">Neo [<xref ref-type="bibr" rid="CR11">11</xref>] is a tool whose purpose is to handle electrophysiological data in multiple formats. Due to its unique property of being able to read or write the data from or to a variety of commonly used file formats, it is included in the list. NeuroChaT [<xref ref-type="bibr" rid="CR12">12</xref>] is an Python open-source toolbox created to standardized open-source analysis tools available for the analysis of neuronal signals recorded in vivo in the freely behaving animals.</p>
    <p id="Par9">Spycode [<xref ref-type="bibr" rid="CR13">13</xref>] is a smart tool for multi-channel data processing which possesses a vast compendium of algorithms for extracting information both at a single channel in addition to at the whole network level, and the capability of autonomously repeating the same set of computational operations to multiple recording streams, all without manual intervention.</p>
    <p id="Par10">Out of the aforementioned toolboxes, the only one that allows for artifact detection is Brainstorm. It allows for manual inspection and automatic detection of artifacts, mainly of muscular and movement origin, by filtering the signals in frequency bands (ocular 1.5–15 Hz; for ECG: 10–40 Hz; for muscle noise and some sensor artifacts: 40–240 Hz and subject movement, eye movements, and dental work 1–7 Hz) and classifying the absolute value of signal with a standard deviation threshold. However, artifacts can span a large bandwidth and studies show that they can overlap with those of the neural signals [<xref ref-type="bibr" rid="CR14">14</xref>]. As an example, the alpha band (8–12 Hz) can have oscillations of high amplitude and be falsely detected as an artifact.</p>
    <p id="Par11">There is one other toolbox that deals with LFP artifact detection. This is SigMate [<xref ref-type="bibr" rid="CR15">15</xref>–<xref ref-type="bibr" rid="CR17">17</xref>], a Matlab-based tool that incorporates standard methods to analyze spikes and electroencephalography (EEG) signals, and in-house solutions for LFP analysis. The functionality provided by SigMate include: artifact removal, both fast [<xref ref-type="bibr" rid="CR18">18</xref>] and slow [<xref ref-type="bibr" rid="CR14">14</xref>], angular tuning detection [<xref ref-type="bibr" rid="CR19">19</xref>], noise characterization [<xref ref-type="bibr" rid="CR20">20</xref>], cortical layer activation order detection, and network decoding [<xref ref-type="bibr" rid="CR21">21</xref>–<xref ref-type="bibr" rid="CR24">24</xref>], sorting of single trial LFP [<xref ref-type="bibr" rid="CR25">25</xref>–<xref ref-type="bibr" rid="CR28">28</xref>], etc. It deals with slow stimulus artifact removal through an algorithm that subtracts an estimation of the signal by averaging the peaks and valleys detected in it, eliminating the offset. In addition, it allows for visualization of the spectrogram using short-time Fourier transform of the recording to allocate artifactual frequency bands and allow their filtering, among many other analysis functionalities.</p>
    <p id="Par12">To offer a more competitive toolbox, it has been expanded with new functionalities, reported in Table <xref rid="Tab2" ref-type="table">2</xref>. These include state-of-the-art modules for artifact detection, or the analysis of any number of channels unlike SigMate which is limited to 5. Thus, in this paper, we present the SANTIA toolbox (SigMate Advanced: a Novel Tool for Identification of Artifacts in Neuronal Signals), a friendly user interface that aids the offline identification of artifacts process by simplifying the steps to train powerful computational algorithms with the minimum input of the user. For a wider adoption by the community, the toolbox is freely available online at <ext-link ext-link-type="uri" xlink:href="https://github.com/IgnacioFabietti/SANTIAtoolbox">https://github.com/IgnacioFabietti/SANTIAtoolbox</ext-link>.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Advancements of SANTIA over SigMate</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Toolbox</th><th align="left">SAD</th><th align="left">UNoC</th><th align="left">SE</th><th align="left">Up</th><th align="left">DF</th><th align="left">DV</th><th align="left">SA</th><th align="left">SAR</th><th align="left">FO</th><th align="left">MF</th></tr></thead><tbody><tr><td align="left">SigMate [<xref ref-type="bibr" rid="CR15">15</xref>]</td><td align="left">X</td><td align="left">X</td><td align="left">X</td><td align="left">X</td><td align="left"><inline-formula id="IEq45"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M80"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq45.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq46"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M82"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq46.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq47"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M84"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq47.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq48"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M86"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq48.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq49"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M88"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq49.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq50"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M90"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq50.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">SANTIA</td><td align="left"><inline-formula id="IEq51"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M92"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq51.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq52"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M94"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq52.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq53"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M96"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq53.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq54"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M98"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq54.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq55"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M100"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq55.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq56"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M102"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq56.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq57"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M104"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq57.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq58"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M106"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq58.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq59"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M108"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq59.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq60"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M110"><mml:mo stretchy="false">✓</mml:mo></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq60.gif"/></alternatives></inline-formula></td></tr></tbody></table><table-wrap-foot><p><italic>SAD</italic> state-of-the-art artifact detection, <italic>UNoC</italic> unlimited number of channels, <italic>SE</italic> supported environment, <italic>Up</italic> updates, <italic>DF</italic> digital filtering, <italic>DV</italic> data visualization, <italic>SA</italic> spectral analysis, <italic>SAR</italic> stimulation artifact removal, <italic>FO</italic> file operations, <italic>MF</italic> multiple formats</p></table-wrap-foot></table-wrap></p>
    <p id="Par13">The recording of neuronal data, especially when using multi-electrode arrays, can lead to electronic files of notable size. Figure <xref rid="Fig1" ref-type="fig">1</xref> illustrates a conducted survey of the formats of invasive neural recordings in open datasets [<xref ref-type="bibr" rid="CR29">29</xref>]. The data show that ‘.mat’ is the preferred extension for storage by a substantial margin. This emphasizes the necessity to develop tools which address the datasets available in ‘.mat’ format. Therefore, SANTIA was implemented in Matlab and works with single files containing multi-channel data files in a variety of formats. The toolbox only depends on the Deep Learning Toolbox and the basic version of Matlab 2020a and above, therefore can function in any operating system. SANTIA has been developed with the latest app development environment of Matlab, which allows it to be supported for longer and be improved with new modules, such as GUI improvements which are planned for the next update.<fig id="Fig1"><label>Fig. 1</label><caption><p>Distribution of formats of local field potential signals in open datasets, extracted from [<xref ref-type="bibr" rid="CR29">29</xref>]</p></caption><graphic xlink:href="40708_2021_135_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par14">The remainder of the paper is composed of 5 sections: Sect. <xref rid="Sec2" ref-type="sec">2</xref> describes the local field potentials; Sect. <xref rid="Sec3" ref-type="sec">3</xref> describes the methods followed by the testing results presented in Sect. <xref rid="Sec9" ref-type="sec">4</xref>. Finally, in Sect. <xref rid="Sec13" ref-type="sec">5</xref>, discussion and conclusion are presented.</p>
  </sec>
  <sec id="Sec2">
    <title>Local field potentials</title>
    <p id="Par15">Local field potentials are invasive neuronal recordings, which are equal to the sum of the activity of a neuronal population, that has been low-pass-filtered under 300 Hz, and whose amplitude ranges from a few micro-volts to hundreds of micro-volts or more depending on the studied structure [<xref ref-type="bibr" rid="CR30">30</xref>]. They can be recorded by single or multi-channel micro-electrodes (glass micro-pipettes, metal, or silicon electrodes), during in vitro or in vivo experiments to gain insight into the behavior of brain structures, and diagnosis, and are used in application such as brain–machine interfaces. Figure <xref rid="Fig2" ref-type="fig">2</xref> illustrates the concept.<fig id="Fig2"><label>Fig. 2</label><caption><p>Recording of extracellular neuronal signals from behaving rodents using linear implantable neural probe (shown in gray). Representative local field potential signals with and without movement artifacts are shown from two datasets. The blue traces denote signals without artifacts and the red traces show examples of movement artifacts present in the signals</p></caption><graphic xlink:href="40708_2021_135_Fig2_HTML" id="MO2"/></fig></p>
    <p id="Par16">As with all neuronal signals, their recording process can be influenced by internal and external factors, causing artifacts. Within an organism, electric potentials are also generated mainly from ocular, muscle, or heart activity, i.e., electrooculogram, electromyogram, and electrocardiogram, respectively. Examples of external sources include transmission lines, cellphone signals, and faulty experimental setup. Local field potentials in particular can be affected by spike bleed-through [<xref ref-type="bibr" rid="CR31">31</xref>], light stimulation [<xref ref-type="bibr" rid="CR32">32</xref>], respiration-coupled oscillations [<xref ref-type="bibr" rid="CR33">33</xref>], and deep brain stimulation artifacts [<xref ref-type="bibr" rid="CR34">34</xref>].</p>
    <p id="Par17">The consequences of the presence of artifacts can be detrimental, such as misdiagnosis, disturbance of the study of the brain activity, or causing a brain–machine interface device to be mistakenly operated. Looking at the case of another neuronal signal, EEG signals, the presence of abnormalities raised the median review time from 8.3 to 20.7 min [<xref ref-type="bibr" rid="CR35">35</xref>]. To make use of these recording successfully, these artifacts must be first identified and then dealt with. The use of computational techniques which are able to learn from complex data patterns has yielded promising results in the field. In the next section, they will be described.</p>
  </sec>
  <sec id="Sec3">
    <title>Methods</title>
    <sec id="Sec4">
      <title>Artifact detection</title>
      <p id="Par18">While there are many contributions on artifact detection in neuronal signals, specially non-invasive ones like EEG, the same cannot be said about LFP. For the latter, the main approach has been the application of ML algorithms in the form of artificial neural networks.</p>
      <p id="Par19">Artificial intelligence has been used for analysis of patterns and classification in diverse fields such as, anomaly detection [<xref ref-type="bibr" rid="CR29">29</xref>, <xref ref-type="bibr" rid="CR36">36</xref>–<xref ref-type="bibr" rid="CR44">44</xref>], biological data mining [<xref ref-type="bibr" rid="CR45">45</xref>, <xref ref-type="bibr" rid="CR46">46</xref>], disease detection [<xref ref-type="bibr" rid="CR47">47</xref>–<xref ref-type="bibr" rid="CR58">58</xref>], monitoring of human [<xref ref-type="bibr" rid="CR59">59</xref>–<xref ref-type="bibr" rid="CR62">62</xref>], financial forecasting [<xref ref-type="bibr" rid="CR63">63</xref>], image analysis [<xref ref-type="bibr" rid="CR64">64</xref>, <xref ref-type="bibr" rid="CR65">65</xref>], and natural language processing [<xref ref-type="bibr" rid="CR66">66</xref>–<xref ref-type="bibr" rid="CR68">68</xref>]. Most of the time, these algorithms are composed of multiple layers of neurons for processing of non-linear information and were inspired by how the human brain works. Each neuron calculates an inner product of its inputs (<inline-formula id="IEq61"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{i}$$\end{document}</tex-math><mml:math id="M112"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq61.gif"/></alternatives></inline-formula>) and their respective weights (<inline-formula id="IEq62"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_{i}$$\end{document}</tex-math><mml:math id="M114"><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq62.gif"/></alternatives></inline-formula>), and then, the bias (<italic>b</italic>) is added and, finally, the non-linear activation function is applied, which in most cases is a sigmoid function, <italic>tan</italic> hyperbolic, or rectified linear unit. Thus, the output of a neuron (<inline-formula id="IEq63"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$z_{i}$$\end{document}</tex-math><mml:math id="M116"><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq63.gif"/></alternatives></inline-formula>) can be expressed as detailed in Eq. <xref rid="Equ1" ref-type="">1</xref><disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$z_{i}=f\left(\sum _{i=1}^{n}x_{i}w_{i}+b\right).$$\end{document}</tex-math><mml:math id="M118" display="block"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mfenced close=")" open="("><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic xlink:href="40708_2021_135_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>To propagate the information and train the network, the output of a layer is fed as input to the subsequent unit in the next layer. The result of the final output layer is used as the solution for the problem.</p>
      <p id="Par20">There are many variations of the neural network architecture based on their principles in determining their rules. For example, authors in [<xref ref-type="bibr" rid="CR69">69</xref>] trained a multi-layered perceptron (MLP) to identify slow-waves in LFP. An MLP is composed of three sections: an input layer, a hidden layer, and an output layer, where the units of the latter two use the non-linear activation defined in Eq. <xref rid="Equ1" ref-type="">1</xref>. The modeling complex of non-linear relations improves when it contains multiple numbers of hidden layers, compared to a shallow architecture [<xref ref-type="bibr" rid="CR70">70</xref>].</p>
      <p id="Par21">In our earlier publications [<xref ref-type="bibr" rid="CR37">37</xref>], an MLP is employed to identify artifacts in LFP along with two other architectures: long short-term memory (LSTM) networks and one dimensional convolutional neural network (1D-CNN) [<xref ref-type="bibr" rid="CR71">71</xref>, <xref ref-type="bibr" rid="CR72">72</xref>]. The diagrams of the main components of these architectures are depicted in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. The LSTM architecture is a type of recurrent network spanning adjacent time steps in a manner that at every point the neurons take the current data input as well as the values of the hidden neurons that collect the information of the previous time steps. On the other hand, convolutional networks are a specific form of neural network that is well suited to computer vision applications due to their capacity to hierarchically abstract representations of spatial operations. A variation of it, designed for problems where the input is a time sequence, is named 1D-CNN.<fig id="Fig3"><label>Fig. 3</label><caption><p>Architectures of different neural network models: multi-layer perceptron (<bold>A</bold>), long short-term memory (<bold>B</bold>), and one-dimension convolutional neural network (<bold>C</bold>). Each circle represents a neuron, multiple rectangles a layer’s depth, and the arrows how the information is propagated throughout each network</p></caption><graphic xlink:href="40708_2021_135_Fig3_HTML" id="MO4"/></fig></p>
      <p id="Par22">A comparison of the results obtained can be seen in Table <xref rid="Tab3" ref-type="table">3</xref>. Unlike other machine learning techniques where expertise is required to extract significant features from the signals and which may cause bias in itself, these results indicate that neural networks have the capacity to do it automatically. In addition, it is done in a computationally efficient way: 1-min LFP sampled at 1017 Hz analyzed in 2.27 s equal 26,881 data points analyzed per second. As a negative, the training of the neural network is the step where most time and computational power are consumed.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Performance comparison, extracted from [<xref ref-type="bibr" rid="CR72">72</xref>]</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Network</th><th align="left">Accuracy</th><th align="left">Parameters</th><th align="left">Computational time (s)</th></tr></thead><tbody><tr><td align="left">1D-CNN [<xref ref-type="bibr" rid="CR72">72</xref>]</td><td char="." align="char">95.1</td><td char="." align="char">561218</td><td char="±" align="char">2.27 ± 0.13</td></tr><tr><td align="left">MLP [<xref ref-type="bibr" rid="CR37">37</xref>]</td><td char="." align="char">93.2</td><td char="." align="char">1532</td><td char="±" align="char">2.57 ± 0.06</td></tr><tr><td align="left">LSTM [<xref ref-type="bibr" rid="CR71">71</xref>]</td><td char="." align="char">87.1</td><td char="." align="char">4418</td><td char="±" align="char">3.47 ± 0.04</td></tr></tbody></table></table-wrap></p>
      <p id="Par23">Having described the classification algorithm that will be used in the toolbox, we proceed to detail its use in the next section.</p>
    </sec>
    <sec id="Sec5">
      <title>Operation</title>
      <p id="Par24">The toolbox can be directly downloaded from the Github repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/IgnacioFabietti/SANTIAtoolbox">https://github.com/IgnacioFabietti/SANTIAtoolbox</ext-link>). Once the toolbox is launched, the GUI provides easy access to all modules. It is important to highlight that SANTIA is a generic environment structured around one single interface in which specific functions were implemented, not a library of functions on top of which a GUI has been added to simplify access.</p>
      <p id="Par25">It is structured in three main modules, designed to perform various processing and analysis on the neuronal signal files. The main functionalities of the first one include: data loading, scaling, reshaping, channel selection, labeling, saving, and 2D display. The second module is composed of: data loading and splitting, hyper-parameter setting, network load or design, network train, test set classification, and threshold setting and saving. Finally, the third one comprehends: data and network loading, classification, and 2D data display and saving.</p>
      <p id="Par26">The GUI allows for user interaction via the selection of functions, parameters, and keyboard inputs, which are processed in the back end. A verification routine executes before running any function to ensure the user has not skipped a step or has not completed the necessary inputs or parameter selection. This minimizes the possible human errors and time expenditure. In case of doubt of the purpose of an element of the GUI, tool tips appear when hovering the cursor over it with a brief explanation.</p>
      <p id="Par27">The functions to display warning messages, generate figures, and compute the labeling, training, or classification are allocated in the back end. These developed features were tested with a dataset recorded from a 4-shank, 16-contact site electrode from anesthetized rats. At the end of each module, the respective outputs can be exported to a ‘.mat’ file, which can easily be utilized in other applications due to the accessibility of the format.</p>
      <p id="Par28">The following sections describe the individual modules in greater detail. As a visual aid, Fig. <xref rid="Fig4" ref-type="fig">4</xref> shows the screenshots of the software package, Fig. <xref rid="Fig5" ref-type="fig">5</xref> illustrates the function block diagram, and finally, Fig. <xref rid="Fig6" ref-type="fig">6</xref> shows the workflow diagram.<fig id="Fig4"><label>Fig. 4</label><caption><p>Screenshots of the SANTIA toolbox graphical user interface: Data Labeling (<bold>A</bold>), Neural Network Training (<bold>B</bold>), and Classify New Unlabeled Data (<bold>C</bold>)</p></caption><graphic xlink:href="40708_2021_135_Fig4_HTML" id="MO5"/></fig><fig id="Fig5"><label>Fig. 5</label><caption><p>Functional block diagram of the Toolbox.Arrows in black correspond to the “Data Labeling” module , in red to the “Neural Network Training” module, in dark blue to the “Classify New Unlabeled Data” module, and the purple arrows indicate the progress output</p></caption><graphic xlink:href="40708_2021_135_Fig5_HTML" id="MO6"/></fig><fig id="Fig6"><label>Fig. 6</label><caption><p>Workflow of the SANTIA toolbox, where the “Data Labeling” modules are colored yellow, the “Neural Network Training” modules in green, and “Classify New Unlabeled Data” modules in blue</p></caption><graphic xlink:href="40708_2021_135_Fig6_HTML" id="MO7"/></fig></p>
      <sec id="Sec6">
        <title>Data labeling</title>
        <p id="Par29">In the first module, the process begins with the ‘Load Signals’ button, which opens the import wizard to load the neural recordings as an <inline-formula id="IEq67"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m \times n$$\end{document}</tex-math><mml:math id="M120"><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq67.gif"/></alternatives></inline-formula> matrix, where m is the number of channels and n are the data points of each channel signal. The compatible formats include ASCII-based text (.txt, .dat, .out, .csv), spreadsheets files (.xls, .xlsx, .xlsm), and Matab files (.set, .mat), which correspond to 93% of the surveyed data in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. The user is required to input the sampling frequency in Hz and the window length in seconds that they wish to analyze. In addition, the unit of the recording and the opportunity to scale is presented, as lots of errors happen due to incorrect annotations of magnitudes.</p>
        <p id="Par30">Once all of these parameters have been filled, ‘Generate Analysis Matrix’ will structure the data for posterior analysis. This means that given a window length <italic>w</italic>, and sampling frequency <italic>f</italic>, the <inline-formula id="IEq68"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m \times n$$\end{document}</tex-math><mml:math id="M122"><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq68.gif"/></alternatives></inline-formula> matrix becomes a new <inline-formula id="IEq69"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p \times q$$\end{document}</tex-math><mml:math id="M124"><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq69.gif"/></alternatives></inline-formula> one, where <inline-formula id="IEq70"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p=\frac{m \times n}{w \times f}$$\end{document}</tex-math><mml:math id="M126"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq70.gif"/></alternatives></inline-formula> and <inline-formula id="IEq71"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$q= w \times f$$\end{document}</tex-math><mml:math id="M128"><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq71.gif"/></alternatives></inline-formula>. This is incorporated into a table that has row names that follow the format ‘file_id+_channel_+i+_window_j’ where file_id is the name of the LFP data file, <italic>i</italic> the number of channels where <inline-formula id="IEq72"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i=1, \ldots, m$$\end{document}</tex-math><mml:math id="M130"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq72.gif"/></alternatives></inline-formula> and <italic>j</italic> the corresponding window. In addition, its columns are named: first “window_power” followed by the values of the signal <inline-formula id="IEq73"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t_k$$\end{document}</tex-math><mml:math id="M132"><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq73.gif"/></alternatives></inline-formula> where <inline-formula id="IEq74"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=1, \ldots, q$$\end{document}</tex-math><mml:math id="M134"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq74.gif"/></alternatives></inline-formula>. As this process involves the creation of <italic>p</italic> amount of row names and window’s power, a memory check is done to read available memory and alert if the usage of more than 80% of the available memory would be needed.</p>
        <p id="Par31">The option to save these data for posterior classification is presented as ‘Save Unlabeled Data’. Otherwise, the user continues by selecting a channel in the drop-down menu or clicking on a table cell and the ‘Threshold Selection Table’ process. This opens a new window with the structured data table, and by clicking on a row, the options to plot the selected window or to define its power as a threshold value appear. As a visual aid, windows with same or higher power are colored red and those with less green, i.e., artifactual and normal, respectively.</p>
        <p id="Par32">In another manner, the user can manually input threshold values in the main app’s table, and once he has completed it for all channels, the data can be labeled and saved as a standardized struct, which contains the original filename, the structured data with its labels, the sampling frequency, window length, the scale, and the threshold values. This information allows researchers to quickly identify different matrices they create and wish to compare. An aid in form of text in the ‘Progress’ banner allows the users to know when each step has been completed, and it is replicated throughout each module.</p>
        <p id="Par33">The user can also structure the data for SigMate analysis. The toolbox expects a <inline-formula id="IEq75"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\text{datapoints} (n) \times \text{channels} (m)$$\end{document}</tex-math><mml:math id="M136"><mml:mrow><mml:mtext>datapoints</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mtext>channels</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq75.gif"/></alternatives></inline-formula> format, with the first column as timestamp and each of the channel’s signal in the following columns. In addition, as it only handles five channels at a time, <italic>m</italic>/5 files have to be generated. Thus, SANTIA transposes the input matrix, generates the timestamp based on the declared sampling frequency, and generates the files. Afterward, it asks the user to select a directory to save them.</p>
      </sec>
      <sec id="Sec7">
        <title>Neural network training</title>
        <p id="Par34">The second module starts with loading structured data from the previous module. The user is asked to set the values for training, validation, and test splitting. This is common practice to avoid over- and under-fitting results. As artifacts are rare events, the datasets usually present strong imbalance which can cause bias in the training; a tick box for balancing the data is present next to the ‘Split’ button. Clicking it generates three datasets with non-repetitive randomized elements from the original matrix.</p>
        <p id="Par35">This is followed by choosing the network, where the options are MLP, LSTM, 1D-CNN, or for the user to load his/her custom set of layers. This is done by choosing a Matlab file which has a Layer-type variable, i.e., layers that define the architecture of neural networks for deep learning, without the pre-trained weights. These can be modified via console or the Deep Network Designer Toolbox, and for more information, we direct the reader to the mathworks page<xref ref-type="fn" rid="Fn1">1</xref>. While employing different architectures might yield better results, it is also possible that they might not be structured properly and lead to under-fitting, over-fitting, or fail to learn at all. Therefore, a limitation of employing custom networks is the time consumption that takes getting the correct combination of layers, as well as setting parameters such as filter size or activation function. Optionally, the user can customize the training hyper-parameters such as the solver, initial learning rate, and execution environment, among others. These intentionally mirror the ones included in the Deep Network Designer to facilitate its usage to those familiarized with it. These are removed for the MLP option, as it uses a different toolbox (i.e., patternnet of Deep Learning Toolbox [<xref ref-type="bibr" rid="CR73">73</xref>]), which thus does not allow the same configurations. Clicking the ‘Create Network” button loads the training options and sets the input layer to match the window size.</p>
        <p id="Par37">The ‘Train Network’ button runs the train network function, which inherits the training options and network previously defined. For the 1D-CNN, as the deep learning toolbox is intended for images, the 2D matrices are resized to a 4D vector: 1 × window length × 1  × number of windows, originally intended to be: width × height × channels × number of examples. A display of the training process automatically appears, unless the user decides not to, which enables monitoring the process and early stopping.</p>
        <p id="Par38">Having completed the training, the user can select whether the ‘Classify Test Set’ displays the confusion matrix, the area under the receiver-operating characteristic (AUROC) curve, or opens up a new window where the accuracy, F1 score, and confusion matrix appear along with the possibility to modify the classification threshold (set at 0.5 by default). Finally, ‘Save Results’ creates a struct with data’s filename, the trained network, the training information, the test set’s classification threshold, AUROC, accuracy, F1 score, and confusion matrix.</p>
      </sec>
      <sec id="Sec8">
        <title>Classify new unlabeled data</title>
        <p id="Par39">The last module begins with loading a trained net along with its classification threshold and unlabeled structured data. After its classification, the options to plot each of the windows with the corresponding color-coded label appear. Finally, users can save the labels as a table with the corresponding window name. Having described the toolbox’s methods, components, and its functions, we proceed to a test case with real recorded LFP.</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec9">
    <title>Results</title>
    <p id="Par40">In this section, we describe the datasets used to test the app, and the results obtained from them. The artifact detection task carried out by SANTIA toolbox was tested on a daily usage grade Acer TravelMate P278-MGlaptop consisting of 8 gigabyte of RAM and Intel®Core™i7-6500U CPU @ 2.50 GHz processor.</p>
    <sec id="Sec10">
      <title>Dataset 1</title>
      <p id="Par43">A publicly available dataset [<xref ref-type="bibr" rid="CR74">74</xref>] was used to test the toolbox. Thorough details of the recording and experiment are explained in the article linked to the dataset [<xref ref-type="bibr" rid="CR75">75</xref>]. Male Long Evans rats (Charles River, Frederick, MD, USA) weighing from 280 to 300 g were trained to walk on a circular treadmill. The recorded LFP were sampled at 2 kHz, and after low-pass filtering, they were amplified times a thousand and band-pass filtered (0.7–150 Hz).</p>
      <p id="Par44">For the purpose of testing the toolbox, only the baseline recordings (prior to ketamine injection) were used. Baseline recordings were composed of at least two 5-min counter-clockwise walking cycles on a slow-moving treadmill and two 40-s rest periods without artifacts. Visual evaluation and videotaped motor activity were used to classify artifact-free periods of 100 s in treadmill-on epochs and 40 to 100 second periods in treadmill-off epochs, which are detailed in Table <xref rid="Tab4" ref-type="table">4</xref>. These labeled artifact-free epochs were used to extract the threshold power value for each channel. It was chosen as the maximum power of the windows in those intervals, for each respective window size.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Guide to determine best channels and epochs to use of baseline walk and rest recordings in medial prefrontal cortex (mPFC) and the mediodorsal (MD) thalamus, as mentioned in the file named “Coherence Phase Plot Guide”</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Rat</th><th align="left">mPFC chan1</th><th align="left">mPFC chan2</th><th align="left">MD chan1</th><th align="left">MD chan2</th><th align="left">Walk epoch</th><th align="left">Rest epoch</th></tr></thead><tbody><tr><td align="left">KF9</td><td char="." align="char">5</td><td char="." align="char">6</td><td char="." align="char">3</td><td char="." align="char">7</td><td align="left">960–1160</td><td align="left">3780–3820</td></tr><tr><td align="left">KF10</td><td char="." align="char">3</td><td char="." align="char">4</td><td char="." align="char">3</td><td char="." align="char">8</td><td align="left">670–860</td><td align="left">1260–1390</td></tr><tr><td align="left">KF14</td><td char="." align="char">2</td><td char="." align="char">6</td><td char="." align="char">5</td><td char="." align="char">7</td><td align="left">740–940</td><td align="left">3350–3550</td></tr><tr><td align="left">KF15</td><td char="." align="char">3</td><td char="." align="char">4</td><td char="." align="char">5</td><td char="." align="char">7</td><td align="left">450–640</td><td align="left">1600–1700</td></tr><tr><td align="left">KF25</td><td char="." align="char">2</td><td char="." align="char">6</td><td char="." align="char">2</td><td char="." align="char">5</td><td align="left">1480–1680</td><td align="left">1700–1800</td></tr><tr><td align="left">KF26</td><td char="." align="char">1</td><td char="." align="char">6</td><td char="." align="char">1</td><td char="." align="char">6</td><td align="left">1180–1380</td><td align="left">1050–1150</td></tr><tr><td align="left">KF27</td><td char="." align="char">2</td><td char="." align="char">4</td><td char="." align="char">5</td><td char="." align="char">8</td><td align="left">480–680</td><td align="left">2160–2250</td></tr></tbody></table><table-wrap-foot><p>The first column is the rat identification, column 2 and 3 the selected two best channels of the mPFC recordings, and 4 and 5 of the MD recordings. Finally, column 6 shows the range of artifact-free epochs during walking and column 7 during resting, respectively [<xref ref-type="bibr" rid="CR74">74</xref>]</p></table-wrap-foot></table-wrap></p>
      <p id="Par45">To understand the effect of window size on the artifact detection process, different windows of 0.05, 0.1, 0.15, and 0.2 s were taken and fed to the model. The number of examples obtained after downsampling to balance the classes was on average 275, 687 per window size. For the 1D-CNN and LSTM, the optimization algorithm used was Adam, with an initial learning rate of 0.001, the momentum of 0.9, and a batch size of 1280. On the other hand, the MLP was optimized via a scaled conjugate gradient function. The performance of the models during training is shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>. As they originate from different toolboxes, the MLP does not generate the accuracy throughout the training, and thus, it is not shown.<fig id="Fig7"><label>Fig. 7</label><caption><p>Training plots for models trained with the first dataset</p></caption><graphic xlink:href="40708_2021_135_Fig7_HTML" id="MO8"/></fig></p>
      <p id="Par46">These results are consistent with previously obtained ones. They indicate that since the filters from the 1D-CNN learn from regions of the signal, instead of the individual values, they are able to learn more robust features of the signals and lead to better classification. Performance on the test sets is similar to that obtained in the validation set, as shown in Table <xref rid="Tab5" ref-type="table">5</xref>. The best test set classification results were achieved by the 50 ms 1D-CNN, an accuracy of <inline-formula id="IEq82"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$96.5\%$$\end{document}</tex-math><mml:math id="M138"><mml:mrow><mml:mn>96.5</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="40708_2021_135_Article_IEq82.gif"/></alternatives></inline-formula>, and an AUROC of 0.993, indicating that the network has been able to learn successfully.<table-wrap id="Tab5"><label>Table 5</label><caption><p>First dataset’s results for different architectures and sequence length: training loss, validation accuracy, testing accuracy, and testing AUROC</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Network</th><th align="left">Sequence length (ms)</th><th align="left">Training loss</th><th align="left">Val. Acc.</th><th align="left">Test Acc.</th><th align="left">Test AUROC</th></tr></thead><tbody><tr><td align="left" rowspan="4">MLP</td><td char="." align="char">50</td><td char="." align="char">0.20</td><td char="." align="char">0.92</td><td char="." align="char">0.92</td><td char="." align="char">0.98</td></tr><tr><td char="." align="char">100</td><td char="." align="char">0.41</td><td char="." align="char">0.82</td><td char="." align="char">0.81</td><td char="." align="char">0.90</td></tr><tr><td char="." align="char">150</td><td char="." align="char">0.39</td><td char="." align="char">0.83</td><td char="." align="char">0.83</td><td char="." align="char">0.90</td></tr><tr><td char="." align="char">200</td><td char="." align="char">0.24</td><td char="." align="char">0.91</td><td char="." align="char">0.91</td><td char="." align="char">0.97</td></tr><tr><td align="left" rowspan="4">1D-CNN</td><td char="." align="char"><bold>50</bold></td><td char="." align="char"><bold>0.10</bold></td><td char="." align="char"><bold>0.96</bold></td><td char="." align="char"><bold>0.97</bold></td><td char="." align="char"><bold>0.99</bold></td></tr><tr><td char="." align="char">100</td><td char="." align="char">0.39</td><td char="." align="char">0.84</td><td char="." align="char">0.84</td><td char="." align="char">0.89</td></tr><tr><td char="." align="char">150</td><td char="." align="char">0.37</td><td char="." align="char">0.83</td><td char="." align="char">0.83</td><td char="." align="char">0.91</td></tr><tr><td char="." align="char">200</td><td char="." align="char">0.36</td><td char="." align="char">0.83</td><td char="." align="char">0.83</td><td char="." align="char">0.91</td></tr><tr><td align="left" rowspan="4">LSTM</td><td char="." align="char">50</td><td char="." align="char">0.16</td><td char="." align="char">0.93</td><td char="." align="char">0.94</td><td char="." align="char">0.99</td></tr><tr><td char="." align="char">100</td><td char="." align="char">0.26</td><td char="." align="char">0.90</td><td char="." align="char">0.91</td><td char="." align="char">0.97</td></tr><tr><td char="." align="char">150</td><td char="." align="char">0.25</td><td char="." align="char">0.89</td><td char="." align="char">0.90</td><td char="." align="char">0.97</td></tr><tr><td char="." align="char">200</td><td char="." align="char">0.25</td><td char="." align="char">0.91</td><td char="." align="char">0.90</td><td char="." align="char">0.97</td></tr></tbody></table><table-wrap-foot><p>Values pertaining to model’s best performance are highlighted in bold</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec11">
      <title>Dataset 2</title>
      <p id="Par48">The toolbox was tested using LFP recorded from rats as previously described in [<xref ref-type="bibr" rid="CR37">37</xref>, <xref ref-type="bibr" rid="CR76">76</xref>]. The LFP were downsampled to 1017.3 Hz and low-pass filtered (with a 0–500 Hz cut-off frequency). 294, 592 zero-mean examples were used in this task which were divided into training (80%), validation (10%), and testing (10%) sets, and used to train the models with the same hyper-parameter configuration used with the previous dataset.</p>
      <p id="Par49">Figure <xref rid="Fig8" ref-type="fig">8</xref> displays the performance of the training and validation set of the different sequence lengths for the two architectures, while the results are compiled in Table <xref rid="Tab6" ref-type="table">6</xref>. Overall, the 1D-CNN outperforms the MLP and LSTM across window sizes. Models with input size of 150 ms have the lowest losses and highest accuracies, meaning that it is the best trade-off between information fed the model and its performance, among the chosen window sizes for this dataset. As shown, different datasets are probable to have different optimal trade-offs between window size and accuracy, due to factors such as sampling rate and artifact frequency.<fig id="Fig8"><label>Fig. 8</label><caption><p>Training plots for models trained with the second dataset</p></caption><graphic xlink:href="40708_2021_135_Fig8_HTML" id="MO9"/></fig><table-wrap id="Tab6"><label>Table 6</label><caption><p>Second dataset’s results for different architectures and sequence length: training loss, validation accuracy, testing accuracy, and testing AUROC</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Network</th><th align="left">Sequence length (ms)</th><th align="left">Training loss</th><th align="left">Val. Acc.</th><th align="left">Test Acc.</th><th align="left">Test AUROC</th></tr></thead><tbody><tr><td align="left" rowspan="4">MLP</td><td char="." align="char">50</td><td char="." align="char">0.24</td><td char="." align="char">0.78</td><td char="." align="char">0.78</td><td char="." align="char">0.857</td></tr><tr><td char="." align="char">100</td><td char="." align="char">0.27</td><td char="." align="char">0.89</td><td char="." align="char">0.86</td><td char="." align="char">0.94</td></tr><tr><td char="." align="char">150</td><td char="." align="char">0.15</td><td char="." align="char">0.94</td><td char="." align="char">0.95</td><td char="." align="char">0.99</td></tr><tr><td char="." align="char">200</td><td char="." align="char">0.16</td><td char="." align="char">0.94</td><td char="." align="char">0.96</td><td char="." align="char">0.98</td></tr><tr><td align="left" rowspan="4">1D-CNN</td><td char="." align="char">50</td><td char="." align="char">0.18</td><td char="." align="char">0.92</td><td char="." align="char">0.91</td><td char="." align="char">0.97</td></tr><tr><td char="." align="char">100</td><td char="." align="char">0.15</td><td char="." align="char">0.94</td><td char="." align="char">0.96</td><td char="." align="char">0.97</td></tr><tr><td char="." align="char"><bold>150</bold></td><td char="." align="char"><bold>0.01</bold></td><td char="." align="char"><bold>0.99</bold></td><td char="." align="char"><bold>0.99</bold></td><td char="." align="char"><bold>0.99</bold></td></tr><tr><td char="." align="char">200</td><td char="." align="char">0.08</td><td char="." align="char">0.98</td><td char="." align="char">0.97</td><td char="." align="char">0.99</td></tr><tr><td align="left" rowspan="4">LSTM</td><td char="." align="char">50</td><td char="." align="char">0.25</td><td char="." align="char">0.86</td><td char="." align="char">0.86</td><td char="." align="char">0.94</td></tr><tr><td char="." align="char">100</td><td char="." align="char">0.26</td><td char="." align="char">0.89</td><td char="." align="char">0.89</td><td char="." align="char">0.96</td></tr><tr><td char="." align="char">150</td><td char="." align="char">0.02</td><td char="." align="char">0.97</td><td char="." align="char">0.97</td><td char="." align="char">0.99</td></tr><tr><td char="." align="char">200</td><td char="." align="char">0.07</td><td char="." align="char">0.96</td><td char="." align="char">0.96</td><td char="." align="char">0.99</td></tr></tbody></table><table-wrap-foot><p>Values pertaining to model’s best performance are highlighted in bold</p></table-wrap-foot></table-wrap></p>
      <p id="Par50">The results are on par with the previous dataset, indicating that the method is robust and possesses generalizability. The 1D-CNN model has shown to obtain the best scores in both cases, establishing it as the better architecture for this type of data.</p>
    </sec>
    <sec id="Sec12">
      <title>Outputs</title>
      <p id="Par52">Figures <xref rid="Fig9" ref-type="fig">9</xref>, <xref rid="Fig10" ref-type="fig">10</xref>, <xref rid="Fig11" ref-type="fig">11</xref> and <xref rid="Fig12" ref-type="fig">12</xref> show output windows of the toolbox generated during its operation. Figure <xref rid="Fig9" ref-type="fig">9</xref> displays output windows generated after the data file is loaded. They include the selection of threshold, as shown in Fig. <xref rid="Fig9" ref-type="fig">9</xref>A, where green lines show windows representing data above the threshold and red lines show below it, and two representative figures of normal (in Fig. <xref rid="Fig9" ref-type="fig">9</xref>B) and artifactual windows (in Fig. <xref rid="Fig9" ref-type="fig">9</xref>C). Figure <xref rid="Fig10" ref-type="fig">10</xref> shows the output windows for the neural network training process which currently support MLP, LSTM, and 1D-CNN. As the networks come from different Matlab-toolboxes, their individual configurations require separate processes which are represented in Fig. <xref rid="Fig10" ref-type="fig">10</xref>A, B for MLP and 1D-CNN/LSTM, respectively. After having completed the training, the different plots of the test set results of the first dataset for the 50 ms window that were generated are shown in Fig. <xref rid="Fig11" ref-type="fig">11</xref>. As a part of allowing the user to evaluate the performance of the models, these figures show the confusion matrix (see Fig. <xref rid="Fig11" ref-type="fig">11</xref>A), AUROC curve (see Fig. <xref rid="Fig11" ref-type="fig">11</xref>B), and accuracy and F1 score for given classification thresholds (see Fig. <xref rid="Fig11" ref-type="fig">11</xref>C, D). Finally, Fig. <xref rid="Fig12" ref-type="fig">12</xref> illustrates the contents of output files generated in each module. These files are saved in Matlab format (.mat) and contain key values for the user to quickly access them, as well as the processed variables needed for any posterior predictions.</p>
      <p id="Par51">
        <fig id="Fig9">
          <label>Fig. 9</label>
          <caption>
            <p>Screenshots of the toolbox’s threshold selection outputs: threshold selection table (<bold>A</bold>), a window of a non-artifactual signal (<bold>B</bold>), and a window of an artifactual signal (<bold>C</bold>)</p>
          </caption>
          <graphic xlink:href="40708_2021_135_Fig9_HTML" id="MO10"/>
        </fig>
        <fig id="Fig10">
          <label>Fig. 10</label>
          <caption>
            <p>Screenshots of the toolbox’s network training outputs: multi-layer perceptron training process (<bold>A</bold>) and one dimensional convolutional neural network training process (<bold>B</bold>)</p>
          </caption>
          <graphic xlink:href="40708_2021_135_Fig10_HTML" id="MO11"/>
        </fig>
        <fig id="Fig11">
          <label>Fig. 11</label>
          <caption>
            <p>Screenshots of the toolbox’s network test set results outputs: confusion matrix (<bold>A</bold>), AUROC curve (<bold>B</bold>), threshold selection window with default (<bold>C</bold>), and custom values (<bold>D</bold>)</p>
          </caption>
          <graphic xlink:href="40708_2021_135_Fig11_HTML" id="MO12"/>
        </fig>
        <fig id="Fig12">
          <label>Fig. 12</label>
          <caption>
            <p>Screenshots of the toolbox’s saved files: labeled data (<bold>A</bold>), trained network and results (<bold>B</bold>), and new data labels (<bold>C</bold>)</p>
          </caption>
          <graphic xlink:href="40708_2021_135_Fig12_HTML" id="MO13"/>
        </fig>
      </p>
    </sec>
  </sec>
  <sec id="Sec13">
    <title>Discussion and conclusion</title>
    <p id="Par53">We developed the SANTIA toolbox to facilitate and standardize the labeling of artifacts in recorded LFP. The simple three-module GUI is designed for researchers without a programming background, and the built-in methodology will allow them to quickly scan and detect the artifacts in their data. It is a project under constant development, and the current version provides an environment where new features can quickly be implemented and adapted to the toolbox. Examples of future developments include:</p>
    <p id="Par54"><italic>Online processing</italic> The tool currently allows for offline labeling, but we wish to expand it a allow the analysis of signals as they are being recorded, to optimize the process.</p>
    <p id="Par55"><italic>Expand format compatibility</italic> There are different libraries for deep learning such as the TensorFlow-Keras, Caffe, and the ONNX (Open Neural Network Exchange) model formats for neural network layers [<xref ref-type="bibr" rid="CR46">46</xref>]. We wish to add the possibility to read those formats, and in addition the options to import from and save to HDF5 files for the neuronal data under the epHDF standard [<xref ref-type="bibr" rid="CR77">77</xref>].</p>
    <p id="Par56"><italic>User experience</italic> As this app is adopted by the community, with the feedback, we will improve its shortcomings. The inclusion of testing data, a video tutorial and upgrades of the threshold selection to facilitate its use via graphic elements is also planned. The optimization of some routines via parallelism is also a feature we wish to include, due to the possible large sizes of data files.</p>
    <p id="Par57"><italic>Multi-modality</italic> The incorporation of another source of information (e.g., sensor signal or video) can facilitate and improve the detection of artifacts [<xref ref-type="bibr" rid="CR78">78</xref>]. A new module would allow the incorporation of such data to facilitate the labeling process or as part of a classification model’s input.</p>
    <p id="Par58"><italic>Artifact removal</italic> Future work will pursue this aspect of artifact analysis as well, with state-of-the-art techniques such as denoising autoencoders [<xref ref-type="bibr" rid="CR79">79</xref>, <xref ref-type="bibr" rid="CR80">80</xref>].</p>
    <p id="Par59"><italic>Portability</italic> As a long-term goal, we consider the implementation in a portable device, e.g., FPGA or Arduino board, to expand the practicality of its usage.</p>
    <p id="Par60">To conclude, SANTIA now represents an option for researchers looking to label artifacts in LFP recordings automatically. This is a work in progress, and some features are yet to be developed; however, the tests with a public and custom dataset have shown promising results. We hope that the neuroscience community adopts this tool, and with their feedback together with our future plans, an improved toolbox is achieved.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn id="Fn1">
      <label>1</label>
      <p id="Par36">
        <ext-link ext-link-type="uri" xlink:href="https://uk.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.layer.html">https://uk.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.layer.html</ext-link>
      </p>
    </fn>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>The authors would like to express their heartfelt gratitude to the scientists who had kindly released the data from their experiments.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>This work was done in close collaboration among the authors. MF and MM conceived the idea and designed the initial prototype of the app, MF, MM, AL, MSK and JC refined the app, performed the analysis and wrote the paper. AA, DJG, RJN and MC collected the one of the datasets and edited the paper. All authors have contributed to, seen the paper. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported by the Nottingham Trent University PhD studentship 2019 which was awarded to Marcos I. Fabietti. Also, by the Science and Technology Project of Beijing Municipal Commission of Education (No. KM201710005026), the National Basic Research Program of China (No. 2014CB744600), and the Beijing Natural Science Foundation (No. 4182005).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The source-code of the toolbox is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/IgnacioFabietti/SANTIAtoolbox">https://github.com/IgnacioFabietti/SANTIAtoolbox</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes>
      <title>Ethics approval and consent to participate</title>
      <p>Not applicable.</p>
    </notes>
    <notes>
      <title>Consent for publication</title>
      <p>Not applicable.</p>
    </notes>
    <notes id="FPar2" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par65">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Delorme</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Makeig</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title>
        <source>J Neurosci Methods</source>
        <year>2004</year>
        <volume>134</volume>
        <issue>1</issue>
        <fpage>9</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2003.10.009</pub-id>
        <pub-id pub-id-type="pmid">15102499</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Egert</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Knott</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Schwarz</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Nawrot</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Brandt</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Rotter</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Diesmann</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>MEA-tools: an open source toolbox for the analysis of multi-electrode data with MATLAB</article-title>
        <source>J Neurosci Methods</source>
        <year>2002</year>
        <volume>117</volume>
        <issue>1</issue>
        <fpage>33</fpage>
        <lpage>42</lpage>
        <pub-id pub-id-type="doi">10.1016/S0165-0270(02)00045-6</pub-id>
        <pub-id pub-id-type="pmid">12084562</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yger</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Spampinato</surname>
            <given-names>GL</given-names>
          </name>
          <name>
            <surname>Esposito</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Lefebvre</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Deny</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Gardella</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Stimberg</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Jetter</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Zeck</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Picaud</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A spike sorting toolbox for up to thousands of electrodes validated with ground truth recordings in vitro and in vivo</article-title>
        <source>Elife</source>
        <year>2018</year>
        <volume>7</volume>
        <fpage>34518</fpage>
        <pub-id pub-id-type="doi">10.7554/eLife.34518</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Unakafova</surname>
            <given-names>VA</given-names>
          </name>
          <name>
            <surname>Gail</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Comparing open-source toolboxes for processing and analysis of spike and local field potentials data</article-title>
        <source>Front Neuroinform</source>
        <year>2019</year>
        <volume>13</volume>
        <fpage>57</fpage>
        <pub-id pub-id-type="doi">10.3389/fninf.2019.00057</pub-id>
        <pub-id pub-id-type="pmid">31417389</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tadel</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Baillet</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Mosher</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Pantazis</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Leahy</surname>
            <given-names>RM</given-names>
          </name>
        </person-group>
        <article-title>Brainstorm: a user-friendly application for MEG/EEG analysis</article-title>
        <source>Comput Intell Neurosci</source>
        <year>2011</year>
        <pub-id pub-id-type="doi">10.1155/2011/879716</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cui</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Bressler</surname>
            <given-names>SL</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>BSMART: a Matlab/C toolbox for analysis of multichannel neural time series</article-title>
        <source>Neural Netw</source>
        <year>2008</year>
        <volume>21</volume>
        <issue>8</issue>
        <fpage>1094</fpage>
        <lpage>1104</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neunet.2008.05.007</pub-id>
        <pub-id pub-id-type="pmid">18599267</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bokil</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Andrews</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Kulkarni</surname>
            <given-names>JE</given-names>
          </name>
          <name>
            <surname>Mehta</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Mitra</surname>
            <given-names>PP</given-names>
          </name>
        </person-group>
        <article-title>Chronux: a platform for analyzing neural signals</article-title>
        <source>J Neurosci Methods</source>
        <year>2010</year>
        <volume>192</volume>
        <issue>1</issue>
        <fpage>146</fpage>
        <lpage>151</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2010.06.020</pub-id>
        <pub-id pub-id-type="pmid">20637804</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">Yegenoglu A et al (2015) Elephant—open-source tool for the analysis of electrophysiological data sets. In: Proc. Bernstein conference, pp 134–135</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Oostenveld</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Fries</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Maris</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Schoffelen</surname>
            <given-names>J-M</given-names>
          </name>
        </person-group>
        <article-title>FieldTrip: open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title>
        <source>Comput Intell Neurosci</source>
        <year>2011</year>
        <pub-id pub-id-type="doi">10.1155/2011/156869</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hazan</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zugaro</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Buzsáki</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Klusters, NeuroScope, NDManager: a free software suite for neurophysiological data processing and visualization</article-title>
        <source>J Neurosci Methods</source>
        <year>2006</year>
        <volume>155</volume>
        <issue>2</issue>
        <fpage>207</fpage>
        <lpage>216</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2006.01.017</pub-id>
        <pub-id pub-id-type="pmid">16580733</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Garcia</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Guarino</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Jaillet</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Jennings</surname>
            <given-names>TR</given-names>
          </name>
          <name>
            <surname>Pröpper</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Rautenberg</surname>
            <given-names>PL</given-names>
          </name>
          <name>
            <surname>Rodgers</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sobolev</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wachtler</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Yger</surname>
            <given-names>P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Neo: an object model for handling electrophysiology data in multiple formats</article-title>
        <source>Front Neuroinform</source>
        <year>2014</year>
        <volume>8</volume>
        <fpage>10</fpage>
        <pub-id pub-id-type="doi">10.3389/fninf.2014.00010</pub-id>
        <pub-id pub-id-type="pmid">24600386</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Islam</surname>
            <given-names>MN</given-names>
          </name>
          <name>
            <surname>Martin</surname>
            <given-names>SK</given-names>
          </name>
          <name>
            <surname>Aggleton</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>O’Mara</surname>
            <given-names>SM</given-names>
          </name>
        </person-group>
        <article-title>NeuroChaT: a toolbox to analyse the dynamics of neuronal encoding in freely-behaving rodents in vivo</article-title>
        <source>Wellcome Open Res</source>
        <year>2019</year>
        <volume>4</volume>
        <fpage>196</fpage>
        <pub-id pub-id-type="doi">10.12688/wellcomeopenres.15533.1</pub-id>
        <pub-id pub-id-type="pmid">32055710</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bologna</surname>
            <given-names>LL</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Investigating neuronal activity by SPYCODE multi-channel data analyzer</article-title>
        <source>Neural Netw</source>
        <year>2010</year>
        <volume>23</volume>
        <issue>6</issue>
        <fpage>685</fpage>
        <lpage>697</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neunet.2010.05.002</pub-id>
        <pub-id pub-id-type="pmid">20554151</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Girardi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Maschietto</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Rahman</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>Bertoldo</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Vassanelli</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Slow stimulus artifact removal through peak-valley detection of neuronal signals recorded from somatosensory cortex by high resolution brain–chip interface</article-title>
        <source>IFMBE Proc</source>
        <year>2009</year>
        <volume>25</volume>
        <issue>4</issue>
        <fpage>2062</fpage>
        <lpage>2065</lpage>
        <pub-id pub-id-type="doi">10.1007/978-3-642-03882-2_547</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Mahmud M, Bertoldo A, Girardi S, Maschietto M, Vassanelli S (2010) Sigmate: a MATLAB-based neuronal signal processing tool. In: Proc. IEEE EMBC, pp 1352–1355</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Mahmud M, Bertoldo A, Girardi S, Maschietto M, Pasqualotto E, Vassanelli S (2011) SigMate: a comprehensive software package for extracellular neuronal signal processing and analysis. In: Proc. NER, pp 88–91. 10.1109/NER.2011.5910495</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bertoldo</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Girardi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Maschietto</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Vassanelli</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>SigMate: a Matlab-based automated tool for extracellular neuronal signal processing and analysis</article-title>
        <source>J Neurosci Methods</source>
        <year>2012</year>
        <volume>207</volume>
        <issue>1</issue>
        <fpage>97</fpage>
        <lpage>112</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2012.03.009</pub-id>
        <pub-id pub-id-type="pmid">22513383</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Mahmud M, Girardi S, Maschietto M, Vassanelli S (2012) An automated method to remove artifacts induced by microstimulation in local field potentials recorded from rat somatosensory cortex. In: Proc. BRC, pp 1–4. 10.1109/BRC.2012.6222169</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Mahmud M, Girardi S, Maschietto M, Pasqualotto E, Vassanelli S (2011) An automated method to determine angular preferentiality using LFPs recorded from rat barrel cortex by brain–chip interface under mechanical whisker stimulation. In: Proc. EMBC, pp 2307–2310. 10.1109/IEMBS.2011.6090580</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Mahmud M, Girardi S, Maschietto M, Rahman MM, Vassanelli S (2009) Noise characterization of electrophysiological signals recorded from high resolution brain–chip interface. In: Proc. ISBB, pp 84–87</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Mahmud M, Bertoldo A, Maschietto M, Girardi S, Vassanelli S (2010) Automatic detection of layer activation order in information processing pathways of rat barrel cortex under mechanical whisker stimulation. In: Proc. EMBC, pp 6095–6098. 10.1109/IEMBS.2010.5627639</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Mahmud M, Maschietto M, Girardi S, Vassanelli S (2012) A Matlab based tool for cortical layer activation order detection through latency calculation in local field potentials recorded from rat barrel cortex by brain–chip interface. In: Proc. BRC, pp 1–4. 10.1109/BRC.2012.6222170</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Pasqualotto</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Bertoldo</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Girardi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Maschietto</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Vassanelli</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>An automated method for detection of layer activation order in information processing pathway of rat barrel cortex under mechanical whisker stimulation</article-title>
        <source>J Neurosci Methods</source>
        <year>2011</year>
        <volume>196</volume>
        <issue>1</issue>
        <fpage>141</fpage>
        <lpage>150</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2010.11.024</pub-id>
        <pub-id pub-id-type="pmid">21145917</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>An automated method for characterization of evoked single-trial local field potentials recorded from rat barrel cortex under mechanical whisker stimulation</article-title>
        <source>Cogn Comput</source>
        <year>2016</year>
        <volume>8</volume>
        <issue>5</issue>
        <fpage>935</fpage>
        <lpage>945</lpage>
        <pub-id pub-id-type="doi">10.1007/s12559-016-9399-3</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Mahmud M, Travalin D, Bertoldo A, Girardi S, Maschietto M, Vassanelli S (2010) A contour based automatic method to classify local field potentials recorded from rat barrel cortex. In: Proc. CIBEC, pp 163–166. 10.1109/CIBEC.2010.5716087</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Mahmud M, Travalin D, Hussain A, Girardi S, Maschietto M, Felderer F, Vassanelli S (2012) Single LFP sorting for high-resolution brain-chip interfacing. In Proc. BICS, 7366 LNAI, pp 329–337. 10.1007/978-3-642-31561-9_37</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Mahmud M, Travalin D, Hussain A (2012) Decoding network activity from LFPS: a computational approach. In: Proc. ICONIP, 7663 LNCS, pp 584–591. 10.1007/978-3-642-34475-6_70</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Travalin</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Bertoldo</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Girardi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Maschietto</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Vassanelli</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>An automated classification method for single sweep local field potentials recorded from rat barrel cortex under mechanical whisker stimulation</article-title>
        <source>J Med Biol Eng</source>
        <year>2012</year>
        <pub-id pub-id-type="doi">10.5405/jmbe.923</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Fabietti M, Mahmud M, Lotfi A (2020) Machine learning in analysing invasively recorded neuronal signals: available open access data sources. In: Proc. brain informatics, pp 151–162</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Destexhe</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Goldberg</surname>
            <given-names>JA</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Jaeger</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Jung</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>LFP analysis: overview</article-title>
        <source>Encyclopedia of computational neuroscience</source>
        <year>2013</year>
        <publisher-loc>New York, NY</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>52</fpage>
        <lpage>55</lpage>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boroujeni</surname>
            <given-names>KB</given-names>
          </name>
          <name>
            <surname>Tiesinga</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Womelsdorf</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Adaptive spike-artifact removal from local field potentials uncovers prominent beta and gamma band neuronal synchronization</article-title>
        <source>J Neurosci Methods</source>
        <year>2020</year>
        <volume>330</volume>
        <fpage>108485</fpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2019.108485</pub-id>
        <pub-id pub-id-type="pmid">31705936</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mikulovic</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Pupe</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Peixoto</surname>
            <given-names>HM</given-names>
          </name>
          <name>
            <surname>Do Nascimento</surname>
            <given-names>GC</given-names>
          </name>
          <name>
            <surname>Kullander</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Tort</surname>
            <given-names>AB</given-names>
          </name>
          <name>
            <surname>Leão</surname>
            <given-names>RN</given-names>
          </name>
        </person-group>
        <article-title>On the photovoltaic effect in local field potential recordings</article-title>
        <source>Neurophotonics</source>
        <year>2016</year>
        <volume>3</volume>
        <issue>1</issue>
        <fpage>015002</fpage>
        <pub-id pub-id-type="doi">10.1117/1.NPh.3.1.015002</pub-id>
        <pub-id pub-id-type="pmid">26835485</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tort</surname>
            <given-names>AB</given-names>
          </name>
          <name>
            <surname>Ponsel</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Jessberger</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yanovsky</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Brankačk</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Draguhn</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Parallel detection of theta and respiration-coupled oscillations throughout the mouse brain</article-title>
        <source>Sci Rep</source>
        <year>2018</year>
        <volume>8</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="doi">10.1038/s41598-018-24629-z</pub-id>
        <pub-id pub-id-type="pmid">29311619</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Qian</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Hao</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>A method for removal of deep brain stimulation artifact from local field potentials</article-title>
        <source>IEEE Trans Neural Syst Rehabilitat Eng</source>
        <year>2016</year>
        <volume>25</volume>
        <issue>12</issue>
        <fpage>2217</fpage>
        <lpage>2226</lpage>
        <pub-id pub-id-type="doi">10.1109/TNSRE.2016.2613412</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brogger</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Eichele</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Aanestad</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Olberg</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Hjelland</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Aurlien</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Visual EEG reviewing times with score EEG</article-title>
        <source>Clin Neurophysiol Pract</source>
        <year>2018</year>
        <volume>3</volume>
        <fpage>59</fpage>
        <lpage>64</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cnp.2018.03.002</pub-id>
        <pub-id pub-id-type="pmid">30215010</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yahaya</surname>
            <given-names>SW</given-names>
          </name>
          <name>
            <surname>Lotfi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>A consensus novelty detection ensemble approach for anomaly detection in activities of daily living</article-title>
        <source>Appl Soft Comput</source>
        <year>2019</year>
        <volume>83</volume>
        <fpage>105613</fpage>
        <pub-id pub-id-type="doi">10.1016/j.asoc.2019.105613</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Fabietti M, Mahmud M, Lotfi A, Averna A, Guggenmo D, Nudo R, Chiappalone M (2020) Neural network-based artifact detection in local field potentials recorded from chronically implanted neural probes. In: Proc. IJCNN, pp 1–8</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Fabietti M, Mahmud M, Lotfi A, Averna A, Guggenmos D, Nudo R, Chiappalone M (2020) Adaptation of convolutional neural networks for multi-channel artifact detection in chronically recorded local field potentials. In: 2020 IEEE symposium series on computational intelligence (SSCI). IEEE, pp 1607–1613</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Fabietti M, Mahmud M, Lotfi A (2020) Effectiveness of employing multimodal signals in removing artifacts from neuronal signals: an empirical analysis. In: Proc. brain informatics. Springer, pp 183–193</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yahaya</surname>
            <given-names>SW</given-names>
          </name>
          <name>
            <surname>Lotfi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Towards a data-driven adaptive anomaly detection system for human activity</article-title>
        <source>Pattern Recogn Lett</source>
        <year>2021</year>
        <volume>145</volume>
        <fpage>200</fpage>
        <lpage>207</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patrec.2021.02.006</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">Farhin F, Sultana I, Islam N, Kaiser MS, Rahman MS, Mahmud M (2020) Attack detection in internet of things using software defined network and fuzzy neural network. In: 2020 joint 9th international conference on informatics, electronics &amp; vision (ICIEV) and 2020 4th international conference on imaging, vision &amp; pattern recognition (icIVPR). IEEE, pp 1–6</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <mixed-citation publication-type="other">Zaman S, Alhazmi K, Aseeri M, Ahmed MR, Khan RT, Kaiser MS, Mahmud M (2021) Security threats and artificial intelligence based countermeasures for internet of things networks: a comprehensive survey. IEEE Access</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Fabietti M, Mahmud M, Lotfi A, Averna A, Guggenmos D, Nudo R, Chiappalone M (2021) Signal power affects artefact detection accuracy in chronically recorded local field potentials: preliminary results. In: 2021 10th international IEEE/EMBS conference on neural engineering (NER). IEEE, pp 166–169</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <mixed-citation publication-type="other">Tahura S, Samiul SH, Kaiser MS, Mahmud M (2021) Anomaly detection in electroencephalography signal using deep learning model. In: Proceedings of international conference on trends in computational and cognitive engineering. Springer, pp 205–217</mixed-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kaiser</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Hussain</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Vassanelli</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Applications of deep learning and reinforcement learning to biological data</article-title>
        <source>IEEE Trans Neural Netw Learn Syst</source>
        <year>2018</year>
        <volume>29</volume>
        <issue>6</issue>
        <fpage>2063</fpage>
        <lpage>2079</lpage>
        <pub-id pub-id-type="doi">10.1109/TNNLS.2018.2790388</pub-id>
        <pub-id pub-id-type="pmid">29771663</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kaiser</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>McGinnity</surname>
            <given-names>MT</given-names>
          </name>
          <name>
            <surname>Hussain</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Deep learning in mining biological data</article-title>
        <source>Cogn Comput</source>
        <year>2021</year>
        <volume>13</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>33</lpage>
        <pub-id pub-id-type="doi">10.1007/s12559-020-09773-x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <mixed-citation publication-type="other">Noor MBT, Zenia NZ, Kaiser MS, Mahmud M, Al Mamun S (2019) Detecting neurodegenerative disease from MRI: a brief review on a deep learning perspective. In: Proc. brain informatics, pp 115–125</mixed-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <mixed-citation publication-type="other">Miah Y, Prima CNE, Seema SJ, Mahmud M, Kaiser MS (2021) Performance comparison of machine learning techniques in identifying dementia from open access clinical datasets. In: Proc. ICACIn, pp 79–89</mixed-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <mixed-citation publication-type="other">Zohora MF, Tania MH, Kaiser MS, Mahmud M (2020) Forecasting the risk of type II diabetes using reinforcement learning. In: Proc. ICIEV. IEEE, pp 1–6</mixed-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <mixed-citation publication-type="other">Sharpe R, Mahmud M (2020) Effect of the gamma entrainment frequency in pertinence to mood, memory and cognition. In: Proc. brain informatics, pp 50–61</mixed-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <mixed-citation publication-type="other">Satu MS, Rahman S, Khan MI, Abedin MZ, Kaiser MS, Mahmud M (2020) Towards improved detection of cognitive performance using bidirectional multilayer long-short term memory neural network. In: Proc. brain informatics, pp 297–306</mixed-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <mixed-citation publication-type="other">Rahman S, Sharma T, Mahmud M (2020) Improving alcoholism diagnosis: comparing instance-based classifiers against neural networks for classifying EEG signal. In: Proc. brain informatics, pp 239–250</mixed-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Noor</surname>
            <given-names>MBT</given-names>
          </name>
          <name>
            <surname>Zenia</surname>
            <given-names>NZ</given-names>
          </name>
          <name>
            <surname>Kaiser</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Al Mamun</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Application of deep learning in detecting neurological disorders from magnetic resonance images: a survey on the detection of Alzheimer’s disease, Parkinson’s disease and schizophrenia</article-title>
        <source>Brain Inform</source>
        <year>2020</year>
        <volume>7</volume>
        <fpage>1</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="doi">10.1186/s40708-020-00112-2</pub-id>
        <pub-id pub-id-type="pmid">32064541</pub-id>
      </element-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Aradhya</surname>
            <given-names>VNM</given-names>
          </name>
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Guru</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Agarwal</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Kaiser</surname>
            <given-names>MS</given-names>
          </name>
        </person-group>
        <article-title>One shot cluster based approach for the detection of COVID-19 from chest X-ray images</article-title>
        <source>Cogn Comput</source>
        <year>2021</year>
        <pub-id pub-id-type="doi">10.1007/s12559-020-09774-w</pub-id>
      </element-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dey</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Rajinikanth</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Fong</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Kaiser</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Social group optimization-assisted Kapur’s entropy and morphological segmentation for automated detection of covid-19 infection from computed tomography images</article-title>
        <source>Cogn Comput</source>
        <year>2020</year>
        <volume>12</volume>
        <issue>5</issue>
        <fpage>1011</fpage>
        <lpage>1023</lpage>
        <pub-id pub-id-type="doi">10.1007/s12559-020-09751-3</pub-id>
      </element-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <mixed-citation publication-type="other">Al Banna MH, Ghosh T, Taher KA, Kaiser MS, Mahmud M (2020) A monitoring system for patients of autism spectrum disorder using artificial intelligence. In: Proc. brain informatics, pp 251–262</mixed-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <mixed-citation publication-type="other">Sumi AI, Zohora MF, Mahjabeen M, Faria TJ, Mahmud M, Kaiser MS (2018) fASSERT: a fuzzy assistive system for children with autism using internet of things. In: Proc. brain informatics, pp 403–412</mixed-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <mixed-citation publication-type="other">Tonni SI, Aka TA, Antik MM, Taher KA, Mahmud M, Kaiser MS (2021) Artificial intelligence based driver vigilance system for accident prevention. In: 2021 international conference on information and communication technology for sustainable development (ICICT4SD). IEEE, pp 412–416</mixed-citation>
    </ref>
    <ref id="CR59">
      <label>59.</label>
      <mixed-citation publication-type="other">Al Nahian MJ, Ghosh T, Uddin MN, Islam MM, Mahmud M, Kaiser M (2020) Towards artificial intelligence driven emotion aware fall monitoring framework suitable for elderly people with neurological disorder. In: Proc. brain informatics, pp 275–286</mixed-citation>
    </ref>
    <ref id="CR60">
      <label>60.</label>
      <mixed-citation publication-type="other">Jesmin S, Kaiser MS, Mahmud M (2020) Artificial and internet of healthcare things based Alzheimer care during COVID 19. In: Proc. brain informatics, pp 263–274</mixed-citation>
    </ref>
    <ref id="CR61">
      <label>61.</label>
      <mixed-citation publication-type="other">Nahiduzzaman M, Tasnim M, Newaz NT, Kaiser MS, Mahmud M (2020) Machine learning based early fall detection for elderly people with neurological disorder using multimodal data fusion. In: Proc. brain informatics, pp 204–214</mixed-citation>
    </ref>
    <ref id="CR62">
      <label>62.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kaiser</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Noor</surname>
            <given-names>MBT</given-names>
          </name>
          <name>
            <surname>Zenia</surname>
            <given-names>NZ</given-names>
          </name>
          <name>
            <surname>Al Mamun</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Mahmud</surname>
            <given-names>KA</given-names>
          </name>
          <name>
            <surname>Azad</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Aradhya</surname>
            <given-names>VM</given-names>
          </name>
          <name>
            <surname>Stephan</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Stephan</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>iWorksafe: towards healthy workplaces during COVID-19 with an intelligent phealth app for industrial settings</article-title>
        <source>IEEE Access</source>
        <year>2021</year>
        <volume>9</volume>
        <fpage>13814</fpage>
        <lpage>13828</lpage>
        <pub-id pub-id-type="doi">10.1109/ACCESS.2021.3050193</pub-id>
      </element-citation>
    </ref>
    <ref id="CR63">
      <label>63.</label>
      <mixed-citation publication-type="other">Orojo O, Tepper J, McGinnity TM, Mahmud M (2019) A multi-recurrent network for crude oil price prediction. In: Proc. IEEE SSCI, pp 2953–2958</mixed-citation>
    </ref>
    <ref id="CR64">
      <label>64.</label>
      <mixed-citation publication-type="other">Ali HM, Kaiser MS, Mahmud M (2019) Application of convolutional neural network in segmenting brain regions from MRI data. In: International conference on brain informatics, pp. 136–146</mixed-citation>
    </ref>
    <ref id="CR65">
      <label>65.</label>
      <mixed-citation publication-type="other">Ruiz J, Mahmud M, Modasshir M, Shamim Kaiser M (2020) Alzheimer’s disease neuroimaging initiative, f.t.: 3D DenseNet ensemble in 4-way classification of Alzheimer’s disease. In: Proc. brain informatics, pp 85–96</mixed-citation>
    </ref>
    <ref id="CR66">
      <label>66.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rabby</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Azad</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zamli</surname>
            <given-names>KZ</given-names>
          </name>
          <name>
            <surname>Rahman</surname>
            <given-names>MM</given-names>
          </name>
        </person-group>
        <article-title>Teket: a tree-based unsupervised keyphrase extraction technique</article-title>
        <source>Cogn Comput</source>
        <year>2020</year>
        <volume>12</volume>
        <fpage>811</fpage>
        <lpage>833</lpage>
        <pub-id pub-id-type="doi">10.1007/s12559-019-09706-3</pub-id>
      </element-citation>
    </ref>
    <ref id="CR67">
      <label>67.</label>
      <mixed-citation publication-type="other">Watkins J, Fabietti M, Mahmud M (2020) Sense: a student performance quantifier using sentiment analysis. In: Proc. IJCNN, pp 1–6</mixed-citation>
    </ref>
    <ref id="CR68">
      <label>68.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sheng</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Mahmud</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>An event based topic learning pipeline for neuroimaging literature mining</article-title>
        <source>Brain Inform</source>
        <year>2020</year>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="doi">10.1186/s40708-020-00121-1</pub-id>
        <pub-id pub-id-type="pmid">32064541</pub-id>
      </element-citation>
    </ref>
    <ref id="CR69">
      <label>69.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bukhtiyarova</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Soltani</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Chauvette</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Timofeev</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Supervised semi-automatic detection of slow waves in non-anaesthetized mice with the use of neural network approach</article-title>
        <source>Transl Brain Rhythmicity</source>
        <year>2016</year>
        <volume>1</volume>
        <issue>1</issue>
        <fpage>14</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="doi">10.15761/TBR.1000104</pub-id>
      </element-citation>
    </ref>
    <ref id="CR70">
      <label>70.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Kanal</surname>
            <given-names>LN</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Smelser</surname>
            <given-names>NJ</given-names>
          </name>
          <name>
            <surname>Baltes</surname>
            <given-names>PB</given-names>
          </name>
        </person-group>
        <article-title>Perceptrons</article-title>
        <source>International encyclopedia of the social &amp; behavioral sciences</source>
        <year>2001</year>
        <publisher-loc>Oxford</publisher-loc>
        <publisher-name>Pergamon</publisher-name>
        <fpage>11218</fpage>
        <lpage>11221</lpage>
      </element-citation>
    </ref>
    <ref id="CR71">
      <label>71.</label>
      <mixed-citation publication-type="other">Fabietti M, Mahmud M, Lotfi A, Averna A, Guggenmo D, Nudo R, Chiappalone M (2020) Artifact detection in chronically recorded local field potentials using long-short term memory neural network. In: Proc. AICT, pp 1–6</mixed-citation>
    </ref>
    <ref id="CR72">
      <label>72.</label>
      <mixed-citation publication-type="other">Fabietti M, Mahmud M, Lotfi A, Averna A, Guggenmo D, Nudo R, Chiappalone M (2020) Adaptation of convolutional neural networks for multi-channel artifact detection in chronically recorded local field potentials. In: Proc. SSCI, pp 1–7</mixed-citation>
    </ref>
    <ref id="CR73">
      <label>73.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Arulmozhi</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Classification task by using matlab neural network tool box—a beginner’s view</article-title>
        <source>Int J Wisdom Based Comput</source>
        <year>2011</year>
        <volume>1</volume>
        <issue>2</issue>
        <fpage>59</fpage>
        <lpage>60</lpage>
      </element-citation>
    </ref>
    <ref id="CR74">
      <label>74.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Furth</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Replication Data for: neuronal correlates of ketamine and walking induced gamma oscillations in the medial prefrontal cortex and mediodorsal thalamus</article-title>
        <source>Harvard Dataverse</source>
        <year>2017</year>
        <pub-id pub-id-type="doi">10.7910/DVN/MIBZLZ</pub-id>
      </element-citation>
    </ref>
    <ref id="CR75">
      <label>75.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Furth</surname>
            <given-names>KE</given-names>
          </name>
          <name>
            <surname>McCoy</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Dodge</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Walters</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Buonanno</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Delaville</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Neuronal correlates of ketamine and walking induced gamma oscillations in the medial prefrontal cortex and mediodorsal thalamus</article-title>
        <source>PLoS ONE</source>
        <year>2017</year>
        <volume>12</volume>
        <issue>11</issue>
        <fpage>0186732</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0186732</pub-id>
      </element-citation>
    </ref>
    <ref id="CR76">
      <label>76.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Averna</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Differential effects of open- and closed-loop intracortical microstimulation on firing patterns of neurons in distant cortical areas</article-title>
        <source>Cereb Cortex</source>
        <year>2020</year>
        <volume>30</volume>
        <issue>5</issue>
        <fpage>2879</fpage>
        <lpage>2896</lpage>
        <pub-id pub-id-type="doi">10.1093/cercor/bhz281</pub-id>
        <pub-id pub-id-type="pmid">31832642</pub-id>
      </element-citation>
    </ref>
    <ref id="CR77">
      <label>77.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Teeters</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sommer</surname>
            <given-names>FT</given-names>
          </name>
        </person-group>
        <article-title>epHDF-a standard for storing electrophysiology data in HDF5</article-title>
        <source>F1000Research</source>
        <year>2013</year>
        <pub-id pub-id-type="doi">10.3389/conf.fninf.2013.09.00068</pub-id>
      </element-citation>
    </ref>
    <ref id="CR78">
      <label>78.</label>
      <mixed-citation publication-type="other">Fabietti M, Mahmud M, Lotfi A (2020) Effectiveness of employing multimodal signals in removing artifacts from neuronal signals: an empirical analysis. In: Proc. brain informatics, pp 183–193</mixed-citation>
    </ref>
    <ref id="CR79">
      <label>79.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ghosh</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Sinha</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Biswas</surname>
            <given-names>SK</given-names>
          </name>
        </person-group>
        <article-title>Automated eye blink artefact removal from EEG using support vector machine and autoencoder</article-title>
        <source>IET Signal Process</source>
        <year>2018</year>
        <volume>13</volume>
        <issue>2</issue>
        <fpage>141</fpage>
        <lpage>148</lpage>
        <pub-id pub-id-type="doi">10.1049/iet-spr.2018.5111</pub-id>
      </element-citation>
    </ref>
    <ref id="CR80">
      <label>80.</label>
      <mixed-citation publication-type="other">Leite NMN, Pereira ET, Gurjao EC, Veloso LR (2018) Deep convolutional autoencoder for EEG noise filtering. In: Proc. BIBM, pp 2605–2612</mixed-citation>
    </ref>
  </ref-list>
</back>
