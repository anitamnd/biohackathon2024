<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with OASIS Tables with MathML3 v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-archive-oasis-article1-mathml3.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jpoasis-nisons2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Biophotonics</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Biophotonics</journal-id>
    <journal-id journal-id-type="doi">10.1002/(ISSN)1864-0648</journal-id>
    <journal-id journal-id-type="publisher-id">JBIO</journal-id>
    <journal-title-group>
      <journal-title>Journal of Biophotonics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1864-063X</issn>
    <issn pub-type="epub">1864-0648</issn>
    <publisher>
      <publisher-name>WILEY‐VCH Verlag GmbH &amp; Co. KGaA</publisher-name>
      <publisher-loc>Weinheim</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7065628</article-id>
    <article-id pub-id-type="doi">10.1002/jbio.201960050</article-id>
    <article-id pub-id-type="publisher-id">JBIO201960050</article-id>
    <article-categories>
      <subj-group subj-group-type="overline">
        <subject>Full Article</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Full Articles</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Classifying T cell activity in autofluorescence intensity images with convolutional neural networks</article-title>
      <alt-title alt-title-type="left-running-head">Wang et al.</alt-title>
    </title-group>
    <contrib-group>
      <contrib id="jbio201960050-cr-0001" contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Zijie J.</given-names>
        </name>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-4360-1423</contrib-id>
        <xref ref-type="aff" rid="jbio201960050-aff-0001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="jbio201960050-aff-0002">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib id="jbio201960050-cr-0002" contrib-type="author">
        <name>
          <surname>Walsh</surname>
          <given-names>Alex J.</given-names>
        </name>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-3832-8207</contrib-id>
        <xref ref-type="aff" rid="jbio201960050-aff-0002">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib id="jbio201960050-cr-0003" contrib-type="author">
        <name>
          <surname>Skala</surname>
          <given-names>Melissa C.</given-names>
        </name>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-6320-7637</contrib-id>
        <xref ref-type="aff" rid="jbio201960050-aff-0002">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="jbio201960050-aff-0003">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib id="jbio201960050-cr-0004" contrib-type="author" corresp="yes">
        <name>
          <surname>Gitter</surname>
          <given-names>Anthony</given-names>
        </name>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-5324-9833</contrib-id>
        <xref ref-type="aff" rid="jbio201960050-aff-0001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="jbio201960050-aff-0002">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="jbio201960050-aff-0004">
          <sup>4</sup>
        </xref>
        <address>
          <email>gitter@biostat.wisc.edu</email>
        </address>
      </contrib>
    </contrib-group>
    <aff id="jbio201960050-aff-0001">
      <label>
        <sup>1</sup>
      </label>
      <named-content content-type="organisation-division">Department of Computer Sciences</named-content>
      <institution>University of Wisconsin‐Madison</institution>
      <city>Madison</city>
      <named-content content-type="country-part">Wisconsin</named-content>
    </aff>
    <aff id="jbio201960050-aff-0002">
      <label>
        <sup>2</sup>
      </label>
      <institution>Morgridge Institute for Research</institution>
      <city>Madison</city>
      <named-content content-type="country-part">Wisconsin</named-content>
    </aff>
    <aff id="jbio201960050-aff-0003">
      <label>
        <sup>3</sup>
      </label>
      <named-content content-type="organisation-division">Department of Biomedical Engineering</named-content>
      <institution>University of Wisconsin‐Madison</institution>
      <city>Madison</city>
      <named-content content-type="country-part">Wisconsin</named-content>
    </aff>
    <aff id="jbio201960050-aff-0004">
      <label>
        <sup>4</sup>
      </label>
      <named-content content-type="organisation-division">Department of Biostatistics and Medical Informatics</named-content>
      <institution>University of Wisconsin‐Madison</institution>
      <city>Madison</city>
      <named-content content-type="country-part">Wisconsin</named-content>
    </aff>
    <author-notes>
      <corresp id="correspondenceTo"><label>*</label><bold>Correspondence</bold><break/>
Anthony Gitter, Department of Biostatistics and Medical Informatics, University of Wisconsin‐Madison, Madison, WI.<break/>
Email: <email>gitter@biostat.wisc.edu</email><break/></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>15</day>
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <month>3</month>
      <year>2020</year>
    </pub-date>
    <volume>13</volume>
    <issue>3</issue>
    <issue-id pub-id-type="doi">10.1002/jbio.v13.3</issue-id>
    <elocation-id>e201960050</elocation-id>
    <history>
      <date date-type="received">
        <day>19</day>
        <month>7</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>28</day>
        <month>9</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>16</day>
        <month>10</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <!--<copyright-statement content-type="issue-copyright"> &#x000a9; 2020 WILEY&#x02010;VCH Verlag GmbH & Co. KGaA, Weinheim <copyright-statement>-->
      <copyright-statement content-type="article-copyright">© 2019 The Authors. <italic>Journal of Biophotonics</italic> published by WILEY‐VCH Verlag GmbH &amp; Co. KGaA, Weinheim</copyright-statement>
      <license license-type="creativeCommonsBy">
        <license-p>This is an open access article under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link> License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="file:JBIO-13-e201960050.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>The importance of T cells in immunotherapy has motivated developing technologies to improve therapeutic efficacy. One objective is assessing antigen‐induced T cell activation because only functionally active T cells are capable of killing the desired targets. Autofluorescence imaging can distinguish T cell activity states in a non‐destructive manner by detecting endogenous changes in metabolic co‐enzymes such as NAD(P)H. However, recognizing robust activity patterns is computationally challenging in the absence of exogenous labels. We demonstrate machine learning methods that can accurately classify T cell activity across human donors from NAD(P)H intensity images. Using 8260 cropped single‐cell images from six donors, we evaluate classifiers ranging from traditional models that use previously‐extracted image features to convolutional neural networks (CNNs) pre‐trained on general non‐biological images. Adapting pre‐trained CNNs for the T cell activity classification task provides substantially better performance than traditional models or a simple CNN trained with the autofluorescence images alone. Visualizing the images with dimension reduction provides intuition into why the CNNs achieve higher accuracy than other approaches. Our image processing and classifier training software is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/gitter-lab/t-cell-classification">https://github.com/gitter-lab/t-cell-classification</ext-link>.<inline-graphic xlink:href="JBIO-13-e201960050-g010.jpg" xlink:title="image"/>
</p>
    </abstract>
    <abstract abstract-type="graphical">
      <p>Improving T cell‐based immunotherapy efficiency requires non‐destructive techniques to screen T cells for functional activity. Autofluorescence imaging of metabolic co‐enzymes characterizes T cell activity without destructive exogenous labelling, but detecting robust activity signatures remains a challenge. Convolutional neural networks pre‐trained on general non‐biological images can accurately predict T cell activity from autofluorescence intensity images and substantially outperform alternative approaches that train on extracted image features or only T cell images.<boxed-text position="anchor" content-type="graphic" id="jbio201960050-blkfxd-0001" orientation="portrait"><graphic xlink:href="JBIO-13-e201960050-g011.jpg" position="anchor" id="nlm-graphic-1" orientation="portrait"/></boxed-text>
</p>
    </abstract>
    <kwd-group kwd-group-type="author-generated">
      <kwd id="jbio201960050-kwd-0001">deep learning</kwd>
      <kwd id="jbio201960050-kwd-0002">label‐free</kwd>
      <kwd id="jbio201960050-kwd-0003">NAD(P)H intensity</kwd>
      <kwd id="jbio201960050-kwd-0004">transfer learning</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="funding-0001">
        <funding-source>Morgridge Institute for Research</funding-source>
      </award-group>
      <award-group id="funding-0002">
        <funding-source>
          <institution-wrap>
            <institution>National Cancer Institute </institution>
            <institution-id institution-id-type="open-funder-registry">10.13039/100000054</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>P30 CA014520</award-id>
        <award-id>R01 CA205101</award-id>
      </award-group>
      <award-group id="funding-0003">
        <funding-source>
          <institution-wrap>
            <institution>University of Wisconsin‐Madison </institution>
            <institution-id institution-id-type="open-funder-registry">10.13039/100007015</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="9"/>
      <table-count count="3"/>
      <page-count count="18"/>
      <word-count count="11126"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>source-schema-version-number</meta-name>
        <meta-value>2.0</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>cover-date</meta-name>
        <meta-value>March 2020</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>details-of-publishers-convertor</meta-name>
        <meta-value>Converter:WILEY_ML3GV2_TO_JATSPMC version:5.7.7 mode:remove_FC converted:11.03.2020</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <p content-type="self-citation">
      <mixed-citation publication-type="journal" id="jbio201960050-cit-9001"><string-name><surname>Wang</surname><given-names>ZJ</given-names></string-name>, <string-name><surname>Walsh</surname><given-names>AJ</given-names></string-name>, <string-name><surname>Skala</surname><given-names>MC</given-names></string-name>, <string-name><surname>Gitter</surname><given-names>A</given-names></string-name>. <article-title>Classifying T cell activity in autofluorescence intensity images with convolutional neural networks</article-title>. <source xml:lang="en">J. Biophotonics</source>. <year>2020</year>;<volume>13</volume>:<elocation-id>e201960050</elocation-id><pub-id pub-id-type="doi">10.1002/jbio.201960050</pub-id><pub-id pub-id-type="pmid">31661592</pub-id></mixed-citation>
    </p>
    <fn-group id="jbio201960050-ntgp-0001">
      <fn id="jbio201960050-note-0001">
        <p><bold>Present address</bold> Zijie J. Wang, School of Computational Science and Engineering, Georgia Institute of Technology, Atlanta, Georgia. Alex J. Walsh, Department of Biomedical Engineering, Texas A&amp;M University, College Station, Texas.</p>
      </fn>
      <fn id="jbio201960050-note-1002">
        <p><bold>Funding information</bold> Morgridge Institute for Research; National Cancer Institute, Grant/Award Numbers: P30 CA014520, R01 CA205101; University of Wisconsin‐Madison</p>
      </fn>
    </fn-group>
  </notes>
</front>
<body id="jbio201960050-body-0001">
  <sec id="jbio201960050-sec-0001">
    <label>1</label>
    <title>INTRODUCTION</title>
    <p>Immunotherapy is a type of cancer treatment that uses the body's own immune cells to boost natural defenses against cancer. T cells are a promising target for immunotherapies because of their antigen specificity and diverse cytotoxic and immune‐modulating activities. Prior to activation by an antigen, T cells are in a resting or quiescent state. Upon activation, T cells increase in size, proliferate, and produce cytokines <xref rid="jbio201960050-bib-0001" ref-type="ref">1</xref>. T cells are highly heterogeneous due to various states of activation and production of cytokines with cytotoxic or immune‐modulating effects. Immunotherapies that enhance T cell cytotoxicity are currently used in clinical cancer treatments <xref rid="jbio201960050-bib-0002" ref-type="ref">2</xref>. Other immunotherapies that enhance T cell regulatory activities are in development for diseases including HIV and diabetes <xref rid="jbio201960050-bib-0003" ref-type="ref">3</xref>, <xref rid="jbio201960050-bib-0004" ref-type="ref">4</xref>.</p>
    <p>Adoptive cell therapies are the class of immunotherapies in which immune cells from a patient or donor are removed from the body, expanded in vitro, and then injected into the patient. Chimeric antigen receptor (CAR) T cell therapies are adoptive cell therapies in which a patient's T cells are genetically engineered to express a CAR that is specifically targeted to a particular cancer‐expressing protein. Several CAR T cell therapies are currently used clinically for cancer treatment. However, extensive functional heterogeneity at the single‐cell level has been observed in vivo for CAR T cell immunotherapy for B cell lymphoma in mice, with only approximately 20% of CAR T cell‐B cell interactions leading to target killing <xref rid="jbio201960050-bib-0005" ref-type="ref">5</xref>. The difference in killing efficiency is likely due to heterogeneity in cytotoxic potential among the CAR T cells <xref rid="jbio201960050-bib-0005" ref-type="ref">5</xref>. Owing to this T cell heterogeneity, T cell activation and function must be assessed in a non‐destructive and label‐free manner at the single‐cell level to allow assessment and purification of the therapeutic cells subsequently injected into the patient. However, most current T cell profiling methods, such as immunofluorescence of surface protein expression and cytokine production, rely on exogenous contrast agents. Labelling intracellular cytokine production requires cell fixation, limiting application of these methods to in vitro assessment of subsets of T cells. A label‐free and non‐destructive pipeline to determine T cell activation is necessary for in vitro characterization and sorting of expanded T cells to ensure optimally functional T cells are used in cellular immunotherapies and for in vivo pre‐clinical assessment of immunotherapies <xref rid="jbio201960050-bib-0006" ref-type="ref">6</xref>.</p>
    <p>Autofluorescence imaging is appealing because it only relies on endogenous contrast and is non‐destructive. Endogenous fluorophores include NAD(P)H, FAD and collagen. Reduced nicotinamide adenine dinucleotide (NADH) and flavin adenine dinucleotide (FAD) are co‐enzymes of metabolism. NAD(P)H is an electron donor and is produced in glycolysis and consumed in oxidative phosphorylation. FAD is an electron acceptor and is produced in oxidative phosphorylation. The fluorescence lifetime is the time that the fluorophore is in the excited state, typically picoseconds to nanoseconds in duration, and is sensitive to the microenvironment of the fluorophore. Activated, functional immune cells require specific metabolic programs to support high levels of proliferation and cytokine production. Therefore, autofluorescence imaging of NAD(P)H and FAD provides endogenous endpoints of cellular metabolism reflective of immune cell function. Previous studies have used autofluorescence lifetime imaging to identify macrophages within the tumor microenvironment in vivo <xref rid="jbio201960050-bib-0007" ref-type="ref">7</xref> and classified the activation state of T cells in vitro <xref rid="jbio201960050-bib-0006" ref-type="ref">6</xref>. The fluorescence lifetime of NAD(P)H and FAD is highly sensitive to the microenvironment and binding of NAD(P)H and FAD. Thus, this fluorescence lifetime can be used to resolve metabolic differences between functional states of immune cells. However, fluorescence lifetime imaging requires specialized and expensive microscope components, limiting its use. Although autofluorescence intensity images lack the depth of information provided by the fluorescence lifetime, intensity images can easily and quickly be acquired on almost any commercial fluorescence microscope, allowing widespread adoption and seamless integration of a new technique into existing protocols of live cell assessment. Here, we develop a computational framework that uses autofluorescence intensity images to assess T cell activation state at the single‐cell level.</p>
    <p>Machine learning is promising for classifying cell subtypes from label‐free images. For example, Pavillon et al. <xref rid="jbio201960050-bib-0008" ref-type="ref">8</xref> used regularized logistic regression to predict macrophage activation state, and Yoon et al. <xref rid="jbio201960050-bib-0009" ref-type="ref">9</xref> identified lymphocyte cell types with <italic>k</italic>‐nearest neighbors. Advanced machine learning models, in particular convolutional neural networks (CNNs), are now the prevailing approach for a variety of cellular image analyses <xref rid="jbio201960050-bib-0010" ref-type="ref">10</xref>, <xref rid="jbio201960050-bib-0011" ref-type="ref">11</xref>, <xref rid="jbio201960050-bib-0012" ref-type="ref">12</xref>. CNNs can classify cell phenotypes <xref rid="jbio201960050-bib-0013" ref-type="ref">13</xref>, <xref rid="jbio201960050-bib-0014" ref-type="ref">14</xref>, segment cells <xref rid="jbio201960050-bib-0015" ref-type="ref">15</xref>, <xref rid="jbio201960050-bib-0016" ref-type="ref">16</xref>, restore images <xref rid="jbio201960050-bib-0017" ref-type="ref">17</xref>, and predict protein localization <xref rid="jbio201960050-bib-0018" ref-type="ref">18</xref>, <xref rid="jbio201960050-bib-0019" ref-type="ref">19</xref>, cell lineage choice <xref rid="jbio201960050-bib-0020" ref-type="ref">20</xref>, the biological activity of small molecules <xref rid="jbio201960050-bib-0021" ref-type="ref">21</xref> or ratios of activated T cells in a population <xref rid="jbio201960050-bib-0022" ref-type="ref">22</xref>. They are also effective at cell type classification tasks such as predicting cell cycle state <xref rid="jbio201960050-bib-0023" ref-type="ref">23</xref> and cell sorting <xref rid="jbio201960050-bib-0024" ref-type="ref">24</xref>.</p>
    <p>In this study, we use transfer learning with a pre‐trained CNN to classify T cell activation state at the single‐cell level. Transfer learning re‐uses a model for one task to improve performance on another task. Instead of extracting a small set of features from images before training a cell type classifier <xref rid="jbio201960050-bib-0025" ref-type="ref">25</xref>, we treat the autofluorescence intensity images as the input and take advantage of an existing CNN that has been trained on generic images. The pre‐trained CNN extracts high dimensional image features. We train a simple classifier on these features or fine‐tune partial layers to adapt the CNN for T cell activity classification. Repurposing a CNN pre‐trained on generic images has been successful in medical imaging applications <xref rid="jbio201960050-bib-0026" ref-type="ref">26</xref>, <xref rid="jbio201960050-bib-0027" ref-type="ref">27</xref>, <xref rid="jbio201960050-bib-0028" ref-type="ref">28</xref> and cellular image analyses <xref rid="jbio201960050-bib-0029" ref-type="ref">29</xref> such as classifying white blood cell types <xref rid="jbio201960050-bib-0030" ref-type="ref">30</xref>, recognizing cell staining patterns <xref rid="jbio201960050-bib-0031" ref-type="ref">31</xref>, and predicting mechanism of action in compound treatments <xref rid="jbio201960050-bib-0032" ref-type="ref">32</xref>, <xref rid="jbio201960050-bib-0033" ref-type="ref">33</xref>, <xref rid="jbio201960050-bib-0034" ref-type="ref">34</xref>. Compared to end‐to‐end CNN training, the transfer learning approach is more computationally efficient and requires fewer training samples. Because T cells differ from donor to donor in real immunotherapy applications, we use a rigorous donor‐specific cross‐validation scheme to train and evaluate our models. For the same reason, we hold out all images from one donor and only use them to assess the final performance of our best model.</p>
    <p>The pre‐trained CNN can accurately classify T cell activity across donors with autofluorescence intensity images as the only input. We compare the pre‐trained CNN to a spectrum of simpler models to better understand when and why deep learning is needed. Adapting pre‐trained CNNs is an important strategy in this domain and the most accurate approach overall, improving upon classifiers that operate on previously‐extracted cell image features. In particular, fine‐tuning some higher‐level layers outperforms directly using pre‐trained CNN‐extracted features. However, it is generally not worth the additional computational expense to fine‐tune all layers of the CNN. Interpretation techniques demonstrate that the pre‐trained CNN learns better representations for the two types of T cell images than other featurizations. Our success in classifying T cell activity without exogenous contrast agents or fluorescence lifetime suggests that modern machine learning approaches may help compensate for imaging data with less molecular specificity.</p>
  </sec>
  <sec id="jbio201960050-sec-0002">
    <label>2</label>
    <title>RESULTS</title>
    <sec id="jbio201960050-sec-0003">
      <label>2.1</label>
      <title>Overview</title>
      <p>Our goal is to classify individual T cells as activated (positive instances) or quiescent (negative instances) using only cropped autofluorescence intensity cell images. We explore multiple classification approaches of increasing complexity. A frequency classifier uses the frequency of positive samples in the training set as the probability of the activated label. This naive baseline model assesses how well the class skew in the training images can predict the label of new images. In addition, we test three Lasso logistic regression approaches on different featurizations of the cropped T cell images. The first uses the image pixel intensities directly as features. The second uses only two image summaries as features, the cell size and total intensity. The third uses attributes calculated with CellProfiler <xref rid="jbio201960050-bib-0035" ref-type="ref">35</xref>, such as the mean intensity value and cell perimeter.</p>
      <p>We also assess multiple types of neural networks. A fully connected neural network (multilayer perceptron) generalizes the logistic regression model with pixel intensities by adding a single hidden layer. The LeNet CNN architecture <xref rid="jbio201960050-bib-0036" ref-type="ref">36</xref> learns convolutional filters that take advantage of the image structure of the input data. This CNN is simple enough to train from random initialization with a limited number of images. Finally, we consider two deeper and more complex CNNs. Both use transfer learning to initialize the Inception v3 CNN architecture with a model that has been pre‐trained on generic (non‐biological) images. One version trains a new fully connected layer from scratch using off‐the‐shelf features extracted from cell images with the pre‐trained CNN. An alternative fine‐tunes multiple layers of the pre‐trained CNN.</p>
      <p>We select these classifiers from the same broad category. Except for the trivial frequency classifier, all models can be represented as a form of neural network with different input features and architectures. Also, we select features that are easy to extract from cell images, such as the raw pixel matrix and total intensity, as well as CellProfiler attributes, which are commonly used in cellular image classification studies <xref rid="jbio201960050-bib-0008" ref-type="ref">8</xref>, <xref rid="jbio201960050-bib-0037" ref-type="ref">37</xref>.</p>
      <p>The overall workflow for our pre‐trained CNN with fine‐tuning is described in Figure <xref rid="jbio201960050-fig-0001" ref-type="fig">1</xref>. The original microscopy images are segmented, cropped and padded. We filter images that do not contain a T cell and other artifacts, leaving the final image counts for each of the six donors shown in Table <xref rid="jbio201960050-tbl-0001" ref-type="table">1</xref>. Then we train, evaluate and interpret the machine learning models. Figure <xref rid="jbio201960050-fig-0001" ref-type="fig">1</xref> shows the training procedure for the pre‐trained CNN with fine‐tuning as an example.</p>
      <fig fig-type="Figure" xml:lang="en" id="jbio201960050-fig-0001" orientation="portrait" position="float">
        <label>Figure 1</label>
        <caption>
          <p>Our T cell image data processing workflow</p>
        </caption>
        <graphic id="nlm-graphic-3" xlink:href="JBIO-13-e201960050-g001"/>
      </fig>
      <table-wrap id="jbio201960050-tbl-0001" xml:lang="en" orientation="portrait" position="float">
        <label>Table 1</label>
        <caption>
          <p>Image count per donor in different filtering stages</p>
        </caption>
        <table frame="hsides" rules="groups">
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="char" char="." span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="char" char="." span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="char" char="." span="1"/>
          <thead valign="bottom">
            <tr style="border-bottom:solid 1px #000000">
              <th style="border-bottom:solid 1px #000000" align="left" valign="bottom" rowspan="1" colspan="1"/>
              <th colspan="3" style="border-bottom:solid 1px #000000" align="left" valign="bottom" rowspan="1">Original</th>
              <th colspan="3" style="border-bottom:solid 1px #000000" align="left" valign="bottom" rowspan="1">After lifetime filtering</th>
              <th colspan="3" style="border-bottom:solid 1px #000000" align="left" valign="bottom" rowspan="1">After entropy and intensity filtering</th>
            </tr>
            <tr style="border-bottom:solid 1px #000000">
              <th style="border-bottom:solid 1px #000000" align="left" valign="bottom" rowspan="1" colspan="1"/>
              <th colspan="2" style="border-bottom:solid 1px #000000" align="left" valign="bottom" rowspan="1">Cell count</th>
              <th align="left" style="border-bottom:solid 1px #000000" valign="bottom" rowspan="1" colspan="1"/>
              <th colspan="2" style="border-bottom:solid 1px #000000" align="left" valign="bottom" rowspan="1">Cell count</th>
              <th align="left" style="border-bottom:solid 1px #000000" valign="bottom" rowspan="1" colspan="1"/>
              <th colspan="2" style="border-bottom:solid 1px #000000" align="left" valign="bottom" rowspan="1">Cell count</th>
              <th align="left" style="border-bottom:solid 1px #000000" valign="bottom" rowspan="1" colspan="1"/>
            </tr>
            <tr style="border-bottom:solid 1px #000000">
              <th align="left" valign="bottom" rowspan="1" colspan="1"/>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Activated</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Quiescent</th>
              <th align="left" style="border-bottom:solid 1px #000000" valign="bottom" rowspan="1" colspan="1">Class skew</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Activated</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Quiescent</th>
              <th align="left" style="border-bottom:solid 1px #000000" valign="bottom" rowspan="1" colspan="1">Class skew</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Activated</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Quiescent</th>
              <th align="left" style="border-bottom:solid 1px #000000" valign="bottom" rowspan="1" colspan="1">Class skew</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">Donor 1</td>
              <td align="left" valign="top" rowspan="1" colspan="1">609</td>
              <td align="left" valign="top" rowspan="1" colspan="1">2184</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.22</td>
              <td align="left" valign="top" rowspan="1" colspan="1">271</td>
              <td align="left" valign="top" rowspan="1" colspan="1">1631</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.14</td>
              <td align="left" valign="top" rowspan="1" colspan="1">235</td>
              <td align="left" valign="top" rowspan="1" colspan="1">1551</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.13</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">Donor 2</td>
              <td align="left" valign="top" rowspan="1" colspan="1">1139</td>
              <td align="left" valign="top" rowspan="1" colspan="1">399</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.74</td>
              <td align="left" valign="top" rowspan="1" colspan="1">656</td>
              <td align="left" valign="top" rowspan="1" colspan="1">152</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.81</td>
              <td align="left" valign="top" rowspan="1" colspan="1">647</td>
              <td align="left" valign="top" rowspan="1" colspan="1">141</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.82</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">Donor 3</td>
              <td align="left" valign="top" rowspan="1" colspan="1">604</td>
              <td align="left" valign="top" rowspan="1" colspan="1">2351</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.20</td>
              <td align="left" valign="top" rowspan="1" colspan="1">487</td>
              <td align="left" valign="top" rowspan="1" colspan="1">1276</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.28</td>
              <td align="left" valign="top" rowspan="1" colspan="1">446</td>
              <td align="left" valign="top" rowspan="1" colspan="1">1238</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.26</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">Donor 4</td>
              <td align="left" valign="top" rowspan="1" colspan="1">789</td>
              <td align="left" valign="top" rowspan="1" colspan="1">2110</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.27</td>
              <td align="left" valign="top" rowspan="1" colspan="1">494</td>
              <td align="left" valign="top" rowspan="1" colspan="1">1629</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.23</td>
              <td align="left" valign="top" rowspan="1" colspan="1">482</td>
              <td align="left" valign="top" rowspan="1" colspan="1">1569</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.24</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">Donor 5</td>
              <td align="left" valign="top" rowspan="1" colspan="1">791</td>
              <td align="left" valign="top" rowspan="1" colspan="1">528</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.60</td>
              <td align="left" valign="top" rowspan="1" colspan="1">694</td>
              <td align="left" valign="top" rowspan="1" colspan="1">252</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.73</td>
              <td align="left" valign="top" rowspan="1" colspan="1">683</td>
              <td align="left" valign="top" rowspan="1" colspan="1">246</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.74</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">Donor 6</td>
              <td align="left" valign="top" rowspan="1" colspan="1">531</td>
              <td align="left" valign="top" rowspan="1" colspan="1">1007</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.35</td>
              <td align="left" valign="top" rowspan="1" colspan="1">446</td>
              <td align="left" valign="top" rowspan="1" colspan="1">589</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.43</td>
              <td align="left" valign="top" rowspan="1" colspan="1">442</td>
              <td align="left" valign="top" rowspan="1" colspan="1">580</td>
              <td align="char" valign="top" rowspan="1" colspan="1">0.43</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot id="jbio201960050-ntgp-0002">
          <fn id="jbio201960050-note-0003">
            <p><italic>Note</italic>: The mean fluorescence lifetime filter is used to discard cells that are visually indistinguishable from T cells, such as red blood cells. Then, the entropy and total intensity thresholds are used to remove dim images or images containing no cells. The donor class skew is measured as the percentage of activated cells.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>The T cell microscopy images may vary from donor to donor. A trained model must be able to generalize to new donors in order to be useful in a practical pre‐clinical or clinical setting. Therefore, all of our evaluation strategies train on images from some donors and evaluate the trained models on separate images from a different donor, which is referred to as subject‐wise cross‐validation <xref rid="jbio201960050-bib-0038" ref-type="ref">38</xref> or a leave‐one‐patient‐out scheme <xref rid="jbio201960050-bib-0031" ref-type="ref">31</xref>. We initially assess the classifiers with cross‐validation across donors. In addition, we hold out all images from a randomly selected donor, donor 4, and only use them after completing the rest of our study to confirm that our model selection and hyper‐parameter tuning strategies generalize to a new donor.</p>
    </sec>
    <sec id="jbio201960050-sec-0004">
      <label>2.2</label>
      <title>Cross‐validation across donors</title>
      <p>In order to assess our classifiers' performance on cell images from new donors, we design a nested cross‐validation scheme to train, tune and test all models. Due to this cross‐validation design, the same model could have different optimal hyper‐parameters for different test donors. Therefore, we group the final model performance by test donors (Figure <xref rid="jbio201960050-fig-0002" ref-type="fig">2</xref>). We plot multiple evaluation metrics because each metric rewards different behaviors <xref rid="jbio201960050-bib-0039" ref-type="ref">39</xref>. The area under the curve (AUC) and average precision are summary statistics of the receiver operating characteristic (ROC) curve (Figure <xref rid="jbio201960050-fig-0003" ref-type="fig">3</xref>) and precision recall (PR) curve (Figure <xref rid="jbio201960050-fig-0004" ref-type="fig">4</xref>), respectively. The test donors have different training sets and class skews (Table <xref rid="jbio201960050-tbl-0001" ref-type="table">1</xref>), and some classifiers are more robust to imbalanced data than others. Therefore, each donor has a specific pattern in the two curves, especially in the PR curves (Figure <xref rid="jbio201960050-fig-0004" ref-type="fig">4</xref>). However, for each curve, the relative ordering of the classifiers is generally consistent across donors. For all three evaluation metrics, the two pre‐trained CNN models outperform other classifiers.</p>
      <fig fig-type="Figure" xml:lang="en" id="jbio201960050-fig-0002" orientation="portrait" position="float">
        <label>Figure 2</label>
        <caption>
          <p>Model summary per donor for three different evaluation metrics. The line graphs display the classifiers' performance across donors. The bar graphs display the number of activated and quiescent images for each donor, which affects the baseline accuracy and average precision of a random classifier</p>
        </caption>
        <graphic id="nlm-graphic-5" xlink:href="JBIO-13-e201960050-g002"/>
      </fig>
      <fig fig-type="Figure" xml:lang="en" id="jbio201960050-fig-0003" orientation="portrait" position="float">
        <label>Figure 3</label>
        <caption>
          <p>ROC curves for each type of classifier and donor. The gray bars to the right display the number of activated and quiescent images for each donor [Correction added on 17 February 2020, after first online publication: This figure has been corrected and replaced]</p>
        </caption>
        <graphic id="nlm-graphic-7" xlink:href="JBIO-13-e201960050-g003"/>
      </fig>
      <fig fig-type="Figure" xml:lang="en" id="jbio201960050-fig-0004" orientation="portrait" position="float">
        <label>Figure 4</label>
        <caption>
          <p>PR curves for each type of classifier and donor. The gray bars to the right display the number of activated and quiescent images for each donor</p>
        </caption>
        <graphic id="nlm-graphic-9" xlink:href="JBIO-13-e201960050-g004"/>
      </fig>
      <p>The frequency classifier's average accuracy for all test donors is 37.56% (Figure <xref rid="jbio201960050-fig-0002" ref-type="fig">2</xref> and <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Table S1</xref>). The low accuracy of this simple method implies that the majority class in the training and test sets is likely to be different. For example, there are more activated cells from donor 2 while there are more quiescent cells from the combination of donors 1, 3, 5 and 6. This baseline establishes that classifiers that fail to use features other than the label count will perform poorly.</p>
      <p>Three logistic regression models using different features all give better classifications than the baseline model. Logistic regression with the image pixel matrix leads to an average accuracy of 78.74% (Figure <xref rid="jbio201960050-fig-0002" ref-type="fig">2</xref> and <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Table S2</xref>). Among those 6724 pixel features, 5822 features on average are removed by the Lasso regularization. To interpret this model, we plot the exponential of each pixel's coefficient to visualize the odds ratios. As shown in <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Figure S1</xref>, this model learns the shape of cells. Larger cells are more likely to be classified as activated. Logistic regression using only mask size and total intensity as features gives slightly better performance with an average accuracy of 79.93% (Figure <xref rid="jbio201960050-fig-0002" ref-type="fig">2</xref> and <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Table S3</xref>). For all test donors, the optimal coefficient of cell mask size is negative, whereas the coefficient of total intensity is positive. In practice, we expect larger cells to be activated, but the negative coefficient indicates the model learns the wrong relationship between cell size and activity state. This can be explained by the inconsistent cell size distribution across donors (<xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Figure S2</xref>) and the correlation of cell size and total intensity (multicollinearity). Comparing the odds ratio of one standard deviation (SD) increment of each feature, however, shows this logistic regression model is much more sensitive to total intensity than cell size. Finally, the logistic regression model with CellProfiler attributes yields 87.14% average accuracy (Figure <xref rid="jbio201960050-fig-0002" ref-type="fig">2</xref> and <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Table S4</xref>). After computing the odds ratio adjusted to the SD of each feature, attributes that are related to image intensity and cell area have the strongest impact on the predictions.</p>
      <p>Non‐linear models with image pixels as input have accuracies comparable to the logistic regression model with CellProfiler features. We tune the learning rate, batch size and the number of hidden layer neurons of the simple neural network with one hidden layer. Even though its average accuracy of 86.48% (Figure <xref rid="jbio201960050-fig-0002" ref-type="fig">2</xref> and <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Table S5</xref>) is slightly lower than logistic regression with CellProfiler features, it has more stable performance across the test donors. In comparison, the LeNet CNN has a more complex architecture and takes advantage of the image structure of the input data. After selecting the best learning rate and batch size, LeNet reaches an average accuracy of 89.51% (Figure <xref rid="jbio201960050-fig-0002" ref-type="fig">2</xref> and <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Table S6</xref>).</p>
      <p>Our most advanced models using the pre‐trained CNN outperform all other methods. Both versions of the pre‐trained CNN use cell images as input and require a previously trained CNN. For one version, we use the pre‐trained CNN as a feature extractor and then train a new hidden layer with off‐the‐shelf features. Alternatively, we fine‐tune multiple higher‐level layers of the CNN with T cell images. We include the fine‐tuned layers as a hyper‐parameter. Specifically, we define <italic>n</italic>, ranging from 1 to 11, as the number of last Inception modules in the pre‐trained Inception v3 CNN to fine‐tune. For example, if n = 1, we only fine‐tune the last Inception module, whereas we fine‐tune all the layers of the Inception v3 CNN when n = 11. After tuning <italic>n</italic> along with the other hyper‐parameters, we compare the CNN with fine‐tuning to the CNN off‐the‐shelf model in order to study the effect of fine‐tuning on classifier performance. In addition, we compare the test results of different <italic>n</italic> to analyze how the number of fine‐tuned layers affects classification.</p>
      <p>The average accuracy for the pre‐trained CNN off‐the‐shelf model is 90.36% (Figure <xref rid="jbio201960050-fig-0002" ref-type="fig">2</xref> and <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Table S7</xref>) and 93.56% for the pre‐trained CNN with fine‐tuning (Figure <xref rid="jbio201960050-fig-0002" ref-type="fig">2</xref> and <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Table S8</xref>). The fine‐tuning model uses 11, 10, 7, 11, and 8 layers as the optimal <italic>n</italic> for the five test donors. However, depending on the test donor and the evaluation metric, the number of fine‐tuned layers does not necessarily have a strong effect on the predictive performance (Figure <xref rid="jbio201960050-fig-0005" ref-type="fig">5</xref>). Different <italic>n</italic> values yield similar evaluation metrics. Fine‐tuning all 11 layers also greatly increases the CNN training time (Figures <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">S3</xref> and <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">S4</xref>).</p>
      <fig fig-type="Figure" xml:lang="en" id="jbio201960050-fig-0005" orientation="portrait" position="float">
        <label>Figure 5</label>
        <caption>
          <p>Performance comparison of fine‐tuning a different number of layers and the pre‐trained CNN off‐the‐shelf model</p>
        </caption>
        <graphic id="nlm-graphic-11" xlink:href="JBIO-13-e201960050-g005"/>
      </fig>
    </sec>
    <sec id="jbio201960050-sec-0005">
      <label>2.3</label>
      <title>Confirming generalization with a new donor</title>
      <p>In order to evaluate our ability to generalize to T cell images from a new individual, we completely hold out images from donor 4 during the study design, model implementation and cross‐validation above. We apply the same nested cross‐validation scheme to train, tune and test the pre‐trained CNN with fine‐tuning, the most accurate model in the previous cross‐validation, on images from donor 4. It gives an accuracy of 98.83% (Table <xref rid="jbio201960050-tbl-0002" ref-type="table">2</xref>). Out of 2051 predictions, there are only four false positives and 20 false negatives. The performance metrics in Table <xref rid="jbio201960050-tbl-0002" ref-type="table">2</xref> are substantially higher than their counterparts in <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Table S8</xref>. Having training data from five donors instead of four likely contributes to the improved performance.</p>
      <table-wrap id="jbio201960050-tbl-0002" xml:lang="en" orientation="portrait" position="float">
        <label>Table 2</label>
        <caption>
          <p>Performance of the pre‐trained CNN with fine‐tuning on held out donor 4</p>
        </caption>
        <table frame="hsides" rules="groups">
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <thead valign="bottom">
            <tr style="border-bottom:solid 1px #000000">
              <th align="left" valign="bottom" rowspan="1" colspan="1">Donor</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Accuracy</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Precision</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Recall</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Average precision</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">AUC</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Activated count</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Quiescent count</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">4</td>
              <td align="left" valign="top" rowspan="1" colspan="1">98.83%</td>
              <td align="left" valign="top" rowspan="1" colspan="1">99.14%</td>
              <td align="left" valign="top" rowspan="1" colspan="1">95.85%</td>
              <td align="left" valign="top" rowspan="1" colspan="1">99.79%</td>
              <td align="left" valign="top" rowspan="1" colspan="1">99.93%</td>
              <td align="left" valign="top" rowspan="1" colspan="1">482</td>
              <td align="left" valign="top" rowspan="1" colspan="1">1569</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot id="jbio201960050-ntgp-0003">
          <fn id="jbio201960050-note-0004">
            <p>Abbreviation: CNN, convolutional neural network.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="jbio201960050-sec-0006">
      <label>2.4</label>
      <title>Pre‐trained CNN with fine‐tuning errors</title>
      <p>We inspect the T cell images that the pre‐trained CNN with fine‐tuning classifies incorrectly in order to better understand its failures and accuracy. We visualize the misclassified images for all test donors in <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Figures S5‐S10</xref> along with the predicted label, the Softmax score of the network output layer and the temperature‐scaled confidence calibration <xref rid="jbio201960050-bib-0040" ref-type="ref">40</xref>. The majority of misclassified cell images are badly cropped, with no cells or multiple cells included in the frame. Therefore, using a more progressive dim image filter or adding a multiple‐cell detector in the image processing pipeline could further improve the model performance. However, for other images with a clear single cell in the frame, the pre‐trained CNN tends to give high confidence in its misclassification. These scores suggest that these errors cannot be easily fixed without a more powerful classifier or more diverse training dataset. Temperature scaling could either soften the original Softmax score toward 50<italic>%</italic> or increase the confidence toward 100<italic>%</italic>. For the misclassified images in our study, temperature scaling always drops the Softmax probability. This observation matches Guo et al.'s finding that neural networks with higher model capacity are more likely to be overconfident in their predictions <xref rid="jbio201960050-bib-0040" ref-type="ref">40</xref>.</p>
    </sec>
    <sec id="jbio201960050-sec-0007">
      <label>2.5</label>
      <title>Pre‐trained CNN with fine‐tuning interpretation</title>
      <p>Visualizing the T cell dataset in two dimensions (2D) helps us understand why some classifiers perform better than others. We use Uniform Manifold Approximation and Projection (UMAP) <xref rid="jbio201960050-bib-0041" ref-type="ref">41</xref> to project the images into 2D such that similar images in the original feature space are nearby in the 2D space. Coloring the images with their activity labels shows how different input representations or learned representations separate the activated and quiescent cells. For example, in Figure <xref rid="jbio201960050-fig-0006" ref-type="fig">6</xref>, each dot corresponds to one image based on its representation in the last layer of the pre‐trained CNNs with fine‐tuning. UMAP projects the 2048 learned features in the last layer of the CNN into 2D. In general, the activated and quiescent cells are well‐separated in the 2D space, suggesting that the CNN has successfully learned distinct representations for the two types of T cells. Using t‐Distributed Stochastic Neighbor Embedding (t‐SNE) <xref rid="jbio201960050-bib-0042" ref-type="ref">42</xref> instead of UMAP for dimension reduction provides qualitatively similar results (<xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Figure S11</xref>).</p>
      <fig fig-type="Figure" xml:lang="en" id="jbio201960050-fig-0006" orientation="portrait" position="float">
        <label>Figure 6</label>
        <caption>
          <p>2D representations of T cell features extracted from the pre‐trained CNN with fine‐tuning. Dimensions are reduced from 2048 using UMAP. The thick outlines indicate incorrect cell activity state predictions</p>
        </caption>
        <graphic id="nlm-graphic-13" xlink:href="JBIO-13-e201960050-g006"/>
      </fig>
      <p>Generating similar UMAP plots for three alternative image representations shows that the two image classes are not as well separated (<xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Figures S12‐S14</xref>). When using the raw pixel features (<xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Figure S12</xref>), the two types of T cells are spread throughout the 2D space. This contributes to the lower performance of the logistic regression and fully connected neural network models that operate directly on pixel intensity. Similarly, there is only moderate spatial separation when using the CellProfiler features (<xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Figure S13</xref>) or the last layer of the CNN before fine‐tuning it to predict T cell activity (<xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Figure S14</xref>). These comparisons demonstrate the strong effect of fine‐tuning the pre‐trained CNN and also help explain the superior performance of pre‐trained CNNs over the logistic regression model with CellProfiler features. In addition, by annotating the images that are misclassified by the pre‐trained CNN with fine‐tuning as outlined dots in each of the 2D representations, we see where this classifier makes errors. In Figure <xref rid="jbio201960050-fig-0006" ref-type="fig">6</xref>, the incorrect predictions are predominantly distributed in the boundary between the two clusters.</p>
      <p>In addition to visualizing the feature representation in the pre‐trained CNNs with fine‐tuning, we use saliency maps <xref rid="jbio201960050-bib-0043" ref-type="ref">43</xref> to interpret how these models make decisions. We generate saliency maps by computing the gradient of the CNN class score with respect to a few randomly chosen donor 1 images from both the activated and quiescent classes (Figure <xref rid="jbio201960050-fig-0007" ref-type="fig">7</xref>). We use two methods to calculate gradients: standard backpropagation and guided backpropagation <xref rid="jbio201960050-bib-0044" ref-type="ref">44</xref>. In these heat maps, larger values (green or yellow) highlight the image regions that cause the most change in the T cell activity prediction. Smaller values (dark blue or purple) indicate pixels that have less influence. The uniformly dark blue background in both types of saliency maps indicates that the pre‐trained CNNs with fine‐tuning have learned to focus on the original cell image instead of the black padding. The larger values in the saliency maps with guided backpropagation often align with the high‐intensity regions of the cell images, which correspond to mitochondria and depict metabolic activity <xref rid="jbio201960050-bib-0045" ref-type="ref">45</xref>. Although the influential regions of the guided backpropagation‐based saliency maps are biologically plausible, this type of saliency map is insensitive to random changes of either the input data or model parameters <xref rid="jbio201960050-bib-0046" ref-type="ref">46</xref>. The saliency maps generated with standard backpropagation are properly affected by these randomized controls but do not concentrate on the high‐intensity regions of the input images.</p>
      <fig fig-type="Figure" xml:lang="en" id="jbio201960050-fig-0007" orientation="portrait" position="float">
        <label>Figure 7</label>
        <caption>
          <p>Saliency maps of randomly selected cell images from donor 1 (scale bar: 10 μm). The backpropagation and guided backpropagation rows show two different techniques for generating saliency maps from the same T cell images in the first row</p>
        </caption>
        <graphic id="nlm-graphic-15" xlink:href="JBIO-13-e201960050-g007"/>
      </fig>
    </sec>
    <sec id="jbio201960050-sec-0008">
      <label>2.6</label>
      <title>Running the analysis pipeline</title>
      <p>Our GitHub repository <ext-link ext-link-type="uri" xlink:href="https://github.com/gitter-lab/t-cell-classification">https://github.com/gitter-lab/t-cell-classification</ext-link> demonstrates and documents all steps of our analysis pipeline, from pre‐processing the cropped images to fine‐tuning and interpreting the Inception v3 CNN. Our Python code is presented in Jupyter notebooks <xref rid="jbio201960050-bib-0047" ref-type="ref">47</xref>, which integrate our code with explanations of its functionality and visualizations of its outputs. These notebooks can serve as a tutorial of best practices in machine learning on autofluorescence microscopy images. We use Binder <xref rid="jbio201960050-bib-0048" ref-type="ref">48</xref> to enable readers to execute our Jupyter notebooks in a web browser without having to download any software locally or configure a Python environment. We ensure the Jupyter notebooks continue to run as expected by automatically testing them in Linux, macOS and Windows with the Travis CI and AppVeyor continuous integration services. Our software re‐runs our analyses with a randomly selected 10% of the images. This allows users to quickly train the machine learning models and understand our pipeline.</p>
    </sec>
  </sec>
  <sec id="jbio201960050-sec-0009">
    <label>3</label>
    <title>DISCUSSION</title>
    <p>Our study demonstrates that machine learning models trained on autofluorescence intensity images can accurately classify activated and quiescent T cells across donors. Because autofluorescence images are easier to acquire with standard commercial microscopes compared to fluorescence lifetime images, this workflow has the potential to become a widely applicable approach for live T cell profiling. Fine‐tuning a pre‐trained CNN is the most powerful classification approach, outperforming alternative machine learning models that are commonly used for microscopy image classification over multiple evaluation metrics. In particular, this CNN applied directly to cropped images has better performance than logistic regression with domain‐relevant features extracted by CellProfiler.</p>
    <p>We thoroughly explored the effect of fine‐tuning more layers of the pre‐trained CNN and compared it with the off‐the‐shelf CNN model. The common transfer learning approach fixes the CNN parameters of the initial network layers, which extract learned features from the images, and trains a simple classifier from scratch that predicts the domain‐specific image labels. Our results indicate that fine‐tuning pre‐trained CNN layers yields better performance than directly using off‐the‐shelf features. In addition, although fine‐tuning more layers tends to give better predictive performance (Figure <xref rid="jbio201960050-fig-0005" ref-type="fig">5</xref>), it is generally not worth the additional computational time and expense to fine‐tune all 11 layers (Figures <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">S3</xref> and <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">S4</xref>). Possible reasons include the limited sample size and relatively homogeneous cell image representations. Given the extra computational costs and implementation challenges, we recommend fine‐tuning only the last few layers of a pre‐trained CNN for similar autofluorescence microscopy applications. In settings that do require fine‐tuning additional layers because the images are more heterogeneous, we suggest taking a larger step size in the layer number hyper‐parameter optimization.</p>
    <p>The machine learning models recognize image attributes that recapitulate biological domain knowledge. Activated T cells are larger in size <xref rid="jbio201960050-bib-0006" ref-type="ref">6</xref>, <xref rid="jbio201960050-bib-0049" ref-type="ref">49</xref>. In addition, there are metabolic differences between quiescent and activated T cells <xref rid="jbio201960050-bib-0001" ref-type="ref">1</xref>, which are evident in the NAD(P)H images. The high intensity regions in the images likely correspond to mitochondria, where the majority of metabolism occurs. It is straightforward to inspect the trained logistic regression model that takes total image intensity and mask size as inputs and observe that it correctly recognizes the relationship between NAD(P)H intensity and activation state.</p>
    <p>The parameters of the pre‐trained CNN with fine‐tuning are not as directly interpretable as the logistic regression model. An additional challenge is that different interpretation techniques provide distinct views of the fine‐tuned CNN. Nevertheless, there are some indications in the saliency maps that this CNN also reflects T cell biology. Saliency maps help locate which regions of the input image influence the classification the most. With guided backpropagation, the high‐intensity regions of the T cell images tend to be the focal points in the saliency maps. This suggests that the CNN may be sensitive to metabolic differences between quiescent and activated cells and not only changes in cell size. However, guided backpropagation and other more advanced saliency maps were found to be independent of the data, model and model parameters <xref rid="jbio201960050-bib-0046" ref-type="ref">46</xref>. The standard backpropagation gradient map is sensitive to these controls, but it focuses more on general cell morphology than the metabolic activity within cells.</p>
    <p>Each model in our study is only tuned and evaluated once, which limits our ability to assess the statistical significance of the performance differences across models. Substantial computing time and costs are required for nested cross‐validation, especially when fine‐tuning multiple layers of the pre‐trained CNN (Figures <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">S3</xref> and <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">S4</xref>). The fine‐tuning jobs took 5096 hours (212 days) in total to train on graphics processing units (GPUs). Therefore, we do not train each model multiple times to assess the variability in model performance due to random sampling, computer hardware, non‐deterministic algorithms and other factors. Slight differences in performance should not be over‐interpreted.</p>
    <p>Based on the misclassified images, the performance of the pre‐trained CNN model with fine‐tuning is limited by the image cropping quality. Some images contain multiple cells. Others do not contain any T cells. Developing a better filter to detect images with artifacts and adopting state‐of‐the‐art segmentation approaches <xref rid="jbio201960050-bib-0016" ref-type="ref">16</xref>, <xref rid="jbio201960050-bib-0050" ref-type="ref">50</xref> could further boost classification accuracy. We highlight the images that are misclassified by the pre‐trained CNN with fine‐tuning on the UMAP plots for three alternative image representations (Figures <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">S12‐S14</xref>). Some of these misclassified images are better aligned with other images from the correct class in these alternative feature spaces than in Figure <xref rid="jbio201960050-fig-0006" ref-type="fig">6</xref>. These images may be easier to classify correctly with the alternative image representations. Therefore, ensemble methods combining multiple image representations and classifiers may further improve performance. However, an ensemble learning approach would still be limited by the image cropping quality and any errors in the image labelling.</p>
    <p>Although the pre‐trained CNN with fine‐tuning has strong predictive performance in this study, there are several caveats regarding how these results may translate to other autofluorescence intensity image classification tasks. We have a small set of donors. The nested cross‐validation involves only five donors, and the generalization test uses a single held out donor. In addition, all donors are from a narrow, young and healthy population. They may not adequately represent the general public or cancer patients, and further study is needed to see if the model is still applicable in more challenging populations. Also, T cells in our study are isolated from the bulk blood cell population, and two subtypes of T cells are separated during data acquisition. It is possible to classify some blood cell types in a bulk population with only label‐free autofluorescence parameters <xref rid="jbio201960050-bib-0051" ref-type="ref">51</xref>, but future work is needed to assess the performance of our approach on image samples with additional immune cells and mixed activation states. Finally, quantitative fluorescence intensity imaging has technical limitations, requiring consistent imaging settings such as illumination power and detector gain.</p>
    <p>Future work also can assess how robust our trained CNN models are to more diverse imaging settings and whether new training strategies are required to adapt to other domains. To sort T cells in practice and improve cell manufacturing processes, the classifier would need to be coupled to a flow sorter. Transitioning from the current imaging platform to a commercial imaging flow cytometer would make our approach more widely available. However, imaging flow cytometry is typically single‐photon and requires UV excitation to measure NAD(P)H intensity, which can be damaging to cells. In addition, lower resolution imaging and the flowing nature of the cells may make it more difficult to detect the intracellular structures of small T cells. Although the resulting images may be different enough to require a distinct CNN, recent advances in CNNs for imaging flow cytometry <xref rid="jbio201960050-bib-0010" ref-type="ref">10</xref>, <xref rid="jbio201960050-bib-0023" ref-type="ref">23</xref>, <xref rid="jbio201960050-bib-0024" ref-type="ref">24</xref>, <xref rid="jbio201960050-bib-0038" ref-type="ref">38</xref>, <xref rid="jbio201960050-bib-0052" ref-type="ref">52</xref>, <xref rid="jbio201960050-bib-0053" ref-type="ref">53</xref> suggest our pipeline could be optimized for this practical setting. Overall, our strong results demonstrate the feasibility of classifying T cells directly from autofluorescence intensity images, which can guide future work to bring this technology to pre‐clinical and clinical applications.</p>
  </sec>
  <sec id="jbio201960050-sec-0010">
    <label>4</label>
    <title>METHODS</title>
    <sec id="jbio201960050-sec-0011">
      <label>4.1</label>
      <title>Cell preparation and imaging</title>
      <p>This study was approved by the Institutional Review Board of the University of Wisconsin‐Madison (#2018–0103). Informed consent was obtained from all donors. All NAD(P)H intensity images were created from a subset of the NAD(P)H fluorescence lifetime images acquired in Walsh et al. <xref rid="jbio201960050-bib-0006" ref-type="ref">6</xref>. No new images were generated for this study. The protocols summarized below are described in more detail in Walsh et al. <xref rid="jbio201960050-bib-0006" ref-type="ref">6</xref>.</p>
      <p>CD3 and CD8 T cells were isolated using negative selection methods (RosetteSep, StemCell Technologies) from the peripheral blood of six healthy donors (three male, three female, mean age = 26). The T cells were divided into quiescent and activated groups. The quiescent group came directly from the body without any antibody or chemical treatment, whereas the activated group was stimulated with a tetrameric antibody against CD2, CD3 and CD28 (StemCell Technologies). CD69 immunofluorescence labelling in a subset of cells verified the quiescent (CD69‐) and activated (CD69+) phenotypes due to the culture conditions. In our dataset, all treated cells were assigned to the activated class, which could introduce a small amount of noise in the class labels. T cell populations were cultured for 48 hours at 37C, 5% CO2 and 99% humidity and then plated before imaging. The T cells were not adherent or immobilized. For all donors, an equal number of quiescent and activated cells were initially cultured. However, different numbers of cells were imaged for each donor and activation state due to differences in the proliferation rates of quiescent and activated cells, differences in the clumping behaviors of the cells, potential bias by the operator in the selection of the imaging fields of view and dilution of the cell concentration due to parallel experiments (particularly for the antibody experiments reported by Walsh et al. <xref rid="jbio201960050-bib-0006" ref-type="ref">6</xref>). Therefore, there are different activated and quiescent class skews among donors (Table <xref rid="jbio201960050-tbl-0001" ref-type="table">1</xref>).</p>
      <p>NAD(P)H intensity images were created by integrating the photon counts of fluorescence lifetime decays at each pixel within the fluorescence lifetime images acquired, as described by Walsh et al. <xref rid="jbio201960050-bib-0006" ref-type="ref">6</xref>. Briefly, images were acquired using an Ultima (Bruker Fluorescence Microscopy) two‐photon microscope coupled to an inverted microscope body (TiE, Nikon) with an Insight DS+ (Spectra Physics) as the excitation source. A 100X objective (Nikon Plan Apo Lambda, NA 1.45), lending an approximate field of view of 110 <italic>μ</italic>m, was used in all experiments with the laser tuned to 750 nm for NAD(P)H two‐photon excitation and a 440/80 nm bandpass emission filter in front of a GaAsP photomultiplier tube (PMT; H7422, Hamamatsu). Images were acquired for 60 seconds with a laser power at the sample of 3.0 to 3.2 mW and a pixel dwell time of 4.6 μs. Grayscale microscopy images were labeled with a deidentified donor ID and T cell activity state according to the culture conditions: quiescent for T cells not exposed to the activating antibodies or activated for T cells exposed to the activating antibodies.</p>
    </sec>
    <sec id="jbio201960050-sec-0012">
      <label>4.2</label>
      <title>Image processing</title>
      <p>We segmented cell images using CellProfiler <xref rid="jbio201960050-bib-0035" ref-type="ref">35</xref>. Each cell was cropped according to the bounding box of its segmented mask. Cell short NAD(P)H lifetime was used to filter out other visually indistinguishable cells (eg, red blood cells) by removing cells with a mean fluorescence lifetime less than 200 ps. To remove very dim images and images containing no cells, we further filtered the segmented images by thresholding the combination of image entropy and total intensity (<xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Figure S15</xref>). The threshold values in <xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Figure S15</xref> were chosen based on the distributions of entropy and intensity with a Gaussian approximation. This filter was conservative. We manually inspected the removed images to ensure none of them contained T cells.</p>
      <p>Because the classifiers that used image pixels as input required uniform size and some required square images, we padded all activated and quiescent cell images with black borders. The padding size of 82 × 82 was chosen based on the largest image in the dataset after removing extremely large outliers. Also, we augmented the dataset by rotating each original image by 90, 180 and 270 degrees and also by flipping the original image horizontally and vertically, which added five extra images for each cell (Figure <xref rid="jbio201960050-fig-0001" ref-type="fig">1</xref>). We implemented this image processing pipeline using the Python package OpenCV <xref rid="jbio201960050-bib-0054" ref-type="ref">54</xref>.</p>
    </sec>
    <sec id="jbio201960050-sec-0013">
      <label>4.3</label>
      <title>Nested cross‐validation</title>
      <p>We trained and evaluated eight classifiers of increasing complexity (Table <xref rid="jbio201960050-tbl-0003" ref-type="table">3</xref>). We used the same leave‐one‐donor‐out test principle to measure the performance of all models. For example, when using donor 1 as the test donor, the frequency classifier counts the positive proportion among all images in the augmented dataset from donors 2, 3, 5 and 6. Then, it uses this frequency to predict the activity for all unaugmented images from donor 1. By testing in this way, the classification result tells us how well each model performs on images from new donors. Donor 4 was not included in this cross‐validation because we randomly selected it as a complete hold‐out donor. All images from donor 4 were only used after hyper‐parameter tuning and model selection as a final independent test to assess the generalizability of our pipeline to a new donor.</p>
      <table-wrap id="jbio201960050-tbl-0003" xml:lang="en" orientation="portrait" position="float">
        <label>Table 3</label>
        <caption>
          <p>The eight classifiers with their input features and hyper‐parameters</p>
        </caption>
        <table frame="hsides" rules="groups">
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <thead valign="bottom">
            <tr style="border-bottom:solid 1px #000000">
              <th align="left" valign="bottom" rowspan="1" colspan="1">Model</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Description</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">Frequency Classifier</td>
              <td align="left" valign="top" rowspan="1" colspan="1">Predict class probability using the class frequencies in the training set.</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">Logistic Regression with Pixel Intensity</td>
              <td align="left" valign="top" rowspan="1" colspan="1">Regularized logistic regression model with pixel intensity as input. Regularization power <italic>λ</italic> of <italic>ℓ</italic>
<sub>1</sub> penalty is tuned.</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">Logistic Regression with Total Intensity and Size</td>
              <td align="left" valign="top" rowspan="1" colspan="1">Regularized logistic regression model fitted with two numerical values: image total intensity and cell mask size. Regularization power <italic>λ</italic> of <italic>ℓ</italic>
<sub>1</sub> penalty is tuned.</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">Logistic Regression with CellProfiler Features</td>
              <td align="left" valign="top" rowspan="1" colspan="1">Regularized logistic regression model fitted with 123 features extracted from CellProfiler related to intensity, texture and area. Regularization power <italic>λ</italic> of <italic>ℓ</italic>
<sub>1</sub> penalty is tuned.</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">One‐layer Fully Connected Neural Network</td>
              <td align="left" valign="top" rowspan="1" colspan="1">Fully connected one‐hidden‐layer neural network with pixel intensity as input. Number of neurons, learning rate and batch size are tuned.</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">LeNet CNN</td>
              <td align="left" valign="top" rowspan="1" colspan="1">CNN with the LeNet architecture with pixel intensity as input. Learning rate and batch size are tuned.</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">Pre‐trained CNN Off‐the‐shelf Model</td>
              <td align="left" valign="top" rowspan="1" colspan="1">Freeze layers of a pre‐trained Inception v3 CNN. Train a final added layer from scratch with extracted off‐the‐shelf features. Learning rate and batch size are tuned.</td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">Pre‐trained CNN with Fine‐tuning</td>
              <td align="left" valign="top" rowspan="1" colspan="1">Fine‐tune the last <italic>n</italic> layers of a pre‐trained Inception v3 CNN. The number of layers <italic>n</italic>, learning rate and batch size are tuned.</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>Following the leave‐one‐donor‐out test principle <xref rid="jbio201960050-bib-0031" ref-type="ref">31</xref>, <xref rid="jbio201960050-bib-0038" ref-type="ref">38</xref>, we wanted the selection of the optimal hyper‐parameters to be generalizable to new donors as well. Therefore, we applied a nested cross‐validation scheme <xref rid="jbio201960050-bib-0055" ref-type="ref">55</xref>, <xref rid="jbio201960050-bib-0056" ref-type="ref">56</xref> (Figure <xref rid="jbio201960050-fig-0008" ref-type="fig">8</xref>). For each test donor, within the inner loop we performed 4‐fold cross‐validation to measure the average performance of each hyper‐parameter combination (grid search). Each fold in the inner loop cross‐validation corresponds to one donor's augmented images. The outer cross‐validation loop used the selected hyper‐parameters from the inner loop cross‐validation to train a new model with the four other donors' augmented images. We evaluated the trained model on the outer loop test donor. For models requiring early stopping, we constructed an early stopping set by randomly sampling one‐fourth of the unaugmented images from the training set and removing their augmented copies. Then, training continued as long as the performance on images in the early stopping set improved. Similarly, we did not include augmented images in the validation set or the test set.</p>
      <fig fig-type="Figure" xml:lang="en" id="jbio201960050-fig-0008" orientation="portrait" position="float">
        <label>Figure 8</label>
        <caption>
          <p>5 × 4 nested cross‐validation scheme. For each test donor (blue), we used an inner cross‐validation loop to optimize the hyper‐parameters. We trained a model for each hyper‐parameter combination using the training donors' augmented images (yellow) and selected the hyper‐parameters that performed best on the validation donor's images (green). The validation donor is sometimes referred to as a tuning donor in cross‐validation. Then, we trained a final model for each test donor using the selected hyper‐parameters</p>
        </caption>
        <graphic id="nlm-graphic-17" xlink:href="JBIO-13-e201960050-g008"/>
      </fig>
      <p>No single evaluation metric can capture all the strengths and weaknesses of a classifier, especially because our dataset was class imbalanced and not skewed in the same way for all donors. Therefore, we considered multiple evaluation metrics in the outer loop. Accuracy measures the percentage of correct predictions. It is easy to interpret, but it does not necessarily characterize a useful classifier. For example, when positive samples are rare, a trivial classifier that predicts all samples as negative yields high accuracy. Precision and recall (sensitivity), on the other hand, consider the costs of false positive and false negative predictions, respectively. Graphical metrics such as the ROC curve and PR curve avoid setting a specific classification threshold. We used AUC to summarize ROC curves and average precision for the PR curves. The ROC curve performance of a random classifier is independent of the class distribution, while the PR curve is useful when the classes are imbalanced <xref rid="jbio201960050-bib-0039" ref-type="ref">39</xref>. For this reason, we used mean average precision of the inner loop 4‐fold cross‐validation to select optimal hyper‐parameters.</p>
      <p>During the nested cross‐validation, we trained the LeNet CNN and pre‐trained CNN with fine‐tuning using GPUs. These jobs ran on GTX 1080, GTX 1080 Ti, K40, K80, P100 or RTX 2080 Ti GPUs. All other models were trained using CPUs.</p>
    </sec>
    <sec id="jbio201960050-sec-0014">
      <label>4.4</label>
      <title>Linear classifiers</title>
      <p>We used a trivial frequency classifier as a baseline model. This model computes the positive sample percentage in the training set. Then, it uses this frequency as a positive class prediction score (between 0 and 1) for all samples in the test set.</p>
      <p>Logistic regression with Lasso regularization is a standard and interpretable statistical model used to classify microscopy images <xref rid="jbio201960050-bib-0008" ref-type="ref">8</xref>. The Lasso approach reduces the number of effective parameters by shrinking the parameters of less predictive features to zero. These features are ignored when making a new prediction. We fitted and tested three Lasso logistic regression models with different types of features using the Python package scikit‐learn <xref rid="jbio201960050-bib-0057" ref-type="ref">57</xref>. An image intensity matrix with dimension 82 × 82 and values from 0 to 255, reshaped into a vector with length 6724, was used to fit the first model. The second model was trained with two scalar features, cell size and image total intensity, where cell size was computed using the pixel count in the cell mask generated by CellProfiler. The last model used 123 features relating to cell intensity, texture and area, which were extracted from cell images using a CellProfiler pipeline with modules <italic>MeaureObjectSizeShape</italic>, <italic>MeasureObjectIntensity</italic> and <italic>MeasureTexture</italic>. The Lasso regularization parameter <italic>λ</italic> was tuned for all three classifiers with nested cross‐validation (<xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Table S9</xref>). We also applied inverse class frequencies in the training data as class weights to adjust the imbalanced dataset.</p>
    </sec>
    <sec id="jbio201960050-sec-0015">
      <label>4.5</label>
      <title>Simple neural network classifiers</title>
      <p>We developed a fully connected neural network with one hidden layer (<xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Figure S16</xref>) using the Python package Keras with the TensorFlow backend <xref rid="jbio201960050-bib-0058" ref-type="ref">58</xref>, <xref rid="jbio201960050-bib-0059" ref-type="ref">59</xref>. The input layer uses the flattened image pixel vector with dimension 6724 × 1. Network hyper‐parameters—number of hidden neurons, learning rate and batch size—were tuned using nested cross‐validation (<xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Table S9</xref>). The cross‐entropy loss function was weighted according to the class distribution in the training set.</p>
      <p>Also, we trained a CNN with the LeNet architecture <xref rid="jbio201960050-bib-0036" ref-type="ref">36</xref> with randomly initialized weights (no pre‐training). The LeNet architecture has two convolutional layers and two pooling layers (<xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Figure S17</xref>). We used the default number of neurons specified in the original LeNet paper in each layer. The input layer was modified to support 82 × 82 one‐channel images, so we could train this network with image pixel intensities. Similar to the fully connected neural network, we used nested cross‐validation to tune the learning rate and batch size (<xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Table S9</xref>) and applied class weighting. We used early stopping with a patience of 10 for both models, which means we stopped training if the loss function failed to improve on the early stopping set in 10 consecutive epochs.</p>
    </sec>
    <sec id="jbio201960050-sec-0016">
      <label>4.6</label>
      <title>Pre‐trained CNN classifiers</title>
      <p>We developed a transfer learning classifier that uses the Inception v3 CNN with pre‐trained ImageNet weights <xref rid="jbio201960050-bib-0060" ref-type="ref">60</xref>, <xref rid="jbio201960050-bib-0061" ref-type="ref">61</xref>. Instead of training the whole network end‐to‐end from scratch, we took advantage of the pre‐trained weights by extracting and modeling off‐the‐shelf features or fine‐tuning the last <italic>n</italic> Inception modules, where <italic>n</italic> was treated as a hyper‐parameter (Figure <xref rid="jbio201960050-fig-0009" ref-type="fig">9</xref>). Inception modules are mini‐networks that constitute the overall Inception v3 architecture. Our first approach is a popular practice for transfer learning with Inception v3. We freeze the weights of all layers before the output layer and use them to extract generic image characteristics. Then, we train a light‐weight classifier from scratch, specifically a neural network with an average pooling layer and a fully connected hidden layer with 1024 neurons, using these off‐the‐shelf features. We refer to this model as the pre‐trained CNN off‐the‐shelf model.</p>
      <fig fig-type="Figure" xml:lang="en" id="jbio201960050-fig-0009" orientation="portrait" position="float">
        <label>Figure 9</label>
        <caption>
          <p>Fine‐tuning the Inception v3 CNN to predict T cell activity. The example generic images are adapted from ImageNet</p>
        </caption>
        <graphic id="nlm-graphic-19" xlink:href="JBIO-13-e201960050-g009"/>
      </fig>
      <p>An alternative is to fix some earlier layers and fine‐tune the higher‐level <italic>n</italic> layers by initializing them with pre‐trained weights and continuing training on a new dataset. For this model, we modified the output layer to support binary classification, and we did not add new layers. In addition, we used the nested cross‐validation scheme to optimize <italic>n</italic> along with the learning rate and batch size (<xref rid="jbio201960050-supitem-0001" ref-type="supplementary-material">Table S9</xref>), creating the pre‐trained CNN with fine‐tuning.</p>
      <p>To implement these two pre‐trained CNN models, we resized the padded cell images with bilinear interpolation to fit the input layer dimension (299 × 299 × 3) and generated three‐channel images by merging three copies of the same grayscale image. For the pre‐trained CNN with fine‐tuning, we first used the resized cell images to generate intermediate features (“bottlenecks”). Then, we used these features to fine‐tune a sub‐network. This approach significantly shortened the training time. Finally, we used class weighting and early stopping with a patience of 10 for both models. We implemented these two models using Keras with the TensorFlow backend.</p>
    </sec>
    <sec id="jbio201960050-sec-0017">
      <label>4.7</label>
      <title>Pre‐trained CNN interpretation</title>
      <p>We implemented multiple approaches for interpreting the pre‐trained CNNs. Computing classification confidence on misclassified images can help us understand why classifiers make certain errors. The Softmax score is sometimes used as a confidence prediction. Softmax is a function that maps the output real‐valued number (Logit) from a neural network into a score between 0 and 1, which is then used to make a classification as a class probability. However, using the Softmax score from a neural network as a confidence calibration does not match the real accuracy <xref rid="jbio201960050-bib-0040" ref-type="ref">40</xref>. Therefore, we used temperature scaling to better calibrate the predictions <xref rid="jbio201960050-bib-0040" ref-type="ref">40</xref>. After training, for each donor, we optimized the temperature <italic>T</italic> on the nested cross‐validation outer loop validation set. Then, we applied <italic>T</italic> to scale the Logit before Softmax computation and used the new Softmax score to infer classification confidence.</p>
      <p>In addition to confidence calibration, we used dimension reduction to investigate the high‐dimensional representations learned by our pre‐trained CNN models. Dimension reduction is a method to project high‐dimensional features into lower dimensions while preserving the characteristics of the data. Therefore, it provides a good way to visualize how trained models represent different cell image inputs. In our study, we choose UMAP <xref rid="jbio201960050-bib-0041" ref-type="ref">41</xref>, <xref rid="jbio201960050-bib-0062" ref-type="ref">62</xref> as our dimension reduction algorithm. UMAP uses manifold learning techniques to reduce feature dimensions. It arguably preserves more of the global structure and is more scalable than the standard form of t‐SNE <xref rid="jbio201960050-bib-0042" ref-type="ref">42</xref>, an alternative approach. Using UMAP, we projected the image features, extracted from the CNN layer right before the output layer, from 2048 dimensions to two dimensions. We used the default UMAP parameter values: “n_neighbors” as 15, “metrics” as “euclidean” and “min_dist” as 0.1. Then, we visualized and analyzed these projected features of T cell images using 2D scatter plots. When comparing UMAP with t‐SNE, we used the default t‐SNE parameters: “perplexity” as 30 and “metric” as “euclidean”.</p>
      <p>For the pre‐trained CNN with fine‐tuning, each test donor has different tuned hyper‐parameters and a different fine‐tuned CNN. Therefore, we performed feature extraction and dimension reduction independently for each test donor. There is no guarantee that these five scatter plots share the same 2D basis. In contrast, the image pixel features, CellProfiler features and off‐the‐shelf last layer features from a pre‐trained CNN do not vary by test donor. For these three UMAP applications, we performed feature extraction and dimension reduction in one batch for all donors simultaneously.</p>
      <p>Finally, we used saliency maps to further analyze what morphology features were used in classification <xref rid="jbio201960050-bib-0043" ref-type="ref">43</xref>. A saliency map is a straightforward and efficient way to detect how prediction value changes with respect to a small change in the input cell image pixels. It is generated by computing the gradient of the output class score with respect to the input image. We compared two ways to compute this gradient: standard backpropagation and guided backpropagation <xref rid="jbio201960050-bib-0044" ref-type="ref">44</xref>. Backpropagation is a method to calculate the gradient of loss function with respect to the neural network's weights. Guided backpropagation is a variant that only backpropagates positive gradients. We generated saliency maps of the output layer for the pre‐trained CNN with fine‐tuning model for test donor 1 with a few randomly sampled images from the test set. The saliency map interpretations help us assess whether the classification basis is intuitive and whether the predictions derive from image artifacts instead of cell morphology.</p>
    </sec>
    <sec sec-type="data-availability" id="jbio201960050-sec-0018">
      <label>4.8</label>
      <title>Software and data availability</title>
      <p>Our GitHub repository <ext-link ext-link-type="uri" xlink:href="https://github.com/gitter-lab/t-cell-classification">https://github.com/gitter-lab/t-cell-classification</ext-link> contains Jupyter notebooks demonstrating how to run our Python code to pre‐process images and train each of the classifiers. The notebooks can be run in a web browser using Binder and the links in the repository. The software is available under the BSD 3‐Clause Clear License. This repository also contains a randomly selected subset of the T cell images that can be used to quickly test our software as well as the CellProfiler segmentation and feature extraction pipeline files. We archived the GitHub repository on Zenodo (DOI:10.5281/zenodo.3455314). In addition, our Zenodo dataset (DOI:10.5281/zenodo.2640835) contains bottleneck features from the Inception v3 model and trained model weights.</p>
    </sec>
  </sec>
  <sec sec-type="COI-statement" id="jbio201960050-sec-0020">
    <title>CONFLICT OF INTEREST</title>
    <p>The authors and the Wisconsin Alumni Research Foundation have filed a provisional patent application based on these results.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material content-type="local-data" id="jbio201960050-supitem-0001">
      <caption>
        <p><bold>Appendix S1.</bold> Supporting information.</p>
      </caption>
      <media xlink:href="JBIO-13-e201960050-s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="jbio201960050-sec-0019">
    <title>ACKNOWLEDGMENTS</title>
    <p>We thank Tiffany Heaster for assistance with the T cell image processing; Quan Yin for CNN transfer learning advice; Shengchao Liu and Christine Walsh for general machine learning feedback; Katie Mueller, Steve Trier and Kelsey Tweed for discussion of the classification results; and Jaime Frey and Zach Miller for assistance with the Cooley cluster. This research was funded by NIH R01 CA205101, the UW Carbone Cancer Center Support Grant NIH P30 CA014520, the Morgridge Institute for Research and a UW‐Madison L&amp;S Honors Program Summer Senior Thesis Research Grant. In addition, this research benefited from GPU hardware from NVIDIA, resources of the Argonne Leadership Computing Facility, which is a DOE Office of Science User Facility supported under contract DE‐AC02‐06CH11357, the use of credits from the NIH Cloud Credits Model Pilot, a component of the NIH Big Data to Knowledge (BD2K) program, and the compute resources and assistance of the UW‐Madison Center for High Throughput Computing (CHTC) in the Department of Computer Sciences. The CHTC is supported by UW‐Madison, the Advanced Computing Initiative, the Wisconsin Alumni Research Foundation, the Wisconsin Institutes for Discovery and the National Science Foundation and is an active member of the Open Science Grid.</p>
  </ack>
  <ref-list id="jbio201960050-bibl-0001" content-type="cited-references">
    <title>REFERENCES</title>
    <ref id="jbio201960050-bib-0001">
      <label>1</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0001"><string-name><given-names>E. L.</given-names><surname>Pearce</surname></string-name>, <source xml:lang="en">Curr. Opin. Immunol.</source><year>2010</year>, <volume>22</volume>, <fpage>314</fpage><pub-id pub-id-type="doi">10.1016/j.coi.2010.01.018</pub-id>.<pub-id pub-id-type="pmid">20189791</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0002">
      <label>2</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0002"><string-name><given-names>D. M.</given-names><surname>Pardoll</surname></string-name>, <source xml:lang="en">Nat. Rev. Cancer</source><year>2012</year>, <volume>12</volume>, <fpage>252</fpage><pub-id pub-id-type="doi">10.1038/nrc3239</pub-id>.<pub-id pub-id-type="pmid">22437870</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0003">
      <label>3</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0003"><string-name><given-names>N. P.</given-names><surname>Restifo</surname></string-name>, <string-name><given-names>M. E.</given-names><surname>Dudley</surname></string-name>, <string-name><given-names>S. A.</given-names><surname>Rosenberg</surname></string-name>, <source xml:lang="en">Nat. Rev. Immunol.</source><year>2012</year>, <volume>12</volume>, <fpage>269</fpage><pub-id pub-id-type="doi">10.1038/nri3191</pub-id>.<pub-id pub-id-type="pmid">22437939</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0004">
      <label>4</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0004"><string-name><given-names>N.</given-names><surname>Marek‐Trzonkowska</surname></string-name>, <string-name><given-names>M.</given-names><surname>Myśliwiec</surname></string-name>, <string-name><given-names>A.</given-names><surname>Dobyszuk</surname></string-name>, <string-name><given-names>M.</given-names><surname>Grabowska</surname></string-name>, <string-name><given-names>I.</given-names><surname>Techmańska</surname></string-name>, <string-name><given-names>J.</given-names><surname>Juścińska</surname></string-name>, <string-name><given-names>M. A.</given-names><surname>Wujtewicz</surname></string-name>, <string-name><given-names>P.</given-names><surname>Witkowski</surname></string-name>, <string-name><given-names>W.</given-names><surname>Młynarski</surname></string-name>, <string-name><given-names>A.</given-names><surname>Balcerska</surname></string-name>, <string-name><given-names>J.</given-names><surname>Myśliwska</surname></string-name>, <string-name><given-names>P.</given-names><surname>Trzonkowski</surname></string-name>, <source xml:lang="en">Diabetes Care</source><year>2012</year>, <volume>35</volume>, <fpage>1817</fpage><pub-id pub-id-type="doi">10.2337/dc12-0038</pub-id>.<pub-id pub-id-type="pmid">22723342</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0005">
      <label>5</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0005"><string-name><given-names>M.</given-names><surname>Cazaux</surname></string-name>, <string-name><given-names>C. L.</given-names><surname>Grandjean</surname></string-name>, <string-name><given-names>F.</given-names><surname>Lemaître</surname></string-name>, <string-name><given-names>Z.</given-names><surname>Garcia</surname></string-name>, <string-name><given-names>R. J.</given-names><surname>Beck</surname></string-name>, <string-name><given-names>I.</given-names><surname>Milo</surname></string-name>, <string-name><given-names>J.</given-names><surname>Postat</surname></string-name>, <string-name><given-names>J. B.</given-names><surname>Beltman</surname></string-name>, <string-name><given-names>E. J.</given-names><surname>Cheadle</surname></string-name>, <string-name><given-names>P.</given-names><surname>Bousso</surname></string-name>, <source xml:lang="en">J. Exp. Med.</source><year>2019</year>, <volume>216</volume>, <fpage>1038</fpage><pub-id pub-id-type="doi">10.1084/jem.20182375</pub-id>.<pub-id pub-id-type="pmid">30936262</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0006">
      <label>6</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0006"><string-name><given-names>A.</given-names><surname>Walsh</surname></string-name>, <string-name><given-names>K.</given-names><surname>Mueller</surname></string-name>, <string-name><given-names>I.</given-names><surname>Jones</surname></string-name>, <string-name><given-names>C. M.</given-names><surname>Walsh</surname></string-name>, <string-name><given-names>N.</given-names><surname>Piscopo</surname></string-name>, <string-name><given-names>N. N.</given-names><surname>Niemi</surname></string-name>, <string-name><given-names>D. J.</given-names><surname>Pagliarini</surname></string-name>, <string-name><given-names>K.</given-names><surname>Saha</surname></string-name>, <string-name><given-names>M. C.</given-names><surname>Skala</surname></string-name>, <source xml:lang="en">bioRxiv</source><year>2019</year>, <fpage>536813</fpage><pub-id pub-id-type="doi">10.1101/536813</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0007">
      <label>7</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0007"><string-name><given-names>J. M.</given-names><surname>Szulczewski</surname></string-name>, <string-name><given-names>D. R.</given-names><surname>Inman</surname></string-name>, <string-name><given-names>D.</given-names><surname>Entenberg</surname></string-name>, <string-name><given-names>S. M.</given-names><surname>Ponik</surname></string-name>, <string-name><given-names>J.</given-names><surname>Aguirre‐Ghiso</surname></string-name>, <string-name><given-names>J.</given-names><surname>Castracane</surname></string-name>, <string-name><given-names>J.</given-names><surname>Condeelis</surname></string-name>, <string-name><given-names>K. W.</given-names><surname>Eliceiri</surname></string-name>, <string-name><given-names>P. J.</given-names><surname>Keely</surname></string-name>, <source xml:lang="en">Sci. Rep.</source><year>2016</year>, <volume>6</volume>, <fpage>25086</fpage><pub-id pub-id-type="doi">10.1038/srep25086</pub-id>.<pub-id pub-id-type="pmid">27220760</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0008">
      <label>8</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0008"><string-name><given-names>N.</given-names><surname>Pavillon</surname></string-name>, <string-name><given-names>A. J.</given-names><surname>Hobro</surname></string-name>, <string-name><given-names>S.</given-names><surname>Akira</surname></string-name>, <string-name><given-names>N. I.</given-names><surname>Smith</surname></string-name>, <source xml:lang="en">Proc. Natl. Acad. Sci.</source><year>2018</year>, <volume>115</volume>, <fpage>E2676</fpage><pub-id pub-id-type="doi">10.1073/pnas.1711872115</pub-id>.<pub-id pub-id-type="pmid">29511099</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0009">
      <label>9</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0009"><string-name><given-names>J.</given-names><surname>Yoon</surname></string-name>, <string-name><given-names>Y. J.</given-names><surname>Jo</surname></string-name>, <string-name><given-names>M. H.</given-names><surname>Kim</surname></string-name>, <string-name><given-names>K.</given-names><surname>Kim</surname></string-name>, <string-name><given-names>S. Y.</given-names><surname>Lee</surname></string-name>, <string-name><given-names>S. J.</given-names><surname>Kang</surname></string-name>, <string-name><given-names>Y. K.</given-names><surname>Park</surname></string-name>, <source xml:lang="en">Sci. Rep.</source><year>2017</year>, <volume>7</volume>, <fpage>6654</fpage><pub-id pub-id-type="doi">10.1038/s41598-017-06311-y</pub-id>.<pub-id pub-id-type="pmid">28751719</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0010">
      <label>10</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0010"><string-name><given-names>A.</given-names><surname>Gupta</surname></string-name>, <string-name><given-names>P. J.</given-names><surname>Harrison</surname></string-name>, <string-name><given-names>H.</given-names><surname>Wieslander</surname></string-name>, <string-name><given-names>N.</given-names><surname>Pielawski</surname></string-name>, <string-name><given-names>K.</given-names><surname>Kartasalo</surname></string-name>, <string-name><given-names>G.</given-names><surname>Partel</surname></string-name>, <string-name><given-names>L.</given-names><surname>Solorzano</surname></string-name>, <string-name><given-names>A.</given-names><surname>Suveer</surname></string-name>, <string-name><given-names>A. H.</given-names><surname>Klemm</surname></string-name>, <string-name><given-names>O.</given-names><surname>Spjuth</surname></string-name>, <string-name><given-names>I. M.</given-names><surname>Sintorn</surname></string-name>, <string-name><given-names>C.</given-names><surname>Wählby</surname></string-name>, <source xml:lang="en">Cytometry A</source><year>2019</year>, <volume>95</volume>, <fpage>366</fpage><pub-id pub-id-type="doi">10.1002/cyto.a.23701</pub-id>.<pub-id pub-id-type="pmid">30565841</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0011">
      <label>11</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0011"><string-name><given-names>M.</given-names><surname>Doan</surname></string-name>, <string-name><given-names>A. E.</given-names><surname>Carpenter</surname></string-name>, <source xml:lang="en">Nat. Mater.</source><year>2019</year>, <volume>18</volume>, <fpage>414</fpage><pub-id pub-id-type="doi">10.1038/s41563-019-0339-y</pub-id>.<pub-id pub-id-type="pmid">31000804</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0012">
      <label>12</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0012"><string-name><given-names>E.</given-names><surname>Moen</surname></string-name>, <string-name><given-names>D.</given-names><surname>Bannon</surname></string-name>, <string-name><given-names>T.</given-names><surname>Kudo</surname></string-name>, <string-name><given-names>W.</given-names><surname>Graf</surname></string-name>, <string-name><given-names>M.</given-names><surname>Covert</surname></string-name>, <string-name><given-names>D.</given-names><surname>Van Valen</surname></string-name>, <source xml:lang="en">Nat. Methods</source><year>2019</year>, <volume>1</volume><pub-id pub-id-type="doi">10.1038/s41592-019-0403-1</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0013">
      <label>13</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0013"><string-name><given-names>W. J.</given-names><surname>Godinez</surname></string-name>, <string-name><given-names>I.</given-names><surname>Hossain</surname></string-name>, <string-name><given-names>S. E.</given-names><surname>Lazic</surname></string-name>, <string-name><given-names>J. W.</given-names><surname>Davies</surname></string-name>, <string-name><given-names>X.</given-names><surname>Zhang</surname></string-name>, <source xml:lang="en">Bioinformatics</source><year>2017</year>, <volume>33</volume>, <fpage>2010</fpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btx069</pub-id>.<pub-id pub-id-type="pmid">28203779</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0014">
      <label>14</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0014"><string-name><given-names>O.</given-names><surname>Dürr</surname></string-name>, <string-name><given-names>B.</given-names><surname>Sick</surname></string-name>, <source xml:lang="en">J. Biomol. Screen.</source><year>2016</year>, <volume>21</volume>, <fpage>998</fpage><pub-id pub-id-type="doi">10.1177/1087057116631284</pub-id>.<pub-id pub-id-type="pmid">26950929</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0015">
      <label>15</label>
      <mixed-citation publication-type="book" id="jbio201960050-cit-0015"><string-name><given-names>O.</given-names><surname>Ronneberger</surname></string-name>, <string-name><given-names>P.</given-names><surname>Fischer</surname></string-name>, <string-name><given-names>T.</given-names><surname>Brox</surname></string-name>, <chapter-title>U‐Net: Convolutional Networks for Biomedical Image Segmentation</chapter-title> in <source xml:lang="en">Medical Image Computing and Computer‐Assisted Intervention – MICCAI 2015, vol. 9351 of Lecture Notes in Computer Science</source> (Eds: <person-group person-group-type="editor"><name name-style="western"><surname>Navab</surname><given-names>N.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Hornegger</surname><given-names>J.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Wells</surname><given-names>W. M.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Frangi</surname><given-names>A. F.</given-names></name></person-group>), <publisher-name>Springer International Publishing</publisher-name>, <publisher-loc>Cham, Switzerland</publisher-loc>
<year>2015</year>, p. <fpage>234</fpage>
<pub-id pub-id-type="doi">10.1007/978-3-319-24574-4_28</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0016">
      <label>16</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0016"><string-name><given-names>D.</given-names><surname>Bannon</surname></string-name>, <string-name><given-names>E.</given-names><surname>Moen</surname></string-name>, <string-name><given-names>M.</given-names><surname>Schwartz</surname></string-name>, <string-name><given-names>E.</given-names><surname>Borba</surname></string-name>, <string-name><given-names>S.</given-names><surname>Cui</surname></string-name>, <string-name><given-names>K.</given-names><surname>Huang</surname></string-name>, <string-name><given-names>I.</given-names><surname>Camplisson</surname></string-name>, <string-name><given-names>N.</given-names><surname>Koe</surname></string-name>, <string-name><given-names>D.</given-names><surname>Kyme</surname></string-name>, <string-name><given-names>T.</given-names><surname>Kudo</surname></string-name>, <string-name><given-names>B.</given-names><surname>Chang</surname></string-name>, <string-name><given-names>E.</given-names><surname>Pao</surname></string-name>, <string-name><given-names>E.</given-names><surname>Osterman</surname></string-name>, <string-name><given-names>W.</given-names><surname>Graf</surname></string-name>, <string-name><given-names>D.</given-names><surname>Van Valen</surname></string-name>, <source xml:lang="en">bioRxiv</source><year>2018</year>, <fpage>505032</fpage><pub-id pub-id-type="doi">10.1101/505032</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0017">
      <label>17</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0017"><string-name><given-names>M.</given-names><surname>Weigert</surname></string-name>, <string-name><given-names>U.</given-names><surname>Schmidt</surname></string-name>, <string-name><given-names>T.</given-names><surname>Boothe</surname></string-name>, <string-name><given-names>A.</given-names><surname>Müller</surname></string-name>, <string-name><given-names>A.</given-names><surname>Dibrov</surname></string-name>, <string-name><given-names>A.</given-names><surname>Jain</surname></string-name>, <string-name><given-names>B.</given-names><surname>Wilhelm</surname></string-name>, <string-name><given-names>D.</given-names><surname>Schmidt</surname></string-name>, <string-name><given-names>C.</given-names><surname>Broaddus</surname></string-name>, <string-name><given-names>S.</given-names><surname>Culley</surname></string-name>, <string-name><given-names>M.</given-names><surname>Rocha‐Martins</surname></string-name>, <string-name><given-names>F.</given-names><surname>Segovia‐Miranda</surname></string-name>, <string-name><given-names>C.</given-names><surname>Norden</surname></string-name>, <string-name><given-names>R.</given-names><surname>Henriques</surname></string-name>, <string-name><given-names>M.</given-names><surname>Zerial</surname></string-name>, <string-name><given-names>M.</given-names><surname>Solimena</surname></string-name>, <string-name><given-names>J.</given-names><surname>Rink</surname></string-name>, <string-name><given-names>P.</given-names><surname>Tomancak</surname></string-name>, <string-name><given-names>L.</given-names><surname>Royer</surname></string-name>, <string-name><given-names>F.</given-names><surname>Jug</surname></string-name>, <string-name><given-names>E. W.</given-names><surname>Myers</surname></string-name>, <source xml:lang="en">Nat. Methods</source><year>2018</year>, <volume>15</volume>, <fpage>1090</fpage><pub-id pub-id-type="doi">10.1038/s41592-018-0216-7</pub-id>.<pub-id pub-id-type="pmid">30478326</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0018">
      <label>18</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0018"><string-name><given-names>T.</given-names><surname>Pärnamaa</surname></string-name>, <string-name><given-names>L.</given-names><surname>Parts</surname></string-name>, <source xml:lang="en">G3: Genes, Genomes, Genetics</source><year>2017</year>, <volume>7</volume>, <fpage>1385</fpage><pub-id pub-id-type="doi">10.1534/g3.116.033654</pub-id>.<pub-id pub-id-type="pmid">28391243</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0019">
      <label>19</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0019"><string-name><given-names>O. Z.</given-names><surname>Kraus</surname></string-name>, <string-name><given-names>J. L.</given-names><surname>Ba</surname></string-name>, <string-name><given-names>B. J.</given-names><surname>Frey</surname></string-name>, <source xml:lang="en">Bioinformatics</source><year>2016</year>, <volume>32</volume>, <fpage>i52</fpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btw252</pub-id>.<pub-id pub-id-type="pmid">27307644</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0020">
      <label>20</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0020"><string-name><given-names>F.</given-names><surname>Buggenthin</surname></string-name>, <string-name><given-names>F.</given-names><surname>Buettner</surname></string-name>, <string-name><given-names>P. S.</given-names><surname>Hoppe</surname></string-name>, <string-name><given-names>M.</given-names><surname>Endele</surname></string-name>, <string-name><given-names>M.</given-names><surname>Kroiss</surname></string-name>, <string-name><given-names>M.</given-names><surname>Strasser</surname></string-name>, <string-name><given-names>M.</given-names><surname>Schwarzfischer</surname></string-name>, <string-name><given-names>D.</given-names><surname>Loeffler</surname></string-name>, <string-name><given-names>K. D.</given-names><surname>Kokkaliaris</surname></string-name>, <string-name><given-names>O.</given-names><surname>Hilsenbeck</surname></string-name>, <string-name><given-names>T.</given-names><surname>Schroeder</surname></string-name>, <string-name><given-names>F. J.</given-names><surname>Theis</surname></string-name>, <string-name><given-names>C.</given-names><surname>Marr</surname></string-name>, <source xml:lang="en">Nat. Methods</source><year>2017</year>, <volume>14</volume>, <fpage>403</fpage><pub-id pub-id-type="doi">10.1038/nmeth.4182</pub-id>.<pub-id pub-id-type="pmid">28218899</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0021">
      <label>21</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0021"><string-name><given-names>M.</given-names><surname>Hofmarcher</surname></string-name>, <string-name><given-names>E.</given-names><surname>Rumetshofer</surname></string-name>, <string-name><given-names>D.‐A.</given-names><surname>Clevert</surname></string-name>, <string-name><given-names>S.</given-names><surname>Hochreiter</surname></string-name>, <string-name><given-names>G.</given-names><surname>Klambauer</surname></string-name>, <source xml:lang="en">J. Chem. Inf. Model.</source><year>2019</year>, <volume>59</volume>, <fpage>1163</fpage><pub-id pub-id-type="doi">10.1021/acs.jcim.8b00670</pub-id>.<pub-id pub-id-type="pmid">30840449</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0022">
      <label>22</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0022"><string-name><given-names>S. H.</given-names><surname>Karandikar</surname></string-name>, <string-name><given-names>C.</given-names><surname>Zhang</surname></string-name>, <string-name><given-names>A.</given-names><surname>Meiyappan</surname></string-name>, <string-name><given-names>I.</given-names><surname>Barman</surname></string-name>, <string-name><given-names>C.</given-names><surname>Finck</surname></string-name>, <string-name><given-names>P. K.</given-names><surname>Srivastava</surname></string-name>, <string-name><given-names>R.</given-names><surname>Pandey</surname></string-name>, <source xml:lang="en">Anal. Chem.</source><year>2019</year>, <volume>91</volume>, <fpage>3405</fpage><pub-id pub-id-type="doi">10.1021/acs.analchem.8b04895</pub-id>.<pub-id pub-id-type="pmid">30741527</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0023">
      <label>23</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0023"><string-name><given-names>P.</given-names><surname>Eulenberg</surname></string-name>, <string-name><given-names>N.</given-names><surname>Köhler</surname></string-name>, <string-name><given-names>T.</given-names><surname>Blasi</surname></string-name>, <string-name><given-names>A.</given-names><surname>Filby</surname></string-name>, <string-name><given-names>A. E.</given-names><surname>Carpenter</surname></string-name>, <string-name><given-names>P.</given-names><surname>Rees</surname></string-name>, <string-name><given-names>F. J.</given-names><surname>Theis</surname></string-name>, <string-name><given-names>F. A.</given-names><surname>Wolf</surname></string-name>, <source xml:lang="en">Nat. Commun.</source><year>2017</year>, <volume>8</volume>, <fpage>463</fpage><pub-id pub-id-type="doi">10.1038/s41467-017-00623-3</pub-id>.<pub-id pub-id-type="pmid">28878212</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0024">
      <label>24</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0024"><string-name><given-names>N.</given-names><surname>Nitta</surname></string-name>, <string-name><given-names>T.</given-names><surname>Sugimura</surname></string-name>, <string-name><given-names>A.</given-names><surname>Isozaki</surname></string-name>, <string-name><given-names>H.</given-names><surname>Mikami</surname></string-name>, <string-name><given-names>K.</given-names><surname>Hiraki</surname></string-name>, <string-name><given-names>S.</given-names><surname>Sakuma</surname></string-name>, <string-name><given-names>T.</given-names><surname>Iino</surname></string-name>, <string-name><given-names>F.</given-names><surname>Arai</surname></string-name>, <string-name><given-names>T.</given-names><surname>Endo</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Fujiwaki</surname></string-name>, <string-name><given-names>H.</given-names><surname>Fukuzawa</surname></string-name>, <string-name><given-names>M.</given-names><surname>Hase</surname></string-name>, <string-name><given-names>T.</given-names><surname>Hayakawa</surname></string-name>, <string-name><given-names>K.</given-names><surname>Hiramatsu</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Hoshino</surname></string-name>, <string-name><given-names>M.</given-names><surname>Inaba</surname></string-name>, <string-name><given-names>T.</given-names><surname>Ito</surname></string-name>, <string-name><given-names>H.</given-names><surname>Karakawa</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Kasai</surname></string-name>, <string-name><given-names>K.</given-names><surname>Koizumi</surname></string-name>, <string-name><given-names>S. W.</given-names><surname>Lee</surname></string-name>, <string-name><given-names>C.</given-names><surname>Lei</surname></string-name>, <string-name><given-names>M.</given-names><surname>Li</surname></string-name>, <string-name><given-names>T.</given-names><surname>Maeno</surname></string-name>, <string-name><given-names>S.</given-names><surname>Matsusaka</surname></string-name>, <string-name><given-names>D.</given-names><surname>Murakami</surname></string-name>, <string-name><given-names>A.</given-names><surname>Nakagawa</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Oguchi</surname></string-name>, <string-name><given-names>M.</given-names><surname>Oikawa</surname></string-name>, <string-name><given-names>T.</given-names><surname>Ota</surname></string-name>, <string-name><given-names>K.</given-names><surname>Shiba</surname></string-name>, <string-name><given-names>H.</given-names><surname>Shintaku</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Shirasaki</surname></string-name>, <string-name><given-names>K.</given-names><surname>Suga</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Suzuki</surname></string-name>, <string-name><given-names>N.</given-names><surname>Suzuki</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Tanaka</surname></string-name>, <string-name><given-names>H.</given-names><surname>Tezuka</surname></string-name>, <string-name><given-names>C.</given-names><surname>Toyokawa</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Yalikun</surname></string-name>, <string-name><given-names>M.</given-names><surname>Yamada</surname></string-name>, <string-name><given-names>M.</given-names><surname>Yamagishi</surname></string-name>, <string-name><given-names>T.</given-names><surname>Yamano</surname></string-name>, <string-name><given-names>A.</given-names><surname>Yasumoto</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Yatomi</surname></string-name>, <string-name><given-names>M.</given-names><surname>Yazawa</surname></string-name>, <string-name><given-names>D.</given-names><surname>Di Carlo</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Hosokawa</surname></string-name>, <string-name><given-names>S.</given-names><surname>Uemura</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Ozeki</surname></string-name>, <string-name><given-names>K.</given-names><surname>Goda</surname></string-name>, <source xml:lang="en">Cell</source><year>2018</year>, <volume>175</volume>, <fpage>266</fpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.08.028</pub-id>.<pub-id pub-id-type="pmid">30166209</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0025">
      <label>25</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0025"><string-name><given-names>C. L.</given-names><surname>Chen</surname></string-name>, <string-name><given-names>A.</given-names><surname>Mahjoubfar</surname></string-name>, <string-name><given-names>L. C.</given-names><surname>Tai</surname></string-name>, <string-name><given-names>I. K.</given-names><surname>Blaby</surname></string-name>, <string-name><given-names>A.</given-names><surname>Huang</surname></string-name>, <string-name><given-names>K. R.</given-names><surname>Niazi</surname></string-name>, <string-name><given-names>B.</given-names><surname>Jalali</surname></string-name>, <source xml:lang="en">Sci. Rep.</source><year>2016</year>, <volume>6</volume>, <fpage>21471</fpage><pub-id pub-id-type="doi">10.1038/srep21471</pub-id>.<pub-id pub-id-type="pmid">26975219</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0026">
      <label>26</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0026"><string-name><given-names>M. D.</given-names><surname>Abràmoff</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Lou</surname></string-name>, <string-name><given-names>A.</given-names><surname>Erginay</surname></string-name>, <string-name><given-names>W.</given-names><surname>Clarida</surname></string-name>, <string-name><given-names>R.</given-names><surname>Amelon</surname></string-name>, <string-name><given-names>J. C.</given-names><surname>Folk</surname></string-name>, <string-name><given-names>M.</given-names><surname>Niemeijer</surname></string-name>, <source xml:lang="en">Investigative Opthalmology &amp; Visual Science</source><year>2016</year>, <volume>57</volume>, <fpage>5200</fpage><pub-id pub-id-type="doi">10.1167/iovs.16-19964</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0027">
      <label>27</label>
      <mixed-citation publication-type="miscellaneous" id="jbio201960050-cit-0027"><string-name><given-names>X.</given-names><surname>Wang</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Peng</surname></string-name>, <string-name><given-names>L.</given-names><surname>Lu</surname></string-name>, <string-name><given-names>Z.</given-names><surname>Lu</surname></string-name>, <string-name><given-names>M.</given-names><surname>Bagheri</surname></string-name>, <string-name><given-names>R. M.</given-names><surname>Summers</surname></string-name>, ChestX‐Ray8: Hospital‐Scale Chest X‐Ray Database and Benchmarks on Weakly‐Supervised Classification and Localization of Common Thorax Diseases. In 2017 <italic>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</italic>, 3462–3471 (IEEE, Honolulu, HI, 2017). <pub-id pub-id-type="doi">10.1109/CVPR.2017.369</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0028">
      <label>28</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0028"><string-name><given-names>M.</given-names><surname>Raghu</surname></string-name>, <string-name><given-names>C.</given-names><surname>Zhang</surname></string-name>, <string-name><given-names>J.</given-names><surname>Kleinberg</surname></string-name>, <string-name><given-names>S.</given-names><surname>Bengio</surname></string-name>, <source xml:lang="en">arXiv</source><year>2019</year>, <fpage>1902.07208</fpage>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0029">
      <label>29</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0029"><string-name><given-names>T.</given-names><surname>Ching</surname></string-name>, <string-name><given-names>D. S.</given-names><surname>Himmelstein</surname></string-name>, <string-name><given-names>B. K.</given-names><surname>Beaulieu‐Jones</surname></string-name>, <string-name><given-names>A. A.</given-names><surname>Kalinin</surname></string-name>, <string-name><given-names>B. T.</given-names><surname>Do</surname></string-name>, <string-name><given-names>G. P.</given-names><surname>Way</surname></string-name>, <string-name><given-names>E.</given-names><surname>Ferrero</surname></string-name>, <string-name><given-names>P. M.</given-names><surname>Agapow</surname></string-name>, <string-name><given-names>M.</given-names><surname>Zietz</surname></string-name>, <string-name><given-names>M. M.</given-names><surname>Hoffman</surname></string-name>, <string-name><given-names>W.</given-names><surname>Xie</surname></string-name>, <string-name><given-names>G. L.</given-names><surname>Rosen</surname></string-name>, <string-name><given-names>B. J.</given-names><surname>Lengerich</surname></string-name>, <string-name><given-names>J.</given-names><surname>Israeli</surname></string-name>, <string-name><given-names>J.</given-names><surname>Lanchantin</surname></string-name>, <string-name><given-names>S.</given-names><surname>Woloszynek</surname></string-name>, <string-name><given-names>A. E.</given-names><surname>Carpenter</surname></string-name>, <string-name><given-names>A.</given-names><surname>Shrikumar</surname></string-name>, <string-name><given-names>J.</given-names><surname>Xu</surname></string-name>, <string-name><given-names>E. M.</given-names><surname>Cofer</surname></string-name>, <string-name><given-names>C. A.</given-names><surname>Lavender</surname></string-name>, <string-name><given-names>S. C.</given-names><surname>Turaga</surname></string-name>, <string-name><given-names>A. M.</given-names><surname>Alexandari</surname></string-name>, <string-name><given-names>Z.</given-names><surname>Lu</surname></string-name>, <string-name><given-names>D. J.</given-names><surname>Harris</surname></string-name>, <string-name><given-names>D.</given-names><surname>DeCaprio</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Qi</surname></string-name>, <string-name><given-names>A.</given-names><surname>Kundaje</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Peng</surname></string-name>, <string-name><given-names>L. K.</given-names><surname>Wiley</surname></string-name>, <string-name><given-names>M. H. S.</given-names><surname>Segler</surname></string-name>, <string-name><given-names>S. M.</given-names><surname>Boca</surname></string-name>, <string-name><given-names>S. J.</given-names><surname>Swamidass</surname></string-name>, <string-name><given-names>A.</given-names><surname>Huang</surname></string-name>, <string-name><given-names>A.</given-names><surname>Gitter</surname></string-name>, <string-name><given-names>C. S.</given-names><surname>Greene</surname></string-name>, <source xml:lang="en">Journal of The Royal Society Interface</source><year>2018</year>, <volume>15</volume>, <elocation-id>20170387</elocation-id><pub-id pub-id-type="doi">10.1098/rsif.2017.0387</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0030">
      <label>30</label>
      <mixed-citation publication-type="book" id="jbio201960050-cit-0030"><string-name><given-names>M.</given-names><surname>Habibzadeh Motlagh</surname></string-name>, <string-name><given-names>M.</given-names><surname>Jannesari</surname></string-name>, <string-name><given-names>Z.</given-names><surname>Rezaei</surname></string-name>, <string-name><given-names>M.</given-names><surname>Totonchi</surname></string-name>, <string-name><given-names>H.</given-names><surname>Baharvand</surname></string-name>, <chapter-title>Automatic white blood cell classification using pre‐trained deep learning models: ResNet and Inception</chapter-title> in <source xml:lang="en">Tenth International Conference on Machine Vision (ICMV 2017), 105</source> (Eds: <person-group person-group-type="editor"><name name-style="western"><surname>Zhou</surname><given-names>J.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Radeva</surname><given-names>P.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Nikolaev</surname><given-names>D.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Verikas</surname><given-names>A.</given-names></name></person-group>), <publisher-name>SPIE</publisher-name>, <publisher-loc>Vienna, Austria</publisher-loc>
<year>2018</year>
<pub-id pub-id-type="doi">10.1117/12.2311282</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0031">
      <label>31</label>
      <mixed-citation publication-type="miscellaneous" id="jbio201960050-cit-0031"><string-name><given-names>H. T. H.</given-names><surname>Phan</surname></string-name>, <string-name><given-names>A.</given-names><surname>Kumar</surname></string-name>, <string-name><given-names>J.</given-names><surname>Kim</surname></string-name>, <string-name><given-names>D.</given-names><surname>Feng</surname></string-name>. Transfer learning of a convolutional neural network for HEp‐2 cell image classification. In 2016 <italic>IEEE 13th International Symposium on Biomedical Imaging (ISBI)</italic>, 1208–1211 (IEEE, Prague, Czech Republic, 2016). <pub-id pub-id-type="doi">10.1109/ISBI.2016.7493483</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0032">
      <label>32</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0032"><string-name><given-names>A.</given-names><surname>Kensert</surname></string-name>, <string-name><given-names>P. J.</given-names><surname>Harrison</surname></string-name>, <string-name><given-names>O.</given-names><surname>Spjuth</surname></string-name>, <source xml:lang="en">SLAS DISCOVERY: Advancing Life Sciences R&amp;D</source><year>2019</year>, <volume>24</volume>, <fpage>466</fpage><pub-id pub-id-type="doi">10.1177/2472555218818756</pub-id>.<pub-id pub-id-type="pmid">30641024</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0033">
      <label>33</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0033"><string-name><given-names>C.</given-names><surname>Kandaswamy</surname></string-name>, <string-name><given-names>L. M.</given-names><surname>Silva</surname></string-name>, <string-name><given-names>L. A.</given-names><surname>Alexandre</surname></string-name>, <string-name><given-names>J. M.</given-names><surname>Santos</surname></string-name>, <source xml:lang="en">J. Biomol. Screen.</source><year>2016</year>, <volume>21</volume>, <fpage>252</fpage><pub-id pub-id-type="doi">10.1177/1087057115623451</pub-id>.<pub-id pub-id-type="pmid">26746583</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0034">
      <label>34</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0034"><string-name><given-names>N.</given-names><surname>Pawlowski</surname></string-name>, <string-name><given-names>J. C.</given-names><surname>Caicedo</surname></string-name>, <string-name><given-names>S.</given-names><surname>Singh</surname></string-name>, <string-name><given-names>A. E.</given-names><surname>Carpenter</surname></string-name>, <string-name><given-names>A.</given-names><surname>Storkey</surname></string-name>, <source xml:lang="en">bioRxiv</source><year>2016</year>, <fpage>085118</fpage><pub-id pub-id-type="doi">10.1101/085118</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0035">
      <label>35</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0035"><string-name><given-names>A. E.</given-names><surname>Carpenter</surname></string-name>, <string-name><given-names>T. R.</given-names><surname>Jones</surname></string-name>, <string-name><given-names>M. R.</given-names><surname>Lamprecht</surname></string-name>, <string-name><given-names>C.</given-names><surname>Clarke</surname></string-name>, <string-name><given-names>I. H.</given-names><surname>Kang</surname></string-name>, <string-name><given-names>O.</given-names><surname>Friman</surname></string-name>, <string-name><given-names>D. A.</given-names><surname>Guertin</surname></string-name>, <string-name><given-names>J. H.</given-names><surname>Chang</surname></string-name>, <string-name><given-names>R. A.</given-names><surname>Lindquist</surname></string-name>, <string-name><given-names>J.</given-names><surname>Moffat</surname></string-name>, <string-name><given-names>P.</given-names><surname>Golland</surname></string-name>, <string-name><given-names>D. M.</given-names><surname>Sabatini</surname></string-name>, <source xml:lang="en">Genome Biol.</source><year>2006</year>, <volume>7</volume>, <fpage>R100</fpage><pub-id pub-id-type="doi">10.1186/gb-2006-7-10-r100</pub-id>.<pub-id pub-id-type="pmid">17076895</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0036">
      <label>36</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0036"><string-name><given-names>Y.</given-names><surname>Lecun</surname></string-name>, <string-name><given-names>L.</given-names><surname>Bottou</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Bengio</surname></string-name>, <string-name><given-names>P.</given-names><surname>Haffner</surname></string-name>, <source xml:lang="en">Proc. IEEE</source><year>1998</year>, <volume>86</volume>, <fpage>2278</fpage><pub-id pub-id-type="doi">10.1109/5.726791</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0037">
      <label>37</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0037"><string-name><given-names>J.</given-names><surname>Simm</surname></string-name>, <string-name><given-names>G.</given-names><surname>Klambauer</surname></string-name>, <string-name><given-names>A.</given-names><surname>Arany</surname></string-name>, <string-name><given-names>M.</given-names><surname>Steijaert</surname></string-name>, <string-name><given-names>J. K.</given-names><surname>Wegner</surname></string-name>, <string-name><given-names>E.</given-names><surname>Gustin</surname></string-name>, <string-name><given-names>V.</given-names><surname>Chupakhin</surname></string-name>, <string-name><given-names>Y. T.</given-names><surname>Chong</surname></string-name>, <string-name><given-names>J.</given-names><surname>Vialard</surname></string-name>, <string-name><given-names>P.</given-names><surname>Buijnsters</surname></string-name>, <string-name><given-names>I.</given-names><surname>Velter</surname></string-name>, <string-name><given-names>A.</given-names><surname>Vapirev</surname></string-name>, <string-name><given-names>S.</given-names><surname>Singh</surname></string-name>, <string-name><given-names>A. E.</given-names><surname>Carpenter</surname></string-name>, <string-name><given-names>R.</given-names><surname>Wuyts</surname></string-name>, <string-name><given-names>S.</given-names><surname>Hochreiter</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Moreau</surname></string-name>, <string-name><given-names>H.</given-names><surname>Ceulemans</surname></string-name>, <source xml:lang="en">Cell Chem. Biol.</source><year>2018</year>, <volume>25</volume>, <fpage>611</fpage><pub-id pub-id-type="doi">10.1016/j.chembiol.2018.01.015</pub-id>.<pub-id pub-id-type="pmid">29503208</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0038">
      <label>38</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0038"><string-name><given-names>M.</given-names><surname>Nassar</surname></string-name>, <string-name><given-names>M.</given-names><surname>Doan</surname></string-name>, <string-name><given-names>A.</given-names><surname>Filby</surname></string-name>, <string-name><given-names>O.</given-names><surname>Wolkenhauer</surname></string-name>, <string-name><given-names>D. K.</given-names><surname>Fogg</surname></string-name>, <string-name><given-names>J.</given-names><surname>Piasecka</surname></string-name>, <string-name><given-names>C. A.</given-names><surname>Thornton</surname></string-name>, <string-name><given-names>A. E.</given-names><surname>Carpenter</surname></string-name>, <string-name><given-names>H. D.</given-names><surname>Summers</surname></string-name>, <string-name><given-names>P.</given-names><surname>Rees</surname></string-name>, <string-name><given-names>H.</given-names><surname>Hennig</surname></string-name>, <source xml:lang="en">Cytometry A</source><year>2019</year>, <volume>95</volume>, <fpage>836</fpage><pub-id pub-id-type="doi">10.1002/cyto.a.23794</pub-id>.<pub-id pub-id-type="pmid">31081599</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0039">
      <label>39</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0039"><string-name><given-names>J.</given-names><surname>Lever</surname></string-name>, <string-name><given-names>M.</given-names><surname>Krzywinski</surname></string-name>, <string-name><given-names>N.</given-names><surname>Altman</surname></string-name>, <source xml:lang="en">Nat. Methods</source><year>2016</year>, <volume>13</volume>, <fpage>603</fpage><pub-id pub-id-type="doi">10.1038/nmeth.3945</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0040">
      <label>40</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0040"><string-name><given-names>C.</given-names><surname>Guo</surname></string-name>, <string-name><given-names>G.</given-names><surname>Pleiss</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Sun</surname></string-name>, <string-name><given-names>K. Q.</given-names><surname>Weinberger</surname></string-name>, <source xml:lang="en">arXiv</source><year>2017</year>, <fpage>1706.04599</fpage>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0041">
      <label>41</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0041"><string-name><given-names>L.</given-names><surname>McInnes</surname></string-name>, <string-name><given-names>J.</given-names><surname>Healy</surname></string-name>, <string-name><given-names>J.</given-names><surname>Melville</surname></string-name>, <source xml:lang="en">arXiv</source><year>2018</year>, <fpage>1802.03426</fpage>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0042">
      <label>42</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0042"><string-name><given-names>L. v. d.</given-names><surname>Maaten</surname></string-name>, <string-name><given-names>G.</given-names><surname>Hinton</surname></string-name>, <source xml:lang="en">J. Mach. Learn. Res.</source><year>2008</year>, <volume>9</volume>, <fpage>2579</fpage>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0043">
      <label>43</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0043"><string-name><given-names>K.</given-names><surname>Simonyan</surname></string-name>, <string-name><given-names>A.</given-names><surname>Vedaldi</surname></string-name>, <string-name><given-names>A.</given-names><surname>Zisserman</surname></string-name>, <source xml:lang="en">arXiv</source><year>2013</year>, <fpage>1312.6034</fpage>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0044">
      <label>44</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0044"><string-name><given-names>J. T.</given-names><surname>Springenberg</surname></string-name>, <string-name><given-names>A.</given-names><surname>Dosovitskiy</surname></string-name>, <string-name><given-names>T.</given-names><surname>Brox</surname></string-name>, <string-name><given-names>M.</given-names><surname>Riedmiller</surname></string-name>, <source xml:lang="en">arXiv</source><year>2014</year>, <fpage>1412.6806</fpage>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0045">
      <label>45</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0045"><string-name><given-names>N. A.</given-names><surname>Ramey</surname></string-name>, <string-name><given-names>C. Y.</given-names><surname>Park</surname></string-name>, <string-name><given-names>P. L.</given-names><surname>Gehlbach</surname></string-name>, <string-name><given-names>R. S.</given-names><surname>Chuck</surname></string-name>, <source xml:lang="en">Photochem. Photobiol.</source><year>2007</year>, <volume>83</volume>, <fpage>1325</fpage><pub-id pub-id-type="doi">10.1111/j.1751-1097.2007.00162.x</pub-id>.<pub-id pub-id-type="pmid">18028205</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0046">
      <label>46</label>
      <mixed-citation publication-type="book" id="jbio201960050-cit-0046"><string-name><given-names>J.</given-names><surname>Adebayo</surname></string-name>, <string-name><given-names>J.</given-names><surname>Gilmer</surname></string-name>, <string-name><given-names>M.</given-names><surname>Muelly</surname></string-name>, <string-name><given-names>I.</given-names><surname>Goodfellow</surname></string-name>, <string-name><given-names>M.</given-names><surname>Hardt</surname></string-name>, <string-name><given-names>B.</given-names><surname>Kim</surname></string-name>, <chapter-title>Sanity Checks for Saliency Maps</chapter-title> in <source xml:lang="en">Advances in Neural Information Processing Systems 31</source> (Eds: <person-group person-group-type="editor"><name name-style="western"><surname>Bengio</surname><given-names>S.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Wallach</surname><given-names>H.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Larochelle</surname><given-names>H.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Grauman</surname><given-names>K.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Cesa‐Bianchi</surname><given-names>N.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Garnett</surname><given-names>R.</given-names></name></person-group>), <publisher-name>Curran Associates</publisher-name>, <publisher-name>Inc.</publisher-name>, <publisher-loc>Montréal, Canada</publisher-loc>
<year>2018</year>, p. <fpage>9505</fpage>
<ext-link ext-link-type="uri" xlink:href="https://papers.nips.cc/book/advances-in-neural-information-processing-systems-31-2018">https://papers.nips.cc/book/advances-in-neural-information-processing-systems-31-2018</ext-link>
</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0047">
      <label>47</label>
      <mixed-citation publication-type="book" id="jbio201960050-cit-0047"><string-name><given-names>T.</given-names><surname>Kluyver</surname></string-name>, <string-name><given-names>B.</given-names><surname>Ragan‐Kelley</surname></string-name>, <string-name><given-names>F.</given-names><surname>Pérez</surname></string-name>, <string-name><given-names>B.</given-names><surname>Granger</surname></string-name>, <string-name><given-names>M.</given-names><surname>Bussonnier</surname></string-name>, <string-name><given-names>J.</given-names><surname>Frederic</surname></string-name>, <string-name><given-names>K.</given-names><surname>Kelley</surname></string-name>, <string-name><given-names>J.</given-names><surname>Hamrick</surname></string-name>, <string-name><given-names>J.</given-names><surname>Grout</surname></string-name>, <string-name><given-names>S.</given-names><surname>Corlay</surname></string-name>, <string-name><given-names>P.</given-names><surname>Ivanov</surname></string-name>, <string-name><given-names>D.</given-names><surname>Avila</surname></string-name>, <string-name><given-names>S.</given-names><surname>Abdalla</surname></string-name>, <string-name><given-names>C.</given-names><surname>Willing</surname></string-name>, Jupyter development team, <chapter-title>Jupyter Notebooks ‐ a publishing format for reproducible computational workflows</chapter-title> in <source xml:lang="en">Positioning and Power in Academic Publishing: Players, Agents and Agendas</source> (Eds: <person-group person-group-type="editor"><name name-style="western"><surname>Loizides</surname><given-names>F.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Scmidt</surname><given-names>B.</given-names></name></person-group>), <publisher-name>IOS Press</publisher-name>, <publisher-loc>Amsterdam, Netherlands</publisher-loc>
<year>2016</year>, p. <fpage>87</fpage>
<pub-id pub-id-type="doi">10.3233/978-1-61499-649-1-87</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0048">
      <label>48</label>
      <mixed-citation publication-type="miscellaneous" id="jbio201960050-cit-0048"><collab collab-type="authors">Project Jupyter, M. Bussonnier, J. Forde, J. Freeman, B. Granger, T. Head, C. Holdgraf, K. Kelley, G. Nalvarte, A. Osherof, M. Pacer, Y. Panda, F. Perez, B. Ragan‐Kelley, C. Willing</collab>
, Binder 2.0 ‐ Reproducible, interactive, sharable environments for science at scale. <italic>Proceedings of the 17th Python in Science Conference</italic> 113–120 (2018). <pub-id pub-id-type="doi">10.25080/Majora-4af1f417-011</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0049">
      <label>49</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0049"><string-name><given-names>E.</given-names><surname>Gavgiotaki</surname></string-name>, <string-name><given-names>G.</given-names><surname>Filippidis</surname></string-name>, <string-name><given-names>I.</given-names><surname>Zerva</surname></string-name>, <string-name><given-names>G.</given-names><surname>Kenanakis</surname></string-name>, <string-name><given-names>E.</given-names><surname>Archontakis</surname></string-name>, <string-name><given-names>S.</given-names><surname>Agelaki</surname></string-name>, <string-name><given-names>V.</given-names><surname>Georgoulias</surname></string-name>, <string-name><given-names>I.</given-names><surname>Athanassakis</surname></string-name>, <source xml:lang="en">J. Biophotonics</source><year>2019</year>, <volume>12</volume>, <elocation-id>e201800277</elocation-id><pub-id pub-id-type="doi">10.1002/jbio.201800277</pub-id>.<pub-id pub-id-type="pmid">30353667</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0050">
      <label>50</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0050"><string-name><given-names>T.</given-names><surname>Falk</surname></string-name>, <string-name><given-names>D.</given-names><surname>Mai</surname></string-name>, <string-name><given-names>R.</given-names><surname>Bensch</surname></string-name>, <string-name><given-names>Ö.</given-names><surname>Çiçek</surname></string-name>, <string-name><given-names>A.</given-names><surname>Abdulkadir</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Marrakchi</surname></string-name>, <string-name><given-names>A.</given-names><surname>Böhm</surname></string-name>, <string-name><given-names>J.</given-names><surname>Deubner</surname></string-name>, <string-name><given-names>Z.</given-names><surname>Jäckel</surname></string-name>, <string-name><given-names>K.</given-names><surname>Seiwald</surname></string-name>, <string-name><given-names>A.</given-names><surname>Dovzhenko</surname></string-name>, <string-name><given-names>O.</given-names><surname>Tietz</surname></string-name>, <string-name><given-names>C.</given-names><surname>Dal Bosco</surname></string-name>, <string-name><given-names>S.</given-names><surname>Walsh</surname></string-name>, <string-name><given-names>D.</given-names><surname>Saltukoglu</surname></string-name>, <string-name><given-names>T. L.</given-names><surname>Tay</surname></string-name>, <string-name><given-names>M.</given-names><surname>Prinz</surname></string-name>, <string-name><given-names>K.</given-names><surname>Palme</surname></string-name>, <string-name><given-names>M.</given-names><surname>Simons</surname></string-name>, <string-name><given-names>I.</given-names><surname>Diester</surname></string-name>, <string-name><given-names>T.</given-names><surname>Brox</surname></string-name>, <string-name><given-names>O.</given-names><surname>Ronneberger</surname></string-name>, <source xml:lang="en">Nat. Methods</source><year>2019</year>, <volume>16</volume>, <fpage>67</fpage><pub-id pub-id-type="doi">10.1038/s41592-018-0261-2</pub-id>.<pub-id pub-id-type="pmid">30559429</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0051">
      <label>51</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0051"><string-name><given-names>B. P.</given-names><surname>Yakimov</surname></string-name>, <string-name><given-names>M. A.</given-names><surname>Gogoleva</surname></string-name>, <string-name><given-names>A. N.</given-names><surname>Semenov</surname></string-name>, <string-name><given-names>S. A.</given-names><surname>Rodionov</surname></string-name>, <string-name><given-names>M. V.</given-names><surname>Novoselova</surname></string-name>, <string-name><given-names>A. V.</given-names><surname>Gayer</surname></string-name>, <string-name><given-names>A. V.</given-names><surname>Kovalev</surname></string-name>, <string-name><given-names>A. I.</given-names><surname>Bernakevich</surname></string-name>, <string-name><given-names>V. V.</given-names><surname>Fadeev</surname></string-name>, <string-name><given-names>A. G.</given-names><surname>Armaganov</surname></string-name>, <string-name><given-names>V. P.</given-names><surname>Drachev</surname></string-name>, <string-name><given-names>D. A.</given-names><surname>Gorin</surname></string-name>, <string-name><given-names>M. E.</given-names><surname>Darvin</surname></string-name>, <string-name><given-names>V. I.</given-names><surname>Shcheslavskiy</surname></string-name>, <string-name><given-names>G. S.</given-names><surname>Budylin</surname></string-name>, <string-name><given-names>A. V.</given-names><surname>Priezzhev</surname></string-name>, <string-name><given-names>E. A.</given-names><surname>Shirshin</surname></string-name>, <source xml:lang="en">Biomed. Opt. Express</source><year>2019</year>, <volume>10</volume>, <fpage>4220</fpage><pub-id pub-id-type="doi">10.1364/BOE.10.004220</pub-id>.<pub-id pub-id-type="pmid">31453006</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0052">
      <label>52</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0052"><string-name><given-names>Y. J.</given-names><surname>Heo</surname></string-name>, <string-name><given-names>D.</given-names><surname>Lee</surname></string-name>, <string-name><given-names>J.</given-names><surname>Kang</surname></string-name>, <string-name><given-names>K.</given-names><surname>Lee</surname></string-name>, <string-name><given-names>W. K.</given-names><surname>Chung</surname></string-name>, <source xml:lang="en">Sci. Rep.</source><year>2017</year>, <volume>7</volume>, <fpage>11651</fpage><pub-id pub-id-type="doi">10.1038/s41598-017-11534-0</pub-id>.<pub-id pub-id-type="pmid">28912565</pub-id></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0053">
      <label>53</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0053"><string-name><given-names>M.</given-names><surname>Lippeveld</surname></string-name>, <string-name><given-names>C.</given-names><surname>Knill</surname></string-name>, <string-name><given-names>E.</given-names><surname>Ladlow</surname></string-name>, <string-name><given-names>A.</given-names><surname>Fuller</surname></string-name>, <string-name><given-names>L. J.</given-names><surname>Michaelis</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Saeys</surname></string-name>, <string-name><given-names>A.</given-names><surname>Filby</surname></string-name>, <string-name><given-names>D.</given-names><surname>Peralta</surname></string-name>, <source xml:lang="en">bioRxiv</source><year>2019</year>, <fpage>680975</fpage><pub-id pub-id-type="doi">10.1101/680975</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0054">
      <label>54</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0054"><string-name><given-names>G.</given-names><surname>Bradski</surname></string-name>, <source xml:lang="en">Dr. Dobb's J. Soft. Tools</source><year>2000</year><ext-link ext-link-type="uri" xlink:href="https://github.com/opencv/opencv/wiki/CiteOpenCV">https://github.com/opencv/opencv/wiki/CiteOpenCV</ext-link></mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0055">
      <label>55</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0055"><string-name><given-names>S.</given-names><surname>Raschka</surname></string-name>, <source xml:lang="en">arXiv</source><year>2018</year>, <fpage>1811.12808</fpage>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0056">
      <label>56</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0056"><string-name><given-names>S.</given-names><surname>Varma</surname></string-name>, <string-name><given-names>R.</given-names><surname>Simon</surname></string-name>, <source xml:lang="en">BMC Bioinformat</source><year>2006</year>, <volume>7</volume>, <fpage>91</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-7-91</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0057">
      <label>57</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0057"><string-name><given-names>F.</given-names><surname>Pedregosa</surname></string-name>, <string-name><given-names>G.</given-names><surname>Varoquaux</surname></string-name>, <string-name><given-names>A.</given-names><surname>Gramfort</surname></string-name>, <string-name><given-names>V.</given-names><surname>Michel</surname></string-name>, <string-name><given-names>B.</given-names><surname>Thirion</surname></string-name>, <string-name><given-names>O.</given-names><surname>Grisel</surname></string-name>, <string-name><given-names>M.</given-names><surname>Blondel</surname></string-name>, <string-name><given-names>P.</given-names><surname>Prettenhofer</surname></string-name>, <string-name><given-names>R.</given-names><surname>Weiss</surname></string-name>, <string-name><given-names>V.</given-names><surname>Dubourg</surname></string-name>, <string-name><given-names>J.</given-names><surname>Vanderplas</surname></string-name>, <string-name><given-names>A.</given-names><surname>Passos</surname></string-name>, <string-name><given-names>D.</given-names><surname>Cournapeau</surname></string-name>, <string-name><given-names>M.</given-names><surname>Brucher</surname></string-name>, <string-name><given-names>M.</given-names><surname>Perrot</surname></string-name>, <string-name><given-names>É.</given-names><surname>Duchesnay</surname></string-name>. <source xml:lang="en">J. Mach. Learn. Res.</source><year>2011</year>, <volume>12</volume>, <fpage>2825</fpage>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0058">
      <label>58</label>
      <mixed-citation publication-type="book" id="jbio201960050-cit-0058"><collab collab-type="authors">F. Chollet</collab>
, <source xml:lang="en">Keras</source>
<year>2015</year>
<ext-link ext-link-type="uri" xlink:href="https://keras.io/">https://keras.io/</ext-link>
</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0059">
      <label>59</label>
      <mixed-citation publication-type="miscellaneous" id="jbio201960050-cit-0059"><string-name><given-names>M.</given-names><surname>Abadi</surname></string-name>, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Mane, R. Monga, S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Viegas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, X. Zheng, <italic>arXiv</italic><year>2016</year>, 1603.04467</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0060">
      <label>60</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0060"><string-name><given-names>C.</given-names><surname>Szegedy</surname></string-name>, <string-name><given-names>V.</given-names><surname>Vanhoucke</surname></string-name>, <string-name><given-names>S.</given-names><surname>Ioffe</surname></string-name>, <string-name><given-names>J.</given-names><surname>Shlens</surname></string-name>, <string-name><given-names>Z.</given-names><surname>Wojna</surname></string-name>, <source xml:lang="en">arXiv</source><year>2015</year>, <fpage>1512.00567</fpage>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0061">
      <label>61</label>
      <mixed-citation publication-type="book" id="jbio201960050-cit-0061"><string-name><given-names>J.</given-names><surname>Deng</surname></string-name>, <string-name><given-names>W.</given-names><surname>Dong</surname></string-name>, <string-name><given-names>R.</given-names><surname>Socher</surname></string-name>, <string-name><given-names>L.</given-names><surname>Li</surname></string-name>, <string-name><given-names>K.</given-names><surname>Li</surname></string-name>, <string-name><given-names>L.</given-names><surname>Fei‐Fei</surname></string-name>, <chapter-title>ImageNet: A Large‐Scale Hierarchical Image Database</chapter-title><italic>in 2009 IEEE Conference on Computer Vision and Pattern Recognition, IEEE, Piscataway, New Jersey</italic><year>2009</year><pub-id pub-id-type="doi">10.1109/CVPR.2009.5206848</pub-id>.</mixed-citation>
    </ref>
    <ref id="jbio201960050-bib-0062">
      <label>62</label>
      <mixed-citation publication-type="journal" id="jbio201960050-cit-0062"><string-name><given-names>L.</given-names><surname>McInnes</surname></string-name>, <string-name><given-names>J.</given-names><surname>Healy</surname></string-name>, <string-name><given-names>N.</given-names><surname>Saul</surname></string-name>, <string-name><given-names>L.</given-names><surname>Großberger</surname></string-name>, <source xml:lang="en">J. Open Source Software</source><year>2018</year>, <volume>3</volume>, <fpage>861</fpage><pub-id pub-id-type="doi">10.21105/joss.00861</pub-id>.</mixed-citation>
    </ref>
  </ref-list>
</back>
