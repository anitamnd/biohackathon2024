<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8756178</article-id>
    <article-id pub-id-type="pmid">34643666</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btab714</article-id>
    <article-id pub-id-type="publisher-id">btab714</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Multi-instance learning of graph neural networks for aqueous p<italic toggle="yes">K</italic><sub>a</sub> prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Xiong</surname>
          <given-names>Jiacheng</given-names>
        </name>
        <aff><institution>Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences</institution>, Shanghai 201203, <country country="CN">China</country></aff>
        <aff><institution>College of Pharmacy, University of Chinese Academy of Sciences</institution>, Beijing 100049, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Zhaojun</given-names>
        </name>
        <aff><institution>Development Department, Suzhou Alphama Biotechnology Co., Ltd</institution>, Suzhou City 215000, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Guangchao</given-names>
        </name>
        <aff><institution>College of Computer and Information Engineering, Dezhou University</institution>, Dezhou City 253023, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fu</surname>
          <given-names>Zunyun</given-names>
        </name>
        <aff><institution>Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences</institution>, Shanghai 201203, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhong</surname>
          <given-names>Feisheng</given-names>
        </name>
        <aff><institution>Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences</institution>, Shanghai 201203, <country country="CN">China</country></aff>
        <aff><institution>College of Pharmacy, University of Chinese Academy of Sciences</institution>, Beijing 100049, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xu</surname>
          <given-names>Tingyang</given-names>
        </name>
        <aff><institution>Tencent AI Lab</institution>, Tencent, Shenzhen 518057, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Xiaomeng</given-names>
        </name>
        <aff><institution>Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences</institution>, Shanghai 201203, <country country="CN">China</country></aff>
        <aff><institution>College of Pharmacy, University of Chinese Academy of Sciences</institution>, Beijing 100049, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Huang</surname>
          <given-names>Ziming</given-names>
        </name>
        <aff><institution>Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences</institution>, Shanghai 201203, <country country="CN">China</country></aff>
        <aff><institution>College of Pharmacy, University of Chinese Academy of Sciences</institution>, Beijing 100049, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Xiaohong</given-names>
        </name>
        <aff><institution>Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences</institution>, Shanghai 201203, <country country="CN">China</country></aff>
        <aff><institution>Development Department, Suzhou Alphama Biotechnology Co., Ltd</institution>, Suzhou City 215000, <country country="CN">China</country></aff>
        <aff><institution>Shanghai Institute for Advanced Immunochemical Studies, and School of Life Science and Technology, ShanghaiTech University</institution>, Shanghai 200031, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Kaixian</given-names>
        </name>
        <aff><institution>Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences</institution>, Shanghai 201203, <country country="CN">China</country></aff>
        <aff><institution>College of Pharmacy, University of Chinese Academy of Sciences</institution>, Beijing 100049, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Jiang</surname>
          <given-names>Hualiang</given-names>
        </name>
        <xref rid="btab714-cor1" ref-type="corresp"/>
        <aff><institution>Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences</institution>, Shanghai 201203, <country country="CN">China</country></aff>
        <aff><institution>College of Pharmacy, University of Chinese Academy of Sciences</institution>, Beijing 100049, <country country="CN">China</country></aff>
        <aff><institution>Shanghai Institute for Advanced Immunochemical Studies, and School of Life Science and Technology, ShanghaiTech University</institution>, Shanghai 200031, <country country="CN">China</country></aff>
        <!--hljiang@simm.ac.cn-->
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3323-3092</contrib-id>
        <name>
          <surname>Zheng</surname>
          <given-names>Mingyue</given-names>
        </name>
        <xref rid="btab714-cor1" ref-type="corresp"/>
        <aff><institution>Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences</institution>, Shanghai 201203, <country country="CN">China</country></aff>
        <aff><institution>College of Pharmacy, University of Chinese Academy of Sciences</institution>, Beijing 100049, <country country="CN">China</country></aff>
        <!--hljiang@simm.ac.cn-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Lu</surname>
          <given-names>Zhiyong</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btab714-cor1">To whom correspondence should be addressed. <email>hljiang@simm.ac.cn</email> or <email>myzheng@simm.ac.cn</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>2</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-10-13">
      <day>13</day>
      <month>10</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>13</day>
      <month>10</month>
      <year>2021</year>
    </pub-date>
    <volume>38</volume>
    <issue>3</issue>
    <fpage>792</fpage>
    <lpage>798</lpage>
    <history>
      <date date-type="received">
        <day>11</day>
        <month>6</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>26</day>
        <month>9</month>
        <year>2021</year>
      </date>
      <date date-type="editorial-decision">
        <day>09</day>
        <month>10</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>15</day>
        <month>10</month>
        <year>2021</year>
      </date>
      <date date-type="corrected-typeset">
        <day>05</day>
        <month>11</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btab714.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>The acid dissociation constant (p<italic toggle="yes">K</italic><sub>a</sub>) is a critical parameter to reflect the ionization ability of chemical compounds and is widely applied in a variety of industries. However, the experimental determination of p<italic toggle="yes">K</italic><sub>a</sub> is intricate and time-consuming, especially for the exact determination of micro-p<italic toggle="yes">K</italic><sub>a</sub> information at the atomic level. Hence, a fast and accurate prediction of p<italic toggle="yes">K</italic><sub>a</sub> values of chemical compounds is of broad interest.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Here, we compiled a large-scale p<italic toggle="yes">K</italic><sub>a</sub> dataset containing 16 595 compounds with 17 489 p<italic toggle="yes">K</italic><sub>a</sub> values. Based on this dataset, a novel p<italic toggle="yes">K</italic><sub>a</sub> prediction model, named Graph-p<italic toggle="yes">K</italic><sub>a</sub>, was established using graph neural networks. Graph-p<italic toggle="yes">K</italic><sub>a</sub> performed well on the prediction of macro-p<italic toggle="yes">K</italic><sub>a</sub> values, with a mean absolute error around 0.55 and a coefficient of determination around 0.92 on the test dataset. Furthermore, combining multi-instance learning, Graph-p<italic toggle="yes">K</italic><sub>a</sub> was also able to automatically deconvolute the predicted macro-p<italic toggle="yes">K</italic><sub>a</sub> into discrete micro-p<italic toggle="yes">K</italic><sub>a</sub> values.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The Graph-p<italic toggle="yes">K</italic><sub>a</sub> model is now freely accessible via a web-based interface (<ext-link xlink:href="https://pka.simm.ac.cn/" ext-link-type="uri">https://pka.simm.ac.cn/</ext-link>).</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Project supported by Shanghai Municipal Science and Technology Major Project</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>81773634</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Tencent AI Lab Rhino-Bird Focused Research Program</institution>
          </institution-wrap>
        </funding-source>
        <award-id>JR202002</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>The acid dissociation constant p<italic toggle="yes">K</italic><sub>a</sub>, an equilibrium constant defined as the negative logarithm of the ratio of the protonated and deprotonated form of a compound, is a key parameter to describe the ionization ability of substances. It has been reported that about two-thirds of marketed drugs are ionizable in the aqueous solution (<xref rid="btab714-B12" ref-type="bibr">Manallack, 2007</xref>). Hence, in the design of new drugs, p<italic toggle="yes">K</italic><sub>a</sub> is a crucial physical property to be considered, which has profound effects on biological activities, ADMET (absorption, distribution, metabolism, excretion and toxicity) properties and other properties of drugs (<xref rid="btab714-B3" ref-type="bibr">Charifson and Walters, 2014</xref>; <xref rid="btab714-B13" ref-type="bibr">Manallack <italic toggle="yes">et al.</italic>, 2013</xref>). Apart from the pharmaceutical industry, the p<italic toggle="yes">K</italic><sub>a</sub> is also related to environmental ecotoxicology, agriculture and chemical industries. Hence, the fast and accurate prediction of p<italic toggle="yes">K</italic><sub>a</sub> values of chemical compounds from their structures is of great interest.</p>
    <p>Graph neural networks (GNN) are a type of neural network to process graph structure data (<xref rid="btab714-B4" ref-type="bibr">Defferrard <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btab714-B15" ref-type="bibr">Niepert <italic toggle="yes">et al.</italic>, 2016</xref>). Since first introduced into the prediction of molecular properties several years ago (<xref rid="btab714-B5" ref-type="bibr">Duvenaud <italic toggle="yes">et al.</italic>, 2015</xref>), reports of different GNN architectures and their successful applications have been rapidly accumulating in this field (<xref rid="btab714-B18" ref-type="bibr">Sun <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btab714-B24" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2021</xref>). However, so far, graph neural networks have rarely been applied in the prediction of p<italic toggle="yes">K</italic><sub>a</sub>, presumably because the p<italic toggle="yes">K</italic><sub>a</sub> values are not only molecular-level ‘global’ properties but also atomic-level ‘local’ properties (<xref rid="btab714-F1" ref-type="fig">Fig. 1</xref>). The molecular-level ‘global’ properties refer to the macro-p<italic toggle="yes">K</italic><sub>a</sub>, the acid dissociation constant related to the observable loss or gain of a proton from a molecule regardless of specific ionization site. The ‘local’ properties refer to micro-p<italic toggle="yes">K</italic><sub>a</sub>, the acid dissociation constant related to the loss or gain of a proton from a single titratable site (<xref rid="btab714-B11" ref-type="bibr">Işık <italic toggle="yes">et al.</italic>, 2018</xref>). Apart from the macro-p<italic toggle="yes">K</italic><sub>a</sub>, a powerful p<italic toggle="yes">K</italic><sub>a</sub> prediction model should also be capable of providing micro-p<italic toggle="yes">K</italic><sub>a</sub> information at the atomic level. Such information can not only enhance our confidence in the predicted results but also provide useful reference information for the structural modification of compounds, chemical reaction prediction and other related studies. However, for a molecule with multiple ionization sites, usually, we can only measure one or a few macro-p<italic toggle="yes">K</italic><sub>a</sub> values experimentally, but not the micro-p<italic toggle="yes">K</italic><sub>a</sub> values of all individual sites. Thus, it is intricate to predict micro-p<italic toggle="yes">K</italic><sub>a</sub> values, posing a significant challenge to the overall prediction of p<italic toggle="yes">K</italic><sub>a</sub>.</p>
    <fig position="float" id="btab714-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>The relationship between macro- and micro-p<italic toggle="yes">K</italic><sub>a</sub> of basic compounds. p<italic toggle="yes">K</italic><sub>a(macro)</sub> refers to the macro-p<italic toggle="yes">K</italic><sub>a</sub>; p<italic toggle="yes">K</italic><sub>a</sub><sup>1</sup>, p<italic toggle="yes">K</italic><sub>a</sub><sup>2</sup> and p<italic toggle="yes">K</italic><sub>a</sub><sup>3</sup> refer to the micro-p<italic toggle="yes">K</italic><sub>a</sub></p>
      </caption>
      <graphic xlink:href="btab714f1" position="float"/>
    </fig>
    <p>In 2019, Roszak <italic toggle="yes">et al.</italic> built a graph convolution model for the prediction of the p<italic toggle="yes">K</italic><sub>a</sub> value of the C-H bond in organic solvents and applied this model to predict the products of hydrogen abstraction reaction (<xref rid="btab714-B16" ref-type="bibr">Roszak <italic toggle="yes">et al.</italic>, 2019</xref>). To the best of our knowledge, this study was the only attempt to predict compound p<italic toggle="yes">K</italic><sub>a</sub> with graph neural networks. However, the training of their model relied on the p<italic toggle="yes">K</italic><sub>a</sub> dataset containing atomic level labels, which were mainly obtained from quantum chemical calculation or molecules with a single ionizable site. Hence, this method is difficult to extend to the p<italic toggle="yes">K</italic><sub>a</sub> prediction of heterogeneous chemical classes with multiple ionizable sites. Another alternative strategy to obtain micro-p<italic toggle="yes">K</italic><sub>a</sub> data is to assign the macro-p<italic toggle="yes">K</italic><sub>a</sub> value of a molecule to its major responsible ionization site and take it as an approximation of the micro-p<italic toggle="yes">K</italic><sub>a</sub> value. Recently, some p<italic toggle="yes">K</italic><sub>a</sub> prediction models have used this strategy (<xref rid="btab714-B10" ref-type="bibr">Hunt <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btab714-B22" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2020</xref>), but there are also two significant problems. As illustrated in <xref rid="btab714-F1" ref-type="fig">Figure 1</xref>, (i) for molecules such as propane-1,2,3-triamine, there are multiple sites having similar ionization capacity, this approximate treatment may bring large errors; (ii) the selection of major responsible ionization site is a non-trivial process and requires substantial chemical domain knowledge, and in many cases, a macro-p<italic toggle="yes">K</italic><sub>a</sub> value could not be unambiguously assigned to one major ionizable group.</p>
    <p>Multi-instance learning (MIL) is a kind of weakly supervised learning algorithm for data with only coarse-grained labels (<xref rid="btab714-B26" ref-type="bibr">Zhou, 2018</xref>). In classic MIL, the training set is composed of many ‘bags’, each of which contains a series of ‘instances’. A bag is labeled as positive if containing at least one positive instance; otherwise, it is labeled as negative. The goal of MIL is to train a classifier that can correctly label unseen bags. Due to the ability to provide instance-level interpretation, MIL has attracted extensive attention in many classification tasks such as medical image analysis, text classification and video annotation (<xref rid="btab714-B2" ref-type="bibr">Carbonneau <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btab714-B19" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab714-B25" ref-type="bibr">Zhou <italic toggle="yes">et al.</italic>, 2017</xref>). However, so far, MIL has rarely been used in regression tasks. This is because a necessary prerequisite for obtaining instance labels through MIL is that there should be a clear mathematical relationship between instance labels and bag labels. This relationship is common in classification tasks (such as ‘or’ relationship) but rare in regression tasks. For p<italic toggle="yes">K</italic><sub>a</sub>, there is a relatively clear relationship between macro-p<italic toggle="yes">K</italic><sub>a</sub> and micro-p<italic toggle="yes">K</italic><sub>a</sub>. For example, <xref rid="btab714-F1" ref-type="fig">Figure 1</xref> shows the formula between macro-p<italic toggle="yes">K</italic><sub>a</sub> and micro-p<italic toggle="yes">K</italic><sub>a</sub> of basic compounds.</p>
    <p>Here, combining multi-instance learning and graph neural networks, we designed a novel p<italic toggle="yes">K</italic><sub>a</sub> prediction model named Graph-p<italic toggle="yes">K</italic><sub>a</sub>. In Graph-p<italic toggle="yes">K</italic><sub>a</sub>, a molecule is regarded as a ‘bag’, and those ionizable atoms in this molecule are regarded as ‘instances’. It means that the macro-p<italic toggle="yes">K</italic><sub>a</sub> value of a molecule is designated as the label of a bag, which is available in the training set, and the unavailable information regarding to the micro-p<italic toggle="yes">K</italic><sub>a</sub> values of ionizable sites are considered as the labels of instances. Under this scheme, Graph-p<italic toggle="yes">K</italic><sub>a</sub> can follow the MIL framework to learn the labels of instances through training against the labels of bags (<xref rid="btab714-F2" ref-type="fig">Fig. 2</xref>). Furthermore, it should be noted that those molecules containing multiple ionization sites may have multiple macro-p<italic toggle="yes">K</italic><sub>a</sub> values. In this work, we only consider the most acidic and basic p<italic toggle="yes">K</italic><sub>a</sub> values, which are key parameters that can unambiguously and concisely describe the ionization capabilities of compounds. Some chemical information websites, including ChEMBL (<xref rid="btab714-B7" ref-type="bibr">Gaulton <italic toggle="yes">et al.</italic>, 2017</xref>) and DrugBank (<xref rid="btab714-B20" ref-type="bibr">Wishart <italic toggle="yes">et al.</italic>, 2018</xref>) also describe the prediction for the p<italic toggle="yes">K</italic><sub>a</sub> of compounds in terms of the most acidic and basic p<italic toggle="yes">K</italic><sub>a</sub> values.</p>
    <fig position="float" id="btab714-F2">
      <label>Fig. 2.</label>
      <caption>
        <p>The schematic representation of the proposed Graph-p<italic toggle="yes">K</italic><sub>a</sub> model</p>
      </caption>
      <graphic xlink:href="btab714f2" position="float"/>
    </fig>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 S-p<italic toggle="yes">k</italic><sub>a</sub> dataset</title>
      <p>A large p<italic toggle="yes">K</italic><sub>a</sub> dataset named S-p<italic toggle="yes">K</italic><sub>a</sub> was compiled, mainly from three main sources: (i) datasets used in several previous studies on p<italic toggle="yes">K</italic><sub>a</sub>, (ii) a free software named QSAR Toolbox, (iii) manual extraction from various literature. Those chemical structures from different sources were standardized and then merged. The structure standardization procedure includes removing all salts from molecules, neutralizing charged molecules, and standardizing SMILES strings. In addition, considering that the accuracy of publicly available experimentally determined p<italic toggle="yes">K</italic><sub>a</sub> values was often dubious (<xref rid="btab714-B17" ref-type="bibr">Rupp <italic toggle="yes">et al.</italic>, 2011</xref>), each data would undergo manual inspection to ensure that it belongs to the most acidic or basic p<italic toggle="yes">K</italic><sub>a</sub> value of its corresponding molecule before adding to the S-p<italic toggle="yes">K</italic><sub>a</sub> dataset. The detailed processes of data collection and cleaning is given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>. The S-p<italic toggle="yes">K</italic><sub>a</sub> dataset can be separated into an acidic subset and a basic subset, containing the most acidic p<italic toggle="yes">K</italic><sub>a</sub> values of 9043 chemical structures and the most basic p<italic toggle="yes">K</italic><sub>a</sub> values of 8436 chemical structures, respectively (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2a</xref>). The distribution of p<italic toggle="yes">K</italic><sub>a</sub> values in the acidic and basic subset is shown in <xref rid="btab714-F3" ref-type="fig">Figure 3a</xref>. The most acidic p<italic toggle="yes">K</italic><sub>a</sub> values varied from -3.3 to 40, while the most basic p<italic toggle="yes">K</italic><sub>a</sub> values varied from -10.1 to 14. Since to learn micro-p<italic toggle="yes">K</italic><sub>a</sub> via MIL is a critical concept utilized in the establishment of the Graph-p<italic toggle="yes">K</italic><sub>a</sub> model, the acidic or basic ionizable sites of compounds in the S-p<italic toggle="yes">K</italic><sub>a</sub> dataset are all enumerated and displayed (<xref rid="btab714-F3" ref-type="fig">Fig. 3b</xref>). In this study, the acidic ionizable sites are defined as non-carbon atoms connected with at least one hydrogen atom, and the basic ionizable sites are defined as nitrogen atoms with no positive formal charge. The distribution of the molecular weight of compounds across the S-p<italic toggle="yes">K</italic><sub>a</sub> dataset is also shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2b</xref>.</p>
      <fig position="float" id="btab714-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>The distributions of simple compound properties in the S-p<italic toggle="yes">K</italic><sub>a</sub> dataset. (<bold>a</bold>) The experimental p<italic toggle="yes">K</italic><sub>a</sub> values. (<bold>b</bold>) The number of ionizable sites</p>
        </caption>
        <graphic xlink:href="btab714f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.2 Graph-p<italic toggle="yes">K</italic><sub>a</sub> model</title>
      <p>The architecture of Graph-p<italic toggle="yes">K</italic><sub>a</sub> is shown in <xref rid="btab714-F2" ref-type="fig">Figure 2</xref>. It begins by describing each molecule as an undirected graph where nodes and edges correspond to atoms and chemical bonds, respectively. The molecular graph is then input into the graph neural layers where atoms receive the message of other atoms in the molecule and use the aggregated messages to update their own features. The graph neural layer in Graph-p<italic toggle="yes">K</italic><sub>a</sub> is the same as our previously developed Attentive FP (<xref rid="btab714-B21" ref-type="bibr">Xiong <italic toggle="yes">et al.</italic>, 2020</xref>), a molecular representation learning scheme that uses a graph attention mechanism. Here, six graph neural layers are stacked in Graph-p<italic toggle="yes">K</italic><sub>a</sub> for the extraction of atom features.</p>
      <p>The major difference between Graph-p<italic toggle="yes">K</italic><sub>a</sub> and other graph neural networks lies in the approach to deal with the features of nodes extracted by graph neural network layers. In molecular graph neural networks such as GCN (<xref rid="btab714-B5" ref-type="bibr">Duvenaud <italic toggle="yes">et al.</italic>, 2015</xref>), MPNN (<xref rid="btab714-B9" ref-type="bibr">Gilmer <italic toggle="yes">et al.</italic>, 2017</xref>) and Attentive FP (<xref rid="btab714-B21" ref-type="bibr">Xiong <italic toggle="yes">et al.</italic>, 2020</xref>), those node features are aggregated with various pooling operations such as average pooling and Set2Set to generate the features of the whole molecule, which are next used to fit and predict the molecular properties. However, in Graph-p<italic toggle="yes">K</italic><sub>a</sub> those learned node features are directly fed into a fully connected (FC) layer to predict the p<italic toggle="yes">K</italic><sub>a</sub> values of atoms. Since some atoms in molecules are not ionizable, their predicted p<italic toggle="yes">K</italic><sub>a</sub> values will be masked. In the acidic and basic p<italic toggle="yes">K</italic><sub>a</sub> prediction model, the mask values are respectively positive infinity and negative infinity. Finally, the macro-p<italic toggle="yes">K</italic><sub>a</sub> values of molecules are calculated according to the approximate mathematical relationships between them and the predicted p<italic toggle="yes">K</italic><sub>a</sub> values of ionizable atoms. More specifically, given an atom <italic toggle="yes">A<sub>i</sub></italic> with features <italic toggle="yes">X<sub>i</sub></italic>, the above process can be formulated as follows:</p>
      <p>In acidic p<italic toggle="yes">K</italic><sub>a</sub> prediction model:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">acidic</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">FC</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></disp-formula>
 <disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mfenced separators="|"><mml:mi>acidic</mml:mi></mml:mfenced></mml:mrow></mml:msub><mml:mi mathvariant="normal">i</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mfenced open="{" close="" separators="|"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mo>(</mml:mo><mml:mi>acidic</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mi mathvariant="normal">i</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:mi>P</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>∉</mml:mo><mml:mi>P</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math></disp-formula>
 <disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">acidic</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">p</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">acidic</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>In basic p<italic toggle="yes">K</italic><sub>a</sub> prediction model:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">basic</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">FC</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></disp-formula>
 <disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mfenced separators="|"><mml:mi>basic</mml:mi></mml:mfenced></mml:mrow></mml:msub><mml:mi mathvariant="normal">i</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mfenced open="{" close="" separators="|"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mo>(</mml:mo><mml:mi>basic</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mi mathvariant="normal">i</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:mi>Q</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>-</mml:mo><mml:mi mathvariant="italic">inf</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>∉</mml:mo><mml:mi>Q</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math></disp-formula>
 <disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">basic</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">basic</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mi mathvariant="normal">FC</mml:mi></mml:math></inline-formula> is referred to a fully connected neural network layer, <italic toggle="yes">P</italic> is the acidic ionizable sites, <italic toggle="yes">Q</italic> is the basic ionizable sites, <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mi>N</mml:mi></mml:math></inline-formula> is the number of heavy atoms in a molecule, <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mi mathvariant="italic">inf</mml:mi></mml:math></inline-formula> is the positive infinity, <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mo>(</mml:mo><mml:mi>acidic</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mo>(</mml:mo><mml:mi>basic</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> are the most acidic/basic p<italic toggle="yes">K</italic><sub>a</sub> values of a molecule.</p>
      <p>Obviously, formula 3 and 6 are the key formulas for MIL. Yang <italic toggle="yes">et al.</italic> also had used formula 6 to calculate the macro-p<italic toggle="yes">K</italic><sub>a</sub> values in their study (<xref rid="btab714-B22" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2020</xref>). Here, we provided the derivation of formula 3 and 6 in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3</xref>.</p>
    </sec>
    <sec>
      <title>2.3 Implement of Graph-p<italic toggle="yes">K</italic><sub>a</sub> and other benchmark methods</title>
      <p>In Graph-p<italic toggle="yes">K</italic><sub>a</sub>, the conversion from a SMILES string to an undirected graph and initialization for it was implemented with the DGL-LifeSci package. The representations of the graph were initialized with eight kinds of atom features and four kinds of bond features (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). The Graph-p<italic toggle="yes">K</italic><sub>a</sub> model was implemented using the PyTorch and DGL. The loss function used to train Graph-p<italic toggle="yes">K</italic><sub>a</sub> was MSELoss. Attentive FP and four machine learning models, including SVM, RF, XGBoost and ANN were implemented as baseline models. XGBoost was implemented with the XGBoost package, SVM, RF and ANN were implemented with the Scikit-learn package. Attentive FP is a graph neural network with the same GNN layers as Graph-p<italic toggle="yes">K</italic><sub>a</sub> but without MIL, which was also implemented as a control for model performance evaluation. For baseline models except Attentive FP, the molecular fingerprints used to encode the molecular structures were a kind of combined molecular fingerprint that integrated eight types of common molecular fingerprints including CDK, Estate, CDK graph only, MACCS, PubChem, Substructure, Klekota-Roth and 2D atom pairs. Those molecular fingerprints had 9121 bits in total and were calculated using PaDEL(<xref rid="btab714-B23" ref-type="bibr">Yap, 2011</xref>).</p>
    </sec>
    <sec>
      <title>2.4 Model training and evaluation</title>
      <p>In the experiment of predicting macro-p<italic toggle="yes">K</italic><sub>a</sub>, the S-p<italic toggle="yes">K</italic><sub>a</sub> dataset was randomly split into training/validation/test set in a 70:15:15 ratio. Graph-p<italic toggle="yes">K</italic><sub>a</sub> and other models were trained on the same training set. The best set of hyperparameters for each model were determined based on the result on the validation set. The search ranges and optimal values of these hyperparameters are provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>. The final model performance was assessed on the test set and two external tests set through three independent runs. The metrics for evaluating model performance were mean absolute error (MAE), root mean squared error (RMSE) and coefficient of determination (<italic toggle="yes">R</italic><sup>2</sup>). The structural similarity between the two molecules was calculated using the 1024-bit Morgan2 fingerprints and the Tanimoto coefficient.</p>
      <p>In the experiment of predicting micro-p<italic toggle="yes">K</italic><sub>a</sub>, about 500 molecules that possessed multiple different acidic/basic ionization sites and whose dominant ionization sites had been uniquely assigned by <xref rid="btab714-B10" ref-type="bibr">Hunt <italic toggle="yes">et al.</italic> (2020)</xref> were extracted as test data. Those molecules were then removed from the S-p<italic toggle="yes">K</italic><sub>a</sub> Dataset. Graph-p<italic toggle="yes">K</italic><sub>a</sub> was retrained on the remaining dataset with the same set of hyperparameters previously used. The metrics for evaluating the model are consistency rate and difference values. Consistency rate is the probability that the dominant ionization sites of molecules selected by Graph-p<italic toggle="yes">K</italic><sub>a</sub> are the same as that of human experts. Different value is used to quantify the degree of divergence between Graph-p<italic toggle="yes">K</italic><sub>a</sub> and human experts. They are calculated as follows:
<disp-formula id="E7"><label>(7)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:malignmark/><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:malignmark/><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∉</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math></disp-formula>
 <disp-formula id="E8"><label>(8)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mi mathvariant="normal">consistency</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mi mathvariant="normal">rate</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E9"><label>(9)</label><mml:math id="M9" display="block" overflow="scroll"><mml:mi mathvariant="normal">difference</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mi mathvariant="normal">value</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="italic">Abs</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math></disp-formula>where <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the most acidic/basic atom of molecule <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula> selected by human experts, <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the most acidic/basic atoms of molecule <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula> predicted by Graph-p<italic toggle="yes">K</italic><sub>a</sub>, <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal"> </mml:mi></mml:math></inline-formula>is an arbitrary element in <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the reason why <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a collection is that some molecules have multiple dominant ionization sites with the same ionization ability, <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mi>f</mml:mi></mml:math></inline-formula> is referred to a function of Graph-p<italic toggle="yes">K</italic><sub>a</sub> for atomic p<italic toggle="yes">K</italic><sub>a</sub> prediction.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <sec>
      <title>3.1 Comparison with benchmark methods</title>
      <p>In order to evaluate the performance of Graph-p<italic toggle="yes">K</italic><sub>a</sub>, four conventional machine learning models were implemented and taken as benchmark methods. A kind of combined molecular fingerprints was used as the representation of molecules and the input of these machine learning models, due to its good performance on a previous study for p<italic toggle="yes">K</italic><sub>a</sub> prediction (<xref rid="btab714-B14" ref-type="bibr">Mansouri <italic toggle="yes">et al.</italic>, 2019</xref>). The comparison between Graph-p<italic toggle="yes">K</italic><sub>a</sub> and other models was carried out on the S-p<italic toggle="yes">K</italic><sub>a</sub> dataset that was randomly divided into training, validation and test set. The performances of those models on the test set are shown in <xref rid="btab714-F4" ref-type="fig">Figure 4</xref>. Among the four machine learning models, ANN and XGBoost performed comparatively well, which was consistent with some previous studies (<xref rid="btab714-B14" ref-type="bibr">Mansouri <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab714-B22" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2020</xref>). However, the performances of these two models still obviously fell behind Graph-p<italic toggle="yes">K</italic><sub>a</sub>, which achieved a MAE around 0.55 and a <italic toggle="yes">R</italic><sup>2</sup> around 0.92 on the test sets (<xref rid="btab714-F4" ref-type="fig">Fig. 4a and b</xref>). As known, the performance of QSAR models is closely related to the similarity between predicted molecules and the molecules of the training set. To evaluate the generalization capability of different models, we also calculated the pairwise similarity of test set molecules to the training set molecules, and split the test set molecules into five individual subsets according to their maximum similarity to training set molecules (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref>). Then, the MAE of those models on each subset was compared. As shown in <xref rid="btab714-F4" ref-type="fig">Figure 4c and d</xref>, the Graph-p<italic toggle="yes">K</italic><sub>a</sub> outperformed other machine learning models on nearly all similarity subsets, which demonstrated it possesses high robustness and generalization ability. For the molecules with max similarity higher than 0.5 to the training set, the MAE of the model was lower than 0.65. If using it as the threshold for acceptable errors, 81.1% of test molecules were within the applicability domain of the models. Furthermore, the performance of Attentive FP on macro-p<italic toggle="yes">K</italic><sub>a</sub> prediction was not better than that of Graph-p<italic toggle="yes">K</italic><sub>a</sub>, meaning that MIL could endow Graph-p<italic toggle="yes">K</italic><sub>a</sub> with the prediction ability of micro-p<italic toggle="yes">K</italic><sub>a</sub> without significant trade-off on its prediction ability of macro-p<italic toggle="yes">K</italic><sub>a</sub>.</p>
      <fig position="float" id="btab714-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>The performance of the various model on macro-p<italic toggle="yes">K</italic><sub>a</sub> prediction on the S-p<italic toggle="yes">K</italic><sub>a</sub> dataset. (<bold>a,b</bold>) The MAE and R<sup>2</sup> of those models on the test dataset. (<bold>c,d</bold>) The MAE of those models for acidic (c) and basic (d) p<italic toggle="yes">K</italic><sub>a</sub> prediction on a series of similarity subsets. Error bars represent standard deviations</p>
        </caption>
        <graphic xlink:href="btab714f4" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.2 Evaluation on external datasets</title>
      <p>The performance of Graph-p<italic toggle="yes">K</italic><sub>a</sub> was further validated by testing against two external datasets that were obtained from two blind p<italic toggle="yes">K</italic><sub>a</sub> prediction challenges named SAMPL6 and SAMPL7. These two challenges were launched by the Drug Design Data Resource Community in 2018 and 2020, respectively. The SAMPL6 dataset comprises 24 kinase inhibitor-like molecules with 31 experimental p<italic toggle="yes">K</italic><sub>a</sub> values, and the SAMPL7 dataset comprises 22 molecules (most are sulfonamides) with 20 experimental p<italic toggle="yes">K</italic><sub>a</sub> values. There are two p<italic toggle="yes">K</italic><sub>a</sub> values not belonging to the most acidic or basic p<italic toggle="yes">K</italic><sub>a</sub> values in the SAMPL6 dataset and two molecules without corresponding experiment p<italic toggle="yes">K</italic><sub>a</sub> values in the SAMPL7 dataset, they were excluded from this testing. The performances of Graph-p<italic toggle="yes">K</italic><sub>a</sub> and some commonly used software and models on these two external datasets are shown in <xref rid="btab714-T1" ref-type="table">Table 1</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref>. Graph-p<italic toggle="yes">K</italic><sub>a</sub> achieved a low MAE of 0.594 and 0.758 as well as a high R<sup>2</sup> of 0.918 and 0.839 on SAMPL6 and SAMPL7 datasets, respectively, comparable to the performance of those commercial software established based on large collections of proprietary data.</p>
      <table-wrap position="float" id="btab714-T1">
        <label>Table 1.</label>
        <caption>
          <p>Performance of Graph-p<italic toggle="yes">K</italic><sub>a</sub> and other models on the SAMPL6 and SAMPL7 external test sets </p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Dataset</th>
              <th align="center" rowspan="1" colspan="1">Model name</th>
              <th align="center" rowspan="1" colspan="1">Model class</th>
              <th align="center" rowspan="1" colspan="1">MAE</th>
              <th align="center" rowspan="1" colspan="1">RMSE</th>
              <th align="center" rowspan="1" colspan="1">
                <italic toggle="yes">R</italic>
                <sup>2</sup>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="10" colspan="1"><hr/>SAMPL6</td>
              <td rowspan="1" colspan="1">Epik Scan<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">Commercial</td>
              <td rowspan="1" colspan="1">0.784</td>
              <td rowspan="1" colspan="1">0.962</td>
              <td rowspan="1" colspan="1">0.857</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Epik Micro<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">Commercial</td>
              <td rowspan="1" colspan="1">0.783</td>
              <td rowspan="1" colspan="1">0.972</td>
              <td rowspan="1" colspan="1">0.854</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ACD/pKa<sup>a</sup></td>
              <td rowspan="1" colspan="1">Commercial</td>
              <td rowspan="1" colspan="1">
                <bold>0.550</bold>
              </td>
              <td rowspan="1" colspan="1">0.783</td>
              <td rowspan="1" colspan="1">0.905</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">MoKa<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">Commercial</td>
              <td rowspan="1" colspan="1">0.854</td>
              <td rowspan="1" colspan="1">0.970</td>
              <td rowspan="1" colspan="1">0.854</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ChemAxon<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">Commercial</td>
              <td rowspan="1" colspan="1">1.007</td>
              <td rowspan="1" colspan="1">1.248</td>
              <td rowspan="1" colspan="1">0.759</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Hunt’s model<xref rid="tblfn3" ref-type="table-fn"><sup>b</sup></xref></td>
              <td rowspan="1" colspan="1">Academic</td>
              <td rowspan="1" colspan="1">0.687</td>
              <td rowspan="1" colspan="1">0.864</td>
              <td rowspan="1" colspan="1">0.885</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Yang’s XGB<xref rid="tblfn3" ref-type="table-fn"><sup>b</sup></xref></td>
              <td rowspan="1" colspan="1">Academic</td>
              <td rowspan="1" colspan="1">0.767</td>
              <td rowspan="1" colspan="1">1.011</td>
              <td rowspan="1" colspan="1">0.842</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Yang’s NN<xref rid="tblfn3" ref-type="table-fn"><sup>b</sup></xref></td>
              <td rowspan="1" colspan="1">Academic</td>
              <td rowspan="1" colspan="1">0.832</td>
              <td rowspan="1" colspan="1">1.141</td>
              <td rowspan="1" colspan="1">0.799</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">OPERA<xref rid="tblfn5" ref-type="table-fn"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">Academic</td>
              <td rowspan="1" colspan="1">0.970</td>
              <td rowspan="1" colspan="1">1.283</td>
              <td rowspan="1" colspan="1">0.619</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"><hr/>Graph-p<italic toggle="yes">K</italic><sub>a</sub></td>
              <td rowspan="1" colspan="1"><hr/>Academic</td>
              <td rowspan="1" colspan="1"><hr/>0.594</td>
              <td rowspan="1" colspan="1">
                <hr/>
                <bold>0.726</bold>
              </td>
              <td rowspan="1" colspan="1">
                <hr/>
                <bold>0.918</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="6" colspan="1">SAMPL7</td>
              <td rowspan="1" colspan="1">Epik Scan<xref rid="tblfn4" ref-type="table-fn"><sup>c</sup></xref></td>
              <td rowspan="1" colspan="1">Commercial</td>
              <td rowspan="1" colspan="1">1.121</td>
              <td rowspan="1" colspan="1">1.648</td>
              <td rowspan="1" colspan="1">0.508</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ChemAxon<xref rid="tblfn4" ref-type="table-fn"><sup>c</sup></xref></td>
              <td rowspan="1" colspan="1">Commercial</td>
              <td rowspan="1" colspan="1">
                <bold>0.559</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.708</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.909</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Yang’s XGB<xref rid="tblfn4" ref-type="table-fn"><sup>c</sup></xref></td>
              <td rowspan="1" colspan="1">Academic</td>
              <td rowspan="1" colspan="1">1.476</td>
              <td rowspan="1" colspan="1">1.622</td>
              <td rowspan="1" colspan="1">0.523</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Yang’s NN<xref rid="tblfn4" ref-type="table-fn"><sup>c</sup></xref></td>
              <td rowspan="1" colspan="1">Academic</td>
              <td rowspan="1" colspan="1">0.932</td>
              <td rowspan="1" colspan="1">1.156</td>
              <td rowspan="1" colspan="1">0.758</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">OPERA<xref rid="tblfn5" ref-type="table-fn"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">Academic</td>
              <td rowspan="1" colspan="1">2.135</td>
              <td rowspan="1" colspan="1">2.515</td>
              <td rowspan="1" colspan="1">−3.752</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Graph-p<italic toggle="yes">K</italic><sub>a</sub></td>
              <td rowspan="1" colspan="1">Academic</td>
              <td rowspan="1" colspan="1">0.758</td>
              <td rowspan="1" colspan="1">0.934</td>
              <td rowspan="1" colspan="1">0.839</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p>The bold entries in the “MAE”, “RMSE”, and “R2” columns represent the best results in corresponding datasets.</p>
          </fn>
          <fn id="tblfn2">
            <label>a</label>
            <p>The results are cited from a summary of the SAMPL6 challenge results. (<ext-link xlink:href="https://github.com/samplchallenges/SAMPL6/blob/master/physical_properties/pKa/analysis/" ext-link-type="uri">https://github.com/samplchallenges/SAMPL6/blob/master/physical_properties/pKa/analysis/</ext-link>).</p>
          </fn>
          <fn id="tblfn3">
            <label>b</label>
            <p>The results are cited from articles of <xref rid="btab714-B10" ref-type="bibr">Hunt <italic toggle="yes">et al.</italic> (2020)</xref> and <xref rid="btab714-B22" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> (2020)</xref>.</p>
          </fn>
          <fn id="tblfn4">
            <label>c</label>
            <p>The results of Epik predictions are from Schrödinger Suite 2017; the results of ChemAxon predictions are from ChemAxon Marvin Suite 20.15.0. The results of Yang’s XGB and Yang’s NN are from a webserver (<ext-link xlink:href="http://pka.luoszgroup.com/prediction" ext-link-type="uri">http://pka.luoszgroup.com/prediction</ext-link>).</p>
          </fn>
          <fn id="tblfn5">
            <label>d</label>
            <p>The results are from OPERA 2.7. Nine p<italic toggle="yes">K</italic><sub>a</sub> values that OPERA2.7 failed to predict were excluded.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Although our Graph-p<italic toggle="yes">K</italic><sub>a</sub> model has achieved satisfactory prediction performance, there are potentially two limitations. Frist, Graph-p<italic toggle="yes">K</italic><sub>a</sub> is only trained to predict the most acidic and basic p<italic toggle="yes">K</italic><sub>a</sub> values and its capability to predict other types of p<italic toggle="yes">K</italic><sub>a</sub> values such as the 2nd strongest acidic and basic p<italic toggle="yes">K</italic><sub>a</sub> values has not been fully evaluated. This is mainly because of the difficulty in the collection, cleaning, and labeling of this kind of training data. Second, the tautomerism of molecules has not been taken into account in Graph-p<italic toggle="yes">K</italic><sub>a</sub>, which means that the model will give different prediction results for different tautomers of the same molecule. We leave this issue to follow-up studies, such as averaging the predicted values of different tautomers.</p>
    </sec>
    <sec>
      <title>3.3 Performance on micro-p<italic toggle="yes">K</italic><sub>a</sub> prediction</title>
      <p>Macro-p<italic toggle="yes">K</italic><sub>a</sub> values can describe the ionization degree of the molecule in the solvent but can't pinpoint the ionization state of each atom in this molecule. To acquire more comprehensive knowledge about the ionization of molecules, the prediction of micro-p<italic toggle="yes">K</italic><sub>a</sub> values is equally important. Thus, the performance of Graph-p<italic toggle="yes">K</italic><sub>a</sub> on predicting micro-p<italic toggle="yes">K</italic><sub>a</sub> was also evaluated here. Unfortunately, the experimental determination of micro-p<italic toggle="yes">K</italic><sub>a</sub> values is highly complicated, and there is currently no available micro-p<italic toggle="yes">K</italic><sub>a</sub> dataset. Given this situation, a Turing-like test was designed to determine if Graph-p<italic toggle="yes">K</italic><sub>a</sub> exhibited the intelligent behavior (i.e. to designate the most acidic/basic atoms in a molecule structure) that was indistinguishable from that of a human expert. The results of expert judgments were obtained from a recent work of Hunt <italic toggle="yes">et al.</italic> for p<italic toggle="yes">K</italic><sub>a</sub> prediction (<xref rid="btab714-B10" ref-type="bibr">Hunt <italic toggle="yes">et al.</italic>, 2020</xref>), where each p<italic toggle="yes">K</italic><sub>a</sub> value in their collected dataset (Hunt’s dataset) and two external test sets (Jensen’s dataset and SAMLP6 dataset) was carefully inspected and assigned to a specific site by human experts. As shown in <xref rid="btab714-F5" ref-type="fig">Figure 5a</xref>, the overall consistency rates between the most acidic/basic atoms predicted by Graph-p<italic toggle="yes">K</italic><sub>a</sub> and the most acidic/basic atoms selected by the human experts were over 90%. To further quantify the degree of divergence between Graph-p<italic toggle="yes">K</italic><sub>a</sub> and human experts on those controversial molecules, the difference values of the predicted p<italic toggle="yes">K</italic><sub>a</sub> between the most acidic/basic atoms predicted by Graph-p<italic toggle="yes">K</italic><sub>a</sub> and those selected by the human experts are shown in <xref rid="btab714-F5" ref-type="fig">Figure 5b</xref>. It could be observed that the difference values of 80% these controversial molecules were within 1.2 p<italic toggle="yes">K</italic><sub>a</sub> units, which indicated that the divergences between Graph-p<italic toggle="yes">K</italic><sub>a</sub> and human expert mainly derived from those molecules whose several atoms had similar ionization capability.</p>
      <fig position="float" id="btab714-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>Application of Graph-p<italic toggle="yes">K</italic><sub>a</sub> to predict the dominant ionization sites of molecules. (<bold>a</bold>) The consistency rates between the prediction of Graph-p<italic toggle="yes">K</italic><sub>a</sub> and the judgment of human experts. (<bold>b</bold>) The distribution of difference values representing the degree of divergence between Graph-p<italic toggle="yes">K</italic><sub>a</sub> and human experts on controversial molecules. (<bold>c,d</bold>) Some examples of molecules on which the predictions of Graph-p<italic toggle="yes">K</italic><sub>a</sub> and human experts are consistent (c) and different (d), the arrows and circles denote to the dominant ionization sites selected by Graph-p<italic toggle="yes">K</italic><sub>a</sub> and human experts, respectively, red and blue numbers, respectively, denote to the predicted acidic and basic p<italic toggle="yes">K</italic><sub>a</sub> values of atoms by Graph-p<italic toggle="yes">K</italic><sub>a</sub>. (<bold>e</bold>) Some molecules and their p<italic toggle="yes">K</italic><sub>a</sub> values for reference</p>
        </caption>
        <graphic xlink:href="btab714f5" position="float"/>
      </fig>
      <p>Some examples of agreement and disagreement between Graph-p<italic toggle="yes">K</italic><sub>a</sub> and human experts are respectively shown in <xref rid="btab714-F5" ref-type="fig">Figure 5c</xref> and d. In the assignment of the most acidic atoms, two controversial molecules of note were A1 and A2, and most of the others were hydroxamic acid derivatives. Hunt <italic toggle="yes">et al.</italic> attributed the acidities of hydroxamic acid derivatives all to their hydroxyls. In fact, the dissociation ability of hydroxylic hydrogen and amino hydrogen in hydroxamic acids was quite similar (<xref rid="btab714-B1" ref-type="bibr">Bartmess, 2010</xref>) (also see R1, R2 in <xref rid="btab714-F5" ref-type="fig">Fig. 5e</xref>, <ext-link xlink:href="http://ibond.nankai.edu.cn" ext-link-type="uri">http://ibond.nankai.edu.cn</ext-link>), and the prediction results of Graph-p<italic toggle="yes">K</italic><sub>a</sub> supported their equivalent protonation potential. In the assignment of the most basic atoms, the two most controversial molecules were B1 and B2. Our prediction for B1 was supported by a record from PubChem that the p<italic toggle="yes">K</italic><sub>a</sub> value of the amine in B1 was 7.75 (<ext-link xlink:href="https://pubchem.ncbi.nlm.nih.gov/compound/135398737" ext-link-type="uri">https://pubchem.ncbi.nlm.nih.gov/compound/135398737</ext-link>). In addition, the basicity of the 1,3,4-Oxadiazol ring in B2 should be very weak, given that the p<italic toggle="yes">K</italic><sub>a</sub> of 1,3,4-thiadiazole was only -4.9 (R3 in <xref rid="btab714-F5" ref-type="fig">Fig. 5e</xref>, <ext-link xlink:href="https://www.scripps.edu/baran/heterocycles/Essentials1-2009.pdf" ext-link-type="uri">https://www.scripps.edu/baran/heterocycles/Essentials1-2009.pdf</ext-link>). According to Graph-p<italic toggle="yes">K</italic><sub>a</sub> prediction, the basicity of B2 was attributed to the pyridine ring, instead of the 1,3,4-Oxadiazol ring. This assignment was further confirmed by quantum chemical calculation. As shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4</xref>, the protonation energies of nitrogen atom in the pyridine ring were -5.25 kcal/mol, significantly lower than that of nitrogen atoms in the 1,3,4-Oxadiazol ring (4.74 and 5.39 kcal/mol). The methods of quantum chemistry calculation are described in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>. Besides, two molecules (B3, B4) in SAMPL6 datasets (<xref rid="btab714-B11" ref-type="bibr">Işık <italic toggle="yes">et al.</italic>, 2018</xref>), whose dominant ionization sites have been determined by nuclear magnetic resonance, are also shown in <xref rid="btab714-F5" ref-type="fig">Figure 5d</xref>. The predicted results of Graph-p<italic toggle="yes">K</italic><sub>a</sub> were consistent with the experimental results. The above results demonstrated that Graph-p<italic toggle="yes">K</italic><sub>a</sub> performed outstandingly in the prediction of micro-p<italic toggle="yes">K</italic><sub>a</sub>. It is impressive that in many cases the capability of Graph-p<italic toggle="yes">K</italic><sub>a</sub> to locate the most acidic/basic sites of molecules is equivalent to or better than that of human experts, while all the chemical insight has been learned without explicit supervision in multi-instance learning. It can be expected that when there are more available training data in the future, the capability will be further improved.</p>
    </sec>
    <sec>
      <title>3.4 Visualization of the atomic embeddings</title>
      <p>In order to visualize the features of the atoms learned by the Graph-p<italic toggle="yes">K</italic><sub>a</sub> model, the embeddings in the last hidden layer of several types of acidic ionization sites in the training data were extracted and submitted to principal component analysis. As shown in <xref rid="btab714-F6" ref-type="fig">Figure 6</xref>, after training, the atomic embeddings from phenol hydroxyl, carboxyl, and sulfonamide groups were respectively gathered together. However, the distributions of atomic embeddings from alcoholic hydroxyl and amide groups were still relatively dispersed. These patterns suggest that alcoholic hydroxyl or amide groups in different chemical environments exhibit relatively larger variances, posing challenges for accurate micro-p<italic toggle="yes">K</italic><sub>a</sub> prediction. We speculated that a possible reason was that, although alcoholic hydroxyl and amide groups widely existed in the training set, they have less contribution to the macro-p<italic toggle="yes">K</italic><sub>a</sub> of the whole molecule due to their weak acidity. Therefore, they had lower weights and were less supervised during model training. Three molecules and their atomic embeddings visually display such a situation. After training, the atomic embeddings from carboxyl groups of the three similar molecules are close, whereas the atomic embeddings from amide groups of the three molecules are dispersed. Apparently, adding more samples whose dominant ionization groups are alcoholic hydroxyl groups or amide groups into training data may alleviate this problem.</p>
      <fig position="float" id="btab714-F6">
        <label>Fig. 6.</label>
        <caption>
          <p>Visualizing the atomic embeddings in last hidden layer using principal component analysis</p>
        </caption>
        <graphic xlink:href="btab714f6" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.5 Web server for the prediction of p<italic toggle="yes">K</italic><sub>a</sub></title>
      <p>For the convenience of the community, a free web server wrapping the Graph-p<italic toggle="yes">K</italic><sub>a</sub> model has been developed (<ext-link xlink:href="https://pka.simm.ac.cn/" ext-link-type="uri">https://pka.simm.ac.cn/</ext-link>). This web server was built using the python language and could be simultaneously accessed by multiple users. The web server can take multiple types of inputs including drawing a molecule from the molecular editor or uploading a txt/mol/sdf file. There are two main functions in this web server: p<italic toggle="yes">K</italic><sub>a</sub> prediction and similarity search (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S5</xref>). In the p<italic toggle="yes">K</italic><sub>a</sub> prediction module, the most acidic/basic p<italic toggle="yes">K</italic><sub>a</sub> values and their corresponding micro-p<italic toggle="yes">K</italic><sub>a</sub> values of the input molecule are predicted. The Monte Carlo dropout is used to evaluate the uncertainty of the prediction results and calculate the 95% confidence interval of the predicted value (<xref rid="btab714-B6" ref-type="bibr">Gal and Ghahramani, 2016</xref>). It is noteworthy that, due to our definition of possible ionization sites and the processing of input molecules, the web server does not support the p<italic toggle="yes">K</italic><sub>a</sub> prediction for C-H bonds and ionized molecules. In the similarity search module, the most acidic/basic atoms of the molecules from the S-p<italic toggle="yes">K</italic><sub>a</sub> dataset and the most acidic/basic atoms of the molecule input by the user are first predicted by Graph-p<italic toggle="yes">K</italic><sub>a</sub>. Then, the embeddings of those predicted most acidic/basic atoms in the last hidden layer are extracted. Finally, the Euclidean distances between the atomic embeddings of the input molecule and that of the molecules in the S-p<italic toggle="yes">K</italic><sub>a</sub> dataset are calculated. If the Euclidean distance is close enough (the threshold is set as less than 0.05), molecules are considered to be similar, and for each input molecule, up to four similar molecules and their experimentally determined p<italic toggle="yes">K</italic><sub>a</sub> values will be output for reference.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusions</title>
    <p>In this work, we have developed a novel in silico p<italic toggle="yes">K</italic><sub>a</sub> prediction model named Graph-p<italic toggle="yes">K</italic><sub>a</sub>. Combining multi-instance learning into graph neural network, Graph-p<italic toggle="yes">K</italic><sub>a</sub> not only outperforms those conventional machine learning models based on molecular fingerprints in predicting macro-p<italic toggle="yes">K</italic><sub>a</sub>, but more significantly, can learn the micro-p<italic toggle="yes">K</italic><sub>a</sub> values of atoms through training against the macro-p<italic toggle="yes">K</italic><sub>a</sub> values of molecules. A Turing-like test demonstrated that it gained chemical insights to locate the most acidic/basic sites of molecules, which compared favorably with that of human experts. Such micro-p<italic toggle="yes">K</italic><sub>a</sub> inference ability greatly enhances the interpretability and practicability of this model. Furthermore, in Graph-p<italic toggle="yes">K</italic><sub>a</sub>, the fitting and prediction of macro-p<italic toggle="yes">K</italic><sub>a</sub> are all dependent on the reasoning of micro-p<italic toggle="yes">K</italic><sub>a</sub>, which can also avoid shortcut learning to some extent (<xref rid="btab714-B8" ref-type="bibr">Geirhos <italic toggle="yes">et al.</italic>, 2020</xref>). In the end, a Web application based on Graph-p<italic toggle="yes">K</italic><sub>a</sub> model has been made freely available at <ext-link xlink:href="https://pka.simm.ac.cn" ext-link-type="uri">https://pka.simm.ac.cn</ext-link>.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the Project supported by Shanghai Municipal Science and Technology Major Project, National Natural Science Foundation of China [81773634] and Tencent AI Lab Rhino-Bird Focused Research Program [JR202002].</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared. </p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btab714_Supplementary_Data</label>
      <media xlink:href="btab714_supplementary_data.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btab714-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bartmess</surname><given-names>J.E.</given-names></string-name></person-group> (<year>2010</year>) <italic toggle="yes">The Brønsted Acid/Base Character of Hydroxylamines, Oximes and Hydroxamic Acids. Patai's Chemistry of Functional Groups</italic>.  John Wiley &amp; Sons, Ltd., Chichester, UK.</mixed-citation>
    </ref>
    <ref id="btab714-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carbonneau</surname><given-names>M.-A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Multiple instance learning: a survey of problem characteristics and applications</article-title>. <source>Pattern Recognit</source>., <volume>77</volume>, <fpage>329</fpage>–<lpage>353</lpage>.</mixed-citation>
    </ref>
    <ref id="btab714-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Charifson</surname><given-names>P.S.</given-names></string-name>, <string-name><surname>Walters</surname><given-names>W.P.</given-names></string-name></person-group> (<year>2014</year>) <article-title>Acidic and basic drugs in medicinal chemistry: a perspective</article-title>. <source>J. Med. Chem</source>., <volume>57</volume>, <fpage>9701</fpage>–<lpage>9717</lpage>.<pub-id pub-id-type="pmid">25180901</pub-id></mixed-citation>
    </ref>
    <ref id="btab714-B4">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Defferrard</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) Convolutional neural networks on graphs with fast localized spectral filtering. In: <italic toggle="yes">Proceedings of the 30th International Conference on Neural Information Processing Systems</italic>. New York, USA, pp. <fpage>3844</fpage>–<lpage>3852</lpage>.</mixed-citation>
    </ref>
    <ref id="btab714-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Duvenaud</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) Convolutional networks on graphs for learning molecular fingerprints. In: <italic toggle="yes">Proceedings of the 28th International Conference on Neural Information Processing Systems,</italic> Montreal, Canada, pp. <fpage>2224</fpage>–<lpage>2232</lpage>.</mixed-citation>
    </ref>
    <ref id="btab714-B6">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gal</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Ghahramani</surname><given-names>Z.</given-names></string-name></person-group> (<year>2016</year>) Dropout as a Bayesian approximation: representing model uncertainty in deep learning. In: <italic toggle="yes">International Conference on Machine Learning</italic>. New York, USA, pp. <fpage>1050</fpage>–<lpage>1059</lpage>.</mixed-citation>
    </ref>
    <ref id="btab714-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gaulton</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>The ChEMBL database in 2017</article-title>. <source>Nucleic Acids Res</source>., <volume>45</volume>, <fpage>D945</fpage>–<lpage>D954</lpage>.<pub-id pub-id-type="pmid">27899562</pub-id></mixed-citation>
    </ref>
    <ref id="btab714-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Geirhos</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Shortcut learning in deep neural networks</article-title>. <source>Nat. Mach. Intell</source>., <volume>2</volume>, <fpage>665</fpage>–<lpage>673</lpage>.</mixed-citation>
    </ref>
    <ref id="btab714-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gilmer</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) Neural message passing for quantum chemistry. In: <italic toggle="yes">International Conference on Machine Learning</italic>. Sydney, Australia, pp. 1263–1272.</mixed-citation>
    </ref>
    <ref id="btab714-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hunt</surname><given-names>P.A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Predicting pKa using a combination of semi-empirical quantum mechanics and radial basis function methods</article-title>. <source>J. Chem Inf. Model</source>., <volume>60</volume>, <fpage>2989</fpage>–<lpage>2997</lpage>.<pub-id pub-id-type="pmid">32357002</pub-id></mixed-citation>
    </ref>
    <ref id="btab714-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Işık</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>pka measurements for the sampl6 prediction challenge for a set of kinase inhibitor-like fragments</article-title>. <source>J. Comput. Aided Mol. Des</source>., <volume>32</volume>, <fpage>1117</fpage>–<lpage>1138</lpage>.<pub-id pub-id-type="pmid">30406372</pub-id></mixed-citation>
    </ref>
    <ref id="btab714-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manallack</surname><given-names>D.T.</given-names></string-name></person-group> (<year>2007</year>) <article-title>The pKa distribution of drugs: application to drug discovery</article-title>. <source>Perspect. Med. Chem</source>., <volume>1</volume>, <fpage>25</fpage>–<lpage>28</lpage>.</mixed-citation>
    </ref>
    <ref id="btab714-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manallack</surname><given-names>D.T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>The significance of acid/base properties in drug discovery</article-title>. <source>Chem. Soc. Rev</source>., <volume>42</volume>, <fpage>485</fpage>–<lpage>496</lpage>.<pub-id pub-id-type="pmid">23099561</pub-id></mixed-citation>
    </ref>
    <ref id="btab714-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mansouri</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Open-source QSAR models for pKa prediction using multiple machine learning approaches</article-title>. <source>J. Cheminf</source>., <volume>11</volume>, <fpage>1</fpage>–<lpage>20</lpage>.</mixed-citation>
    </ref>
    <ref id="btab714-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Niepert</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) Learning convolutional neural networks for graphs. In: <italic toggle="yes">International Conference on Machine Learning</italic>. New York, USS, pp. 2014–2023.</mixed-citation>
    </ref>
    <ref id="btab714-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roszak</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Rapid and accurate prediction of p K a values of C–H acids using graph convolutional neural networks</article-title>. <source>J. Am. Chem. Soc</source>., <volume>141</volume>, <fpage>17142</fpage>–<lpage>17149</lpage>.<pub-id pub-id-type="pmid">31633925</pub-id></mixed-citation>
    </ref>
    <ref id="btab714-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rupp</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) <article-title>Predicting the pKa of small molecules</article-title>. <source>Comb. Chem. High Throughput Screen</source>., <volume>14</volume>, <fpage>307</fpage>–<lpage>327</lpage>.<pub-id pub-id-type="pmid">21470178</pub-id></mixed-citation>
    </ref>
    <ref id="btab714-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Graph convolutional networks for computational drug development and discovery</article-title>. <source>Brief. Bioinform</source>., <volume>21</volume>, <fpage>919</fpage>–<lpage>935</lpage>.<pub-id pub-id-type="pmid">31155636</pub-id></mixed-citation>
    </ref>
    <ref id="btab714-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>RMDL: recalibrated multi-instance deep learning for whole slide gastric image classification</article-title>. <source>Med. Image Anal</source>., <volume>58</volume>, <fpage>101549</fpage>.<pub-id pub-id-type="pmid">31499320</pub-id></mixed-citation>
    </ref>
    <ref id="btab714-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wishart</surname><given-names>D.S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>DrugBank 5.0: a major update to the DrugBank database for 2018</article-title>. <source>Nucleic Acids Res</source>., <volume>46</volume>, <fpage>D1074</fpage>–<lpage>D1082</lpage>.<pub-id pub-id-type="pmid">29126136</pub-id></mixed-citation>
    </ref>
    <ref id="btab714-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xiong</surname><given-names>Z.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Pushing the boundaries of molecular representation for drug discovery with the graph attention mechanism</article-title>. <source>J. Med. Chem</source>., <volume>63</volume>, <fpage>8749</fpage>–<lpage>8760</lpage>.<pub-id pub-id-type="pmid">31408336</pub-id></mixed-citation>
    </ref>
    <ref id="btab714-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Q.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Holistic prediction of pKa in diverse solvents based on machine-learning approach</article-title>. <source>Angew. Chem. Int. Ed</source>., <volume>59</volume>, <fpage>19282</fpage>–<lpage>19291</lpage>.</mixed-citation>
    </ref>
    <ref id="btab714-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yap</surname><given-names>C.W.</given-names></string-name></person-group> (<year>2011</year>) <article-title>PaDEL‐descriptor: an open source software to calculate molecular descriptors and fingerprints</article-title>. <source>J. Comput. Chem</source>., <volume>32</volume>, <fpage>1466</fpage>–<lpage>1474</lpage>.<pub-id pub-id-type="pmid">21425294</pub-id></mixed-citation>
    </ref>
    <ref id="btab714-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Z.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>FraGAT: a fragment-oriented multi-scale graph attention model for molecular property prediction</article-title>. <source>Bioinformatics</source>, <volume>37</volume>, <fpage>2981</fpage>–<lpage>2987</lpage>.<pub-id pub-id-type="pmid">33769437</pub-id></mixed-citation>
    </ref>
    <ref id="btab714-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) Adaptive pooling in multi-instance learning for web video annotation. In: <italic toggle="yes">Proceedings of the IEEE International Conference on Computer Vision Workshops</italic>. Venice, Italy, pp. <fpage>318</fpage>–<lpage>327</lpage>.</mixed-citation>
    </ref>
    <ref id="btab714-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>Z.-H.</given-names></string-name></person-group> (<year>2018</year>) <article-title>A brief introduction to weakly supervised learning</article-title>. <source>Natl. Sci. Rev</source>., <volume>5</volume>, <fpage>44</fpage>–<lpage>53</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
