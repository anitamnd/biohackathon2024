<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinform Adv</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinform Adv</journal-id>
    <journal-id journal-id-type="publisher-id">bioadv</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics Advances</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2635-0041</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9194947</article-id>
    <article-id pub-id-type="pmid">35722206</article-id>
    <article-id pub-id-type="doi">10.1093/bioadv/vbac033</article-id>
    <article-id pub-id-type="publisher-id">vbac033</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Article</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Sufficient principal component regression for pattern discovery in transcriptomic data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Ding</surname>
          <given-names>Lei</given-names>
        </name>
        <aff><institution>Department of Statistics, Indiana University</institution>, Bloomington, IN 47405, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-0801-7646</contrib-id>
        <name>
          <surname>Zentner</surname>
          <given-names>Gabriel E</given-names>
        </name>
        <aff><institution>Department of Biology, Indiana University</institution>, Bloomington, IN 47405, <country country="US">USA</country></aff>
        <aff><institution>Indiana University Melvin and Bren Simon Comprehensive Cancer Center</institution>, Indianapolis, IN 46202, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-0443-4282</contrib-id>
        <name>
          <surname>McDonald</surname>
          <given-names>Daniel J</given-names>
        </name>
        <aff><institution>Department of Statistics, University of British Columbia</institution>, Vancouver, BC, <country country="CA">Canada</country></aff>
        <xref rid="vbac033-cor1" ref-type="corresp"/>
        <!--daniel@stat.ubc.ca-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Mulder</surname>
          <given-names>Nicola</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="vbac033-cor1">To whom correspondence should be addressed. Email: <email>daniel@stat.ubc.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-05-14">
      <day>14</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>14</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <volume>2</volume>
    <issue>1</issue>
    <elocation-id>vbac033</elocation-id>
    <history>
      <date date-type="received">
        <day>12</day>
        <month>11</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>16</day>
        <month>3</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>03</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>04</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>13</day>
        <month>6</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="vbac033.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Methods for the global measurement of transcript abundance such as microarrays and RNA-Seq generate datasets in which the number of measured features far exceeds the number of observations. Extracting biologically meaningful and experimentally tractable insights from such data therefore requires high-dimensional prediction. Existing sparse linear approaches to this challenge have been stunningly successful, but some important issues remain. These methods can fail to select the correct features, predict poorly relative to non-sparse alternatives or ignore any unknown grouping structures for the features.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We propose a method called SuffPCR that yields improved predictions in high-dimensional tasks including regression and classification, especially in the typical context of omics with correlated features. SuffPCR first estimates sparse principal components and then estimates a linear model on the recovered subspace. Because the estimated subspace is sparse in the features, the resulting predictions will depend on only a small subset of genes. SuffPCR works well on a variety of simulated and experimental transcriptomic data, performing nearly optimally when the model assumptions are satisfied. We also demonstrate near-optimal theoretical guarantees.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>Code and raw data are freely available at <ext-link xlink:href="https://github.com/dajmcdon/suffpcr" ext-link-type="uri">https://github.com/dajmcdon/suffpcr</ext-link>. Package documentation may be viewed at <ext-link xlink:href="https://dajmcdon.github.io/suffpcr" ext-link-type="uri">https://dajmcdon.github.io/suffpcr</ext-link>.</p>
      </sec>
      <sec id="s4">
        <title>Contact</title>
        <p>
          <email>daniel@stat.ubc.ca</email>
        </p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics Advances</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Science Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>DMS–1753171</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R35GM128631</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Sciences and Engineering Research Council of Canada</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NSERC</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000038</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>RGPIN-2021-02618</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Global transcriptome measurement with microarrays and RNA-Seq is a staple approach in many areas of biological research and has yielded numerous insights into gene regulation. Given data from such experiments, it is often desirable to identify a small number of transcripts whose expression levels are associated with a phenotype of interest (for instance, disease-free survival of cancer patients). Indeed, projects such as The Cancer Genome Atlas have aimed to generate massive volumes of such data to enable molecular characterization of various cancers. While these data are readily available, their high-dimensional nature (tens of thousands of transcript measurements from a single experiment) makes identification of a compact gene expression signature statistically and computationally challenging. While the identification of a minimal gene expression signature is valuable in evaluating disease prognosis, it is also helpful for guiding experimental exploration. In practical terms, a set of five genes highly associated with a certain disease phenotype can be characterized more rapidly, at lower cost, and in more depth than a set of 50 or 100 such genes using genetic techniques such as CRISPR knockout and cancer biological methods such as xenotransplantation of genetically modified cells into mice. Therefore, this article prioritizes selecting a small subset of transcript measurements, which still provide an accurate prediction of phenotypes.</p>
    <p>With these goals in mind, supervised linear regression techniques such as ridge regression (<xref rid="vbac033-B19" ref-type="bibr">Hoerl and Kennard, 1970</xref>), the lasso (<xref rid="vbac033-B34" ref-type="bibr">Tibshirani, 1996</xref>), elastic net (<xref rid="vbac033-B39" ref-type="bibr">Zou and Hastie, 2005</xref>) or other penalized methods are often employed. More commonly, especially in genomics applications, the outcomes of interest tend to be the result of groups of genes, which perhaps together describe more complicated processes. Therefore, researchers often turn to unsupervised methods such as principal component analysis (PCA), principal component regression (PCR) and partial least squares (PLS) for both preprocessing and as predictive models (e.g. <xref rid="vbac033-B7" ref-type="bibr">Cera <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="vbac033-B15" ref-type="bibr">Harel <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="vbac033-B22" ref-type="bibr">Kabir <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="vbac033-B35" ref-type="bibr">Traglia <italic toggle="yes">et al.</italic>, 2017</xref>).</p>
    <p>In genomics, one may collect expression measurements for thousands of genes from microarrays or RNA-Seq with the goal of predicting phenotypes or class outcomes. In these settings, the number of patients is much smaller than the number of gene measurements and researchers are interested in (i) the accurate prediction of the phenotype, (ii) the correct identification of a handful of predictive genes and (iii) computational tractability. Among these properties, the correct identification of a small number of predictive genes is of crucial importance in practice, since it can lead biologists to further investigate specific genes through CRISPR knockout or other techniques. It is this genetic pattern discovery for which our proposed methodology is intended: data with many more measurements than observations; the potential that some of the measurements may be grouped or correlated; the existence of either a continuous or discrete outcome we wish to predict; and the belief that these predictions only depend on some small collection of groups rather than the entire set of measurements.</p>
    <sec>
      <title>1.1 Recent related work</title>
      <p>PCA has two main drawbacks when used in high dimensions. The first is that PCA is non-sparse, so it uses information from all the available genes instead of selecting only those which are important, a key objective in omics applications. That is, the right singular vectors or ‘eigengenes’ (<xref rid="vbac033-B1" ref-type="bibr">Alter <italic toggle="yes">et al.</italic>, 2000</xref>) depend on all the genes measured rather than a small collection. The second is that these sample principal components are not consistent estimators of the population parameters in high dimensions (<xref rid="vbac033-B21" ref-type="bibr">Johnstone and Lu, 2009</xref>). This means essentially that when the number of patients is smaller than the number of genes, even if the first eigengene could perfectly explain the data, PCA will not be able to recover it.</p>
      <p>Modern approaches specifically for pattern discovery in the genomics context such as supervised gene shaving (<xref rid="vbac033-B16" ref-type="bibr">Hastie <italic toggle="yes">et al.</italic>, 2000</xref>), tree harvesting (<xref rid="vbac033-B17" ref-type="bibr">Hastie <italic toggle="yes">et al.</italic>, 2001</xref>) and supervised principal components (SPC) (<xref rid="vbac033-B4" ref-type="bibr">Bair and Tibshirani, 2004</xref>; <xref rid="vbac033-B5" ref-type="bibr">Bair <italic toggle="yes">et al.</italic>, 2006</xref>; <xref rid="vbac033-B30" ref-type="bibr">Paul <italic toggle="yes">et al.</italic>, 2008</xref>) seek to combine the presence of the phenotype with the structure estimation properties of eigendecompositions on the gene expression measurements using unsupervised techniques to obtain the best of both. PLS is common in genomics (e.g. <xref rid="vbac033-B8" ref-type="bibr">Chakraborty, 2019</xref>; <xref rid="vbac033-B24" ref-type="bibr">Leek and Storey, 2007</xref>), though it remains uncommon in statistics and machine learning, and its theoretical properties are poorly understood. Other recent PCA-based approaches for genetics, though not directly applicable for prediction are SMSSVD (<xref rid="vbac033-B18" ref-type="bibr">Henningsson and Fontes, 2019</xref>) and ESPCA (<xref rid="vbac033-B29" ref-type="bibr">Min <italic toggle="yes">et al.</italic>, 2018</xref>).</p>
    </sec>
    <sec>
      <title>1.2 Contributions</title>
      <p>In this paper, we leverage the strong theoretical properties associated with sparse PCA to improve predictive accuracy for regression and classification problems in genomics. We avoid the strong assumptions necessary for SPC, the current state-of-the-art, while obtaining the benefits associated with sparse subspace estimation. In the case that the phenotype is actually generated as a linear function of a handful of genes, our method, SuffPCR, performs nearly optimally: it does as well as if we had known which genes were relevant beforehand. Furthermore, we justify theoretically that our procedure can both predict accurately and recover the correct genes. Our contributions can be succinctly summarized as follows:
</p>
      <list list-type="order">
        <list-item>
          <p>We present a methodology for discovering small sets of predictive genes using sparse PCA;</p>
        </list-item>
        <list-item>
          <p>Our method improves the computational properties of existing sparse subspace estimation approaches to enable previously impossible inference when the number of genes is very large;</p>
        </list-item>
        <list-item>
          <p>We demonstrate state-of-the-art performance of our method in synthetic examples and with standard cancer microarray measurements;</p>
        </list-item>
        <list-item>
          <p>We provide near-optimal theoretical guarantees.</p>
        </list-item>
      </list>
      <p>Our methodology can be used in a variety of genomic pattern discovery settings. One such example is a modified version of traditional differential expression analysis. If we have treatment and control measurements, the logistic version of our method is appropriate with the advantage that it examines the impact of one gene adjusted for the contributions of others. In addition, with a continuous treatment, the detection power can be increased relative to using an artificial dichotomization.</p>
      <p>In Section 2.1, we motivate the desire for <italic toggle="yes">sufficient</italic> PCR relative to previous approaches and present details of SuffPCR. Section 2.2 illustrates performance in simulated, semi-simulated and real examples (Section 2.3) and discusses the biological implications of our methods for a selection of cancers. Section 2.4 theoretically justifies our methods, providing guarantees for prediction accuracy and correct gene selection. Section 3 concludes.</p>
      <p><italic toggle="yes">Notation</italic>. We use bold uppercase letters to denote matrices, lowercase Arabic letters to denote row vectors and scalars and uppercase Arabic letters for random variables. Let <italic toggle="yes">Y</italic> be a random, real-valued <italic toggle="yes">n</italic>-vector of independent variables <italic toggle="yes">Y<sub>i</sub></italic>, and <bold>X</bold> be the row-wise concatenation of i.i.d. draws <italic toggle="yes">X<sub>i</sub></italic> from a distribution on <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> with covariance <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mi mathvariant="bold">Σ</mml:mi></mml:math></inline-formula>. We denote the observed realization of the outcome variable <italic toggle="yes">Y</italic> as <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>. To be explicit in the genomics context, <bold>X</bold> is an <italic toggle="yes">n </italic>×<italic toggle="yes"> p</italic> matrix where each row is a set of transcriptomic measurements from RNA-Seq or microarrays for a patient while <italic toggle="yes">y<sub>i</sub></italic> is an observed phenotype of interest for the <italic toggle="yes">i</italic>th patient. Because <bold>X</bold> is a matrix, this symbol represents both a random matrix and its realization. In the following, the meaning should be clear from the context. We assume, without loss of generality, that <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and that the measurements <bold>X</bold> have been centered. The singular value decomposition of a matrix <bold>A</bold> is <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">A</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="bold">Λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. In the specific case of <bold>X</bold>, we suppress the dependence on <bold>X</bold> in the notation and write <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">U</mml:mi><mml:mo>Λ</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>. We write <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> to indicate the first <italic toggle="yes">d</italic> columns of the matrix <bold>A</bold> and <italic toggle="yes">a<sub>j</sub></italic> to denote the <italic toggle="yes">j</italic>th row. In the case of the identity matrix, we use a subscript to denote its dimension when necessary: <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Let <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denote the sum of the diagonal entries of <bold>A</bold> while <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> is the squared Frobenius norm of <bold>A</bold>. <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> denotes (2, 0)-norm of <bold>A</bold>, that is the number of rows in <bold>A</bold> that have non-zero <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> norm. <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the sum of the row-wise <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> norms. Finally, <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the indicator function for the expression <italic toggle="yes">a</italic>, taking value 1 if <italic toggle="yes">a</italic> is true or 0 if not.</p>
    </sec>
  </sec>
  <sec>
    <title>2 Methods</title>
    <p>SPC (<xref rid="vbac033-B4" ref-type="bibr">Bair and Tibshirani, 2004</xref>; <xref rid="vbac033-B5" ref-type="bibr">Bair <italic toggle="yes">et al.</italic>, 2006</xref>; <xref rid="vbac033-B30" ref-type="bibr">Paul <italic toggle="yes">et al.</italic>, 2008</xref>) is widely used for solving high-dimensional prediction and feature selection problems. It targets dimension reduction and sparsity simultaneously by first screening genes [or individual messenger RNA (mRNA) probes] based on their marginal correlation with the phenotype (or likelihood ratio test in the case of non-Gaussian noise). Then, it performs PCA on this selected subset and regresses the phenotype on the resulting components (possibly with additional penalization). This procedure is computationally simple, but, zero population marginal correlation is neither necessary nor sufficient to guarantee that the associated population regression coefficient is zero. To make this statement mathematically precise, consider the linear model <inline-formula id="IE160"><mml:math id="IM150" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mi>β</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> where <italic toggle="yes">Y<sub>i</sub></italic> is a real-valued scalar phenotype, <italic toggle="yes">X<sub>i</sub></italic> is a real-valued vector of genes, <inline-formula id="IE17"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> is the true (unknown) coefficient vector and <italic toggle="yes">ϵ<sub>i</sub></italic> is a mean-zero error. Defining as above <inline-formula id="IE18"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mtext>Cov</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE19"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:mtext>Cov</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>Φ</mml:mo></mml:mrow></mml:math></inline-formula>, then, for this procedure to correctly recover the true nonzero components of <inline-formula id="IE20"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>, it requires
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>Φ</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>⇒</mml:mo><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>Φ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mrow></mml:math></disp-formula></p>
    <p>In words, we assume that the dot product of the <italic toggle="yes">j</italic>th row of the precision matrix with the marginal covariance between <italic toggle="yes">x</italic> and <italic toggle="yes">y</italic> is zero whenever the <italic toggle="yes">j</italic>th element of <inline-formula id="IE21"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mo>Φ</mml:mo></mml:math></inline-formula> is zero. While reasonable in some settings, this assumption frequently fails. For example, individual features may only be predictive of the response in the presence of other features. To illustrate why this assumption fails for genomics problems, we examine a motivating counterexample. Using mRNA measurements for acute myeloid leukemia (AML, <xref rid="vbac033-B6" ref-type="bibr">Bullinger <italic toggle="yes">et al.</italic> 2004</xref>), we estimate both <inline-formula id="IE22"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE23"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mo>Φ</mml:mo></mml:math></inline-formula> and proceed as if these estimates are the true population quantities. To estimate <inline-formula id="IE24"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mo>Φ</mml:mo></mml:math></inline-formula>, we use the empirical covariance and set all but the largest <italic toggle="yes">n </italic>=<italic toggle="yes"> </italic>116 values equal to zero, corresponding to an extremely sparse estimate. For <inline-formula id="IE25"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, we use the Graphical Lasso (<xref rid="vbac033-B13" ref-type="bibr">Friedman <italic toggle="yes">et al.</italic>, 2008</xref>) for all <italic toggle="yes">p </italic>=<italic toggle="yes"> </italic>6283 genes at different sparsity levels ranging from 100% sparse (<inline-formula id="IE26"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for all <inline-formula id="IE27"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>) to 95% sparse. We then create a pseudotrue <inline-formula id="IE28"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>Φ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> as in <xref rid="E1" ref-type="disp-formula">Equation (1)</xref>. This is essentially the most favorable condition for SPC. To reiterate, in order to evaluate this assumption, we create <inline-formula id="IE29"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> based on estimates from real genetics data that are highly sparse. But, as we will see below, because the inverse covariance matrix is not ‘sparse in the right way’, SPC will have a very high false negative rate and ignore important genes.</p>
    <p><xref rid="vbac033-T1" ref-type="table">Table 1</xref> shows the sparsity of <inline-formula id="IE30"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, the percent of non-zero regression coefficients, and the percent of non-zero regression coefficients which are incorrectly ignored under the assumption (the false negative rate). Even if the precision matrix is 99.9% sparse, the false negative rate is over 40%, meaning we find fewer than 60% of the true genes. If the sparsity of <inline-formula id="IE31"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is allowed to decrease only slightly, the false negative rate increases to over 95%. Clearly, this screening procedure will ignore many important genes in even the most favorable conditions for SPC.</p>
    <table-wrap position="float" id="vbac033-T1">
      <label>Table 1.</label>
      <caption>
        <p>Illustration of the failure of <xref rid="E1" ref-type="disp-formula">Equation (1)</xref> on the AML data</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="center" span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
        </colgroup>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">% sparsity of <inline-formula id="IE32"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula></td>
            <td rowspan="1" colspan="1">100</td>
            <td rowspan="1" colspan="1">99.9</td>
            <td rowspan="1" colspan="1">99.6</td>
            <td rowspan="1" colspan="1">98.9</td>
            <td rowspan="1" colspan="1">97.5</td>
            <td rowspan="1" colspan="1">95.3</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">% non-zero <inline-formula id="IE33"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>’s</td>
            <td rowspan="1" colspan="1">1.8</td>
            <td rowspan="1" colspan="1">3.3</td>
            <td rowspan="1" colspan="1">8.4</td>
            <td rowspan="1" colspan="1">23.5</td>
            <td rowspan="1" colspan="1">50.2</td>
            <td rowspan="1" colspan="1">77.9</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">False negative rate</td>
            <td rowspan="1" colspan="1">0.000</td>
            <td rowspan="1" colspan="1">0.431</td>
            <td rowspan="1" colspan="1">0.778</td>
            <td rowspan="1" colspan="1">0.921</td>
            <td rowspan="1" colspan="1">0.963</td>
            <td rowspan="1" colspan="1">0.976</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>More recent work has attempted to avoid this assumption. <xref rid="vbac033-B11" ref-type="bibr">Ding and McDonald (2017)</xref> uses the initially selected set of features to approximate the information lost in the screening step via techniques from numerical linear algebra. An alternative discussed in <xref rid="vbac033-B31" ref-type="bibr">Piironen and Vehtari (2018)</xref> iterates the screening step with the prediction step, adding back features which correlate with the residual. Finally, <xref rid="vbac033-B33" ref-type="bibr">Tay <italic toggle="yes">et al.</italic> (2018)</xref> assumes that feature groupings are known and and estimates separate subspaces for different groups. All these methodologies are tailored to perform well when <inline-formula id="IE34"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mo>Φ</mml:mo></mml:math></inline-formula> and <inline-formula id="IE35"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> have particular compatible structures.</p>
    <p>On the other hand, it is important to observe that a sufficient condition for <inline-formula id="IE36"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> in <xref rid="E1" ref-type="disp-formula">Equation (1)</xref> is that the <italic toggle="yes">j</italic>th row of the left eigenvectors of <inline-formula id="IE37"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mi mathvariant="bold">Σ</mml:mi></mml:math></inline-formula> is 0. Based on this intuition, we develop sufficient PCR (abbreviated as SuffPCR) which leverages this insight: row sparse eigenvectors imply sparse coefficients, and hence depend on only a subset of genes. SuffPCR is tailored to the case that <bold>X</bold> lies approximately on a low-dimensional linear manifold which depends on a small subset of features. Because the linear manifold depends on only some of the features, <inline-formula id="IE38"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> does as well.</p>
    <sec>
      <title>2.1 Prediction with principal components</title>
      <p>PCA is a canonical unsupervised dimension reduction method when it is reasonable to imagine that <bold>X</bold> lies on (or near) a low-dimensional linear manifold. It finds the best <italic toggle="yes">d</italic>-dimensional approximation of the span of <bold>X</bold> such that the reconstruction error in <inline-formula id="IE39"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> norm is minimized. This problem is equivalent to maximizing the variance explained by the projection:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:munder><mml:mo> </mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">S</mml:mi><mml:mi mathvariant="bold">V</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo> </mml:mo><mml:mtext>subject to</mml:mtext><mml:mo> </mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mi mathvariant="bold">V</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE40"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">S</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mi mathvariant="bold">X</mml:mi></mml:mrow></mml:math></inline-formula> is the sample covariance matrix. Let <inline-formula id="IE41"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">U</mml:mi><mml:mo>Λ</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, then the solution of this optimization problem is <inline-formula id="IE42"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, the first <italic toggle="yes">d</italic> right singular vectors, and the estimator of the first <italic toggle="yes">d</italic> principal components is <inline-formula id="IE43"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> or <inline-formula id="IE44"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> equivalently. Given an estimate of the principal components, PCR is simply ordinary least squares (OLS) regression of the phenotype on the derived components <inline-formula id="IE45"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. One can convert the lower-dimensional estimator, say <inline-formula id="IE46"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, back to the original space to reacquire an estimator of <inline-formula id="IE47"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> as <inline-formula id="IE48"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. Other generalized linear models can be used place of OLS to find <inline-formula id="IE49"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>.</p>
      <sec>
        <title>2.1.1 Sparse principal component analysis</title>
        <p>As discussed in Section 1.1, standard PCA works poorly in high dimensions. Much like the high-dimensional regression problem, estimating high-dimensional principal components is ill-posed without additional structure. To address this issue many authors have focused on different sparse PCA estimators for the case when <bold>V</bold> is sparse in some sense. Many of these methods achieve this goal by adding a penalty to <xref rid="E2" ref-type="disp-formula">Equation (2)</xref>. Of particular utility for the case of PCR when <inline-formula id="IE50"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> is sparse is to choose a penalty that results in row-sparse <bold>V</bold>. This intuition is justified by the following result.<statement id="mthst1"><p><sc>Proposition</sc> 1. <italic toggle="yes">Consider the linear model</italic> <inline-formula id="IE51"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mo>ϵ</mml:mo></mml:mrow></mml:math></inline-formula><italic toggle="yes">with</italic> <inline-formula id="IE52"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mrow><mml:mtext>Cov</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow></mml:math></inline-formula><italic toggle="yes">. Let</italic> <inline-formula id="IE53"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="bold">Λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula><italic toggle="yes">be the eigendecomposition of</italic> <inline-formula id="IE54"><mml:math id="IM53" display="inline" overflow="scroll"><mml:mi mathvariant="bold">Σ</mml:mi></mml:math></inline-formula><italic toggle="yes">with</italic> <inline-formula id="IE55"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula><italic toggle="yes">for</italic> <inline-formula id="IE56"><mml:math id="IM55" display="inline" overflow="scroll"><mml:mrow><mml:mi>j</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>d</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">Z</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula><italic toggle="yes">. Then</italic> <inline-formula id="IE57"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>v</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>⇒</mml:mo><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mrow></mml:math></inline-formula></p></statement></p>
        <p>The proof is immediate. For any <italic toggle="yes">j</italic>, if <inline-formula id="IE58"><mml:math id="IM57" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>v</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, then every element in <inline-formula id="IE59"><mml:math id="IM58" display="inline" overflow="scroll"><mml:mrow><mml:mi>v</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is 0, indicating the <inline-formula id="IE60"><mml:math id="IM59" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>th</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> row of <inline-formula id="IE61"><mml:math id="IM60" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> will be 0. Since <inline-formula id="IE62"><mml:math id="IM61" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>Φ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> where <inline-formula id="IE63"><mml:math id="IM62" display="inline" overflow="scroll"><mml:mrow><mml:mtext>Cov</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>Φ</mml:mo></mml:mrow></mml:math></inline-formula>, it also results in <inline-formula id="IE64"><mml:math id="IM63" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. This result stands in stark contrast to the assumption in <xref rid="E1" ref-type="disp-formula">Equation (1)</xref>. This proposition gives a guarantee rather than requiring an assumption: if the rows of <inline-formula id="IE65"><mml:math id="IM64" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are sparse, then <inline-formula id="IE66"><mml:math id="IM65" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> is sparse. The same intuition can easily be extended to the case <inline-formula id="IE67"><mml:math id="IM66" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for all <italic toggle="yes">j</italic> given a gap between the <italic toggle="yes">d</italic>th and <inline-formula id="IE68"><mml:math id="IM67" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> eigenvalues. In this setting, the natural analogue of PCA is the solution to:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:munder><mml:mo> </mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">S</mml:mi><mml:mi mathvariant="bold">V</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mo>λ</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo> </mml:mo><mml:mtext>subject to</mml:mtext><mml:mo> </mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mi mathvariant="bold">V</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>Solutions <inline-formula id="IE69"><mml:math id="IM68" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> of <xref rid="E3" ref-type="disp-formula">Equation (3)</xref> will give projection matrices onto the best <italic toggle="yes">d</italic>-dimensional linear manifold such that <inline-formula id="IE70"><mml:math id="IM69" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is row sparse. However, this problem is NP-hard.</p>
        <p>Many authors have developed different versions of sparse PCA. For example, <xref rid="vbac033-B9" ref-type="bibr">d’Aspremont <italic toggle="yes">et al.</italic> (2005)</xref> and <xref rid="vbac033-B40" ref-type="bibr">Zou <italic toggle="yes">et al.</italic> (2006)</xref> focus on the first principal component and add additional principal components iteratively to account for the variation left unexplained by the previous principal components. <xref rid="vbac033-B37" ref-type="bibr">Vu and Lei (2013)</xref> derive a rate-minimax lower bound, illustrating that no estimator can approach the population quantity faster than, essentially, <inline-formula id="IE71"><mml:math id="IM70" display="inline" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi><mml:msqrt><mml:mrow><mml:mi>d</mml:mi><mml:mo>/</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> where <italic toggle="yes">q</italic> is a deterministic function of <inline-formula id="IE72"><mml:math id="IM71" display="inline" overflow="scroll"><mml:mi mathvariant="bold">Σ</mml:mi></mml:math></inline-formula>. Later work in <xref rid="vbac033-B38" ref-type="bibr">Vu <italic toggle="yes">et al.</italic> (2013)</xref> proposes a convex relaxation to <xref rid="E3" ref-type="disp-formula">Equation (3)</xref> which finds the first <italic toggle="yes">d</italic> principal components simultaneously and nearly achieves the lower bound:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:munder><mml:mo> </mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">S</mml:mi><mml:mi mathvariant="bold">V</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mo>λ</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mtext>subject to</mml:mtext><mml:mo> </mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">F</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE73"><mml:math id="IM72" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">F</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mo>:</mml:mo><mml:mn>0</mml:mn><mml:mo> </mml:mo><mml:mo>⪯</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mo> </mml:mo><mml:mo>⪯</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mtext>and tr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> is a convex body called Fantope, motivating the name Fantope Projection and Selection (FPS). The authors solve the optimization problem in <xref rid="E4" ref-type="disp-formula">Equation (4)</xref> with an alternating direction method of multipliers (ADMM) algorithm.</p>
        <p>For these reasons, FPS is known as the current state-of-the-art sparse PCA estimator with the best performance. However, despite its theoretical justification, FPS is less useful in practice for solving prediction tasks, especially in genomics applications with <inline-formula id="IE74"><mml:math id="IM73" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≫</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> (rather than just <italic toggle="yes">p </italic>&gt;<italic toggle="yes"> n</italic>) for two reasons. First, the original ADMM algorithm has per-iteration computational complexity <inline-formula id="IE75"><mml:math id="IM74" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, which is a burden especially when <italic toggle="yes">p</italic> is large. Second, because of the convex relaxation using <xref rid="E4" ref-type="disp-formula">Equation (4)</xref> rather than <xref rid="E3" ref-type="disp-formula">Equation (3)</xref>, <inline-formula id="IE76"><mml:math id="IM75" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> from FPS tends to be entry-wise sparse, but infrequently row-wise sparse unless the signal-to-noise ratio (SNR) is very large (<italic toggle="yes">q</italic> is a function of this ratio). We give explicit formulas for the SNR under this model in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>, but heuristically, the SNR captures how well the data is described by a <italic toggle="yes">d</italic>-dimensional subspace through the relative magnitude of <inline-formula id="IE77"><mml:math id="IM76" display="inline" overflow="scroll"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> compared to <italic toggle="yes">p</italic>. In genomics applications with low SNR, which is common, estimates <inline-formula id="IE78"><mml:math id="IM77" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> tend to have large numbers of non-zero coefficients with very small estimated values. Thus, we design SuffPCR based on the insights from Proposition 1, utilizing the best sparse PCA estimator FPS and further addressing both of these issues to achieve better empirical performance while maintaining theoretical justification.</p>
      </sec>
      <sec>
        <title>2.1.2 Sufficient principal component regression</title>
        <p>In this section, we introduce SuffPCR. The main idea of SuffPCR is to detect the relationship between the phenotype <italic toggle="yes">Y</italic> and gene expression measurements <bold>X</bold> by making use of the (near) low-dimensional manifold that supports <bold>X</bold>. In broad outline, SuffPCR first uses a tailored version of FPS to produce a row-sparse estimate <inline-formula id="IE90"><mml:math id="IM89" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and then regresses <italic toggle="yes">Y</italic> on the derived components to produce sparse coefficient estimates. SuffPCR for regression is stated in Algorithm 1 and summarized visually in <xref rid="vbac033-F1" ref-type="fig">Figure 1</xref>. For ease of exposition, we remind the reader that <italic toggle="yes">Y</italic> and <bold>X</bold> are standardized so that <inline-formula id="IE91"><mml:math id="IM90" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">S</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mi mathvariant="bold">X</mml:mi></mml:mrow></mml:math></inline-formula> is the correlation matrix.</p>
        <fig position="float" id="vbac033-F1">
          <label>Fig. 1.</label>
          <caption>
            <p>Graphical depiction of Algorithm 1. Solid colors represent nonzero matrix entries</p>
          </caption>
          <graphic xlink:href="vbac033f1" position="float"/>
        </fig>
        <boxed-text id="vbac033-BOX1" position="float">
          <label>Algorithm 1</label>
          <caption>
            <p>SuffPCR (regression version)</p>
          </caption>
          <p>1: <bold>Input: X</bold>, <bold>S</bold>, <italic toggle="yes">y</italic>, <italic toggle="yes">d</italic>, <italic toggle="yes">λ</italic>.</p>
          <p>2: <inline-formula id="IE79"><mml:math id="IM78" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi><mml:mo>←</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold">C</mml:mi><mml:mo>←</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>    ▹ Initialization</p>
          <p>3: <bold>while</bold> not converged <bold>do</bold></p>
          <p>4: <inline-formula id="IE80"><mml:math id="IM79" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">A</mml:mi><mml:mo>←</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>Proj</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">F</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">B</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold">C</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold">S</mml:mi><mml:mo>/</mml:mo><mml:mo>λ</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> ▹ Approximate projection</p>
          <p>5: <inline-formula id="IE81"><mml:math id="IM80" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi><mml:mo>←</mml:mo><mml:mtext>Soft</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold">C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>       ▹ Elementwise soft-thresholding</p>
          <p>6: <inline-formula id="IE82"><mml:math id="IM81" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi><mml:mo>←</mml:mo><mml:mi mathvariant="bold">C</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold">B</mml:mi></mml:mrow></mml:math></inline-formula></p>
          <p>7: <bold>end while</bold></p>
          <p>8: Decompose <inline-formula id="IE83"><mml:math id="IM82" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> ▹ Rank <italic toggle="yes">d</italic> eigen decomposition</p>
          <p>9: Compute <inline-formula id="IE84"><mml:math id="IM83" display="inline" overflow="scroll"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, sort in descending order</p>
          <p>10: Choose <italic toggle="yes">t</italic> by applying Algorithm 2 to <italic toggle="yes">l</italic></p>
          <p>11: Set rows in <inline-formula id="IE85"><mml:math id="IM84" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> whose <inline-formula id="IE86"><mml:math id="IM85" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> norm is smaller than <italic toggle="yes">t</italic> as 0, and get <inline-formula id="IE87"><mml:math id="IM86" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></p>
          <p>12: Solve <inline-formula id="IE88"><mml:math id="IM87" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>argmin</mml:mtext></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>γ</mml:mo><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula></p>
          <p>13: <bold>Return:</bold><inline-formula id="IE89"><mml:math id="IM88" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula></p>
        </boxed-text>
        <p>The first issue is the time complexity of the original FPS algorithm. Essentially, FPS uses the same three steps depicted in Lines 4–6 in Algorithm 1.<disp-quote content-type="extract"><p><inline-formula id="IE92"><mml:math id="IM91" display="inline" overflow="scroll"><mml:mrow><mml:mn>4</mml:mn><mml:mo>′</mml:mo></mml:mrow></mml:math></inline-formula>. <inline-formula id="IE93"><mml:math id="IM92" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">A</mml:mi><mml:mo>←</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>Proj</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">F</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">B</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold">C</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold">S</mml:mi><mml:mo>/</mml:mo><mml:mo>λ</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p><p>5. <inline-formula id="IE94"><mml:math id="IM93" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi><mml:mo>←</mml:mo><mml:mtext>Soft</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold">C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> where <inline-formula id="IE95"><mml:math id="IM94" display="inline" overflow="scroll"><mml:mrow><mml:mtext>Soft</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>sign</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>max</mml:mi><mml:mo>{</mml:mo><mml:mo>|</mml:mo><mml:mi>b</mml:mi><mml:mo>|</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula></p><p>6. <inline-formula id="IE96"><mml:math id="IM95" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi><mml:mo>←</mml:mo><mml:mi mathvariant="bold">C</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold">B</mml:mi></mml:mrow></mml:math></inline-formula>.</p></disp-quote></p>
        <p>The only difference here between our implementation and that in FPS is in Step 4. Each of these steps takes a matrix and produces another matrix, where the matrices have <italic toggle="yes">p</italic><sup>2</sup> elements. The second and third steps are computationally simple (element-wise soft-thresholding and matrix addition). But the first, <inline-formula id="IE97"><mml:math id="IM96" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>Proj</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">F</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, is more challenging. The solution requires computing the eigendecomposition of <bold>Q</bold>, an <inline-formula id="IE98"><mml:math id="IM97" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> operation, and then modifying the eigenvalues of <bold>Q</bold> through the solution of a piecewise linear equation in <italic toggle="yes">τ</italic>: <inline-formula id="IE99"><mml:math id="IM98" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>+</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>min</mml:mi><mml:mo>{</mml:mo><mml:mi>max</mml:mi><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo>τ</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> with <italic toggle="yes">τ</italic> such that <inline-formula id="IE100"><mml:math id="IM99" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>min</mml:mi><mml:mo>{</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>+</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula>. The final result is then reconstructed as <inline-formula id="IE101"><mml:math id="IM100" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">A</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>. Because of the cubic complexity in <italic toggle="yes">p</italic>, the authors suggest the number of features should not exceed one thousand. But typical transcriptomics data have many thousands of gene measurements, and preliminary selection of a subset is suboptimal, as illustrated above. Due to the form of the piecewise solution, most eigenvalues will be set to 0. Thus, while we will generally require more than <italic toggle="yes">d</italic> eigenpairs, most are unnecessary, certainly fewer than <inline-formula id="IE102"><mml:math id="IM101" display="inline" overflow="scroll"><mml:mrow><mml:mi>min</mml:mi><mml:mo>{</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. Our implementation computes only a handful of eigenvectors corresponding to the largest eigenvalues, rather than all <italic toggle="yes">p</italic>. If we compute enough to ensure that some <inline-formula id="IE103"><mml:math id="IM102" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>+</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> will be 0, then the rest are as well. Our implementation uses Augmented Implicitly Restarted Lanczos Bidiagonalization (AIRLB; <xref rid="vbac033-B2" ref-type="bibr">Baglama and Reichel, 2005</xref>) as implemented in the irlba package (<xref rid="vbac033-B3" ref-type="bibr">Baglama <italic toggle="yes">et al.</italic>, 2019</xref>), though alternative techniques such as those in <xref rid="vbac033-B20" ref-type="bibr">Homrighausen and McDonald (2016)</xref>; <xref rid="vbac033-B14" ref-type="bibr">Gittens and Mahoney (2013)</xref> may work as well. We provide a more detailed discussion in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
        <p>For moderate problems (<inline-formula id="IE104"><mml:math id="IM103" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>≈</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula>), the truncated eigendecomposition with AIRLB rather than the full eigendecomposition leads to a three-fold speedup while the further incorporation of specialized initializations leads to an eight-fold improvement without any discernable loss of accuracy (results on a 2018 MacBook Pro with 2.7 GHz Quad-Core processor and 16GB of memory running maxOS 10.15). The results are similar when <italic toggle="yes">p </italic>=<italic toggle="yes"> </italic>5000, though the same experiment on a high-performance Intel Xeon E5-2680 v3 CPU with 12 cores, 256 GB of memory, and optimized BLAS were somewhat less dramatic (improvements of three-fold and four-fold respectively). For large RNA-Seq datasets (<inline-formula id="IE105"><mml:math id="IM104" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≈</mml:mo><mml:mn>20</mml:mn><mml:mo> </mml:mo><mml:mn>000</mml:mn></mml:mrow></mml:math></inline-formula>), we observed a nearly ten-fold improvement in computation time.</p>
        <p>The second issue is that the Fantope constraint in <xref rid="E4" ref-type="disp-formula">Equation (4)</xref> ensures only that <inline-formula id="IE106"><mml:math id="IM105" display="inline" overflow="scroll"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula> but not that the number of rows with non-zero <italic toggle="yes">l</italic><sub>2</sub>-norm is small. This feature of the convex relaxation results in many rows with small, but non-zero, row-norm resulting in dense estimates of <inline-formula id="IE107"><mml:math id="IM106" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. Thus, to make the final estimator <inline-formula id="IE108"><mml:math id="IM107" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> sparse, we hard-threshold rows in <inline-formula id="IE109"><mml:math id="IM108" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> whose <inline-formula id="IE110"><mml:math id="IM109" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> norm is small, as illustrated in line 9, 10 and 11 in Algorithm 1. From empirical experience, we have found that there is often a strong elbow-type behavior in the row-wise <inline-formula id="IE111"><mml:math id="IM110" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> norm of <inline-formula id="IE112"><mml:math id="IM111" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, similar to the Skree plot used to choose <italic toggle="yes">d</italic> in standard PCA. Therefore, we develop a simple procedure, Algorithm 2, to find the best threshold automatically. Essentially, it calculates the empirical derivative of the observation-weighted variances on each side of a potential threshold and maximizes their difference, resulting in signal and noise groups. We set the rows in <inline-formula id="IE113"><mml:math id="IM112" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> corresponding to the noise to 0. SuffPCR is also amenable for solving other generalized linear models. For example, replacing line 12 in Algorithm 1 with logistic regression solves classification problems.</p>
        <p>
          <boxed-text id="vbac033-BOX2" position="float">
            <label>Algorithm 2</label>
            <caption>
              <p>Find a <italic toggle="yes">t</italic> to hard-threshold <italic toggle="yes">l</italic></p>
            </caption>
            <p>1: <bold>Input:</bold> a <italic toggle="yes">p</italic>-vector <italic toggle="yes">l</italic></p>
            <p>2: <bold>for</bold><inline-formula id="IE114"><mml:math id="IM113" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:math></inline-formula><bold>do</bold></p>
            <p>3: <inline-formula id="IE115"><mml:math id="IM114" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="monospace">var</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">l</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi mathvariant="italic">i</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></p>
            <p>4: <inline-formula id="IE116"><mml:math id="IM115" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="monospace">var</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">l</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>:</mml:mo><mml:mi>p</mml:mi><mml:mo mathvariant="italic">]</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></p>
            <p>5: <inline-formula id="IE117"><mml:math id="IM116" display="inline" overflow="scroll"><mml:mrow><mml:mi>T</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>*</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula></p>
            <p>6: <inline-formula id="IE118"><mml:math id="IM117" display="inline" overflow="scroll"><mml:mrow><mml:mo>δ</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>    ▹ empirical derivative of <italic toggle="yes">T</italic></p>
            <p>7: <bold>end for</bold></p>
            <p>8: Set <inline-formula id="IE119"><mml:math id="IM118" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>argmin</mml:mtext></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>{</mml:mo><mml:mo>δ</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>−</mml:mo><mml:mo>δ</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo>&gt;</mml:mo><mml:mi mathvariant="monospace">mean</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>|</mml:mo><mml:mo>δ</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>|</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula></p>
            <p>9: <bold>Return:</bold><inline-formula id="IE120"><mml:math id="IM119" display="inline" overflow="scroll"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula></p>
          </boxed-text>
        </p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Synthetic data experiments</title>
      <p>In this section, we show how SuffPCR performs on synthetic data and on real public genomics datasets relative to state-of-the-art methods. Section 2.2.1 first presents a generative model for synthetic data and motivates the assumptions required for our theoretical results in Section 2.2.4. We include here one synthetic experiment under conditions favorable to SuffPCR relative to SPC. We also investigate conditions favorable to SPC, the influence of tuning parameter selection, and the effect of the signal to noise ratio but defer these to the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>. Section 2.2.3 uses the non-small-cell lung cancer (NSCLC) data as the <bold>X</bold> matrix but creates the response from a linear model. Section 2.3 reports the performance of SuffPCR on 5 public genomics datasets. The <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> includes similar results for binary survival-status outcomes. Across most settings in both synthetic and real data, SuffPCR outperforms all competitors in prediction mean-squared error and is able to select the true genes (those with <inline-formula id="IE121"><mml:math id="IM120" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) more accurately. An R package implementing SuffPCR and raw data are freely available at <ext-link xlink:href="https://github.com/dajmcdon/suffpcr" ext-link-type="uri">https://github.com/dajmcdon/suffpcr</ext-link>. Package documentation may be viewed at <ext-link xlink:href="https://dajmcdon.github.io/suffpcr" ext-link-type="uri">https://dajmcdon.github.io/suffpcr</ext-link>.</p>
      <sec>
        <title>2.2.1 Experimental setup</title>
        <p>We generate data from the multivatiate Gaussian linear model <inline-formula id="IE122"><mml:math id="IM121" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>ϵ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> where <inline-formula id="IE123"><mml:math id="IM122" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE124"><mml:math id="IM123" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> is the <italic toggle="yes">p</italic>-dimensional regression coefficient, <inline-formula id="IE125"><mml:math id="IM124" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>ϵ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mi mathvariant="normal">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. We impose an orthogonal factor model for the covariates <inline-formula id="IE126"><mml:math id="IM125" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> where <italic toggle="yes">u<sub>i</sub></italic> are generated from <inline-formula id="IE127"><mml:math id="IM126" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> independently, <inline-formula id="IE128"><mml:math id="IM127" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a diagonal matrix with entries <inline-formula id="IE129"><mml:math id="IM128" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in descending order, and <inline-formula id="IE130"><mml:math id="IM129" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> with <inline-formula id="IE131"><mml:math id="IM130" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. The vector <inline-formula id="IE132"><mml:math id="IM131" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> has i.i.d. <inline-formula id="IE133"><mml:math id="IM132" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> entries independent of <italic toggle="yes">u<sub>i</sub></italic>, and <inline-formula id="IE134"><mml:math id="IM133" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>x</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. We assume <inline-formula id="IE135"><mml:math id="IM134" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is row sparse with only <italic toggle="yes">s</italic> rows containing non-zero entries. These non-zero rows are the ‘true’ features to be discovered, and they correspond to <inline-formula id="IE136"><mml:math id="IM135" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
        <p>It is important to note that, under this model, the rows of <bold>X</bold> follow a multivariate Gaussian distribution independently, with mean 0 and full-rank covariance <inline-formula id="IE137"><mml:math id="IM136" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mi mathvariant="bold">L</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> whenever <inline-formula id="IE138"><mml:math id="IM137" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. Here, the columns of <bold>V</bold> are orthonormal eigenvectors on <inline-formula id="IE139"><mml:math id="IM138" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and the eigenvalues are <inline-formula id="IE140"><mml:math id="IM139" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>≥</mml:mo><mml:mo>⋯</mml:mo><mml:mo>≥</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. Straightforward calculation shows that the first <italic toggle="yes">d</italic> columns in <bold>V</bold> are the same as the right singular vectors <inline-formula id="IE141"><mml:math id="IM140" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in the signal component of <bold>X</bold>. Furthermore, <inline-formula id="IE142"><mml:math id="IM141" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mn>1</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:math></inline-formula>.</p>
        <p>We generate <inline-formula id="IE143"><mml:math id="IM142" display="inline" overflow="scroll"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> as a linear function of the latent factors <inline-formula id="IE144"><mml:math id="IM143" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> with additive Gaussian noise: <inline-formula id="IE145"><mml:math id="IM144" display="inline" overflow="scroll"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>Θ</mml:mo><mml:mo>+</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> where Θ is the regression coefficient, and <italic toggle="yes">z<sub>i</sub></italic> are i.i.d. <inline-formula id="IE146"><mml:math id="IM145" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>, independent of <bold>X</bold>. Under this model the population marginal correlation between each feature in <bold>X</bold> and <italic toggle="yes">y</italic> is <inline-formula id="IE147"><mml:math id="IM146" display="inline" overflow="scroll"><mml:mrow><mml:mo>Φ</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>Θ</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> and the population OLS coefficient of regressing <italic toggle="yes">y</italic> on <bold>X</bold> is <inline-formula id="IE148"><mml:math id="IM147" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">L</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>Θ</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> Note that the number of non-zero <inline-formula id="IE149"><mml:math id="IM148" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> is <italic toggle="yes">s</italic>, because <inline-formula id="IE150"><mml:math id="IM149" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> has only <italic toggle="yes">s</italic> rows with non-zero entries.</p>
        <p>In all cases, we use <italic toggle="yes">n </italic>=<italic toggle="yes"> </italic>100 observations and <italic toggle="yes">p </italic>=<italic toggle="yes"> </italic>1000 features, generating three equal-sized sets for training, validation and testing. We use prediction accuracy on the validation set to select tuning parameters for all methods. For the case of SuffPCR, this means only <italic toggle="yes">λ</italic>, because we choose <italic toggle="yes">t</italic> with Algorithm 2 and set <italic toggle="yes">d </italic>=<italic toggle="yes"> </italic>3. We use the test set for evaluating out-of-sample performance. Each simulation is repeated 50 times. Results with <italic toggle="yes">n </italic>=<italic toggle="yes"> </italic>200 and <italic toggle="yes">p </italic>=<italic toggle="yes"> </italic>5000 were similar. Algorithm 3 makes this entire procedure more explicit.</p>
        <p>We compare SuffPCR with a number of alternative methods. The Oracle estimator uses OLS on the true features and serves as a natural baseline: it uses information unavailable to the analyst (the true genes) but represents the best method were that information available. We also present results for Lasso (<xref rid="vbac033-B34" ref-type="bibr">Tibshirani, 1996</xref>), Ridge (<xref rid="vbac033-B19" ref-type="bibr">Hoerl and Kennard, 1970</xref>), Elastic Net (<xref rid="vbac033-B39" ref-type="bibr">Zou and Hastie, 2005</xref>), SPC (<xref rid="vbac033-B5" ref-type="bibr">Bair <italic toggle="yes">et al.</italic>, 2006</xref>), AIMER (<xref rid="vbac033-B11" ref-type="bibr">Ding and McDonald, 2017</xref>), ISPCA (<xref rid="vbac033-B31" ref-type="bibr">Piironen and Vehtari, 2018</xref>) and PCR using FPS directly without feature screening (using Algorithm 1 without Steps 9–11). For ISPCA, we use the <monospace>dimreduce</monospace> R package to estimate the principal components before performing regression. For all competitors, we choose any tuning parameters that do not have default values using the validation set. Examples are <italic toggle="yes">λ</italic> in Lasso, Ridge and Elastic Net or the initial thresholding step in SPC. We use the correct embedding dimension (<italic toggle="yes">d </italic>=<italic toggle="yes"> </italic>3) whenever this is meaningful. Additional experiments are given in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>. There, we investigate conditions favorable to SPC, the choice of <italic toggle="yes">d</italic> and the impact of different SNR choices.</p>
        <boxed-text id="vbac033-BOX3" position="float">
          <label>Algorithm 3 Generate synthetic data</label>
          <p>1: <bold>Input:</bold> <italic toggle="yes">n </italic>=<italic toggle="yes"> </italic>100, <italic toggle="yes">p </italic>=<italic toggle="yes"> </italic>1000, <italic toggle="yes">r </italic>=<italic toggle="yes"> </italic>5, <italic toggle="yes">d </italic>=<italic toggle="yes"> </italic>3, <inline-formula id="IE1511"><mml:math id="IM1501" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>SNR</mml:mtext></mml:mrow></mml:mrow><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>SNR</mml:mtext></mml:mrow></mml:mrow><mml:mi>y</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
          <p>2: Generate i.i.d. <inline-formula id="IE152"><mml:math id="IM151" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE153"><mml:math id="IM152" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">E</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>z</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
          <p>3: Set <inline-formula id="IE154"><mml:math id="IM153" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
          <p>4: Generate i.i.d. <inline-formula id="IE155"><mml:math id="IM154" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo> </mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and orthogonalize the columns.</p>
          <p>5: Extend <inline-formula id="IE156"><mml:math id="IM155" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> by repeating each row <italic toggle="yes">r</italic> times (<italic toggle="yes">s</italic> = <italic toggle="yes">rd</italic>).</p>
          <p>6: Set <inline-formula id="IE157"><mml:math id="IM156" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mo> </mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
          <p>7: Generate i.i.d. <inline-formula id="IE158"><mml:math id="IM157" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo> </mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>Θ</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
          <p>8: Set <inline-formula id="IE159"><mml:math id="IM158" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>Θ</mml:mo></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>Θ</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
          <p>9: Set <inline-formula id="IE1601"><mml:math id="IM1591" display="inline" overflow="scroll"><mml:mrow><mml:mo>Θ</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>Θ</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>Θ</mml:mo></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
          <p>10: Set <inline-formula id="IE161"><mml:math id="IM160" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">L</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>Θ</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
          <p>11: Set <inline-formula id="IE162"><mml:math id="IM161" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mtext>tr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:msubsup><mml:mrow><mml:mrow><mml:mtext>SNR</mml:mtext></mml:mrow></mml:mrow><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></p>
          <p>12: Set <inline-formula id="IE163"><mml:math id="IM162" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mrow><mml:mo>*</mml:mo><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:msubsup><mml:mrow><mml:mrow><mml:mtext>SNR</mml:mtext></mml:mrow></mml:mrow><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
          <p>13: Set <inline-formula id="IE164"><mml:math id="IM163" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>x</mml:mi></mml:msub><mml:mi mathvariant="bold">E</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE165"><mml:math id="IM164" display="inline" overflow="scroll"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>Θ</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>y</mml:mi></mml:msub><mml:mi>z</mml:mi></mml:mrow></mml:math></inline-formula></p>
        </boxed-text>
      </sec>
      <sec>
        <title>2.2.2 Conditions favorable to SuffPCR</title>
        <p>The first setting is designed to show the advantages of SuffPCR relative to alternative methods, especially SPC. We note that other methods that employ screening by the marginal correlation (<xref rid="vbac033-B11" ref-type="bibr">Ding and McDonald, 2017</xref>; <xref rid="vbac033-B31" ref-type="bibr">Piironen and Vehtari, 2018</xref>) will have similar deficiencies. Because SPC works well if <xref rid="E1" ref-type="disp-formula">Equation (1)</xref> holds, we design <inline-formula id="IE166"><mml:math id="IM165" display="inline" overflow="scroll"><mml:mi mathvariant="bold">Σ</mml:mi></mml:math></inline-formula> to violate this condition and set the first 15 features to have non-zero <inline-formula id="IE167"><mml:math id="IM166" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> but allow only the first 10 features to have non-zero correlation with the phenotype. This behaviour is achieved with Line 8 of Algorithm 3. By solving this equation in one unknown component of Θ, we force Φ = 0 for the third group of 5 components. Thus, as described in above, <xref rid="E1" ref-type="disp-formula">Equation (1)</xref> will not hold: some <inline-formula id="IE168"><mml:math id="IM167" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>Φ</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> but <inline-formula id="IE169"><mml:math id="IM168" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. We set the true dimension of the subspace as <italic toggle="yes">d </italic>=<italic toggle="yes"> </italic>3, and we use the correct dimension for methods based on principal components.</p>
        <p><xref rid="vbac033-F2" ref-type="fig">Figure 2</xref> shows the performance of SuffPCR and state-of-the-art alternatives. In addition to reporting each method’s prediction MSE on the test set, we also show the number of features selected, precision, recall and the receiver operating characteristic (ROC) curve. The ISPCA implementation does not select features. In this example, SuffPCR actually outperforms the oracle estimator, attaining smaller MSE while generally selecting the correct features. This seemingly implausible result is likely because the variance of estimating OLS on 15 features is large relative to that of estimating the low-dimensional manifold followed by 3 regression coefficients. SuffPCR has a clear advantage over all the alternative methods, especially SPC which is three orders of magnitude worse. SPC works so poorly because it ignores five features. ISPCA has slightly lower MSE than SPC. Ridge is the worst, due to fitting a dense model when a sparse model generated the data. SuffPCR reduces MSE significantly relative to simply using FPS due to more accurate feature selection. The right plot in <xref rid="vbac033-F2" ref-type="fig">Figure 2</xref> further shows the ROC curve for SuffPCR, Lasso, Elastic Net, SPC and AIMER in which we can easily vary the tuning parameter and select various numbers of features. SuffPCR and AIMER have a perfect ROC curve, while the other three methods are unable to identify five features. We undertake a similar exercise under conditions favorable to SPC in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
        <fig position="float" id="vbac033-F2">
          <label>Fig. 2.</label>
          <caption>
            <p>This figure compares the performance of SuffPCR against alternatives when the features come from a row-sparse factor model under favorable conditions for SuffPCR. Boxplots and ROC curve (far right figure) are over 50 replications. We have omitted the other methods from the ROC curve for legibility, but their behavior is similar to lasso. TPR and FPR stand for true/false positive rate, respectively. Note that (as one would expect from the simulation conditions) SPC has the worst performance in terms of the ROC curve while both SuffPCR and Elastic net have AUC of almost 1</p>
          </caption>
          <graphic xlink:href="vbac033f2" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>2.2.3 Semi-synthetic analysis with real genomics data</title>
        <p>The simulations in Section 2.2.2 explore various scenarios for the data generation process and show the performance of SuffPCR relative to the alternatives; however, they do not use any real genomic data. In this section, rather than fully generating <bold>X</bold>, we create a semi-synthetic analysis wherein only the phenotypes are generated. We first performed PCA on the NSCLC data (<xref rid="vbac033-B23" ref-type="bibr">Lazar <italic toggle="yes">et al.</italic>, 2013</xref>) and note that the first two empirical eigenvalues are relatively large, so we chose the number of PCs to be <italic toggle="yes">d </italic>=<italic toggle="yes"> </italic>2. We keep the top 20 rows in the empirical <bold>V</bold> which have the largest norm and set the rest to 0. We then recombine and add noise. The phenotype is constructed as in the previous simulations, and the SNR is calibrated as above. <xref rid="vbac033-F3" ref-type="fig">Figure 3</xref> shows the results analogous to those in <xref rid="vbac033-F2" ref-type="fig">Figure 2</xref>. SuffPCR continues to perform well relative to alternatives, though here, FPS has similar MSE, albeit poor feature selection.</p>
        <fig position="float" id="vbac033-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>This figure compares the performance of SuffPCR against alternatives when the features come from a row-sparse factor model extracted from the NSCLC data. Boxplots and ROC curve (far right figure) are over 50 replications. In terms of the ROC curve, SPC and AIMER have the best performance, though SuffPCR is not far behind. But note that SPC has much worse precision and recall</p>
          </caption>
          <graphic xlink:href="vbac033f3" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec>
      <title>2.3 Analysis of real genomics data</title>
      <p>We analyze five microarray datasets that are publicly available and widely used as benchmarks. Four of the datasets present mRNA abundance measurements from patients with breast cancer (<xref rid="vbac033-B36" ref-type="bibr">Van’t Veer <italic toggle="yes">et al.</italic>, 2002</xref>; <xref rid="vbac033-B28" ref-type="bibr">Miller <italic toggle="yes">et al.</italic>, 2005</xref>), diffuse large B-cell lymphoma (DLBCL) (<xref rid="vbac033-B32" ref-type="bibr">Rosenwald <italic toggle="yes">et al.</italic>, 2002</xref>) and AML (<xref rid="vbac033-B6" ref-type="bibr">Bullinger <italic toggle="yes">et al.</italic>, 2004</xref>), and the fifth reports microRNA (miRNA) levels from NSCLC patients (<xref rid="vbac033-B23" ref-type="bibr">Lazar <italic toggle="yes">et al.</italic>, 2013</xref>). The features in <bold>X</bold> are gene expression measurements from microarrays. In the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>, we apply SuffPCR to predict COVID-19 viral load from RNA-Seq data.</p>
      <p>The phenotypes <italic toggle="yes">Y</italic> are censored survival time in all cases, though some of the datasets also contain binary survival status indicators. Because the real valued phenotype is non-negative and right censored, we follow common practice and transform <italic toggle="yes">Y</italic> to <inline-formula id="IE170"><mml:math id="IM169" display="inline" overflow="scroll"><mml:mrow><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Each observation is a unique patient. The first breast cancer dataset has 78 observations and 4751 genes, the second has 253 observations and 11 331 genes, DLBCL has 240 observations and 7399 genes, AML has 116 observations and 6283 genes and NSCLC has 123 observations and 939 genes.</p>
      <p>We randomly split each dataset into 3-fold for training, validation and testing with proportions 40%, 30% and 30% respectively. We set the number of components <italic toggle="yes">d </italic>=<italic toggle="yes"> </italic>3 and search over 5 log-linearly spaced <italic toggle="yes">λ</italic> values. Other choices for <italic toggle="yes">d</italic> and <italic toggle="yes">λ</italic> yield similar results. We train all methods on the training set, use the validation set to choose any necessary tuning parameters and report performance of each method on the test set. We repeat the entire process (data splitting, validation and testing) 10 times to reduce any bias induced by the random splits. In all cases, all methods were tuned to optimize validation-set MSE.</p>
      <p><xref rid="vbac033-T2" ref-type="table">Table 2</xref> shows the average prediction MSE and the average number of selected features for SuffPCR and any alternative methods that perform feature selection. SuffPCR works better than all the alternative methods on 4 out of 5 datasets with a comparatively small number of features selected. The DLBCL data are difficult for both sparse and PC-based methods. As described above, FPS cannot be used for these data sets because of the number of genes. Non-sparse alternatives have much smaller MSE, suggesting that many genes may play a roll in mortality rather than only a subset. SPCA is designed to maximize the variance explained by the principal components subject to a penalty on the non-sparsity, and it does not seem to work well in regression tasks. DSPCA has relatively low prediction MSE, and it does in principle perform feature selection, though it generally produces a dense model. While Ridge, Random Forests and SVM predict well in general, they do not perform any feature selection, which is a key objective here, so show their MSE in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
      <table-wrap position="float" id="vbac033-T2">
        <label>Table 2.</label>
        <caption>
          <p>Prediction MSE and number of selected features for regression of survival time on gene expression measurements</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th colspan="2" align="center" rowspan="1">Breast Cancer1<hr/></th>
              <th colspan="2" align="center" rowspan="1">Breast Cancer2<hr/></th>
              <th colspan="2" align="center" rowspan="1">DLBCL<hr/></th>
              <th colspan="2" align="center" rowspan="1">AML<hr/></th>
              <th colspan="2" align="center" rowspan="1">NSCLC<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">Method</th>
              <th align="center" rowspan="1" colspan="1">MSE</th>
              <th align="center" rowspan="1" colspan="1">Feature #</th>
              <th align="center" rowspan="1" colspan="1">MSE</th>
              <th align="center" rowspan="1" colspan="1">Feature #</th>
              <th align="center" rowspan="1" colspan="1">MSE</th>
              <th align="center" rowspan="1" colspan="1">Feature #</th>
              <th align="center" rowspan="1" colspan="1">MSE</th>
              <th align="center" rowspan="1" colspan="1">Feature #</th>
              <th align="center" rowspan="1" colspan="1">MSE</th>
              <th align="center" rowspan="1" colspan="1">Feature #</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SuffPCR</td>
              <td rowspan="1" colspan="1">
                <bold>0.5980</bold>
              </td>
              <td rowspan="1" colspan="1">80</td>
              <td rowspan="1" colspan="1">
                <bold>0.4168</bold>
              </td>
              <td rowspan="1" colspan="1">121</td>
              <td rowspan="1" colspan="1">0.7073</td>
              <td rowspan="1" colspan="1">48</td>
              <td rowspan="1" colspan="1">
                <bold>1.9568</bold>
              </td>
              <td rowspan="1" colspan="1">75</td>
              <td rowspan="1" colspan="1">
                <bold>0.1970</bold>
              </td>
              <td rowspan="1" colspan="1">27</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Lasso</td>
              <td rowspan="1" colspan="1">0.7141</td>
              <td rowspan="1" colspan="1">7</td>
              <td rowspan="1" colspan="1">0.4622</td>
              <td rowspan="1" colspan="1">39</td>
              <td rowspan="1" colspan="1">0.6992</td>
              <td rowspan="1" colspan="1">31</td>
              <td rowspan="1" colspan="1">2.0998</td>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">0.2263</td>
              <td rowspan="1" colspan="1">4</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ElasticNet</td>
              <td rowspan="1" colspan="1">0.6845</td>
              <td rowspan="1" colspan="1">41</td>
              <td rowspan="1" colspan="1">0.4517</td>
              <td rowspan="1" colspan="1">104</td>
              <td rowspan="1" colspan="1">
                <bold>0.6869</bold>
              </td>
              <td rowspan="1" colspan="1">87</td>
              <td rowspan="1" colspan="1">2.0820</td>
              <td rowspan="1" colspan="1">5</td>
              <td rowspan="1" colspan="1">0.2332</td>
              <td rowspan="1" colspan="1">20</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SPC</td>
              <td rowspan="1" colspan="1">0.6188</td>
              <td rowspan="1" colspan="1">59</td>
              <td rowspan="1" colspan="1">0.4179</td>
              <td rowspan="1" colspan="1">823</td>
              <td rowspan="1" colspan="1">0.7677</td>
              <td rowspan="1" colspan="1">67</td>
              <td rowspan="1" colspan="1">2.3237</td>
              <td rowspan="1" colspan="1">62</td>
              <td rowspan="1" colspan="1">0.2795</td>
              <td rowspan="1" colspan="1">62</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ISPCA</td>
              <td rowspan="1" colspan="1">0.8647</td>
              <td rowspan="1" colspan="1">NA</td>
              <td rowspan="1" colspan="1">0.5882</td>
              <td rowspan="1" colspan="1">NA</td>
              <td rowspan="1" colspan="1">0.9441</td>
              <td rowspan="1" colspan="1">NA</td>
              <td rowspan="1" colspan="1">2.3109</td>
              <td rowspan="1" colspan="1">NA</td>
              <td rowspan="1" colspan="1">0.2408</td>
              <td rowspan="1" colspan="1">NA</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AIMER</td>
              <td rowspan="1" colspan="1">0.6629</td>
              <td rowspan="1" colspan="1">76</td>
              <td rowspan="1" colspan="1">0.4192</td>
              <td rowspan="1" colspan="1">795</td>
              <td rowspan="1" colspan="1">0.7003</td>
              <td rowspan="1" colspan="1">76</td>
              <td rowspan="1" colspan="1">1.9737</td>
              <td rowspan="1" colspan="1">36</td>
              <td rowspan="1" colspan="1">0.2120</td>
              <td rowspan="1" colspan="1">50</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SPCA</td>
              <td rowspan="1" colspan="1">17.0965</td>
              <td rowspan="1" colspan="1">212</td>
              <td rowspan="1" colspan="1">4.7239</td>
              <td rowspan="1" colspan="1">38</td>
              <td rowspan="1" colspan="1">2.5980</td>
              <td rowspan="1" colspan="1">652</td>
              <td rowspan="1" colspan="1">31.11</td>
              <td rowspan="1" colspan="1">1043</td>
              <td rowspan="1" colspan="1">0.9757</td>
              <td rowspan="1" colspan="1">387</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DSPCA</td>
              <td rowspan="1" colspan="1">0.6132</td>
              <td rowspan="1" colspan="1">4374</td>
              <td rowspan="1" colspan="1">0.4557</td>
              <td rowspan="1" colspan="1">7880</td>
              <td rowspan="1" colspan="1">0.7249</td>
              <td rowspan="1" colspan="1">1342</td>
              <td rowspan="1" colspan="1">1.9781</td>
              <td rowspan="1" colspan="1">2742</td>
              <td rowspan="1" colspan="1">0.2041</td>
              <td rowspan="1" colspan="1">305</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p>Bolded text emphasizes the method with the lowest MSE.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>To assess the potential relevance of the genes selected by SuffPCR to the cancer type from which they were identified, we further explored the DLBCL data and extracted the selected genes. (We do the same with AML in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.) We first find the best <italic toggle="yes">λ</italic> via 5-fold cross-validation on all the data and then train SuffPCR with this <italic toggle="yes">λ</italic>. Our model selects 87 features corresponding to 32 unique genes and 2 expressed sequence tags (ESTs) for DLBCL. Seventeen of the identified genes encode ribosomal proteins, overexpression of which is associated with poor prognosis (<xref rid="vbac033-B12" ref-type="bibr">Ednersson <italic toggle="yes">et al.</italic>, 2018</xref>). A further nine genes encoding major histocompatibility complex class II (MHCII) proteins were detected, a notable finding in light of the fact that MHCII downregulation is a means by which some DLBCLs evade the immune system (<xref rid="vbac033-B10" ref-type="bibr">de Charette and Houot, 2018</xref>). Discovering these large groups of similarly functioning genes illustrates the benefits of SuffPCR relative to alternatives. <italic toggle="yes">CORO1A</italic> encodes the actin-binding tumor suppressor p57/coronin-1a, the promoter of which is often hypermethylated, and therefore likely silenced in DLBCL (<xref rid="vbac033-B25" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2002</xref>). <italic toggle="yes">FEZ1</italic> expression has been used in a prognostic model (<xref rid="vbac033-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2019</xref>). <italic toggle="yes">RAG1</italic>, encoding a protein involved in generating antibody diversity, can induce specific genetic aberrations found in DLBCL (<xref rid="vbac033-B27" ref-type="bibr">Miao <italic toggle="yes">et al.</italic>, 2019</xref>). <italic toggle="yes">RYK</italic> encodes a catalytically dead receptor tyrosine kinase involved in Wnt signaling and <italic toggle="yes">CXCL5</italic> encodes a chemokine. To our knowledge, neither gene has been implicated in DLBCL and thus may be of interest for further exploration. EST Hs.22635 (GenBank accession <ext-link xlink:href="AA262469" ext-link-type="DDBJ/EMBL/GenBank">AA262469</ext-link>) corresponds to a portion of <italic toggle="yes">ZBTB44</italic>, which encodes an uncharacterized transcriptional repressor, while EST Hs.343870 (GenBank accession <ext-link xlink:href="AA804270" ext-link-type="DDBJ/EMBL/GenBank">AA804270</ext-link>) does not appear to be contained within an annotated gene. The <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> lists the selected genes and associated references. A separate listing of the genes encoding ribosomal and MHCII proteins are given in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
    </sec>
    <sec>
      <title>2.4 Theoretical guarantees</title>
      <p>When the sparse factor model described in Section 2.2.1 is true, SuffPCR enjoys near-optimal convergence rates. We now make the necessary assumptions concrete and note that some can be weakened.<disp-quote content-type="extract"><p>A1 <inline-formula id="IE171"><mml:math id="IM170" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>ϵ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE172"><mml:math id="IM171" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>ϵ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mi mathvariant="normal">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>y</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>y</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>A2 <inline-formula id="IE173"><mml:math id="IM172" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>.</p><p>A3 <inline-formula id="IE174"><mml:math id="IM173" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mi mathvariant="bold">L</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, is symmetric, <inline-formula id="IE175"><mml:math id="IM174" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msup><mml:mi mathvariant="bold">V</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <bold>L</bold> is diagonal.</p><p>A4 <inline-formula id="IE176"><mml:math id="IM175" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mn>1</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE177"><mml:math id="IM176" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mo>ϕ</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>A5 <inline-formula id="IE178"><mml:math id="IM177" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mtext>diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>0</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE179"><mml:math id="IM178" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>min</mml:mi></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi mathvariant="sans-serif">T</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∨</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn><mml:mo>τ</mml:mo></mml:mrow></mml:math></inline-formula>.</p><p>A6 as <inline-formula id="IE180"><mml:math id="IM179" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>→</mml:mo><mml:mo>∞</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>n</mml:mi><mml:mo>&gt;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> eventually.</p></disp-quote></p>
      <p>Assumptions A1–A4 are the same as those used in Section 2.2.1 to generate data from a linear factor model. Assumption A5 says that the number of true nonzero coefficients <inline-formula id="IE181"><mml:math id="IM180" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> must be no more than <italic toggle="yes">s</italic> and that the size of the associated components must be large enough. Assumption A6 means that eventually, we must have at least as many observations <italic toggle="yes">n</italic> as a logarithmic function of <italic toggle="yes">p</italic> times the true number of components plus the square of the number of nonzero <inline-formula id="IE182"><mml:math id="IM181" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> coefficients.<statement id="mthst5"><p><sc>Theorem</sc> 1. <italic toggle="yes">Suppose Assumptions A1–</italic><italic toggle="yes">A6 hold and let</italic> <inline-formula id="IE183"><mml:math id="IM182" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula><italic toggle="yes">be the estimate produced by</italic> SuffPCR <italic toggle="yes">with</italic> <inline-formula id="IE184"><mml:math id="IM183" display="inline" overflow="scroll"><mml:mrow><mml:mo>λ</mml:mo><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:msqrt><mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula><italic toggle="yes">and</italic> <inline-formula id="IE185"><mml:math id="IM184" display="inline" overflow="scroll"><mml:mrow><mml:mi>t</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>2</mml:mn><mml:mo>τ</mml:mo></mml:mrow></mml:math></inline-formula><italic toggle="yes">where t is the threshold used in Algorithm 1 and τ is given in A5. Then</italic><disp-formula id="E5"><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">O</mml:mi></mml:mrow><mml:mi>P</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></statement><statement id="mthst6"><p><sc>Theorem</sc> 2. <italic toggle="yes">Suppose Assumptions A1–</italic><italic toggle="yes">A6 hold and let</italic> <inline-formula id="IE186"><mml:math id="IM185" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula><italic toggle="yes">be the estimate produced by</italic> SuffPCR <italic toggle="yes">with</italic> <inline-formula id="IE187"><mml:math id="IM186" display="inline" overflow="scroll"><mml:mrow><mml:mo>λ</mml:mo><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:msqrt><mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula><italic toggle="yes">and</italic> <inline-formula id="IE188"><mml:math id="IM187" display="inline" overflow="scroll"><mml:mrow><mml:mn>2</mml:mn><mml:mo>τ</mml:mo><mml:mo>&gt;</mml:mo><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:mo>τ</mml:mo></mml:mrow></mml:math></inline-formula><italic toggle="yes">where t is the threshold used in Algorithm 1 and τ is given in A5. Then</italic><disp-formula id="E6"><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mtext>supp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>△</mml:mo><mml:mtext>supp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script" class="calligraphy">O</mml:mi></mml:mrow><mml:mi>P</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><italic toggle="yes">where</italic> <inline-formula id="IE189"><mml:math id="IM188" display="inline" overflow="scroll"><mml:mrow><mml:mi>A</mml:mi><mml:mo>△</mml:mo><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo>/</mml:mo><mml:mi>B</mml:mi><mml:mo>∪</mml:mo><mml:mi>B</mml:mi><mml:mo>/</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:math></inline-formula><italic toggle="yes">is the symmetric difference operator and</italic> <inline-formula id="IE190"><mml:math id="IM189" display="inline" overflow="scroll"><mml:mrow><mml:mtext>supp</mml:mtext></mml:mrow></mml:math></inline-formula><italic toggle="yes">denotes the support set.</italic></p></statement></p>
      <p>In both results above, <italic toggle="yes">c</italic> is a positive number (possibly different between the two) that is independent of <italic toggle="yes">n</italic> and <italic toggle="yes">p</italic> but may depend on any of the other values given in A1–A6. Theorem 1 gives a convergence rate for the prediction error of SuffPCR comparable to that of Lasso though with explicit additional dependence on <italic toggle="yes">d</italic>. Under standard assumptions with fixed design, this dependence would not exist for Lasso. On the other hand, our results are for random design with <italic toggle="yes">d</italic> small, along with different constants absorbed by the big-<inline-formula id="IE191"><mml:math id="IM190" display="inline" overflow="scroll"><mml:mi mathvariant="script" class="calligraphy">O</mml:mi></mml:math></inline-formula>. Theorem 2 shows that our procedure can correctly recover the set of nonzero <inline-formula id="IE192"><mml:math id="IM191" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> as long as the threshold <italic toggle="yes">t</italic> is chosen correctly. We note that this result is a direct consequence of <xref rid="vbac033-B38" ref-type="bibr">Vu <italic toggle="yes">et al.</italic> (2013</xref>, Theorem 3.2). In practice, the condition <inline-formula id="IE193"><mml:math id="IM192" display="inline" overflow="scroll"><mml:mrow><mml:mn>2</mml:mn><mml:mo>τ</mml:mo><mml:mo>&gt;</mml:mo><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:mo>τ</mml:mo></mml:mrow></mml:math></inline-formula> cannot be verified, although the ‘elbow’ condition we employ in the empirical examples seems to work well. Finally, we emphasize that, as is standard in the literature, these results are for asymptotically optimal tuning parameters <inline-formula id="IE194"><mml:math id="IM193" display="inline" overflow="scroll"><mml:mrow><mml:mo>λ</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> rather than empirically chosen values. The proof of Theorem 1 is given in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>. These results suggest that SuffPCR is nearly optimal as <italic toggle="yes">p</italic> and <italic toggle="yes">n</italic> grow.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Discussion</title>
    <p>High-dimensional prediction methods, including regression and classification, are widely used to gain biological insights from large datasets. Three main goals in this setting are accurate prediction, feature selection and computational tractability. We propose a new method called SuffPCR which is capable of achieving these goals simultaneously. SuffPCR is a linear predictor on estimated sparse principal components. Because of the sparsity of the projected subspace, SuffPCR usually selects a small number of features. We conduct a series of synthetic, semi-synthetic and real data analyses to demonstrate the performance of SuffPCR and compare it with existing techniques. We also prove near-optimal convergence rates of SuffPCR under sparse assumptions. SuffPCR works better than alternative methods when the true model only involves a subset of features.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>The authors gratefully acknowledge support National Science Foundation (grant DMS–1753171 to D.J.M.), the National Institutes of Health (grant R35GM128631 to G.E.Z.) and the National Sciences and Engineering Research Council of Canada (NSERC) (grant RGPIN-2021-02618 to D.J.M.).</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>vbac033_Supplementary_Data</label>
      <media xlink:href="vbac033_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="vbac033-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alter</surname><given-names>O.</given-names></string-name></person-group><etal>et al</etal> (<year>2000</year>) <article-title>Singular value decomposition for genome-wide expression data processing and modeling</article-title>. <source>Proc. Natl. Acad. Sci. U S A</source>, <volume>97</volume>, <fpage>10101</fpage>–<lpage>10106</lpage>.<pub-id pub-id-type="pmid">10963673</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baglama</surname><given-names>J.</given-names></string-name>, <string-name><surname>Reichel</surname><given-names>L.</given-names></string-name></person-group> (<year>2005</year>) <article-title>Augmented implicitly restarted Lanczos bidiagonalization methods</article-title>. <source>SIAM J. Sci. Comput</source>., <volume>27</volume>, <fpage>19</fpage>–<lpage>42</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac033-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Baglama</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <italic toggle="yes">irlba: Fast Truncated Singular Value Decomposition and Principal Components Analysis for Large Dense and Sparse Matrices</italic>. R package version 2.3.3.</mixed-citation>
    </ref>
    <ref id="vbac033-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bair</surname><given-names>E.</given-names></string-name>, <string-name><surname>Tibshirani</surname><given-names>R.</given-names></string-name></person-group> (<year>2004</year>) <article-title>Semi-supervised methods to predict patient survival from gene expression data</article-title>. <source>PLoS Biol</source>., <volume>2</volume>, <fpage>e108</fpage>.<pub-id pub-id-type="pmid">15094809</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bair</surname><given-names>E.</given-names></string-name></person-group><etal>et al</etal> (<year>2006</year>) <article-title>Prediction by supervised principal components</article-title>. <source>J. Am. Stat. Assoc</source>., <volume>101</volume>, <fpage>119</fpage>–<lpage>137</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac033-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bullinger</surname><given-names>L.</given-names></string-name></person-group><etal>et al</etal> (<year>2004</year>) <article-title>Gene expression profiling identifies new subclasses and improves outcome prediction in adult myeloid leukemia</article-title>. <source>N. Engl. J. Med</source>., <volume>350</volume>, <fpage>1605</fpage>–<lpage>1616</lpage>.<pub-id pub-id-type="pmid">15084693</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cera</surname><given-names>I.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Genes encoding SATB2-interacting proteins in adult cerebral cortex contribute to human cognitive ability</article-title>. <source>PLoS Genet</source>., <volume>15</volume>, <fpage>e1007890</fpage>.<pub-id pub-id-type="pmid">30726206</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chakraborty</surname><given-names>S.</given-names></string-name></person-group> (<year>2019</year>) <article-title>Use of partial least squares improves the efficacy of removing unwanted variability in differential expression analyses based on RNA-Seq data</article-title>. <source>Genomics</source>, <volume>111</volume>, <fpage>893</fpage>–<lpage>898</lpage>.<pub-id pub-id-type="pmid">29842947</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B9">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>d’Aspremont</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2005</year>) <part-title>A direct formulation for sparse PCA using semidefinite programming</part-title>. In: <source>NeurIPS</source>, MIT Press, Cambridge, MA, USA, pp. <fpage>41</fpage>–<lpage>48</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac033-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Charette</surname><given-names>M.</given-names></string-name>, <string-name><surname>Houot</surname><given-names>R.</given-names></string-name></person-group> (<year>2018</year>) <article-title>Hide or defend, the two strategies of lymphoma immune evasion: potential implications for immunotherapy</article-title>. <source>Haematologica</source>, <volume>103</volume>, <fpage>1256</fpage>–<lpage>1268</lpage>.<pub-id pub-id-type="pmid">30006449</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ding</surname><given-names>L.</given-names></string-name>, <string-name><surname>McDonald</surname><given-names>D.J.</given-names></string-name></person-group> (<year>2017</year>) <article-title>Predicting phenotypes from microarrays using amplified, initially marginal, eigenvector regression</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>i350</fpage>–<lpage>i358</lpage>.<pub-id pub-id-type="pmid">28881997</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ednersson</surname><given-names>S.B.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Expression of ribosomal and actin network proteins and immunochemotherapy resistance in diffuse large B cell lymphoma patients</article-title>. <source>Br. J. Haematol</source>., <volume>181</volume>, <fpage>770</fpage>–<lpage>781</lpage>.<pub-id pub-id-type="pmid">29767447</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friedman</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2008</year>) <article-title>Sparse inverse covariance estimation with the graphical lasso</article-title>. <source>Biostatistics</source>, <volume>9</volume>, <fpage>432</fpage>–<lpage>441</lpage>.<pub-id pub-id-type="pmid">18079126</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gittens</surname><given-names>A.</given-names></string-name>, <string-name><surname>Mahoney</surname><given-names>M.</given-names></string-name></person-group> (<year>2013</year>) Revisiting the Nyström method for improved large-scale machine learning. In: <italic toggle="yes">ICML, JMLR Workshop and Conference Proceedings</italic>. Vol. <volume>28</volume>, Atlanta, GA, pp. <fpage>567</fpage>–<lpage>575</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac033-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harel</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Predicting phenotypic diversity from molecular and genetic data</article-title>. <source>Genetics</source>, <volume>213</volume>, <fpage>297</fpage>–<lpage>311</lpage>.<pub-id pub-id-type="pmid">31352366</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hastie</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2000</year>) <article-title>‘Gene shaving’ as a method for identifying distinct sets of genes with similar expression patterns</article-title>. <source>Genome Biol</source>., <volume>1</volume>, <fpage>research0003.1</fpage>–<lpage>research0003.21</lpage>.<pub-id pub-id-type="pmid">11178228</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hastie</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2001</year>) <article-title>Supervised harvesting of expression trees</article-title>. <source>Genome Biol</source>., <volume>2</volume>, research0003.1–research0003.12.</mixed-citation>
    </ref>
    <ref id="vbac033-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Henningsson</surname><given-names>R.</given-names></string-name>, <string-name><surname>Fontes</surname><given-names>M.</given-names></string-name></person-group> (<year>2019</year>) <article-title>SMSSVD: subMatrix selection singular value decomposition</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>478</fpage>–<lpage>486</lpage>.<pub-id pub-id-type="pmid">30010791</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hoerl</surname><given-names>A.E.</given-names></string-name>, <string-name><surname>Kennard</surname><given-names>R.W.</given-names></string-name></person-group> (<year>1970</year>) <article-title>Ridge regression: biased estimation for nonorthogonal problems</article-title>. <source>Technometrics</source>, <volume>12</volume>, <fpage>55</fpage>–<lpage>67</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac033-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Homrighausen</surname><given-names>D.</given-names></string-name>, <string-name><surname>McDonald</surname><given-names>D.J.</given-names></string-name></person-group> (<year>2016</year>) <article-title>On the Nyström and column-sampling methods for the approximate principal components analysis of large data sets</article-title>. <source>J. Comput. Graph. Stat</source>., <volume>25</volume>, <fpage>344</fpage>–<lpage>362</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac033-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnstone</surname><given-names>I.M.</given-names></string-name>, <string-name><surname>Lu</surname><given-names>A.Y.</given-names></string-name></person-group> (<year>2009</year>) <article-title>On consistency and sparsity for principal components analysis in high dimensions</article-title>. <source>J. Am. Stat. Assoc</source>., <volume>104</volume>, <fpage>682</fpage>–<lpage>693</lpage>.<pub-id pub-id-type="pmid">20617121</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kabir</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Identifying maternal and infant factors associated with newborn size in rural Bangladesh by partial least squares (PLS) regression analysis</article-title>. <source>PLoS One</source>, <volume>12</volume>, <fpage>e0189677</fpage>.<pub-id pub-id-type="pmid">29261760</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lazar</surname><given-names>V.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <article-title>Integrated molecular portrait of non-small cell lung cancers</article-title>. <source>BMC Med. Genomics</source>, <volume>6</volume>, <fpage>53</fpage>.<pub-id pub-id-type="pmid">24299561</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Leek</surname><given-names>J.T.</given-names></string-name>, <string-name><surname>Storey</surname><given-names>J.D.</given-names></string-name></person-group> (<year>2007</year>) <article-title>Capturing heterogeneity in gene expression studies by surrogate variable analysis</article-title>. <source>PLoS Genet</source>., <volume>3</volume>, <fpage>e161</fpage>.<pub-id pub-id-type="pmid">17907809</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2002</year>) <article-title>Aberrant DNA methylation of p57KIP2 gene in the promoter region in lymphoid malignancies of B-cell phenotype</article-title>. <source>Blood</source>, <volume>100</volume>, <fpage>2572</fpage>–<lpage>2577</lpage>.<pub-id pub-id-type="pmid">12239171</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Screening of key genes associated with R-CHOP immunochemotherapy and construction of a prognostic risk model in diffuse large B-cell lymphoma</article-title>. <source>Mol. Med. Rep</source>., <volume>20</volume>, <fpage>3679</fpage>–<lpage>3690</lpage>.<pub-id pub-id-type="pmid">31485671</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miao</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Genetic alterations and their clinical implications in DLBCL</article-title>. <source>Nat. Rev. Clin. Oncol</source>., <volume>16</volume>, <fpage>634</fpage>–<lpage>652</lpage>.<pub-id pub-id-type="pmid">31127191</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miller</surname><given-names>L.D.</given-names></string-name></person-group><etal>et al</etal> (<year>2005</year>) <article-title>An expression signature for p53 status in human breast cancer predicts mutation status, transcriptional effects, and patient survival</article-title>. <source>Proc. Natl. Acad. Sci. U S A</source>, <volume>102</volume>, <fpage>13550</fpage>–<lpage>13555</lpage>.<pub-id pub-id-type="pmid">16141321</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Min</surname><given-names>W.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Edge-group sparse PCA for network-guided high dimensional data analysis</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>3479</fpage>–<lpage>3487</lpage>.<pub-id pub-id-type="pmid">29726900</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Paul</surname><given-names>D.</given-names></string-name></person-group><etal>et al</etal> (<year>2008</year>) <article-title>‘Preconditioning’ for feature selection and regression in high-dimensional problems</article-title>. <source>Ann. Stat</source>., <volume>36</volume>, <fpage>1595</fpage>–<lpage>1618</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac033-B31">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Piironen</surname><given-names>J.</given-names></string-name>, <string-name><surname>Vehtari</surname><given-names>A.</given-names></string-name></person-group> (<year>2018</year>) <article-title>Iterative supervised principal components</article-title>. In: <italic toggle="yes">AISTATS</italic>, <italic toggle="yes">Proceedings of Machine Learning Research</italic>. Vol. 84. PMLR, Playa Blanca, Lanzarote, Canary Islands, pp. <fpage>106</fpage>–<lpage>114</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac033-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rosenwald</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal>; <collab>Lymphoma/Leukemia Molecular Profiling Project</collab> (<year>2002</year>) <article-title>The use of molecular profiling to predict survival after chemotherapy for diffuse large-B-cell lymphoma</article-title>. <source>N. Engl. J. Med</source>., <volume>346</volume>, <fpage>1937</fpage>–<lpage>1947</lpage>.<pub-id pub-id-type="pmid">12075054</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tay</surname>,<given-names>J.K.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Principal component‐guided sparse regression</article-title>. <source>Can. J. Stat.</source>, <volume>49</volume>, <fpage>1222</fpage>–<lpage>1257</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac033-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tibshirani</surname><given-names>R.</given-names></string-name></person-group> (<year>1996</year>) <article-title>Regression shrinkage and selection via the lasso</article-title>. <source>J. R. Stat. Soc. B</source>, <volume>58</volume>, <fpage>267</fpage>–<lpage>288</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac033-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Traglia</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Genetic mechanisms leading to sex differences across common diseases and anthropometric traits</article-title>. <source>Genetics</source>, <volume>205</volume>, <fpage>979</fpage>–<lpage>992</lpage>.<pub-id pub-id-type="pmid">27974502</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van’t Veer</surname><given-names>L.J.</given-names></string-name></person-group><etal>et al</etal> (<year>2002</year>) <article-title>Gene expression profiling predicts clinical outcome of breast cancer</article-title>. <source>Nature</source>, <volume>415</volume>, <fpage>530</fpage>.<pub-id pub-id-type="pmid">11823860</pub-id></mixed-citation>
    </ref>
    <ref id="vbac033-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vu</surname><given-names>V.Q.</given-names></string-name>, <string-name><surname>Lei</surname><given-names>J.</given-names></string-name></person-group> (<year>2013</year>) <article-title>Minimax sparse principal subspace estimation in high dimensions</article-title>. <source>Ann. Stat</source>., <volume>41</volume>, <fpage>2905</fpage>–<lpage>2947</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac033-B38">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Vu</surname><given-names>V.Q.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <part-title>Fantope projection and selection: a near-optimal convex relaxation of sparse PCA</part-title>. In: <source>NeurIPS</source>, Lake Tahoe, UT, pp. <fpage>2670</fpage>–<lpage>2678</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac033-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zou</surname><given-names>H.</given-names></string-name>, <string-name><surname>Hastie</surname><given-names>T.</given-names></string-name></person-group> (<year>2005</year>) <article-title>Regularization and variable selection via the elastic net</article-title>. <source>J. R. Stat. Soc. B</source>, <volume>67</volume>, <fpage>301</fpage>–<lpage>320</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac033-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zou</surname><given-names>H.</given-names></string-name></person-group><etal>et al</etal> (<year>2006</year>) <article-title>Sparse principal component analysis</article-title>. <source>J. Comput. Graph. Stat</source>., <volume>15</volume>, <fpage>265</fpage>–<lpage>286</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
