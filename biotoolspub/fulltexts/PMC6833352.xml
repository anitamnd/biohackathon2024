<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_DIB104670 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?properties open_access?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Data Brief</journal-id>
    <journal-id journal-id-type="iso-abbrev">Data Brief</journal-id>
    <journal-title-group>
      <journal-title>Data in Brief</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2352-3409</issn>
    <publisher>
      <publisher-name>Elsevier</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6833352</article-id>
    <article-id pub-id-type="publisher-id">S2352-3409(19)31025-X</article-id>
    <article-id pub-id-type="doi">10.1016/j.dib.2019.104670</article-id>
    <article-id pub-id-type="publisher-id">104670</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Computer Science</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Time-energy measured data on modern multicore systems running shared-memory applications</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au1">
        <name>
          <surname>Loghin</surname>
          <given-names>Dumitrel</given-names>
        </name>
        <email>dumitrel@comp.nus.edu.sg</email>
        <xref rid="cor1" ref-type="corresp">∗</xref>
      </contrib>
      <contrib contrib-type="author" id="au2">
        <name>
          <surname>Teo</surname>
          <given-names>Yong Meng</given-names>
        </name>
      </contrib>
    </contrib-group>
    <aff id="aff1">National University of Singapore, Singapore</aff>
    <author-notes>
      <corresp id="cor1"><label>∗</label>Corresponding author. <email>dumitrel@comp.nus.edu.sg</email></corresp>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>16</day>
      <month>10</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>16</day>
      <month>10</month>
      <year>2019</year>
    </pub-date>
    <volume>27</volume>
    <elocation-id>104670</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>8</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>30</day>
        <month>9</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>9</day>
        <month>10</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2019 The Authors</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="CC BY" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p>
      </license>
    </permissions>
    <related-article related-article-type="article-reference" id="d31e14" ext-link-type="doi" xlink:href="10.1016/j.parco.2019.04.009"/>
    <abstract id="abs0010">
      <p>This article presents execution time and energy data collected from modern multicore systems running shared-memory applications, analyzed using our analytic models. While the full data sets and source code are available on Github, this data-in-brief article includes some samples and describes the experimental setup.</p>
    </abstract>
    <kwd-group id="kwrds0010">
      <title>Keywords</title>
      <kwd>Time-energy performance</kwd>
      <kwd>Multicore system</kwd>
      <kwd>Shared-memory</kwd>
      <kwd>Amdahl's law</kwd>
      <kwd>Gustafson's law</kwd>
      <kwd>Analytic model</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <p id="p0010">
    <table-wrap position="float" id="undtbl1">
      <caption>
        <p>Specifications Table</p>
      </caption>
      <table frame="hsides" rules="groups">
        <tbody>
          <tr>
            <td>Subject area</td>
            <td>
              <italic>Computer Science</italic>
            </td>
          </tr>
          <tr>
            <td>More specific subject area</td>
            <td>
              <italic>Parallel Systems Performance</italic>
            </td>
          </tr>
          <tr>
            <td>Type of data</td>
            <td>
              <italic>Tables and figures</italic>
            </td>
          </tr>
          <tr>
            <td>How data was acquired</td>
            <td>
              <italic>Power and energy data were collected with a Yokogawa WT210 power meter</italic>
            </td>
          </tr>
          <tr>
            <td>Data format</td>
            <td>
              <italic>Raw and filtered</italic>
            </td>
          </tr>
          <tr>
            <td>Experimental factors</td>
            <td>
              <italic>Execution time and energy data were collected while the hardware system was running only the target shared memory application and the operating systems. The measured data includes noise from the operating system. There is no pretreatment of samples or data.</italic>
            </td>
          </tr>
          <tr>
            <td>Experimental features</td>
            <td>
              <italic>- Power and energy data were collected with a Yokogawa WT210 at a rate of one sample per second</italic>
              <break/>
              <italic>- Execution time represents wall clock time and is measured in Linux using/usr/bin/time</italic>
            </td>
          </tr>
          <tr>
            <td>Data source location</td>
            <td>
              <italic>Singapore</italic>
            </td>
          </tr>
          <tr>
            <td>Data accessibility</td>
            <td>
              <italic>The data and source code associated with this paper are available on Github:</italic>
              <ext-link ext-link-type="uri" xlink:href="https://github.com/dloghin/multicores-time-energy" id="intref0010">https://github.com/dloghin/multicores-time-energy</ext-link>
            </td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap position="float" id="undtbl2">
      <table frame="hsides" rules="groups">
        <tbody>
          <tr>
            <td>
              <bold>Value of the Data</bold>
              <list list-type="simple" id="ulist0010">
                <list-item id="u0010">
                  <label>•</label>
                  <p id="p0015">This set of data includes execution time and energy measurements of up to ten shared-memory applications covering multiple domains on a wide range of modern multicore systems. These systems include both high-performance and low-power, homogeneous and heterogeneous, and are representative for server, desktop and mobile domains.</p>
                </list-item>
                <list-item id="u0015">
                  <label>•</label>
                  <p id="p0020">The data can be used to understand the time and energy performance of modern shared-memory multicore systems. It can serve as a reference for other researchers in the domain.</p>
                </list-item>
                <list-item id="u0020">
                  <label>•</label>
                  <p id="p0025">The source code implements the models described in our work [<xref rid="bib1" ref-type="bibr">1</xref>,<xref rid="bib2" ref-type="bibr">2</xref>] and serves as a starting point for researchers, developers and system designers</p>
                </list-item>
              </list>
            </td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </p>
  <sec id="sec1">
    <label>1</label>
    <title>Data</title>
    <p id="p0030">In this article we present the time-energy data measured for shared-memory applications running on modern multicore systems [<xref rid="bib1" ref-type="bibr">1</xref>,<xref rid="bib2" ref-type="bibr">2</xref>]. We provide two main data sets for each system and application, (i) measured, or raw, time-energy values as shown in <xref rid="tbl3" ref-type="table">Table 3</xref>, <xref rid="tbl4" ref-type="table">Table 4</xref>, <xref rid="tbl5" ref-type="table">Table 5</xref>, <xref rid="tbl6" ref-type="table">Table 6</xref>, <xref rid="tbl7" ref-type="table">Table 7</xref> and (ii) model output as shown in <xref rid="tbl8" ref-type="table">Table 8</xref>, <xref rid="tbl9" ref-type="table">Table 9</xref>. <xref rid="tbl3" ref-type="table">Table 3</xref> presents measured data on homogeneo <xref rid="tbl4" ref-type="table">Table 4</xref>, <xref rid="tbl5" ref-type="table">Table 5</xref>, <xref rid="tbl6" ref-type="table">Table 6</xref> present measured data on heterogeneous multicores with static OpenMP scheduling when big, little and all cores, respectively, are used. <xref rid="tbl7" ref-type="table">Table 7</xref> presents measured data on heterogeneous multicores with dynamic OpenMP scheduling when all cores are used. <xref rid="tbl8" ref-type="table">Table 8</xref> shows model's output per system and application, while <xref rid="tbl9" ref-type="table">Table 9</xref> presents a summary of model accuracy per system for all applications and speedup laws used, with respect to the sequential fraction and energy savings. The data in <xref rid="tbl8" ref-type="table">Table 8</xref>, corresponding to Amdahl's law [<xref rid="bib3" ref-type="bibr">3</xref>], is plotted in <xref rid="fig2" ref-type="fig">Fig. 2</xref>. The corresponding data derived with Gustafson's law [<xref rid="bib4" ref-type="bibr">4</xref>] is plotted in <xref rid="fig3" ref-type="fig">Fig. 3</xref>.</p>
  </sec>
  <sec id="sec2">
    <label>2</label>
    <title>Experimental design, materials and methods</title>
    <sec id="sec2.1">
      <label>2.1</label>
      <title>Setup</title>
      <p id="p0035">The experimental setup is depicted in <xref rid="fig1" ref-type="fig">Fig. 1</xref>. To collect power and energy, we use a Yokogawa WT201 power meter connected to the 240V AC power line. A controller system is used to start the experiments and collect execution and energy data from the target system. The power and energy samples are collected once per second. <xref rid="tbl1" ref-type="table">Table 1</xref> summarizes the characteristics of the target systems used in our measurements.<fig id="fig1"><label>Fig. 1</label><caption><p>Experimental setup.</p></caption><alt-text id="alttext0010">Fig. 1</alt-text><graphic xlink:href="gr1"/></fig><table-wrap position="float" id="tbl1"><label>Table 1</label><caption><p>Systems.</p></caption><alt-text id="alttext0025">Table 1</alt-text><table frame="hsides" rules="groups"><thead><tr><th>System</th><th>CPU</th><th>Cores</th><th>Frequency [GHz]</th><th>Memory [GB]</th></tr></thead><tbody><tr><td>AMD</td><td>AMD Opteron K10</td><td>48</td><td>2.10</td><td>64 (NUMA)</td></tr><tr><td>ARM</td><td>Cavium ThunderX (64-bit ARM)</td><td>48</td><td>2.00</td><td>128 (UMA)</td></tr><tr><td>Xeon</td><td>Intel Xeon E5-2630 v4</td><td>10 (20 HT)</td><td>2.20</td><td>64 (UMA)</td></tr><tr><td>i7</td><td>Intel Core i7-6700</td><td>4 (8 HT)</td><td>3.40</td><td>16</td></tr><tr><td>Pi3</td><td>ARM Cortex-A53</td><td>4</td><td>1.20</td><td>1</td></tr><tr><td>XU3</td><td>ARM big.LITTLE HMP (ARM Cortex-A15 + ARM Cortex-A7)</td><td>8 (4 + 4)</td><td>2.00</td><td>2</td></tr><tr><td>TX2</td><td>HMP (Denver + ARM Cortex-A57)</td><td>6 (2 + 4)</td><td>2.04</td><td>8</td></tr></tbody></table></table-wrap></p>
      <p id="p0040"><xref rid="tbl2" ref-type="table">Table 2</xref> summarizes the shared-memory applications with their input parameters, as used for collecting the measurements. These applications are selected from well-known benchmarking suites, such as NPB [<xref rid="bib5" ref-type="bibr">5</xref>], Rodinia [<xref rid="bib6" ref-type="bibr">6</xref>], Parsec [<xref rid="bib7" ref-type="bibr">7</xref>] and Mantevo [<xref rid="bib8" ref-type="bibr">8</xref>]. In addition to the first seven applications presented in our research work [<xref rid="bib1" ref-type="bibr">1</xref>,<xref rid="bib2" ref-type="bibr">2</xref>], we provide data for CloverLeaf (CL), miniFE (FE) and miniGhost (GH) benchmarks from Mantevo suite [<xref rid="bib8" ref-type="bibr">8</xref>], running on Xeon, i7 and Pi3.<table-wrap position="float" id="tbl2"><label>Table 2</label><caption><p>Applications.</p></caption><alt-text id="alttext0030">Table 2</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Application</th><th>Benchmark Suite</th><th>Input Size</th><th>OpenMP Scheduling</th></tr></thead><tbody><tr><td>EP (Embarrassingly Parallel)</td><td>NPB [<xref rid="bib5" ref-type="bibr">5</xref>]</td><td>Class C (Random-number pairs: 2<sup>32</sup>)</td><td>default</td></tr><tr><td>BT (Block Tri-diagonal Solver)</td><td>NPB [<xref rid="bib5" ref-type="bibr">5</xref>]</td><td>Class C (Grid size: 162 × 162 x 162,<break/>Iterations: 200)</td><td>static</td></tr><tr><td>SP (Scalar Penta-Diagonal solver)</td><td>NPB [<xref rid="bib5" ref-type="bibr">5</xref>]</td><td>Class C (Grid size: 162 × 162 x 162,<break/>Iterations: 400)</td><td>Static</td></tr><tr><td>LV (LavaMD)</td><td>Rodinia [<xref rid="bib6" ref-type="bibr">6</xref>]</td><td>Boxes1d: 24</td><td>default</td></tr><tr><td>KM (Kmeans)</td><td>Rodinia [<xref rid="bib6" ref-type="bibr">6</xref>]</td><td>n = 1,000,000 m = 34 k = 5</td><td>static</td></tr><tr><td>PF (Pathfinder)</td><td>Rodinia [<xref rid="bib6" ref-type="bibr">6</xref>]</td><td>Width (rows): 900,000, Steps (columns): 500</td><td>default</td></tr><tr><td>BS (BlackScholes)</td><td>Parsec [<xref rid="bib7" ref-type="bibr">7</xref>]</td><td>4,000,000 options</td><td>default</td></tr><tr><td>CL (CloverLeaf)</td><td>Mantevo [<xref rid="bib8" ref-type="bibr">8</xref>]</td><td>Grid size 1000, end_time = 30.0</td><td>default</td></tr><tr><td>FE (miniFE)</td><td>Mantevo [<xref rid="bib8" ref-type="bibr">8</xref>]</td><td>nx = 150</td><td>default</td></tr><tr><td>GH (miniGhost)</td><td>Mantevo [<xref rid="bib8" ref-type="bibr">8</xref>]</td><td>nx = 100, num_tsteps = 1000</td><td>default</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="sec2.2">
      <label>2.2</label>
      <title>Measured data</title>
      <p id="p0045">Measured time-energy data consists of seven columns, as shown in <xref rid="tbl3" ref-type="table">Table 3</xref> for EP execution on Xeon. Each row represents the execution on a number of cores of the given application on the given system. The columns represent the number of nodes, number of cores per node, the core clock frequency of the cores, the execution time in seconds (s), the energy in Watts-hour (Wh) and Joules (J), and the average power consumption in Watts (W). The number of nodes is always one because these experiments are run on single-node shared-memory multicore systems. To apply our models [<xref rid="bib1" ref-type="bibr">1</xref>,<xref rid="bib2" ref-type="bibr">2</xref>], the key columns to consider are Cores, Time and Energy.<table-wrap position="float" id="tbl3"><label>Table 3</label><caption><p>Raw time-energy measurements (EP on Xeon).</p></caption><alt-text id="alttext0035">Table 3</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Procs</th><th>Cores</th><th>Freq</th><th>Time [s]</th><th>Energy [Wh]</th><th>Energy [J]</th><th>AvgPower [W]</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2.20GHz</td><td>384.14</td><td>8.46</td><td>30,456</td><td>79.48</td></tr><tr><td>1</td><td>2</td><td>2.20GHz</td><td>195.63</td><td>4.60</td><td>16,560</td><td>84.93</td></tr><tr><td>1</td><td>3</td><td>2.20GHz</td><td>138.33</td><td>3.36</td><td>12,096</td><td>88.32</td></tr><tr><td>1</td><td>4</td><td>2.20GHz</td><td>106.39</td><td>2.71</td><td>9756</td><td>92.10</td></tr><tr><td>1</td><td>5</td><td>2.20GHz</td><td>89.29</td><td>2.31</td><td>8316</td><td>94.73</td></tr><tr><td>1</td><td>6</td><td>2.20GHz</td><td>77.76</td><td>2.08</td><td>7488</td><td>97.18</td></tr><tr><td>1</td><td>7</td><td>2.20GHz</td><td>69.07</td><td>1.87</td><td>6732</td><td>99.04</td></tr><tr><td>1</td><td>8</td><td>2.20GHz</td><td>62.09</td><td>1.73</td><td>6228</td><td>100.73</td></tr><tr><td>1</td><td>9</td><td>2.20GHz</td><td>55.23</td><td>1.58</td><td>5688</td><td>103.89</td></tr><tr><td>1</td><td>10</td><td>2.20GHz</td><td>49.65</td><td>1.46</td><td>5256</td><td>107.49</td></tr><tr><td>1</td><td>11</td><td>2.20GHz</td><td>49.64</td><td>1.46</td><td>5256</td><td>107.85</td></tr><tr><td>1</td><td>12</td><td>2.20GHz</td><td>45.94</td><td>1.37</td><td>4932</td><td>109.42</td></tr><tr><td>1</td><td>13</td><td>2.20GHz</td><td>42.85</td><td>1.28</td><td>4608</td><td>110.22</td></tr><tr><td>1</td><td>14</td><td>2.20GHz</td><td>40.12</td><td>1.20</td><td>4320</td><td>110.81</td></tr><tr><td>1</td><td>15</td><td>2.20GHz</td><td>37.48</td><td>1.14</td><td>4104</td><td>112.08</td></tr><tr><td>1</td><td>16</td><td>2.20GHz</td><td>35.42</td><td>1.10</td><td>3960</td><td>112.64</td></tr><tr><td>1</td><td>17</td><td>2.20GHz</td><td>34.02</td><td>1.06</td><td>3816</td><td>112.98</td></tr><tr><td>1</td><td>18</td><td>2.20GHz</td><td>31.58</td><td>0.97</td><td>3492</td><td>113.88</td></tr><tr><td>1</td><td>19</td><td>2.20GHz</td><td>29.93</td><td>0.92</td><td>3312</td><td>114.54</td></tr><tr><td>1</td><td>20</td><td>2.20GHz</td><td>28.83</td><td>0.89</td><td>3204</td><td>115.21</td></tr></tbody></table></table-wrap></p>
      <p id="p0050">For heterogeneous systems, such as XU3 and TX2, we provide four measured data sets per application, as exemplified in <xref rid="tbl4" ref-type="table">Table 4</xref>, <xref rid="tbl5" ref-type="table">Table 5</xref>, <xref rid="tbl6" ref-type="table">Table 6</xref>, <xref rid="tbl7" ref-type="table">Table 7</xref> for EP on XU3. The first two data sets represent the execution with OpenMP static scheduling on big and little cores, respectively. The last two data sets represent the execution on all cores using static and dynamic OpenMP execution, respectively.<table-wrap position="float" id="tbl4"><label>Table 4</label><caption><p>Raw time-energy measurements on big cores with static scheduling (EP on XU3).</p></caption><alt-text id="alttext0040">Table 4</alt-text><table frame="hsides" rules="groups"><thead><tr><th>#Procs</th><th>Cores</th><th>Freq</th><th>Time [s]</th><th>Energy [Wh]</th><th>Energy [J]</th><th>AvgPower [W]</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2.00GHz</td><td>710.81</td><td>0.02</td><td>60.12</td><td>9.27</td></tr><tr><td>1</td><td>2</td><td>2.00GHz</td><td>363.58</td><td>0.01</td><td>42.12</td><td>12.51</td></tr><tr><td>1</td><td>3</td><td>2.00GHz</td><td>250.09</td><td>0.01</td><td>36.00</td><td>15.03</td></tr><tr><td>1</td><td>4</td><td>2.00GHz</td><td>197.88</td><td>0.01</td><td>29.52</td><td>15.56</td></tr></tbody></table></table-wrap><table-wrap position="float" id="tbl5"><label>Table 5</label><caption><p>Raw time-energy measurements on little cores with static scheduling (EP on XU3).</p></caption><alt-text id="alttext0045">Table 5</alt-text><table frame="hsides" rules="groups"><thead><tr><th>#Procs</th><th>Cores</th><th>Freq</th><th>Time [s]</th><th>Energy [Wh]</th><th>Energy [J]</th><th>AvgPower [W]</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2.00GHz</td><td>1607.79</td><td>0.03</td><td>99.00</td><td>6.65</td></tr><tr><td>1</td><td>2</td><td>2.00GHz</td><td>820.67</td><td>0.01</td><td>53.28</td><td>7.10</td></tr><tr><td>1</td><td>3</td><td>2.00GHz</td><td>548.60</td><td>0.01</td><td>37.80</td><td>7.51</td></tr><tr><td>1</td><td>4</td><td>2.00GHz</td><td>413.19</td><td>0.01</td><td>29.88</td><td>7.89</td></tr></tbody></table></table-wrap><table-wrap position="float" id="tbl6"><label>Table 6</label><caption><p>Raw time-energy measurements on all cores with static scheduling (EP on XU3).</p></caption><alt-text id="alttext0050">Table 6</alt-text><table frame="hsides" rules="groups"><thead><tr><th>#Procs</th><th>Cores</th><th>Freq</th><th>Time [s]</th><th>Energy [Wh]</th><th>Energy [J]</th><th>AvgPower [W]</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2.00GHz</td><td>714.61</td><td>0.017</td><td>61.2</td><td>9.24</td></tr><tr><td>1</td><td>2</td><td>2.00GHz</td><td>363.75</td><td>0.012</td><td>43.2</td><td>12.45</td></tr><tr><td>1</td><td>3</td><td>2.00GHz</td><td>250.87</td><td>0.01</td><td>36</td><td>14.69</td></tr><tr><td>1</td><td>4</td><td>2.00GHz</td><td>198.74</td><td>0.008</td><td>28.8</td><td>15.32</td></tr><tr><td>1</td><td>5</td><td>2.00GHz</td><td>321.7</td><td>0.01</td><td>36</td><td>10.94</td></tr><tr><td>1</td><td>6</td><td>2.00GHz</td><td>273.5</td><td>0.008</td><td>28.8</td><td>11.10</td></tr><tr><td>1</td><td>7</td><td>2.00GHz</td><td>235.14</td><td>0.007</td><td>25.2</td><td>11.35</td></tr><tr><td>1</td><td>8</td><td>2.00GHz</td><td>206.75</td><td>0.007</td><td>25.2</td><td>11.67</td></tr></tbody></table></table-wrap><table-wrap position="float" id="tbl7"><label>Table 7</label><caption><p>Raw time-energy measurements on all cores with dynamic scheduling (EP on XU3).</p></caption><alt-text id="alttext0055">Table 7</alt-text><table frame="hsides" rules="groups"><thead><tr><th>#Procs</th><th>Cores</th><th>Freq</th><th>Time [s]</th><th>Energy [Wh]</th><th>Energy [J]</th><th>AvgPower [W]</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>2.00GHz</td><td>709.82</td><td>0.017</td><td>61.2</td><td>9.25</td></tr><tr><td>1</td><td>2</td><td>2.00GHz</td><td>364.94</td><td>0.012</td><td>43.2</td><td>12.47</td></tr><tr><td>1</td><td>3</td><td>2.00GHz</td><td>248.67</td><td>0.01</td><td>36</td><td>15.11</td></tr><tr><td>1</td><td>4</td><td>2.00GHz</td><td>198.96</td><td>0.008</td><td>28.8</td><td>15.31</td></tr><tr><td>1</td><td>5</td><td>2.00GHz</td><td>179.27</td><td>0.007</td><td>25.2</td><td>15.32</td></tr><tr><td>1</td><td>6</td><td>2.00GHz</td><td>162.8</td><td>0.007</td><td>25.2</td><td>15.41</td></tr><tr><td>1</td><td>7</td><td>2.00GHz</td><td>149.53</td><td>0.006</td><td>21.6</td><td>15.54</td></tr><tr><td>1</td><td>8</td><td>2.00GHz</td><td>137.73</td><td>0.006</td><td>21.6</td><td>15.67</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="sec2.3">
      <label>2.3</label>
      <title>Model output data</title>
      <p id="p0055">Our analytic models [<xref rid="bib1" ref-type="bibr">1</xref>,<xref rid="bib2" ref-type="bibr">2</xref>] are implemented in Python and can be run on a Linux system using the provided bash scripts. There are two wrapper scripts corresponding to homogeneous and heterogeneous systems, respectively. Besides speedup and energy data, these scripts take as parameters the number of cores, the active power fraction (APF) [<xref rid="bib1" ref-type="bibr">1</xref>,<xref rid="bib2" ref-type="bibr">2</xref>] and the idle power of the system. By tweaking these parameters, users can explore new system designs and estimate their time-energy efficiency.</p>
      <p id="p0060">Model output data consists of nine columns, as shown in <xref rid="tbl8" ref-type="table">Table 8</xref> for EP running on Xeon when Amdahl's law [<xref rid="bib3" ref-type="bibr">3</xref>] for speedup is used. The first column represents the number of cores used for execution, while the other eight columns represent measured and predicted speedup, energy savings, execution time and energy, respectively.<table-wrap position="float" id="tbl8"><label>Table 8</label><caption><p>Model output data (EP on Xeon, Amdahl's law).</p></caption><alt-text id="alttext0060">Table 8</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Cores</th><th>Measured Speedup</th><th>Predicted Speedup</th><th>Measured Energy Savings</th><th>Predicted Energy Savings</th><th>Measured Time</th><th>Predicted Time</th><th>Measured Energy</th><th>Predicted Energy</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>384.1</td><td>384.1</td><td>30,530</td><td>24,233.8</td></tr><tr><td>2</td><td>1.96</td><td>1.94</td><td>0.456</td><td>0.464</td><td>195.6</td><td>198</td><td>16,615.1</td><td>13,024.5</td></tr><tr><td>3</td><td>2.78</td><td>2.82</td><td>0.6</td><td>0.619</td><td>138.3</td><td>136</td><td>12,217.2</td><td>9288</td></tr><tr><td>4</td><td>3.61</td><td>3.66</td><td>0.679</td><td>0.696</td><td>106.4</td><td>105</td><td>9798.4</td><td>7419.8</td></tr><tr><td>5</td><td>4.3</td><td>4.45</td><td>0.723</td><td>0.743</td><td>89.3</td><td>86.4</td><td>8458.3</td><td>6298.9</td></tr><tr><td>6</td><td>4.94</td><td>5.19</td><td>0.752</td><td>0.773</td><td>77.8</td><td>73.9</td><td>7556.8</td><td>5551.6</td></tr><tr><td>7</td><td>5.56</td><td>5.9</td><td>0.776</td><td>0.796</td><td>69.1</td><td>65.1</td><td>6841</td><td>5017.8</td></tr><tr><td>8</td><td>6.19</td><td>6.57</td><td>0.795</td><td>0.812</td><td>62.1</td><td>58.4</td><td>6254.2</td><td>4617.5</td></tr><tr><td>9</td><td>6.96</td><td>7.21</td><td>0.812</td><td>0.825</td><td>55.2</td><td>53.3</td><td>5737.6</td><td>4306.1</td></tr><tr><td>10</td><td>7.74</td><td>7.82</td><td>0.825</td><td>0.835</td><td>49.6</td><td>49.1</td><td>5336.9</td><td>4057</td></tr><tr><td>11</td><td>7.74</td><td>8.4</td><td>0.825</td><td>0.844</td><td>49.6</td><td>45.7</td><td>5353.9</td><td>3853.2</td></tr><tr><td>12</td><td>8.36</td><td>8.95</td><td>0.835</td><td>0.851</td><td>45.9</td><td>42.9</td><td>5026.8</td><td>3683.4</td></tr><tr><td>13</td><td>8.96</td><td>9.47</td><td>0.845</td><td>0.857</td><td>42.9</td><td>40.5</td><td>4723</td><td>3539.7</td></tr><tr><td>14</td><td>9.57</td><td>9.98</td><td>0.854</td><td>0.862</td><td>40.1</td><td>38.5</td><td>4445.6</td><td>3416.5</td></tr><tr><td>15</td><td>10.25</td><td>10.46</td><td>0.862</td><td>0.866</td><td>37.5</td><td>36.7</td><td>4200.6</td><td>3309.7</td></tr><tr><td>16</td><td>10.85</td><td>10.92</td><td>0.869</td><td>0.87</td><td>35.4</td><td>35.2</td><td>3989.6</td><td>3216.3</td></tr><tr><td>17</td><td>11.29</td><td>11.36</td><td>0.874</td><td>0.874</td><td>34</td><td>33.8</td><td>3843.4</td><td>3133.9</td></tr><tr><td>18</td><td>12.16</td><td>11.79</td><td>0.882</td><td>0.877</td><td>31.6</td><td>32.6</td><td>3596.3</td><td>3060.6</td></tr><tr><td>19</td><td>12.83</td><td>12.19</td><td>0.888</td><td>0.879</td><td>29.9</td><td>31.5</td><td>3428.1</td><td>2995.1</td></tr><tr><td>20</td><td>13.32</td><td>12.59</td><td>0.891</td><td>0.882</td><td>28.8</td><td>30.5</td><td>3321.6</td><td>2936.1</td></tr></tbody></table></table-wrap></p>
      <p id="p0065">In addition, the source code implementing the model reports the sequential fraction and the Root-Mean-Square Deviation (RMSD) between measured and predicted values across all core counts. A summary consisting of the sequential fraction (f), RMSD of the sequential fraction (RMSD(f)) and RMSD of energy savings (RMSD (es)) for each workload and for both Amdahl's and Gustafson's laws, is written in a <italic>stats.csv</italic> file for each system. <xref rid="tbl9" ref-type="table">Table 9</xref> exemplifies such data for the Xeon system.<table-wrap position="float" id="tbl9"><label>Table 9</label><caption><p>Model accuracy output (on Xeon).</p></caption><alt-text id="alttext0065">Table 9</alt-text><table frame="hsides" rules="groups"><thead><tr><th>#Val<hr/></th><th colspan="2">f<hr/></th><th colspan="2">RMSD(f)<hr/></th><th colspan="2">RMSD (es)<hr/></th></tr><tr><th>#App</th><th>Amdahl</th><th>Gustafson</th><th>Amdahl</th><th>Gustafson</th><th>Amdahl</th><th>Gustafson</th></tr></thead><tbody><tr><td>EP</td><td>0.03</td><td>0.33</td><td>0.373</td><td>0.406</td><td>1.3</td><td>2.3</td></tr><tr><td>LV</td><td>0.05</td><td>0.42</td><td>0.26</td><td>0.664</td><td>1.4</td><td>3.3</td></tr><tr><td>BT</td><td>0.1</td><td>0.62</td><td>0.512</td><td>1.09</td><td>3.1</td><td>7.5</td></tr><tr><td>SP</td><td>0.22</td><td>0.81</td><td>0.583</td><td>1.142</td><td>10.3</td><td>16.6</td></tr><tr><td>BS</td><td>0.06</td><td>0.5</td><td>0.249</td><td>0.594</td><td>1.2</td><td>4.5</td></tr><tr><td>KM</td><td>0.38</td><td>0.89</td><td>0.168</td><td>0.306</td><td>9.5</td><td>11.3</td></tr><tr><td>PF</td><td>0.46</td><td>0.93</td><td>0.036</td><td>0.305</td><td>2.2</td><td>11.8</td></tr><tr><td>CL</td><td>0.2</td><td>0.79</td><td>0.456</td><td>1.011</td><td>8.5</td><td>13.9</td></tr><tr><td>FE</td><td>0.19</td><td>0.78</td><td>0.284</td><td>0.902</td><td>7.4</td><td>11.5</td></tr><tr><td>GH</td><td>0.99</td><td>0.9999</td><td>0.028</td><td>0.029</td><td>2.6</td><td>2.5</td></tr></tbody></table></table-wrap></p>
      <p id="p0070">The speedup values in <xref rid="tbl8" ref-type="table">Table 8</xref> correspond to Amdahl's law [<xref rid="bib3" ref-type="bibr">3</xref>] and are used to plot <xref rid="fig2" ref-type="fig">Fig. 2</xref>. On the other hand, <xref rid="fig3" ref-type="fig">Fig. 3</xref> represents the same measurements, while the predicted speedup is determined using Gustafson's law [<xref rid="bib4" ref-type="bibr">4</xref>]. The results for other systems are presented in our research papers [<xref rid="bib1" ref-type="bibr">1</xref>,<xref rid="bib2" ref-type="bibr">2</xref>].<fig id="fig2"><label>Fig. 2</label><caption><p>Amdahl speedup on Xeon.</p></caption><alt-text id="alttext0015">Fig. 2</alt-text><graphic xlink:href="gr2"/></fig><fig id="fig3"><label>Fig. 3</label><caption><p>Gustafson speedup on Xeon.</p></caption><alt-text id="alttext0020">Fig. 3</alt-text><graphic xlink:href="gr3"/></fig></p>
    </sec>
  </sec>
</body>
<back>
  <ref-list id="cebib0010">
    <title>References</title>
    <ref id="bib1">
      <label>1</label>
      <element-citation publication-type="book" id="sref1">
        <person-group person-group-type="author">
          <name>
            <surname>Loghin</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Teo</surname>
            <given-names>Y.M.</given-names>
          </name>
        </person-group>
        <chapter-title>The energy efficiency of modern multicore systems</chapter-title>
        <source>Proc. of 47th International Conference on Parallel Processing Companion</source>
        <year>2018</year>
        <comment>pages 28:1–28:10</comment>
      </element-citation>
    </ref>
    <ref id="bib2">
      <label>2</label>
      <element-citation publication-type="journal" id="sref2">
        <person-group person-group-type="author">
          <name>
            <surname>Loghin</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Teo</surname>
            <given-names>Y.M.</given-names>
          </name>
        </person-group>
        <article-title>The time and energy efficiency of modern multicore systems</article-title>
        <source>Parallel Comput.</source>
        <volume>86</volume>
        <year>2019</year>
        <fpage>1</fpage>
        <lpage>13</lpage>
      </element-citation>
    </ref>
    <ref id="bib3">
      <label>3</label>
      <element-citation publication-type="book" id="sref3">
        <person-group person-group-type="author">
          <name>
            <surname>Amdahl</surname>
            <given-names>G.M.</given-names>
          </name>
        </person-group>
        <chapter-title>Validity of the Single Processor Approach to Achieving Large Scale Computing Capabilities, Proc. of April 18-20, 1967</chapter-title>
        <source>Spring Joint Computer Conference</source>
        <year>1967</year>
        <fpage>483</fpage>
        <lpage>485</lpage>
      </element-citation>
    </ref>
    <ref id="bib4">
      <label>4</label>
      <element-citation publication-type="journal" id="sref4">
        <person-group person-group-type="author">
          <name>
            <surname>Gustafson</surname>
            <given-names>J.L.</given-names>
          </name>
        </person-group>
        <article-title>Reevaluating Amdahl's law</article-title>
        <source>Commun. ACM</source>
        <volume>31</volume>
        <issue>5</issue>
        <year>1988</year>
        <fpage>532</fpage>
        <lpage>533</lpage>
      </element-citation>
    </ref>
    <ref id="bib5">
      <label>5</label>
      <element-citation publication-type="book" id="sref5">
        <person-group person-group-type="author">
          <name>
            <surname>Bailey</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Harris</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Saphir</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Van Der Wijngaart</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Woo</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Yarrow</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <chapter-title>The NAS Parallel Benchmarks 2.0, Technical Report NAS-95-020</chapter-title>
        <year>1995</year>
        <publisher-name>NASA Ames Research Center</publisher-name>
      </element-citation>
    </ref>
    <ref id="bib6">
      <label>6</label>
      <element-citation publication-type="book" id="sref6">
        <person-group person-group-type="author">
          <name>
            <surname>Che</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Boyer</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Tarjan</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Sheaffer</surname>
            <given-names>J.W.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>S.-H.</given-names>
          </name>
          <name>
            <surname>Skadron</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <chapter-title>Rodinia: a benchmark suite for heterogeneous computing</chapter-title>
        <source>Proc. of 2009 IEEE International Symposium on Workload Characterization</source>
        <year>2009</year>
        <fpage>44</fpage>
        <lpage>54</lpage>
      </element-citation>
    </ref>
    <ref id="bib7">
      <label>7</label>
      <element-citation publication-type="book" id="sref7">
        <person-group person-group-type="author">
          <name>
            <surname>Bienia</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>J.P.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <chapter-title>The PARSEC benchmark suite: characterization and architectural implications</chapter-title>
        <source>Proc. of 17th International Conference on Parallel Architectures and Compilation Techniques</source>
        <year>2008</year>
        <fpage>72</fpage>
        <lpage>81</lpage>
      </element-citation>
    </ref>
    <ref id="bib8">
      <label>8</label>
      <element-citation publication-type="book" id="sref8">
        <person-group person-group-type="author">
          <name>
            <surname>Heroux</surname>
            <given-names>M.A.</given-names>
          </name>
          <name>
            <surname>Doerfler</surname>
            <given-names>D.W.</given-names>
          </name>
          <name>
            <surname>Crozier</surname>
            <given-names>P.S.</given-names>
          </name>
          <name>
            <surname>Willenbring</surname>
            <given-names>J.M.</given-names>
          </name>
          <name>
            <surname>Edwards</surname>
            <given-names>H.C.</given-names>
          </name>
          <name>
            <surname>Williams</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Rajan</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Keiter</surname>
            <given-names>E.R.</given-names>
          </name>
          <name>
            <surname>Thornquist</surname>
            <given-names>H.K.</given-names>
          </name>
          <name>
            <surname>Numrich</surname>
            <given-names>R.W.</given-names>
          </name>
        </person-group>
        <chapter-title>Improving Performance via Mini-Applications</chapter-title>
        <year>2009</year>
        <publisher-name>Sandia National Laboratories</publisher-name>
        <comment>Technical Report SAND2009-5574</comment>
      </element-citation>
    </ref>
  </ref-list>
  <sec id="appsec1">
    <title>Conflict of interest</title>
    <p id="p0130">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
  </sec>
  <ack id="ack0010">
    <title>Acknowledgements</title>
    <p>This work was supported by the <funding-source id="gs1">Ministry of Education - Singapore</funding-source> through the Academic Research Fund Tier 1. The authors thank GIGABYTE for providing access to the 48-core R120-T30 ARM server, and NVIDIA for providing the Jetson TX2 development kit.</p>
  </ack>
</back>
